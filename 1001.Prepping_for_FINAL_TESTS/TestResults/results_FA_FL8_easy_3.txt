EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  0.008087473404076364
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 176, frames: 1011, time: 27.43383502960205
training steps:  2
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
176 : 0.0
LR:  1e-06
replay buffer size:  1250
Time Taken :  0.0  mins 27.433504104614258  seconds
[[[362. 120.   5.   3.   0.   0.   0.   0.]
  [189.  49.  16.   2.   0.   0.   0.   0.]
  [ 50.  11.   9.   2.   0.   0.   0.   0.]
  [  1.   5.   7.   0.   0.   0.   0.   0.]
  [  0.   0.   3.   1.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.33511516
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 1671, frames: 10150, time: 1366.1891777515411
training steps:  874
retraining steps:  0
RDN obj mus: [-0.9377208744227886, -0.9432763240516185, -0.9536154348194599, -0.9543774907217651, -0.4111662805080414]
RDN obj sigmas: [0.02895636111538191, 0.03886358588117275, 0.026289414196339813, 0.04403036987536982, 0.4111662805080414]
1671 : 0.0
LR:  0.000873
replay buffer size:  10668
Time Taken :  22.0  mins 46.18886208534241  seconds
[[[3504. 1110.   71.   36.   13.    1.    0.    0.]
  [2011.  542.  181.   40.    2.    0.    0.    0.]
  [ 475.  148.   84.   17.    1.    0.    0.    0.]
  [  12.   68.   48.   12.    1.    0.    0.    0.]
  [  10.   26.   13.   11.    0.    0.    0.    0.]
  [   1.    4.    3.    1.    2.    0.    0.    0.]
  [   0.    5.   11.    6.    1.    0.    0.    0.]
  [   0.    2.    1.    4.    1.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.48332947
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 3069, frames: 20038, time: 3322.166228055954
training steps:  1731
retraining steps:  0
RDN obj mus: [-0.9257953800439834, -0.9659969075262547, -0.9449950093984604, -0.9559426607090832, -0.8173854202032089]
RDN obj sigmas: [0.03674442383767125, 0.01708660868751656, 0.0408542538711872, 0.04101036016553708, 0.31199328469599136]
3069 : 0.0
LR:  0.001
replay buffer size:  20732
Time Taken :  55.0  mins 22.165905952453613  seconds
[[[7245. 2025.  143.   76.   35.    4.    0.    0.]
  [3961. 1092.  361.   74.    5.    2.    0.    0.]
  [ 867.  363.  187.   39.    1.    0.    0.    0.]
  [  26.  128.   85.   18.    3.    0.    0.    0.]
  [  14.   49.   36.   18.    1.    0.    0.    0.]
  [   5.   11.   11.    8.   10.    5.    0.    0.]
  [   3.    9.   12.    9.    8.    8.    1.    0.]
  [   0.    3.    1.    4.    2.    1.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.56314147
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0021}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.00199960002
Episodes: 3964, frames: 30250, time: 14672.453066825867
training steps:  2598
retraining steps:  0
RDN obj mus: [-0.9236200966060162, -0.9520192095339298, -0.9575557483732701, -0.9547628593683243, -0.935710932648182]
RDN obj sigmas: [0.03760933954382927, 0.017895403206977287, 0.02417937760572351, 0.022956233637149107, 0.037968321781935106]
3964 : 0.0
LR:  0.001
replay buffer size:  31885
Time Taken :  244.0  mins 32.452752113342285  seconds
[[[8630. 2495.  433.  478.  147.   15.    0.    0.]
  [7233. 2441.  775.  152.   89.    6.    0.    0.]
  [1129.  602.  474.   68.   64.   19.    0.    0.]
  [  38.  222.  191.   79.    7.    0.    0.    0.]
  [  20.   78.  113.   25.    2.    0.    0.    0.]
  [  14.   40.   49.   10.   14.    5.    0.    4.]
  [  11.   14.   22.   16.    9.   11.    2.   13.]
  [   0.    5.    5.   11.    4.    1.    0.    1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.60832816
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0021}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.00199960002
Episodes: 4454, frames: 40062, time: 17255.550637722015
training steps:  3438
retraining steps:  0
RDN obj mus: [-0.9409489713966847, -0.9529840890884399, -0.9484866106033325, -0.9483113471925259, -0.9362526310563087]
RDN obj sigmas: [0.029171885220098327, 0.02536375880395068, 0.023728901130656763, 0.02135780173299687, 0.024888436567697774]
4454 : 0.0
LR:  0.001
replay buffer size:  41873
Time Taken :  287.0  mins 35.5503191947937  seconds
[[[9269. 2678.  630.  851.  417.   28.    0.    0.]
  [9729. 3430. 1012.  197.  196.   11.    0.    0.]
  [1254.  841.  742.   88.  123.   39.    0.    0.]
  [  52.  384.  476.  272.   15.   10.    0.    0.]
  [ 206.  404.  444.   49.    8.    9.    3.    0.]
  [  27.  163.  219.  170.   85.   47.   33.    7.]
  [ 111.   97.  224.  106.  122.   43.    7.   13.]
  [  40.   19.   78.  109.   11.    9.    0.    1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  4
maxi score:  0.0001
siam score:  -0.7696176
Scores:  {'0.167': 0.0001, '0.333': 0.0021, '0.5': 0.0021, '0.667': 0.0061, '0.833': 0.0081, '1.0': 0.0041}
best rdn ma / adv:  0.833 0.833
best rdn adv:  0.00799840008
Episodes: 4978, frames: 50279, time: 19643.671925783157
training steps:  4325
retraining steps:  0
RDN obj mus: [-0.964051196295023, -0.971972670418024, -0.9673858209431171, -0.958291686040163, -0.9422730773150921]
RDN obj sigmas: [0.01983672728762242, 0.013796983466419126, 0.020753579326696095, 0.022092379105618596, 0.038877403544315084]
4978 : 0.0
LR:  0.001
replay buffer size:  53073
Time Taken :  327.0  mins 23.671616077423096  seconds
[[[ 9982.  2891.   681.   893.   439.    28.     0.     0.]
  [11039.  3950.  1147.   213.   235.    15.     1.     0.]
  [ 1352.  1151.   884.    95.   162.    63.     9.     0.]
  [   66.   666.   705.   303.    19.    58.    21.     6.]
  [  364.   651.   690.    80.    22.    95.    21.    58.]
  [   50.   490.   634.   506.   253.   364.   193.    84.]
  [  169.   226.   480.   369.   372.   258.   225.   108.]
  [   72.    41.   332.   622.    48.   158.   181.    11.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  10
maxi score:  0.0021
siam score:  -0.8295504
Scores:  {'0.167': 0.0001, '0.333': 0.0021, '0.5': 0.0021, '0.667': 0.0061, '0.833': 0.0081, '1.0': 0.0061}
best rdn ma / adv:  0.833 0.833
best rdn adv:  0.00796643528
Episodes: 6280, frames: 60190, time: 21935.654933691025
training steps:  5179
retraining steps:  0
RDN obj mus: [-0.9490210082352162, -0.9602710017085075, -0.956199809640646, -0.9477863722741604, -0.926170883089304]
RDN obj sigmas: [0.031092707154695653, 0.02166229289624826, 0.02612536313987397, 0.02947017666441595, 0.03377169925255038]
6280 : 0.0
LR:  0.001
replay buffer size:  63708
Time Taken :  365.0  mins 35.654613971710205  seconds
[[[13073.  3835.   749.   944.   458.    32.     0.     0.]
  [12141.  4397.  1278.   237.   252.    19.     4.     0.]
  [ 1590.  1521.  1069.   115.   172.   126.    76.     2.]
  [   77.   964.   856.   320.    27.   115.    73.    49.]
  [  375.   752.   844.    93.    28.   139.    27.    86.]
  [   58.   586.   796.   575.   289.   396.   201.    84.]
  [  186.   296.   572.   402.   392.   274.   231.   109.]
  [   89.    48.   361.   636.    49.   162.   190.    13.]]]
Test reward:  0.48
Q value #end_state_>_threshold:  170
Q value #non_end_state_>threshold:  333
maxi score:  0.0241
siam score:  -0.8253966
Scores:  {'0.167': 0.0301, '0.333': 0.0521, '0.5': 0.048100000000000004, '0.667': 0.0241, '0.833': 0.0161, '1.0': 0.0241}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.04952380212000001
Episodes: 7166, frames: 70069, time: 24126.953878879547
training steps:  6028
retraining steps:  0
RDN obj mus: [-0.9576064752817154, -0.9589059957861901, -0.9531794602453708, -0.9485420139431954, -0.9407572437047959]
RDN obj sigmas: [0.022876305592803046, 0.025318595140197877, 0.024941122739309044, 0.027302016408758813, 0.028415906577235993]
7166 : 0.05
LR:  0.001
replay buffer size:  73921
Time Taken :  402.0  mins 6.953567028045654  seconds
[[[14327.  4341.   789.   983.   492.    35.     0.     0.]
  [12903.  4815.  1349.   249.   265.    42.     9.     0.]
  [ 1714.  1907.  1170.   131.   193.   272.   154.    33.]
  [   88.  1296.  1026.   341.    37.   300.   266.   430.]
  [  387.  1002.  1028.   106.    32.   247.    41.   239.]
  [   63.   836.  1087.   701.   407.   539.   266.   135.]
  [  204.   452.   775.   566.   572.   486.   468.   262.]
  [   91.    57.   382.   655.    61.   212.   488.    99.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  615
Q value #non_end_state_>threshold:  1423
maxi score:  0.0721
siam score:  -0.91861707
Scores:  {'0.167': 0.1061, '0.333': 0.1121, '0.5': 0.1061, '0.667': 0.0381, '0.833': 0.022099999999999998, '1.0': 0.0281}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.030284800000000004
Episodes: 7742, frames: 80151, time: 26359.942013025284
training steps:  6894
retraining steps:  0
RDN obj mus: [-0.9430482055664062, -0.959446365827322, -0.9619709791779518, -0.9613824739634991, -0.956467835599184]
RDN obj sigmas: [0.020670631707539393, 0.018424370420383786, 0.016780733066377954, 0.01603397569984042, 0.017675057236387397]
7742 : 0.3
LR:  0.001
replay buffer size:  84397
Time Taken :  439.0  mins 19.941694974899292  seconds
[[[15118.  4575.   794.   983.   492.    35.     0.     0.]
  [13484.  5208.  1382.   250.   266.    48.    11.     0.]
  [ 1772.  2247.  1271.   135.   199.   348.   198.    37.]
  [   99.  1592.  1172.   353.    43.   416.   349.   622.]
  [  393.  1270.  1233.   118.    50.   397.    66.   455.]
  [   85.  1137.  1486.   878.   642.   765.   398.   283.]
  [  340.   661.  1219.   935.   916.   908.   873.   510.]
  [  117.    71.   502.   757.    82.   341.   791.   231.]]]
Test reward:  0.96
Q value #end_state_>_threshold:  1018
Q value #non_end_state_>threshold:  3402
maxi score:  0.23609999999999998
siam score:  -0.9215962
Scores:  {'0.167': 0.1561, '0.333': 0.1341, '0.5': 0.1201, '0.667': 0.0461, '0.833': 0.0241, '1.0': 0.0301}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 8050, frames: 90302, time: 28634.36998486519
training steps:  7758
retraining steps:  0
RDN obj mus: [-0.9623261239111424, -0.9696889690220356, -0.9700121658563614, -0.9699455704450607, -0.9669712894737721]
RDN obj sigmas: [0.012885454100748787, 0.015049521464707904, 0.016282024547119068, 0.015407357030003252, 0.014477212629169508]
8050 : 0.4
LR:  0.001
replay buffer size:  95249
Time Taken :  477.0  mins 14.369669198989868  seconds
[[[15372.  4618.   795.   983.   492.    35.     0.     0.]
  [13923.  5535.  1406.   250.   266.    50.    12.     0.]
  [ 1800.  2586.  1356.   138.   208.   433.   263.    51.]
  [  110.  1864.  1327.   363.    49.   577.   447.   860.]
  [  404.  1515.  1452.   130.    67.   609.    88.   730.]
  [   95.  1404.  1927.  1163.   931.  1213.   590.   627.]
  [  484.   936.  1768.  1399.  1266.  1382.  1219.   760.]
  [  191.    92.   630.  1022.   101.   472.  1102.   314.]]]
Test reward:  0.92
Q value #end_state_>_threshold:  1247
Q value #non_end_state_>threshold:  5183
maxi score:  0.2801
siam score:  -0.90219146
Scores:  {'0.167': 0.20809999999999998, '0.333': 0.15009999999999998, '0.5': 0.1221, '0.667': 0.0461, '0.833': 0.0241, '1.0': 0.0301}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0003328000000000006
Episodes: 8308, frames: 100049, time: 30887.83078980446
training steps:  8606
retraining steps:  0
RDN obj mus: [-0.9724711006343365, -0.9790720146477222, -0.97742194942832, -0.9751555339932442, -0.9728473356068135]
RDN obj sigmas: [0.01030936420249332, 0.008932250771414465, 0.010101623175910863, 0.01128532498747731, 0.01229091714846648]
8308 : 0.25
LR:  0.001
replay buffer size:  105380
Time Taken :  514.0  mins 47.830471992492676  seconds
[[[15783.  4659.   833.  1017.   504.    35.     0.     0.]
  [14280.  5806.  1456.   252.   294.    52.    14.     0.]
  [ 1816.  2879.  1479.   142.   221.   572.   316.    54.]
  [  118.  2215.  1471.   367.    50.   703.   503.   886.]
  [  434.  1850.  1594.   138.    75.   732.    99.   774.]
  [  123.  1863.  2272.  1357.  1200.  1802.   750.   794.]
  [  897.  1255.  2237.  1696.  1602.  1783.  1429.   965.]
  [  887.   122.   772.  1211.   114.   551.  1215.   371.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1544
Q value #non_end_state_>threshold:  7531
maxi score:  0.4341
siam score:  -0.89660645
Scores:  {'0.167': 0.24609999999999999, '0.333': 0.1581, '0.5': 0.1221, '0.667': 0.040100000000000004, '0.833': 0.022099999999999998, '1.0': 0.0301}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0015743999999999982
Episodes: 8581, frames: 110152, time: 33219.684688806534
training steps:  9467
retraining steps:  0
RDN obj mus: [-0.9754819567143918, -0.9833935425519943, -0.9823015254616737, -0.9801879011332989, -0.9775710451483727]
RDN obj sigmas: [0.012640856150470427, 0.007429535077959373, 0.009697203871853537, 0.01056838400354875, 0.011505664800139766]
8581 : 0.2
LR:  0.001
replay buffer size:  115874
Time Taken :  553.0  mins 39.68437910079956  seconds
[[[16247.  4700.   840.  1037.   530.    37.     0.     0.]
  [14659.  6165.  1555.   257.   322.    58.    18.     0.]
  [ 1839.  3233.  1615.   149.   309.   778.   511.    58.]
  [  127.  2606.  1714.   401.    63.   895.   655.  1020.]
  [  475.  2142.  1784.   144.    89.   859.   116.  1081.]
  [  143.  2231.  2636.  1590.  1664.  2303.   918.  1048.]
  [ 1047.  1565.  2598.  2061.  1873.  2118.  1633.  1195.]
  [  895.   133.   851.  1329.   130.   690.  1405.   427.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1817
Q value #non_end_state_>threshold:  9661
maxi score:  0.4941
siam score:  -0.86538696
Scores:  {'0.167': 0.28209999999999996, '0.333': 0.1601, '0.5': 0.1221, '0.667': 0.040100000000000004, '0.833': 0.0161, '1.0': 0.0281}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 8845, frames: 120114, time: 35553.940292835236
training steps:  10328
retraining steps:  0
RDN obj mus: [-0.9831040480554104, -0.9865475548505783, -0.9858039617538452, -0.9829606460928917, -0.9841465371251106]
RDN obj sigmas: [0.00867850692298643, 0.006605396408795754, 0.00731170337393645, 0.008244148420563781, 0.007195920051160831]
8845 : 0.2
LR:  0.001
replay buffer size:  126214
Time Taken :  592.0  mins 33.939980030059814  seconds
[[[16476.  4726.   844.  1040.   535.    37.     0.     0.]
  [14983.  6496.  1600.   259.   326.    62.    19.     0.]
  [ 1860.  3578.  1764.   157.   334.   849.   605.    72.]
  [  139.  2995.  1947.   414.    69.  1080.   745.  1299.]
  [  513.  2558.  2058.   155.   100.  1055.   142.  1809.]
  [  158.  2717.  3022.  1839.  1996.  2603.  1080.  1698.]
  [ 1174.  1857.  3057.  2383.  2061.  2356.  1770.  1376.]
  [  900.   142.   994.  1479.   153.   794.  1485.   475.]]]
