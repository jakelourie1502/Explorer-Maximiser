EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.0014709561946801841
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 155, frames: 985, time: 24.97335720062256
training steps:  1
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
155 : 0.0
LR:  0.0
replay buffer size:  1154
Time Taken :  0.0  mins 24.973026990890503  seconds
[[[310. 108.  17.   2.   2.   1.   0.   0.]
  [172.  58.  25.   7.   2.   0.   0.   0.]
  [ 31.  24.  16.   5.   2.   0.   0.   0.]
  [  1.  14.   5.   1.   0.   0.   0.   0.]
  [  1.   7.   6.   1.   0.   0.   0.   0.]
  [  1.   4.   6.   1.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.2819936
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 1703, frames: 10042, time: 1303.2663900852203
training steps:  869
retraining steps:  0
RDN obj mus: [-0.9481764067411422, -0.9673038339972496, -0.9741654777228832, -0.9423818010861061, -0.8954744635019968]
RDN obj sigmas: [0.022094484422885433, 0.017548335963002638, 0.012732561135135241, 0.043139141052712014, 0.04603788082363835]
1703 : 0.0
LR:  0.000868
replay buffer size:  10326
Time Taken :  21.0  mins 43.26607608795166  seconds
[[[3367. 1222.   75.   26.   16.    3.    0.    0.]
  [1673.  622.  220.   58.    5.    1.    0.    0.]
  [ 346.  196.  119.   26.    6.    4.    0.    0.]
  [  10.   79.   63.   27.   11.    0.    0.    0.]
  [   6.   28.   36.   14.    1.    0.    0.    0.]
  [  10.   13.   12.    2.    1.    0.    0.    0.]
  [   3.    3.    3.    8.    3.    0.    0.    0.]
  [   6.    0.    8.    6.    1.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.5014092
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 3272, frames: 20053, time: 3264.1941211223602
training steps:  1723
retraining steps:  0
RDN obj mus: [-0.9477035273134709, -0.9606688077986241, -0.9735154488980771, -0.9543979193814044, -0.9343742742116407]
RDN obj sigmas: [0.032496366152198135, 0.035371218005931036, 0.02615951532060826, 0.040188352177821685, 0.055530025649163074]
3272 : 0.0
LR:  0.001
replay buffer size:  20507
Time Taken :  54.0  mins 24.193798065185547  seconds
[[[7059. 2325.  140.   45.   23.    3.    0.    0.]
  [3411. 1198.  388.  103.    5.    1.    1.    0.]
  [ 706.  423.  204.   54.    6.    4.    3.    0.]
  [  20.  160.  112.   43.   13.    1.    4.    0.]
  [  14.   65.   68.   24.    1.    2.    0.    0.]
  [  19.   30.   24.    6.    2.    2.    0.    0.]
  [   6.    6.    9.   15.    3.    0.    0.    0.]
  [   6.    1.    9.   13.    1.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.5141973
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 3917, frames: 30066, time: 6482.3475222587585
training steps:  2581
retraining steps:  0
RDN obj mus: [-0.9594015248656272, -0.9792903673827649, -0.980065924012661, -0.975426979124546, -0.9516980381309986]
RDN obj sigmas: [0.02825860973947719, 0.016927681505240114, 0.015826004504645375, 0.016664151264741293, 0.02396833746158474]
3917 : 0.0
LR:  0.001
replay buffer size:  30643
Time Taken :  108.0  mins 2.3471968173980713  seconds
[[[12739.  2780.   160.    49.    23.     3.     0.     0.]
  [ 5479.  1718.   491.   118.     5.     1.     1.     0.]
  [  868.   540.   273.    59.     6.     4.     3.     0.]
  [   23.   193.   145.    44.    13.     1.     4.     0.]
  [   20.    91.    71.    26.     1.     2.     0.     0.]
  [   20.    46.    24.     6.     2.     2.     0.     0.]
  [   19.    13.     9.    15.     3.     0.     0.     0.]
  [   12.     1.     9.    13.     1.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6550636
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 4271, frames: 40041, time: 9057.765313148499
training steps:  3443
retraining steps:  0
RDN obj mus: [-0.9606345786809921, -0.9712153812289238, -0.9736071493804455, -0.9687950249671936, -0.929438753092289]
RDN obj sigmas: [0.02396621313997019, 0.019254191329166715, 0.017423284093147605, 0.020845335858869083, 0.03514955813963841]
4271 : 0.0
LR:  0.001
replay buffer size:  40721
Time Taken :  150.0  mins 57.764991998672485  seconds
[[[17481.  2967.   202.    60.    24.     3.     0.     0.]
  [ 8388.  2406.   634.   126.     6.     1.     1.     0.]
  [  988.   695.   377.    65.     7.     4.     3.     0.]
  [   30.   253.   257.    65.    16.     1.     4.     0.]
  [   93.   135.   110.    28.     1.     2.     0.     0.]
  [   23.    72.    72.    18.     2.     2.     0.     0.]
  [   44.    14.    22.    19.     4.     0.     0.     0.]
  [   12.     1.     9.    19.     4.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6405672
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 4677, frames: 50127, time: 11176.816450119019
training steps:  4308
retraining steps:  0
RDN obj mus: [-0.9696626415371895, -0.975161285740137, -0.9786005917787551, -0.9741709233224392, -0.9526303002953529]
RDN obj sigmas: [0.017315345116014617, 0.013831812577531218, 0.011142163532134137, 0.013368091245767896, 0.027208644547001264]
4677 : 0.0
LR:  0.001
replay buffer size:  50930
Time Taken :  186.0  mins 16.816126823425293  seconds
[[[21398.  3148.   207.    60.    24.     3.     0.     0.]
  [12344.  3078.   717.   130.     6.     1.     1.     0.]
  [ 1178.   845.   466.    69.     7.     4.     3.     0.]
  [   38.   372.   291.    81.    16.     1.     4.     0.]
  [  135.   192.   147.    30.     1.     2.     0.     0.]
  [   31.    90.    77.    25.    10.     2.     0.     0.]
  [   66.    39.    26.    19.     4.     0.     0.     0.]
  [   29.     1.     9.    19.     4.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7859865
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 5061, frames: 60093, time: 13295.230763196945
training steps:  5163
retraining steps:  0
RDN obj mus: [-0.968998623764515, -0.9773828508377075, -0.9803658717215061, -0.9767681159079075, -0.9550384568870067]
RDN obj sigmas: [0.016832330841591994, 0.014058108032880188, 0.010292991385943449, 0.009998787475632648, 0.03478034458849496]
5061 : 0.0
LR:  0.001
replay buffer size:  61011
Time Taken :  221.0  mins 35.23044800758362  seconds
[[[24708.  3315.   285.   122.    35.     4.     0.     0.]
  [16123.  3683.   956.   141.     6.     1.     1.     0.]
  [ 1340.   996.   644.    79.     7.     4.     3.     0.]
  [   44.   509.   490.   157.    16.     1.     4.     0.]
  [  169.   246.   278.    42.     1.     2.     0.     0.]
  [   35.   102.   112.    41.    10.     2.     0.     0.]
  [   66.    77.    49.    23.     4.     0.     0.     0.]
  [   29.     4.    34.    28.     4.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8374466
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 5446, frames: 70026, time: 15454.083084106445
training steps:  6020
retraining steps:  0
RDN obj mus: [-0.9666018329679966, -0.9789146750509738, -0.9807124274134635, -0.9792912080228329, -0.9735374489009381]
RDN obj sigmas: [0.015589867444953104, 0.013159828430495644, 0.009865659004941685, 0.010523134551251982, 0.016370960913405546]
5446 : 0.0
LR:  0.001
replay buffer size:  71060
Time Taken :  257.0  mins 34.08276915550232  seconds
[[[26610.  3458.   399.   245.   172.     9.     0.     0.]
  [18674.  4447.  1146.   160.    33.     1.     1.     0.]
  [ 1458.  1292.   903.    88.    19.     4.     3.     0.]
  [   62.   771.   815.   240.    18.     1.     4.     0.]
  [  334.   526.   521.    63.     3.     6.     0.     0.]
  [   51.   260.   306.   137.    77.    18.     2.     1.]
  [   99.   184.   213.   237.   123.    47.     4.     0.]
  [   61.    17.   138.   110.     9.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8177901
Scores:  {'0.167': 0.0001, '0.333': 0.0021, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.00199960002
Episodes: 5809, frames: 80247, time: 18010.572964191437
training steps:  6911
retraining steps:  0
RDN obj mus: [-0.9759234178364277, -0.9871908714830875, -0.9857203203737736, -0.9850545116484165, -0.9852702401459217]
RDN obj sigmas: [0.0063157309890767765, 0.0042970144508877265, 0.007804430567254737, 0.009862030146293414, 0.0066415726728215295]
5809 : 0.0
LR:  0.001
replay buffer size:  83781
Time Taken :  300.0  mins 10.57264494895935  seconds
[[[29290.  3594.   626.   531.   509.    24.     0.     0.]
  [20765.  5142.  1424.   181.   127.     8.     2.     0.]
  [ 1549.  1615.  1229.   105.   146.    22.    25.     0.]
  [   73.   977.  1091.   375.    26.     2.    13.     0.]
  [  416.   671.   700.    76.     6.    33.     1.     0.]
  [   59.   340.   419.   258.   178.    33.     2.     1.]
  [  139.   246.   267.   363.   171.    93.     7.     0.]
  [   79.    21.   173.   175.    15.     0.    24.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.88638914
Scores:  {'0.167': 0.0021, '0.333': 0.0021, '0.5': 0.0021, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.00199960002
Episodes: 6214, frames: 90232, time: 20482.764800071716
training steps:  7763
retraining steps:  0
RDN obj mus: [-0.9790861582696437, -0.9866169332385063, -0.9868040681123733, -0.986217961114645, -0.9879984055161476]
RDN obj sigmas: [0.004420802455816646, 0.0036884002745517903, 0.004945419987696537, 0.007873240880387064, 0.004905646727457868]
6214 : 0.0
LR:  0.001
replay buffer size:  96266
Time Taken :  341.0  mins 22.764485120773315  seconds
[[[32536.  3772.   794.   739.   879.    39.     0.     0.]
  [23033.  5725.  1727.   218.   311.    16.     2.     0.]
  [ 1634.  1770.  1429.   128.   235.   137.    43.     2.]
  [   79.  1126.  1275.   489.    38.    20.    33.     0.]
  [  431.   747.   767.    93.     7.    35.     3.     0.]
  [   60.   372.   446.   303.   246.   110.    31.     1.]
  [  139.   252.   289.   397.   202.   126.    88.    17.]
  [   79.    21.   177.   202.    20.    80.    45.     3.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  5
Q value #non_end_state_>threshold:  7
maxi score:  0.0001
siam score:  -0.9106146
Scores:  {'0.167': 0.0041, '0.333': 0.0061, '0.5': 0.0081, '0.667': 0.0021, '0.833': 0.0041, '1.0': 0.0001}
best rdn ma / adv:  0.5 0.5
best rdn adv:  0.00799840008
Episodes: 6682, frames: 100255, time: 23005.98350405693
training steps:  8625
retraining steps:  0
RDN obj mus: [-0.976389474695921, -0.9875520547151565, -0.9902070962905883, -0.9878290596663952, -0.9863624060571193]
RDN obj sigmas: [0.006327391975605486, 0.00509683774387126, 0.005401909794568094, 0.008656890495544566, 0.004599904810202217]
6682 : 0.15
LR:  0.001
replay buffer size:  108789
Time Taken :  383.0  mins 25.983186721801758  seconds
[[[35916.  3953.   982.   815.   971.    48.     0.     0.]
  [25038.  6475.  2182.   294.   348.    16.     2.     0.]
  [ 1714.  1996.  1720.   175.   243.   145.    46.     2.]
  [   88.  1263.  1453.   595.    49.    20.    33.     0.]
  [  432.   823.   849.   121.    11.    86.    10.    36.]
  [   61.   389.   485.   347.   315.   200.   119.   119.]
  [  139.   252.   293.   405.   227.   151.   160.   228.]
  [   79.    21.   177.   213.    20.    95.   116.    12.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  46
Q value #non_end_state_>threshold:  66
maxi score:  0.0001
siam score:  -0.89330095
Scores:  {'0.167': 0.0161, '0.333': 0.018099999999999998, '0.5': 0.0141, '0.667': 0.0061, '0.833': 0.0081, '1.0': 0.0021}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.017996400180000004
Episodes: 7103, frames: 110326, time: 25569.348747015
training steps:  9491
retraining steps:  0
RDN obj mus: [-0.963492864561081, -0.9863387773931026, -0.992057329261303, -0.9889810747146607, -0.9927028845429421]
RDN obj sigmas: [0.006970307450480384, 0.004956657960606322, 0.0051127951032785305, 0.009566231463466114, 0.0064459749941326566]
7103 : 0.0
LR:  0.001
replay buffer size:  121360
Time Taken :  426.0  mins 9.348428010940552  seconds
[[[37624.  4098.  1302.   999.  1356.    67.     0.     0.]
  [26907.  7084.  2570.   342.   624.    34.     3.     0.]
  [ 1769.  2198.  2045.   207.   316.   206.    73.     8.]
  [   93.  1464.  1808.   807.    61.    45.    36.    39.]
  [  450.   965.  1043.   152.    13.    98.    19.   107.]
  [   62.   430.   577.   410.   397.   324.   281.   334.]
  [  139.   257.   308.   430.   267.   280.   369.   401.]
  [   79.    21.   195.   256.    29.   146.   167.    32.]]]
Test reward:  0.64
Q value #end_state_>_threshold:  150
Q value #non_end_state_>threshold:  327
maxi score:  0.032100000000000004
siam score:  -0.89062196
Scores:  {'0.167': 0.032100000000000004, '0.333': 0.0381, '0.5': 0.0361, '0.667': 0.018099999999999998, '0.833': 0.0121, '1.0': 0.0061}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.03559955558
Episodes: 7440, frames: 120200, time: 28009.429223060608
training steps:  10344
retraining steps:  0
RDN obj mus: [-0.9622913467645645, -0.9735828882873059, -0.9794643602192402, -0.9767446893155575, -0.9765178376436233]
RDN obj sigmas: [0.011727963892278516, 0.01309109330316248, 0.011682736383726505, 0.014571624723333997, 0.01899096702998857]
7440 : 0.35
LR:  0.001
replay buffer size:  133059
Time Taken :  466.0  mins 49.42890691757202  seconds
[[[38623.  4185.  1571.  1166.  1511.    74.     0.     0.]
  [27865.  7590.  2889.   365.   804.    39.     3.     0.]
  [ 1805.  2399.  2305.   226.   525.   349.   119.    12.]
  [  103.  1661.  2183.   882.    74.   124.   105.   111.]
  [  457.  1105.  1250.   178.    27.   128.    34.   350.]
  [   64.   493.   730.   549.   623.   601.   564.  1032.]
  [  144.   272.   366.   473.   319.   459.   598.   820.]
  [   83.    24.   220.   285.    46.   280.   445.    73.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  239
Q value #non_end_state_>threshold:  856
maxi score:  0.0961
siam score:  -0.88628554
Scores:  {'0.167': 0.0721, '0.333': 0.0641, '0.5': 0.0621, '0.667': 0.0361, '0.833': 0.022099999999999998, '1.0': 0.0101}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0093312
Episodes: 7714, frames: 130194, time: 30330.565670967102
training steps:  11187
retraining steps:  0
RDN obj mus: [-0.9704983627438545, -0.9777574022352695, -0.9749466134250164, -0.9717917351782321, -0.9648342750906944]
RDN obj sigmas: [0.011370939775109274, 0.014961615262642525, 0.014168781918067452, 0.014696396771582137, 0.019015424828312113]
7714 : 0.25
LR:  0.001
replay buffer size:  143998
Time Taken :  505.0  mins 30.565351724624634  seconds
[[[39222.  4232.  1614.  1188.  1540.    74.     0.     0.]
  [28412.  7931.  3011.   373.   827.    44.     4.     0.]
  [ 1825.  2604.  2412.   234.   557.   390.   144.    18.]
  [  107.  1898.  2338.   910.    76.   163.   180.   279.]
  [  478.  1333.  1447.   188.    37.   158.    63.   725.]
  [   67.   606.   996.   839.   987.   929.  1025.  2238.]
  [  147.   279.   428.   551.   467.   774.  1077.  1393.]
  [   83.    29.   261.   384.    71.   500.  1172.   141.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  397
Q value #non_end_state_>threshold:  2036
maxi score:  0.17609999999999998
siam score:  -0.8916429
Scores:  {'0.167': 0.1121, '0.333': 0.0901, '0.5': 0.0761, '0.667': 0.0461, '0.833': 0.0241, '1.0': 0.0141}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 7980, frames: 140173, time: 32690.097620010376
training steps:  12049
retraining steps:  0
RDN obj mus: [-0.9710826426625252, -0.973999799990654, -0.9727104834079743, -0.967387443703413, -0.9576965413451195]
RDN obj sigmas: [0.01329357250805344, 0.014115038966667642, 0.012449095103497117, 0.0141469152696067, 0.017836913588138173]
7980 : 0.1
LR:  0.001
replay buffer size:  154703
Time Taken :  544.0  mins 50.097301959991455  seconds
[[[39564.  4267.  1670.  1236.  1593.    77.     0.     0.]
  [28805.  8231.  3074.   377.   860.    50.     4.     0.]
  [ 1846.  2814.  2472.   238.   730.   563.   215.    28.]
  [  116.  2129.  2432.   922.    80.   193.   287.   680.]
  [  490.  1566.  1698.   206.    47.   193.    84.  1063.]
  [   71.   729.  1365.  1131.  1298.  1261.  1440.  2965.]
  [  152.   291.   552.   739.   649.  1129.  1588.  1774.]
  [   83.    35.   388.   891.    92.   642.  1824.   204.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  553
Q value #non_end_state_>threshold:  2928
maxi score:  0.2581
siam score:  -0.88096356
Scores:  {'0.167': 0.1541, '0.333': 0.10010000000000001, '0.5': 0.0921, '0.667': 0.050100000000000006, '0.833': 0.026099999999999998, '1.0': 0.0141}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 8255, frames: 150097, time: 35075.02829027176
training steps:  12907
retraining steps:  0
RDN obj mus: [-0.964116695535183, -0.9677795282959938, -0.9633850218608976, -0.9589511606633663, -0.9539022442817688]
RDN obj sigmas: [0.015392974142839253, 0.014913096094371988, 0.015533865009110233, 0.014641391827163517, 0.01474917229698351]
8255 : 0.15
LR:  0.001
replay buffer size:  165396
Time Taken :  584.0  mins 35.027971029281616  seconds
[[[39815.  4293.  1710.  1274.  1636.    79.     0.     0.]
  [29223.  8551.  3145.   382.   890.    56.     8.     0.]
  [ 1864.  3084.  2537.   245.   819.   690.   296.    44.]
  [  121.  2384.  2553.   927.    88.   318.   400.  1127.]
  [  502.  1809.  1952.   221.    55.   314.   109.  1273.]
  [   82.  1086.  1767.  1441.  1660.  1616.  1804.  3380.]
  [  153.   319.   770.  1141.   954.  1404.  1906.  2054.]
  [   83.    43.   569.  1653.   134.   733.  2039.   257.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  741
Q value #non_end_state_>threshold:  4433
maxi score:  0.35209999999999997
siam score:  -0.8475747
Scores:  {'0.167': 0.1921, '0.333': 0.1221, '0.5': 0.1061, '0.667': 0.0541, '0.833': 0.032100000000000004, '1.0': 0.0141}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 8548, frames: 160235, time: 37421.32791209221
training steps:  13769
retraining steps:  0
RDN obj mus: [-0.9613737350821495, -0.9682769482433796, -0.9662751853525638, -0.9633333389103412, -0.9539271892130375]
RDN obj sigmas: [0.014501076540252076, 0.013056708561441963, 0.01193843716139211, 0.0109269383074501, 0.015892484908776712]
8548 : 0.05
LR:  0.001
replay buffer size:  176140
Time Taken :  623.0  mins 41.327611684799194  seconds
[[[40115.  4325.  1744.  1298.  1653.    79.     0.     0.]
  [29745.  8943.  3240.   385.   907.    58.     8.     0.]
  [ 1883.  3383.  2684.   252.   854.   793.   339.    47.]
  [  131.  2641.  2750.   935.    94.   423.   462.  1321.]
  [  527.  2102.  2249.   237.    76.   716.   132.  1351.]
  [   93.  1536.  2215.  1764.  1930.  1845.  1959.  3524.]
  [  154.   422.  1019.  1656.  1330.  1633.  2097.  2225.]
  [   83.    50.   847.  2858.   190.   852.  2202.   321.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1043
Q value #non_end_state_>threshold:  6227
maxi score:  0.4281
siam score:  -0.8240811
Scores:  {'0.167': 0.2621, '0.333': 0.1641, '0.5': 0.1201, '0.667': 0.0661, '0.833': 0.0361, '1.0': 0.0161}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 8869, frames: 170042, time: 39784.120908260345
training steps:  14616
retraining steps:  0
RDN obj mus: [-0.9616376766860485, -0.9702911769807339, -0.9673700626313686, -0.9612299701988697, -0.9561516249477864]
RDN obj sigmas: [0.014885283983841044, 0.013081801466449341, 0.013596277284687134, 0.013521550991681069, 0.01344216430128939]
8869 : 0.25
LR:  0.001
replay buffer size:  186602
Time Taken :  663.0  mins 4.12059211730957  seconds
[[[40441.  4367.  1763.  1314.  1666.    79.     0.     0.]
  [30209.  9354.  3314.   388.   928.    62.    10.     0.]
  [ 1900.  3745.  2812.   261.   919.   932.   426.    65.]
  [  142.  2931.  2876.   940.   110.   635.   622.  1691.]
  [  555.  2457.  2465.   250.    94.  1024.   148.  1454.]
  [  109.  2117.  2656.  2094.  2274.  2093.  2080.  3615.]
  [  175.   520.  1239.  1977.  1695.  1880.  2311.  2322.]
  [   83.    55.   969.  3235.   223.  1087.  2605.   410.]]]
