EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.012424101328684224
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 173, frames: 995, time: 26.59609889984131
training steps:  2
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
173 : 0.0
LR:  1e-06
replay buffer size:  1195
Time Taken :  0.0  mins 26.595766067504883  seconds
[[[374. 122.   0.   0.   0.   0.   0.   0.]
  [182.  53.  10.   8.   0.   0.   0.   0.]
  [ 40.  19.   4.   2.   0.   0.   0.   0.]
  [  1.   5.   1.   1.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.24076034
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.004337288135593221, '1.0': 0.0001}
best rdn ma / adv:  0.833 0.833
best rdn adv:  0.004236440720338983
Episodes: 1641, frames: 10122, time: 1319.2989521026611
training steps:  868
retraining steps:  0
RDN obj mus: [-0.959728384321928, -0.9673477230608464, -0.9648058074831962, -0.9622992725991262, -0.8937238241944995]
RDN obj sigmas: [0.014093740185053306, 0.020864068892969705, 0.019196650226686273, 0.05714321323964539, 0.24803557246390529]
1641 : 0.0
LR:  0.000867
replay buffer size:  10432
Time Taken :  21.0  mins 59.29862880706787  seconds
[[[3843. 1162.   54.   25.    3.    2.    0.    0.]
  [1890.  499.  131.   32.    2.    0.    0.    0.]
  [ 400.  158.   84.   16.    2.    0.    0.    0.]
  [  17.   55.   32.    5.    2.    0.    0.    0.]
  [   6.   13.   12.    4.    0.    0.    0.    0.]
  [   4.    2.    6.    1.    0.    0.    0.    0.]
  [   0.    0.    4.    1.    1.    1.    3.    0.]
  [   0.    1.    3.    1.    0.    0.    3.    1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.33127373
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0023371364653243846, '1.0': 0.0001}
best rdn ma / adv:  0.833 0.833
best rdn adv:  0.0022366890604026846
Episodes: 3128, frames: 20178, time: 3203.2432849407196
training steps:  1735
retraining steps:  0
RDN obj mus: [-0.943584068697691, -0.9530499502718449, -0.9549933404386044, -0.962138101945033, -0.9107309159110574]
RDN obj sigmas: [0.02998585370620585, 0.02855779496716, 0.03784370677151765, 0.05657096231016798, 0.22806751946515652]
3128 : 0.0
LR:  0.001
replay buffer size:  20621
Time Taken :  53.0  mins 23.242967128753662  seconds
[[[7632. 2188.  135.   62.   22.    5.    0.    0.]
  [3844. 1001.  288.   64.    7.    1.    0.    0.]
  [ 773.  326.  193.   34.    4.    3.    1.    0.]
  [  33.  131.   91.   14.    3.    0.    0.    0.]
  [  23.   45.   34.   12.    0.    0.    0.    0.]
  [  10.   11.   17.    6.    0.    0.    0.    0.]
  [   0.    4.    7.    2.    1.    1.    3.    0.]
  [   0.    3.    7.    4.    1.    0.    3.    1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.51596797
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0021, '1.0': 0.0001}
best rdn ma / adv:  0.833 0.833
best rdn adv:  0.00199960002
Episodes: 3704, frames: 30114, time: 6063.456291913986
training steps:  2578
retraining steps:  0
RDN obj mus: [-0.947718855637312, -0.9446245879888534, -0.9407718407690525, -0.9290951830208302, -0.8998426203948346]
RDN obj sigmas: [0.03223924816185285, 0.037141322074840624, 0.03636272119428942, 0.03826784480822245, 0.05390380929928473]
3704 : 0.0
LR:  0.001
replay buffer size:  30733
Time Taken :  101.0  mins 3.4559690952301025  seconds
[[[13068.  2534.   182.    73.    22.     5.     0.     0.]
  [ 6264.  1450.   383.    74.     7.     1.     0.     0.]
  [  976.   485.   236.    38.     4.     3.     1.     0.]
  [   40.   169.   101.    25.     3.     0.     0.     0.]
  [   69.    59.    36.    14.     0.     0.     0.     0.]
  [   14.    14.    17.     6.     0.     0.     0.     0.]
  [    0.     4.     7.     2.     1.     1.     3.     0.]
  [    0.     3.     7.     4.     1.     0.     3.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.5451751
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0021, '1.0': 0.0001}
best rdn ma / adv:  0.833 0.833
best rdn adv:  0.00199960002
Episodes: 4190, frames: 40088, time: 8756.791574001312
training steps:  3450
retraining steps:  0
RDN obj mus: [-0.947225455826521, -0.9393431509077549, -0.9424600049197673, -0.944051940792799, -0.9185380048751831]
RDN obj sigmas: [0.03162140405411993, 0.03347216208447577, 0.026453383698244008, 0.01998970615706703, 0.02961242550700906]
4190 : 0.0
LR:  0.001
replay buffer size:  40927
Time Taken :  145.0  mins 56.79125690460205  seconds
[[[17850.  2828.   360.   200.    41.     7.     0.     0.]
  [ 8261.  2153.   729.    82.    21.     1.     0.     0.]
  [ 1121.   759.   429.    49.     7.     3.     1.     0.]
  [   50.   271.   164.    29.     3.     0.     0.     0.]
  [  108.    90.   113.    17.     0.     0.     0.     0.]
  [   18.    29.    41.     7.     0.     0.     0.     0.]
  [   13.    10.     7.     2.     1.     1.     3.     0.]
  [    0.     3.     7.     4.     1.     0.     3.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.58477855
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 4651, frames: 50099, time: 10877.745428800583
training steps:  4307
retraining steps:  0
RDN obj mus: [-0.9589366969645023, -0.9675345695853234, -0.9565746327638626, -0.9508515084564686, -0.9304514007627964]
RDN obj sigmas: [0.02072277125120511, 0.015216861736275131, 0.017264982342557612, 0.01626931666797772, 0.03616067481775034]
4651 : 0.0
LR:  0.001
replay buffer size:  51085
Time Taken :  181.0  mins 17.745113849639893  seconds
[[[21279.  3085.   576.   277.    57.     9.     0.     0.]
  [10109.  3463.  1293.   114.    24.     1.     0.     0.]
  [ 1243.  1282.   652.    60.     7.     3.     1.     0.]
  [   60.   487.   351.    96.     5.     0.     0.     0.]
  [  195.   226.   157.    22.     0.     0.     0.     0.]
  [   24.    98.    62.     7.     0.     0.     0.     0.]
  [   24.    43.    24.     2.     1.     1.     3.     0.]
  [    0.     8.     8.     4.     1.     0.     3.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.77976424
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 5051, frames: 60094, time: 13003.825385093689
training steps:  5171
retraining steps:  0
RDN obj mus: [-0.945698981231451, -0.9621901313304901, -0.9596555664300919, -0.960303212672472, -0.9541850435376167]
RDN obj sigmas: [0.04194619214432752, 0.023574056647017453, 0.01844062593236632, 0.01974646576965673, 0.02684654321004381]
5051 : 0.0
LR:  0.001
replay buffer size:  61257
Time Taken :  216.0  mins 43.82506990432739  seconds
[[[22832.  3241.   849.   698.   699.    27.     0.     0.]
  [11578.  4163.  1771.   165.   219.     9.     0.     0.]
  [ 1303.  1595.  1128.    76.    79.    13.     1.     0.]
  [   69.   586.   676.   244.    14.     4.     0.     0.]
  [  236.   441.   533.    41.     2.    35.     2.    14.]
  [   45.   312.   284.   110.    69.    26.    17.    19.]
  [  103.   117.   149.   105.    27.     5.    15.     0.]
  [   22.    25.   111.    61.     4.    16.    57.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7371532
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0021, '0.833': 0.0021, '1.0': 0.0001}
best rdn ma / adv:  0.667 0.667
best rdn adv:  0.00199960002
Episodes: 5487, frames: 70171, time: 15428.697057008743
training steps:  6038
retraining steps:  0
RDN obj mus: [-0.9740464517116547, -0.980467716294527, -0.9829897799074649, -0.9680824557960034, -0.9721284274935722]
RDN obj sigmas: [0.01407947160597212, 0.010045249526992836, 0.011984218354405654, 0.02551667132787015, 0.02019400650462865]
5487 : 0.0
LR:  0.001
replay buffer size:  73725
Time Taken :  257.0  mins 8.696735143661499  seconds
[[[23524.  3432.  1407.  1589.  1208.    44.     0.     0.]
  [12248.  4753.  2226.   216.   351.    20.     0.     0.]
  [ 1356.  1931.  1538.    93.    87.    13.     1.     0.]
  [   76.   851.  1154.   308.    18.     4.     0.     0.]
  [  310.   838.  1033.    64.     7.    36.     6.    14.]
  [   58.   645.   656.   268.   264.   148.    41.    31.]
  [  162.   164.   283.   192.   132.    97.   136.    13.]
  [   31.    35.   245.   153.    14.    65.    92.     3.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  12
Q value #non_end_state_>threshold:  7
maxi score:  0.0001
siam score:  -0.8392239
Scores:  {'0.167': 0.0021, '0.333': 0.0061, '0.5': 0.0021, '0.667': 0.0021, '0.833': 0.0021, '1.0': 0.0021}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.005998800060000001
Episodes: 6067, frames: 80260, time: 17844.026805877686
training steps:  6906
retraining steps:  0
RDN obj mus: [-0.9489357362926006, -0.9679218780636787, -0.9621879105687141, -0.9526055379688739, -0.9516535103440285]
RDN obj sigmas: [0.030737948667641644, 0.01719272825781457, 0.0335677153005379, 0.039156680295149224, 0.033991555000268646]
6067 : 0.0
LR:  0.001
replay buffer size:  84901
Time Taken :  297.0  mins 24.026487112045288  seconds
[[[25108.  3734.  1629.  1742.  1539.    56.     0.     0.]
  [13740.  5446.  2543.   240.   443.    29.     1.     0.]
  [ 1451.  2292.  1779.   111.   107.    35.     4.    18.]
  [   84.  1030.  1340.   422.    28.    33.    22.   207.]
  [  346.   921.  1136.    76.    26.    91.    23.   168.]
  [   64.   712.   788.   375.   500.   516.   178.   155.]
  [  184.   212.   313.   259.   279.   395.   324.    52.]
  [   54.    38.   255.   173.    22.   129.   207.     9.]]]
Test reward:  0.64
Q value #end_state_>_threshold:  187
Q value #non_end_state_>threshold:  114
maxi score:  0.032100000000000004
siam score:  -0.8892504
Scores:  {'0.167': 0.0301, '0.333': 0.026099999999999998, '0.5': 0.0161, '0.667': 0.0101, '0.833': 0.0021, '1.0': 0.0041}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.028104912300000003
Episodes: 6458, frames: 90234, time: 20122.727393865585
training steps:  7758
retraining steps:  0
RDN obj mus: [-0.9453088299870491, -0.9540368657886982, -0.9528531486451626, -0.9412649814844132, -0.9258616295993328]
RDN obj sigmas: [0.02713034870595949, 0.029712957003637696, 0.032764410676105915, 0.034915622968960745, 0.04036285271412665]
6458 : 0.15
LR:  0.001
replay buffer size:  95612
Time Taken :  335.0  mins 22.727092027664185  seconds
[[[27141.  3906.  1704.  1850.  1645.    59.     0.     0.]
  [14742.  5888.  2714.   255.   462.    34.     5.     0.]
  [ 1497.  2529.  1917.   122.   132.   133.   157.    39.]
  [   90.  1260.  1527.   459.    31.   148.   157.   517.]
  [  358.  1173.  1327.    90.    29.   137.    38.   334.]
  [   71.   858.  1007.   586.   629.   802.   295.   222.]
  [  207.   237.   389.   449.   458.   801.   590.    97.]
  [  112.    41.   274.   233.    33.   288.   446.    45.]]]
