EVALUATIONS AND MAIN RESULTS
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9721222222222222
siam score:  -0.004080235899891704
Scores:  {'0.167': -0.8332333333333334, '0.333': -0.8570428571428571, '0.5': -0.8999, '0.667': -0.8332333333333334, '0.833': -0.4999, '1.0': -0.8999}
best rdn ma / adv:  1 0.167
best rdn adv:  0.0
Episodes: 51, frames: 1104, time: 44.73207902908325
training steps:  8
retraining steps:  0
RDN obj mus: [-0.01107089951200161, 0.015773919937777908, 0.02142491042613983, 0.014202571163574854, 0.0]
RDN obj sigmas: [0.010947481146710264, 0.00485093268657981, 0.010744880356285076, 0.010471151949984013, 0.0]
51 : -1.0
LR:  7e-06
replay buffer size:  1542
Time Taken :  0.0  mins 44.73185896873474  seconds
[[[  0.   0.   0.   0.   1.   2.   0.   3.   0.   1.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   6.   2.   6.  14.   3.   2.   2.   1.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  50.  20.  57.  10.   2.   3.   1.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0. 348. 105.  46.  31.  71.  81.  74.  44.  29.   8.   6.   1.   1.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   6.   8.   0.   7.   0.   0.   0.   0.   0.   1.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9900960784313726
siam score:  -0.8516772
Scores:  {'0.167': -0.9721222222222222, '0.333': -0.9813814814814815, '0.5': -0.9760904761904762, '0.667': -0.9628629629629629, '0.833': -0.9721222222222222, '1.0': -0.9721222222222222}
best rdn ma / adv:  1 0.667
best rdn adv:  0.26816020364907184
Episodes: 279, frames: 10967, time: 5525.765244722366
training steps:  1286
retraining steps:  0
RDN obj mus: [-0.9212707091212272, -0.9279883755147457, -0.924750830668211, -0.8895773440619513, -0.8921404977905846]
RDN obj sigmas: [0.022637589591392854, 0.024385059539670514, 0.0344554691858162, 0.04686473073214474, 0.057542136531264644]
279 : -1.0
LR:  0.001
replay buffer size:  13296
Time Taken :  92.0  mins 5.765022039413452  seconds
[[[   0.    0.    0.    0.    1.   11.    9.    5.    1.    6.    2.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   24.  272.  300.  301.   85.   20.    8.    2.
      0.    6.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  941.  722.  401.  159.  109.   29.    7.    1.    1.
      1.    3.    1.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 3482. 1016.  454.  438.  563.  443.  344.  215.   99.   50.
     48.   16.    3.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   29.   32.   11.   16.    0.    0.    0.    0.    0.
      1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9947453608247423
siam score:  -0.86754
Scores:  {'0.167': -0.9863864864864865, '0.333': -0.9899, '0.5': -0.9738361702127659, '0.667': -0.9849746268656716, '0.833': -0.9867421052631579, '1.0': -0.9875543209876543}
best rdn ma / adv:  1 0.5
best rdn adv:  0.4025255213958111
Episodes: 606, frames: 20268, time: 10551.894680976868
training steps:  2478
retraining steps:  0
RDN obj mus: [-0.9295590327382087, -0.9280393193423748, -0.9168263628661633, -0.8996060227870941, -0.8836860634433371]
RDN obj sigmas: [0.030669374359601462, 0.0339018704729484, 0.0437026595721439, 0.04183714473687454, 0.05079192412786314]
606 : -0.9879166666666667
LR:  0.001
replay buffer size:  23405
Time Taken :  175.0  mins 51.89445114135742  seconds
[[[   0.    0.    0.    0.    2.   20.   15.   15.    3.   13.    6.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   49.  564.  665.  823.  672.  324.  324.   29.
     22.  138.  315.    5.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1180.  952.  688.  322.  262.   75.   13.   18.    8.
    123.   61.   11.    0.    1.   14.    3.    1.    1.    0.    1.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 4581. 1570.  718.  648.  910.  791.  736.  568.  443.  482.
    188.   43.   13.    0.    2.   21.    6.    4.    1.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   45.   63.   30.   26.    0.    0.    0.    0.    0.
      3.   10.   10.    4.    0.    1.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    1.    2.    3.    0.    1.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -0.9564
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9926681660899653
siam score:  -0.8572969
Scores:  {'0.167': -0.9921480620155039, '0.333': -0.9843516129032258, '0.5': -0.9840935483870968, '0.667': -0.9849370370370372, '0.833': -0.9920259842519685, '1.0': -0.9927057553956835}
best rdn ma / adv:  1 0.5
best rdn adv:  0.24251401460378277
Episodes: 1024, frames: 30454, time: 15572.205118894577
training steps:  3619
retraining steps:  0
RDN obj mus: [-0.913418897908926, -0.9354494306147099, -0.9156180389106273, -0.8910758390843868, -0.8629506897509098]
RDN obj sigmas: [0.023184450857014514, 0.022869626101494962, 0.03843782946648965, 0.03632166266769554, 0.04339467562664697]
1024 : -1.0
LR:  0.001
replay buffer size:  34446
Time Taken :  259.0  mins 32.2048978805542  seconds
[[[   0.    0.    0.    0.   14.   25.   32.   20.    6.   20.    9.
      1.    1.    1.    3.    0.    0.    0.    0.    1.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   72.  786.  856. 1003.  940.  488.  435.   58.
    119.  385.  399.   18.    0.    0.    1.    1.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1306. 1226.  869.  461.  343.  112.   25.  111.   39.
    445.  335.   48.    5.    1.   17.    5.    1.    1.    0.    1.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 5772. 2153.  932.  861. 1289. 1179. 1092.  970.  802. 1040.
    660.  221.   46.    6.   52.   86.   38.   11.    3.    0.    2.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   58.   89.   50.   36.    0.    0.    0.    0.    0.
     24.  253.  211.  203.  115.   90.   12.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    4.   11.    6.    2.    3.    3.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -0.9484
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9915748768472906
siam score:  -0.842637
Scores:  {'0.167': -0.9941196531791907, '0.333': -0.9824247524752475, '0.5': -0.9882333333333334, '0.667': -0.9893791666666668, '0.833': -0.9789960451977402, '1.0': -0.9862793103448275}
best rdn ma / adv:  1 0.833
best rdn adv:  0.31524883498141437
Episodes: 1409, frames: 40617, time: 21657.239068746567
training steps:  4962
retraining steps:  0
RDN obj mus: [-0.9149826292276383, -0.9250186018288136, -0.9320693164288998, -0.9078337351500988, -0.8842798473715782]
RDN obj sigmas: [0.03677076307481377, 0.027092125617449392, 0.034527293402501304, 0.03771695449228482, 0.047014180025514045]
1409 : -0.9885833333333333
LR:  0.001
replay buffer size:  45783
Time Taken :  360.0  mins 57.23884892463684  seconds
[[[   0.    0.    0.    0.   22.   31.   44.   28.    9.   25.   13.
      2.    1.    3.    5.    0.    0.    0.    1.    1.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   88.  925. 1013. 1215. 1076.  576.  579.   95.
    143.  663.  444.   34.    0.    2.    3.    2.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1771. 1571. 1102.  646.  445.  152.   47.  197.  277.
    506.  401.   60.    5.    6.   25.    6.    1.    2.    1.    1.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 7127. 2742. 1083. 1029. 1578. 1533. 1472. 1363. 1188. 1585.
    851.  316.   69.   53.  133.  171.   68.   31.   25.    1.    3.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   71.  110.   58.   42.    0.    0.    0.    0.    0.
     41.  536.  628.  444.  258.  252.   30.    0.    0.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    8.   18.   11.    3.    5.    6.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.99514
siam score:  -0.80809176
Scores:  {'0.167': -0.9846881355932203, '0.333': -0.9692410852713178, '0.5': -0.981540625, '0.667': -0.9741916666666666, '0.833': -0.9782700440528634, '1.0': -0.9832333333333333}
best rdn ma / adv:  1 0.333
best rdn adv:  0.4718151711584562
Episodes: 1790, frames: 50224, time: 26158.68716287613
training steps:  5958
retraining steps:  0
RDN obj mus: [-0.923039220905304, -0.9393642314136028, -0.9246021427690982, -0.9016065891802311, -0.8820973045885563]
RDN obj sigmas: [0.02832734719233114, 0.027547414882496808, 0.0342111711960137, 0.03896549295357587, 0.04015967932838617]
1790 : -0.97575
LR:  0.001
replay buffer size:  55861
Time Taken :  435.0  mins 58.686939001083374  seconds
[[[   0.    0.    0.    0.   29.   33.   62.   46.   18.   29.   14.
      3.    3.    7.    8.    0.    0.    0.    2.    1.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  100. 1083. 1231. 1456. 1351.  708.  748.  141.
    171.  727.  523.   50.    0.    3.    4.    3.    1.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1927. 1872. 1266.  843.  554.  197.   55.  481.  940.
    749.  621.   82.    5.   28.   97.   22.    2.    3.    3.    2.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 7991. 3193. 1234. 1198. 1750. 1709. 1719. 1619. 1439. 1941.
   1078.  584.   97.  135.  321.  234.  114.   55.   35.    3.    4.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   85.  122.   64.   50.    0.    0.    0.    0.    0.
     48.  731.  980.  602.  366.  492.   51.    0.   13.    7.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    9.   25.   13.    6.    6.    7.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  7
Q value #non_end_state_>threshold:  6
maxi score:  -0.99228
siam score:  -0.68498474
Scores:  {'0.167': -0.9759130718954248, '0.333': -0.960525, '0.5': -0.961697385620915, '0.667': -0.9682050847457628, '0.833': -0.9691226148409895, '1.0': -0.9778496402877698}
best rdn ma / adv:  1 0.333
best rdn adv:  0.7216481356063017
Episodes: 2195, frames: 60338, time: 31888.851588010788
training steps:  7269
retraining steps:  0
RDN obj mus: [-0.9282361511051654, -0.9417055695921183, -0.9413018848598004, -0.9180272105515003, -0.8734745646953582]
RDN obj sigmas: [0.023648938254129476, 0.021039146733556485, 0.02720540115848491, 0.03260453053503481, 0.06598259429797614]
2195 : -0.9241666666666667
LR:  0.001
replay buffer size:  67184
Time Taken :  531.0  mins 28.85137176513672  seconds
[[[   0.    0.    0.    0.   37.   41.   84.   51.   30.   39.   19.
      4.    4.    8.   10.    0.    0.    0.    3.    1.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  125. 1286. 1447. 1633. 1532.  865.  983.  171.
    264.  913.  577.   66.    0.    4.    9.   27.    3.    2.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 2070. 2223. 1483. 1006.  630.  241.   65.  925. 1596.
    943.  861.  107.    7.  293.  146.   32.    6.    5.   10.    2.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 9011. 3698. 1395. 1331. 1913. 1889. 1897. 1827. 1701. 2301.
   1282.  879.  125.  156.  406.  336.  144.   80.   51.    7.    8.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  102.  141.   68.   54.    0.    0.    0.    0.    0.
     55.  996. 1169.  837.  597.  619.   72.    0.   15.    9.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   12.   28.   16.   11.    7.    9.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -0.27240000000000003
Q value #end_state_>_threshold:  305
Q value #non_end_state_>threshold:  200
maxi score:  -0.9486000000000001
siam score:  -0.67087144
Scores:  {'0.167': -0.936913698630137, '0.333': -0.9316777777777779, '0.5': -0.9178178082191781, '0.667': -0.9427494623655914, '0.833': -0.9482188405797102, '1.0': -0.9526906976744186}
best rdn ma / adv:  1 0.5
best rdn adv:  1.906447841478224
Episodes: 2661, frames: 70393, time: 37676.27885580063
training steps:  8587
retraining steps:  0
RDN obj mus: [-0.9310356586694717, -0.9549211904346943, -0.9306064947664737, -0.9078307891130447, -0.8751639080226421]
RDN obj sigmas: [0.02729775281665342, 0.0185749865788318, 0.039472381693939636, 0.04115136392130383, 0.06376073862916765]
2661 : -0.8265833333333334
LR:  0.001
replay buffer size:  78139
Time Taken :  627.0  mins 56.278631925582886  seconds
[[[   0.    0.    0.    0.   49.   45.   93.   60.   41.   53.   24.
      8.    5.   10.   13.    0.    0.    0.    3.    2.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  158. 1459. 1600. 1844. 1668. 1046. 1538.  224.
    534. 1220.  775.   94.    0.    4.   11.   29.    5.    4.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 2225. 2530. 1633. 1205.  791.  285.   70. 1124. 1938.
   1285.  993.  123.    8.  555.  234.   44.   11.   54.   23.    3.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 9597. 4219. 1498. 1467. 2060. 2077. 2094. 2035. 1918. 2579.
   1476. 1231.  162.  233.  532.  395.  223.  148.  130.   25.   19.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  121.  174.   76.   58.    0.    0.    0.    0.    0.
     60. 1195. 1357. 1036.  869.  689.   82.    0.   26.   20.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   14.   31.   19.   17.    8.    9.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.5043999999999998
Q value #end_state_>_threshold:  759
Q value #non_end_state_>threshold:  1017
maxi score:  -0.7395800000000001
siam score:  -0.6738158
Scores:  {'0.167': -0.9308574468085107, '0.333': -0.9237279569892473, '0.5': -0.9023439918533606, '0.667': -0.9449602409638554, '0.833': -0.9480797235023042, '1.0': -0.962906833712984}
best rdn ma / adv:  1 0.5
best rdn adv:  0.30057316265120887
Episodes: 3476, frames: 80326, time: 41862.63378405571
training steps:  9825
retraining steps:  0
RDN obj mus: [-0.9299842287957668, -0.9231054328978062, -0.918421474802494, -0.9076444053590298, -0.8840350967228413]
RDN obj sigmas: [0.03364167957358455, 0.04427490716938315, 0.0395755504355401, 0.04012326548653424, 0.03998989104443098]
3476 : -0.7480833333333334
LR:  0.001
replay buffer size:  88883
Time Taken :  697.0  mins 42.63356399536133  seconds
[[[    0.     0.     0.     0.    70.    70.   107.    88.    63.    81.
      30.     9.     6.    14.    19.     0.     0.     0.     3.     2.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   216.  1680.  1790.  2104.  1803.  1197.  1662.
     270.   564.  1417.   819.   103.     0.     4.    11.    35.     7.
       9.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2473.  2982.  1784.  1460.   897.   405.    86.  1210.
    2011.  1354.  1222.   154.     8.   559.   272.    57.    15.   112.
      49.     5.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 10418.  5125.  1654.  1713.  2335.  2308.  2337.  2359.  2314.
    2871.  1685.  1356.   189.   255.   561.   441.   353.   265.   223.
      44.    29.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   184.   269.   113.    82.     0.     0.     0.     0.
       0.    66.  1296.  1452.  1136.   960.   777.    99.     0.    59.
      40.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    19.    36.    21.    18.    10.    10.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6896000000000001
Q value #end_state_>_threshold:  1416
Q value #non_end_state_>threshold:  2491
maxi score:  -0.5030400000000002
siam score:  -0.71132094
Scores:  {'0.167': -0.88226, '0.333': -0.88856, '0.5': -0.87304, '0.667': -0.9098200000000001, '0.833': -0.9309600000000001, '1.0': -0.94318}
best rdn ma / adv:  1 0.5
best rdn adv:  0.03201919094393478
Episodes: 4263, frames: 90108, time: 45911.24143791199
training steps:  11037
retraining steps:  0
RDN obj mus: [-0.931563260036707, -0.9275553477346897, -0.9202309012949467, -0.9086616662383079, -0.8933635620057583]
RDN obj sigmas: [0.03215041779056136, 0.03533843228074422, 0.0319798648434688, 0.03430018202276858, 0.03341804353338004]
4263 : -0.7378333333333333
LR:  0.001
replay buffer size:  99094
Time Taken :  765.0  mins 11.241230010986328  seconds
[[[    0.     0.     0.     0.    81.    87.   125.   111.    77.    97.
      37.     9.     8.    15.    24.     0.     0.     0.     4.     3.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   263.  1846.  1939.  2312.  1923.  1336.  1793.
     315.   595.  1504.   839.   114.     0.     5.    17.    42.    14.
      18.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2582.  3352.  1951.  1661.   977.   490.    95.  1308.
    2149.  1449.  1282.   172.     9.   651.   310.    89.    30.   235.
      89.     9.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 11362.  5996.  1835.  1911.  2595.  2538.  2596.  2573.  2511.
    3118.  1908.  1463.   215.   283.   618.   521.   532.   456.   495.
      78.    47.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   236.   407.   136.   109.     0.     0.     0.     0.
       0.    72.  1493.  1582.  1244.  1150.   875.   120.     0.   125.
      64.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    26.    40.    26.    20.    13.    13.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6659999999999999
Q value #end_state_>_threshold:  1930
Q value #non_end_state_>threshold:  4563
maxi score:  -0.2823000000000001
siam score:  -0.75843585
Scores:  {'0.167': -0.78188, '0.333': -0.84328, '0.5': -0.82668, '0.667': -0.8697400000000001, '0.833': -0.9114800000000001, '1.0': -0.9179}
best rdn ma / adv:  1 0.5
best rdn adv:  0.01743748647774998
Episodes: 5007, frames: 100108, time: 50152.90976572037
training steps:  12276
retraining steps:  0
RDN obj mus: [-0.934300429391861, -0.9272302159607411, -0.9212077597558498, -0.9136421181440353, -0.8909088611245155]
RDN obj sigmas: [0.030865335384303264, 0.03343317888312671, 0.03556220095369096, 0.03543394246980571, 0.03720117016258815]
5007 : -0.6635000000000001
LR:  0.001
replay buffer size:  109550
Time Taken :  835.0  mins 52.909547090530396  seconds
[[[    0.     0.     0.     0.    97.   105.   149.   140.    93.   117.
      44.     9.     8.    15.    26.     0.     0.     0.     6.     4.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   308.  2054.  2099.  2561.  2038.  1512.  1895.
     362.   610.  1544.   853.   118.     0.     5.    21.    52.    37.
      32.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2637.  3739.  2139.  1877.  1047.   573.   107.  1401.
    2320.  1573.  1441.   184.    10.   776.   361.   196.    76.   454.
     135.    14.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 12019.  6824.  2008.  2081.  2794.  2697.  2769.  2750.  2681.
    3363.  2142.  1823.   249.   341.   693.   620.   742.   645.   704.
     116.    59.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   292.   484.   154.   121.     0.     0.     0.     0.
       0.    79.  1671.  1769.  1420.  1330.   957.   137.     0.   330.
     101.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    31.    46.    31.    21.    19.    14.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6671999999999998
Q value #end_state_>_threshold:  2954
Q value #non_end_state_>threshold:  7582
maxi score:  -0.20178000000000013
siam score:  -0.7537648
Scores:  {'0.167': -0.7110600000000001, '0.333': -0.80474, '0.5': -0.7672599999999999, '0.667': -0.80788, '0.833': -0.8589, '1.0': -0.8858600000000001}
best rdn ma / adv:  1 0.5
best rdn adv:  0.031169265159796875
Episodes: 5633, frames: 110085, time: 54330.0704638958
training steps:  13497
retraining steps:  0
RDN obj mus: [-0.9364331589519977, -0.9364829451978207, -0.9275604011952877, -0.9183102877676487, -0.9117059662401676]
RDN obj sigmas: [0.02659431175783575, 0.0279536668756299, 0.028221315753048606, 0.03123752674730486, 0.030955173274463045]
5633 : -0.6700833333333335
LR:  0.001
replay buffer size:  119974
Time Taken :  905.0  mins 30.070239067077637  seconds
[[[    0.     0.     0.     0.   109.   116.   165.   159.   102.   124.
      46.     9.     8.    16.    29.     0.     0.     0.     6.     6.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   339.  2182.  2230.  2744.  2141.  1647.  1979.
     388.   648.  1615.   862.   123.     0.     7.    28.    82.   128.
      46.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2728.  4026.  2282.  2056.  1109.   635.   108.  1520.
    2407.  1721.  1543.   199.    10.   860.   478.   306.   130.   665.
     183.    19.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 12518.  7528.  2162.  2250.  2987.  2892.  2945.  2933.  2846.
    3588.  2395.  2168.   277.   388.   871.   765.  1001.   922.   940.
     143.    81.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   350.   557.   168.   128.     0.     0.     0.     0.
       0.    85.  1849.  1972.  1633.  1622.  1143.   151.     0.   787.
     154.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    32.    49.    40.    26.    22.    14.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6799999999999998
Q value #end_state_>_threshold:  4181
Q value #non_end_state_>threshold:  10906
maxi score:  -0.16690000000000013
siam score:  -0.7223439
Scores:  {'0.167': -0.6385000000000002, '0.333': -0.74614, '0.5': -0.7486200000000001, '0.667': -0.79566, '0.833': -0.83044, '1.0': -0.8625200000000001}
best rdn ma / adv:  1 0.167
best rdn adv:  0.034287438855602634
Episodes: 6272, frames: 120081, time: 58444.77227592468
training steps:  14712
retraining steps:  0
RDN obj mus: [-0.9339712872505188, -0.9429488354325295, -0.9352616490900516, -0.9261599857151508, -0.9206941934347153]
RDN obj sigmas: [0.024116609700542635, 0.02231481432752211, 0.02664992311549157, 0.029907159609824242, 0.027354717006227287]
6272 : -0.547
LR:  0.001
replay buffer size:  130405
Time Taken :  974.0  mins 4.772054195404053  seconds
[[[    0.     0.     0.     0.   127.   121.   184.   180.   114.   135.
      52.     9.     9.    19.    31.     0.     0.     0.     7.     9.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   374.  2329.  2374.  2952.  2280.  1804.  2099.
     427.   682.  1665.   878.   128.     0.     7.    33.    94.   148.
      59.     2.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2821.  4363.  2477.  2263.  1195.   692.   116.  1666.
    2537.  1838.  1672.   216.    13.   974.   588.   407.   164.   929.
     245.    27.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 13051.  8221.  2324.  2441.  3121.  3077.  3136.  3106.  3010.
    3808.  2633.  2346.   304.   442.  1012.   917.  1290.  1287.  1242.
     184.   102.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   390.   605.   187.   139.     0.     0.     0.     0.
       0.    88.  2089.  2163.  1846.  1825.  1273.   166.     0.  1055.
     187.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    36.    55.    43.    31.    27.    15.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6763999999999999
Q value #end_state_>_threshold:  5545
Q value #non_end_state_>threshold:  13445
maxi score:  -0.07286000000000009
siam score:  -0.7269124
Scores:  {'0.167': -0.57244, '0.333': -0.68064, '0.5': -0.7123400000000001, '0.667': -0.73448, '0.833': -0.80562, '1.0': -0.83006}
best rdn ma / adv:  1 0.167
best rdn adv:  0.04027392185415401
Episodes: 6932, frames: 130109, time: 62639.66254591942
training steps:  15934
retraining steps:  0
RDN obj mus: [-0.9384360780596733, -0.9435830153763294, -0.9346887839436531, -0.9274739172339439, -0.9186811641156674]
RDN obj sigmas: [0.02254252595024148, 0.021894712621492497, 0.02599551018412563, 0.03076772855357319, 0.031263192937472]
6932 : -0.5240000000000001
LR:  0.001
replay buffer size:  140867
Time Taken :  1043.0  mins 59.662322998046875  seconds
[[[    0.     0.     0.     0.   141.   133.   195.   202.   127.   148.
      55.     9.    11.    24.    31.     0.     0.     0.     8.    10.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   402.  2465.  2500.  3154.  2406.  1946.  2196.
     455.   684.  1680.   886.   132.     0.     9.    42.   110.   202.
      81.     4.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2933.  4673.  2669.  2456.  1268.   749.   122.  1806.
    2635.  1945.  1705.   228.    13.  1060.   720.   568.   248.  1138.
     301.    33.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 13687.  8949.  2521.  2623.  3299.  3248.  3314.  3279.  3195.
    4063.  2963.  2521.   327.   518.  1233.  1063.  1584.  1557.  1437.
     228.   138.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   422.   695.   213.   146.     0.     0.     0.     0.
       0.    98.  2355.  2407.  2086.  2102.  1468.   176.     0.  1102.
     219.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    41.    59.    46.    32.    29.    15.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6768
Q value #end_state_>_threshold:  6914
Q value #non_end_state_>threshold:  15832
maxi score:  -0.0229000000000001
siam score:  -0.70355475
Scores:  {'0.167': -0.49208, '0.333': -0.6338600000000001, '0.5': -0.6778400000000001, '0.667': -0.72348, '0.833': -0.76358, '1.0': -0.8005800000000001}
best rdn ma / adv:  1 0.167
best rdn adv:  0.05354209957185073
Episodes: 7569, frames: 140100, time: 66998.66329908371
training steps:  17154
retraining steps:  0
RDN obj mus: [-0.9401139024317264, -0.9419545845925807, -0.9339045438110828, -0.927320932662487, -0.9274836328625679]
RDN obj sigmas: [0.020905084448735445, 0.024404716622123106, 0.02777357295174176, 0.03364808260393071, 0.033388794258068975]
7569 : -0.42666666666666675
LR:  0.001
replay buffer size:  151291
Time Taken :  1116.0  mins 38.66308093070984  seconds
[[[    0.     0.     0.     0.   145.   137.   206.   220.   136.   158.
      61.     9.    12.    32.    33.     0.     0.     0.     8.    12.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   432.  2594.  2614.  3369.  2538.  2110.  2307.
     481.   692.  1724.   899.   136.     0.     9.    44.   147.   227.
      95.     5.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3042.  4968.  2811.  2654.  1342.   801.   132.  1980.
    2772.  2146.  1764.   247.    13.  1153.   844.   675.   314.  1266.
     382.    39.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 14236.  9644.  2701.  2793.  3442.  3402.  3473.  3424.  3370.
    4276.  3320.  2819.   359.   648.  1387.  1220.  1877.  1860.  1654.
     263.   170.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   463.   764.   234.   156.     0.     0.     0.     0.
       0.   103.  2731.  2673.  2314.  2365.  1599.   187.     0.  1168.
     246.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    43.    70.    54.    36.    31.    16.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6772
Q value #end_state_>_threshold:  8270
Q value #non_end_state_>threshold:  18430
maxi score:  0.0813199999999999
siam score:  -0.700513
Scores:  {'0.167': -0.44778, '0.333': -0.57438, '0.5': -0.64096, '0.667': -0.69088, '0.833': -0.73554, '1.0': -0.78592}
best rdn ma / adv:  1 0.167
best rdn adv:  0.05424081979605627
Episodes: 8197, frames: 150118, time: 71474.50876092911
training steps:  18389
retraining steps:  0
RDN obj mus: [-0.9452423389196396, -0.9477015470027924, -0.9395321258187294, -0.933839355045557, -0.9229957066357136]
RDN obj sigmas: [0.019395238761470996, 0.02185761054141646, 0.02478841384505461, 0.0300710981512397, 0.033899660816988746]
8197 : -0.4444166666666668
LR:  0.001
replay buffer size:  161739
Time Taken :  1191.0  mins 14.508549928665161  seconds
[[[    0.     0.     0.     0.   151.   146.   220.   235.   147.   172.
      64.     9.    12.    39.    34.     0.     0.     0.     9.    13.
       4.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   458.  2699.  2738.  3622.  2663.  2305.  2401.
     505.   713.  1763.   940.   147.     0.    10.    46.   174.   256.
     119.    10.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3164.  5244.  2932.  2883.  1411.   845.   146.  2180.
    2896.  2270.  1806.   263.    13.  1256.   979.   781.   483.  1419.
     453.    55.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 14817. 10339.  2841.  3000.  3588.  3568.  3641.  3594.  3550.
    4538.  3661.  3064.   387.   752.  1653.  1357.  2186.  2114.  1798.
     304.   192.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   493.   834.   248.   165.     0.     0.     0.     0.
       0.   112.  3084.  2924.  2659.  2553.  1661.   202.     0.  1193.
     270.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    48.    75.    59.    41.    37.    16.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6775999999999999
Q value #end_state_>_threshold:  9419
Q value #non_end_state_>threshold:  20893
maxi score:  0.04283999999999991
siam score:  -0.70605683
Scores:  {'0.167': -0.42660000000000003, '0.333': -0.5372600000000002, '0.5': -0.6239399999999999, '0.667': -0.68402, '0.833': -0.7023600000000001, '1.0': -0.77398}
best rdn ma / adv:  1 0.167
best rdn adv:  0.06072424028988871
Episodes: 8819, frames: 160116, time: 75925.45613384247
training steps:  19614
retraining steps:  0
RDN obj mus: [-0.9474196792960167, -0.9457650153398514, -0.9374138447105884, -0.9327246089160443, -0.9206360201299191]
RDN obj sigmas: [0.020371866680111275, 0.02177324840142991, 0.02522240749116551, 0.03283400272098434, 0.03304211064435167]
8819 : -0.3834166666666667
LR:  0.001
replay buffer size:  172166
Time Taken :  1265.0  mins 25.455912113189697  seconds
[[[    0.     0.     0.     0.   161.   154.   235.   244.   160.   177.
      66.    11.    12.    49.    35.     0.     0.     0.     9.    15.
       4.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   500.  2836.  2875.  3876.  2783.  2502.  2520.
     543.   765.  1791.   963.   156.     0.    12.    54.   226.   337.
     147.    14.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3263.  5556.  3071.  3090.  1501.   888.   156.  2394.
    3046.  2458.  1852.   275.    13.  1415.  1185.   916.   539.  1485.
     510.    66.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15352. 11018.  3002.  3169.  3712.  3699.  3774.  3721.  3702.
    4740.  3903.  3371.   416.   892.  1853.  1538.  2401.  2400.  1955.
     330.   233.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   523.   887.   271.   174.     0.     0.     0.     0.
       0.   117.  3464.  3254.  2974.  2732.  1727.   213.     0.  1270.
     300.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    51.    80.    66.    42.    42.    18.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7480000000000001
Q value #end_state_>_threshold:  10657
Q value #non_end_state_>threshold:  23150
maxi score:  0.06325999999999991
siam score:  -0.6962381
Scores:  {'0.167': -0.38960000000000006, '0.333': -0.49398000000000003, '0.5': -0.62438, '0.667': -0.6793000000000001, '0.833': -0.69174, '1.0': -0.7755000000000002}
best rdn ma / adv:  1 0.167
best rdn adv:  0.07027421655375174
Episodes: 9411, frames: 170083, time: 80220.08218288422
training steps:  20845
retraining steps:  0
RDN obj mus: [-0.9453730595350266, -0.9421493261516094, -0.932382003903389, -0.9295885997653007, -0.9222115624755621]
RDN obj sigmas: [0.022278125189007104, 0.028468479138145122, 0.03339872806873846, 0.03683316855767056, 0.04962667537800289]
9411 : -0.6619166666666667
LR:  0.001
replay buffer size:  182556
Time Taken :  1337.0  mins 0.08197212219238281  seconds
[[[    0.     0.     0.     0.   167.   160.   245.   256.   177.   183.
      69.    11.    12.    54.    37.     0.     0.     0.    11.    19.
       5.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   524.  2940.  3042.  4141.  2931.  2713.  2663.
     587.   786.  1849.  1003.   168.     0.    16.    58.   263.   372.
     164.    25.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3374.  5836.  3219.  3363.  1592.   942.   174.  2635.
    3195.  2583.  1885.   297.    16.  1570.  1374.  1007.   609.  1554.
     576.    81.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15951. 11667.  3138.  3383.  3832.  3840.  3905.  3866.  3856.
    4972.  4169.  3582.   449.  1046.  2090.  1648.  2670.  2662.  2093.
     360.   266.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   538.   929.   277.   180.     0.     0.     0.     0.
       0.   122.  3856.  3664.  3275.  2889.  1803.   225.     0.  1295.
     323.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    54.    83.    71.    48.    44.    18.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6828
Q value #end_state_>_threshold:  11835
Q value #non_end_state_>threshold:  25170
maxi score:  0.00943999999999991
siam score:  -0.6941046
Scores:  {'0.167': -0.3544800000000001, '0.333': -0.49440000000000006, '0.5': -0.5887800000000001, '0.667': -0.6435200000000001, '0.833': -0.6879400000000001, '1.0': -0.77188}
best rdn ma / adv:  1 0.167
best rdn adv:  0.04091495000019802
Episodes: 9975, frames: 180079, time: 87267.33340787888
training steps:  22145
retraining steps:  0
RDN obj mus: [-0.9451173857688904, -0.9471253411889077, -0.9412544672071934, -0.9353279914259911, -0.9283558649837971]
RDN obj sigmas: [0.018122312975766948, 0.026974076487868474, 0.028871935672235456, 0.0320208482704027, 0.04491684627469637]
9975 : -0.4045
LR:  0.001
replay buffer size:  192980
Time Taken :  1454.0  mins 27.3332040309906  seconds
[[[    0.     0.     0.     0.   173.   163.   255.   268.   185.   187.
      72.    11.    12.    56.    39.     0.     0.     0.    11.    20.
       5.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   548.  3031.  3193.  4406.  3111.  2935.  2871.
     624.   792.  1901.  1039.   185.     0.    18.    61.   296.   413.
     191.    34.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3476.  6125.  3395.  3616.  1662.   980.   193.  2878.
    3373.  2739.  2016.   323.    19.  1736.  1573.  1100.   714.  1614.
     632.    90.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 16360. 12282.  3263.  3580.  3950.  3963.  4042.  3983.  4044.
    5224.  4448.  3783.   474.  1183.  2286.  1769.  2910.  2941.  2225.
     385.   310.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   558.   956.   288.   187.     0.     0.     0.     0.
       0.   129.  4198.  4050.  3563.  3242.  1918.   240.     0.  1309.
     347.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    57.    91.    78.    55.    50.    23.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7272
Q value #end_state_>_threshold:  13024
Q value #non_end_state_>threshold:  27446
maxi score:  0.027639999999999908
siam score:  -0.67426103
Scores:  {'0.167': -0.3214200000000001, '0.333': -0.49900000000000005, '0.5': -0.5946600000000001, '0.667': -0.6584, '0.833': -0.69194, '1.0': -0.76566}
best rdn ma / adv:  1 0.167
best rdn adv:  0.07307517225177117
Episodes: 10553, frames: 190057, time: 93568.12282371521
training steps:  23372
retraining steps:  0
RDN obj mus: [-0.9454692360758782, -0.9468732986211776, -0.940246658140421, -0.9345851311862469, -0.9192404534518719]
RDN obj sigmas: [0.018445505584107406, 0.02173833438836448, 0.02504103736109502, 0.031491543904085366, 0.04672981287154406]
10553 : -0.5010833333333334
LR:  0.001
replay buffer size:  200231
Time Taken :  1559.0  mins 28.12261700630188  seconds
[[[    0.     0.     0.     0.   178.   169.   268.   280.   198.   192.
      73.    11.    12.    57.    41.     0.     0.     0.    11.    21.
       9.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   571.  3123.  3358.  4639.  3305.  3149.  2992.
     675.   793.  1909.  1051.   193.     0.    20.    65.   318.   457.
     210.    51.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3600.  6387.  3540.  3888.  1741.  1031.   214.  3061.
    3549.  2846.  2063.   342.    20.  1862.  1780.  1256.   799.  1670.
     692.   108.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 16780. 12907.  3401.  3797.  4090.  4116.  4218.  4150.  4247.
    5522.  4779.  3984.   503.  1363.  2524.  1915.  3085.  3113.  2332.
     398.   337.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   578.   986.   302.   192.     0.     0.     0.     0.
       0.   134.  4667.  4567.  3915.  3393.  2004.   257.     0.  1340.
     375.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    59.    97.    89.    59.    55.    26.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.8472000000000002
Q value #end_state_>_threshold:  14015
Q value #non_end_state_>threshold:  29590
maxi score:  0.03813999999999992
siam score:  -0.67765594
Scores:  {'0.167': -0.3059400000000001, '0.333': -0.47648000000000007, '0.5': -0.6083, '0.667': -0.67038, '0.833': -0.71994, '1.0': -0.76936}
best rdn ma / adv:  1 0.167
best rdn adv:  0.053800107023914905
Episodes: 11163, frames: 200067, time: 100757.19413280487
training steps:  24569
retraining steps:  0
RDN obj mus: [-0.9447986555635929, -0.9442308520197868, -0.9390458194851875, -0.9345548706531525, -0.9230380549967289]
RDN obj sigmas: [0.019323308744483493, 0.022549450965084067, 0.029442007448206152, 0.03527068440618698, 0.0399614378776343]
11163 : -0.5618333333333335
LR:  0.001
replay buffer size:  200211
Time Taken :  1679.0  mins 17.193916082382202  seconds
[[[    0.     0.     0.     0.   185.   174.   281.   294.   212.   200.
      75.    11.    12.    58.    47.     0.     0.     0.    11.    21.
       9.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   596.  3231.  3498.  4888.  3490.  3346.  3158.
     733.   797.  1969.  1075.   203.     0.    20.    73.   349.   482.
     229.    58.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3708.  6663.  3714.  4178.  1850.  1092.   236.  3271.
    3706.  2990.  2116.   367.    23.  1926.  1940.  1351.   863.  1761.
     743.   121.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17129. 13556.  3530.  4027.  4188.  4248.  4361.  4299.  4406.
    5782.  5062.  4176.   534.  1453.  2680.  2075.  3289.  3348.  2446.
     415.   374.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   602.  1017.   316.   203.     0.     0.     0.     0.
       0.   139.  5092.  5343.  4213.  3619.  2136.   279.     0.  1361.
     395.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    62.   100.    96.    63.    59.    27.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.8495999999999999
Q value #end_state_>_threshold:  14990
Q value #non_end_state_>threshold:  31360
maxi score:  0.02999999999999992
siam score:  -0.6948555
Scores:  {'0.167': -0.29702000000000006, '0.333': -0.4842000000000001, '0.5': -0.6085200000000001, '0.667': -0.67788, '0.833': -0.74524, '1.0': -0.78352}
best rdn ma / adv:  1 0.167
best rdn adv:  0.0006380803976261278
Episodes: 11676, frames: 210085, time: 107822.37164998055
training steps:  25751
retraining steps:  0
RDN obj mus: [-0.9431764645755291, -0.9579014401972293, -0.951439374256134, -0.9418819952487946, -0.9368277602374554]
RDN obj sigmas: [0.02145957543244331, 0.01767987518287081, 0.02258809034309291, 0.030036520211641504, 0.03586354189754762]
11676 : -0.5205833333333334
LR:  0.001
replay buffer size:  200385
Time Taken :  1797.0  mins 2.3714399337768555  seconds
[[[    0.     0.     0.     0.   190.   178.   286.   305.   221.   210.
      79.    13.    14.    60.    48.     0.     0.     0.    11.    22.
       9.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   611.  3312.  3636.  5146.  3711.  3573.  3291.
     778.   834.  1982.  1169.   210.     0.    20.    75.   388.   506.
     250.    72.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3779.  6856.  3847.  4430.  1934.  1142.   258.  3456.
    3925.  3091.  2189.   379.    23.  2026.  2120.  1430.   907.  1807.
     772.   136.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17435. 14141.  3650.  4251.  4292.  4376.  4504.  4434.  4560.
    6016.  5368.  4475.   563.  1570.  2840.  2199.  3467.  3512.  2551.
     437.   402.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   622.  1042.   326.   214.     0.     0.     0.     0.
       0.   143.  5522.  6554.  4639.  3829.  2220.   295.     0.  1395.
     416.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    63.   109.   103.    67.    60.    30.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7728
Q value #end_state_>_threshold:  16104
Q value #non_end_state_>threshold:  33243
maxi score:  0.07765999999999994
siam score:  -0.69603026
Scores:  {'0.167': -0.27370000000000005, '0.333': -0.4771000000000001, '0.5': -0.6455000000000001, '0.667': -0.69288, '0.833': -0.73668, '1.0': -0.7831400000000001}
best rdn ma / adv:  1 0.167
best rdn adv:  0.0006332560382115024
Episodes: 12162, frames: 220106, time: 115139.08199977875
training steps:  26934
retraining steps:  0
RDN obj mus: [-0.9473647979676724, -0.9499698880195617, -0.9446284907877445, -0.9406396059691906, -0.940464856261015]
RDN obj sigmas: [0.01813330954856935, 0.022414726730695337, 0.027028838746705065, 0.033630633049993475, 0.03672646486036612]
12162 : -0.474
LR:  0.001
replay buffer size:  200225
Time Taken :  1918.0  mins 59.08178687095642  seconds
[[[    0.     0.     0.     0.   194.   181.   291.   315.   232.   218.
      81.    13.    14.    60.    50.     0.     0.     0.    12.    25.
       9.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   618.  3382.  3785.  5430.  4227.  4016.  3473.
     820.   858.  2020.  1218.   224.     0.    20.    81.   403.   528.
     266.    81.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3879.  7054.  4043.  4689.  2033.  1171.   278.  3655.
    4119.  3194.  2232.   396.    25.  2188.  2307.  1544.   998.  1859.
     814.   154.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17738. 14669.  3750.  4477.  4377.  4486.  4615.  4566.  4692.
    6241.  5652.  4682.   588.  1691.  3007.  2387.  3639.  3685.  2663.
     461.   429.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   652.  1055.   338.   218.     0.     0.     0.     0.
       0.   146.  6160.  7289.  4926.  3970.  2280.   313.     0.  1421.
     437.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    64.   114.   114.    76.    64.    35.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7027999999999999
Q value #end_state_>_threshold:  16880
Q value #non_end_state_>threshold:  34476
maxi score:  0.07691999999999993
siam score:  -0.67847884
Scores:  {'0.167': -0.26338, '0.333': -0.4978, '0.5': -0.65044, '0.667': -0.6967000000000001, '0.833': -0.7694599999999999, '1.0': -0.80258}
best rdn ma / adv:  1 0.167
best rdn adv:  0.030465786044958077
Episodes: 12632, frames: 230029, time: 122645.92520689964
training steps:  28111
retraining steps:  0
RDN obj mus: [-0.9457650290012359, -0.9397215775966644, -0.9363869463920593, -0.932006282454729, -0.8936644866764546]
RDN obj sigmas: [0.017212633236157463, 0.02457278353666404, 0.027803126143707477, 0.033659813008819116, 0.05291090640908263]
12632 : -0.5599166666666666
LR:  0.001
replay buffer size:  200040
Time Taken :  2044.0  mins 5.924999952316284  seconds
[[[    0.     0.     0.     0.   196.   187.   299.   324.   245.   233.
      85.    13.    14.    62.    51.     0.     0.     0.    12.    26.
       9.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   625.  3451.  3957.  5860.  4845.  4820.  3711.
     862.   862.  2112.  1291.   245.     0.    21.    83.   418.   552.
     288.    89.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  4033.  7280.  4216.  4947.  2112.  1219.   292.  3857.
    4318.  3304.  2292.   419.    25.  2330.  2423.  1609.  1040.  1891.
     840.   163.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 18062. 15181.  3860.  4687.  4495.  4598.  4725.  4690.  4811.
    6465.  5945.  4885.   620.  1802.  3114.  2465.  3752.  3804.  2727.
     470.   458.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   672.  1068.   349.   225.     0.     0.     0.     0.
       0.   150.  6669.  7950.  5100.  4063.  2372.   331.     0.  1433.
     453.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    66.   116.   120.    80.    68.    38.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
