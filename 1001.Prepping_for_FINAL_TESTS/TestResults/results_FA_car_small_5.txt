EVALUATIONS AND MAIN RESULTS
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9695969696969697
siam score:  -0.0038768365810115243
Scores:  {'0.167': -0.8332333333333334, '0.333': -0.8749, '0.5': -0.8749, '0.667': -0.8749, '0.833': -0.7499, '1.0': -0.8749}
best rdn ma / adv:  1 0.167
best rdn adv:  0.0
Episodes: 45, frames: 939, time: 61.17069721221924
training steps:  4
retraining steps:  0
RDN obj mus: [0.04912609581408204, 0.05780708374210981, 0.035963159427046774, 0.03318429132923484, 0.0]
RDN obj sigmas: [0.00828251225053876, 0.0031853701289427288, 0.011992747874932928, 0.012589990329822541, 0.0]
45 : -1.0
LR:  3e-06
replay buffer size:  1449
Time Taken :  1.0  mins 1.1704509258270264  seconds
[[[  0.   0.   0.   0.   0.   2.   1.   0.   1.   0.   0.   0.   0.   0.
     1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   4.   1.   9.   4.   1.   0.   0.   0.   0.   1.   1.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  43.  32.  48.  18.   7.   5.   0.   0.   0.   0.   1.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0. 276.  94.  34.  27.  87.  54.  24.  42.  20.  14.  17.   1.   1.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  10.   7.   5.   1.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9909714285714286
siam score:  -0.8420024
Scores:  {'0.167': -0.9781608695652174, '0.333': -0.9766441860465116, '0.5': -0.9760904761904762, '0.667': -0.9771727272727273, '0.833': -0.9766441860465116, '1.0': -0.9771727272727273}
best rdn ma / adv:  1 0.5
best rdn adv:  0.17286655260960007
Episodes: 321, frames: 10969, time: 5784.6662929058075
training steps:  1325
retraining steps:  0
RDN obj mus: [-0.9207049196302891, -0.9282297509133816, -0.9296188358426094, -0.8607924490817731, -0.8609686424334844]
RDN obj sigmas: [0.02258332294677341, 0.026030137668376276, 0.03573521374602207, 0.07162871716375227, 0.12603872218806536]
321 : -1.0
LR:  0.001
replay buffer size:  13318
Time Taken :  96.0  mins 24.66603922843933  seconds
[[[   0.    0.    0.    0.    2.   12.    9.    6.    4.    1.    0.
      0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   23.  215.  213.  143.   65.    9.    7.    5.
      0.    4.    2.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  775.  358.  385.  247.  158.   25.    6.    7.   12.
     48.   18.    0.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 3445. 1350.  441.  205.  601.  613.  452.  315.  194.   93.
     46.    2.    1.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   41.   45.   28.   10.    0.    0.    0.    0.    0.
      3.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9949
siam score:  -0.87371546
Scores:  {'0.167': -0.9890304347826087, '0.333': -0.9885363636363637, '0.5': -0.9890304347826087, '0.667': -0.9881352941176471, '0.833': -0.9867421052631579, '1.0': -0.9885363636363637}
best rdn ma / adv:  1 0.833
best rdn adv:  0.09672572889465662
Episodes: 640, frames: 20145, time: 10444.624273061752
training steps:  2421
retraining steps:  0
RDN obj mus: [-0.9226940242648125, -0.943430591082573, -0.9073695640206337, -0.8850830549418927, -0.869622932805401]
RDN obj sigmas: [0.02988348580572465, 0.03079278170210558, 0.052925660511523955, 0.05736451635826298, 0.06448016418612909]
640 : -1.0
LR:  0.001
replay buffer size:  22798
Time Taken :  174.0  mins 4.624016284942627  seconds
[[[   0.    0.    0.    0.   10.   21.   22.   21.   16.    6.    6.
      0.    1.    0.    2.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   55.  676.  830.  627.  308.  265.   97.   24.
      7.  114.   13.    3.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1232. 1023.  949.  610.  569.   86.   11.   46.   21.
    134.  198.   12.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 4853. 1943.  615.  360.  808.  834.  671.  484.  345.  259.
     98.    8.    9.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   60.   77.   37.   17.    0.    0.    0.    0.    0.
      6.    1.    1.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    1.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.996993023255814
siam score:  -0.85766274
Scores:  {'0.167': -0.9940860465116279, '0.333': -0.9935305732484077, '0.5': -0.9939119760479042, '0.667': -0.9937650306748467, '0.833': -0.9932774834437086, '1.0': -0.9931885906040269}
best rdn ma / adv:  1 1.0
best rdn adv:  0.04966424170358007
Episodes: 1197, frames: 30151, time: 16002.669708967209
training steps:  3692
retraining steps:  0
RDN obj mus: [-0.8970136344969273, -0.9267033120572566, -0.905375448590517, -0.8792476967453957, -0.8383809992551804]
RDN obj sigmas: [0.03148379643316921, 0.038643138904733115, 0.05329856162307666, 0.0503390024456426, 0.058193066006846705]
1197 : -1.0
LR:  0.001
replay buffer size:  32951
Time Taken :  266.0  mins 42.669453144073486  seconds
[[[   0.    0.    0.    0.   23.   42.   42.   32.   25.   16.    7.
      0.    1.    1.    2.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  106.  872.  988.  775.  372.  302.  140.   45.
     10.  329.   53.    8.    0.    0.    0.   18.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1761. 1464. 1175.  766.  762.  158.   25.   66.   33.
    221.  369.   33.    2.    0.    2.    1.    1.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 6550. 2750.  856.  585. 1167. 1169. 1011.  853.  960.  748.
    222.  190.   44.   21.    3.    0.    0.    5.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  118.  138.   79.   36.    0.    0.    0.    0.    0.
     23.  199.  161.   13.    0.    1.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    1.    1.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9977947368421053
siam score:  -0.84710467
Scores:  {'0.167': -0.9956264957264958, '0.333': -0.9957677685950413, '0.5': -0.9955521739130435, '0.667': -0.9955896551724138, '0.833': -0.9952488372093024, '1.0': -0.9952703703703704}
best rdn ma / adv:  1 0.833
best rdn adv:  0.03450584431435698
Episodes: 1714, frames: 40209, time: 20971.41540503502
training steps:  4818
retraining steps:  0
RDN obj mus: [-0.9350851751565933, -0.9447838853597641, -0.9299620776534081, -0.8946737712442875, -0.8664652009785175]
RDN obj sigmas: [0.029633727216425442, 0.030923854688934604, 0.04315735090392677, 0.04695455107767157, 0.05527167215883036]
1714 : -1.0
LR:  0.001
replay buffer size:  43665
Time Taken :  349.0  mins 31.41515326499939  seconds
[[[   0.    0.    0.    0.   30.   61.   59.   48.   31.   20.    8.
      0.    1.    5.    4.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  131. 1015. 1112.  999.  435.  365.  293.   88.
     10.  607.  290.   16.    0.    0.    0.   18.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 2239. 1905. 1468.  926.  924.  237.   31.  157.   60.
    290.  626.   56.    3.    0.    2.    1.    1.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 7905. 3420. 1091.  847. 1551. 1492. 1364. 1214. 1600. 1309.
    413.  572.   81.   25.    4.    3.   14.    5.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  156.  195.  108.   56.    0.    0.    0.    0.    0.
     38.  248.  187.   15.    0.    1.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    3.    4.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.84156126
Scores:  {'0.167': -0.9965887417218543, '0.333': -0.9966105263157895, '0.5': -0.9963412811387901, '0.667': -0.9964277777777778, '0.833': -0.996315770609319, '1.0': -0.9924714285714287}
best rdn ma / adv:  1 1.0
best rdn adv:  0.061023046599957685
Episodes: 2147, frames: 50139, time: 26969.4022231102
training steps:  6169
retraining steps:  0
RDN obj mus: [-0.9383915772259236, -0.959945024061203, -0.9329857554554939, -0.9109500701248646, -0.8899684804916382]
RDN obj sigmas: [0.029009184879753534, 0.02860385354113885, 0.0453581159089451, 0.04495826273012709, 0.05363152955257977]
2147 : -1.0
LR:  0.001
replay buffer size:  53896
Time Taken :  449.0  mins 29.401965141296387  seconds
[[[   0.    0.    0.    0.   41.   76.   68.   57.   37.   26.   10.
      0.    1.   12.    4.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  147. 1120. 1225. 1112.  522.  457.  692.  134.
     32.  959.  585.   33.    0.    0.    0.   18.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 2468. 2222. 1675. 1082.  970.  276.   35.  547.  177.
    469. 1093.   90.    6.    0.   20.    1.    1.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 8830. 3929. 1255. 1059. 1787. 1790. 1654. 1648. 2153. 1791.
    685. 1142.  127.   25.    4.   13.   16.    7.    1.    0.    1.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  180.  236.  125.   74.    0.    0.    0.    0.    0.
     56.  386.  291.  117.   87.   10.    2.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    4.    6.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.72125345
Scores:  {'0.167': -0.9972753280839896, '0.333': -0.9970988795518207, '0.5': -0.9970509971509972, '0.667': -0.9971144846796658, '0.833': -0.9969588235294118, '1.0': -0.9938710144927537}
best rdn ma / adv:  1 1.0
best rdn adv:  0.04952595086373377
Episodes: 2659, frames: 60376, time: 32676.891846179962
training steps:  7489
retraining steps:  0
RDN obj mus: [-0.941897566485405, -0.9572727396726608, -0.9468298586249352, -0.9132941848278046, -0.8901861795544624]
RDN obj sigmas: [0.027118086442219032, 0.02596445799568967, 0.03468244468360874, 0.04114877829465504, 0.049406196639467215]
2659 : -1.0
LR:  0.001
replay buffer size:  65016
Time Taken :  544.0  mins 36.891592264175415  seconds
[[[    0.     0.     0.     0.    46.    83.    88.    71.    49.    38.
      20.     1.     5.    16.     6.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   174.  1312.  1448.  1335.   667.   603.  1192.
     177.    99.  1111.  1095.    65.     0.     0.     0.    18.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2684.  2551.  1847.  1270.  1104.   320.    49.   832.
     269.   569.  1532.   133.     9.     0.    20.     1.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 10019.  4641.  1441.  1234.  2015.  2013.  1889.  1931.  2489.
    2192.   883.  1457.   170.    40.    80.    35.    51.    15.     1.
       0.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   198.   281.   149.    89.     0.     0.     0.     0.
       0.    75.   529.   482.   203.   124.    43.    11.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    11.    10.     3.     1.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  1
maxi score:  -0.9999
siam score:  -0.6547601
Scores:  {'0.167': -0.9924053078556264, '0.333': -0.994503524229075, '0.5': -0.9946297297297296, '0.667': -0.9975851851851852, '0.833': -0.9975303317535545, '1.0': -0.9827297362110312}
best rdn ma / adv:  1 1.0
best rdn adv:  0.5380446330613277
Episodes: 3281, frames: 70280, time: 37860.31625318527
training steps:  8673
retraining steps:  0
RDN obj mus: [-0.9329912016510964, -0.9481038163542748, -0.9292057348132133, -0.9082575968921185, -0.8764218594193458]
RDN obj sigmas: [0.031689392607334894, 0.036423192080934676, 0.04220695384136519, 0.038411983837467446, 0.0631176642977492]
3281 : -0.9865833333333334
LR:  0.001
replay buffer size:  75185
Time Taken :  631.0  mins 0.31600308418273926  seconds
[[[    0.     0.     0.     0.    69.   103.   113.    98.    60.    50.
      29.     2.     7.    23.    14.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   201.  1514.  1685.  1644.   894.   767.  1406.
     238.   144.  1260.  1508.    91.     0.     0.     2.    19.     0.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2871.  2915.  2087.  1494.  1194.   379.    73.   926.
     391.   691.  1683.   158.    17.    24.    33.     4.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 11011.  5342.  1640.  1427.  2189.  2186.  2061.  2112.  2646.
    2581.  1072.  1613.   208.    68.   184.    90.   109.    57.    17.
       1.     4.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   225.   350.   170.   100.     0.     0.     0.     0.
       0.    91.   718.   821.   323.   229.   381.    34.     0.     8.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    16.    15.     9.     4.     2.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  4
Q value #non_end_state_>threshold:  115
maxi score:  -0.99726
siam score:  -0.6609619
Scores:  {'0.167': -0.98056, '0.333': -0.99164, '0.5': -0.98044, '0.667': -0.9951129817444219, '0.833': -0.9855389452332657, '1.0': -0.9761985685071575}
best rdn ma / adv:  1 1.0
best rdn adv:  0.686208306025794
Episodes: 3762, frames: 80578, time: 40980.028013944626
training steps:  9492
retraining steps:  0
RDN obj mus: [-0.9509286597788333, -0.9573596174359321, -0.9517520744681358, -0.9195141900062561, -0.8858251580357551]
RDN obj sigmas: [0.01959541714329492, 0.024521797294659173, 0.03115290728126042, 0.03619024717271744, 0.06258623793401252]
3762 : -0.91325
LR:  0.001
replay buffer size:  87026
Time Taken :  683.0  mins 0.027761220932006836  seconds
[[[    0.     0.     0.     0.    78.   112.   123.   117.    70.    55.
      32.     4.     9.    25.    17.     0.     0.     0.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   223.  1634.  1846.  1878.  1036.   903.  1526.
     277.   171.  1356.  1854.   116.     0.     1.     5.    22.     3.
       4.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3081.  3177.  2274.  1707.  1280.   416.    85.  1037.
     479.   747.  1836.   182.    21.    74.   142.    19.     4.     3.
      13.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 12038.  5919.  1866.  1690.  2418.  2419.  2287.  2352.  2930.
    2923.  1288.  1854.   242.   175.   292.   158.   189.   120.    60.
       1.     7.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   242.   391.   183.   112.     0.     0.     0.     0.
       0.   102.  1048.  1433.   494.   420.   940.    61.     0.     8.
       5.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    24.    21.    15.     7.     4.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -0.36200000000000004
Q value #end_state_>_threshold:  34
Q value #non_end_state_>threshold:  312
maxi score:  -0.9630000000000001
siam score:  -0.67263484
Scores:  {'0.167': -0.95792, '0.333': -0.96738, '0.5': -0.9693400000000001, '0.667': -0.97862, '0.833': -0.96606, '1.0': -0.9644199999999999}
best rdn ma / adv:  1 0.167
best rdn adv:  0.9501865591433852
Episodes: 4325, frames: 90281, time: 44925.687224149704
training steps:  10654
retraining steps:  0
RDN obj mus: [-0.944061936712265, -0.9585279525399208, -0.9406048048853874, -0.9162445017516613, -0.8878347170352936]
RDN obj sigmas: [0.02285051319332512, 0.023492481276494632, 0.03499993064051923, 0.03996147763931858, 0.056988127834002]
4325 : -0.8926666666666667
LR:  0.001
replay buffer size:  97772
Time Taken :  748.0  mins 45.68697500228882  seconds
[[[    0.     0.     0.     0.    86.   130.   146.   126.    85.    66.
      35.     5.    10.    30.    22.     0.     0.     0.     1.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   257.  1816.  2023.  2108.  1225.  1039.  1748.
     325.   180.  1507.  2192.   135.     0.     2.     6.    24.     5.
       7.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3205.  3490.  2462.  1889.  1365.   468.    99.  1187.
     672.   840.  1921.   200.    26.    77.   294.    98.     8.    40.
      19.     3.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 12988.  6545.  2011.  1903.  2587.  2617.  2486.  2576.  3127.
    3230.  1480.  1985.   276.   186.   351.   302.   336.   197.   146.
       9.    17.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   276.   446.   191.   121.     0.     0.     0.     0.
       0.   121.  1231.  1774.   623.   512.  1351.    85.     0.    47.
      14.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    37.    27.    17.    10.     8.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.4847999999999999
Q value #end_state_>_threshold:  149
Q value #non_end_state_>threshold:  997
maxi score:  -0.7730800000000001
siam score:  -0.7721803
Scores:  {'0.167': -0.9164, '0.333': -0.9319600000000001, '0.5': -0.9440200000000001, '0.667': -0.95986, '0.833': -0.9481200000000001, '1.0': -0.95492}
best rdn ma / adv:  1 0.167
best rdn adv:  0.32140995072938583
Episodes: 5088, frames: 100243, time: 49177.08295607567
training steps:  11892
retraining steps:  0
RDN obj mus: [-0.9237189690411091, -0.9151664748728275, -0.9060660638034344, -0.9033269367873669, -0.8612003644406796]
RDN obj sigmas: [0.028698765094647628, 0.04285746884603807, 0.044297529077646496, 0.04138171082602504, 0.053742392715463494]
5088 : -0.86025
LR:  0.001
replay buffer size:  108435
Time Taken :  819.0  mins 37.08270812034607  seconds
[[[    0.     0.     0.     0.   105.   155.   171.   156.   100.    76.
      40.     6.    11.    32.    23.     0.     0.     0.     1.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   321.  2021.  2183.  2344.  1353.  1167.  1843.
     358.   182.  1535.  2216.   138.     0.     2.     8.    33.     7.
       8.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3334.  3927.  2595.  2084.  1432.   520.   121.  1268.
     738.   915.  1945.   211.    29.    78.   322.   113.    13.    54.
      49.     5.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 13840.  7389.  2209.  2157.  2778.  2836.  2745.  2851.  3386.
    3521.  1712.  2099.   301.   205.   417.   393.   527.   368.   257.
      23.    39.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   358.   542.   228.   140.     0.     0.     0.     0.
       0.   129.  1517.  1915.   752.   645.  2116.   114.     0.   120.
      34.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    48.    35.    25.    18.    11.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7484000000000001
Q value #end_state_>_threshold:  567
Q value #non_end_state_>threshold:  2232
maxi score:  -0.48746000000000006
siam score:  -0.79133135
Scores:  {'0.167': -0.8559599999999999, '0.333': -0.89758, '0.5': -0.9244, '0.667': -0.93946, '0.833': -0.93046, '1.0': -0.9446000000000001}
best rdn ma / adv:  1 0.167
best rdn adv:  0.028697932633311062
Episodes: 5882, frames: 110137, time: 53424.2492351532
training steps:  13128
retraining steps:  0
RDN obj mus: [-0.9374154590666294, -0.9376240763187409, -0.9313634680330753, -0.9201038705468177, -0.9023890636324883]
RDN obj sigmas: [0.024985301161666567, 0.03577413445442236, 0.03226009460701593, 0.034140883966846704, 0.033464384945940714]
5882 : -0.6925000000000001
LR:  0.001
replay buffer size:  118775
Time Taken :  890.0  mins 24.24898099899292  seconds
[[[    0.     0.     0.     0.   125.   169.   201.   182.   110.    97.
      51.     6.    12.    34.    24.     0.     0.     0.     1.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   360.  2191.  2306.  2590.  1475.  1297.  1941.
     399.   184.  1559.  2253.   142.     0.     3.    12.    58.    23.
      17.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3411.  4325.  2716.  2308.  1492.   588.   134.  1348.
     818.   958.  1996.   230.    30.   138.   459.   149.    20.   155.
      85.     8.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 14579.  8261.  2319.  2327.  2995.  3035.  2978.  3066.  3592.
    3778.  1956.  2212.   326.   232.   506.   586.   783.   620.   468.
      46.    62.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   442.   672.   259.   152.     0.     0.     0.     0.
       0.   145.  1757.  2058.   886.   752.  2599.   127.     0.   252.
      62.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    56.    43.    29.    20.    15.     9.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7888
Q value #end_state_>_threshold:  1207
Q value #non_end_state_>threshold:  3839
maxi score:  -0.2384200000000001
siam score:  -0.74692065
Scores:  {'0.167': -0.7700000000000001, '0.333': -0.85712, '0.5': -0.87076, '0.667': -0.9197599999999999, '0.833': -0.9118400000000001, '1.0': -0.9482}
best rdn ma / adv:  1 0.167
best rdn adv:  0.004410088050206598
Episodes: 6642, frames: 120074, time: 57533.77873921394
training steps:  14345
retraining steps:  0
RDN obj mus: [-0.9463579708576202, -0.9273896393060684, -0.9288380677759648, -0.925419031625986, -0.9165450293242932]
RDN obj sigmas: [0.023669057889929714, 0.041410877311207676, 0.03515904908798645, 0.031984854049595245, 0.027340461171084178]
6642 : -0.6147500000000001
LR:  0.001
replay buffer size:  129131
Time Taken :  958.0  mins 53.7784903049469  seconds
[[[    0.     0.     0.     0.   144.   185.   218.   205.   125.   114.
      52.     6.    12.    38.    25.     0.     0.     0.     1.     3.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   395.  2332.  2424.  2827.  1585.  1455.  2020.
     427.   185.  1571.  2288.   145.     0.     3.    14.    66.    27.
      23.     2.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3464.  4698.  2841.  2527.  1549.   629.   141.  1475.
     892.  1016.  2019.   244.    34.   149.   615.   235.    38.   222.
     130.    12.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15112.  9061.  2421.  2480.  3127.  3206.  3151.  3252.  3786.
    4089.  2198.  2322.   345.   328.   734.   870.  1130.   975.   747.
      80.    92.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   534.   810.   286.   167.     0.     0.     0.     0.
       0.   150.  2062.  2256.  1035.   918.  3080.   151.     0.   332.
      93.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    64.    53.    34.    23.    19.    11.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7872000000000001
Q value #end_state_>_threshold:  1765
Q value #non_end_state_>threshold:  5358
maxi score:  -0.1999400000000001
siam score:  -0.7402427
Scores:  {'0.167': -0.64634, '0.333': -0.8087, '0.5': -0.8314400000000001, '0.667': -0.8830600000000001, '0.833': -0.89014, '1.0': -0.94518}
best rdn ma / adv:  1 0.167
best rdn adv:  0.006796539761008333
Episodes: 7383, frames: 130047, time: 61760.35712814331
training steps:  15579
retraining steps:  0
RDN obj mus: [-0.9457866777300835, -0.9440795338213444, -0.9346075028538704, -0.9284016545236111, -0.9111759875476361]
RDN obj sigmas: [0.022607591436169715, 0.02958857940338547, 0.03094470777548472, 0.03043050758419056, 0.030448735569491406]
7383 : -0.5956666666666666
LR:  0.001
replay buffer size:  139509
Time Taken :  1029.0  mins 20.35687518119812  seconds
[[[    0.     0.     0.     0.   160.   202.   237.   218.   138.   124.
      55.     6.    12.    39.    25.     0.     0.     0.     2.     3.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   436.  2506.  2564.  3146.  1710.  1681.  2135.
     461.   189.  1593.  2320.   148.     0.     5.    15.    75.    61.
      35.     2.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3567.  5119.  2979.  2763.  1652.   690.   150.  1674.
     998.  1121.  2044.   267.    37.   167.   711.   284.    56.   294.
     182.    18.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15596.  9844.  2523.  2634.  3175.  3267.  3228.  3319.  3870.
    4317.  2414.  2506.   371.   549.   889.  1234.  1624.  1428.   995.
     114.   112.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   610.   884.   309.   200.     0.     0.     0.     0.
       0.   163.  2385.  2482.  1184.  1071.  3219.   165.     0.   532.
     139.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    70.    61.    37.    33.    23.    11.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7896000000000001
Q value #end_state_>_threshold:  2488
Q value #non_end_state_>threshold:  6872
maxi score:  -0.08392000000000005
siam score:  -0.74605185
Scores:  {'0.167': -0.5645400000000002, '0.333': -0.77114, '0.5': -0.7875800000000001, '0.667': -0.87016, '0.833': -0.8742399999999999, '1.0': -0.94478}
best rdn ma / adv:  1 0.167
best rdn adv:  0.008299797161609827
Episodes: 7970, frames: 140043, time: 66107.19464421272
training steps:  16805
retraining steps:  0
RDN obj mus: [-0.9456574877977372, -0.9510111556112766, -0.9444091944813728, -0.9357209706842899, -0.937608655500412]
RDN obj sigmas: [0.021474707778106342, 0.022809295336897226, 0.023398394284903968, 0.026564578253920067, 0.017578588808828146]
7970 : -0.5304166666666668
LR:  0.001
replay buffer size:  149906
Time Taken :  1101.0  mins 47.19439625740051  seconds
[[[    0.     0.     0.     0.   168.   213.   256.   230.   148.   132.
      62.     6.    13.    43.    25.     0.     0.     0.     2.     4.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   466.  2641.  2656.  3415.  1819.  1899.  2269.
     490.   196.  1621.  2331.   150.     0.     9.    17.    81.    67.
      46.     3.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3604.  5473.  3078.  2965.  1733.   716.   166.  1854.
    1080.  1262.  2118.   279.    39.   229.   962.   336.    78.   366.
     239.    22.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 16007. 10467.  2598.  2738.  3249.  3340.  3298.  3398.  3968.
    4500.  2588.  2655.   386.   823.  1171.  1953.  2080.  1931.  1241.
     147.   135.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   666.   943.   319.   209.     0.     0.     0.     0.
       0.   166.  2775.  2723.  1388.  1277.  3555.   185.     0.   679.
     178.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    72.    63.    42.    39.    27.    16.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.8068000000000001
Q value #end_state_>_threshold:  3349
Q value #non_end_state_>threshold:  8241
maxi score:  -0.02280000000000005
siam score:  -0.7233754
Scores:  {'0.167': -0.46738, '0.333': -0.70642, '0.5': -0.74978, '0.667': -0.8479800000000001, '0.833': -0.88212, '1.0': -0.94284}
best rdn ma / adv:  1 0.167
best rdn adv:  0.011618994886274084
Episodes: 8653, frames: 150083, time: 70639.58887600899
training steps:  18057
retraining steps:  0
RDN obj mus: [-0.9486800290346146, -0.9513243218362332, -0.9459934655189515, -0.9376793205618859, -0.9303627303659916]
RDN obj sigmas: [0.017351105371103234, 0.020321625144369793, 0.020984287698406275, 0.025087688146615734, 0.02058975729547809]
8653 : -0.48125000000000007
LR:  0.001
replay buffer size:  160360
Time Taken :  1177.0  mins 19.588632106781006  seconds
[[[    0.     0.     0.     0.   177.   225.   269.   251.   156.   145.
      64.     7.    14.    45.    25.     0.     0.     0.     2.     6.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   495.  2768.  2739.  3722.  1926.  2141.  2376.
     512.   200.  1635.  2350.   152.     0.    14.    18.   110.    94.
      60.     4.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3662.  5863.  3172.  3207.  1776.   744.   183.  2079.
    1171.  1399.  2157.   295.    41.   260.  1086.   427.   100.   494.
     295.    29.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 16526. 11189.  2689.  2859.  3323.  3430.  3387.  3487.  4077.
    4729.  2806.  2822.   412.   984.  1468.  2382.  2623.  2342.  1545.
     190.   158.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   740.  1031.   334.   226.     0.     0.     0.     0.
       0.   178.  3085.  2969.  1557.  1455.  3808.   204.     0.   763.
     222.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    75.    70.    43.    43.    35.    19.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.8008
Q value #end_state_>_threshold:  4172
Q value #non_end_state_>threshold:  9746
maxi score:  -0.008140000000000047
siam score:  -0.7412663
Scores:  {'0.167': -0.39458000000000004, '0.333': -0.6260600000000001, '0.5': -0.71746, '0.667': -0.82998, '0.833': -0.8689, '1.0': -0.93518}
best rdn ma / adv:  1 0.167
best rdn adv:  0.006048103283563586
Episodes: 9158, frames: 160055, time: 75111.70960497856
training steps:  19290
retraining steps:  0
RDN obj mus: [-0.9482322957396507, -0.9479365026712417, -0.9432366351246834, -0.9383312364041805, -0.930307763338089]
RDN obj sigmas: [0.020675678699483696, 0.023277870008007042, 0.021815452415630487, 0.024250003609580427, 0.020579114764142568]
9158 : -0.42550000000000004
LR:  0.001
replay buffer size:  170747
Time Taken :  1251.0  mins 51.709360122680664  seconds
[[[    0.     0.     0.     0.   187.   229.   279.   263.   165.   151.
      65.     7.    16.    47.    25.     0.     0.     0.     2.     6.
       4.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   520.  2899.  2797.  3980.  2024.  2350.  2488.
     540.   222.  1650.  2356.   154.     0.    16.    20.   137.    99.
      72.     4.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3701.  6161.  3256.  3402.  1827.   773.   196.  2268.
    1256.  1522.  2170.   308.    42.   319.  1244.   478.   122.   623.
     341.    34.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 16924. 11719.  2760.  2969.  3368.  3483.  3458.  3551.  4168.
    4913.  2966.  2996.   428.  1387.  2178.  3151.  3027.  2736.  1931.
     228.   170.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   768.  1073.   350.   238.     0.     0.     0.     0.
       0.   180.  3387.  3406.  1815.  1581.  4067.   220.     0.   919.
     261.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    76.    72.    48.    47.    41.    20.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.79
Q value #end_state_>_threshold:  5046
Q value #non_end_state_>threshold:  11482
maxi score:  -0.017760000000000043
siam score:  -0.730153
Scores:  {'0.167': -0.33082000000000006, '0.333': -0.5775000000000001, '0.5': -0.6844, '0.667': -0.8048200000000001, '0.833': -0.8521000000000001, '1.0': -0.9280200000000001}
best rdn ma / adv:  1 0.167
best rdn adv:  0.009721994219710858
Episodes: 9711, frames: 170062, time: 79461.10731697083
training steps:  20532
retraining steps:  0
RDN obj mus: [-0.9450162749767304, -0.9541881664276123, -0.9477528823137283, -0.9382064828693867, -0.9298408410668373]
RDN obj sigmas: [0.019347140824479525, 0.022631305925990358, 0.025791127140189576, 0.025917303383473794, 0.030884743520067006]
9711 : -0.4874166666666667
LR:  0.001
replay buffer size:  181160
Time Taken :  1324.0  mins 21.107078313827515  seconds
[[[    0.     0.     0.     0.   199.   232.   293.   282.   171.   157.
      66.     8.    18.    48.    27.     0.     0.     0.     2.     7.
       5.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   547.  3028.  2896.  4255.  2136.  2557.  2586.
     552.   227.  1670.  2364.   156.     0.    16.    26.   151.   168.
      89.     4.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3743.  6465.  3349.  3609.  1885.   808.   205.  2475.
    1374.  1662.  2280.   319.    45.   385.  1340.   534.   142.   787.
     378.    44.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17288. 12305.  2845.  3055.  3400.  3533.  3504.  3600.  4226.
    5041.  3145.  3197.   458.  1731.  2941.  3965.  3351.  3084.  2304.
     278.   182.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   831.  1120.   362.   244.     0.     0.     0.     0.
       0.   182.  3629.  3700.  2025.  1867.  4333.   236.     0.   997.
     294.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    81.    78.    51.    52.    43.    21.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7892000000000001
Q value #end_state_>_threshold:  6056
Q value #non_end_state_>threshold:  13390
maxi score:  -0.017240000000000047
siam score:  -0.7167492
Scores:  {'0.167': -0.24928000000000006, '0.333': -0.5130800000000001, '0.5': -0.64866, '0.667': -0.7738400000000001, '0.833': -0.83826, '1.0': -0.9073200000000001}
best rdn ma / adv:  1 0.167
best rdn adv:  0.019590709144909433
Episodes: 10310, frames: 180080, time: 86112.4589779377
training steps:  21832
retraining steps:  0
RDN obj mus: [-0.9495284167289734, -0.9507364456892013, -0.9444683100700378, -0.9395260300278664, -0.935937884491682]
RDN obj sigmas: [0.019178236507399693, 0.02177079741515653, 0.0236722827492333, 0.02548384409202292, 0.022361500063329615]
10310 : -0.5003333333333334
LR:  0.001
replay buffer size:  191580
Time Taken :  1435.0  mins 12.4587881565094  seconds
[[[    0.     0.     0.     0.   208.   240.   307.   301.   179.   164.
      71.     8.    19.    50.    28.     0.     0.     0.     2.     8.
       5.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   579.  3202.  2999.  4553.  2294.  2768.  2782.
     573.   232.  1713.  2373.   163.     0.    17.    27.   179.   206.
     112.     7.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3782.  6847.  3464.  3820.  1948.   849.   216.  2697.
    1537.  1809.  2325.   333.    46.   442.  1527.   655.   194.  1016.
     441.    58.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17701. 12932.  2950.  3156.  3429.  3570.  3546.  3641.  4288.
    5239.  3352.  3389.   490.  1987.  3389.  4636.  3644.  3491.  2641.
     315.   197.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   871.  1165.   369.   264.     0.     0.     0.     0.
       0.   184.  3826.  4024.  2194.  2014.  4468.   254.     0.  1096.
     325.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    85.    87.    54.    59.    49.    24.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.814
Q value #end_state_>_threshold:  6871
Q value #non_end_state_>threshold:  14898
maxi score:  -0.04192000000000004
siam score:  -0.7083906
Scores:  {'0.167': -0.2199200000000001, '0.333': -0.48578, '0.5': -0.62612, '0.667': -0.76954, '0.833': -0.8452, '1.0': -0.90592}
best rdn ma / adv:  1 0.167
best rdn adv:  0.026259795853586156
Episodes: 10885, frames: 190098, time: 92403.59925699234
training steps:  23084
retraining steps:  0
RDN obj mus: [-0.9488158506989479, -0.9580573960244656, -0.9527516812801361, -0.9451504543662071, -0.9329720233798027]
RDN obj sigmas: [0.02156249921787443, 0.01929061715230773, 0.02106419480880185, 0.023424726558929694, 0.02342214561472094]
10885 : -0.6304166666666667
LR:  0.001
replay buffer size:  200421
Time Taken :  1540.0  mins 3.5990171432495117  seconds
[[[    0.     0.     0.     0.   223.   249.   317.   313.   192.   171.
      72.     8.    20.    52.    29.     0.     0.     0.     2.     9.
       6.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   614.  3391.  3062.  4836.  2430.  2977.  2899.
     601.   256.  1719.  2394.   167.     0.    19.    30.   206.   340.
     129.     7.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3848.  7229.  3549.  4002.  2004.   889.   229.  2911.
    1670.  1915.  2349.   347.    47.   510.  1816.   774.   236.  1233.
     502.    66.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 18003. 13524.  3011.  3231.  3469.  3635.  3595.  3686.  4366.
    5451.  3562.  3576.   506.  2446.  3723.  5210.  3966.  3832.  2776.
     344.   207.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   912.  1218.   379.   273.     0.     0.     0.     0.
       0.   185.  4159.  4560.  2640.  2112.  4616.   276.     0.  1157.
     351.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    88.    94.    57.    65.    57.    29.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.8160000000000001
Q value #end_state_>_threshold:  7646
Q value #non_end_state_>threshold:  16471
maxi score:  0.05165999999999996
siam score:  -0.6879024
Scores:  {'0.167': -0.20980000000000007, '0.333': -0.4769400000000001, '0.5': -0.6201000000000001, '0.667': -0.7586800000000001, '0.833': -0.8374600000000001, '1.0': -0.91894}
best rdn ma / adv:  1 0.167
best rdn adv:  0.01477384570192614
Episodes: 11464, frames: 200048, time: 99815.04149913788
training steps:  24305
retraining steps:  0
RDN obj mus: [-0.9451513733446598, -0.9519819046258926, -0.9476798360645771, -0.9446595682680606, -0.9337109717309475]
RDN obj sigmas: [0.019324729232519024, 0.01934091405124247, 0.020183262568068676, 0.02151897873101037, 0.021925964677958553]
11464 : -0.5456666666666667
LR:  0.001
replay buffer size:  200025
Time Taken :  1663.0  mins 35.04126000404358  seconds
[[[    0.     0.     0.     0.   233.   256.   325.   325.   206.   188.
      75.     9.    20.    53.    29.     0.     0.     0.     2.    10.
       6.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   646.  3561.  3171.  5101.  2591.  3191.  3041.
     624.   261.  1732.  2412.   173.     0.    19.    36.   219.   529.
     154.    10.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3909.  7581.  3684.  4179.  2067.   922.   241.  3155.
    1861.  2023.  2362.   355.    48.   590.  1953.   848.   287.  1402.
     562.    71.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 18299. 14132.  3094.  3319.  3494.  3660.  3626.  3711.  4419.
    5663.  3793.  3784.   531.  2633.  4085.  5713.  4299.  4192.  3066.
     384.   223.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   955.  1266.   388.   283.     0.     0.     0.     0.
       0.   193.  4501.  5191.  3020.  2297.  4773.   292.     0.  1199.
     371.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    94.   101.    66.    75.    61.    30.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.8179999999999998
Q value #end_state_>_threshold:  8448
Q value #non_end_state_>threshold:  17895
maxi score:  0.07373999999999996
siam score:  -0.69948
Scores:  {'0.167': -0.20998000000000008, '0.333': -0.47412000000000004, '0.5': -0.6357800000000001, '0.667': -0.7350200000000001, '0.833': -0.82956, '1.0': -0.91504}
best rdn ma / adv:  1 0.167
best rdn adv:  0.016004215247500918
Episodes: 11964, frames: 210038, time: 106988.11684203148
training steps:  25497
retraining steps:  0
RDN obj mus: [-0.9415605248451233, -0.9542653678834438, -0.9527014786362648, -0.9458834494650364, -0.9415473983764648]
RDN obj sigmas: [0.026199718688819634, 0.023792129607481383, 0.022164458258654023, 0.02277654913719241, 0.022542587408560945]
11964 : -0.4951666666666667
LR:  0.001
replay buffer size:  200147
Time Taken :  1783.0  mins 8.116591215133667  seconds
[[[    0.     0.     0.     0.   237.   265.   329.   338.   210.   196.
      84.     9.    24.    56.    29.     0.     0.     0.     3.    12.
       7.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   660.  3714.  3289.  5359.  2763.  3381.  3195.
     645.   272.  1785.  2435.   179.     0.    21.    41.   235.   584.
     168.    14.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3972.  7908.  3805.  4348.  2142.   958.   250.  3408.
    2016.  2121.  2379.   361.    51.   646.  2209.   926.   348.  1519.
     632.    76.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 18577. 14660.  3178.  3402.  3523.  3700.  3686.  3765.  4523.
    5943.  4017.  3954.   559.  2910.  4662.  6090.  4570.  4587.  3211.
     409.   238.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   983.  1300.   397.   293.     0.     0.     0.     0.
       0.   196.  4925.  5854.  3500.  2531.  4935.   301.     0.  1223.
     396.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    97.   109.    73.    82.    68.    33.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.8319999999999999
Q value #end_state_>_threshold:  9294
Q value #non_end_state_>threshold:  19213
maxi score:  0.07139999999999996
siam score:  -0.6824013
Scores:  {'0.167': -0.21452000000000007, '0.333': -0.4630600000000001, '0.5': -0.6289600000000002, '0.667': -0.7487800000000001, '0.833': -0.82408, '1.0': -0.9155599999999999}
best rdn ma / adv:  1 0.167
best rdn adv:  0.015923763620608173
Episodes: 12490, frames: 220053, time: 114359.6931040287
training steps:  26692
retraining steps:  0
RDN obj mus: [-0.9549804540276527, -0.9608763824284077, -0.9552463285326958, -0.9454308719456196, -0.9356347131192684]
RDN obj sigmas: [0.016705815104411194, 0.019344283756597847, 0.022561735095666786, 0.025874476802178824, 0.027834943901709052]
12490 : -0.5999166666666668
LR:  0.001
replay buffer size:  200396
Time Taken :  1905.0  mins 59.692893981933594  seconds
[[[    0.     0.     0.     0.   240.   273.   341.   348.   222.   209.
      93.     9.    27.    56.    30.     0.     0.     0.     3.    12.
       7.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   685.  3859.  3406.  5602.  2956.  3606.  3357.
     676.   287.  1811.  2444.   183.     0.    23.    51.   267.   696.
     191.    18.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  4037.  8221.  3951.  4509.  2213.   985.   261.  3614.
    2182.  2215.  2402.   376.    54.   711.  2392.  1006.   397.  1663.
     681.    82.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 18955. 15237.  3283.  3497.  3574.  3754.  3767.  3843.  4618.
    6231.  4252.  4145.   574.  3158.  5105.  6553.  5013.  4978.  3390.
     443.   255.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  1013.  1331.   410.   302.     0.     0.     0.     0.
       0.   203.  5203.  6437.  3864.  2760.  4984.   310.     0.  1271.
     414.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.   101.   122.    81.    87.    71.    34.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.8327999999999999
Q value #end_state_>_threshold:  10232
Q value #non_end_state_>threshold:  20534
maxi score:  0.10479999999999995
siam score:  -0.67825663
Scores:  {'0.167': -0.23912000000000005, '0.333': -0.43678000000000006, '0.5': -0.62136, '0.667': -0.75926, '0.833': -0.8138200000000001, '1.0': -0.91188}
best rdn ma / adv:  1 0.167
best rdn adv:  0.005963647440447492
Episodes: 12990, frames: 230143, time: 122052.79455113411
training steps:  27901
retraining steps:  0
RDN obj mus: [-0.9298061377704143, -0.9602548500180245, -0.9523305758297443, -0.9278245032668113, -0.9423737494051456]
RDN obj sigmas: [0.0679368797108668, 0.019537432974653778, 0.022181860519729306, 0.0629806915843696, 0.017324179489617467]
12990 : -0.47125000000000006
LR:  0.001
replay buffer size:  200128
Time Taken :  2034.0  mins 12.794317245483398  seconds
[[[    0.     0.     0.     0.   244.   279.   344.   362.   230.   218.
      98.     9.    27.    57.    31.     0.     0.     0.     4.    15.
      10.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   699.  3995.  3541.  5831.  3165.  3799.  3509.
     701.   302.  1853.  2571.   190.     0.    26.    56.   316.   839.
     216.    21.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  4092.  8539.  4101.  4673.  2303.  1021.   279.  3824.
    2329.  2322.  2418.   382.    59.   754.  2535.  1130.   468.  1772.
     734.    93.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 19187. 15758.  3371.  3595.  3619.  3807.  3842.  3911.  4731.
    6460.  4490.  4345.   597.  3469.  5847.  6749.  5230.  5328.  3514.
     469.   273.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  1039.  1358.   420.   310.     0.     0.     0.     0.
       0.   211.  5476.  7262.  4417.  2923.  5124.   325.     0.  1353.
     436.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.   102.   129.    86.    94.    71.    39.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
