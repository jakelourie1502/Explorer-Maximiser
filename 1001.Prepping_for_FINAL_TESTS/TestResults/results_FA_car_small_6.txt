EVALUATIONS AND MAIN RESULTS
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.967641935483871
siam score:  -0.002291657844103784
Scores:  {'0.167': -0.8749, '0.333': -0.8749, '0.5': -0.7999, '0.667': -0.8570428571428571, '0.833': -0.4999, '1.0': -0.8999}
best rdn ma / adv:  1 0.167
best rdn adv:  0.0
Episodes: 40, frames: 864, time: 62.00209307670593
training steps:  5
retraining steps:  0
RDN obj mus: [-0.06372619214121852, -0.15477125428374172, -0.12438042036124639, 0.0, 0.0]
RDN obj sigmas: [0.017550379144365236, 0.00618223541210507, 0.05089332767662591, 0.0, 0.0]
40 : -1.0
LR:  4e-06
replay buffer size:  1503
Time Taken :  1.0  mins 2.00179123878479  seconds
[[[  0.   0.   0.   0.   2.   3.   1.   0.   1.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   3.   6.   1.  27.   3.   1.   2.   1.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  45.  14.   9.   9.   2.   3.   1.   0.   0.   0.   1.   1.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0. 263.  83.  35.  46.  75.  73.  50.  17.  21.   4.   3.   0.   1.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   4.   4.   3.   4.   0.   0.   0.   0.   0.   0.   1.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9892617021276596
siam score:  -0.8155046
Scores:  {'0.167': -0.9749, '0.333': -0.9823561403508771, '0.5': -0.9665666666666667, '0.667': -0.9760904761904762, '0.833': -0.9794918367346939, '1.0': -0.9704882352941177}
best rdn ma / adv:  1 0.5
best rdn adv:  0.24070822888714155
Episodes: 300, frames: 10618, time: 5614.610218048096
training steps:  1310
retraining steps:  0
RDN obj mus: [-0.936206978982687, -0.9435411236047745, -0.9427648720264434, -0.9025026986891518, -0.9123569469262914]
RDN obj sigmas: [0.018892924489914278, 0.01861891354245524, 0.023218191087867927, 0.04427796875029646, 0.040060483250782125]
300 : -1.0
LR:  0.001
replay buffer size:  13501
Time Taken :  93.0  mins 34.60988211631775  seconds
[[[   0.    0.    0.    0.    2.   10.   15.    7.    5.    3.    0.
      0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   12.  174.  140.  164.   59.   26.   62.    6.
     16.    6.    2.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  608.  558.  267.  217.  198.   26.    4.    9.   19.
     20.   23.    5.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 3186. 1165.  671.  252.  537.  609.  420.  260.  209.  116.
     52.   31.    9.    6.    2.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   26.   40.   21.   14.    0.    0.    0.    0.    0.
      4.    6.    1.    2.    6.    4.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    1.    1.    0.    0.    0.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9949738916256158
siam score:  -0.87297493
Scores:  {'0.167': -0.9881352941176471, '0.333': -0.9905542056074766, '0.5': -0.9885363636363637, '0.667': -0.9892617021276596, '0.833': -0.9903761904761905, '1.0': -0.9879952380952381}
best rdn ma / adv:  1 1.0
best rdn adv:  0.08753420607825332
Episodes: 691, frames: 20541, time: 10820.101452112198
training steps:  2540
retraining steps:  0
RDN obj mus: [-0.9369485434472561, -0.9530432318031787, -0.9362273514330387, -0.9169565416157246, -0.9017501449593661]
RDN obj sigmas: [0.023052563240305336, 0.020248297287426522, 0.028185916201284116, 0.030060305349268658, 0.03857200434131673]
691 : -1.0
LR:  0.001
replay buffer size:  24479
Time Taken :  180.0  mins 20.10114026069641  seconds
[[[   0.    0.    0.    0.    5.   24.   37.   24.   17.    9.    9.
      0.    2.    1.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   50.  526.  573.  623.  340.  303.  268.   51.
     30.  212.   76.    8.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1168. 1117.  698.  523.  461.   95.   14.   53.   49.
    125.   92.   16.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 4601. 1995. 1118.  478.  770.  850.  678.  528.  486.  321.
    128.   45.   25.    6.    2.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   42.   65.   29.   25.    0.    0.    0.    0.    0.
      7.   16.    4.    4.    7.    5.    3.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    5.    4.    1.    0.    0.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9968879518072289
siam score:  -0.83555704
Scores:  {'0.167': -0.9870518987341772, '0.333': -0.9862030303030304, '0.5': -0.9682647798742139, '0.667': -0.9781456140350877, '0.833': -0.9700169590643274, '1.0': -0.9736499999999999}
best rdn ma / adv:  1 1.0
best rdn adv:  0.5791869859447893
Episodes: 1204, frames: 30283, time: 15755.22774720192
training steps:  3666
retraining steps:  0
RDN obj mus: [-0.948912839204073, -0.9609182750701905, -0.9587414529919625, -0.9220657554268837, -0.9044449436068535]
RDN obj sigmas: [0.022473080453209254, 0.021407604959161764, 0.02536849575390918, 0.034508027431351285, 0.043180830463843585]
1204 : -0.9514166666666667
LR:  0.001
replay buffer size:  35576
Time Taken :  262.0  mins 35.22741508483887  seconds
[[[   0.    0.    0.    0.   17.   34.   64.   56.   34.   21.   11.
      0.    3.    3.    7.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   79.  778.  909.  977.  537.  443.  333.   85.
     49.  357.  120.   30.    0.    0.    2.    2.    0.    2.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1461. 1562.  987.  740.  656.  153.   30.  143.  206.
    251.  209.   48.    2.   10.   10.    3.    1.   24.    2.    1.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 5881. 2775. 1408.  678.  994. 1073.  948.  818.  797.  734.
    410.  141.   56.   23.   23.   11.   25.   16.   10.    2.    4.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   74.  102.   47.   35.    0.    0.    0.    0.    0.
     19.  199.  117.  107.   52.   14.    9.    0.    0.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   10.    8.    4.    1.    0.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -0.5944000000000002
Q value #end_state_>_threshold:  35
Q value #non_end_state_>threshold:  57
maxi score:  -0.9717625277161863
siam score:  -0.8152446
Scores:  {'0.167': -0.9607837209302326, '0.333': -0.9494258620689656, '0.5': -0.9448047619047619, '0.667': -0.9502703703703704, '0.833': -0.9455306306306307, '1.0': -0.9366179487179487}
best rdn ma / adv:  1 0.333
best rdn adv:  1.2516136683218653
Episodes: 1614, frames: 40465, time: 21888.903929948807
training steps:  5037
retraining steps:  0
RDN obj mus: [-0.94850934638381, -0.9579013231277466, -0.940508713388443, -0.9188632587969303, -0.8980145012795925]
RDN obj sigmas: [0.020945732309325258, 0.024141469723058133, 0.03086467857608303, 0.03346124918422234, 0.039622070786411646]
1614 : -0.8238333333333333
LR:  0.001
replay buffer size:  47147
Time Taken :  364.0  mins 48.90359902381897  seconds
[[[   0.    0.    0.    0.   19.   37.   71.   68.   44.   27.   12.
      0.    3.    6.   11.    0.    0.    0.    0.    1.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   93.  964. 1181. 1167.  670.  558.  513.  112.
     61.  622.  249.   48.    0.    0.    9.    3.    8.    5.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1709. 1879. 1287.  945.  823.  209.   40.  248.  278.
    350.  297.   71.    9.   67.   96.   27.   16.   47.   17.    3.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 6781. 3389. 1608.  827. 1371. 1380. 1228. 1173. 1158. 1308.
    693.  356.   91.  114.  187.   64.  150.  129.   36.    7.    9.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   83.  120.   53.   43.    0.    0.    0.    0.    0.
     31.  403.  396.  357.  218.   33.   18.    0.    4.    5.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   16.   19.    8.    2.    1.    2.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.5711999999999999
Q value #end_state_>_threshold:  449
Q value #non_end_state_>threshold:  822
maxi score:  -0.8758600000000001
siam score:  -0.7779001
Scores:  {'0.167': -0.9129824372759857, '0.333': -0.9004119453924916, '0.5': -0.8925966292134833, '0.667': -0.9128520295202953, '0.833': -0.8666229729729729, '1.0': -0.90398}
best rdn ma / adv:  1 0.833
best rdn adv:  0.9510156329243965
Episodes: 2079, frames: 50180, time: 26081.14090514183
training steps:  5954
retraining steps:  0
RDN obj mus: [-0.9388596539735794, -0.9329620164573192, -0.930154101395607, -0.9202517648756504, -0.9037089826822281]
RDN obj sigmas: [0.028033766170107596, 0.026611435623233308, 0.026454755078326515, 0.028812388441770607, 0.03492015062378333]
2079 : -0.6679166666666667
LR:  0.001
replay buffer size:  57421
Time Taken :  434.0  mins 41.14057016372681  seconds
[[[   0.    0.    0.    0.   27.   54.   79.   83.   46.   33.   14.
      0.    4.    9.   17.    0.    0.    0.    3.    1.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  114. 1085. 1319. 1345.  797.  655.  617.  129.
     79.  754.  371.   69.    0.    1.   14.   26.   14.   11.    5.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1868. 2196. 1466. 1132.  934.  249.   49.  461.  428.
    452.  433.   89.   14.  119.  152.   63.   33.   68.   42.    9.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 7628. 4040. 1818. 1030. 1603. 1618. 1488. 1472. 1580. 1763.
    945.  746.  135.  231.  303.  139.  280.  282.   92.   25.   20.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  101.  148.   64.   46.    0.    0.    0.    0.    0.
     46.  709.  614.  518.  342.  105.   31.    0.   19.   13.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   24.   27.   11.    6.    4.    3.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.6831999999999999
Q value #end_state_>_threshold:  1185
Q value #non_end_state_>threshold:  1674
maxi score:  -0.6654800000000001
siam score:  -0.7262851
Scores:  {'0.167': -0.8764428571428571, '0.333': -0.8561500000000001, '0.5': -0.8495438356164384, '0.667': -0.8990620111731843, '0.833': -0.8701116402116402, '1.0': -0.8788489489489489}
best rdn ma / adv:  1 0.5
best rdn adv:  0.021204786775320453
Episodes: 2728, frames: 60134, time: 31653.90264725685
training steps:  7250
retraining steps:  0
RDN obj mus: [-0.947547416907549, -0.9394152820885181, -0.9239386624217033, -0.921770609664917, -0.915356211644411]
RDN obj sigmas: [0.02384958896847491, 0.030204513817751886, 0.031697275334199186, 0.028296527852047098, 0.027854393642282607]
2728 : -0.6850833333333334
LR:  0.001
replay buffer size:  67858
Time Taken :  527.0  mins 33.90232229232788  seconds
[[[   0.    0.    0.    0.   42.   71.   99.  107.   66.   50.   18.
      3.    6.   13.   22.    0.    0.    0.    3.    3.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  143. 1220. 1489. 1563.  947.  798.  757.  161.
     89.  764.  394.   79.    0.    6.   19.   41.   22.   21.    8.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1973. 2607. 1678. 1359. 1080.  306.   55.  574.  542.
    549.  555.  109.   16.  239.  259.  115.   63.   94.   77.   18.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 8198. 4776. 2019. 1230. 1857. 1911. 1824. 1807. 1914. 2146.
   1238.  928.  173.  317.  438.  227.  406.  437.  180.   43.   48.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  155.  182.   86.   60.    0.    0.    0.    0.    0.
     55.  983.  799.  752.  432.  279.   54.    0.   25.   26.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   32.   35.   19.   10.    8.    5.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.6947999999999999
Q value #end_state_>_threshold:  2365
Q value #non_end_state_>threshold:  2975
maxi score:  -0.3644400000000001
siam score:  -0.72971374
Scores:  {'0.167': -0.8121297297297297, '0.333': -0.8203612159329141, '0.5': -0.8329585683297179, '0.667': -0.884291891891892, '0.833': -0.8698365750528542, '1.0': -0.8736442922374429}
best rdn ma / adv:  1 0.333
best rdn adv:  0.017961656720733195
Episodes: 3451, frames: 70063, time: 37512.02200102806
training steps:  8586
retraining steps:  0
RDN obj mus: [-0.9538898217856884, -0.9525462640762329, -0.9419124531388283, -0.9338485484957695, -0.9261796058833599]
RDN obj sigmas: [0.020138437484180458, 0.024931809124511498, 0.023633661564529444, 0.024190528801084226, 0.022214823409889256]
3451 : -0.5941666666666667
LR:  0.001
replay buffer size:  78241
Time Taken :  625.0  mins 12.02167010307312  seconds
[[[   0.    0.    0.    0.   57.   79.  111.  145.   90.   72.   30.
      5.    6.   19.   29.    0.    0.    0.    5.    5.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  170. 1421. 1706. 1815. 1156.  961.  913.  214.
     96.  800.  443.   91.    0.    6.   26.   59.   41.   38.   12.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 2064. 3000. 1907. 1571. 1191.  363.   68.  713.  674.
    640.  617.  121.   21.  289.  394.  184.  107.  132.  127.   22.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 8735. 5550. 2187. 1425. 2097. 2200. 2110. 2064. 2166. 2471.
   1522. 1163.  208.  396.  577.  359.  573.  603.  316.   81.   76.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  214.  236.   98.   75.    0.    0.    0.    0.    0.
     59. 1151.  983.  907.  550.  318.   68.    0.   60.   44.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   37.   42.   26.   18.   13.    7.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.7663999999999999
Q value #end_state_>_threshold:  3661
Q value #non_end_state_>threshold:  4329
maxi score:  -0.1671000000000001
siam score:  -0.73942804
Scores:  {'0.167': -0.70964, '0.333': -0.77034, '0.5': -0.79634, '0.667': -0.8524, '0.833': -0.84342, '1.0': -0.85862}
best rdn ma / adv:  1 0.167
best rdn adv:  0.024262691714605742
Episodes: 4146, frames: 80058, time: 41713.18574285507
training steps:  9840
retraining steps:  0
RDN obj mus: [-0.9486393827319145, -0.9459470897197724, -0.9394022374153137, -0.932063161277771, -0.9241214908123017]
RDN obj sigmas: [0.02300714924399008, 0.024199881214369237, 0.024985251129857965, 0.026715018030544223, 0.027224976988981252]
4146 : -0.6746666666666667
LR:  0.001
replay buffer size:  88645
Time Taken :  695.0  mins 13.185410022735596  seconds
[[[   0.    0.    0.    0.   61.   91.  128.  183.  109.   94.   31.
      6.    7.   28.   32.    0.    0.    0.    5.    5.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  197. 1568. 1922. 2085. 1363. 1124. 1081.  259.
    127.  838.  474.  111.    0.    9.   30.   79.   61.   49.   18.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 2210. 3359. 2130. 1818. 1304.  420.   80.  873.  874.
    728.  702.  140.   22.  344.  494.  239.  151.  172.  184.   31.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 9190. 6305. 2344. 1634. 2287. 2413. 2371. 2273. 2404. 2818.
   1837. 1335.  242.  474.  704.  486.  782.  837.  460.  114.  112.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  257.  278.  110.   83.    0.    0.    0.    0.    0.
     75. 1435. 1185. 1086.  695.  422.   80.    0.   85.   73.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   42.   49.   33.   23.   17.   11.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.7143999999999999
Q value #end_state_>_threshold:  4928
Q value #non_end_state_>threshold:  5978
maxi score:  -0.036680000000000115
siam score:  -0.7243089
Scores:  {'0.167': -0.5560200000000001, '0.333': -0.7047800000000001, '0.5': -0.7447400000000001, '0.667': -0.80176, '0.833': -0.8286, '1.0': -0.84754}
best rdn ma / adv:  1 0.167
best rdn adv:  0.018201676883693382
Episodes: 4857, frames: 90076, time: 45884.20914101601
training steps:  11088
retraining steps:  0
RDN obj mus: [-0.9508169219553471, -0.9492075202524662, -0.9440400576233864, -0.9376414033651352, -0.9322360007286071]
RDN obj sigmas: [0.019981561829873255, 0.02125847991840216, 0.022515410352213345, 0.02432317576366766, 0.025023708646526626]
4857 : -0.35450000000000004
LR:  0.001
replay buffer size:  99094
Time Taken :  764.0  mins 44.20882201194763  seconds
[[[   0.    0.    0.    0.   70.  107.  149.  209.  131.  109.   38.
      6.    8.   36.   34.    0.    0.    0.    5.    6.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  222. 1761. 2150. 2364. 1601. 1289. 1270.  312.
    150.  902.  525.  124.    0.   11.   36.   90.   89.   66.   27.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 2301. 3737. 2360. 2072. 1412.  490.   98. 1044. 1069.
    779.  783.  156.   23.  394.  640.  304.  217.  249.  248.   38.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 9717. 7066. 2501. 1830. 2509. 2640. 2622. 2478. 2646. 3102.
   2194. 1520.  274.  539.  853.  603.  989. 1023.  595.  142.  156.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  300.  319.  122.   92.    0.    0.    0.    0.    0.
     87. 1657. 1337. 1247.  775.  488.   96.    0.   95.   96.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   44.   61.   38.   25.   18.   11.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.7239999999999999
Q value #end_state_>_threshold:  6264
Q value #non_end_state_>threshold:  8262
maxi score:  0.0180799999999999
siam score:  -0.74280185
Scores:  {'0.167': -0.46622, '0.333': -0.62744, '0.5': -0.71514, '0.667': -0.7515400000000001, '0.833': -0.81538, '1.0': -0.84602}
best rdn ma / adv:  1 0.167
best rdn adv:  0.04711192419247561
Episodes: 5491, frames: 100093, time: 50130.29233002663
training steps:  12330
retraining steps:  0
RDN obj mus: [-0.948295756471157, -0.9505555913090706, -0.9475207547664642, -0.9437982452690601, -0.9404658661782741]
RDN obj sigmas: [0.019581468772459556, 0.022271087924524438, 0.025400068767311344, 0.025871493790160915, 0.023399670957880293]
5491 : -0.4502500000000001
LR:  0.001
replay buffer size:  109522
Time Taken :  835.0  mins 30.29200005531311  seconds
[[[    0.     0.     0.     0.    79.   112.   158.   231.   140.   125.
      45.     8.    11.    38.    38.     0.     0.     0.     5.     6.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   246.  1882.  2352.  2649.  1844.  1471.  1481.
     349.   166.   973.   551.   134.     0.    12.    40.   111.   107.
      85.    35.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2367.  4020.  2529.  2326.  1520.   530.   116.  1252.
    1373.   866.   878.   175.    25.   438.   786.   388.   275.   313.
     295.    53.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 10177.  7766.  2682.  2074.  2709.  2835.  2842.  2694.  2902.
    3398.  2530.  1668.   300.   672.   997.   730.  1189.  1255.   743.
     179.   199.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   324.   366.   148.   104.     0.     0.     0.     0.
       0.    93.  1963.  1537.  1438.   874.   590.   112.     0.   146.
     127.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    53.    65.    49.    29.    22.    11.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7216
Q value #end_state_>_threshold:  7489
Q value #non_end_state_>threshold:  10477
maxi score:  0.028319999999999918
siam score:  -0.73335177
Scores:  {'0.167': -0.35192000000000007, '0.333': -0.62414, '0.5': -0.6825800000000001, '0.667': -0.768, '0.833': -0.86238, '1.0': -0.8894599999999999}
best rdn ma / adv:  1 0.167
best rdn adv:  0.055712359076472824
Episodes: 6202, frames: 110122, time: 54377.21733999252
training steps:  13573
retraining steps:  0
RDN obj mus: [-0.9480302040338516, -0.9520344689905643, -0.9493965082108975, -0.9474280370056629, -0.9406202004790306]
RDN obj sigmas: [0.02248296440446655, 0.019269058424918977, 0.023098423885101027, 0.021632820916420253, 0.021108088419599623]
6202 : -0.5789166666666666
LR:  0.001
replay buffer size:  119964
Time Taken :  906.0  mins 17.217010259628296  seconds
[[[    0.     0.     0.     0.    82.   119.   177.   257.   165.   145.
      49.     8.    12.    42.    42.     0.     0.     0.     6.     6.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   266.  2023.  2550.  2959.  2117.  1646.  1680.
     398.   187.  1010.   601.   161.     0.    12.    45.   123.   122.
     103.    39.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2457.  4295.  2716.  2637.  1633.   583.   138.  1531.
    1636.   983.   916.   192.    29.   465.   879.   460.   334.   380.
     337.    70.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 10698.  8534.  2853.  2342.  2884.  3058.  3064.  2898.  3125.
    3670.  2859.  1871.   324.   763.  1109.   859.  1368.  1437.   853.
     216.   229.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   355.   434.   182.   111.     0.     0.     0.     0.
       0.   106.  2222.  1740.  1583.   970.   670.   129.     0.   166.
     155.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    57.    71.    57.    34.    25.    15.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7768
Q value #end_state_>_threshold:  8632
Q value #non_end_state_>threshold:  13016
maxi score:  0.018299999999999882
siam score:  -0.7259589
Scores:  {'0.167': -0.3340600000000001, '0.333': -0.59216, '0.5': -0.6753600000000001, '0.667': -0.76246, '0.833': -0.8635, '1.0': -0.88896}
best rdn ma / adv:  1 0.167
best rdn adv:  0.0568444230972993
Episodes: 6882, frames: 120119, time: 58525.61970114708
training steps:  14802
retraining steps:  0
RDN obj mus: [-0.9563247932970523, -0.9519013056159019, -0.9459854656457901, -0.9428850158810616, -0.925505804169178]
RDN obj sigmas: [0.016951679098670666, 0.02166146944717821, 0.024303701053267478, 0.026609321958668233, 0.03178576238811008]
6882 : -0.5549166666666667
LR:  0.001
replay buffer size:  130364
Time Taken :  975.0  mins 25.61937403678894  seconds
[[[    0.     0.     0.     0.    84.   125.   197.   284.   179.   162.
      53.     8.    14.    45.    43.     0.     0.     0.     6.     8.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   295.  2116.  2740.  3241.  2326.  1817.  1845.
     438.   193.  1028.   629.   180.     0.    13.    48.   134.   134.
     127.    42.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2529.  4536.  2859.  2951.  1732.   636.   150.  1797.
    1811.  1077.   985.   216.    30.   489.   976.   568.   379.   454.
     378.    91.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 11129.  9246.  2984.  2638.  3073.  3311.  3311.  3154.  3420.
    4024.  3198.  2052.   350.   859.  1242.   990.  1588.  1615.   953.
     231.   275.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   391.   500.   201.   123.     0.     0.     0.     0.
       0.   115.  2496.  2153.  1772.  1108.   734.   148.     0.   179.
     175.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    59.    81.    70.    36.    38.    16.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7315999999999999
Q value #end_state_>_threshold:  9740
Q value #non_end_state_>threshold:  15648
maxi score:  -0.029440000000000074
siam score:  -0.6873439
Scores:  {'0.167': -0.31456000000000006, '0.333': -0.57274, '0.5': -0.6443800000000002, '0.667': -0.7763800000000001, '0.833': -0.8629800000000001, '1.0': -0.9066200000000001}
best rdn ma / adv:  1 0.167
best rdn adv:  0.03341573517336608
Episodes: 7487, frames: 130101, time: 62711.745014190674
training steps:  16024
retraining steps:  0
RDN obj mus: [-0.9555382543504238, -0.9559283786416054, -0.9512507817387581, -0.9486778365910054, -0.9457570100188255]
RDN obj sigmas: [0.01624733261229764, 0.018982909675559066, 0.02281664829180886, 0.024745458954045712, 0.025600857026528485]
7487 : -0.5500833333333334
LR:  0.001
replay buffer size:  140754
Time Taken :  1045.0  mins 11.744697093963623  seconds
[[[    0.     0.     0.     0.    88.   131.   208.   302.   190.   182.
      57.     8.    15.    51.    47.     0.     0.     0.     7.     9.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   310.  2219.  2936.  3494.  2572.  2008.  2017.
     475.   211.  1074.   654.   194.     0.    15.    53.   160.   153.
     137.    46.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2593.  4761.  3028.  3216.  1835.   676.   164.  2002.
    2108.  1186.  1019.   226.    32.   535.  1056.   658.   472.   518.
     420.   111.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 11552.  9882.  3109.  2902.  3259.  3549.  3557.  3418.  3771.
    4445.  3561.  2246.   371.   965.  1395.  1124.  1779.  1777.  1082.
     267.   309.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   415.   563.   215.   138.     0.     0.     0.     0.
       0.   124.  2798.  2516.  1966.  1209.   812.   172.     0.   196.
     193.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    65.    90.    77.    40.    46.    18.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7392
Q value #end_state_>_threshold:  10764
Q value #non_end_state_>threshold:  17683
maxi score:  -0.024640000000000096
siam score:  -0.6694908
Scores:  {'0.167': -0.32024, '0.333': -0.53494, '0.5': -0.6397, '0.667': -0.7893800000000001, '0.833': -0.8810800000000001, '1.0': -0.9117999999999999}
best rdn ma / adv:  1 0.167
best rdn adv:  0.05401849160069571
Episodes: 8065, frames: 140092, time: 67107.73172903061
training steps:  17256
retraining steps:  0
RDN obj mus: [-0.9453655192017555, -0.9478509877681732, -0.9442299923002719, -0.9391814138174057, -0.9316172637164593]
RDN obj sigmas: [0.020453898531959783, 0.021303303073406003, 0.024149332437751074, 0.02765331365993711, 0.03155553008666285]
8065 : -0.62175
LR:  0.001
replay buffer size:  151190
Time Taken :  1118.0  mins 27.731417179107666  seconds
[[[    0.     0.     0.     0.    92.   134.   224.   323.   197.   197.
      65.     9.    16.    56.    47.     0.     0.     0.     7.    10.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   329.  2320.  3074.  3724.  2784.  2196.  2200.
     507.   225.  1101.   676.   207.     0.    15.    57.   179.   168.
     155.    54.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2653.  4968.  3237.  3481.  1931.   711.   172.  2265.
    2391.  1287.  1072.   243.    32.   571.  1145.   738.   517.   573.
     454.   115.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 12011. 10500.  3239.  3154.  3428.  3786.  3789.  3671.  4128.
    4874.  3948.  2430.   405.  1068.  1508.  1232.  1981.  2002.  1213.
     296.   348.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   440.   617.   235.   145.     0.     0.     0.     0.
       0.   131.  3198.  3001.  2142.  1315.   881.   183.     0.   228.
     220.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    72.    97.    88.    43.    51.    23.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.736
Q value #end_state_>_threshold:  11883
Q value #non_end_state_>threshold:  19016
maxi score:  0.01235999999999991
siam score:  -0.6579949
Scores:  {'0.167': -0.3261600000000001, '0.333': -0.5322000000000001, '0.5': -0.63068, '0.667': -0.80112, '0.833': -0.8920800000000001, '1.0': -0.9198000000000001}
best rdn ma / adv:  1 0.167
best rdn adv:  0.05261925039581116
Episodes: 8677, frames: 150066, time: 71576.5183172226
training steps:  18491
retraining steps:  0
RDN obj mus: [-0.9479570092797279, -0.9559310509681702, -0.9526952716648579, -0.9490128557860851, -0.9418711430072785]
RDN obj sigmas: [0.01978496220318218, 0.01555168789173086, 0.021195534863964555, 0.02448208401724062, 0.03277344529087277]
8677 : -0.5963333333333334
LR:  0.001
replay buffer size:  161573
Time Taken :  1192.0  mins 56.51800608634949  seconds
[[[    0.     0.     0.     0.    99.   141.   245.   339.   217.   206.
      72.    11.    17.    61.    49.     0.     0.     0.     8.    12.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   358.  2458.  3261.  3978.  3007.  2375.  2355.
     544.   236.  1127.   698.   219.     0.    16.    60.   192.   179.
     170.    59.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2739.  5220.  3433.  3731.  2030.   750.   180.  2581.
    2736.  1420.  1103.   266.    34.   606.  1213.   796.   553.   612.
     489.   127.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 12433. 11166.  3400.  3386.  3606.  3987.  3992.  3904.  4433.
    5201.  4325.  2583.   434.  1130.  1609.  1324.  2199.  2180.  1325.
     333.   383.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   469.   681.   245.   158.     0.     0.     0.     0.
       0.   139.  3567.  3370.  2542.  1464.   962.   198.     0.   232.
     235.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    78.   106.    92.    48.    55.    25.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7152
Q value #end_state_>_threshold:  13007
Q value #non_end_state_>threshold:  20604
maxi score:  0.06593999999999987
siam score:  -0.6568439
Scores:  {'0.167': -0.33338000000000007, '0.333': -0.53174, '0.5': -0.65068, '0.667': -0.8344600000000001, '0.833': -0.8923200000000001, '1.0': -0.9350199999999999}
best rdn ma / adv:  1 0.167
best rdn adv:  0.04926649215425928
Episodes: 9210, frames: 160064, time: 76041.90974712372
training steps:  19727
retraining steps:  0
RDN obj mus: [-0.9391842173039913, -0.9512487203776836, -0.9520909578800202, -0.948545494401455, -0.935927261865139]
RDN obj sigmas: [0.021680907329527335, 0.018223379737130604, 0.019925885641362277, 0.021624531134840922, 0.03916626367384849]
9210 : -0.5775833333333333
LR:  0.001
replay buffer size:  171996
Time Taken :  1267.0  mins 21.90941834449768  seconds
[[[    0.     0.     0.     0.   103.   150.   256.   355.   222.   214.
      77.    11.    20.    62.    50.     0.     0.     0.     8.    13.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   382.  2568.  3390.  4186.  3200.  2527.  2499.
     573.   242.  1157.   774.   230.     0.    17.    66.   215.   194.
     184.    65.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2791.  5405.  3610.  3960.  2147.   777.   187.  2824.
    2896.  1535.  1133.   280.    34.   644.  1339.   874.   612.   651.
     531.   137.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 12821. 11729.  3579.  3597.  3816.  4211.  4282.  4214.  4783.
    5554.  4748.  2762.   466.  1229.  1733.  1449.  2431.  2414.  1435.
     357.   417.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   489.   724.   271.   167.     0.     0.     0.     0.
       0.   146.  4036.  3915.  2876.  1646.  1019.   209.     0.   252.
     266.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    81.   112.    96.    54.    60.    29.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7116
Q value #end_state_>_threshold:  13972
Q value #non_end_state_>threshold:  21937
maxi score:  0.035819999999999914
siam score:  -0.65964836
Scores:  {'0.167': -0.36508000000000007, '0.333': -0.5020800000000001, '0.5': -0.66166, '0.667': -0.84942, '0.833': -0.88824, '1.0': -0.9268400000000001}
best rdn ma / adv:  1 0.167
best rdn adv:  0.05494338192772342
Episodes: 9740, frames: 170130, time: 80415.89394497871
training steps:  20975
retraining steps:  0
RDN obj mus: [-0.9581978536069393, -0.9662615279495717, -0.9626853648900986, -0.9487875997364521, -0.9478351373314857]
RDN obj sigmas: [0.01782398856405176, 0.012988296578777859, 0.015315310855978675, 0.02506641725384899, 0.026916120254395905]
9740 : -0.6920833333333334
LR:  0.001
replay buffer size:  182476
Time Taken :  1340.0  mins 15.893625020980835  seconds
[[[    0.     0.     0.     0.   109.   157.   276.   362.   230.   219.
      80.    11.    20.    64.    51.     0.     0.     0.     8.    14.
       4.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   424.  2674.  3572.  4371.  3380.  2701.  2598.
     600.   310.  1290.   879.   250.     0.    19.    69.   253.   209.
     191.    71.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2855.  5643.  3802.  4140.  2234.   813.   193.  2982.
    3015.  1633.  1164.   290.    34.   728.  1559.   920.   649.   704.
     568.   146.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 13231. 12290.  3736.  3791.  4081.  4431.  4523.  4505.  5081.
    5930.  5341.  2915.   494.  1278.  1817.  1599.  2571.  2564.  1533.
     387.   446.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   507.   774.   294.   180.     0.     0.     0.     0.
       0.   153.  4436.  4601.  3180.  1866.  1101.   220.     0.   260.
     276.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    82.   120.   102.    56.    65.    35.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7128
Q value #end_state_>_threshold:  14760
Q value #non_end_state_>threshold:  22943
maxi score:  0.06235999999999992
siam score:  -0.67617744
Scores:  {'0.167': -0.33864000000000005, '0.333': -0.50926, '0.5': -0.67956, '0.667': -0.8382600000000001, '0.833': -0.8970800000000001, '1.0': -0.94342}
best rdn ma / adv:  1 0.167
best rdn adv:  0.05192314034756623
Episodes: 10236, frames: 180076, time: 87482.74049592018
training steps:  22272
retraining steps:  0
RDN obj mus: [-0.947389615136385, -0.9545728460490703, -0.9523100823283196, -0.946344965684414, -0.9332682994306087]
RDN obj sigmas: [0.018466249188495196, 0.01914468101391107, 0.020995413790439402, 0.024454102386789987, 0.03860979455049406]
10236 : -0.6056666666666667
LR:  0.001
replay buffer size:  192841
Time Taken :  1458.0  mins 2.7401981353759766  seconds
[[[    0.     0.     0.     0.   120.   164.   290.   375.   244.   225.
      83.    11.    21.    67.    58.     0.     0.     0.     8.    15.
       4.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   464.  2782.  3755.  4552.  3569.  2853.  2713.
     634.   373.  1412.   967.   258.     0.    20.    70.   259.   220.
     201.    76.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2943.  5878.  3985.  4333.  2316.   839.   200.  3241.
    3210.  1743.  1209.   305.    36.   770.  1614.   991.   710.   747.
     604.   156.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 13604. 12836.  3865.  3973.  4273.  4686.  4768.  4786.  5474.
    6392.  6017.  3045.   508.  1397.  1952.  1706.  2745.  2737.  1642.
     417.   473.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   533.   805.   307.   185.     0.     0.     0.     0.
       0.   158.  4818.  5062.  3475.  2003.  1169.   230.     0.   328.
     293.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    83.   124.   107.    61.    69.    41.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.714
Q value #end_state_>_threshold:  15504
Q value #non_end_state_>threshold:  23694
maxi score:  0.06789999999999992
siam score:  -0.6580217
Scores:  {'0.167': -0.35508000000000006, '0.333': -0.5079600000000001, '0.5': -0.6734, '0.667': -0.85722, '0.833': -0.8982, '1.0': -0.94664}
best rdn ma / adv:  1 0.167
best rdn adv:  0.04915618400602485
Episodes: 10675, frames: 190110, time: 93972.71269321442
training steps:  23503
retraining steps:  0
RDN obj mus: [-0.9537579845905304, -0.9584821163654328, -0.9553270346105098, -0.9479112554430962, -0.9403087879836559]
RDN obj sigmas: [0.01701826433306585, 0.019040186935752285, 0.020662881009346955, 0.025653306804582898, 0.030024126331984174]
10675 : -0.6241666666666668
LR:  0.001
replay buffer size:  200204
Time Taken :  1566.0  mins 12.712379217147827  seconds
[[[    0.     0.     0.     0.   128.   169.   301.   388.   250.   231.
      87.    12.    22.    71.    63.     0.     0.     0.     8.    16.
       4.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   513.  2863.  3940.  4684.  3698.  3062.  2828.
     649.   456.  1676.  1208.   278.     0.    21.    73.   279.   227.
     209.    80.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3005.  6083.  4150.  4491.  2381.   853.   210.  3591.
    3496.  1935.  1274.   317.    38.   844.  1715.  1043.   728.   768.
     635.   161.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 14020. 13315.  3989.  4137.  4539.  4952.  5049.  5109.  5804.
    6758.  6875.  3190.   519.  1485.  2074.  1823.  2910.  2862.  1718.
     433.   499.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   551.   830.   322.   195.     0.     0.     0.     0.
       0.   163.  5074.  5419.  3726.  2285.  1212.   238.     0.   332.
     306.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    87.   127.   109.    66.    76.    45.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7055999999999999
Q value #end_state_>_threshold:  16211
Q value #non_end_state_>threshold:  24425
maxi score:  -0.005440000000000095
siam score:  -0.6686053
Scores:  {'0.167': -0.3762000000000001, '0.333': -0.5046200000000001, '0.5': -0.71014, '0.667': -0.8694600000000001, '0.833': -0.90282, '1.0': -0.9557599999999999}
best rdn ma / adv:  1 0.167
best rdn adv:  0.04545795211899773
Episodes: 11138, frames: 200081, time: 101110.66550707817
training steps:  24697
retraining steps:  0
RDN obj mus: [-0.9521679705500603, -0.9529632189691066, -0.950493951612711, -0.945890323126316, -0.9230285390555859]
RDN obj sigmas: [0.01957741798008326, 0.020649317447745123, 0.02509856405335598, 0.028608343143927954, 0.05296007109888666]
11138 : -0.6969166666666666
LR:  0.001
replay buffer size:  200319
Time Taken :  1685.0  mins 10.665200233459473  seconds
[[[    0.     0.     0.     0.   134.   178.   313.   400.   259.   238.
      89.    13.    22.    78.    65.     0.     0.     0.     9.    17.
       4.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   538.  2943.  4132.  4846.  3855.  3290.  2973.
     670.   632.  1997.  1387.   298.     0.    22.    74.   290.   256.
     224.    83.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3100.  6295.  4315.  4666.  2459.   870.   215.  3779.
    3877.  2614.  1340.   330.    39.   909.  1803.  1102.   756.   804.
     664.   171.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 14505. 13822.  4128.  4316.  4707.  5192.  5266.  5485.  6097.
    7083.  7460.  3299.   545.  1551.  2194.  1886.  3090.  2968.  1783.
     451.   515.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   575.   865.   346.   204.     0.     0.     0.     0.
       0.   172.  5364.  5625.  3910.  2407.  1254.   245.     0.   338.
     316.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    91.   135.   115.    70.    85.    46.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7124000000000001
Q value #end_state_>_threshold:  16867
Q value #non_end_state_>threshold:  25135
maxi score:  -0.02896000000000011
siam score:  -0.6793606
Scores:  {'0.167': -0.38234000000000007, '0.333': -0.51766, '0.5': -0.72436, '0.667': -0.88278, '0.833': -0.9247, '1.0': -0.95272}
best rdn ma / adv:  1 0.167
best rdn adv:  0.047599529870088315
Episodes: 11557, frames: 210039, time: 108143.17823600769
training steps:  25879
retraining steps:  0
RDN obj mus: [-0.9581159176111221, -0.9582339426338673, -0.9537641267001629, -0.9506416428625584, -0.922277678155899]
RDN obj sigmas: [0.01734195354364628, 0.017778237287740906, 0.01999411985535078, 0.022844866177899437, 0.052128312962758015]
11557 : -0.76275
LR:  0.001
replay buffer size:  200420
Time Taken :  1802.0  mins 23.177906274795532  seconds
[[[    0.     0.     0.     0.   139.   181.   322.   407.   261.   242.
      96.    13.    22.    82.    69.     0.     0.     0.    10.    18.
       5.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   568.  3017.  4304.  4969.  3988.  3419.  3089.
     683.   744.  2258.  1696.   324.     0.    22.    81.   298.   273.
     236.    84.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3180.  6485.  4490.  4831.  2548.   889.   225.  3895.
    3991.  3312.  1391.   343.    44.   970.  1908.  1186.   794.   832.
     691.   180.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15126. 14289.  4256.  4475.  4940.  5481.  5580.  5863.  6647.
    7481.  7997.  3429.   564.  1625.  2292.  1955.  3190.  3072.  1836.
     468.   530.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   596.   900.   352.   211.     0.     0.     0.     0.
       0.   174.  5757.  5849.  4014.  2610.  1311.   259.     0.   356.
     327.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    95.   142.   118.    72.    87.    51.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6991999999999998
Q value #end_state_>_threshold:  17371
Q value #non_end_state_>threshold:  25602
maxi score:  -0.047980000000000106
siam score:  -0.7345554
Scores:  {'0.167': -0.38406000000000007, '0.333': -0.5238200000000001, '0.5': -0.7397800000000001, '0.667': -0.8956200000000001, '0.833': -0.92212, '1.0': -0.9585600000000001}
best rdn ma / adv:  1 0.167
best rdn adv:  0.039598145926483364
Episodes: 11944, frames: 220104, time: 115500.17217898369
training steps:  27066
retraining steps:  0
RDN obj mus: [-0.9503620580136776, -0.95990142095685, -0.9548830725193024, -0.9423975595772266, -0.9290245176494122]
RDN obj sigmas: [0.03172045930709595, 0.018798847353790553, 0.019993379906424236, 0.02611748823433405, 0.03572376323772276]
11944 : -0.7501666666666668
LR:  0.001
replay buffer size:  200072
Time Taken :  1925.0  mins 0.17185401916503906  seconds
[[[    0.     0.     0.     0.   144.   185.   328.   414.   269.   246.
      99.    15.    22.    89.    77.     0.     0.     0.    12.    20.
       5.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   597.  3152.  4513.  5092.  4171.  3621.  3198.
     701.  1098.  2510.  1951.   340.     0.    23.    84.   307.   276.
     243.    84.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3274.  6674.  4791.  5000.  2660.   910.   231.  4052.
    4158.  4093.  1438.   352.    44.  1056.  1973.  1227.   851.   868.
     720.   189.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15657. 14725.  4386.  4636.  5148.  5712.  5875.  6206.  7040.
    7722.  8768.  3555.   590.  1711.  2413.  2042.  3299.  3179.  1887.
     481.   547.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   615.   916.   362.   221.     0.     0.     0.     0.
       0.   180.  6008.  6096.  4127.  2725.  1341.   266.     0.   358.
     332.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    96.   146.   125.    75.    90.    55.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6872000000000001
Q value #end_state_>_threshold:  17916
Q value #non_end_state_>threshold:  25989
maxi score:  -0.08114000000000009
siam score:  -0.6977867
Scores:  {'0.167': -0.3871400000000001, '0.333': -0.5163200000000001, '0.5': -0.7543000000000001, '0.667': -0.89704, '0.833': -0.9251999999999999, '1.0': -0.96128}
best rdn ma / adv:  1 0.167
best rdn adv:  0.04034437108012078
Episodes: 12329, frames: 230071, time: 123064.24113321304
training steps:  28251
retraining steps:  0
RDN obj mus: [-0.9586930608391762, -0.9610079217135906, -0.9570547781288624, -0.9514738239705562, -0.9138667360126972]
RDN obj sigmas: [0.017436347435329836, 0.0184723371093922, 0.020896584460597646, 0.023258270011914883, 0.0795383911577435]
12329 : -0.6358333333333335
LR:  0.001
replay buffer size:  200414
Time Taken :  2051.0  mins 4.240822076797485  seconds
[[[    0.     0.     0.     0.   147.   186.   338.   429.   274.   251.
     101.    15.    23.    93.    82.     0.     0.     0.    12.    21.
       7.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   623.  3260.  4779.  5243.  4286.  3838.  3345.
     717.  1368.  2791.  2056.   356.     0.    24.    90.   332.   285.
     254.    87.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3377.  6892.  5014.  5166.  2764.   932.   238.  4215.
    4401.  4279.  1474.   361.    45.  1091.  2068.  1302.   872.   895.
     742.   198.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 16170. 15189.  4514.  4780.  5478.  6009.  6196.  6588.  7413.
    8110.  9570.  3682.   612.  1777.  2510.  2138.  3432.  3262.  1947.
     496.   562.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   629.   936.   369.   229.     0.     0.     0.     0.
       0.   184.  6523.  6263.  4231.  2945.  1373.   274.     0.   361.
     343.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.   101.   153.   129.    76.    91.    58.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
