EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.012579929161942206
Scores:  {'0.167': 0.04176666666666667, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.07702307692307693, '0.833': 0.07152857142857143, '1.0': 0.08343333333333333}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.2560892113411456
Episodes: 82, frames: 1381, time: 36.84899091720581
training steps:  6
retraining steps:  0
RDN obj mus: [-0.01322628021109524, -0.019278689006876785, -0.024574841106576577, 0.0, 0.0]
RDN obj sigmas: [0.007656144248353518, 0.005594097432275594, 0.006855849082306972, 0.0, 0.0]
82 : 0.042682926829268296
LR:  5e-06
replay buffer size:  1775
Time Taken :  0.0  mins 36.848840951919556  seconds
[[[302. 185.  29.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
  [210. 123.  33.   0.   1.   0.   0.   0.   0.   0.   0.   0.]
  [113.  76.  13.   2.   1.   0.   0.   0.   0.   0.   0.   0.]
  [ 57.  43.  11.   1.   0.   0.   0.   0.   0.   0.   0.   0.]
  [ 58.  34.   7.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.38
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.11148613861386139
siam score:  -0.6157032
Scores:  {'0.167': 0.1051, '0.333': 0.09205402298850575, '0.5': 0.15104339622641508, '0.667': 0.11175048543689321, '0.833': 0.10785862068965517, '1.0': 0.11588947368421053}
best rdn ma / adv:  0.5 0.5
best rdn adv:  0.3261470149120252
Episodes: 770, frames: 10055, time: 1754.9206719398499
training steps:  1210
retraining steps:  0
RDN obj mus: [-0.9330321451902389, -0.9382997686386109, -0.9212850164830685, -0.903256086491737, -0.8763897446583682]
RDN obj sigmas: [0.035404754964916525, 0.034130817349778644, 0.04236324206281477, 0.05334857013281327, 0.06455671502837794]
770 : 0.26666666666666666
LR:  0.001
replay buffer size:  10637
Time Taken :  29.0  mins 14.920519828796387  seconds
[[[2323. 1478.  304.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]
  [1330.  833.  184.    7.    4.    0.    0.    0.    0.    0.    0.
      0.]
  [ 556.  516.   88.   26.    9.    0.    0.    0.    0.    0.    0.
      0.]
  [ 336.  361.   81.    6.    1.    0.    0.    0.    0.    0.    0.
      0.]
  [ 302.  357.  183.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  15
maxi score:  0.2565102564102564
siam score:  -0.8352133
Scores:  {'0.167': 0.24400243902439023, '0.333': 0.24873387978142075, '0.5': 0.2764157894736842, '0.667': 0.2324232323232323, '0.833': 0.21375638766519822, '1.0': 0.2001}
best rdn ma / adv:  0.5 0.5
best rdn adv:  0.2554105702296695
Episodes: 1549, frames: 20030, time: 3942.7311351299286
training steps:  2352
retraining steps:  0
RDN obj mus: [-0.9576288345932961, -0.9552602493345738, -0.9565284868240357, -0.9578570507884026, -0.9516541047573089]
RDN obj sigmas: [0.02696802432917837, 0.03406873028585417, 0.04634140165706823, 0.053855879731794724, 0.061239850832430165]
1549 : 0.2708333333333333
LR:  0.001
replay buffer size:  20869
Time Taken :  65.0  mins 42.730984926223755  seconds
[[[3275. 2032.  368.    0.    0.    0.    1.    0.    0.    0.    0.
      0.]
  [2352. 1546.  256.   11.    7.    2.    3.    1.    2.    0.    0.
      0.]
  [1298. 1481.  232.   76.   31.   10.    6.    0.    1.    0.    0.
      0.]
  [ 904. 1211.  144.   10.    2.    2.    0.    0.    0.    0.    0.
      0.]
  [ 978. 1494.  745.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  15
maxi score:  0.3271
siam score:  -0.82033426
Scores:  {'0.167': 0.2704180212014134, '0.333': 0.20958616600790514, '0.5': 0.21231864951768487, '0.667': 0.17602592592592592, '0.833': 0.16457368421052632, '1.0': 0.1447886446886447}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 2129, frames: 30045, time: 6126.547164916992
training steps:  3528
retraining steps:  0
RDN obj mus: [-0.939160617351532, -0.97263595277071, -0.9657404768824578, -0.9567236090123653, -0.9457102713048459]
RDN obj sigmas: [0.03138856971069906, 0.017650514057908927, 0.025239541341894694, 0.03349212251155951, 0.047118944080530814]
2129 : 0.13333333333333333
LR:  0.001
replay buffer size:  31093
Time Taken :  102.0  mins 6.547013759613037  seconds
[[[4956. 4335.  562.    0.    0.    0.    3.    0.    1.    1.    0.
      0.]
  [3138. 2483.  345.   15.   17.   12.   22.    8.    7.    1.    0.
      0.]
  [1700. 2029.  408.  204.  171.  124.   94.   25.    3.    0.    0.
      0.]
  [1193. 1641.  175.   16.    7.    8.   13.    0.    0.    0.    0.
      0.]
  [1351. 1923.  925.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  15
maxi score:  0.3751
siam score:  -0.8204556
Scores:  {'0.167': 0.2819991097922849, '0.333': 0.20044246575342464, '0.5': 0.1876, '0.667': 0.1496327102803738, '0.833': 0.14315555555555554, '1.0': 0.12708412698412697}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 2495, frames: 40070, time: 8489.06601190567
training steps:  4704
retraining steps:  0
RDN obj mus: [-0.9585990927398205, -0.9728790944337845, -0.970765752351284, -0.9681160515487194, -0.9569117307126522]
RDN obj sigmas: [0.03261929609454594, 0.025548337905984975, 0.036509077665444575, 0.03509568532056849, 0.04042194182391049]
2495 : 0.22083333333333333
LR:  0.001
replay buffer size:  41319
Time Taken :  141.0  mins 29.06585693359375  seconds
[[[8469. 6706.  697.    0.    0.    0.    3.    3.    1.    2.    0.
      0.]
  [3833. 3109.  390.   21.   27.   16.   40.   29.   26.    8.    1.
      0.]
  [1943. 2407.  548.  315.  249.  168.  131.   29.    4.    2.    1.
      0.]
  [1373. 1926.  189.   22.    9.   10.   16.    0.    0.    0.    0.
      0.]
  [1577. 2236. 1039.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  33
maxi score:  0.41509999999999997
siam score:  -0.80621886
Scores:  {'0.167': 0.283094923857868, '0.333': 0.20096705202312137, '0.5': 0.1815720812182741, '0.667': 0.13245294117647058, '0.833': 0.13181355498721226, '1.0': 0.10850108401084012}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.007802138274096222
Episodes: 2847, frames: 50003, time: 10850.943065166473
training steps:  5865
retraining steps:  0
RDN obj mus: [-0.9687294479310512, -0.9766121036231518, -0.9767596493065357, -0.9758731660842895, -0.9593441377997398]
RDN obj sigmas: [0.01935758452666271, 0.020151398177041747, 0.02496008556687734, 0.027558565552016624, 0.04590112479711501]
2847 : 0.19166666666666668
LR:  0.001
replay buffer size:  51459
Time Taken :  180.0  mins 50.942917823791504  seconds
[[[12245.  8746.   805.     0.     0.     0.     7.     3.     4.     4.
       1.     0.]
  [ 4694.  3644.   441.    22.    31.    19.    76.    65.    67.    57.
      14.     2.]
  [ 2220.  2713.   653.   378.   309.   209.   180.    30.     7.     5.
       4.     0.]
  [ 1552.  2164.   213.    26.    11.    14.    18.     0.     0.     0.
       0.     0.]
  [ 1834.  2515.  1154.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  4
Q value #non_end_state_>threshold:  49
maxi score:  0.41309999999999997
siam score:  -0.77713346
Scores:  {'0.167': 0.2869663594470046, '0.333': 0.19531410579345088, '0.5': 0.17630137299771165, '0.667': 0.12091339712918661, '0.833': 0.1251, '1.0': 0.10107323600973236}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.01758605537753954
Episodes: 3168, frames: 60001, time: 13254.741017103195
training steps:  7039
retraining steps:  0
RDN obj mus: [-0.9696681643545627, -0.9786748234808444, -0.9742257266521454, -0.9670878639340401, -0.9489668269634247]
RDN obj sigmas: [0.02649054901294448, 0.019372810005523742, 0.025203189284499227, 0.028549253588992404, 0.03715759371632209]
3168 : 0.14583333333333334
LR:  0.001
replay buffer size:  61673
Time Taken :  220.0  mins 54.740867137908936  seconds
[[[15887. 10800.   883.     0.     0.     0.     8.     8.     5.     6.
       4.     0.]
  [ 5535.  4200.   479.    28.    35.    26.   127.   128.   123.   136.
      65.    10.]
  [ 2488.  3059.   820.   498.   427.   288.   257.    36.    11.     9.
       5.     0.]
  [ 1715.  2417.   238.    31.    19.    19.    22.     0.     0.     0.
       0.     0.]
  [ 2004.  2734.  1243.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  12
Q value #non_end_state_>threshold:  73
maxi score:  0.41209999999999997
siam score:  -0.74814844
Scores:  {'0.167': 0.28788467908902693, '0.333': 0.19825668202764976, '0.5': 0.16366107660455487, '0.667': 0.11132881355932203, '0.833': 0.11444511434511435, '1.0': 0.09723024282560706}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.022275670144883422
Episodes: 3504, frames: 70032, time: 15660.129852056503
training steps:  8216
retraining steps:  0
RDN obj mus: [-0.9745546008408069, -0.9785684508442879, -0.9763833572387696, -0.9649353752613068, -0.9300562665045261]
RDN obj sigmas: [0.017831684390450776, 0.025448219235238656, 0.0267979615561118, 0.032602104545547315, 0.05442229568601918]
3504 : 0.15416666666666667
LR:  0.001
replay buffer size:  71902
Time Taken :  261.0  mins 0.12970185279846191  seconds
[[[19096. 12585.   961.     0.     0.     0.     9.    12.     8.     9.
       6.     0.]
  [ 6491.  4808.   528.    31.    42.    36.   215.   215.   203.   192.
      89.    18.]
  [ 2766.  3420.  1006.   645.   571.   416.   410.    52.    15.    12.
       5.     0.]
  [ 1972.  2729.   261.    37.    23.    23.    30.     0.     0.     0.
       0.     0.]
  [ 2270.  2980.  1331.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  33
Q value #non_end_state_>threshold:  88
maxi score:  0.4001
siam score:  -0.7425734
Scores:  {'0.167': 0.3051, '0.333': 0.18968333333333331, '0.5': 0.1571, '0.667': 0.1051, '0.833': 0.1071, '1.0': 0.0951}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.024592339839951297
Episodes: 3843, frames: 80028, time: 18046.50341820717
training steps:  9382
retraining steps:  0
RDN obj mus: [-0.9718538477003574, -0.9797127129673958, -0.975165411388874, -0.9734493343949318, -0.949415250313282]
RDN obj sigmas: [0.024766843471236862, 0.02074136672770653, 0.026083377929679463, 0.02998169543557875, 0.04369410814257748]
3843 : 0.15416666666666667
LR:  0.001
replay buffer size:  82135
Time Taken :  300.0  mins 46.50326991081238  seconds
[[[22439. 14667.  1050.     0.     0.     0.    10.    15.    11.    10.
       6.     0.]
  [ 7456.  5467.   589.    36.    53.    44.   287.   294.   285.   253.
     112.    26.]
  [ 3030.  3798.  1194.   795.   687.   493.   496.    60.    17.    14.
       7.     0.]
  [ 2098.  2950.   281.    45.    27.    28.    37.     0.     0.     0.
       0.     0.]
  [ 2429.  3179.  1410.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  72
Q value #non_end_state_>threshold:  112
maxi score:  0.3981
siam score:  -0.7642154
Scores:  {'0.167': 0.3331, '0.333': 0.1971, '0.5': 0.14509999999999998, '0.667': 0.1041, '0.833': 0.1061, '1.0': 0.0911}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.03074042479993912
Episodes: 4187, frames: 90190, time: 20474.114557027817
training steps:  10576
retraining steps:  0
RDN obj mus: [-0.9813782372951507, -0.9861596191465855, -0.9819112669169903, -0.9736373753607274, -0.9426099741578102]
RDN obj sigmas: [0.01177055906539251, 0.010377275894657175, 0.025574913267453488, 0.02778866149083324, 0.04573613112090774]
4187 : 0.13333333333333333
LR:  0.001
replay buffer size:  92544
Time Taken :  341.0  mins 14.114407777786255  seconds
[[[26017. 16565.  1127.     0.     0.     0.    17.    16.    13.    13.
       8.     0.]
  [ 8422.  6029.   639.    43.    62.    57.   409.   352.   334.   309.
     157.    35.]
  [ 3327.  4175.  1380.   935.   832.   612.   596.    71.    19.    17.
       9.     0.]
  [ 2264.  3185.   301.    52.    34.    37.    40.     0.     0.     0.
       0.     0.]
  [ 2586.  3410.  1497.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  79
Q value #non_end_state_>threshold:  123
maxi score:  0.3851
siam score:  -0.7378905
Scores:  {'0.167': 0.34609999999999996, '0.333': 0.20709999999999998, '0.5': 0.11410000000000001, '0.667': 0.0971, '0.833': 0.0901, '1.0': 0.0811}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.033814467279933036
Episodes: 4506, frames: 100138, time: 22848.007865190506
training steps:  11738
retraining steps:  0
RDN obj mus: [-0.9757042730391026, -0.9788151191651822, -0.9770084881961346, -0.9711137204051018, -0.9448477905809879]
RDN obj sigmas: [0.018461590792248593, 0.021659789957827507, 0.02766822147224671, 0.02982981895870384, 0.058690939085420994]
4506 : 0.17083333333333334
LR:  0.001
replay buffer size:  102767
Time Taken :  380.0  mins 48.007734060287476  seconds
[[[29349. 18338.  1183.     0.     0.     0.    20.    17.    19.    17.
       8.     0.]
  [ 9526.  6581.   672.    52.    75.    65.   497.   417.   422.   356.
     173.    38.]
  [ 3657.  4528.  1557.  1054.   961.   700.   695.    79.    19.    20.
      12.     0.]
  [ 2484.  3395.   331.    55.    44.    43.    45.     0.     0.     0.
       0.     0.]
  [ 2858.  3674.  1596.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  155
Q value #non_end_state_>threshold:  190
maxi score:  0.3831
siam score:  -0.7666446
Scores:  {'0.167': 0.35009999999999997, '0.333': 0.1991, '0.5': 0.0901, '0.667': 0.0591, '0.833': 0.0541, '1.0': 0.058100000000000006}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.043036594719914764
Episodes: 4851, frames: 110095, time: 25231.13885116577
training steps:  12900
retraining steps:  0
RDN obj mus: [-0.9652664826989173, -0.9777974253118038, -0.9715814346492291, -0.9643392909228802, -0.9351655176103115]
RDN obj sigmas: [0.030649497702207533, 0.02461504689411065, 0.02821432585640774, 0.03477308824155825, 0.06562981685250473]
4851 : 0.20416666666666666
LR:  0.001
replay buffer size:  112958
Time Taken :  420.0  mins 31.138693809509277  seconds
[[[32023. 20040.  1241.     0.     0.     0.    29.    22.    24.    20.
      16.     0.]
  [10377.  7183.   709.    65.    88.    71.   641.   554.   620.   489.
     303.    58.]
  [ 3947.  4969.  1767.  1242.  1178.   888.   873.    87.    21.    24.
      16.     0.]
  [ 2675.  3624.   350.    63.    57.    52.    51.     0.     0.     0.
       0.     0.]
  [ 3177.  3927.  1683.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  286
Q value #non_end_state_>threshold:  368
maxi score:  0.3841
siam score:  -0.74874794
Scores:  {'0.167': 0.35409999999999997, '0.333': 0.18009999999999998, '0.5': 0.0771, '0.667': 0.0371, '0.833': 0.026099999999999998, '1.0': 0.0281}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.0768510619998478
Episodes: 5263, frames: 120036, time: 27418.629663944244
training steps:  14066
retraining steps:  0
RDN obj mus: [-0.967455187857151, -0.9781335031509399, -0.9712253206551075, -0.9655105169653893, -0.9246483338594437]
RDN obj sigmas: [0.02813315413595916, 0.02250260140697409, 0.02843081717934654, 0.034605437849303367, 0.08443023718752302]
5263 : 0.18333333333333332
LR:  0.001
replay buffer size:  123189
Time Taken :  456.0  mins 58.62951397895813  seconds
[[[34146. 21369.  1298.     0.     0.     0.    42.    28.    29.    24.
      18.     0.]
  [11187.  7784.   751.    77.    96.    87.   855.   684.   845.   661.
     483.    91.]
  [ 4351.  5510.  2033.  1470.  1420.  1080.  1099.    98.    25.    30.
      24.     0.]
  [ 2948.  3934.   370.    78.    67.    63.    67.     0.     0.     0.
       0.     0.]
  [ 3562.  4197.  1792.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.52
Q value #end_state_>_threshold:  550
Q value #non_end_state_>threshold:  603
maxi score:  0.3971
siam score:  -0.73259926
Scores:  {'0.167': 0.3681, '0.333': 0.1991, '0.5': 0.1021, '0.667': 0.049100000000000005, '0.833': 0.0281, '1.0': 0.0251}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.11066552927978084
Episodes: 5698, frames: 130190, time: 52868.5251159668
training steps:  15255
retraining steps:  0
RDN obj mus: [-0.9736186964809894, -0.9823873376190663, -0.9775707594513893, -0.970050569319725, -0.9452386758387089]
RDN obj sigmas: [0.021275799961896272, 0.019815907868673543, 0.02706491618998972, 0.03424415401603671, 0.06595073336765178]
5698 : 0.25416666666666665
LR:  0.001
replay buffer size:  133620
Time Taken :  881.0  mins 8.524963855743408  seconds
[[[36306. 22592.  1357.     0.     0.     0.    57.    35.    33.    33.
      22.     0.]
  [11942.  8354.   796.    91.   104.   109.  1146.   906.  1104.   873.
     641.   147.]
  [ 4660.  6032.  2381.  1780.  1792.  1383.  1412.   113.    33.    34.
      28.     0.]
  [ 3158.  4148.   394.    93.    82.    78.    80.     0.     0.     0.
       0.     0.]
  [ 3836.  4457.  1870.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.64
Q value #end_state_>_threshold:  868
Q value #non_end_state_>threshold:  988
maxi score:  0.4041
siam score:  -0.7373011
Scores:  {'0.167': 0.3881, '0.333': 0.20509999999999998, '0.5': 0.1191, '0.667': 0.0601, '0.833': 0.035100000000000006, '1.0': 0.0281}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.1298539556295482
Episodes: 6162, frames: 140078, time: 55151.527290821075
training steps:  16418
retraining steps:  0
RDN obj mus: [-0.9703391862690449, -0.9767233504772186, -0.9740226709187031, -0.9672179844975471, -0.958186319231987]
RDN obj sigmas: [0.021136351477284272, 0.01744503671997314, 0.027400478314322085, 0.03655612812470537, 0.04087514460988104]
6162 : 0.2
LR:  0.001
replay buffer size:  143860
Time Taken :  919.0  mins 11.527154922485352  seconds
[[[37875. 23541.  1408.     0.     0.     0.    75.    44.    45.    39.
      30.     0.]
  [12574.  8876.   821.    99.   114.   144.  1484.  1185.  1481.  1133.
     856.   208.]
  [ 4951.  6603.  2778.  2176.  2398.  1781.  1756.   143.    37.    46.
      33.     0.]
  [ 3346.  4355.   419.   113.   104.    89.    94.     0.     0.     0.
       0.     0.]
  [ 4072.  4642.  1948.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.8
Q value #end_state_>_threshold:  1316
Q value #non_end_state_>threshold:  1788
maxi score:  0.4371
siam score:  -0.74944365
Scores:  {'0.167': 0.3981, '0.333': 0.2241, '0.5': 0.1351, '0.667': 0.06910000000000001, '0.833': 0.0371, '1.0': 0.035100000000000006}
best rdn ma / adv:  0.167 0.333
best rdn adv:  0.12043960884563792
Episodes: 6652, frames: 150090, time: 71656.46240520477
training steps:  17591
retraining steps:  0
RDN obj mus: [-0.9576227337241173, -0.9755767477214337, -0.9715073717594147, -0.9690656535506248, -0.967327582937479]
RDN obj sigmas: [0.02719156344041764, 0.02255727921538417, 0.02831232705838601, 0.03374016154787105, 0.03736386640115463]
6652 : 0.2375
LR:  0.001
replay buffer size:  154247
Time Taken :  1194.0  mins 16.46226692199707  seconds
[[[39401. 24140.  1439.     0.     0.     0.    93.    57.    55.    46.
      37.     0.]
  [13225.  9367.   863.   107.   128.   169.  1887.  1521.  1935.  1439.
    1175.   297.]
  [ 5281.  7180.  3229.  2575.  2938.  2244.  2144.   164.    52.    59.
      48.     0.]
  [ 3531.  4503.   446.   127.   119.   111.   112.     0.     0.     0.
       0.     0.]
  [ 4350.  4831.  2013.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.9
Q value #end_state_>_threshold:  1775
Q value #non_end_state_>threshold:  2554
maxi score:  0.47009999999999996
siam score:  -0.7290654
Scores:  {'0.167': 0.41409999999999997, '0.333': 0.2261, '0.5': 0.14609999999999998, '0.667': 0.0711, '0.833': 0.0431, '1.0': 0.032100000000000004}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.09880525325062434
Episodes: 7135, frames: 160012, time: 73766.83596611023
training steps:  18747
retraining steps:  0
RDN obj mus: [-0.9759466442108155, -0.9838393749773502, -0.97833085090518, -0.9696891074240208, -0.9679336745142937]
RDN obj sigmas: [0.016284354215183167, 0.015334794738927614, 0.02367486616841949, 0.033192918070245485, 0.0404247486462272]
7135 : 0.19583333333333333
LR:  0.001
replay buffer size:  164565
Time Taken :  1229.0  mins 26.835814952850342  seconds
[[[40841. 25024.  1487.     0.     0.     0.   111.    68.    61.    64.
      44.     0.]
  [13761.  9839.   913.   122.   139.   198.  2328.  1866.  2335.  1823.
    1446.   378.]
  [ 5580.  7785.  3759.  3038.  3488.  2673.  2540.   191.    66.    72.
      60.     0.]
  [ 3635.  4613.   475.   142.   133.   124.   126.     0.     0.     0.
       0.     0.]
  [ 4526.  4954.  2049.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.96
Q value #end_state_>_threshold:  2378
Q value #non_end_state_>threshold:  3779
maxi score:  0.5101
siam score:  -0.7624992
Scores:  {'0.167': 0.4321, '0.333': 0.2561, '0.5': 0.1661, '0.667': 0.0811, '0.833': 0.0451, '1.0': 0.022099999999999998}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.09457850991265054
Episodes: 7606, frames: 170253, time: 75837.16314005852
training steps:  19950
retraining steps:  0
RDN obj mus: [-0.9700658746898174, -0.9787743395388127, -0.9774684450507164, -0.9741744854986668, -0.9647321922719478]
RDN obj sigmas: [0.020862343762137026, 0.019364777539345058, 0.023740799360037507, 0.027599192585049517, 0.03721852071294488]
7606 : 0.23333333333333334
LR:  0.001
replay buffer size:  175251
Time Taken :  1263.0  mins 57.162997007369995  seconds
[[[42293. 25804.  1518.     0.     0.     0.   127.    79.    71.    72.
      49.     0.]
  [14335. 10298.   955.   140.   165.   227.  2759.  2262.  2783.  2175.
    1741.   489.]
  [ 5878.  8365.  4381.  3628.  4222.  3225.  3002.   222.    77.    81.
      68.     0.]
  [ 3705.  4681.   502.   157.   148.   136.   138.     0.     0.     0.
       0.     0.]
  [ 4599.  5018.  2072.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2921
Q value #non_end_state_>threshold:  4715
maxi score:  0.5511
siam score:  -0.6976944
Scores:  {'0.167': 0.4421, '0.333': 0.2641, '0.5': 0.18109999999999998, '0.667': 0.0891, '0.833': 0.042100000000000005, '1.0': 0.022099999999999998}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.09832975393004513
Episodes: 8032, frames: 180145, time: 78040.6486852169
training steps:  21108
retraining steps:  0
RDN obj mus: [-0.9609571376144886, -0.9778123217701912, -0.9727631288945675, -0.9674204847514629, -0.9698569072544575]
RDN obj sigmas: [0.020698591364434447, 0.016961762762787404, 0.02435852868560271, 0.03431952572504973, 0.03668129168031959]
8032 : 0.24166666666666667
LR:  0.001
replay buffer size:  185578
Time Taken :  1300.0  mins 40.64854979515076  seconds
[[[44067. 26688.  1561.     0.     0.     0.   140.    84.    83.    79.
      52.     0.]
  [14856. 10778.   982.   154.   176.   248.  3189.  2565.  3129.  2524.
    1963.   585.]
  [ 6131.  8952.  4971.  4160.  4771.  3670.  3399.   245.    84.    89.
      77.     0.]
  [ 3788.  4763.   523.   186.   169.   151.   156.     0.     0.     0.
       0.     0.]
  [ 4759.  5073.  2093.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
