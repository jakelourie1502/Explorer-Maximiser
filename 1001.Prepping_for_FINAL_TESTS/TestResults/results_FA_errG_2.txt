EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.014805882352941176
siam score:  -0.027164937052673296
Scores:  {'0.167': 0.08343333333333333, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.08833529411764707, '1.0': 0.04555454545454546}
best rdn ma / adv:  0.833 0.833
best rdn adv:  0.2588322571730334
Episodes: 75, frames: 1296, time: 40.627535820007324
training steps:  9
retraining steps:  0
RDN obj mus: [-0.038280475573254126, -0.027491792226513673, 0.0, 0.0, 0.0]
RDN obj sigmas: [0.006178521897914639, 0.0017720534579232447, 0.0, 0.0, 0.0]
75 : 0.04666666666666667
LR:  8e-06
replay buffer size:  1884
Time Taken :  0.0  mins 40.62736201286316  seconds
[[[287. 130.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
  [203. 107.  29.   0.   1.   0.   0.   0.   0.   0.   0.   0.]
  [108.  74.  25.   4.   1.   0.   0.   0.   0.   0.   0.   0.]
  [ 62.  36.  12.   1.   0.   0.   0.   0.   0.   0.   0.   0.]
  [ 71.  38.   7.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.1297296296296296
siam score:  -0.66021913
Scores:  {'0.167': 0.20992142857142856, '0.333': 0.15989381443298967, '0.5': 0.1647341463414634, '0.667': 0.14509999999999998, '0.833': 0.15206078431372547, '1.0': 0.140725}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.4279512055441033
Episodes: 719, frames: 10042, time: 1756.6367909908295
training steps:  1213
retraining steps:  0
RDN obj mus: [-0.945714981162548, -0.9484025886118412, -0.9317803106069564, -0.9186344968073943, -0.900457952671662]
RDN obj sigmas: [0.027194332129117964, 0.030635301585830367, 0.041463270072837094, 0.047168439034454, 0.0557562435987692]
719 : 0.32916666666666666
LR:  0.001
replay buffer size:  10813
Time Taken :  29.0  mins 16.636618852615356  seconds
[[[2127. 1114.  225.    0.    0.    0.    1.    0.    0.    0.    0.
      0.]
  [1447.  738.  160.    3.    2.    0.    1.    0.    0.    0.    0.
      0.]
  [ 706.  555.  133.   32.   11.    5.    6.    1.    0.    0.    0.
      0.]
  [ 425.  399.   79.   10.    2.    0.    2.    0.    0.    0.    0.
      0.]
  [ 417.  488.  234.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.2721364741641337
siam score:  -0.84910965
Scores:  {'0.167': 0.28436395939086295, '0.333': 0.2234502538071066, '0.5': 0.2472264367816092, '0.667': 0.1764157894736842, '0.833': 0.1834333333333333, '1.0': 0.17241638418079094}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 1367, frames: 20086, time: 3948.6009080410004
training steps:  2364
retraining steps:  0
RDN obj mus: [-0.9513327508926391, -0.9681928464055062, -0.9600749143779278, -0.9617572330534458, -0.9438766947031021]
RDN obj sigmas: [0.02794793066312394, 0.026219778950924352, 0.037575155782698884, 0.03512625140669303, 0.05181075514516375]
1367 : 0.25
LR:  0.001
replay buffer size:  21168
Time Taken :  65.0  mins 48.60073494911194  seconds
[[[3191. 1636.  271.    0.    0.    0.    1.    0.    0.    0.    0.
      0.]
  [2433. 1307.  227.   17.   15.   12.    7.    2.    0.    0.    0.
      0.]
  [1447. 1323.  420.  309.  426.  315.  108.   15.    0.    0.    0.
      0.]
  [ 997. 1007.  136.   25.   18.   11.    6.    0.    0.    0.    0.
      0.]
  [1067. 1357.  613.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.30898888888888887
siam score:  -0.8373474
Scores:  {'0.167': 0.31464545454545456, '0.333': 0.25828181818181817, '0.5': 0.23005780590717298, '0.667': 0.16610790513833992, '0.833': 0.1420753086419753, '1.0': 0.1325110671936759}
best rdn ma / adv:  0.167 0.333
best rdn adv:  0.005589168145443477
Episodes: 1880, frames: 30093, time: 6136.672152996063
training steps:  3539
retraining steps:  0
RDN obj mus: [-0.9622790630698204, -0.9708904642522335, -0.9707428532004356, -0.9557448365092277, -0.9381990790069104]
RDN obj sigmas: [0.023948042698867064, 0.020649153477083886, 0.023024372210496066, 0.034479624858729706, 0.04459975167758342]
1880 : 0.1875
LR:  0.001
replay buffer size:  31409
Time Taken :  102.0  mins 16.671982049942017  seconds
[[[5890. 3066.  376.    0.    0.    0.    4.    3.    4.    1.    1.
      0.]
  [3233. 1795.  271.   26.   23.   20.   79.   86.   48.   50.   17.
      1.]
  [1896. 1816.  634.  473.  547.  401.  183.   26.    6.    2.    0.
      0.]
  [1381. 1417.  182.   33.   26.   14.    9.    0.    0.    0.    0.
      0.]
  [1474. 1853.  846.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.3731
siam score:  -0.84105116
Scores:  {'0.167': 0.3303752293577982, '0.333': 0.25745294117647055, '0.5': 0.20960704225352111, '0.667': 0.14488114478114478, '0.833': 0.12254897959183673, '1.0': 0.11284509803921569}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.005412046619707592
Episodes: 2281, frames: 40057, time: 8483.359540939331
training steps:  4698
retraining steps:  0
RDN obj mus: [-0.9577298993349075, -0.9705337717831135, -0.9658676126658916, -0.9569568634837866, -0.9521279440820217]
RDN obj sigmas: [0.027110665279567903, 0.026757322394994214, 0.027873879366747168, 0.04443944745546439, 0.0349100758289572]
2281 : 0.22083333333333333
LR:  0.001
replay buffer size:  41600
Time Taken :  141.0  mins 23.35936975479126  seconds
[[[9384. 4804.  487.    0.    0.    0.    7.    4.    7.    6.    5.
      0.]
  [3977. 2153.  304.   32.   25.   31.  182.  175.  174.  140.   64.
      3.]
  [2225. 2177.  808.  606.  675.  495.  287.   33.   10.    3.    2.
      0.]
  [1617. 1674.  195.   40.   34.   17.   14.    0.    0.    0.    0.
      0.]
  [1723. 2169. 1008.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  31
maxi score:  0.41809999999999997
siam score:  -0.8281903
Scores:  {'0.167': 0.34130734908136484, '0.333': 0.2545529262086514, '0.5': 0.18666716417910448, '0.667': 0.1309139534883721, '0.833': 0.11219439528023599, '1.0': 0.10152857142857143}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.008782978514268321
Episodes: 2645, frames: 50030, time: 10878.815079927444
training steps:  5869
retraining steps:  0
RDN obj mus: [-0.9493156713843346, -0.9645837307393551, -0.9607182862341404, -0.9576034887909889, -0.9321857211172581]
RDN obj sigmas: [0.026575456142597785, 0.025364231263961794, 0.03203534184792195, 0.038559719292023696, 0.05180878280229445]
2645 : 0.20416666666666666
LR:  0.001
replay buffer size:  51906
Time Taken :  181.0  mins 18.81491494178772  seconds
[[[13334.  6061.   580.     0.     0.     0.    11.     6.     8.    11.
       5.     0.]
  [ 5015.  2465.   346.    35.    28.    39.   250.   235.   253.   206.
      89.     6.]
  [ 2673.  2508.   937.   702.   748.   569.   357.    35.    13.     8.
       4.     0.]
  [ 1863.  1907.   217.    51.    37.    20.    18.     0.     0.     0.
       0.     0.]
  [ 2105.  2487.  1143.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  32
maxi score:  0.4231
siam score:  -0.81413954
Scores:  {'0.167': 0.3528315914489311, '0.333': 0.2495199535962877, '0.5': 0.17625176151761515, '0.667': 0.12307297297297298, '0.833': 0.10364223433242507, '1.0': 0.09508680738786279}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.008110930026369161
Episodes: 2891, frames: 60236, time: 13301.330717802048
training steps:  7057
retraining steps:  0
RDN obj mus: [-0.976960813432932, -0.9813482081592083, -0.9809713127255439, -0.9724635758042336, -0.9342499751567841]
RDN obj sigmas: [0.015330397651463355, 0.015473652632248513, 0.018719167935389202, 0.023894180050231376, 0.05828932528254079]
2891 : 0.2125
LR:  0.001
replay buffer size:  62316
Time Taken :  221.0  mins 41.33055305480957  seconds
[[[17603.  7023.   627.     0.     0.     0.    11.     6.     9.    12.
       5.     0.]
  [ 6686.  2763.   370.    39.    30.    44.   264.   240.   262.   215.
      90.     7.]
  [ 3543.  2804.  1028.   752.   786.   589.   379.    38.    13.     8.
       4.     0.]
  [ 2232.  2106.   233.    54.    40.    21.    19.     0.     0.     0.
       0.     0.]
  [ 2412.  2734.  1244.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  6
Q value #non_end_state_>threshold:  36
maxi score:  0.4311
siam score:  -0.8157593
Scores:  {'0.167': 0.35486718403547673, '0.333': 0.2408809110629067, '0.5': 0.17098607594936707, '0.667': 0.11819045226130653, '0.833': 0.09883417721518988, '1.0': 0.0890423076923077}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.007389525192293058
Episodes: 3115, frames: 70102, time: 15665.786082029343
training steps:  8221
retraining steps:  0
RDN obj mus: [-0.9821598377227784, -0.9820589817285538, -0.9820185974001885, -0.9756896711707115, -0.955676566028595]
RDN obj sigmas: [0.010279883252134695, 0.013918986843339021, 0.013710527728100238, 0.02033870779741388, 0.04258668404644114]
3115 : 0.17916666666666667
LR:  0.001
replay buffer size:  72395
Time Taken :  261.0  mins 5.78590989112854  seconds
[[[21290.  8006.   666.     0.     0.     0.    13.     6.    10.    12.
       5.     0.]
  [ 8649.  3040.   393.    47.    33.    48.   300.   275.   289.   227.
      92.     8.]
  [ 4624.  3079.  1129.   805.   824.   611.   398.    40.    15.     8.
       4.     0.]
  [ 2553.  2270.   256.    57.    44.    22.    19.     0.     0.     0.
       0.     0.]
  [ 2594.  2905.  1321.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  6
Q value #non_end_state_>threshold:  38
maxi score:  0.4281
siam score:  -0.78019744
Scores:  {'0.167': 0.35040549898167006, '0.333': 0.23444343434343434, '0.5': 0.16445185185185185, '0.667': 0.11411425178147269, '0.833': 0.09143489461358315, '1.0': 0.08124035087719299}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.006741321228056825
Episodes: 3371, frames: 80059, time: 18025.503630161285
training steps:  9386
retraining steps:  0
RDN obj mus: [-0.9779746843516827, -0.9811827673733234, -0.9803823099076748, -0.9748295692622662, -0.961744730257988]
RDN obj sigmas: [0.014005154309854856, 0.012768607415171837, 0.01649272528251426, 0.023313610184555, 0.044167792803064806]
3371 : 0.14166666666666666
LR:  0.001
replay buffer size:  82663
Time Taken :  300.0  mins 25.503458976745605  seconds
[[[24443.  8978.   717.     0.     0.     0.    16.     7.    13.    13.
       6.     0.]
  [10474.  3436.   430.    56.    39.    52.   373.   311.   324.   253.
     114.     8.]
  [ 5949.  3394.  1254.   883.   881.   654.   455.    43.    16.     8.
       5.     0.]
  [ 2986.  2411.   274.    66.    47.    25.    23.     0.     0.     0.
       0.     0.]
  [ 2804.  3051.  1396.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  6
Q value #non_end_state_>threshold:  38
maxi score:  0.41209999999999997
siam score:  -0.81561494
Scores:  {'0.167': 0.3701, '0.333': 0.24609999999999999, '0.5': 0.15879565217391303, '0.667': 0.10507835497835498, '0.833': 0.08451558441558442, '1.0': 0.07585757575757576}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.00621018682827053
Episodes: 3644, frames: 90097, time: 20405.737276792526
training steps:  10560
retraining steps:  0
RDN obj mus: [-0.9668988699316978, -0.9807977775275707, -0.9814441855370999, -0.9678178997635841, -0.9379557938337326]
RDN obj sigmas: [0.018913820260821158, 0.01807201532560366, 0.02003128010234864, 0.03493426110287397, 0.05748496572074847]
3644 : 0.17083333333333334
LR:  0.001
replay buffer size:  93083
Time Taken :  340.0  mins 5.737114667892456  seconds
[[[27654.  9978.   780.     0.     0.     0.    18.     7.    14.    15.
       6.     0.]
  [12034.  3800.   467.    60.    45.    55.   402.   334.   338.   257.
     116.     8.]
  [ 7011.  3707.  1361.   945.   929.   685.   483.    47.    17.     8.
       6.     0.]
  [ 3620.  2594.   302.    73.    51.    27.    24.     0.     0.     0.
       0.     0.]
  [ 3441.  3257.  1477.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  6
Q value #non_end_state_>threshold:  41
maxi score:  0.4031
siam score:  -0.82004195
Scores:  {'0.167': 0.3921, '0.333': 0.2501, '0.5': 0.1533258064516129, '0.667': 0.10112040816326531, '0.833': 0.0798979797979798, '1.0': 0.07010000000000001}
best rdn ma / adv:  0.167 0.667
best rdn adv:  0.006273556081620228
Episodes: 3906, frames: 100065, time: 22804.61265206337
training steps:  11738
retraining steps:  0
RDN obj mus: [-0.9691694453060627, -0.9704893493771553, -0.9769152408719063, -0.9718189599514008, -0.9429896485567093]
RDN obj sigmas: [0.024215931869974082, 0.021196064852713786, 0.02072200744730551, 0.025332549371536617, 0.055964118548582756]
3906 : 0.12916666666666668
LR:  0.001
replay buffer size:  103366
Time Taken :  380.0  mins 4.612480878829956  seconds
[[[30608. 11026.   831.     0.     0.     0.    22.     9.    15.    15.
       6.     0.]
  [13642.  4217.   499.    65.    49.    63.   446.   345.   358.   271.
     123.     9.]
  [ 8049.  4048.  1513.  1012.   978.   744.   540.    50.    17.     9.
       6.     0.]
  [ 4144.  2751.   327.    79.    53.    32.    34.     0.     0.     0.
       0.     0.]
  [ 4114.  3484.  1556.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  6
Q value #non_end_state_>threshold:  41
maxi score:  0.4021
siam score:  -0.8289583
Scores:  {'0.167': 0.3961, '0.333': 0.24209999999999998, '0.5': 0.1561, '0.667': 0.1021, '0.833': 0.0761, '1.0': 0.0621}
best rdn ma / adv:  0.167 0.667
best rdn adv:  0.006148084959987824
Episodes: 4157, frames: 110116, time: 25222.406031847
training steps:  12916
retraining steps:  0
RDN obj mus: [-0.9756889677286148, -0.9790184542536735, -0.9793256138682366, -0.9707278310954571, -0.9614312992691993]
RDN obj sigmas: [0.01306666019466523, 0.011178651702483666, 0.014083862215387348, 0.03266644971157293, 0.04663097177765116]
4157 : 0.18333333333333332
LR:  0.001
replay buffer size:  113950
Time Taken :  420.0  mins 22.40585684776306  seconds
[[[33377. 11729.   876.     0.     0.     0.    25.    11.    15.    15.
       6.     0.]
  [15236.  4592.   537.    71.    53.    68.   484.   403.   367.   271.
     123.     9.]
  [ 9305.  4341.  1603.  1065.  1010.   763.   587.    52.    17.     9.
       6.     0.]
  [ 4923.  2965.   343.    87.    55.    33.    36.     0.     0.     0.
       0.     0.]
  [ 5113.  3735.  1643.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  6
Q value #non_end_state_>threshold:  41
maxi score:  0.3961
siam score:  -0.801165
Scores:  {'0.167': 0.3951, '0.333': 0.2271, '0.5': 0.14909999999999998, '0.667': 0.0911, '0.833': 0.0711, '1.0': 0.048100000000000004}
best rdn ma / adv:  0.167 0.667
best rdn adv:  0.006148084959987824
Episodes: 4418, frames: 120085, time: 27409.04509282112
training steps:  14090
retraining steps:  0
RDN obj mus: [-0.9831191058158875, -0.9850433136105538, -0.9818906955897808, -0.9725302056968212, -0.9315158809840679]
RDN obj sigmas: [0.009843327048940566, 0.013024653875241128, 0.021087363987874388, 0.033978366877432505, 0.06917318240054261]
4418 : 0.175
LR:  0.001
replay buffer size:  124194
Time Taken :  456.0  mins 49.04491996765137  seconds
[[[36602. 12565.   931.     0.     0.     0.    26.    11.    15.    15.
       6.     0.]
  [16945.  5001.   588.    78.    56.    69.   487.   404.   367.   271.
     123.     9.]
  [10521.  4643.  1689.  1091.  1016.   766.   589.    52.    17.     9.
       6.     0.]
  [ 5557.  3153.   374.    94.    55.    33.    36.     0.     0.     0.
       0.     0.]
  [ 5731.  3942.  1724.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  6
Q value #non_end_state_>threshold:  41
maxi score:  0.3831
siam score:  -0.78997177
Scores:  {'0.167': 0.3951, '0.333': 0.2221, '0.5': 0.1271, '0.667': 0.0721, '0.833': 0.0621, '1.0': 0.0281}
best rdn ma / adv:  0.167 0.667
best rdn adv:  0.006148084959987824
Episodes: 4638, frames: 130254, time: 52821.408079862595
training steps:  15259
retraining steps:  0
RDN obj mus: [-0.983664811629057, -0.982534103167057, -0.9818138385117055, -0.9737906768620014, -0.9591038484334946]
RDN obj sigmas: [0.008316927382620663, 0.009997210844725376, 0.01569941637634228, 0.023185896105881513, 0.041280304097406254]
4638 : 0.1625
LR:  0.001
replay buffer size:  134636
Time Taken :  880.0  mins 21.407907009124756  seconds
[[[39543. 13261.   971.     0.     0.     0.    26.    11.    15.    15.
       6.     0.]
  [18720.  5484.   626.    82.    57.    69.   487.   404.   367.   271.
     123.     9.]
  [11777.  5007.  1748.  1117.  1026.   774.   591.    53.    17.     9.
       6.     0.]
  [ 6350.  3379.   397.    99.    56.    34.    37.     0.     0.     0.
       0.     0.]
  [ 6668.  4136.  1788.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  6
Q value #non_end_state_>threshold:  41
maxi score:  0.3811
siam score:  -0.7845461
Scores:  {'0.167': 0.3931, '0.333': 0.21109999999999998, '0.5': 0.1021, '0.667': 0.0531, '0.833': 0.0361, '1.0': 0.0211}
best rdn ma / adv:  0.167 0.667
best rdn adv:  0.006148084959987824
Episodes: 4872, frames: 140095, time: 55064.70408177376
training steps:  16418
retraining steps:  0
RDN obj mus: [-0.9795227941274643, -0.9705563530862331, -0.9706826914787292, -0.9569789644479751, -0.9244347996354103]
RDN obj sigmas: [0.013636838247229352, 0.01652496255506244, 0.0233275237259629, 0.04070785132088589, 0.08646207482808661]
4872 : 0.13333333333333333
LR:  0.001
replay buffer size:  144907
Time Taken :  917.0  mins 44.7039258480072  seconds
[[[42815. 14117.  1016.     0.     0.     0.    30.    12.    15.    15.
       6.     0.]
  [20278.  5961.   680.    88.    57.    72.   506.   417.   371.   271.
     123.     9.]
  [12924.  5374.  1851.  1157.  1049.   797.   618.    56.    17.     9.
       6.     0.]
  [ 6899.  3581.   415.   103.    58.    38.    37.     0.     0.     0.
       0.     0.]
  [ 7234.  4292.  1849.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  6
Q value #non_end_state_>threshold:  41
maxi score:  0.3861
siam score:  -0.7807551
Scores:  {'0.167': 0.3931, '0.333': 0.2031, '0.5': 0.0911, '0.667': 0.0451, '0.833': 0.022099999999999998, '1.0': 0.0171}
best rdn ma / adv:  0.167 0.667
best rdn adv:  0.006148084959987824
Episodes: 5099, frames: 150089, time: 71555.76922082901
training steps:  17590
retraining steps:  0
RDN obj mus: [-0.9783545459151268, -0.9805758439719677, -0.9768211905241012, -0.9695644914805889, -0.9600247053802013]
RDN obj sigmas: [0.013045311756229399, 0.016643545359290447, 0.0219253655398813, 0.03120762688023486, 0.037158245195038936]
5099 : 0.1375
LR:  0.001
replay buffer size:  155293
Time Taken :  1192.0  mins 35.769047021865845  seconds
[[[46100. 14921.  1057.     0.     0.     0.    31.    12.    15.    15.
       6.     0.]
  [22059.  6489.   732.    94.    58.    72.   508.   417.   371.   271.
     123.     9.]
  [13865.  5747.  1987.  1180.  1056.   800.   623.    56.    17.     9.
       6.     0.]
  [ 7543.  3791.   435.   107.    60.    40.    37.     0.     0.     0.
       0.     0.]
  [ 7901.  4455.  1915.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
