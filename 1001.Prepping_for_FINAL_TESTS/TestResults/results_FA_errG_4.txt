EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.021116181992266964
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.050100000000000006}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.15365352680468736
Episodes: 72, frames: 1346, time: 41.18747687339783
training steps:  8
retraining steps:  0
RDN obj mus: [-0.08789472879978379, -0.0883284972940005, -0.0804440254966418, 0.0, 0.0]
RDN obj sigmas: [0.011310930440762552, 0.00613770487650914, 0.02844384763549751, 0.0, 0.0]
72 : 0.006944444444444444
LR:  7e-06
replay buffer size:  1824
Time Taken :  0.0  mins 41.18730020523071  seconds
[[[327. 131.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
  [199.  99.  23.   3.   0.   1.   0.   0.   0.   0.   0.   0.]
  [102.  86.  32.   7.   2.   2.   2.   1.   0.   0.   0.   0.]
  [ 78.  58.  18.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
  [ 45.  32.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.18
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.07678711656441718
siam score:  -0.57105035
Scores:  {'0.167': 0.0976609756097561, '0.333': 0.15356534653465345, '0.5': 0.10214081632653062, '0.667': 0.08343333333333333, '0.833': 0.08562631578947369, '1.0': 0.050732911392405065}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.37005293645806026
Episodes: 646, frames: 10175, time: 1277.9267208576202
training steps:  1192
retraining steps:  0
RDN obj mus: [-0.9474777173340321, -0.9237878847360611, -0.9252699343383313, -0.901093406669635, -0.8771436847296337]
RDN obj sigmas: [0.024377044992457363, 0.03369615879022606, 0.035070685830029744, 0.04661224216417045, 0.05655224277576559]
646 : 0.2375
LR:  0.001
replay buffer size:  10866
Time Taken :  21.0  mins 17.926539182662964  seconds
[[[2705. 1297.  255.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]
  [1537.  774.  182.    4.    1.    1.    0.    0.    0.    0.    0.
      0.]
  [ 732.  409.  116.   27.   10.    4.    3.    1.    0.    0.    0.
      0.]
  [ 419.  265.   66.    7.    2.    0.    1.    0.    0.    0.    0.
      0.]
  [ 318.  267.  126.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  8
maxi score:  0.199388256227758
siam score:  -0.8767264
Scores:  {'0.167': 0.24384999999999998, '0.333': 0.2422875, '0.5': 0.20598235294117645, '0.667': 0.17911234567901232, '0.833': 0.16081428571428572, '1.0': 0.11996301369863013}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.39886202124054604
Episodes: 1234, frames: 20140, time: 2875.02561879158
training steps:  2360
retraining steps:  0
RDN obj mus: [-0.9424360338389873, -0.9626381700634956, -0.9584845207214355, -0.9613644056975842, -0.9376681365142123]
RDN obj sigmas: [0.03564241585145649, 0.02640040978901847, 0.031451297171102253, 0.03174125537232699, 0.056231678574714006]
1234 : 0.225
LR:  0.001
replay buffer size:  21063
Time Taken :  47.0  mins 55.025434255599976  seconds
[[[4045. 2058.  340.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]
  [2577. 1269.  232.    9.    7.    4.    0.    0.    0.    0.    0.
      0.]
  [1545.  938.  255.  126.   73.   50.   20.    3.    0.    0.    0.
      0.]
  [1256.  821.  120.   12.    6.    5.    3.    0.    0.    0.    0.
      0.]
  [1406. 1233.  493.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.48
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  18
maxi score:  0.27142701421800947
siam score:  -0.8343447
Scores:  {'0.167': 0.2873340425531915, '0.333': 0.209055223880597, '0.5': 0.16870465116279068, '0.667': 0.13646363636363634, '0.833': 0.12458132780082988, '1.0': 0.09579377990430622}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.007354168612425627
Episodes: 1748, frames: 30117, time: 4516.569925069809
training steps:  3533
retraining steps:  0
RDN obj mus: [-0.9614508820652962, -0.9659570969641209, -0.9653819613873958, -0.9576780487298966, -0.9438714662611485]
RDN obj sigmas: [0.02480715349463385, 0.022214721183822114, 0.029402981022702956, 0.03374379573265895, 0.042864385040866725]
1748 : 0.16666666666666666
LR:  0.001
replay buffer size:  31292
Time Taken :  75.0  mins 16.569749116897583  seconds
[[[6027. 3516.  442.    0.    0.    0.    5.    7.    5.    6.    3.
      0.]
  [3292. 1817.  295.   25.   15.   27.  101.   93.   67.   68.   23.
      2.]
  [2060. 1504.  618.  442.  342.  289.  170.   23.    0.    3.    1.
      0.]
  [1636. 1119.  149.   26.   23.   17.   11.    0.    0.    0.    0.
      0.]
  [1832. 1606.  662.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.52
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  23
maxi score:  0.3191
siam score:  -0.8432876
Scores:  {'0.167': 0.2870415807560137, '0.333': 0.20041055900621116, '0.5': 0.14157909967845658, '0.667': 0.11182161172161173, '0.833': 0.09851269841269841, '1.0': 0.08788625954198473}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.19332618323742207
Episodes: 2175, frames: 40051, time: 6219.422870874405
training steps:  4705
retraining steps:  0
RDN obj mus: [-0.9713088349223137, -0.9722798664867878, -0.9709781391322613, -0.9643605186194182, -0.9451183278739452]
RDN obj sigmas: [0.02043496945224887, 0.02718605296605474, 0.028975094216057887, 0.031925168196289495, 0.05583227129912304]
2175 : 0.16666666666666666
LR:  0.001
replay buffer size:  41490
Time Taken :  103.0  mins 39.42269206047058  seconds
[[[8660. 5533.  567.    0.    0.    0.    7.   12.   10.   10.    7.
      0.]
  [3883. 2357.  344.   35.   22.   47.  209.  196.  210.  164.   77.
      6.]
  [2365. 1951.  899.  623.  508.  427.  274.   33.    8.    7.    3.
      0.]
  [1897. 1344.  176.   32.   27.   26.   14.    0.    0.    0.    0.
      0.]
  [2195. 1933.  778.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  19
Q value #non_end_state_>threshold:  40
maxi score:  0.3921
siam score:  -0.8299101
Scores:  {'0.167': 0.30037173913043475, '0.333': 0.19575217391304348, '0.5': 0.13695636856368562, '0.667': 0.09682619047619048, '0.833': 0.09769358288770054, '1.0': 0.06875671641791045}
best rdn ma / adv:  0.167 0.833
best rdn adv:  0.02700468477144496
Episodes: 2671, frames: 50098, time: 7860.196306943893
training steps:  5869
retraining steps:  0
RDN obj mus: [-0.9724223985552788, -0.9813725477397441, -0.9752435928463936, -0.9694053066313266, -0.9549822030067444]
RDN obj sigmas: [0.020488013786486986, 0.021046926874390994, 0.02672331487276698, 0.03636217781121826, 0.04429098057353773]
2671 : 0.19166666666666668
LR:  0.001
replay buffer size:  51812
Time Taken :  131.0  mins 0.19612431526184082  seconds
[[[10608.  7237.   684.     0.     0.     0.    15.    15.    12.    14.
       7.     0.]
  [ 4564.  2990.   405.    44.    31.    61.   337.   268.   278.   230.
     117.    15.]
  [ 2826.  2493.  1191.   862.   701.   585.   413.    42.    11.     9.
       4.     0.]
  [ 2330.  1685.   209.    48.    40.    31.    26.     0.     0.     0.
       0.     0.]
  [ 2662.  2384.   943.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  31
Q value #non_end_state_>threshold:  48
maxi score:  0.40809999999999996
siam score:  -0.76622206
Scores:  {'0.167': 0.31012331002331, '0.333': 0.20336086956521737, '0.5': 0.12920798122065727, '0.667': 0.08425841584158417, '0.833': 0.09370189573459715, '1.0': 0.061168702290076336}
best rdn ma / adv:  0.167 0.833
best rdn adv:  0.03278007383879764
Episodes: 3127, frames: 60084, time: 9805.966601848602
training steps:  7045
retraining steps:  0
RDN obj mus: [-0.9696232231259346, -0.9730497674405575, -0.9720371728777886, -0.9638508909523487, -0.9512335804879666]
RDN obj sigmas: [0.019757120225795705, 0.024353741921148905, 0.0329717816003007, 0.042999945061102406, 0.059121143745099684]
3127 : 0.18333333333333332
LR:  0.001
replay buffer size:  62057
Time Taken :  163.0  mins 25.96642827987671  seconds
[[[12858.  8724.   752.     0.     0.     0.    25.    16.    15.    17.
       8.     0.]
  [ 5332.  3648.   460.    58.    43.    78.   449.   314.   320.   266.
     137.    22.]
  [ 3289.  3108.  1567.  1112.   887.   784.   560.    54.    14.    11.
       4.     0.]
  [ 2655.  2046.   249.    64.    56.    43.    35.     0.     0.     0.
       0.     0.]
  [ 3007.  2776.  1094.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  58
Q value #non_end_state_>threshold:  57
maxi score:  0.3981
siam score:  -0.7767006
Scores:  {'0.167': 0.319772131147541, '0.333': 0.2191, '0.5': 0.12668227848101266, '0.667': 0.08053478260869565, '0.833': 0.08630689655172415, '1.0': 0.056892873051224944}
best rdn ma / adv:  0.167 0.833
best rdn adv:  0.031176901419816553
Episodes: 3568, frames: 70140, time: 11732.266451835632
training steps:  8233
retraining steps:  0
RDN obj mus: [-0.9680719312548638, -0.9829537187576294, -0.9759107465565204, -0.9716114293634891, -0.9486593842566013]
RDN obj sigmas: [0.02246060811971229, 0.013848512409519875, 0.023791758970447278, 0.034574150741654444, 0.04301558914613421]
3568 : 0.15416666666666667
LR:  0.001
replay buffer size:  72397
Time Taken :  195.0  mins 32.266287088394165  seconds
[[[15336.  9962.   813.     0.     0.     0.    30.    19.    16.    20.
       9.     0.]
  [ 6153.  4278.   521.    77.    55.    90.   535.   379.   368.   342.
     184.    28.]
  [ 3812.  3741.  1874.  1323.  1032.   901.   664.    65.    14.    16.
       6.     0.]
  [ 3100.  2391.   287.    78.    66.    52.    45.     0.     0.     0.
       0.     0.]
  [ 3449.  3193.  1248.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  68
Q value #non_end_state_>threshold:  62
maxi score:  0.3871
siam score:  -0.7807013
Scores:  {'0.167': 0.35309999999999997, '0.333': 0.23809999999999998, '0.5': 0.1261, '0.667': 0.0751, '0.833': 0.0861, '1.0': 0.0531}
best rdn ma / adv:  0.167 0.833
best rdn adv:  0.033814467279933036
Episodes: 3955, frames: 80081, time: 13453.435766935349
training steps:  9387
retraining steps:  0
RDN obj mus: [-0.9793811609864235, -0.9821114282727241, -0.9772512339353562, -0.9612991846323014, -0.9122339450955391]
RDN obj sigmas: [0.02070801281018266, 0.019960301568772848, 0.02657348309654393, 0.05534464909869786, 0.0907301446091895]
3955 : 0.19583333333333333
LR:  0.001
replay buffer size:  82579
Time Taken :  224.0  mins 13.435591220855713  seconds
[[[18337. 11367.   882.     0.     0.     0.    33.    21.    18.    23.
      10.     0.]
  [ 7142.  5026.   596.    87.    63.    97.   558.   404.   408.   411.
     225.    31.]
  [ 4275.  4275.  2063.  1421.  1096.   958.   698.    68.    14.    18.
       7.     0.]
  [ 3450.  2709.   327.    88.    76.    54.    47.     0.     0.     0.
       0.     0.]
  [ 3780.  3586.  1377.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  91
Q value #non_end_state_>threshold:  73
maxi score:  0.3771
siam score:  -0.7701296
Scores:  {'0.167': 0.3771, '0.333': 0.2321, '0.5': 0.1281, '0.667': 0.0721, '0.833': 0.0621, '1.0': 0.0521}
best rdn ma / adv:  0.167 0.833
best rdn adv:  0.033814467279933036
Episodes: 4417, frames: 90086, time: 15443.159697055817
training steps:  10560
retraining steps:  0
RDN obj mus: [-0.9838983941435814, -0.9883273392736912, -0.9827664528906346, -0.978564134901762, -0.972623518037796]
RDN obj sigmas: [0.01172333250281803, 0.016164547334831234, 0.025982976922743133, 0.029884863319455435, 0.02925684129980122]
4417 : 0.1875
LR:  0.001
replay buffer size:  92878
Time Taken :  257.0  mins 23.159523248672485  seconds
[[[20502. 12529.   946.     0.     0.     0.    40.    27.    20.    25.
      12.     0.]
  [ 8073.  5736.   650.   112.    73.   109.   655.   488.   466.   457.
     277.    39.]
  [ 4806.  4917.  2406.  1666.  1239.  1077.   822.    82.    14.    20.
       8.     0.]
  [ 3855.  3113.   363.   106.    93.    62.    55.     0.     0.     0.
       0.     0.]
  [ 4148.  4040.  1541.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  184
Q value #non_end_state_>threshold:  145
maxi score:  0.3861
siam score:  -0.7612604
Scores:  {'0.167': 0.3781, '0.333': 0.24609999999999999, '0.5': 0.1111, '0.667': 0.032100000000000004, '0.833': 0.0461, '1.0': 0.033100000000000004}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.04303659471991477
Episodes: 4912, frames: 100035, time: 17889.85442185402
training steps:  11730
retraining steps:  0
RDN obj mus: [-0.9842162224650383, -0.98580059248209, -0.979901166254282, -0.97218366740942, -0.9689271584928035]
RDN obj sigmas: [0.01669744277301877, 0.017491566705903263, 0.028655120816489077, 0.03824433910405848, 0.03554235194721399]
4912 : 0.24166666666666667
LR:  0.001
replay buffer size:  103103
Time Taken :  298.0  mins 9.85424518585205  seconds
[[[22450. 13593.  1007.     0.     0.     0.    46.    32.    22.    27.
      19.     0.]
  [ 8981.  6378.   692.   134.    79.   118.   751.   575.   553.   586.
     392.    65.]
  [ 5325.  5567.  2723.  1896.  1402.  1231.   949.    94.    18.    24.
       9.     0.]
  [ 4243.  3530.   415.   125.   105.    70.    67.     0.     0.     0.
       0.     0.]
  [ 4573.  4535.  1722.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.54
Q value #end_state_>_threshold:  274
Q value #non_end_state_>threshold:  242
maxi score:  0.3991
siam score:  -0.7633446
Scores:  {'0.167': 0.3961, '0.333': 0.2721, '0.5': 0.0981, '0.667': 0.034100000000000005, '0.833': 0.0431, '1.0': 0.0281}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.05533276463989041
Episodes: 5395, frames: 110144, time: 20359.046237945557
training steps:  12911
retraining steps:  0
RDN obj mus: [-0.9837369885385037, -0.9854143029808998, -0.9814203560948372, -0.974351279014349, -0.9606569517850876]
RDN obj sigmas: [0.014663479450392317, 0.015744566931375086, 0.02372749571778239, 0.0339300745998578, 0.04503518967867218]
5395 : 0.23333333333333334
LR:  0.001
replay buffer size:  113530
Time Taken :  339.0  mins 19.04607105255127  seconds
[[[24686. 14836.  1092.     0.     0.     0.    50.    39.    24.    29.
      23.     0.]
  [10087.  7006.   749.   143.    87.   126.   858.   687.   654.   669.
     472.    87.]
  [ 5971.  6097.  2951.  2069.  1527.  1355.  1081.   102.    19.    30.
      11.     0.]
  [ 4628.  3891.   440.   152.   115.    76.    75.     0.     0.     0.
       0.     0.]
  [ 4925.  4931.  1899.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.52
Q value #end_state_>_threshold:  434
Q value #non_end_state_>threshold:  433
maxi score:  0.41509999999999997
siam score:  -0.7631962
Scores:  {'0.167': 0.4031, '0.333': 0.2991, '0.5': 0.1191, '0.667': 0.0441, '0.833': 0.0441, '1.0': 0.0241}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.0704285623274034
Episodes: 5859, frames: 120154, time: 22772.860201835632
training steps:  14082
retraining steps:  0
RDN obj mus: [-0.9820838657736778, -0.9894852145195008, -0.9835478442490101, -0.9758422046482563, -0.9669943309903145]
RDN obj sigmas: [0.019056058897450268, 0.01652755958710918, 0.0251688342413415, 0.03563890533088687, 0.03433616178380721]
5859 : 0.25416666666666665
LR:  0.001
replay buffer size:  123892
Time Taken :  379.0  mins 32.860029220581055  seconds
[[[26975. 16036.  1142.     0.     0.     0.    60.    43.    28.    31.
      31.     0.]
  [10917.  7623.   801.   162.    98.   132.  1057.   846.   813.   852.
     660.   123.]
  [ 6369.  6629.  3248.  2321.  1723.  1531.  1306.   115.    30.    40.
      18.     0.]
  [ 4890.  4185.   470.   173.   129.    82.    84.     0.     0.     0.
       0.     0.]
  [ 5211.  5274.  2037.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.56
Q value #end_state_>_threshold:  569
Q value #non_end_state_>threshold:  692
maxi score:  0.41809999999999997
siam score:  -0.7513249
Scores:  {'0.167': 0.4041, '0.333': 0.3051, '0.5': 0.1281, '0.667': 0.049100000000000005, '0.833': 0.042100000000000005, '1.0': 0.026099999999999998}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.08945494721146655
Episodes: 6177, frames: 130097, time: 25128.265243768692
training steps:  15250
retraining steps:  0
RDN obj mus: [-0.9770324429392815, -0.9660826704144477, -0.9736562408566475, -0.9751226613521576, -0.9514405204713344]
RDN obj sigmas: [0.02196188877602453, 0.025617263451302774, 0.028058725483594428, 0.03870536079995949, 0.06738189383313592]
6177 : 0.15833333333333333
LR:  0.001
replay buffer size:  134202
Time Taken :  418.0  mins 48.26506805419922  seconds
[[[30745. 17666.  1194.     0.     0.     0.    66.    48.    33.    36.
      32.     0.]
  [11754.  8090.   837.   168.   103.   149.  1224.   968.   936.   983.
     744.   144.]
  [ 6621.  6961.  3449.  2497.  1894.  1712.  1512.   131.    38.    46.
      19.     0.]
  [ 5005.  4297.   483.   182.   134.    90.    89.     0.     0.     0.
       0.     0.]
  [ 5306.  5424.  2110.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.86
Q value #end_state_>_threshold:  788
Q value #non_end_state_>threshold:  923
maxi score:  0.4391
siam score:  -0.763533
Scores:  {'0.167': 0.4041, '0.333': 0.3081, '0.5': 0.1301, '0.667': 0.0431, '0.833': 0.0371, '1.0': 0.0281}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.09153997324905214
Episodes: 6488, frames: 140136, time: 27570.01860809326
training steps:  16423
retraining steps:  0
RDN obj mus: [-0.9777219712138175, -0.9875268765032291, -0.9810785081326961, -0.974152210187912, -0.9639426631629467]
RDN obj sigmas: [0.02529355065955956, 0.01474742261747781, 0.023924319531453898, 0.03429242339032204, 0.047480572943737115]
6488 : 0.15833333333333333
LR:  0.001
replay buffer size:  144635
Time Taken :  459.0  mins 30.01843810081482  seconds
[[[34634. 18953.  1236.     0.     0.     0.    76.    53.    38.    44.
      37.     0.]
  [12545.  8508.   872.   178.   106.   162.  1462.  1170.  1128.  1202.
     853.   180.]
  [ 6845.  7312.  3685.  2695.  2064.  1926.  1755.   142.    43.    52.
      21.     0.]
  [ 5113.  4414.   497.   192.   143.    98.    92.     0.     0.     0.
       0.     0.]
  [ 5409.  5546.  2167.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.9
Q value #end_state_>_threshold:  1162
Q value #non_end_state_>threshold:  1407
maxi score:  0.46909999999999996
siam score:  -0.74111265
Scores:  {'0.167': 0.41209999999999997, '0.333': 0.3111, '0.5': 0.1371, '0.667': 0.0531, '0.833': 0.0311, '1.0': 0.026099999999999998}
best rdn ma / adv:  0.167 0.333
best rdn adv:  0.04332644295462227
Episodes: 6875, frames: 150177, time: 30010.657052755356
training steps:  17606
retraining steps:  0
RDN obj mus: [-0.9819290137529373, -0.9884531181454659, -0.9852642402112484, -0.9794511513054371, -0.9709177844882011]
RDN obj sigmas: [0.01874712896365567, 0.011019311678096666, 0.016582293272310412, 0.029082662364288626, 0.04016075544043601]
6875 : 0.22083333333333333
LR:  0.001
replay buffer size:  155242
Time Taken :  500.0  mins 10.65688705444336  seconds
[[[37278. 20058.  1288.     0.     0.     0.    91.    64.    49.    48.
      43.     0.]
  [13281.  8990.   900.   189.   112.   187.  1919.  1532.  1423.  1498.
    1032.   245.]
  [ 7062.  7745.  4047.  3015.  2364.  2257.  2176.   170.    46.    58.
      25.     0.]
  [ 5198.  4495.   512.   206.   158.   109.    98.     0.     0.     0.
       0.     0.]
  [ 5483.  5640.  2211.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.96
Q value #end_state_>_threshold:  1548
Q value #non_end_state_>threshold:  2060
maxi score:  0.5001
siam score:  -0.76811785
Scores:  {'0.167': 0.3991, '0.333': 0.3141, '0.5': 0.1351, '0.667': 0.0521, '0.833': 0.0281, '1.0': 0.0241}
best rdn ma / adv:  0.167 0.333
best rdn adv:  0.04945848683505579
Episodes: 7211, frames: 160060, time: 32401.280993938446
training steps:  18763
retraining steps:  0
RDN obj mus: [-0.9875889660418034, -0.9898028871893882, -0.9887867787599564, -0.9832442523837089, -0.9710185021817684]
RDN obj sigmas: [0.015516483051433425, 0.012622366281616684, 0.014135919412177754, 0.022950281703972796, 0.032471639587404365]
7211 : 0.24166666666666667
LR:  0.001
replay buffer size:  165578
Time Taken :  540.0  mins 1.280820369720459  seconds
[[[40519. 21187.  1341.     0.     0.     0.   103.    72.    57.    54.
      48.     0.]
  [14107.  9397.   921.   200.   121.   209.  2221.  1762.  1653.  1745.
    1202.   306.]
  [ 7289.  8135.  4382.  3303.  2659.  2655.  2513.   192.    54.    66.
      30.     0.]
  [ 5251.  4547.   522.   212.   169.   119.   109.     0.     0.     0.
       0.     0.]
  [ 5509.  5679.  2229.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.98
Q value #end_state_>_threshold:  1891
Q value #non_end_state_>threshold:  2429
maxi score:  0.5421
siam score:  -0.7380055
Scores:  {'0.167': 0.3931, '0.333': 0.3211, '0.5': 0.1281, '0.667': 0.0541, '0.833': 0.0251, '1.0': 0.0211}
best rdn ma / adv:  0.167 0.333
best rdn adv:  0.04952374468009572
Episodes: 7524, frames: 170117, time: 34706.95755004883
training steps:  19941
retraining steps:  0
RDN obj mus: [-0.9824074586808681, -0.9869769273757935, -0.9866171553790569, -0.9836003775954246, -0.9802718220055103]
RDN obj sigmas: [0.014131492852051682, 0.012626740630596146, 0.013686848681765652, 0.016484439216273957, 0.01465594789042716]
7524 : 0.18333333333333332
LR:  0.001
replay buffer size:  176167
Time Taken :  578.0  mins 26.95738697052002  seconds
[[[43982. 22434.  1381.     0.     0.     0.   117.    78.    67.    60.
      49.     0.]
  [14943.  9837.   944.   209.   131.   228.  2563.  2027.  1859.  1932.
    1325.   358.]
  [ 7466.  8475.  4697.  3584.  2973.  3062.  2899.   220.    62.    70.
      31.     0.]
  [ 5292.  4576.   537.   219.   175.   133.   117.     0.     0.     0.
       0.     0.]
  [ 5533.  5708.  2240.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2385
Q value #non_end_state_>threshold:  3248
maxi score:  0.5851
siam score:  -0.74281645
Scores:  {'0.167': 0.3811, '0.333': 0.3081, '0.5': 0.1231, '0.667': 0.0541, '0.833': 0.0271, '1.0': 0.018099999999999998}
best rdn ma / adv:  0.167 0.333
best rdn adv:  0.05322605540652809
Episodes: 7942, frames: 180152, time: 36965.12899184227
training steps:  21108
retraining steps:  0
RDN obj mus: [-0.9690372631728649, -0.989639500117302, -0.9867120463252067, -0.9755126486182213, -0.9360902091443538]
RDN obj sigmas: [0.04486866091599051, 0.009156832819574716, 0.012208394775735603, 0.04234485724305897, 0.09105905149678623]
7942 : 0.2375
LR:  0.001
replay buffer size:  186735
Time Taken :  616.0  mins 5.128822088241577  seconds
[[[45812. 23333.  1407.     0.     0.     0.   134.    87.    80.    78.
      55.     0.]
  [15565. 10371.   977.   220.   151.   257.  2996.  2391.  2205.  2306.
    1582.   440.]
  [ 7658.  9017.  5191.  4068.  3479.  3700.  3477.   256.    77.    79.
      37.     0.]
  [ 5321.  4628.   552.   231.   186.   155.   132.     0.     0.     0.
       0.     0.]
  [ 5542.  5726.  2251.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2963
Q value #non_end_state_>threshold:  4057
maxi score:  0.6001
siam score:  -0.7202394
Scores:  {'0.167': 0.3821, '0.333': 0.3021, '0.5': 0.1271, '0.667': 0.0511, '0.833': 0.0211, '1.0': 0.0161}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 8396, frames: 190140, time: 39428.83447790146
training steps:  22285
retraining steps:  0
RDN obj mus: [-0.9835381677627564, -0.9886280373096467, -0.9879192419588566, -0.9843248377919197, -0.9860188927650452]
RDN obj sigmas: [0.014441391282996848, 0.013252844547331034, 0.014553142967862377, 0.02061471539182564, 0.019053905233097083]
8396 : 0.2
LR:  0.001
replay buffer size:  197163
Time Taken :  657.0  mins 8.834306001663208  seconds
[[[47562. 24052.  1440.     0.     0.     0.   147.   101.    89.    92.
      59.     0.]
  [16158. 10956.  1008.   243.   159.   289.  3473.  2770.  2483.  2625.
    1818.   538.]
  [ 7841.  9644.  5774.  4625.  4041.  4258.  4067.   283.    90.    89.
      46.     0.]
  [ 5347.  4674.   586.   245.   200.   174.   156.     0.     0.     0.
       0.     0.]
  [ 5552.  5735.  2255.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  3401
Q value #non_end_state_>threshold:  4822
maxi score:  0.6341
siam score:  -0.6940967
Scores:  {'0.167': 0.3841, '0.333': 0.2941, '0.5': 0.1211, '0.667': 0.0541, '0.833': 0.018099999999999998, '1.0': 0.0121}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 8732, frames: 200018, time: 41787.05513501167
training steps:  23443
retraining steps:  0
RDN obj mus: [-0.9867583590090275, -0.9909192728817463, -0.9892845209717751, -0.9885124001741409, -0.9840987375617027]
RDN obj sigmas: [0.011930970172043733, 0.010066847793001859, 0.009377431726163808, 0.010341353879873045, 0.013084447176821905]
8732 : 0.21666666666666667
LR:  0.001
replay buffer size:  200225
Time Taken :  696.0  mins 27.054967164993286  seconds
[[[50518. 25409.  1484.     0.     0.     0.   154.   117.    91.    98.
      62.     0.]
  [16969. 11447.  1034.   247.   171.   310.  3796.  3017.  2680.  2846.
    1997.   622.]
  [ 7979. 10071.  6167.  4992.  4390.  4592.  4442.   298.    94.    99.
      48.     0.]
  [ 5358.  4705.   602.   256.   210.   186.   166.     0.     0.     0.
       0.     0.]
  [ 5567.  5740.  2255.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  3690
Q value #non_end_state_>threshold:  5266
maxi score:  0.6441
siam score:  -0.7040005
Scores:  {'0.167': 0.3781, '0.333': 0.28409999999999996, '0.5': 0.1091, '0.667': 0.050100000000000006, '0.833': 0.0171, '1.0': 0.0101}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 8987, frames: 210139, time: 44229.9355969429
training steps:  24630
retraining steps:  0
RDN obj mus: [-0.9876834069430828, -0.9876584807634353, -0.9871795873999596, -0.9875687314152718, -0.9707518059849739]
RDN obj sigmas: [0.009414749881531579, 0.010967226025358134, 0.012055291558356211, 0.015352201496529806, 0.030857129726761537]
8987 : 0.14583333333333334
LR:  0.001
replay buffer size:  200125
Time Taken :  737.0  mins 9.935436010360718  seconds
[[[54705. 27292.  1553.     0.     0.     0.   161.   122.    91.   100.
      63.     0.]
  [18130. 11984.  1059.   252.   177.   318.  3921.  3137.  2789.  2937.
    2071.   660.]
  [ 8112. 10341.  6350.  5168.  4555.  4753.  4608.   306.    99.   102.
      51.     0.]
  [ 5406.  4743.   605.   261.   214.   193.   174.     0.     0.     0.
       0.     0.]
  [ 5584.  5749.  2256.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  4221
Q value #non_end_state_>threshold:  6225
maxi score:  0.6681
siam score:  -0.671369
Scores:  {'0.167': 0.3881, '0.333': 0.2721, '0.5': 0.1071, '0.667': 0.0391, '0.833': 0.0191, '1.0': 0.0081}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 9395, frames: 220064, time: 46854.68741607666
training steps:  25795
retraining steps:  0
RDN obj mus: [-0.9819145811319351, -0.989357669621706, -0.9877283723175526, -0.9858500248253346, -0.9825902261793613]
RDN obj sigmas: [0.02213850880673873, 0.011954696697052718, 0.012879942891956615, 0.016310991290719064, 0.01728975029391838]
9395 : 0.22083333333333333
LR:  0.001
replay buffer size:  200059
Time Taken :  780.0  mins 54.6872501373291  seconds
[[[56211. 28578.  1609.     0.     0.     0.   174.   135.    96.   106.
      69.     0.]
  [18799. 12824.  1102.   267.   193.   335.  4273.  3451.  3021.  3143.
    2235.   754.]
  [ 8398. 11066.  6858.  5627.  5031.  5199.  5000.   331.   104.   108.
      56.     0.]
  [ 5484.  4858.   626.   274.   231.   203.   187.     0.     0.     0.
       0.     0.]
  [ 5612.  5781.  2260.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
