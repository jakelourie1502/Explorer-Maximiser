EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.006357048339616027
Scores:  {'0.167': 0.06676666666666667, '0.333': 0.050100000000000006, '0.5': 0.0001, '0.667': 0.04555454545454546, '0.833': 0.04555454545454546, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.20487136907291648
Episodes: 81, frames: 1316, time: 36.52733635902405
training steps:  6
retraining steps:  0
RDN obj mus: [-0.08682199863751387, -0.052287108301148785, -0.04368125044164203, 0.0, 0.0]
RDN obj sigmas: [0.0075668901003804285, 0.006036937004741332, 0.009857394515103283, 0.0, 0.0]
81 : 0.030864197530864196
LR:  5e-06
replay buffer size:  1719
Time Taken :  0.0  mins 36.52713894844055  seconds
[[[270. 175.  37.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
  [201. 125.  23.   1.   1.   0.   0.   0.   0.   0.   0.   0.]
  [108.  75.  18.   2.   1.   0.   0.   0.   0.   0.   0.   0.]
  [ 64.  41.  14.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
  [ 42.  32.   5.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.18364430379746835
siam score:  -0.6383011
Scores:  {'0.167': 0.21062631578947366, '0.333': 0.2579125, '0.5': 0.191458024691358, '0.667': 0.1401, '0.833': 0.1321754716981132, '1.0': 0.10204174757281553}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.44340863050051427
Episodes: 676, frames: 10026, time: 1959.0233211517334
training steps:  1198
retraining steps:  0
RDN obj mus: [-0.9456090940356254, -0.9403756845295429, -0.9056173062622547, -0.8856874700242858, -0.8566512360177262]
RDN obj sigmas: [0.024245759594229956, 0.04337238719821354, 0.0649499297292846, 0.08030431099395376, 0.09315159985402102]
676 : 0.35
LR:  0.001
replay buffer size:  10646
Time Taken :  32.0  mins 39.023107051849365  seconds
[[[2132. 1139.  207.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]
  [1364.  755.  140.    8.    2.    0.    0.    0.    0.    0.    0.
      0.]
  [ 791.  526.   97.   26.    7.    0.    0.    0.    0.    0.    0.
      0.]
  [ 511.  405.   75.    3.    1.    0.    0.    0.    0.    0.    0.
      0.]
  [ 420.  501.  240.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  12
maxi score:  0.2920354838709677
siam score:  -0.87279236
Scores:  {'0.167': 0.29405604395604396, '0.333': 0.3456056179775281, '0.5': 0.2809988764044944, '0.667': 0.2202086956521739, '0.833': 0.17336732673267324, '1.0': 0.11999795918367347}
best rdn ma / adv:  0.333 0.167
best rdn adv:  0.0
Episodes: 1375, frames: 20072, time: 4859.943450212479
training steps:  2350
retraining steps:  0
RDN obj mus: [-0.9567662004470825, -0.96461190533638, -0.9623144936859608, -0.9705900248646736, -0.9584152953922749]
RDN obj sigmas: [0.030460654512561285, 0.039030654050955446, 0.04183437374406256, 0.03271091230823886, 0.05784219245748037]
1375 : 0.2916666666666667
LR:  0.001
replay buffer size:  20888
Time Taken :  80.0  mins 59.94323682785034  seconds
[[[3051. 1922.  285.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]
  [2211. 1436.  216.   17.   10.    3.    5.    1.    0.    0.    0.
      0.]
  [1480. 1324.  320.  147.  109.  105.   57.   16.    0.    0.    0.
      0.]
  [1086. 1107.  116.   11.    2.    9.    5.    0.    0.    0.    0.
      0.]
  [1329. 1632.  685.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  12
maxi score:  0.3142809290953545
siam score:  -0.84970057
Scores:  {'0.167': 0.3103766798418972, '0.333': 0.34253697478991596, '0.5': 0.2405255319148936, '0.667': 0.18263968253968252, '0.833': 0.13543834586466164, '1.0': 0.09118527131782946}
best rdn ma / adv:  0.333 0.167
best rdn adv:  0.0
Episodes: 1829, frames: 30077, time: 7841.370569944382
training steps:  3532
retraining steps:  0
RDN obj mus: [-0.9563438885211945, -0.973453980821371, -0.9635301109671592, -0.9600117514669895, -0.9554999650716781]
RDN obj sigmas: [0.03058210105584285, 0.021218818151783912, 0.03535547626342007, 0.04475350422393558, 0.04732930824540692]
1829 : 0.1625
LR:  0.001
replay buffer size:  31087
Time Taken :  130.0  mins 41.370354890823364  seconds
[[[6034. 3254.  386.    0.    0.    0.    2.    1.    1.    0.    0.
      0.]
  [2991. 1953.  268.   29.   22.   14.   16.    7.    1.    0.    0.
      0.]
  [1927. 1862.  564.  341.  278.  210.  102.   30.    0.    0.    0.
      0.]
  [1457. 1483.  168.   18.   13.   17.    6.    0.    0.    0.    0.
      0.]
  [1829. 2113.  851.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  12
maxi score:  0.3631
siam score:  -0.8275024
Scores:  {'0.167': 0.3218821782178218, '0.333': 0.3375558303886926, '0.5': 0.21264355400696863, '0.667': 0.16016600660066005, '0.833': 0.11003975903614457, '1.0': 0.07330872274143302}
best rdn ma / adv:  0.333 0.5
best rdn adv:  0.005355474703822146
Episodes: 2231, frames: 40163, time: 11159.871975183487
training steps:  4705
retraining steps:  0
RDN obj mus: [-0.9742039149701596, -0.9840016187250614, -0.974947231477499, -0.9714123057365418, -0.9572373750090599]
RDN obj sigmas: [0.02894082648124164, 0.0174646160731569, 0.028863222482014873, 0.034876588599578116, 0.069370015152277]
2231 : 0.1625
LR:  0.001
replay buffer size:  41375
Time Taken :  185.0  mins 59.87175393104553  seconds
[[[9085. 4771.  462.    0.    0.    0.    6.    4.    2.    2.    1.
      0.]
  [3845. 2464.  316.   40.   32.   37.   82.   58.   69.   24.    6.
      1.]
  [2356. 2382.  899.  584.  515.  334.  159.   36.    3.    3.    0.
      0.]
  [1730. 1744.  203.   27.   25.   22.   10.    0.    0.    0.    0.
      0.]
  [2138. 2467.  988.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  51
maxi score:  0.41509999999999997
siam score:  -0.8164807
Scores:  {'0.167': 0.33628233618233616, '0.333': 0.3358771260997067, '0.5': 0.18777908309455588, '0.667': 0.14081038251366118, '0.833': 0.0969586387434555, '1.0': 0.0641}
best rdn ma / adv:  0.167 0.333
best rdn adv:  0.004507393665680223
Episodes: 2646, frames: 50058, time: 13779.885295152664
training steps:  5881
retraining steps:  0
RDN obj mus: [-0.9741996531128884, -0.9806799375176429, -0.9734747550487518, -0.9708644870758056, -0.9576439090192318]
RDN obj sigmas: [0.022095047539061823, 0.01966313512949853, 0.03020803431519518, 0.029578590458548815, 0.03405718354602885]
2646 : 0.2125
LR:  0.001
replay buffer size:  51480
Time Taken :  229.0  mins 39.885074853897095  seconds
[[[11568.  5612.   512.     0.     0.     0.    11.    10.     2.     7.
       5.     0.]
  [ 4962.  2960.   374.    53.    45.    52.   172.   157.   157.   135.
      40.     3.]
  [ 2955.  2954.  1229.   784.   665.   446.   241.    46.     6.     6.
       3.     0.]
  [ 2159.  2064.   237.    38.    33.    26.    14.     0.     0.     0.
       0.     0.]
  [ 2608.  2913.  1148.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  11
Q value #non_end_state_>threshold:  68
maxi score:  0.41709999999999997
siam score:  -0.7773133
Scores:  {'0.167': 0.33897468030690536, '0.333': 0.32958717948717947, '0.5': 0.1912057692307692, '0.667': 0.14028691588785044, '0.833': 0.09599041095890411, '1.0': 0.06941818181818182}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.020959380545413037
Episodes: 3074, frames: 60146, time: 16299.001424312592
training steps:  7047
retraining steps:  0
RDN obj mus: [-0.9634002222299576, -0.965443556600809, -0.9666206218957901, -0.9716335143148899, -0.9598184369266033]
RDN obj sigmas: [0.03350446431677918, 0.03775208162105568, 0.03882715069587456, 0.03169833927269703, 0.039022998304042315]
3074 : 0.25833333333333336
LR:  0.001
replay buffer size:  61768
Time Taken :  271.0  mins 39.001200675964355  seconds
[[[13703.  6336.   550.     0.     0.     0.    21.    18.     6.    10.
      11.     0.]
  [ 5742.  3428.   415.    66.    57.    63.   331.   333.   310.   275.
     146.    19.]
  [ 3508.  3575.  1581.  1085.   917.   626.   405.    62.    16.    14.
       7.     0.]
  [ 2641.  2416.   262.    52.    41.    35.    19.     0.     0.     0.
       0.     0.]
  [ 3264.  3393.  1313.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  86
Q value #non_end_state_>threshold:  94
maxi score:  0.41109999999999997
siam score:  -0.7519104
Scores:  {'0.167': 0.35020940919037197, '0.333': 0.34116728538283064, '0.5': 0.1971021413276231, '0.667': 0.14355991561181433, '0.833': 0.09929028340080973, '1.0': 0.0641}
best rdn ma / adv:  0.167 0.667
best rdn adv:  0.03242660843875435
Episodes: 3479, frames: 70028, time: 18819.75252509117
training steps:  8215
retraining steps:  0
RDN obj mus: [-0.9787166869282723, -0.9802420286476612, -0.9780586858868598, -0.9618978125810623, -0.9514948452621699]
RDN obj sigmas: [0.020794252316657543, 0.017001245672441337, 0.025406268260867036, 0.052473160587553254, 0.06072475582498908]
3479 : 0.2833333333333333
LR:  0.001
replay buffer size:  71881
Time Taken :  313.0  mins 39.75231575965881  seconds
[[[15574.  7011.   586.     0.     0.     0.    24.    21.     7.    16.
      13.     0.]
  [ 6652.  3920.   453.    84.    64.    78.   439.   413.   406.   378.
     215.    38.]
  [ 4114.  4158.  1847.  1319.  1091.   800.   518.    74.    21.    21.
       7.     0.]
  [ 3288.  2784.   289.    57.    52.    47.    24.     0.     0.     0.
       0.     0.]
  [ 4242.  3922.  1482.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  128
Q value #non_end_state_>threshold:  113
maxi score:  0.41409999999999997
siam score:  -0.7585329
Scores:  {'0.167': 0.3591, '0.333': 0.3498983870967742, '0.5': 0.20909999999999998, '0.667': 0.14409999999999998, '0.833': 0.0971, '1.0': 0.057100000000000005}
best rdn ma / adv:  0.167 0.667
best rdn adv:  0.03688850975992695
Episodes: 3944, frames: 80021, time: 21345.374361276627
training steps:  9383
retraining steps:  0
RDN obj mus: [-0.9828625064015388, -0.9843191766560078, -0.9822726926386356, -0.9722461597234011, -0.9665556618541479]
RDN obj sigmas: [0.018857005241088614, 0.017172479355354375, 0.0257356974237836, 0.039523983611705046, 0.033477122851568744]
3944 : 0.2875
LR:  0.001
replay buffer size:  82136
Time Taken :  355.0  mins 45.37414193153381  seconds
[[[17358.  7675.   634.     0.     0.     0.    32.    23.    10.    20.
      17.     0.]
  [ 7631.  4474.   503.   103.    73.    93.   517.   487.   454.   415.
     241.    48.]
  [ 4799.  4784.  2143.  1543.  1267.   953.   613.    81.    23.    22.
       8.     0.]
  [ 4009.  3200.   314.    79.    68.    63.    33.     0.     0.     0.
       0.     0.]
  [ 5137.  4455.  1675.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  197
Q value #non_end_state_>threshold:  159
maxi score:  0.41809999999999997
siam score:  -0.7524182
Scores:  {'0.167': 0.3891, '0.333': 0.3681, '0.5': 0.21109999999999998, '0.667': 0.14509999999999998, '0.833': 0.0721, '1.0': 0.033100000000000004}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.05533276463989042
Episodes: 4397, frames: 90084, time: 23892.16942214966
training steps:  10565
retraining steps:  0
RDN obj mus: [-0.9824037751972675, -0.9859368145883083, -0.9823474274456501, -0.9699587598979473, -0.95992620588243]
RDN obj sigmas: [0.01887782326289422, 0.01954629059073523, 0.027630557750947426, 0.04486061122318557, 0.04171456735550054]
4397 : 0.225
LR:  0.001
replay buffer size:  92456
Time Taken :  398.0  mins 12.169204950332642  seconds
[[[19217.  8379.   683.     0.     0.     0.    35.    29.    14.    23.
      20.     0.]
  [ 8607.  4934.   545.   121.    83.   101.   580.   554.   509.   467.
     284.    67.]
  [ 5467.  5308.  2369.  1709.  1415.  1104.   696.    89.    24.    22.
      10.     0.]
  [ 4867.  3673.   350.    93.    78.    72.    37.     0.     0.     0.
       0.     0.]
  [ 6158.  5018.  1876.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  260
Q value #non_end_state_>threshold:  219
maxi score:  0.41409999999999997
siam score:  -0.76207656
Scores:  {'0.167': 0.3921, '0.333': 0.3711, '0.5': 0.20809999999999998, '0.667': 0.1271, '0.833': 0.0451, '1.0': 0.0371}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.06455489207987217
Episodes: 4784, frames: 100050, time: 26394.215757131577
training steps:  11727
retraining steps:  0
RDN obj mus: [-0.9852936779737472, -0.9857611077010632, -0.9828217890828848, -0.9740845265179873, -0.9716591774195432]
RDN obj sigmas: [0.01452275962117047, 0.019200254254221217, 0.027752783992857456, 0.03886826967707715, 0.0381194450537358]
4784 : 0.24583333333333332
LR:  0.001
replay buffer size:  102680
Time Taken :  439.0  mins 54.21554183959961  seconds
[[[20698.  8926.   716.     0.     0.     0.    36.    34.    16.    26.
      20.     0.]
  [ 9609.  5334.   585.   130.    89.   110.   637.   624.   576.   546.
     334.    81.]
  [ 6190.  5753.  2525.  1846.  1527.  1202.   790.    98.    28.    26.
      13.     0.]
  [ 6000.  4090.   374.   108.    82.    78.    44.     0.     0.     0.
       0.     0.]
  [ 7708.  5598.  2059.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.58
Q value #end_state_>_threshold:  421
Q value #non_end_state_>threshold:  386
maxi score:  0.4211
siam score:  -0.7741632
Scores:  {'0.167': 0.4021, '0.333': 0.3691, '0.5': 0.2291, '0.667': 0.1321, '0.833': 0.0531, '1.0': 0.058100000000000006}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.07992510447984172
Episodes: 5187, frames: 110103, time: 28923.268084049225
training steps:  12898
retraining steps:  0
RDN obj mus: [-0.9578385313659906, -0.9783627459347248, -0.9726269910961389, -0.9687440058112144, -0.9525484461545944]
RDN obj sigmas: [0.02647765315749888, 0.023948229608990162, 0.03429245860542843, 0.04033077479729768, 0.05344206669355822]
5187 : 0.35833333333333334
LR:  0.001
replay buffer size:  113056
Time Taken :  482.0  mins 3.267871856689453  seconds
[[[22021.  9389.   736.     0.     0.     0.    42.    40.    20.    39.
      22.     0.]
  [10403.  5763.   607.   139.    94.   121.   771.   779.   710.   680.
     401.   116.]
  [ 6797.  6240.  2727.  2021.  1674.  1360.   932.   108.    30.    32.
      15.     0.]
  [ 6908.  4543.   403.   115.    87.    84.    52.     0.     0.     0.
       0.     0.]
  [ 9367.  6278.  2250.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.52
Q value #end_state_>_threshold:  687
Q value #non_end_state_>threshold:  670
maxi score:  0.4411
siam score:  -0.76022387
Scores:  {'0.167': 0.40909999999999996, '0.333': 0.3891, '0.5': 0.2581, '0.667': 0.1591, '0.833': 0.1091, '1.0': 0.0931}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.08354281983620111
Episodes: 5694, frames: 120026, time: 31453.161715984344
training steps:  14073
retraining steps:  0
RDN obj mus: [-0.9823231456607581, -0.9871904596567154, -0.979682128739357, -0.9606822508215904, -0.9551566184192896]
RDN obj sigmas: [0.019139891088603728, 0.015288409528158665, 0.03198783071088213, 0.0517565372271306, 0.055439669429439856]
5694 : 0.37916666666666665
LR:  0.001
replay buffer size:  123282
Time Taken :  524.0  mins 13.16150188446045  seconds
[[[22964.  9829.   759.     0.     0.     0.    49.    46.    24.    46.
      29.     0.]
  [11286.  6211.   634.   145.   100.   128.   935.   940.   886.   915.
     530.   190.]
  [ 7485.  6871.  3008.  2257.  1892.  1576.  1133.   119.    33.    40.
      23.     0.]
  [ 7617.  4995.   430.   120.    97.    92.    63.     0.     0.     0.
       0.     0.]
  [10406.  6938.  2491.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.58
Q value #end_state_>_threshold:  846
Q value #non_end_state_>threshold:  1015
maxi score:  0.4491
siam score:  -0.77416015
Scores:  {'0.167': 0.4231, '0.333': 0.4001, '0.5': 0.2981, '0.667': 0.17909999999999998, '0.833': 0.1241, '1.0': 0.1091}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.10965445142050737
Episodes: 6180, frames: 130123, time: 34008.043335199356
training steps:  15254
retraining steps:  0
RDN obj mus: [-0.9779514087110758, -0.9834761825174093, -0.9798538746416569, -0.9715466304361821, -0.9565660955607891]
RDN obj sigmas: [0.025416869845500754, 0.024417201094963578, 0.028690952309509132, 0.03625348954873316, 0.04592364280946034]
6180 : 0.31666666666666665
LR:  0.001
replay buffer size:  133684
Time Taken :  566.0  mins 48.043115854263306  seconds
[[[24023. 10282.   786.     0.     0.     0.    59.    46.    33.    50.
      33.     0.]
  [12076.  6622.   661.   163.   110.   141.  1070.  1086.  1032.  1053.
     607.   239.]
  [ 8162.  7445.  3280.  2509.  2097.  1761.  1302.   127.    40.    43.
      28.     0.]
  [ 8500.  5441.   461.   132.   109.   105.    80.     0.     0.     0.
       0.     0.]
  [11819.  7634.  2696.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.76
Q value #end_state_>_threshold:  1341
Q value #non_end_state_>threshold:  1794
maxi score:  0.48009999999999997
siam score:  -0.7423204
Scores:  {'0.167': 0.4351, '0.333': 0.41109999999999997, '0.5': 0.3271, '0.667': 0.1981, '0.833': 0.1541, '1.0': 0.1181}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.1241207608994988
Episodes: 6667, frames: 140069, time: 36543.033219099045
training steps:  16418
retraining steps:  0
RDN obj mus: [-0.9783450878858566, -0.98388861977458, -0.9751783192873001, -0.9751504912883043, -0.961293937844038]
RDN obj sigmas: [0.028514896331835425, 0.02150575617558566, 0.03567720434330428, 0.045190377143658186, 0.04766337565862633]
6667 : 0.3458333333333333
LR:  0.001
replay buffer size:  143988
Time Taken :  609.0  mins 3.0330049991607666  seconds
[[[24870. 10667.   798.     0.     0.     0.    66.    61.    44.    58.
      40.     0.]
  [12828.  7045.   678.   179.   119.   164.  1382.  1440.  1420.  1447.
     849.   354.]
  [ 8643.  7973.  3641.  2886.  2471.  2166.  1647.   143.    52.    67.
      32.     0.]
  [ 9031.  5717.   478.   139.   118.   116.    91.     0.     0.     0.
       0.     0.]
  [12638.  8012.  2832.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1814
Q value #non_end_state_>threshold:  3161
maxi score:  0.4991
siam score:  -0.75641024
Scores:  {'0.167': 0.4351, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21409999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.5
best rdn adv:  0.08916209582067013
Episodes: 7136, frames: 150041, time: 39101.677104234695
training steps:  17588
retraining steps:  0
RDN obj mus: [-0.984241276204586, -0.9869217616081237, -0.985254319947958, -0.9782762368410826, -0.9792297604173422]
RDN obj sigmas: [0.016628057580094457, 0.018944311018219657, 0.02490797759738542, 0.03765924640264319, 0.028459056729042587]
7136 : 0.3333333333333333
LR:  0.001
replay buffer size:  154376
Time Taken :  651.0  mins 41.676883935928345  seconds
[[[25626. 11016.   809.     0.     0.     0.    79.    69.    63.    68.
      53.     0.]
  [13518.  7481.   698.   187.   127.   187.  1755.  1860.  1975.  2043.
    1156.   471.]
  [ 9067.  8542.  4064.  3315.  2893.  2599.  2063.   166.    69.    89.
      42.     0.]
  [ 9382.  5938.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13224.  8290.  2913.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.88
Q value #end_state_>_threshold:  1814
Q value #non_end_state_>threshold:  3281
maxi score:  0.5221
siam score:  -0.7549623
Scores:  {'0.167': 0.4361, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21209999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.167
best rdn adv:  0.0
Episodes: 7138, frames: 255037, time: 39138.53766703606
training steps:  17594
retraining steps:  0
RDN obj mus: [-0.9839865394890308, -0.9893854086220264, -0.9849907760918141, -0.9782585876196623, -0.9798760698020458]
RDN obj sigmas: [0.015687723049701504, 0.015084772489001098, 0.02280935854993441, 0.03544730609824093, 0.023360893636840588]
7138 : 0.32916666666666666
LR:  0.001
replay buffer size:  154804
Time Taken :  652.0  mins 18.537450790405273  seconds
[[[25626. 11018.   809.     0.     0.     0.    79.    69.    64.    68.
      53.     0.]
  [13519.  7484.   698.   187.   127.   187.  1756.  1863.  1981.  2043.
    1156.   471.]
  [ 9067.  8544.  4065.  3316.  2894.  2601.  2065.   166.    69.    89.
      42.     0.]
  [ 9382.  5939.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13229.  8292.  2914.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.9
Q value #end_state_>_threshold:  1814
Q value #non_end_state_>threshold:  3413
maxi score:  0.5541
siam score:  -0.7560845
Scores:  {'0.167': 0.4361, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21209999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.5
best rdn adv:  0.06100663906057248
Episodes: 7138, frames: 255037, time: 39174.11950016022
training steps:  17600
retraining steps:  0
RDN obj mus: [-0.9842504998028279, -0.990451423072815, -0.984591260612011, -0.9789663412421942, -0.9796828608512879]
RDN obj sigmas: [0.015059851098749735, 0.011419524536605953, 0.01988955077481817, 0.03329676910480046, 0.019477298163429257]
7138 : 0.32916666666666666
LR:  0.001
replay buffer size:  155218
Time Taken :  652.0  mins 54.11928176879883  seconds
[[[25626. 11018.   809.     0.     0.     0.    79.    69.    64.    68.
      53.     0.]
  [13519.  7484.   698.   187.   127.   187.  1756.  1863.  1981.  2043.
    1156.   471.]
  [ 9067.  8544.  4065.  3316.  2894.  2601.  2065.   166.    69.    89.
      42.     0.]
  [ 9382.  5939.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13229.  8292.  2914.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.98
Q value #end_state_>_threshold:  1934
Q value #non_end_state_>threshold:  3573
maxi score:  0.5740999999999999
siam score:  -0.7534721
Scores:  {'0.167': 0.4361, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21209999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.5
best rdn adv:  0.05726772159848565
Episodes: 7138, frames: 255037, time: 39210.63361406326
training steps:  17606
retraining steps:  0
RDN obj mus: [-0.985583582162857, -0.9903815580189228, -0.9853816291332245, -0.9819476461708546, -0.9797533997178077]
RDN obj sigmas: [0.013897524887985567, 0.010270592187078206, 0.01897889237439069, 0.029967140161527947, 0.013190033690856971]
7138 : 0.32916666666666666
LR:  0.001
replay buffer size:  155654
Time Taken :  653.0  mins 30.633403778076172  seconds
[[[25626. 11018.   809.     0.     0.     0.    79.    69.    64.    68.
      53.     0.]
  [13519.  7484.   698.   187.   127.   187.  1756.  1863.  1981.  2043.
    1156.   471.]
  [ 9067.  8544.  4065.  3316.  2894.  2601.  2065.   166.    69.    89.
      42.     0.]
  [ 9382.  5939.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13229.  8292.  2914.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2057
Q value #non_end_state_>threshold:  3758
maxi score:  0.6021
siam score:  -0.7514092
Scores:  {'0.167': 0.4361, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21209999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.5
best rdn adv:  0.04446733742823866
Episodes: 7138, frames: 255037, time: 39244.95108604431
training steps:  17611
retraining steps:  0
RDN obj mus: [-0.9864176791608333, -0.9901096280157566, -0.9863021474659442, -0.9827650534003973, -0.981397196573019]
RDN obj sigmas: [0.01295991803744913, 0.011510955436735049, 0.01628473737221901, 0.027926366745837605, 0.011649606146010169]
7138 : 0.32916666666666666
LR:  0.001
replay buffer size:  156067
Time Taken :  654.0  mins 4.950864791870117  seconds
[[[25626. 11018.   809.     0.     0.     0.    79.    69.    64.    68.
      53.     0.]
  [13519.  7484.   698.   187.   127.   187.  1756.  1863.  1981.  2043.
    1156.   471.]
  [ 9067.  8544.  4065.  3316.  2894.  2601.  2065.   166.    69.    89.
      42.     0.]
  [ 9382.  5939.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13229.  8292.  2914.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.98
Q value #end_state_>_threshold:  2175
Q value #non_end_state_>threshold:  3914
maxi score:  0.6371
siam score:  -0.75257385
Scores:  {'0.167': 0.4361, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21209999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.167
best rdn adv:  0.0
Episodes: 7138, frames: 255037, time: 39279.372987270355
training steps:  17617
retraining steps:  0
RDN obj mus: [-0.9863959709644318, -0.9892954485237598, -0.986003420829773, -0.9830700009554625, -0.9829147783756256]
RDN obj sigmas: [0.012559189244767429, 0.013535621143491057, 0.014818022107307899, 0.0259270546582248, 0.009828991834845598]
7138 : 0.32916666666666666
LR:  0.001
replay buffer size:  156481
Time Taken :  654.0  mins 39.37276792526245  seconds
[[[25626. 11018.   809.     0.     0.     0.    79.    69.    64.    68.
      53.     0.]
  [13519.  7484.   698.   187.   127.   187.  1756.  1863.  1981.  2043.
    1156.   471.]
  [ 9067.  8544.  4065.  3316.  2894.  2601.  2065.   166.    69.    89.
      42.     0.]
  [ 9382.  5939.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13229.  8292.  2914.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2295
Q value #non_end_state_>threshold:  4062
maxi score:  0.6461
siam score:  -0.75373197
Scores:  {'0.167': 0.4361, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21209999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.5
best rdn adv:  0.04446733742823866
Episodes: 7138, frames: 255037, time: 39311.94177007675
training steps:  17622
retraining steps:  0
RDN obj mus: [-0.9861478543877602, -0.9892968757092953, -0.9863199836790562, -0.9836792672008275, -0.9822826596021652]
RDN obj sigmas: [0.012667787345598012, 0.013873843100957404, 0.013632392639418461, 0.02350389680140058, 0.010102989194377058]
7138 : 0.32916666666666666
LR:  0.001
replay buffer size:  156872
Time Taken :  655.0  mins 11.941551685333252  seconds
[[[25626. 11018.   809.     0.     0.     0.    79.    69.    64.    68.
      53.     0.]
  [13519.  7484.   698.   187.   127.   187.  1756.  1863.  1981.  2043.
    1156.   471.]
  [ 9067.  8544.  4065.  3316.  2894.  2601.  2065.   166.    69.    89.
      42.     0.]
  [ 9382.  5939.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13229.  8292.  2914.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2419
Q value #non_end_state_>threshold:  4210
maxi score:  0.6721
siam score:  -0.7569574
Scores:  {'0.167': 0.4361, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21209999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.167
best rdn adv:  0.0
Episodes: 7138, frames: 255037, time: 39343.78379416466
training steps:  17627
retraining steps:  0
RDN obj mus: [-0.9854224937200546, -0.9874288035094738, -0.9861529337882996, -0.9835560370177031, -0.9810441629529]
RDN obj sigmas: [0.012794725382426698, 0.016338218009006412, 0.01393653576761892, 0.020452075459296056, 0.011051273109352576]
7138 : 0.32916666666666666
LR:  0.001
replay buffer size:  157254
Time Taken :  655.0  mins 43.7835807800293  seconds
[[[25626. 11018.   809.     0.     0.     0.    79.    69.    64.    68.
      53.     0.]
  [13519.  7484.   698.   187.   127.   187.  1756.  1863.  1981.  2043.
    1156.   471.]
  [ 9067.  8544.  4065.  3316.  2894.  2601.  2065.   166.    69.    89.
      42.     0.]
  [ 9382.  5939.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13229.  8292.  2914.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2539
Q value #non_end_state_>threshold:  4356
maxi score:  0.7261
siam score:  -0.7569063
Scores:  {'0.167': 0.4361, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21209999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.167
best rdn adv:  0.0
Episodes: 7138, frames: 255037, time: 39377.13505935669
training steps:  17633
retraining steps:  0
RDN obj mus: [-0.9844556490182876, -0.9850283185958862, -0.9856309526085854, -0.9843900398731231, -0.9800486867249012]
RDN obj sigmas: [0.013083755190877053, 0.01921470577432287, 0.015155989808017656, 0.01657189547016522, 0.011390168386836933]
7138 : 0.32916666666666666
LR:  0.001
replay buffer size:  157644
Time Taken :  656.0  mins 17.134841680526733  seconds
[[[25626. 11018.   809.     0.     0.     0.    79.    69.    64.    68.
      53.     0.]
  [13519.  7484.   698.   187.   127.   187.  1756.  1863.  1981.  2043.
    1156.   471.]
  [ 9067.  8544.  4065.  3316.  2894.  2601.  2065.   166.    69.    89.
      42.     0.]
  [ 9382.  5939.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13229.  8292.  2914.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.96
Q value #end_state_>_threshold:  2659
Q value #non_end_state_>threshold:  4588
maxi score:  0.7271
siam score:  -0.7618608
Scores:  {'0.167': 0.4361, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21209999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.167
best rdn adv:  0.0
Episodes: 7138, frames: 255037, time: 39409.790023326874
training steps:  17638
retraining steps:  0
RDN obj mus: [-0.9841089097082615, -0.985571394020319, -0.9854798209309578, -0.9846522365450859, -0.9777387351036072]
RDN obj sigmas: [0.012700647022661367, 0.017950740194368917, 0.015187024631158523, 0.015274936100020791, 0.013885601044560663]
7138 : 0.32916666666666666
LR:  0.001
replay buffer size:  158035
Time Taken :  656.0  mins 49.7898108959198  seconds
[[[25626. 11018.   809.     0.     0.     0.    79.    69.    64.    68.
      53.     0.]
  [13519.  7484.   698.   187.   127.   187.  1756.  1863.  1981.  2043.
    1156.   471.]
  [ 9067.  8544.  4065.  3316.  2894.  2601.  2065.   166.    69.    89.
      42.     0.]
  [ 9382.  5939.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13229.  8292.  2914.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2784
Q value #non_end_state_>threshold:  4826
maxi score:  0.7541
siam score:  -0.76885635
Scores:  {'0.167': 0.4361, '0.333': 0.4391, '0.5': 0.3391, '0.667': 0.21209999999999998, '0.833': 0.15009999999999998, '1.0': 0.1251}
best rdn ma / adv:  0.333 0.5
best rdn adv:  0.047370538389656776
Episodes: 7138, frames: 255037, time: 39444.89169836044
training steps:  17644
retraining steps:  0
RDN obj mus: [-0.9822022502243519, -0.983737978553772, -0.9839300846099853, -0.98340447666049, -0.974798893147707]
RDN obj sigmas: [0.013889415312372384, 0.018294914986425905, 0.017326142885659566, 0.014381199368278167, 0.016009329172863362]
7138 : 0.32916666666666666
LR:  0.001
replay buffer size:  158447
Time Taken :  657.0  mins 24.891479015350342  seconds
[[[25626. 11018.   809.     0.     0.     0.    79.    69.    64.    68.
      53.     0.]
  [13519.  7484.   698.   187.   127.   187.  1756.  1863.  1981.  2043.
    1156.   471.]
  [ 9067.  8544.  4065.  3316.  2894.  2601.  2065.   166.    69.    89.
      42.     0.]
  [ 9382.  5939.   497.   150.   124.   130.   107.     0.     0.     0.
       0.     0.]
  [13229.  8292.  2914.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
