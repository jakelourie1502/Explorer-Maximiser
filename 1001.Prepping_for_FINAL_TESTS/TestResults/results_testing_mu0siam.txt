EVALUATIONS AND MAIN RESULTS
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9766441860465116
siam score:  2.350372683611654e-05
Scores:  {'0.333': -0.7499, '0.667': -0.8749, '1.0': -0.7999, '1.333': -0.8332333333333334, '1.667': -0.9229769230769231, '2.0': -0.9089909090909091}
best rdn ma / adv:  2 0.333
best rdn adv:  0.0
Episodes: 63, frames: 1472, time: 38.67517900466919
training steps:  5
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
63 : -1.0
LR:  4e-06
replay buffer size:  1935
Time Taken :  0.0  mins 38.67501187324524  seconds
[[[  0.   0.   0.   0.   1.   1.   2.   1.   1.   1.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   5.  15.  28.  23.   3.   2.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  41.  50.  28.  20.  43.   2.   3.   0.   0.   8.   2.   2.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0. 464. 124.  61.  29.  86. 109. 107.  40.  49.  24.   3.   0.   1.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   9.  10.   7.   4.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  41
Q value #non_end_state_>threshold:  2
maxi score:  0.0001
siam score:  -0.7228884
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0021, '2.0': 0.0001}
best rdn ma / adv:  1.667 1.667
best rdn adv:  0.014936622250094948
Episodes: 4062, frames: 50176, time: 5752.128635883331
training steps:  4314
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4062 : 0.0
LR:  0.001
replay buffer size:  52007
Time Taken :  95.0  mins 52.12848901748657  seconds
[[[7831. 5144. 2843. 1541.  222.   94.   44.   15.]
  [4959. 1494.  473. 1037.  257.  220.   89.   38.]
  [3214.  896.  901. 1070.  307.  200.   77.   52.]
  [2093.  514.  862.  818.  294.  243.  112.   93.]
  [1818.  296.  498.  400.  136.  122.   91.   79.]
  [1670.  241.  227.  121.   28.   66.   62.   32.]
  [1448.  168.  105.   72.   48.   17.   25.    4.]
  [ 214.    0.   23.   33.   16.    4.    2.    1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  48
Q value #non_end_state_>threshold:  36
maxi score:  0.0021
siam score:  -0.90096307
Scores:  {'0.333': 0.0001, '0.667': 0.0021, '1.0': 0.0021, '1.333': 0.0001, '1.667': 0.0021, '2.0': 0.0021}
best rdn ma / adv:  0.667 0.667
best rdn adv:  0.014842452860031479
Episodes: 4829, frames: 60059, time: 7379.519649028778
training steps:  5164
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4829 : 0.0
LR:  0.001
replay buffer size:  62155
Time Taken :  122.0  mins 59.51949381828308  seconds
[[[8507. 5877. 3390. 1900.  258.  125.   57.   21.]
  [5685. 1675.  554. 1306.  332.  288.  128.   80.]
  [3794. 1072. 1102. 1349.  391.  282.  109.   78.]
  [2502.  604. 1035. 1039.  415.  386.  172.  145.]
  [2190.  353.  638.  502.  172.  210.  161.  139.]
  [2138.  290.  291.  157.   59.  147.  114.   73.]
  [1828.  212.  140.  107.   81.   45.   43.   14.]
  [ 284.    0.   33.   48.   48.   32.   18.    5.]]]
