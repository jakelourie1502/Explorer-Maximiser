Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0
siam score:  0.0
Scores:  {'0.25': 0, '0.5': 0, '0.75': 0, '1.0': 0}
best rdn ma / adv:  1 1
best rdn adv:  0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 71, frames: 862, time: 26.492369890213013
training steps:  0.0
retraining steps:  0.0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
71 : 0.0
LR:  0
replay buffer size:  1063
Time Taken :  0.0  mins 26.492167949676514  seconds
[[[262. 107.  53.  25.   4.   0.   0.   0.]
  [134.  42.  13.   7.   0.   0.   0.   0.]
  [ 65.  10.   4.   4.   0.   0.   0.   0.]
  [ 28.   7.   2.   3.   0.   0.   0.   0.]
  [ 12.   3.   0.   2.   0.   0.   0.   0.]
  [  2.   0.   0.   2.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6654014
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 911, frames: 10108, time: 2985.8062710762024
training steps:  1191.0
retraining steps:  0.0
RDN obj mus: [-0.9526425228655339, -0.9563713986635208, -0.9489137826263905, -0.9297345507646275, -0.7780251204967499]
RDN obj sigmas: [0.016361804401368894, 0.01910999904549712, 0.020414028868642693, 0.05123959668170379, 0.3487225788974914]
911 : 0.0
LR:  0.001
replay buffer size:  10567
Time Taken :  49.0  mins 45.80610513687134  seconds
[[[2815. 1328.  489.  216.   50.    4.    0.    0.]
  [1621.  574.  120.   62.   19.   16.    3.    4.]
  [ 818.  201.   58.   43.   16.   15.    5.    6.]
  [ 278.  115.   20.   23.   10.   11.    0.    4.]
  [ 117.   29.   11.   13.    2.    3.    1.   10.]
  [  34.    5.    4.    4.    0.    0.    2.    1.]
  [   7.    2.    3.    0.    0.    0.    1.    0.]
  [   3.    0.    1.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.71331614
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 1793, frames: 20028, time: 7200.299710988998
training steps:  2386.0
retraining steps:  0.0
RDN obj mus: [-0.9527580707848072, -0.9648532665252686, -0.9485579177618026, -0.9155930770993378, -0.7780251204967499]
RDN obj sigmas: [0.01680682283426818, 0.018298744639124127, 0.024713041907629987, 0.04421894574773379, 0.3487225788974914]
1793 : 0.0
LR:  0.001
replay buffer size:  20730
Time Taken :  120.0  mins 0.2995340824127197  seconds
[[[5580. 2389.  806.  307.   67.    4.    1.    0.]
  [3322. 1140.  208.  101.   37.   25.    5.    4.]
  [1699.  455.  116.   74.   29.   19.    7.    7.]
  [ 725.  242.   43.   39.   23.   14.    2.    8.]
  [ 308.   60.   21.   22.    6.    5.    1.   14.]
  [ 142.   22.    6.    7.    0.    1.    2.    5.]
  [  78.   10.    3.    0.    0.    1.    2.    1.]
  [  19.    0.    1.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7266079
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 2665, frames: 30064, time: 11026.962275981903
training steps:  3739.0
retraining steps:  0.0
RDN obj mus: [-0.9629710470557212, -0.9750763088703156, -0.9591462885320187, -0.9103540505767874, -0.7780251204967499]
RDN obj sigmas: [0.015969468383002373, 0.014390831697350425, 0.02215026826391606, 0.041631143208518476, 0.3487225788974914]
2665 : 0.0
LR:  0.001
replay buffer size:  30950
Time Taken :  183.0  mins 46.96207904815674  seconds
[[[8434. 3575. 1168.  418.   89.    5.    4.    0.]
  [5026. 1720.  292.  150.   65.   31.    7.    4.]
  [2542.  695.  192.  123.   43.   24.    7.    7.]
  [1042.  364.   67.   66.   31.   14.    2.    8.]
  [ 484.   83.   39.   33.    9.    5.    1.   14.]
  [ 254.   39.   14.    9.    0.    1.    2.    5.]
  [ 133.   14.    8.    1.    0.    1.    2.    1.]
  [  29.    0.    3.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7246198
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 3515, frames: 40056, time: 13949.987663030624
training steps:  4751.0
retraining steps:  0.0
RDN obj mus: [-0.9616151787340641, -0.9649189671814442, -0.9614651618540287, -0.9149372806087617, -0.7780251204967499]
RDN obj sigmas: [0.011423008372373537, 0.01601680362964642, 0.02003879488700783, 0.0397199350978758, 0.3487225788974914]
3515 : 0.0
LR:  0.001
replay buffer size:  41115
Time Taken :  232.0  mins 29.987468004226685  seconds
[[[11347.  4689.  1499.   514.   103.     7.     6.     0.]
  [ 6737.  2291.   386.   200.    73.    34.     9.     4.]
  [ 3430.   938.   256.   165.    63.    29.     8.     7.]
  [ 1401.   466.    88.    77.    39.    17.     3.     8.]
  [  680.   113.    52.    37.    11.     5.     1.    14.]
  [  365.    52.    27.    13.     0.     1.     2.     5.]
  [  182.    19.    18.     2.     0.     1.     2.     1.]
  [   40.     0.     4.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.70704323
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 4450, frames: 50073, time: 17592.30252790451
training steps:  6085.0
retraining steps:  0.0
RDN obj mus: [-0.9685677263975143, -0.9665732820928097, -0.9555515671491623, -0.9174501210521581, -0.7780251204967499]
RDN obj sigmas: [0.014704649223396657, 0.01619816634183931, 0.026332174472256616, 0.038965271960308245, 0.3487225788974914]
4450 : 0.0
LR:  0.001
replay buffer size:  51430
Time Taken :  293.0  mins 12.302335977554321  seconds
[[[14442.  6000.  1822.   597.   125.     8.     6.     0.]
  [ 8444.  2957.   471.   226.    85.    37.     9.     4.]
  [ 4141.  1127.   300.   180.    76.    35.    11.     7.]
  [ 1704.   568.   124.    92.    53.    21.     3.     8.]
  [  794.   131.    68.    45.    19.    11.     2.    14.]
  [  424.    66.    32.    16.     0.     1.     2.     5.]
  [  209.    23.    18.     2.     0.     1.     2.     1.]
  [   50.     0.     4.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.70890427
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 5379, frames: 60054, time: 21521.135980129242
training steps:  7477.0
retraining steps:  0.0
RDN obj mus: [-0.971816485273838, -0.9627287298858166, -0.9552532038807869, -0.9130710954646072, -0.7886102563805051]
RDN obj sigmas: [0.016962642885044562, 0.023629994724467168, 0.03255995178586136, 0.04181924167166474, 0.20197848954565606]
5379 : 0.0
LR:  0.001
replay buffer size:  61664
Time Taken :  358.0  mins 41.13578796386719  seconds
[[[17275.  7211.  2209.   689.   143.     8.     7.     2.]
  [10184.  3591.   568.   265.   103.    41.    13.     8.]
  [ 4853.  1338.   357.   227.   106.    48.    16.     9.]
  [ 2016.   673.   140.   113.    70.    24.     5.    10.]
  [  973.   169.    71.    56.    21.    11.     2.    19.]
  [  530.    75.    32.    20.     0.     1.     2.     5.]
  [  249.    33.    18.     2.     0.     1.     2.     1.]
  [   56.     0.     4.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7139231
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 6313, frames: 70103, time: 23963.791935920715
training steps:  8429.0
retraining steps:  0.0
RDN obj mus: [-0.9716090606689454, -0.9610713609874248, -0.9551524881005287, -0.9115833465078371, -0.8151868760585785]
RDN obj sigmas: [0.016774029063204382, 0.021516417737967156, 0.032053400661650536, 0.042616390303020814, 0.1618516041017051]
6313 : 0.0
LR:  0.001
replay buffer size:  71935
Time Taken :  399.0  mins 23.79175591468811  seconds
[[[20076.  8414.  2606.   821.   173.    10.     8.     2.]
  [11880.  4214.   664.   325.   120.    49.    14.     8.]
  [ 5658.  1530.   412.   266.   126.    60.    19.     9.]
  [ 2377.   788.   179.   149.    86.    39.     7.    10.]
  [ 1119.   198.    81.    66.    26.    16.     3.    19.]
  [  590.    86.    37.    23.     1.     3.     4.     5.]
  [  277.    39.    19.     2.     0.     2.     3.     1.]
  [   67.     0.     4.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.71417
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 7249, frames: 80072, time: 27390.40879011154
training steps:  9481.0
retraining steps:  0.0
RDN obj mus: [-0.973224853181839, -0.9666754414439201, -0.960665433138609, -0.911703070466435, -0.8149220001312995]
RDN obj sigmas: [0.014711913413130362, 0.018285358757474765, 0.030667430445050943, 0.0456614638044294, 0.15922630482730818]
7249 : 0.0
LR:  0.001
replay buffer size:  82152
Time Taken :  456.0  mins 30.4085910320282  seconds
[[[22898.  9735.  3022.   935.   196.    14.     9.     2.]
  [13535.  4853.   766.   375.   147.    58.    15.     8.]
  [ 6405.  1718.   461.   307.   150.    67.    21.     9.]
  [ 2649.   901.   209.   172.    96.    44.     9.    12.]
  [ 1261.   220.    97.    78.    29.    16.     3.    20.]
  [  652.    97.    43.    26.     1.     3.     4.     5.]
  [  312.    48.    20.     5.     0.     2.     3.     1.]
  [   75.     0.     4.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6972011
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 8183, frames: 90040, time: 30438.36495399475
training steps:  10817.0
retraining steps:  0.0
RDN obj mus: [-0.9659534809529782, -0.9707248266041278, -0.9553098282873631, -0.9102939366533466, -0.8138419613242149]
RDN obj sigmas: [0.01846936368787903, 0.02070160131618418, 0.030799113783362163, 0.046049674134032485, 0.14108869639019866]
8183 : 0.0
LR:  0.001
replay buffer size:  92354
Time Taken :  507.0  mins 18.364754915237427  seconds
[[[25736. 11088.  3449.  1094.   242.    26.    11.     2.]
  [15090.  5481.   864.   452.   179.    83.    20.     8.]
  [ 7056.  1901.   525.   353.   182.    88.    26.     9.]
  [ 2905.   999.   246.   200.   111.    56.    13.    12.]
  [ 1394.   243.   107.    94.    36.    19.     9.    29.]
  [  709.   106.    48.    30.     1.     3.     5.     7.]
  [  335.    54.    22.     6.     0.     2.     3.     2.]
  [   82.     0.     4.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7060054
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 9124, frames: 100064, time: 33585.91860103607
training steps:  12147.0
retraining steps:  0.0
RDN obj mus: [-0.9479402261376381, -0.9532106288313865, -0.9434690845370293, -0.9052075164174773, -0.7969842562752385]
RDN obj sigmas: [0.05208386015168485, 0.017735185477179515, 0.03806783802497807, 0.048749661680731, 0.1235705596184884]
9124 : 0.0
LR:  0.001
replay buffer size:  102620
Time Taken :  559.0  mins 45.91840410232544  seconds
[[[28503. 12323.  3893.  1245.   270.    32.    13.     3.]
  [16661.  6094.   970.   529.   203.   101.    26.    18.]
  [ 7762.  2089.   588.   393.   204.   100.    30.    13.]
  [ 3292.  1122.   273.   221.   122.    61.    13.    12.]
  [ 1574.   269.   122.   104.    41.    20.     9.    29.]
  [  805.   125.    51.    32.     1.     3.     5.     7.]
  [  373.    59.    25.     6.     0.     2.     3.     2.]
  [   90.     0.     4.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.70750725
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 10054, frames: 110062, time: 36714.39819383621
training steps:  13476.0
retraining steps:  0.0
RDN obj mus: [-0.9715133866846561, -0.9749279461562633, -0.9567640541732311, -0.9047843119196138, -0.8110428225052985]
RDN obj sigmas: [0.021690219533339942, 0.014342578233990221, 0.03453670524837685, 0.047753999563491634, 0.1167398423072797]
10054 : 0.0
LR:  0.001
replay buffer size:  112839
Time Taken :  611.0  mins 54.39798903465271  seconds
[[[31329. 13443.  4211.  1345.   294.    42.    17.     4.]
  [18280.  6695.  1072.   581.   239.   118.    32.    21.]
  [ 8613.  2303.   665.   446.   247.   128.    35.    13.]
  [ 3687.  1260.   305.   258.   141.    69.    13.    12.]
  [ 1702.   291.   139.   117.    50.    22.     9.    29.]
  [  876.   142.    71.    35.     1.     3.     5.     7.]
  [  387.    61.    33.     6.     0.     2.     3.     2.]
  [   93.     0.     4.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.71438706
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 10936, frames: 120062, time: 39861.604170084
training steps:  14817.0
retraining steps:  0.0
RDN obj mus: [-0.9633648508250713, -0.9642382495462894, -0.9515006583571434, -0.9055003723498202, -0.8238282993938146]
RDN obj sigmas: [0.025537810898490644, 0.022109651256876833, 0.03143638507171238, 0.04651076487133912, 0.11289688415186346]
10936 : 0.0
LR:  0.001
replay buffer size:  123078
Time Taken :  664.0  mins 21.60396695137024  seconds
[[[34302. 14661.  4639.  1510.   327.    55.    23.     6.]
  [19880.  7267.  1187.   640.   271.   141.    43.    27.]
  [ 9355.  2482.   726.   474.   279.   143.    40.    15.]
  [ 3991.  1353.   331.   271.   153.    71.    13.    12.]
  [ 1845.   316.   150.   120.    54.    23.     9.    29.]
  [  947.   153.    78.    35.     1.     4.     5.     7.]
  [  436.    66.    36.     6.     0.     3.     4.     2.]
  [  104.     0.     5.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.70367956
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 11844, frames: 130043, time: 42943.582558870316
training steps:  16129.0
retraining steps:  0.0
RDN obj mus: [-0.9565288093745709, -0.939741794526577, -0.9472717311620712, -0.9057917583597025, -0.8257341417281524]
RDN obj sigmas: [0.025042629198167344, 0.02660871174174803, 0.03563177901667856, 0.04605126013103183, 0.11165091022585111]
11844 : 0.0
LR:  0.001
replay buffer size:  133255
Time Taken :  715.0  mins 43.58236002922058  seconds
[[[37234. 15796.  5049.  1674.   366.    65.    29.     9.]
  [21371.  7862.  1272.   698.   311.   161.    50.    30.]
  [10066.  2668.   788.   516.   314.   167.    42.    16.]
  [ 4343.  1459.   365.   309.   166.    83.    18.    18.]
  [ 2028.   350.   169.   143.    62.    25.    10.    29.]
  [ 1036.   168.    87.    39.     1.     4.     5.     7.]
  [  479.    73.    38.     6.     0.     3.     4.     2.]
  [  110.     0.     6.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7041528
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 12815, frames: 140066, time: 46003.462171792984
training steps:  17432.0
retraining steps:  0.0
RDN obj mus: [-0.9688014981865883, -0.9817441489815713, -0.9563142268359661, -0.906573171737841, -0.8325473506851951]
RDN obj sigmas: [0.01930153371720243, 0.015210610175798068, 0.0346896072427688, 0.046016206141203574, 0.10912348251134364]
12815 : 0.0
LR:  0.001
replay buffer size:  143459
Time Taken :  766.0  mins 43.461979150772095  seconds
[[[40146. 17022.  5429.  1777.   401.    76.    30.     9.]
  [22969.  8492.  1379.   752.   351.   188.    52.    30.]
  [10777.  2884.   857.   555.   343.   180.    44.    16.]
  [ 4621.  1593.   398.   340.   185.    88.    22.    19.]
  [ 2153.   378.   185.   158.    74.    25.    12.    32.]
  [ 1098.   178.   102.    45.     2.     5.     8.    10.]
  [  511.    79.    40.     6.     0.     3.     4.     2.]
  [  110.     0.     6.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6974253
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 13743, frames: 150084, time: 49048.868753910065
training steps:  18726.0
retraining steps:  0.0
RDN obj mus: [-0.9594762825131417, -0.9509084798157215, -0.9533057591557502, -0.9072802738203902, -0.8534061880111694]
RDN obj sigmas: [0.025035586101619288, 0.022426438858256136, 0.03273656891411876, 0.04614663913912936, 0.10739251751256551]
13743 : 0.0
LR:  0.001
replay buffer size:  153711
Time Taken :  817.0  mins 28.868552923202515  seconds
[[[43198. 18285.  5769.  1892.   438.    80.    32.     9.]
  [24603.  9110.  1490.   804.   374.   200.    52.    30.]
  [11419.  3052.   928.   610.   369.   187.    46.    18.]
  [ 4929.  1686.   437.   375.   204.    94.    27.    25.]
  [ 2286.   403.   202.   178.    80.    26.    14.    34.]
  [ 1164.   191.   109.    54.     2.     5.     8.    11.]
  [  536.    82.    44.     6.     0.     3.     4.     2.]
  [  119.     0.     6.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.72174615
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 14606, frames: 160086, time: 52116.49585008621
training steps:  20009.0
retraining steps:  0.0
RDN obj mus: [-0.9627077793300152, -0.9801224598646164, -0.9476544870436192, -0.8999394537933486, -0.8317437302058851]
RDN obj sigmas: [0.02115333691149684, 0.013894418780938857, 0.044095329010699444, 0.05908999782227758, 0.12732170315717764]
14606 : 0.0
LR:  0.001
replay buffer size:  163938
Time Taken :  868.0  mins 36.49564599990845  seconds
[[[46373. 19522.  6139.  2022.   469.   102.    35.     9.]
  [26145.  9685.  1594.   865.   398.   224.    57.    31.]
  [12052.  3219.   993.   658.   384.   198.    51.    18.]
  [ 5238.  1764.   473.   416.   225.   111.    31.    25.]
  [ 2442.   430.   222.   200.    93.    27.    14.    34.]
  [ 1226.   203.   124.    59.     2.     5.     8.    11.]
  [  567.    86.    48.     8.     2.     4.     5.     2.]
  [  124.     0.     6.     2.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7157968
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 15477, frames: 170205, time: 54079.70295596123
training steps:  20716.0
retraining steps:  0.0
RDN obj mus: [-0.9617094855427742, -0.9397768362939358, -0.9517491943180562, -0.900236879034478, -0.8305276792624902]
RDN obj sigmas: [0.01883918330313977, 0.022505743729774447, 0.03579901321102528, 0.05793815633025628, 0.12628719343609832]
15477 : 0.0
LR:  0.001
replay buffer size:  174342
Time Taken :  901.0  mins 19.70275616645813  seconds
[[[49392. 20782.  6517.  2122.   496.   121.    38.    13.]
  [27715. 10249.  1692.   931.   429.   247.    58.    37.]
  [12811.  3436.  1062.   707.   424.   228.    59.    24.]
  [ 5566.  1882.   514.   460.   255.   133.    45.    32.]
  [ 2571.   455.   236.   216.    99.    30.    18.    36.]
  [ 1272.   211.   127.    64.     2.     5.     8.    11.]
  [  590.    90.    50.    10.     2.     4.     5.     2.]
  [  129.     0.     6.     2.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.72601503
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 16344, frames: 180124, time: 55984.0842359066
training steps:  21412.0
retraining steps:  0.0
RDN obj mus: [-0.9627303667426109, -0.9705334539830685, -0.9582192670047284, -0.8999459112465381, -0.8313042937892757]
RDN obj sigmas: [0.015561072606528328, 0.018386869251277735, 0.03137398034324995, 0.0579458161580291, 0.12620092352726348]
16344 : 0.0
LR:  0.001
replay buffer size:  184431
Time Taken :  933.0  mins 4.084038019180298  seconds
[[[52413. 22007.  6896.  2233.   524.   130.    42.    13.]
  [29258. 10817.  1782.   992.   456.   266.    61.    37.]
  [13499.  3630.  1129.   778.   464.   251.    66.    24.]
  [ 5857.  1983.   537.   501.   281.   146.    47.    32.]
  [ 2728.   486.   251.   232.   107.    33.    18.    36.]
  [ 1355.   222.   128.    67.     4.     7.     8.    11.]
  [  618.    95.    51.    10.     2.     4.     5.     2.]
  [  139.     0.     7.     2.     0.     0.     0.     0.]]]
