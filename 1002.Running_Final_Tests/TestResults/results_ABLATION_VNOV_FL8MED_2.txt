Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0
siam score:  0.0
Scores:  {'0.25': 0, '0.5': 0, '0.75': 0, '1.0': 0}
best rdn ma / adv:  1 1
best rdn adv:  0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 90, frames: 857, time: 31.807714223861694
training steps:  0.0
retraining steps:  0.0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
90 : 0.0
LR:  0
replay buffer size:  1151
Time Taken :  0.0  mins 31.80717706680298  seconds
[[[244. 128.  48.  24.   7.   0.   0.   0.]
  [123.  61.  11.   5.   0.   0.   0.   0.]
  [ 62.  18.   1.   1.   0.   0.   0.   0.]
  [ 12.   7.   0.   1.   0.   0.   0.   0.]
  [  5.   2.   1.   2.   1.   0.   0.   0.]
  [  1.   0.   0.   0.   0.   0.   0.   0.]
  [  1.   0.   0.   0.   0.   0.   0.   0.]
  [  1.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.66434234
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 864, frames: 10081, time: 2982.1087729930878
training steps:  1187.0
retraining steps:  0.0
RDN obj mus: [-0.9450134845018386, -0.9624151079773903, -0.9513031685769558, -0.898805356874664, 0.0]
RDN obj sigmas: [0.021064645499279087, 0.013951907133118962, 0.0206583367009867, 0.05829613276261174, 0.0]
864 : 0.0
LR:  0.001
replay buffer size:  10636
Time Taken :  49.0  mins 42.108272314071655  seconds
[[[3104. 1371.  499.  156.   34.    1.    1.    0.]
  [1564.  583.  128.   64.   17.    5.    1.    0.]
  [ 732.  183.   68.   37.   11.    4.    2.    0.]
  [ 268.   82.   25.   36.    9.    5.    2.    1.]
  [ 102.   15.    6.    9.    3.    3.    1.    0.]
  [  32.    4.    1.    1.    2.    2.    1.    0.]
  [  18.    4.    1.    0.    5.    3.    0.    0.]
  [   5.    0.    2.    1.    3.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.71564376
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 1793, frames: 20066, time: 7215.7987949848175
training steps:  2385.0
retraining steps:  0.0
RDN obj mus: [-0.9638699304282665, -0.9708346149146557, -0.9642178125262261, -0.9154941061722863, 0.0]
RDN obj sigmas: [0.014742312677720698, 0.01755613580076504, 0.01607770820438074, 0.045087747028418605, 0.0]
1793 : 0.0
LR:  0.001
replay buffer size:  20843
Time Taken :  120.0  mins 15.79826807975769  seconds
[[[6118. 2709.  890.  320.   64.    8.    1.    0.]
  [3081. 1237.  247.  142.   49.   10.    2.    1.]
  [1481.  396.  142.   79.   35.    5.    4.    1.]
  [ 535.  182.   45.   50.   27.    7.    2.    1.]
  [ 204.   30.    6.   10.    5.    3.    1.    0.]
  [  72.    8.    1.    1.    2.    2.    1.    0.]
  [  29.    5.    1.    0.    5.    3.    0.    0.]
  [   7.    0.    2.    1.    3.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7162729
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 2705, frames: 30036, time: 11024.949215173721
training steps:  3725.0
retraining steps:  0.0
RDN obj mus: [-0.9685407298743725, -0.971382464569807, -0.95647871799469, -0.9179256107907273, -0.6306615869204203]
RDN obj sigmas: [0.015418530519114368, 0.013811418982319119, 0.021949533579072446, 0.038423164000860446, 0.4459451234051756]
2705 : 0.0
LR:  0.001
replay buffer size:  31036
Time Taken :  183.0  mins 44.94868516921997  seconds
[[[9012. 3992. 1336.  482.   94.    8.    2.    0.]
  [4767. 1864.  375.  205.   73.   15.    5.    6.]
  [2204.  617.  221.  136.   66.   15.    5.    5.]
  [ 785.  275.   63.   71.   44.   17.    4.    2.]
  [ 285.   47.   14.   13.   10.    3.    3.    2.]
  [  93.   13.    1.    1.    2.    2.    2.    1.]
  [  41.    7.    1.    0.    5.    3.    0.    1.]
  [   9.    0.    2.    1.    3.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6941464
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 3580, frames: 40054, time: 13914.611405849457
training steps:  4723.0
retraining steps:  0.0
RDN obj mus: [-0.9730365551114082, -0.9796014978826046, -0.9561030854284763, -0.9187430589207185, -0.6306615869204203]
RDN obj sigmas: [0.015113067572469753, 0.008785921882844558, 0.022084839213303117, 0.03587124298442936, 0.4459451234051756]
3580 : 0.0
LR:  0.001
replay buffer size:  41284
Time Taken :  231.0  mins 54.610867977142334  seconds
[[[12205.  5236.  1784.   642.   124.     8.     3.     0.]
  [ 6405.  2474.   495.   256.    89.    21.     7.     8.]
  [ 2893.   814.   267.   159.    76.    16.     7.     8.]
  [ 1051.   354.    76.    78.    52.    19.     8.     9.]
  [  415.    63.    22.    17.    13.     3.     5.     6.]
  [  147.    18.     2.     2.     2.     2.     3.     2.]
  [   68.    12.     1.     0.     5.     3.     0.     1.]
  [   12.     0.     2.     1.     3.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7173528
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 4423, frames: 50047, time: 17537.65318107605
training steps:  6053.0
retraining steps:  0.0
RDN obj mus: [-0.974149154561758, -0.982427978771925, -0.9566167895376683, -0.9194838383247815, -0.7499415636062622]
RDN obj sigmas: [0.014472882449649614, 0.009442546870556397, 0.02728193597424713, 0.03383307733247498, 0.3750507280457315]
4423 : 0.0
LR:  0.001
replay buffer size:  51444
Time Taken :  292.0  mins 17.652650117874146  seconds
[[[15348.  6454.  2136.   763.   151.     9.     5.     0.]
  [ 8156.  3064.   594.   308.   116.    33.     8.     8.]
  [ 3619.  1001.   351.   186.    87.    21.     7.     8.]
  [ 1344.   440.   104.    88.    56.    23.     8.     9.]
  [  572.    90.    28.    25.    13.     3.     5.     6.]
  [  205.    25.     2.     3.     2.     2.     3.     2.]
  [   89.    15.     1.     0.     5.     3.     0.     1.]
  [   13.     0.     2.     1.     3.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7263646
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0021}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.00199960002
rdn probs:  [0.12504498530497532, 0.12504498530497532, 0.12504498530497532, 0.6248650440850739]
Episodes: 5329, frames: 60025, time: 21484.19019818306
training steps:  7451.0
retraining steps:  0.0
RDN obj mus: [-0.9640847056925297, -0.9651045318901539, -0.9468714665293694, -0.9146941599847201, -0.7703657373785973]
RDN obj sigmas: [0.020343564751177417, 0.020057327834638858, 0.033443449400039585, 0.03636543236644392, 0.29786359508753546]
5329 : 0.0
LR:  0.001
replay buffer size:  61624
Time Taken :  358.0  mins 4.189659118652344  seconds
[[[18577.  7879.  2577.   943.   192.    18.     6.     0.]
  [ 9600.  3708.   702.   384.   150.    46.     9.     8.]
  [ 4195.  1180.   416.   243.   105.    30.    10.     8.]
  [ 1538.   514.   122.   110.    64.    27.    10.     9.]
  [  644.   107.    34.    36.    20.     5.     7.     6.]
  [  241.    31.     4.     6.     7.     6.     3.     2.]
  [   94.    16.     1.     0.     9.     9.     0.     1.]
  [   13.     0.     2.     1.     3.     3.     4.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7623323
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 6241, frames: 70156, time: 24312.09555697441
training steps:  8510.0
retraining steps:  0.0
RDN obj mus: [-0.9713683190643787, -0.9780449951291085, -0.9689343256652355, -0.909806793162261, -0.7928549289703369]
RDN obj sigmas: [0.009628861758091377, 0.011007421128658754, 0.019255752710914432, 0.03967315999507317, 0.2196893577759774]
6241 : 0.0
LR:  0.001
replay buffer size:  71981
Time Taken :  405.0  mins 12.09504508972168  seconds
[[[21888.  9135.  2918.  1059.   218.    22.     7.     0.]
  [11350.  4372.   786.   426.   174.    54.    10.     8.]
  [ 4900.  1359.   473.   270.   119.    43.    12.     8.]
  [ 1771.   615.   145.   127.    82.    36.    11.     9.]
  [  734.   119.    37.    48.    23.     8.    11.     6.]
  [  272.    40.     5.     8.     7.     7.     4.     3.]
  [  104.    20.     1.     0.     9.    10.     1.     2.]
  [   15.     0.     2.     1.     3.     3.     4.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  1
maxi score:  0.0001
siam score:  -0.7219884
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 7079, frames: 80093, time: 27370.605360031128
training steps:  9440.0
retraining steps:  0.0
RDN obj mus: [-0.9616977194607258, -0.9731824543774128, -0.9578810408234596, -0.9114002495877235, -0.7928549289703369]
RDN obj sigmas: [0.017499466977586673, 0.016843155388049966, 0.02239922325742195, 0.038954233692535936, 0.2196893577759774]
7079 : 0.0
LR:  0.001
replay buffer size:  82207
Time Taken :  456.0  mins 10.604815244674683  seconds
[[[25265. 10366.  3284.  1205.   247.    27.     9.     0.]
  [12985.  4953.   888.   473.   209.    70.    12.     8.]
  [ 5518.  1518.   529.   293.   140.    53.    15.     8.]
  [ 1998.   697.   175.   154.    92.    44.    17.     9.]
  [  832.   141.    55.    63.    26.    11.    15.     6.]
  [  314.    47.    12.    10.     7.     8.     4.     3.]
  [  116.    24.     1.     0.     9.    12.     2.     2.]
  [   15.     0.     2.     1.     3.     6.     5.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  1
maxi score:  0.0001
siam score:  -0.73956954
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0021, '1.0': 0.0001}
best rdn ma / adv:  0.75 0.75
best rdn adv:  0.00199960002
rdn probs:  [0.12504498530497532, 0.12504498530497532, 0.6248650440850739, 0.12504498530497532]
Episodes: 7933, frames: 90035, time: 30414.126878023148
training steps:  10770.0
retraining steps:  0.0
RDN obj mus: [-0.967528529381752, -0.9678544890582561, -0.9590807381570339, -0.9112996483008411, -0.7980303413727704]
RDN obj sigmas: [0.028146734670679296, 0.017662423418771146, 0.03267076480413959, 0.03901934710308969, 0.20773569037955877]
7933 : 0.0
LR:  0.001
replay buffer size:  92354
Time Taken :  506.0  mins 54.126336097717285  seconds
[[[28377. 11595.  3671.  1335.   270.    27.    10.     0.]
  [14689.  5519.  1000.   522.   225.    78.    15.     8.]
  [ 6227.  1678.   591.   326.   170.    78.    16.     8.]
  [ 2227.   789.   211.   175.   109.    57.    18.    10.]
  [  942.   164.    74.    85.    35.    15.    16.     9.]
  [  364.    59.    21.    16.    11.    12.     5.     3.]
  [  134.    27.     2.     3.    13.    14.     3.     2.]
  [   19.     0.     2.     1.     4.     8.     6.     2.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  1
maxi score:  0.0001
siam score:  -0.79818606
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 8797, frames: 100076, time: 33568.45918917656
training steps:  12106.0
retraining steps:  0.0
RDN obj mus: [-0.9725880013525486, -0.9555210101544857, -0.9640733363568783, -0.9095982027562969, -0.7519970655441284]
RDN obj sigmas: [0.018353674901792946, 0.027151238058223556, 0.029489670629546657, 0.043131867750220675, 0.16337801900526924]
8797 : 0.0
LR:  0.001
replay buffer size:  102656
Time Taken :  559.0  mins 28.458649158477783  seconds
[[[31605. 12785.  4045.  1467.   300.    33.    12.     0.]
  [16285.  6087.  1098.   582.   249.    94.    15.     8.]
  [ 6935.  1859.   658.   373.   193.   100.    22.     8.]
  [ 2498.   886.   238.   203.   124.    67.    22.    10.]
  [ 1070.   191.    92.    95.    44.    22.    22.    10.]
  [  416.    74.    26.    20.    13.    16.     9.     4.]
  [  149.    32.     3.     4.    16.    20.     4.     2.]
  [   20.     0.     3.     4.    12.    17.     6.     2.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  1
maxi score:  0.0001
siam score:  -0.7452245
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 9706, frames: 110072, time: 36709.42711687088
training steps:  13439.0
retraining steps:  0.0
RDN obj mus: [-0.952062175321579, -0.9706477984547615, -0.9520290992677212, -0.9057296297497746, -0.7700372164899653]
RDN obj sigmas: [0.04204585379124342, 0.014627112743558502, 0.041590747968785445, 0.04578151952374079, 0.15382690464032445]
9706 : 0.0
LR:  0.001
replay buffer size:  112819
Time Taken :  611.0  mins 49.42657804489136  seconds
[[[34722. 13968.  4495.  1606.   330.    36.    14.     1.]
  [17833.  6679.  1211.   633.   263.   103.    22.    14.]
  [ 7583.  2003.   708.   396.   211.   116.    28.    13.]
  [ 2846.   990.   259.   231.   144.    88.    29.    14.]
  [ 1225.   222.   103.   107.    48.    31.    30.    13.]
  [  474.    92.    34.    25.    19.    21.    10.     5.]
  [  166.    33.     4.     4.    18.    20.     5.     2.]
  [   21.     0.     4.     4.    12.    17.     6.     2.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  1
Q value #non_end_state_>threshold:  1
maxi score:  0.0001
siam score:  -0.7367334
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 10620, frames: 120067, time: 39880.33010387421
training steps:  14789.0
retraining steps:  0.0
RDN obj mus: [-0.9623787793517112, -0.9760527599990367, -0.9510635996580123, -0.8984157520772558, -0.7582065003258841]
RDN obj sigmas: [0.048187119198633624, 0.015044816205351816, 0.05625305236188717, 0.053385040159576305, 0.11909064168138296]
10620 : 0.0
LR:  0.001
replay buffer size:  123084
Time Taken :  664.0  mins 40.32956004142761  seconds
[[[37841. 15143.  4893.  1740.   365.    44.    16.     2.]
  [19472.  7263.  1330.   682.   280.   117.    27.    23.]
  [ 8271.  2162.   772.   439.   227.   130.    32.    18.]
  [ 3126.  1099.   287.   260.   152.   100.    33.    21.]
  [ 1318.   247.   119.   128.    56.    44.    34.    24.]
  [  507.   102.    41.    32.    21.    26.    13.    12.]
  [  181.    39.     6.     5.    20.    22.     6.     2.]
  [   24.     0.     5.     7.    12.    18.     7.     2.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  1
Q value #non_end_state_>threshold:  1
maxi score:  0.0001
siam score:  -0.7284481
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 11579, frames: 130063, time: 42977.7322909832
training steps:  16109.0
retraining steps:  0.0
RDN obj mus: [-0.9701969056487083, -0.9812212415158749, -0.9334125787973404, -0.8954707202519756, -0.7637005960568786]
RDN obj sigmas: [0.024826056692156043, 0.012656096409061061, 0.06542420143252407, 0.05714174124596468, 0.11378053243594077]
11579 : 0.0
LR:  0.001
replay buffer size:  133235
Time Taken :  716.0  mins 17.731751918792725  seconds
[[[40824. 16488.  5341.  1880.   397.    55.    19.     9.]
  [21065.  7911.  1451.   741.   318.   138.    39.    34.]
  [ 8881.  2308.   809.   466.   262.   149.    43.    23.]
  [ 3353.  1192.   301.   276.   171.   111.    37.    22.]
  [ 1429.   265.   130.   135.    62.    45.    35.    24.]
  [  574.   116.    51.    35.    22.    27.    13.    12.]
  [  210.    42.     6.     5.    20.    22.     6.     2.]
  [   31.     0.     5.     7.    12.    18.     7.     2.]]]
Test reward:  0.05
Q value #end_state_>_threshold:  9
Q value #non_end_state_>threshold:  4
maxi score:  0.0001
siam score:  -0.7242764
Scores:  {'0.25': 0.0021, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.00199960002
rdn probs:  [0.6248650440850742, 0.12504498530497535, 0.12504498530497535, 0.12504498530497535]
Episodes: 12494, frames: 140040, time: 46045.834393024445
training steps:  17418.0
retraining steps:  0.0
RDN obj mus: [-0.9747817596316337, -0.9702173665344715, -0.9579336026310921, -0.8943030898825686, -0.7620360298661997]
RDN obj sigmas: [0.023389630603033944, 0.03021253459454932, 0.0358989434671552, 0.058704616999312134, 0.11112426026797392]
12494 : 0.0
LR:  0.001
replay buffer size:  143402
Time Taken :  767.0  mins 25.833850145339966  seconds
[[[43997. 17801.  5744.  2044.   447.    67.    21.     9.]
  [22655.  8494.  1564.   772.   336.   149.    41.    36.]
  [ 9553.  2458.   862.   499.   284.   155.    47.    23.]
  [ 3596.  1299.   318.   293.   181.   118.    42.    23.]
  [ 1514.   283.   139.   148.    68.    47.    39.    28.]
  [  617.   134.    56.    42.    22.    28.    14.    15.]
  [  223.    45.     7.     6.    20.    24.     7.     2.]
  [   33.     0.     5.     7.    12.    22.     8.     3.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  28
Q value #non_end_state_>threshold:  70
maxi score:  0.0041
siam score:  -0.870666
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0061, '1.0': 0.0001}
best rdn ma / adv:  0.75 0.75
best rdn adv:  0.005415
rdn probs:  [0.12504025711384392, 0.12504025711384392, 0.6248792286584682, 0.12504025711384392]
Episodes: 13430, frames: 150155, time: 49140.84668183327
training steps:  18738.0
retraining steps:  0.0
RDN obj mus: [-0.9635021843731403, -0.9595902359604835, -0.9487392881691455, -0.8904355006992817, -0.7665396978875169]
RDN obj sigmas: [0.03106585666522539, 0.04851058512679102, 0.044019199812397686, 0.06119277678539129, 0.10373176719253356]
13430 : 0.0
LR:  0.001
replay buffer size:  153836
Time Taken :  819.0  mins 0.8461410999298096  seconds
[[[47099. 19029.  6163.  2197.   488.    85.    25.    10.]
  [24182.  9101.  1678.   826.   366.   183.    50.    40.]
  [10147.  2608.   929.   552.   328.   182.    58.    27.]
  [ 3845.  1383.   351.   321.   207.   146.    57.    27.]
  [ 1599.   306.   160.   165.    76.    57.    44.    32.]
  [  662.   147.    64.    50.    25.    37.    17.    17.]
  [  266.    53.     9.     8.    29.    42.    10.     3.]
  [   40.     0.     5.     9.    23.    37.    36.     7.]]]
Test reward:  0.45
Q value #end_state_>_threshold:  344
Q value #non_end_state_>threshold:  477
maxi score:  0.042100000000000005
siam score:  -0.89745
Scores:  {'0.25': 0.0041, '0.5': 0.058100000000000006, '0.75': 0.0301, '1.0': 0.0021}
best rdn ma / adv:  0.5 0.5
best rdn adv:  0.05321919978
rdn probs:  [0.11273083017793088, 0.4928608389159685, 0.29575638994068965, 0.09865194096541097]
Episodes: 14183, frames: 160093, time: 51816.15936398506
training steps:  19835.0
retraining steps:  0.0
RDN obj mus: [-0.9409910521864892, -0.9407132954597474, -0.9180657578706741, -0.8748253756344319, -0.8732646897006721]
RDN obj sigmas: [0.049360488833917006, 0.05907113109602986, 0.054244326909535984, 0.06135587668427058, 0.058201433536158996]
14183 : 0.2
LR:  0.001
replay buffer size:  164065
Time Taken :  863.0  mins 36.15882706642151  seconds
[[[49311. 20026.  6549.  2410.   537.   122.    37.    26.]
  [25231.  9502.  1764.   957.   434.   226.    63.    54.]
  [10571.  2801.  1062.   693.   444.   285.    76.    37.]
  [ 3954.  1435.   393.   393.   312.   334.   118.    79.]
  [ 1637.   316.   173.   172.    93.   235.   118.    79.]
  [  680.   153.    76.    61.    90.   272.    89.    49.]
  [  284.    59.    22.    51.   133.   208.    29.     5.]
  [   43.     0.    11.    47.   119.   174.   134.    62.]]]
Test reward:  0.95
Q value #end_state_>_threshold:  1201
Q value #non_end_state_>threshold:  3106
maxi score:  0.1281
siam score:  -0.89539367
Scores:  {'0.25': 0.1121, '0.5': 0.1661, '0.75': 0.0901, '1.0': 0.0121}
best rdn ma / adv:  0.5 0.5
best rdn adv:  0.05021500000000001
rdn probs:  [0.28496296441337926, 0.3960217925499957, 0.23971677517253556, 0.07929846786408958]
Episodes: 14700, frames: 170086, time: 53775.62961387634
training steps:  20552.0
retraining steps:  0.0
RDN obj mus: [-0.9367738334536553, -0.9278885850846768, -0.9303884992718696, -0.9339635931134224, -0.9369974618554116]
RDN obj sigmas: [0.03629132477922359, 0.04183472479389832, 0.0355707642585058, 0.028724274703038098, 0.025016955250260767]
14700 : 0.2
LR:  0.001
replay buffer size:  174447
Time Taken :  896.0  mins 15.629080057144165  seconds
[[[50329. 20505.  6810.  2600.   557.   140.    41.    34.]
  [25775.  9627.  1819.  1146.   491.   249.    68.    58.]
  [11031.  3096.  1349.  1046.   760.   481.    96.    46.]
  [ 3994.  1458.   450.   568.   644.   815.   228.   146.]
  [ 1657.   319.   182.   175.   131.   670.   239.   119.]
  [  692.   157.    85.    69.   240.   741.   180.    71.]
  [  289.    60.    34.    95.   359.   574.    64.     7.]
  [   45.     0.    11.    79.   274.   581.   491.   239.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2250
Q value #non_end_state_>threshold:  6493
maxi score:  0.2741
siam score:  -0.9016065
Scores:  {'0.25': 0.24209999999999998, '0.5': 0.2741, '0.75': 0.1281, '1.0': 0.0201}
best rdn ma / adv:  0.5 0.5
best rdn adv:  0.0006850000000000011
rdn probs:  [0.3406386494650412, 0.3788022913450585, 0.2046806752674794, 0.07587838392242095]
Episodes: 15128, frames: 180034, time: 55731.5758869648
training steps:  21263.0
retraining steps:  0.0
RDN obj mus: [-0.9443535902380943, -0.9399299125611782, -0.9403036483585835, -0.9447325448334217, -0.9384609957933426]
RDN obj sigmas: [0.02900091863852289, 0.031389538485827, 0.031056645592279095, 0.026978477067634208, 0.030641113296286063]
15128 : 0.5
LR:  0.001
replay buffer size:  184740
Time Taken :  928.0  mins 51.57535219192505  seconds
[[[50729. 20839.  7077.  2836.   579.   210.    50.    37.]
  [26091.  9673.  1851.  1405.   589.   312.    72.    63.]
  [11291.  3321.  1604.  1471.  1133.   777.   115.    57.]
  [ 4012.  1470.   501.   777.  1047.  1504.   438.   223.]
  [ 1658.   321.   193.   189.   175.  1205.   452.   202.]
  [  692.   157.    93.    82.   409.  1279.   347.   109.]
  [  289.    60.    53.   173.   584.   969.    96.     7.]
  [   45.     0.    14.   159.   450.  1010.   848.   432.]]]
