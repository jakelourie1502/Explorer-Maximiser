Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0
siam score:  0.0
Scores:  {'0.25': 0, '0.5': 0, '0.75': 0, '1.0': 0}
best rdn ma / adv:  1 1
best rdn adv:  0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 52, frames: 609, time: 29.04797077178955
training steps:  0.0
retraining steps:  0.0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
52 : 0.0
LR:  0
replay buffer size:  834
Time Taken :  0.0  mins 29.04769992828369  seconds
[[[185.  91.  42.  16.   3.   0.   0.   0.]
  [ 83.  32.  10.   9.   4.   0.   0.   0.]
  [ 41.   9.   3.   3.   3.   2.   1.   0.]
  [ 10.   5.   1.   1.   0.   0.   0.   0.]
  [  2.   1.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.66760117
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 960, frames: 10065, time: 2978.0548198223114
training steps:  1192.0
retraining steps:  0.0
RDN obj mus: [-0.9496456340670586, -0.9639442122399807, -0.9584861282885074, -0.9437167686931157, -0.7204168885946274]
RDN obj sigmas: [0.027644233202804656, 0.011388021559488166, 0.017793662783062162, 0.06035662733083934, 0.41593340343356966]
960 : 0.0
LR:  0.001
replay buffer size:  10450
Time Taken :  49.0  mins 38.05458402633667  seconds
[[[2755. 1418.  573.  278.   55.    1.    3.    0.]
  [1421.  601.  143.   86.   28.    9.    6.    5.]
  [ 658.  177.   57.   45.   37.   26.   11.    1.]
  [ 242.   98.   28.   14.   19.    8.    6.   10.]
  [  98.   27.   16.    6.    7.    4.   14.   17.]
  [  28.    3.    3.    6.    1.    6.   12.   17.]
  [  13.    0.    0.    0.    0.    2.    1.    2.]
  [   3.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6777823
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 1988, frames: 20057, time: 7165.084121704102
training steps:  2383.0
retraining steps:  0.0
RDN obj mus: [-0.9480562226653099, -0.9626162993133068, -0.9515064666807651, -0.9230767335872548, -0.7509140014648438]
RDN obj sigmas: [0.018077421588405963, 0.014256249648375149, 0.020950765527735206, 0.04962720525810588, 0.37698908796826064]
1988 : 0.0
LR:  0.001
replay buffer size:  20608
Time Taken :  119.0  mins 25.083863019943237  seconds
[[[5171. 2881. 1177.  538.  104.    6.    7.    0.]
  [2811. 1285.  285.  189.   59.   34.   14.    5.]
  [1305.  403.  146.  114.   74.   51.   15.    1.]
  [ 540.  203.   56.   40.   36.   20.   17.   12.]
  [ 173.   47.   33.   15.   16.   10.   19.   20.]
  [  39.    6.   10.    9.    1.    6.   12.   20.]
  [  21.    4.    0.    0.    0.    2.    1.    3.]
  [   3.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.674196
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 2918, frames: 30021, time: 10967.490592956543
training steps:  3728.0
retraining steps:  0.0
RDN obj mus: [-0.921766441565752, -0.9385233441293239, -0.9235872226476669, -0.8909435153805784, -0.7800489408629281]
RDN obj sigmas: [0.04954068041316244, 0.024073517325597874, 0.04140978045894246, 0.05894820037655634, 0.32210348025711594]
2918 : 0.0
LR:  0.001
replay buffer size:  30750
Time Taken :  182.0  mins 47.49033498764038  seconds
[[[7892. 4300. 1631.  732.  151.    9.   12.    2.]
  [4281. 1903.  402.  286.  124.   60.   28.   15.]
  [1934.  599.  233.  191.  119.   68.   19.    3.]
  [ 805.  299.   88.   72.   52.   28.   20.   14.]
  [ 281.   69.   40.   27.   24.   12.   24.   24.]
  [  84.   10.   12.   10.    1.    6.   15.   23.]
  [  46.    6.    2.    0.    0.    2.    2.    4.]
  [   6.    0.    1.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7020044
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 3844, frames: 40120, time: 13928.875960826874
training steps:  4755.0
retraining steps:  0.0
RDN obj mus: [-0.957768988519907, -0.9671369031310082, -0.9503459444820881, -0.8892637009545978, -0.8247967541217804]
RDN obj sigmas: [0.015324541799164551, 0.016378057331149627, 0.030648657129484173, 0.05787084275013804, 0.27805394769079506]
3844 : 0.0
LR:  0.001
replay buffer size:  41029
Time Taken :  232.0  mins 8.875696182250977  seconds
[[[10855.  5768.  2165.   930.   193.    11.    12.     2.]
  [ 5783.  2515.   537.   348.   156.    78.    33.    15.]
  [ 2535.   782.   304.   226.   142.    73.    25.     3.]
  [ 1080.   379.   122.    95.    62.    33.    20.    14.]
  [  407.    99.    46.    34.    30.    12.    24.    24.]
  [  129.    17.    16.    13.     1.     6.    15.    23.]
  [   56.     6.     2.     0.     0.     2.     2.     4.]
  [   11.     0.     1.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6951056
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 4711, frames: 50044, time: 17530.37955570221
training steps:  6076.0
retraining steps:  0.0
RDN obj mus: [-0.9588290455579758, -0.9660147843360901, -0.9453833811879158, -0.8718549248044503, -0.7923094481229782]
RDN obj sigmas: [0.023484284403182117, 0.03305600716633689, 0.03513387497300121, 0.0705384836602049, 0.26401791781255013]
4711 : 0.0
LR:  0.001
replay buffer size:  51113
Time Taken :  292.0  mins 10.379294872283936  seconds
[[[13768.  7118.  2632.  1154.   233.    22.    17.     2.]
  [ 7262.  3096.   651.   443.   199.   106.    46.    15.]
  [ 3201.   959.   371.   270.   170.    93.    32.     3.]
  [ 1310.   460.   161.   128.    97.    53.    26.    15.]
  [  501.   119.    61.    46.    37.    23.    26.    24.]
  [  167.    23.    19.    17.     3.    12.    15.    23.]
  [   65.     6.     3.     1.     4.     5.     2.     4.]
  [   12.     0.     2.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.71068484
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 5522, frames: 60027, time: 21469.80263400078
training steps:  7469.0
retraining steps:  0.0
RDN obj mus: [-0.9681028469264508, -0.9688550260543823, -0.9547868562698364, -0.8797588674351573, -0.8335915605227152]
RDN obj sigmas: [0.018301461112318847, 0.018022569388137955, 0.03043623666179737, 0.06780256790108131, 0.22333550692929838]
5522 : 0.0
LR:  0.001
replay buffer size:  61256
Time Taken :  357.0  mins 49.80236196517944  seconds
[[[17153.  8643.  3155.  1351.   282.    25.    17.     2.]
  [ 8614.  3650.   763.   512.   222.   124.    47.    15.]
  [ 3711.  1118.   443.   322.   208.   115.    34.     3.]
  [ 1518.   529.   186.   153.   119.    66.    28.    15.]
  [  564.   131.    73.    52.    42.    23.    31.    25.]
  [  185.    25.    19.    20.     4.    15.    18.    24.]
  [   67.     8.     3.     1.     5.     6.     3.     4.]
  [   12.     0.     2.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6013078
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 6360, frames: 70089, time: 24011.23609495163
training steps:  8454.0
retraining steps:  0.0
RDN obj mus: [-0.9566266384005546, -0.9262385513484478, -0.9539789478957653, -0.8827902284132394, -0.8380160300355208]
RDN obj sigmas: [0.03547245684125535, 0.03512382469122977, 0.03598616754913838, 0.06443598313879483, 0.218187804668756]
6360 : 0.0
LR:  0.001
replay buffer size:  71466
Time Taken :  400.0  mins 11.235844135284424  seconds
[[[20757. 10155.  3655.  1496.   312.    28.    18.     2.]
  [10040.  4264.   875.   568.   249.   136.    49.    15.]
  [ 4234.  1293.   495.   352.   222.   126.    35.     3.]
  [ 1670.   585.   204.   170.   131.    71.    28.    15.]
  [  610.   145.    85.    55.    45.    23.    31.    25.]
  [  206.    29.    23.    22.     4.    15.    18.    24.]
  [   70.     9.     4.     1.     5.     6.     3.     4.]
  [   12.     0.     2.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6306236
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 7181, frames: 80082, time: 27316.051245689392
training steps:  9466.0
retraining steps:  0.0
RDN obj mus: [-0.9471185648858548, -0.9543017226934433, -0.9335659166097641, -0.880931057981468, -0.8380160300355208]
RDN obj sigmas: [0.03348145128863252, 0.0280856575534001, 0.05230315074488415, 0.06436529816742359, 0.218187804668756]
7181 : 0.0
LR:  0.001
replay buffer size:  81633
Time Taken :  455.0  mins 16.050979137420654  seconds
[[[24240. 11621.  4195.  1722.   347.    31.    21.     2.]
  [11547.  4863.   981.   634.   268.   148.    55.    18.]
  [ 4688.  1407.   528.   387.   239.   139.    38.     5.]
  [ 1826.   636.   213.   176.   141.    82.    38.    16.]
  [  676.   159.    87.    55.    48.    35.    55.    29.]
  [  220.    33.    26.    22.     4.    19.    29.    30.]
  [   73.    10.     4.     1.     5.     6.     4.     4.]
  [   13.     0.     2.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7346015
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 8013, frames: 90041, time: 30333.986964941025
training steps:  10798.0
retraining steps:  0.0
RDN obj mus: [-0.947070849597454, -0.9538468212306499, -0.9450010733604431, -0.8819386976844005, -0.8035126355561343]
RDN obj sigmas: [0.029246543529189366, 0.02908225439665352, 0.046707612691371, 0.06374493438921362, 0.22095527298452172]
8013 : 0.0
LR:  0.001
replay buffer size:  91747
Time Taken :  505.0  mins 33.98669695854187  seconds
[[[27741. 13190.  4725.  1944.   396.    31.    22.     2.]
  [12948.  5440.  1100.   692.   291.   150.    57.    18.]
  [ 5171.  1543.   580.   415.   254.   140.    40.     5.]
  [ 1981.   701.   240.   186.   148.    82.    38.    16.]
  [  725.   170.    96.    60.    50.    35.    55.    29.]
  [  229.    36.    27.    25.     4.    19.    29.    30.]
  [   73.    10.     4.     1.     5.     6.     4.     4.]
  [   13.     0.     2.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6905574
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 8856, frames: 100051, time: 33463.84926986694
training steps:  12131.0
retraining steps:  0.0
RDN obj mus: [-0.9496012901723385, -0.9212010172963142, -0.9460530819356442, -0.8831558012109249, -0.8035126355561343]
RDN obj sigmas: [0.04422616142968426, 0.07555473391736602, 0.04418040292035248, 0.062146219799431336, 0.22095527298452172]
8856 : 0.0
LR:  0.001
replay buffer size:  101988
Time Taken :  557.0  mins 43.84900188446045  seconds
[[[31301. 14711.  5326.  2166.   451.    42.    27.     3.]
  [14302.  6026.  1211.   762.   316.   161.    58.    19.]
  [ 5614.  1667.   613.   442.   272.   151.    43.     5.]
  [ 2149.   765.   254.   200.   152.    84.    38.    16.]
  [  773.   182.   100.    65.    54.    37.    55.    29.]
  [  247.    38.    28.    26.     4.    19.    29.    30.]
  [   83.    10.     4.     1.     5.     6.     4.     4.]
  [   13.     0.     2.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7224533
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 9711, frames: 110039, time: 36589.106306791306
training steps:  13461.0
retraining steps:  0.0
RDN obj mus: [-0.9617922414422035, -0.9636369578242302, -0.9567943526387215, -0.8843060809296447, -0.802656132241954]
RDN obj sigmas: [0.017050239006624796, 0.023772934554623797, 0.02918205197808245, 0.061202999919944226, 0.2161358589510596]
9711 : 0.0
LR:  0.001
replay buffer size:  112199
Time Taken :  609.0  mins 49.10603904724121  seconds
[[[34821. 16273.  5886.  2387.   490.    46.    28.    11.]
  [15626.  6654.  1321.   848.   347.   169.    59.    21.]
  [ 6108.  1786.   642.   470.   285.   157.    46.     6.]
  [ 2305.   824.   266.   207.   160.    86.    38.    16.]
  [  816.   187.   104.    69.    57.    37.    55.    29.]
  [  268.    44.    28.    26.     4.    19.    29.    30.]
  [   87.    11.     4.     1.     5.     6.     4.     4.]
  [   13.     0.     2.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7036568
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 10474, frames: 120058, time: 39751.77601194382
training steps:  14812.0
retraining steps:  0.0
RDN obj mus: [-0.9537392851352692, -0.9512921898007393, -0.9493177139818668, -0.8816849756699099, -0.785896173229924]
RDN obj sigmas: [0.02272480246438999, 0.02160080685947854, 0.03599440090042999, 0.06293339567705215, 0.2034970291052241]
10474 : 0.0
LR:  0.001
replay buffer size:  122414
Time Taken :  662.0  mins 31.775743007659912  seconds
[[[38772. 17800.  6456.  2630.   528.    51.    29.    11.]
  [16913.  7188.  1447.   905.   354.   173.    60.    21.]
  [ 6535.  1891.   676.   488.   289.   157.    46.     6.]
  [ 2433.   873.   283.   217.   169.    92.    39.    18.]
  [  863.   192.   107.    72.    61.    38.    58.    33.]
  [  284.    48.    28.    26.     4.    19.    30.    30.]
  [   90.    11.     4.     1.     5.     6.     4.     4.]
  [   14.     0.     2.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7471466
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 11322, frames: 130040, time: 42828.49745988846
training steps:  16126.0
retraining steps:  0.0
RDN obj mus: [-0.9596247689545154, -0.9700420490086079, -0.9481731076717377, -0.8799932727694512, -0.785896173229924]
RDN obj sigmas: [0.023537587875363464, 0.020943098720567356, 0.0378006147418126, 0.06119464221629105, 0.2034970291052241]
11322 : 0.0
LR:  0.001
replay buffer size:  132542
Time Taken :  713.0  mins 48.49718713760376  seconds
[[[42276. 19313.  7039.  2822.   564.    53.    30.    11.]
  [18221.  7785.  1569.   966.   368.   175.    61.    21.]
  [ 7035.  2057.   716.   521.   306.   165.    49.     6.]
  [ 2599.   931.   299.   237.   175.    95.    39.    18.]
  [  941.   208.   113.    79.    62.    38.    58.    33.]
  [  314.    54.    28.    27.     4.    19.    30.    30.]
  [  101.    14.     4.     1.     5.     6.     4.     4.]
  [   17.     0.     2.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7178743
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 12120, frames: 140042, time: 45889.375777721405
training steps:  17432.0
retraining steps:  0.0
RDN obj mus: [-0.941535781109333, -0.9311319968104362, -0.95243168181777, -0.8799071473002433, -0.785896173229924]
RDN obj sigmas: [0.04449839014428383, 0.060058627116973906, 0.03695595377928029, 0.06224533251590086, 0.2034970291052241]
12120 : 0.0
LR:  0.001
replay buffer size:  142732
Time Taken :  764.0  mins 49.375499963760376  seconds
[[[45914. 20899.  7625.  3075.   603.    59.    34.    11.]
  [19529.  8333.  1700.  1035.   393.   195.    69.    22.]
  [ 7421.  2144.   761.   564.   319.   173.    53.     7.]
  [ 2740.   977.   328.   273.   184.    97.    39.    18.]
  [ 1002.   226.   128.    84.    62.    38.    58.    33.]
  [  328.    59.    33.    29.     4.    19.    30.    30.]
  [  103.    14.     7.     2.     5.     6.     4.     4.]
  [   17.     0.     3.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7451004
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 12847, frames: 150051, time: 48931.46943998337
training steps:  18728.0
retraining steps:  0.0
RDN obj mus: [-0.9364373556494713, -0.9571267638504505, -0.9527547750651837, -0.8807176668584347, -0.7859088203736714]
RDN obj sigmas: [0.0331567526826557, 0.022432410076131847, 0.035315671055791864, 0.06153970564562329, 0.19983012642867448]
12847 : 0.0
LR:  0.001
replay buffer size:  152937
Time Taken :  815.0  mins 31.469162940979004  seconds
[[[49826. 22477.  8147.  3288.   639.    62.    35.    11.]
  [20883.  8841.  1802.  1093.   410.   200.    69.    22.]
  [ 7845.  2279.   797.   598.   335.   179.    54.     7.]
  [ 2885.  1038.   342.   290.   196.   103.    40.    18.]
  [ 1035.   237.   130.    88.    67.    39.    58.    33.]
  [  334.    61.    34.    29.     4.    19.    30.    30.]
  [  103.    14.     7.     2.     5.     6.     4.     4.]
  [   17.     0.     3.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.75079215
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 13639, frames: 160165, time: 51942.4573969841
training steps:  19980.0
retraining steps:  0.0
RDN obj mus: [-0.9644802146792412, -0.9720015101969242, -0.9556374258697032, -0.884930259758234, -0.7859088203736714]
RDN obj sigmas: [0.01586179813395306, 0.020662201736003367, 0.03683510910089999, 0.057095519372356476, 0.19983012642867448]
13639 : 0.0
LR:  0.001
replay buffer size:  163245
Time Taken :  865.0  mins 42.45712399482727  seconds
[[[53523. 23938.  8702.  3501.   668.    68.    37.    11.]
  [22226.  9380.  1922.  1165.   434.   214.    74.    22.]
  [ 8356.  2428.   846.   636.   347.   192.    56.     7.]
  [ 3076.  1106.   369.   313.   205.   111.    41.    18.]
  [ 1121.   258.   139.    92.    74.    40.    58.    33.]
  [  341.    63.    34.    30.     4.    19.    30.    30.]
  [  105.    14.     7.     2.     5.     6.     4.     4.]
  [   18.     0.     3.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7416531
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 14392, frames: 170191, time: 53864.07652401924
training steps:  20682.0
retraining steps:  0.0
RDN obj mus: [-0.9616406816601754, -0.9719508147418499, -0.9658076661348343, -0.8856788420557976, -0.7859088203736714]
RDN obj sigmas: [0.017041218582804697, 0.015664130704509064, 0.026594963083057095, 0.05663412421968962, 0.19983012642867448]
14392 : 0.0
LR:  0.001
replay buffer size:  173451
Time Taken :  897.0  mins 44.076252937316895  seconds
[[[57371. 25532.  9287.  3745.   706.    76.    39.    16.]
  [23435.  9909.  2034.  1242.   456.   228.    79.    28.]
  [ 8768.  2533.   899.   663.   352.   195.    58.     7.]
  [ 3224.  1155.   391.   336.   212.   116.    41.    18.]
  [ 1171.   267.   148.    99.    78.    40.    58.    33.]
  [  362.    67.    36.    31.     4.    19.    30.    30.]
  [  109.    16.     7.     2.     5.     6.     4.     4.]
  [   19.     0.     3.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.57274574
Scores:  {'0.25': 0.0001, '0.5': 0.0001, '0.75': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.25 0.25
best rdn adv:  0.0
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Episodes: 15081, frames: 180077, time: 55769.66069984436
training steps:  21377.0
retraining steps:  0.0
RDN obj mus: [-0.9176417259573937, -0.9199200112581253, -0.92844741486907, -0.8772281291782856, -0.755551668730649]
RDN obj sigmas: [0.036458384751701836, 0.03277340636429649, 0.04120583016790182, 0.06751150544332334, 0.19762783460146174]
15081 : 0.0
LR:  0.001
replay buffer size:  183539
Time Taken :  929.0  mins 29.66042709350586  seconds
[[[61179. 26966.  9860.  3954.   741.    76.    40.    16.]
  [24746. 10361.  2143.  1298.   485.   235.    82.    28.]
  [ 9216.  2656.   935.   688.   368.   199.    61.     7.]
  [ 3445.  1216.   410.   355.   217.   117.    41.    18.]
  [ 1285.   282.   148.   101.    78.    40.    58.    33.]
  [  397.    73.    36.    33.     4.    19.    30.    30.]
  [  120.    19.     7.     2.     5.     6.     4.     4.]
  [   20.     0.     3.     0.     0.     0.     0.     0.]]]
