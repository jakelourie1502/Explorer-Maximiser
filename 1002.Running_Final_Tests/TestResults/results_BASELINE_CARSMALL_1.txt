EVALUATIONS AND MAIN RESULTS
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9899990099009901
siam score:  -0.003314321761502436
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 81, frames: 2052, time: 28.580883979797363
training steps:  6
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
81 : -1.0
LR:  5e-06
replay buffer size:  2435
Time Taken :  0.0  mins 28.580707788467407  seconds
[[[  0.   0.   0.   0.   1.   3.   7.   3.   1.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   5.  42.  20.   6.  17.   1.   0.   0.   1.   0.   1.
     1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0. 101.  59.  73.  38.  17.   4.   0.   1.   1.   4.   1.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0. 644. 162.  40.  43. 121. 154. 126. 110.  72.  23.  24.   9.   3.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  15.  11.   5.   1.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9965442953020134
siam score:  -0.7464103
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9931005324989864
rdn probs:  [1.0]
Episodes: 263, frames: 10813, time: 1463.510812997818
training steps:  1295
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
263 : -1.0
LR:  0.001
replay buffer size:  12612
Time Taken :  24.0  mins 23.510637760162354  seconds
[[[   0.    0.    0.    0.    3.    8.   13.    7.    7.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   15.  153.  195.  240.   40.    8.    3.    1.
      1.    0.    1.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1207.  602.  333.  126.  137.   20.    4.   11.    1.
      7.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 3829. 1230.  466.  281.  558.  388.  250.  140.  102.   27.
     25.    9.    3.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   40.   35.   16.    5.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.9054917
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 613, frames: 20392, time: 3140.8012988567352
training steps:  2422
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
613 : -1.0
LR:  0.001
replay buffer size:  22689
Time Taken :  52.0  mins 20.80112075805664  seconds
[[[   0.    0.    0.    0.    4.   24.   26.   18.    7.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   55.  332.  327.  342.   85.   11.   21.    4.
      1.    0.    1.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 2081.  973.  631.  271.  164.   47.   10.   11.    1.
     18.    1.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 7313. 2307.  914.  609. 1049.  776.  483.  305.  175.   67.
     32.   11.    3.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  109.  107.   31.   19.    0.    0.    0.    0.    0.
      1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.8779207
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 970, frames: 30221, time: 4726.821786880493
training steps:  3590
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
970 : -1.0
LR:  0.001
replay buffer size:  32867
Time Taken :  78.0  mins 46.82160997390747  seconds
[[[    0.     0.     0.     0.     8.    38.    38.    24.    12.     4.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.    96.   480.   484.   499.   128.    25.    25.
       7.     1.     0.     1.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3157.  1633.   898.   365.   288.    89.    16.    11.
       1.    19.     2.     1.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 10011.  3279.  1390.   816.  1488.  1298.   921.   707.   332.
     179.    45.    27.     4.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   167.   143.    58.    31.     0.     0.     0.     0.
       0.     2.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.8570913
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1315, frames: 40314, time: 6378.15029001236
training steps:  4778
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1315 : -1.0
LR:  0.001
replay buffer size:  43488
Time Taken :  106.0  mins 18.150113821029663  seconds
[[[    0.     0.     0.     0.    10.    47.    46.    28.    18.     8.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   124.   697.   652.   602.   212.    48.    47.
      13.     1.     0.     7.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3858.  2181.  1221.   540.   401.   132.    21.    45.
       3.    33.     4.     2.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 12595.  4087.  1668.  1117.  1919.  1845.  1470.  1341.   885.
     411.    67.    41.    12.     2.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   196.   189.    88.    41.     0.     0.     0.     0.
       0.     6.    10.     4.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.86770606
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1696, frames: 50274, time: 8140.159415960312
training steps:  6082
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1696 : -1.0
LR:  0.001
replay buffer size:  54129
Time Taken :  135.0  mins 40.159241914749146  seconds
[[[    0.     0.     0.     0.    12.    58.    60.    37.    22.    10.
       2.     0.     1.     1.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   157.   800.   856.   688.   291.    61.    73.
      19.    17.    17.    33.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  4438.  2731.  1550.   700.   572.   195.    25.    46.
      14.    78.    20.     6.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15229.  4989.  1983.  1329.  2268.  2281.  2009.  1876.  1436.
     645.   123.    90.    20.    12.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   233.   232.   111.    62.     0.     0.     0.     0.
       0.     8.    29.    16.     3.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     1.     0.     2.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7592158
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2051, frames: 60243, time: 9882.035376787186
training steps:  7376
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2051 : -1.0
LR:  0.001
replay buffer size:  64614
Time Taken :  164.0  mins 42.035202741622925  seconds
[[[    0.     0.     0.     0.    19.    66.    67.    42.    27.    12.
       3.     0.     1.     1.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   184.   978.   980.   803.   381.   102.    80.
      22.    17.    17.    33.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  5118.  3170.  1983.   876.   688.   245.    34.    48.
      16.    79.    32.     7.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17932.  5817.  2362.  1566.  2602.  2759.  2463.  2366.  1929.
    1093.   152.   103.    26.    14.     1.    21.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   280.   271.   139.    72.     0.     0.     0.     0.
       0.    16.    35.    26.     4.     1.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     2.     2.     2.     1.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.75834525
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2409, frames: 70324, time: 11671.022429943085
training steps:  8697
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2409 : -1.0
LR:  0.001
replay buffer size:  75418
Time Taken :  194.0  mins 31.022255897521973  seconds
[[[    0.     0.     0.     0.    22.    72.    72.    55.    29.    13.
       4.     0.     1.     3.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   206.  1093.  1202.   926.   437.   136.   112.
      31.    17.    33.    42.     2.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  5631.  3579.  2466.  1033.   886.   306.    37.    52.
      78.   110.    39.    10.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 20274.  6680.  2636.  1764.  2967.  3289.  2914.  2910.  2467.
    1824.   229.   115.    38.    14.     1.    21.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   313.   304.   170.    82.     0.     0.     0.     0.
       0.    22.    51.    72.     6.     1.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     3.     4.     4.     2.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7657013
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2792, frames: 80252, time: 13316.641911029816
training steps:  9943
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2792 : -1.0
LR:  0.001
replay buffer size:  85711
Time Taken :  221.0  mins 56.64173078536987  seconds
[[[    0.     0.     0.     0.    24.    79.    84.    61.    33.    14.
       6.     0.     1.     4.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   231.  1243.  1363.  1064.   516.   174.   133.
      43.    17.    77.    60.     4.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  6310.  4076.  2781.  1250.  1094.   369.    42.    73.
      92.   252.    97.    18.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 22387.  7449.  2927.  1990.  3240.  3651.  3300.  3516.  3054.
    2420.   341.   140.    55.    30.     1.    21.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   359.   341.   194.    96.     0.     0.     0.     0.
       0.    33.    84.   105.    12.     3.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     4.     8.     6.     4.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.77207583
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3202, frames: 90230, time: 14993.572796821594
training steps:  11186
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3202 : -1.0
LR:  0.001
replay buffer size:  96506
Time Taken :  249.0  mins 53.57262182235718  seconds
[[[    0.     0.     0.     0.    28.    89.    90.    71.    39.    17.
       6.     0.     1.     5.     3.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   259.  1412.  1567.  1198.   621.   222.   228.
      55.    17.   133.    96.     6.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  6956.  4499.  3097.  1350.  1192.   415.    48.    79.
      93.   323.   132.    33.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 24599.  8230.  3257.  2200.  3509.  4033.  3710.  4014.  3594.
    3159.   553.   184.    78.    30.     5.    21.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   409.   386.   233.   115.     0.     0.     0.     0.
       0.    40.   113.   120.    15.     4.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     5.    13.    10.     5.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.77509665
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3583, frames: 100295, time: 16573.430078029633
training steps:  12376
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3583 : -1.0
LR:  0.001
replay buffer size:  107035
Time Taken :  276.0  mins 13.429906845092773  seconds
[[[    0.     0.     0.     0.    33.    91.   100.    78.    42.    17.
       7.     0.     1.     6.     3.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   280.  1701.  1818.  1291.   684.   240.   267.
      68.    17.   134.    99.     7.     0.     0.     0.     7.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  7471.  4927.  3409.  1520.  1392.   483.    53.   124.
     104.   432.   194.    51.     0.     0.     3.     1.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 26701.  9044.  3548.  2422.  3841.  4420.  4206.  4459.  4036.
    3795.   806.   303.   118.    30.    41.    22.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   459.   417.   253.   130.     0.     0.     0.     0.
       0.    47.   172.   204.    29.     5.     2.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     9.    17.    11.     5.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7649978
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3928, frames: 110232, time: 18153.742093086243
training steps:  13549
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3928 : -1.0
LR:  0.001
replay buffer size:  117722
Time Taken :  302.0  mins 33.74191379547119  seconds
[[[    0.     0.     0.     0.    33.    93.   105.    88.    47.    19.
      12.     0.     1.     7.     4.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   294.  1984.  2157.  1471.   781.   299.   308.
      86.    17.   160.   118.     9.     0.     0.     0.     7.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  7971.  5308.  3855.  1835.  1573.   552.    59.   125.
     104.   579.   247.    63.     1.     0.     3.     1.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 28559.  9799.  3863.  2593.  4157.  4763.  4670.  4855.  4420.
    4362.  1083.   423.   158.    40.    64.    25.     5.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   487.   445.   269.   139.     0.     0.     0.     0.
       0.    59.   340.   240.    38.     7.     3.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    16.    21.    15.     5.     0.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9950800000000001
siam score:  -0.74060625
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9901842064000002
rdn probs:  [1.0]
Episodes: 4288, frames: 120331, time: 19765.609107017517
training steps:  14748
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4288 : -1.0
LR:  0.001
replay buffer size:  128686
Time Taken :  329.0  mins 25.608927965164185  seconds
[[[    0.     0.     0.     0.    39.   102.   117.    96.    54.    19.
      14.     0.     1.     9.     4.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   306.  2144.  2281.  1590.   824.   325.   325.
      92.    17.   201.   141.     9.     0.     0.     0.     7.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  8514.  5632.  4199.  2012.  1773.   601.    67.   128.
     107.   629.   420.    89.     3.     0.     3.     1.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 30452. 10650.  4111.  2794.  4470.  5077.  5253.  5362.  4871.
    5105.  1604.   565.   207.    42.    65.    41.    23.    16.     4.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   513.   472.   287.   154.     0.     0.     0.     0.
       0.    72.   509.   280.    53.    13.     4.     6.     0.     0.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    17.    28.    18.     6.     0.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9976200000000001
siam score:  -0.7363657
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9952456644000002
rdn probs:  [1.0]
Episodes: 4601, frames: 130285, time: 21322.997285842896
training steps:  15915
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4601 : -1.0
LR:  0.001
replay buffer size:  139272
Time Taken :  355.0  mins 22.997117042541504  seconds
[[[    0.     0.     0.     0.    42.   107.   120.    98.    56.    21.
      15.     0.     1.     9.     4.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   322.  2220.  2391.  1683.   905.   373.   365.
     105.    17.   228.   226.    15.     0.     0.     0.     7.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  8895.  5969.  4455.  2201.  1893.   643.    71.   151.
     126.   965.   652.   119.     4.     0.     3.     1.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 31946. 11244.  4364.  3042.  4916.  5499.  5949.  5874.  5309.
    5840.  2060.   706.   254.    53.    70.    42.    30.    16.     4.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   523.   492.   303.   158.     0.     0.     0.     0.
       0.    79.   799.   387.    99.    15.    34.     9.     0.     0.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    21.    35.    22.     7.     0.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.99788
siam score:  -0.74627405
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9957644944
rdn probs:  [1.0]
Episodes: 4943, frames: 140332, time: 22948.07433986664
training steps:  17109
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4943 : -1.0
LR:  0.001
replay buffer size:  150269
Time Taken :  382.0  mins 28.074166774749756  seconds
[[[    0.     0.     0.     0.    42.   113.   124.   105.    64.    22.
      15.     0.     1.    10.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   343.  2377.  2540.  1821.   979.   411.   384.
     118.    17.   296.   289.    23.     0.     0.     0.     7.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  9271.  6306.  4694.  2381.  1965.   683.    74.   162.
     147.  1296.   837.   154.     4.     0.     3.     1.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 33572. 11889.  4643.  3305.  5275.  5969.  6671.  6352.  5694.
    6534.  2531.   913.   309.    77.    75.    60.    46.    33.     6.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   538.   509.   325.   165.     0.     0.     0.     0.
       0.    99.   959.   464.   116.    20.    38.    13.     0.     0.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    29.    35.    26.     8.     1.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -0.9339999999999999
Q value #end_state_>_threshold:  5
Q value #non_end_state_>threshold:  7
maxi score:  -0.99524
siam score:  -0.7567662
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9905026576
rdn probs:  [1.0]
Episodes: 5289, frames: 150269, time: 24508.578315973282
training steps:  18282
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5289 : -1.0
LR:  0.001
replay buffer size:  160648
Time Taken :  408.0  mins 28.578140020370483  seconds
[[[    0.     0.     0.     0.    44.   116.   135.   110.    70.    22.
      16.     0.     1.    12.     6.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   352.  2497.  2657.  1917.  1028.   432.   394.
     126.    17.   304.   375.    30.     0.     0.     0.     7.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  9619.  6552.  4936.  2515.  2073.   722.    84.   176.
     156.  1513.  1040.   194.     4.     3.    29.     4.     2.     5.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 35044. 12515.  4839.  3555.  5676.  6461.  7617.  6855.  6144.
    7164.  3057.  1122.   371.    94.   122.    63.    49.    37.     8.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   555.   527.   338.   170.     0.     0.     0.     0.
       0.   119.  1241.   584.   135.    37.    42.    19.     0.     0.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    38.    43.    28.     9.     1.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -0.9455
Q value #end_state_>_threshold:  18
Q value #non_end_state_>threshold:  26
maxi score:  -0.9900800000000001
siam score:  -0.76470643
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.8723559999999999
rdn probs:  [1.0]
Episodes: 5660, frames: 160227, time: 26066.986855983734
training steps:  19460
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5660 : -1.0
LR:  0.001
replay buffer size:  171147
Time Taken :  434.0  mins 26.98668885231018  seconds
[[[    0.     0.     0.     0.    45.   119.   140.   113.    74.    24.
      16.     0.     1.    14.     7.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   367.  2537.  2793.  1989.  1057.   446.   402.
     132.    19.   392.   503.    45.     0.     0.     0.     7.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  9857.  6802.  5089.  2623.  2109.   749.    88.   190.
     190.  1720.  1230.   238.    10.    10.    56.     6.     3.     5.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 36388. 13132.  5055.  3768.  6108.  7086.  8412.  7423.  6623.
    8014.  3627.  1367.   436.   134.   132.    77.    56.    41.     9.
       1.     2.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   573.   552.   355.   189.     0.     0.     0.     0.
       0.   146.  1504.   714.   168.    44.    47.    25.     0.     0.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    42.    52.    31.    11.     1.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -0.6990000000000001
Q value #end_state_>_threshold:  22
Q value #non_end_state_>threshold:  34
maxi score:  -0.97094
siam score:  -0.7542812
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.89397025
rdn probs:  [1.0]
Episodes: 6046, frames: 170245, time: 27660.24626302719
training steps:  20651
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6046 : -1.0
LR:  0.001
replay buffer size:  181885
Time Taken :  461.0  mins 0.24608993530273438  seconds
[[[    0.     0.     0.     0.    47.   127.   143.   118.    75.    26.
      16.     0.     1.    17.     9.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   384.  2604.  2888.  2034.  1100.   471.   420.
     144.    19.   508.   599.    56.     0.     0.     1.     7.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 10167.  7002.  5265.  2724.  2157.   776.    91.   199.
     192.  1890.  1465.   286.    14.    21.    61.    11.     4.     6.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 37825. 13661.  5217.  4035.  6503.  7673.  8993.  8099.  7171.
    9009.  4113.  1643.   519.   158.   165.    91.    74.    49.    13.
       2.     4.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   594.   574.   374.   201.     0.     0.     0.     0.
       0.   166.  1713.   902.   199.    62.    53.    30.     0.     0.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    52.    59.    34.    13.     1.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.2294999999999999
Q value #end_state_>_threshold:  99
Q value #non_end_state_>threshold:  126
maxi score:  -0.8945
siam score:  -0.7608191
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.4886010000000001
rdn probs:  [1.0]
Episodes: 6436, frames: 180205, time: 29217.34614610672
training steps:  21828
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6436 : -0.932
LR:  0.001
replay buffer size:  192255
Time Taken :  486.0  mins 57.345966815948486  seconds
[[[    0.     0.     0.     0.    49.   132.   151.   122.    75.    28.
      17.     1.     1.    22.     9.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   405.  2664.  2965.  2081.  1146.   511.   429.
     148.    20.   612.   706.    69.     0.     1.     2.     8.     2.
       3.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 10494.  7220.  5475.  2812.  2268.   812.    95.   205.
     205.  2071.  1607.   326.    19.    49.    74.    23.     7.     9.
      10.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 39163. 14177.  5456.  4283.  6894.  8141.  9610.  8696.  7650.
    9927.  4614.  1850.   587.   217.   246.   134.   124.    89.    27.
       4.    10.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   618.   593.   395.   210.     0.     0.     0.     0.
       0.   187.  1985.  1103.   242.    85.    65.    37.     0.     0.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    59.    67.    38.    16.     3.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -0.18
Q value #end_state_>_threshold:  431
Q value #non_end_state_>threshold:  321
maxi score:  -0.76592
siam score:  -0.76291215
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 6846, frames: 190215, time: 30780.17433977127
training steps:  23011
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6846 : -0.7990000000000002
LR:  0.001
replay buffer size:  200055
Time Taken :  513.0  mins 0.17416882514953613  seconds
[[[    0.     0.     0.     0.    55.   136.   154.   125.    77.    28.
      17.     1.     1.    24.    12.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   423.  2717.  3035.  2134.  1183.   547.   537.
     160.    21.   705.   851.    80.     0.     4.     6.     8.     3.
       4.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 10712.  7368.  5659.  2930.  2354.   846.   100.   215.
     212.  2236.  1683.   346.    20.    89.   142.    41.    20.    18.
      27.     8.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 40485. 14737.  5731.  4540.  7343.  8697. 10148.  9380.  8136.
   10644.  4974.  2005.   640.   298.   358.   188.   198.   140.   117.
      11.    32.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   652.   617.   414.   220.     0.     0.     0.     0.
       0.   201.  2313.  1265.   305.   116.   107.    49.     0.     1.
       6.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    66.    82.    44.    23.     7.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6809999999999999
Q value #end_state_>_threshold:  1574
Q value #non_end_state_>threshold:  1220
maxi score:  -0.4452200000000001
siam score:  -0.778665
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0324
rdn probs:  [1.0]
Episodes: 7263, frames: 200125, time: 32354.24143886566
training steps:  24180
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7263 : -0.6315000000000001
LR:  0.001
replay buffer size:  200024
Time Taken :  539.0  mins 14.24126386642456  seconds
[[[    0.     0.     0.     0.    58.   138.   161.   128.    78.    29.
      17.     1.     1.    27.    14.     0.     0.     0.     2.     4.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   437.  2751.  3103.  2193.  1203.   569.   552.
     170.    26.   721.   861.    84.     0.     5.    11.    12.    11.
      13.     2.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 11015.  7525.  5785.  3016.  2456.   871.   102.   218.
     215.  2316.  1760.   359.    21.   121.   233.    99.    51.    75.
      67.    20.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 41403. 15302.  6005.  4845.  7897.  9294. 10706. 10099.  8638.
   11206.  5317.  2095.   674.   332.   476.   342.   426.   307.   260.
      39.    67.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   665.   636.   432.   230.     0.     0.     0.     0.
       0.   214.  2625.  1405.   478.   166.   177.    58.     0.    38.
      39.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    77.    90.    52.    28.     7.     8.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
