EVALUATIONS AND MAIN RESULTS
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9847484848484849
siam score:  -0.015488621011415186
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 49, frames: 1264, time: 31.443846940994263
training steps:  6
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
49 : -1.0
LR:  5e-06
replay buffer size:  1819
Time Taken :  0.0  mins 31.443625926971436  seconds
[[[  0.   0.   0.   0.   0.   0.   0.   1.   1.   1.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   3.  40.  13.  35.   5.   2.   1.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  50.  76.  48.  19.  24.   8.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0. 376.  62.  55.  15.  79.  95.  83.  35.  22.  40.   3.   1.   1.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  10.   7.   2.   2.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9961962962962964
siam score:  -0.7949383
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9924070607544583
rdn probs:  [1.0]
Episodes: 238, frames: 10605, time: 1462.492048740387
training steps:  1300
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
238 : -1.0
LR:  0.001
replay buffer size:  12870
Time Taken :  24.0  mins 22.491830110549927  seconds
[[[   0.    0.    0.    0.    1.    9.    7.    4.    5.    4.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   19.  149.  377.  333.   94.   11.    4.    2.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  817.  933.  629.  307.  127.   29.    5.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 3242. 1345.  374.  215.  339.  373.  237.  142.  109.   52.
      3.    1.    1.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   17.   30.   12.    8.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.9009133
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 535, frames: 20421, time: 3208.01030087471
training steps:  2442
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
535 : -1.0
LR:  0.001
replay buffer size:  23891
Time Taken :  53.0  mins 28.010083198547363  seconds
[[[   0.    0.    0.    0.    6.   17.    9.   17.    6.    5.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   65.  518.  521.  451.  148.   16.   22.    7.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1658. 1454. 1071.  424.  172.   65.    7.    3.    0.
      0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 6894. 2477.  796.  370.  654.  709.  533.  319.  186.   76.
     13.    2.    2.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   58.   72.   36.   21.    0.    0.    0.    0.    0.
      0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    1.    1.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.882642
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 831, frames: 30427, time: 4880.664842605591
training steps:  3611
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
831 : -1.0
LR:  0.001
replay buffer size:  34910
Time Taken :  81.0  mins 20.664626121520996  seconds
[[[    0.     0.     0.     0.     9.    28.    18.    23.    12.     7.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.    95.   651.   604.   558.   181.    25.    45.
      10.     0.     3.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2460.  1989.  1554.   588.   206.    96.     9.    23.
       7.     2.    11.     6.     0.    27.     1.     1.     3.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 10007.  3377.  1487.   652.  1034.  1090.   934.   763.   385.
     227.    38.    17.    12.     0.     1.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.    93.    97.    61.    35.     0.     0.     0.     0.
       0.     3.    18.     3.     2.     1.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     2.     2.     0.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.88002294
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1114, frames: 40390, time: 6661.495934963226
training steps:  4841
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1114 : -1.0
LR:  0.001
replay buffer size:  46112
Time Taken :  111.0  mins 1.4957139492034912  seconds
[[[    0.     0.     0.     0.    12.    35.    28.    31.    15.     8.
       2.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   111.   885.   926.   662.   298.    40.    53.
      12.     0.    20.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2956.  2646.  1985.   763.   308.   134.    13.    56.
      10.     4.    42.    14.     0.    27.     1.     1.     3.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 12587.  4729.  2032.   972.  1259.  1355.  1304.  1241.   647.
     437.   108.    28.    27.     0.     1.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   110.   123.    98.    51.     0.     0.     0.     0.
       0.     8.    33.     5.     2.     2.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     9.     3.     1.     0.     2.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.8495323
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1334, frames: 50335, time: 8572.975908756256
training steps:  6156
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1334 : -1.0
LR:  0.001
replay buffer size:  57593
Time Taken :  142.0  mins 52.97568988800049  seconds
[[[    0.     0.     0.     0.    14.    39.    30.    32.    17.     9.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   124.  1084.  1105.   835.   344.    47.    69.
      17.     0.    69.    22.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3746.  3371.  2375.   910.   466.   171.    16.    58.
      10.    12.    84.    24.     1.    27.     1.     1.     3.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15709.  5726.  2787.  1094.  1440.  1626.  1600.  1556.   933.
     613.   171.    39.    41.     1.     1.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   121.   133.   114.    65.     0.     0.     0.     0.
       0.    10.    46.     7.     3.     2.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    12.     3.     2.     0.     2.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7189961
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1543, frames: 60423, time: 10592.04667878151
training steps:  7499
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1543 : -1.0
LR:  0.001
replay buffer size:  69585
Time Taken :  176.0  mins 32.04646110534668  seconds
[[[    0.     0.     0.     0.    16.    44.    33.    34.    19.     9.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   134.  1355.  1216.   988.   394.    54.    84.
      24.     0.   118.    23.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  4877.  3969.  2674.   996.   506.   201.    21.    58.
      11.    29.   103.    36.     1.    27.     2.     2.     3.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 19110.  6319.  3846.  1256.  1598.  1860.  1891.  1862.  1189.
     815.   293.    52.    60.     1.     2.     0.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   126.   150.   122.    74.     0.     0.     0.     0.
       0.    15.    95.    30.     8.     4.     2.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    16.     3.     2.     3.     3.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.73329663
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1737, frames: 70414, time: 12638.180572748184
training steps:  8772
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1737 : -1.0
LR:  0.001
replay buffer size:  81576
Time Taken :  210.0  mins 38.1803560256958  seconds
[[[    0.     0.     0.     0.    22.    45.    37.    36.    20.     9.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   153.  1985.  1351.  1098.   417.    65.    88.
      26.     0.   196.    31.    10.     0.     0.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  6139.  4373.  3072.  1067.   536.   221.    24.    83.
      15.    68.   122.    40.     2.    30.     3.     3.     3.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 22407.  6907.  4831.  1345.  1762.  2028.  2184.  2055.  1367.
    1072.   370.    85.    93.    12.     4.     0.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   135.   159.   132.    77.     0.     0.     0.     0.
       0.    15.   123.    58.     9.    12.     4.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    19.     4.     2.     3.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7649667
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1914, frames: 80450, time: 14678.944034814835
training steps:  9912
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1914 : -1.0
LR:  0.001
replay buffer size:  93612
Time Taken :  244.0  mins 38.943822145462036  seconds
[[[    0.     0.     0.     0.    23.    56.    41.    38.    20.    10.
       3.     0.     0.     2.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   167.  2643.  1494.  1192.   453.    72.    91.
      29.     0.   269.    36.    10.     0.     0.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  7408.  4898.  3403.  1121.   568.   234.    28.    91.
      16.   123.   136.    42.     5.    30.     3.     3.     3.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 26775.  7383.  5238.  1419.  1871.  2156.  2371.  2238.  1511.
    1266.   448.   108.   121.    12.     5.     6.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   135.   164.   141.    84.     0.     0.     0.     0.
       0.    16.   154.    76.    12.    13.     4.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    23.     5.     3.     3.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7822914
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2079, frames: 90597, time: 16728.850672721863
training steps:  11055
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2079 : -1.0
LR:  0.001
replay buffer size:  105733
Time Taken :  278.0  mins 48.85046195983887  seconds
[[[    0.     0.     0.     0.    25.    58.    46.    40.    20.    10.
       3.     0.     0.     3.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   173.  2909.  1553.  1220.   491.   103.    94.
      31.     0.   318.    41.    13.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  8441.  5073.  3592.  1152.   702.   244.    28.    91.
      18.   144.   183.    57.     6.    30.     4.     3.     3.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 31787.  7929.  6020.  1496.  1997.  2377.  2571.  2500.  1679.
    1478.   543.   129.   150.    14.     6.     6.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   137.   174.   143.    85.     0.     0.     0.     0.
       0.    21.   188.    81.    13.    13.     4.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    27.     6.     4.     3.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7526259
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2245, frames: 100563, time: 18770.598032712936
training steps:  12190
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2245 : -1.0
LR:  0.001
replay buffer size:  117699
Time Taken :  312.0  mins 50.597815990448  seconds
[[[    0.     0.     0.     0.    27.    61.    49.    41.    21.    10.
       3.     0.     0.     4.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   180.  3498.  1662.  1304.   500.   106.    96.
      33.     0.   330.    44.    14.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  9480.  5268.  3814.  1199.   783.   257.    33.    95.
      20.   150.   210.    72.     6.    30.     4.     3.     3.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 36701.  8403.  6529.  1583.  2149.  2527.  2777.  2696.  1846.
    1719.   649.   155.   172.    14.     6.     6.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   144.   180.   143.    89.     0.     0.     0.     0.
       0.    25.   201.   101.    15.    13.     4.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    27.    10.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9976
siam score:  -0.7242439
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.99520576
rdn probs:  [1.0]
Episodes: 2396, frames: 110500, time: 20815.779869794846
training steps:  13324
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2396 : -0.9425000000000001
LR:  0.001
replay buffer size:  129573
Time Taken :  346.0  mins 55.77965521812439  seconds
[[[    0.     0.     0.     0.    28.    64.    50.    41.    21.    10.
       3.     0.     0.     6.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   185.  3714.  1710.  1310.   501.   107.    96.
      33.     1.   483.    58.    20.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 10907.  5376.  4096.  1242.   798.   269.    34.    98.
      21.   184.   283.    82.     8.    30.     4.     4.     3.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 41923.  8724.  6776.  1642.  2269.  2712.  3117.  2943.  1981.
    1933.   780.   178.   199.    14.    17.     7.     4.     1.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   145.   182.   143.    93.     0.     0.     0.     0.
       0.    27.   215.   104.    15.    14.     4.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    27.    12.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9976
siam score:  -0.6962519
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.99520576
rdn probs:  [1.0]
Episodes: 2544, frames: 120530, time: 22872.44072985649
training steps:  14459
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2544 : -1.0
LR:  0.001
replay buffer size:  141603
Time Taken :  381.0  mins 12.44051194190979  seconds
[[[    0.     0.     0.     0.    28.    66.    52.    41.    21.    11.
       3.     0.     0.     7.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   191.  3818.  1759.  1331.   516.   108.    96.
      33.     1.   555.    60.    21.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 13070.  5457.  4379.  1293.   809.   278.    36.    98.
      21.   213.   313.    86.     8.    30.     4.     4.     3.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 47264.  8968.  7079.  1700.  2328.  2831.  3292.  3119.  2130.
    2063.   850.   197.   215.    14.    17.     7.     4.     1.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   155.   185.   145.    94.     0.     0.     0.     0.
       0.    34.   270.   106.    15.    14.     4.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    29.    13.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9976
siam score:  -0.702291
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.99520576
rdn probs:  [1.0]
Episodes: 2683, frames: 130627, time: 24936.100275993347
training steps:  15603
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2683 : -1.0
LR:  0.001
replay buffer size:  153700
Time Taken :  415.0  mins 36.10005807876587  seconds
[[[    0.     0.     0.     0.    29.    71.    53.    42.    22.    11.
       3.     0.     0.     9.     2.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   195.  3958.  1788.  1349.   520.   109.    99.
      34.     1.   628.    85.    23.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 15867.  5556.  4508.  1329.   827.   286.    37.    98.
      21.   230.   342.    93.     9.    30.     4.     4.     3.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 52308.  9166.  7381.  1739.  2416.  2940.  3540.  3273.  2221.
    2186.   908.   215.   224.    14.    17.     7.     4.     1.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   158.   185.   149.    94.     0.     0.     0.     0.
       0.    37.   280.   107.    15.    14.     4.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    30.    14.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9976
siam score:  -0.7027867
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.99520576
rdn probs:  [1.0]
Episodes: 2814, frames: 140363, time: 26968.360283851624
training steps:  16735
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2814 : -1.0
LR:  0.001
replay buffer size:  165436
Time Taken :  449.0  mins 28.360074043273926  seconds
[[[    0.     0.     0.     0.    30.    73.    56.    42.    22.    12.
       3.     0.     0.    10.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   198.  4089.  1797.  1353.   521.   111.    99.
      34.     9.   667.    89.    23.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 18506.  5622.  4708.  1357.   840.   297.    37.    99.
      21.   234.   351.    95.     9.    30.     4.     4.     3.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 57649.  9335.  7606.  1773.  2464.  3027.  3694.  3399.  2294.
    2268.   944.   219.   229.    28.    17.     7.     4.     1.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   161.   189.   156.    95.     0.     0.     0.     0.
       0.    40.   282.   108.    15.    14.     4.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    31.    14.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7138904
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2956, frames: 150612, time: 28998.54583978653
training steps:  17894
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2956 : -1.0
LR:  0.001
replay buffer size:  177685
Time Taken :  483.0  mins 18.54562211036682  seconds
[[[    0.     0.     0.     0.    34.    75.    56.    46.    23.    13.
       3.     0.     0.    10.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   204.  4130.  1869.  1382.   528.   114.   101.
      35.     9.   670.   102.    24.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 21855.  5746.  4953.  1388.   853.   305.    38.   101.
      21.   240.   372.    99.     9.    30.     4.     4.     3.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 62582.  9683.  7695.  1817.  2524.  3114.  3854.  3557.  2360.
    2364.   966.   222.   234.    32.    17.     7.     4.     1.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   165.   192.   164.    96.     0.     0.     0.     0.
       0.    46.   296.   109.    15.    14.     4.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    32.    14.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.71809626
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3089, frames: 160575, time: 31025.818873882294
training steps:  19036
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3089 : -1.0
LR:  0.001
replay buffer size:  189648
Time Taken :  517.0  mins 5.818663120269775  seconds
[[[    0.     0.     0.     0.    34.    77.    60.    48.    25.    13.
       3.     0.     0.    11.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   210.  4258.  2008.  1453.   534.   120.   104.
      38.     9.   679.   104.    25.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 24996.  5898.  5340.  1429.   934.   310.    41.   103.
      21.   240.   377.   103.     9.    30.     4.     4.     3.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 66928.  9933.  8073.  1911.  2603.  3186.  3971.  3651.  2437.
    2407.   986.   232.   241.    33.    18.     8.     4.     1.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   167.   196.   165.   106.     0.     0.     0.     0.
       0.    51.   298.   110.    16.    14.    10.     6.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    32.    14.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7846219
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3239, frames: 170604, time: 33146.76440572739
training steps:  20203
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3239 : -1.0
LR:  0.001
replay buffer size:  201400
Time Taken :  552.0  mins 26.764194011688232  seconds
[[[    0.     0.     0.     0.    39.    78.    63.    52.    25.    13.
       4.     0.     0.    11.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   219.  4340.  2207.  1486.   537.   120.   105.
      38.     9.   681.   105.    26.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 28243.  6100.  5540.  1467.   948.   328.    42.   103.
      21.   252.   383.   104.     9.    30.     4.     4.     3.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 71769. 10124.  8300.  2049.  2668.  3243.  4050.  3726.  2471.
    2443.   996.   233.   247.    33.    18.     8.     4.     1.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   176.   211.   170.   111.     0.     0.     0.     0.
       0.    52.   298.   110.    16.    14.    10.     6.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    32.    14.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.74707186
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3386, frames: 180416, time: 34663.48161268234
training steps:  21307
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3386 : -1.0
LR:  0.001
replay buffer size:  200500
Time Taken :  577.0  mins 43.481399059295654  seconds
[[[    0.     0.     0.     0.    41.    81.    64.    56.    26.    15.
       5.     0.     0.    11.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   231.  4557.  2403.  1583.   576.   129.   108.
      40.     9.   687.   106.    26.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 31843.  6340.  5647.  1558.   987.   355.    44.   104.
      21.   259.   397.   110.    10.    30.     4.     4.     3.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 75820. 10316.  8427.  2078.  2750.  3306.  4204.  3789.  2520.
    2503.  1014.   233.   253.    36.    18.     8.     4.     1.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   179.   213.   171.   115.     0.     0.     0.     0.
       0.    54.   319.   112.    16.    14.    10.     6.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    33.    15.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7196652
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3523, frames: 190361, time: 36252.19507980347
training steps:  22425
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3523 : -1.0
LR:  0.001
replay buffer size:  200200
Time Taken :  604.0  mins 12.19486117362976  seconds
[[[    0.     0.     0.     0.    43.    84.    64.    59.    28.    15.
       5.     0.     0.    11.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   234.  4692.  2518.  1612.   579.   130.   108.
      40.     9.   704.   115.    28.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 35178.  6532.  5749.  1604.  1038.   379.    45.   104.
      21.   267.   406.   114.    10.    30.     4.     4.     3.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 80624. 10635.  8527.  2142.  2829.  3428.  4271.  3827.  2551.
    2545.  1031.   235.   259.    36.    18.     8.     4.     1.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   184.   217.   178.   117.     0.     0.     0.     0.
       0.    55.   320.   112.    16.    14.    10.     6.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    33.    16.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7525859
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3664, frames: 200535, time: 38147.23127770424
training steps:  23566
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3664 : -1.0
LR:  0.001
replay buffer size:  200700
Time Taken :  635.0  mins 47.231059074401855  seconds
[[[    0.     0.     0.     0.    44.    86.    67.    64.    33.    15.
       5.     0.     0.    11.     6.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   244.  4781.  2607.  1658.   584.   134.   109.
      42.     9.   712.   117.    28.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0. 39145.  6704.  6125.  1675.  1048.   397.    46.   104.
      21.   270.   417.   117.    11.    30.     4.     4.     3.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 84999. 10775.  8604.  2294.  2888.  3549.  4315.  3859.  2583.
    2585.  1055.   237.   264.    36.    18.     8.     4.     1.     1.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   186.   220.   188.   120.     0.     0.     0.     0.
       0.    55.   324.   113.    16.    14.    10.     6.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    33.    17.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
