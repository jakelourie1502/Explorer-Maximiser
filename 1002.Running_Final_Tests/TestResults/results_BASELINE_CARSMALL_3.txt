EVALUATIONS AND MAIN RESULTS
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9863864864864865
siam score:  -0.004044145758774492
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 54, frames: 1272, time: 30.274640798568726
training steps:  6
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
54 : -1.0
LR:  5e-06
replay buffer size:  1757
Time Taken :  0.0  mins 30.274434089660645  seconds
[[[  0.   0.   0.   0.   1.   1.   0.   1.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   2.   4.  10.   3.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  96.  29.   6.   9.   0.   5.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0. 427. 115.  32.  32.  88. 121.  75.  61.  44.  23.   3.   0.   1.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  11.  11.   3.   2.   0.   0.   0.   0.   0.   2.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9966105263157895
siam score:  -0.81348383
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.993232541163435
rdn probs:  [1.0]
Episodes: 264, frames: 10736, time: 1428.8681468963623
training steps:  1276
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
264 : -1.0
LR:  0.001
replay buffer size:  12716
Time Taken :  23.0  mins 48.86794710159302  seconds
[[[   0.    0.    0.    0.    2.    2.    4.    3.    0.    3.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   16.  181.  168.  142.   59.    8.    4.    3.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  751.  868.  441.   76.   32.   22.    3.   10.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 3394. 1322.  517.  539.  637.  497.  369.  188.   77.   29.
      4.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   28.   42.   18.   10.    0.    0.    0.    0.    0.
      2.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.8917007
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 530, frames: 20426, time: 2834.177938938141
training steps:  2418
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
530 : -1.0
LR:  0.001
replay buffer size:  23621
Time Taken :  47.0  mins 14.177733898162842  seconds
[[[   0.    0.    0.    0.    6.    4.   10.    5.    4.    3.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   42.  396.  243.  188.  109.   15.    6.    5.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1110. 1331.  638.  148.   58.   46.    5.   13.    1.
      9.    2.    2.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 6362. 3029. 1501.  746. 1158.  940.  708.  464.  263.  102.
     11.    2.    3.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   59.   76.   39.   27.    0.    0.    0.    0.    0.
      3.    1.    1.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    1.    0.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.88130957
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 790, frames: 30354, time: 4166.422060966492
training steps:  3704
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
790 : -1.0
LR:  0.001
replay buffer size:  34984
Time Taken :  69.0  mins 26.421858072280884  seconds
[[[   0.    0.    0.    0.    6.   14.   12.    9.    5.    5.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   62.  557.  368.  256.  165.   19.   27.    7.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1579. 1708.  831.  274.  122.   74.    9.   15.    1.
      9.    9.    2.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 9407. 4301. 2547.  951. 1612. 1414. 1120.  950.  543.  237.
     24.    6.    4.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   74.  100.   60.   48.    0.    0.    0.    0.    0.
      6.    4.    3.    1.    0.    1.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    1.    2.    2.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.874033
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1070, frames: 40389, time: 5569.340334177017
training steps:  5015
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1070 : -1.0
LR:  0.001
replay buffer size:  46390
Time Taken :  92.0  mins 49.34013390541077  seconds
[[[    0.     0.     0.     0.     8.    16.    18.    17.     9.     5.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.    80.   665.   486.   305.   178.    25.    34.
      10.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2025.  2123.  1026.   586.   212.   106.    10.    15.
       1.    17.    35.     3.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 11991.  5415.  4158.  1207.  2013.  1849.  1507.  1446.   877.
     361.    46.    12.    10.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.    99.   131.    82.    79.     0.     0.     0.     0.
       0.     6.     4.     3.     1.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     1.     2.     2.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.8240338
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1318, frames: 50331, time: 8261.052253961563
training steps:  6208
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1318 : -1.0
LR:  0.001
replay buffer size:  57314
Time Taken :  137.0  mins 41.052062034606934  seconds
[[[    0.     0.     0.     0.    10.    23.    23.    23.    11.     6.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.    93.   941.   687.   436.   208.    31.    47.
      16.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2474.  2483.  1340.  1151.   802.   157.    13.    15.
       1.    17.    35.     3.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 14174.  6267.  5733.  1426.  2295.  2167.  1796.  1859.  1169.
     514.    62.    16.    16.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   112.   146.    92.   101.     0.     0.     0.     0.
       0.     6.     4.     3.     1.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     1.     2.     2.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7669553
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1575, frames: 60341, time: 11392.899550914764
training steps:  7515
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1575 : -1.0
LR:  0.001
replay buffer size:  69244
Time Taken :  189.0  mins 52.899362087249756  seconds
[[[    0.     0.     0.     0.    11.    31.    31.    30.    12.     6.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   109.  1169.   832.   532.   280.    37.    55.
      17.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2797.  2748.  1672.  1581.  1262.   198.    17.    15.
       2.    19.    49.     4.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 16016.  7217.  8239.  1737.  2562.  2390.  2037.  2243.  1426.
     672.    81.    26.    26.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   131.   160.   116.   125.     0.     0.     0.     0.
       0.     8.    20.     5.     2.     1.     2.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     1.     2.     2.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7252823
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1798, frames: 70463, time: 14487.828867912292
training steps:  8669
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1798 : -1.0
LR:  0.001
replay buffer size:  80946
Time Taken :  241.0  mins 27.828699827194214  seconds
[[[    0.     0.     0.     0.    12.    34.    35.    38.    13.     6.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   119.  1189.   978.   705.   309.    39.    62.
      19.     0.     1.     1.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3061.  3038.  2045.  2131.  1684.   234.    18.    43.
       2.    19.    51.     6.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17605.  8105. 11207.  2249.  2732.  2582.  2340.  2494.  1746.
     865.   112.    41.    39.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   145.   175.   136.   142.     0.     0.     0.     0.
       0.    12.    27.     6.     2.     1.     2.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     1.     2.     2.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.72686166
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2010, frames: 80605, time: 17386.187840938568
training steps:  9737
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2010 : -1.0
LR:  0.001
replay buffer size:  92528
Time Taken :  289.0  mins 46.18764805793762  seconds
[[[    0.     0.     0.     0.    14.    38.    43.    44.    17.     6.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   127.  1233.  1140.   934.   353.    46.    67.
      22.     0.     1.     1.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3372.  3359.  2371.  2822.  1823.   260.    21.    63.
      58.    52.    55.     9.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 18920.  9196. 13548.  3204.  2875.  2715.  2663.  2773.  2082.
    1215.   161.   120.    51.     1.     1.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   154.   189.   149.   144.     0.     0.     0.     0.
       0.    22.    37.     7.     2.     2.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     2.     2.     2.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7189415
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2248, frames: 90494, time: 20115.740767002106
training steps:  10796
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2248 : -1.0
LR:  0.001
replay buffer size:  103903
Time Taken :  335.0  mins 15.74057388305664  seconds
[[[    0.     0.     0.     0.    14.    42.    47.    51.    21.     6.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   136.  1364.  1443.  1548.   425.    58.    71.
      29.     0.     1.     1.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3675.  3786.  2991.  3743.  2393.   296.    31.    63.
      59.    78.    72.    12.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 20242.  9947. 15253.  3499.  2957.  2868.  2961.  3010.  2359.
    1424.   208.   126.    62.     4.     2.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   185.   206.   159.   154.     0.     0.     0.     0.
       0.    28.    82.    28.     4.     2.     4.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     3.     4.     3.     1.     2.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7742413
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2512, frames: 100549, time: 22826.819577932358
training steps:  11851
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2512 : -1.0
LR:  0.001
replay buffer size:  115113
Time Taken :  380.0  mins 26.819385051727295  seconds
[[[    0.     0.     0.     0.    15.    47.    48.    54.    21.     6.
       1.     0.     0.     0.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   153.  1494.  1771.  1652.   485.    70.    88.
      31.    51.    28.     3.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3961.  4112.  3460.  4323.  2886.   336.    36.    64.
      59.   109.    81.    16.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 21808. 10486. 17536.  4034.  3108.  3037.  3260.  3291.  2610.
    1823.   309.   146.    90.     4.     2.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   223.   227.   170.   162.     0.     0.     0.     0.
       0.    37.   145.    33.     6.     2.     4.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     3.     8.     3.     3.     2.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7647221
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2758, frames: 110173, time: 25811.557454109192
training steps:  13208
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2758 : -1.0
LR:  0.001
replay buffer size:  126398
Time Taken :  430.0  mins 11.557265043258667  seconds
[[[    0.     0.     0.     0.    15.    50.    56.    59.    23.     7.
       2.     0.     0.     0.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   164.  1649.  2181.  1716.   606.    80.    94.
      36.    51.    28.     3.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  4289.  4525.  3928.  5019.  3536.   378.    39.    77.
      62.   169.    93.    20.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 22859. 10984. 19015.  4496.  3303.  3305.  3654.  3625.  3034.
    2368.   414.   167.   121.     4.     2.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   239.   233.   179.   165.     0.     0.     0.     0.
       0.    66.   149.    37.     6.     2.     4.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     3.    13.     4.     3.     2.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.72946715
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2992, frames: 120214, time: 29380.562494039536
training steps:  14927
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2992 : -1.0
LR:  0.001
replay buffer size:  137643
Time Taken :  489.0  mins 40.5622980594635  seconds
[[[    0.     0.     0.     0.    16.    54.    59.    59.    27.     7.
       3.     0.     0.     0.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   181.  1835.  2257.  1932.   630.    87.    98.
      40.    51.    35.     3.     0.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  4669.  4887.  4170.  6078.  4261.   410.    42.    78.
      63.   198.   142.    23.     1.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 23833. 11365. 21319.  5047.  3445.  3632.  4060.  3947.  3334.
    2804.   476.   191.   144.     4.     3.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   245.   249.   190.   170.     0.     0.     0.     0.
       0.    85.   186.    45.     9.     2.     5.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     3.    16.     5.     4.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7303328
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3217, frames: 130381, time: 32161.731068849564
training steps:  16124
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3217 : -1.0
LR:  0.001
replay buffer size:  149164
Time Taken :  536.0  mins 1.7308759689331055  seconds
[[[    0.     0.     0.     0.    17.    56.    62.    64.    28.     7.
       4.     0.     0.     0.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   189.  1897.  2277.  1949.   644.    93.   100.
      42.    51.    35.     9.     1.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  4984.  5174.  4284.  6893.  4896.   434.    43.    79.
      64.   209.   172.    30.     1.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 24774. 11868. 24260.  5799.  3641.  4233.  4320.  4262.  3664.
    3271.   557.   219.   167.     4.     3.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   252.   261.   197.   179.     0.     0.     0.     0.
       0.    99.   213.    63.    12.     3.     5.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     6.    22.     8.     6.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.75603193
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3446, frames: 140527, time: 34461.621145009995
training steps:  17148
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3446 : -1.0
LR:  0.001
replay buffer size:  160359
Time Taken :  574.0  mins 21.62094497680664  seconds
[[[    0.     0.     0.     0.    18.    56.    64.    65.    28.     7.
       4.     0.     0.     0.     2.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   194.  1960.  2301.  1976.   648.    97.   101.
      45.    51.    73.    12.     2.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  5351.  5382.  4370.  8512.  5588.   464.    44.   100.
      65.   251.   208.    41.     2.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 25586. 12341. 26639.  6152.  3829.  4643.  4699.  4658.  4038.
    3792.   696.   251.   199.     4.     3.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   263.   270.   206.   185.     0.     0.     0.     0.
       0.   118.   273.    72.    13.     3.     5.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    10.    26.    11.     7.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.75551665
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3664, frames: 150296, time: 36705.99064707756
training steps:  18144
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3664 : -1.0
LR:  0.001
replay buffer size:  170980
Time Taken :  611.0  mins 45.99044895172119  seconds
[[[    0.     0.     0.     0.    20.    59.    65.    65.    28.     7.
       4.     0.     0.     0.     4.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   200.  2024.  2314.  1982.   650.    97.   101.
      45.    51.    88.    15.     3.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  5612.  5561.  4467. 10106.  6798.   496.    45.   100.
      65.   306.   218.    46.     2.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 26555. 12774. 28532.  6412.  4014.  4881.  5090.  4996.  4392.
    4287.   856.   285.   232.     4.     3.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   274.   279.   209.   192.     0.     0.     0.     0.
       0.   137.   372.    96.    28.     6.     5.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    14.    31.    14.    10.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.76192945
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3938, frames: 160376, time: 38898.33018398285
training steps:  19137
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3938 : -1.0
LR:  0.001
replay buffer size:  182359
Time Taken :  648.0  mins 18.32999086380005  seconds
[[[    0.     0.     0.     0.    22.    61.    68.    66.    28.     7.
       4.     0.     0.     1.     4.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   207.  2097.  2349.  2046.   656.    98.   103.
      46.    51.   105.    16.     3.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  5918.  5720.  4579. 11557.  8409.   561.    47.   100.
      65.   371.   237.    55.     2.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 27540. 13259. 30499.  6575.  4192.  5184.  5307.  5255.  4714.
    4816.   971.   306.   271.     8.     4.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   284.   299.   225.   199.     0.     0.     0.     0.
       0.   159.   408.   122.    60.    21.     6.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    22.    39.    14.    11.     4.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.75962967
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 4163, frames: 170100, time: 40816.67847895622
training steps:  20078
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4163 : -1.0
LR:  0.001
replay buffer size:  192459
Time Taken :  680.0  mins 16.678285121917725  seconds
[[[    0.     0.     0.     0.    24.    61.    70.    67.    28.     7.
       4.     0.     0.     2.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   215.  2156.  2366.  2056.   660.    98.   104.
      46.    51.   106.    21.     5.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  6239.  5917.  4675. 13289. 10255.   619.    49.   103.
      66.   409.   275.    60.     3.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 28339. 13618. 32195.  6732.  4346.  5391.  5555.  5489.  4961.
    5316.  1147.   330.   307.    12.     5.     0.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   287.   306.   234.   208.     0.     0.     0.     0.
       0.   172.   510.   165.    63.    21.     6.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    28.    45.    14.    14.     4.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7506964
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 4404, frames: 180423, time: 42747.4640789032
training steps:  21207
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4404 : -1.0
LR:  0.001
replay buffer size:  200100
Time Taken :  712.0  mins 27.46387505531311  seconds
[[[    0.     0.     0.     0.    24.    63.    70.    68.    28.     7.
       4.     0.     0.     2.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   220.  2237.  2382.  2147.   664.    98.   105.
      46.    51.   237.    24.     7.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  6530.  6047.  4742. 14836. 12158.   674.    51.   105.
      67.   464.   360.    74.     4.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 29167. 14034. 33837.  6879.  4548.  5668.  5943.  5716.  5285.
    5897.  1361.   380.   350.    15.     6.     4.    11.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   289.   317.   249.   218.     0.     0.     0.     0.
       0.   191.   618.   215.    65.    24.     7.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    31.    51.    17.    15.     4.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -0.9425000000000001
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9976
siam score:  -0.74878097
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.99520576
rdn probs:  [1.0]
Episodes: 4663, frames: 190476, time: 44594.563493967056
training steps:  22431
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4663 : -1.0
LR:  0.001
replay buffer size:  200241
Time Taken :  743.0  mins 14.563289165496826  seconds
[[[    0.     0.     0.     0.    25.    64.    71.    70.    28.     8.
       4.     0.     0.     3.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   227.  2281.  2394.  2328.   689.    99.   105.
      46.    51.   262.    73.    10.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  6686.  6194.  4862. 16106. 13185.   726.    52.   105.
      67.   644.   469.    92.     4.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 29923. 14482. 35755.  7128.  4820.  5952.  6361.  6022.  5608.
    6624.  1730.   462.   395.    24.     8.     4.    11.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   301.   329.   255.   225.     0.     0.     0.     0.
       0.   202.   682.   229.    68.    27.     9.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    35.    60.    20.    15.     5.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9976
siam score:  -0.76877815
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.8883062500000002
rdn probs:  [1.0]
Episodes: 4924, frames: 200314, time: 46288.536371946335
training steps:  23614
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4924 : -1.0
LR:  0.001
replay buffer size:  200122
Time Taken :  771.0  mins 28.53616690635681  seconds
[[[    0.     0.     0.     0.    27.    64.    74.    70.    28.     8.
       4.     0.     0.     3.     5.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   246.  2309.  2432.  2346.   693.   100.   107.
      47.    51.   262.    86.    10.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  7006.  6338.  5026. 17468. 14421.   784.    52.   122.
      76.   744.   547.   107.     5.     0.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 30716. 14841. 37028.  7744.  5070.  6164.  6608.  6297.  5945.
    7251.  2354.   527.   446.    24.     8.     5.    15.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   311.   334.   264.   231.     0.     0.     0.     0.
       0.   218.   733.   314.    74.    31.    12.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    38.    64.    23.    17.     6.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
