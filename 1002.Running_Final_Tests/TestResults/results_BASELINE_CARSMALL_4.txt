EVALUATIONS AND MAIN RESULTS
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.990890990990991
siam score:  0.00976799585900846
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 93, frames: 1693, time: 26.726373195648193
training steps:  5
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
93 : -1.0
LR:  4e-06
replay buffer size:  1996
Time Taken :  0.0  mins 26.72620701789856  seconds
[[[  0.   0.   0.   0.   0.   1.   1.   4.   0.   1.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   7.  13.   8.   6.   3.   1.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  56.  43.  28.  14.   8.   7.   1.   0.   0.   1.   1.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0. 478. 166.  45.  65. 159. 143.  71. 104.  56.  39.   9.   3.   5.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  19.  19.  11.   1.   0.   0.   0.   0.   0.   1.   1.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9975798143851509
siam score:  -0.72745955
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.995165486068712
rdn probs:  [1.0]
Episodes: 403, frames: 10691, time: 1314.5536398887634
training steps:  1297
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
403 : -1.0
LR:  0.001
replay buffer size:  12888
Time Taken :  21.0  mins 54.553475856781006  seconds
[[[   0.    0.    0.    0.    1.    1.    5.    7.    1.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   30.  125.  100.   53.    8.    3.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  891.  622.  219.  224.   33.   20.    3.    3.    1.
     18.   10.    5.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 3331. 1268.  263.  239.  552.  541.  418.  396.  322.  244.
     57.   11.   23.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   68.   86.   46.   10.    0.    0.    0.    0.    0.
      3.   11.    5.    0.    2.    1.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    1.    4.    0.    0.    1.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.85291654
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 788, frames: 20215, time: 2767.771640062332
training steps:  2439
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
788 : -1.0
LR:  0.001
replay buffer size:  22699
Time Taken :  46.0  mins 7.771517992019653  seconds
[[[   0.    0.    0.    0.    7.    9.    9.   10.    1.    1.    0.
      0.    0.    1.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   80.  294.  155.   78.   17.    5.    1.    2.
      0.   12.    2.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1527.  875.  493.  276.   69.   42.    5.   16.    2.
     29.   17.   10.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 7797. 2209.  582.  408.  763.  749.  654.  621.  510.  421.
    103.   32.   41.    6.    1.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  157.  167.   79.   28.    0.    0.    0.    0.    0.
     14.   16.    5.    2.    3.    2.    2.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    3.    4.    0.    0.    1.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.8679953
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1178, frames: 30284, time: 4323.777206897736
training steps:  3640
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1178 : -1.0
LR:  0.001
replay buffer size:  33350
Time Taken :  72.0  mins 3.7770462036132812  seconds
[[[    0.     0.     0.     0.    12.    16.    15.    14.     5.     4.
       0.     0.     1.     1.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   118.   513.   369.   363.    61.    24.     6.
       6.     1.    12.     2.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2241.  1279.   705.   391.   169.    82.    10.    19.
      10.    58.    47.    15.     1.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 11368.  3351.   866.   549.   955.   978.   866.   985.   826.
     676.   189.    55.    81.    14.     5.     1.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   228.   219.   123.    46.     0.     0.     0.     0.
       0.    17.    88.    12.     3.     3.     8.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.     9.     6.     3.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.99782
siam score:  -0.847883
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9956447524
rdn probs:  [1.0]
Episodes: 1552, frames: 40180, time: 5808.33951997757
training steps:  4757
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1552 : -1.0
LR:  0.001
replay buffer size:  43531
Time Taken :  96.0  mins 48.33935189247131  seconds
[[[    0.     0.     0.     0.    17.    26.    21.    20.     7.     5.
       1.     0.     1.     2.     0.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   145.   642.   618.   523.    81.    28.    11.
       8.     1.    21.     7.     2.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2822.  1703.   969.   507.   366.   124.    16.    24.
      13.    86.    72.    21.     2.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 14937.  4520.  1188.   653.  1161.  1220.  1184.  1258.  1116.
     934.   308.    75.   108.    15.     6.     2.     2.     1.     1.
       0.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   300.   286.   146.    59.     0.     0.     0.     0.
       0.    32.   107.    33.     6.    10.    10.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    12.    10.     5.     1.     2.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.8497099
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 1904, frames: 50210, time: 7405.339963197708
training steps:  5985
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1904 : -1.0
LR:  0.001
replay buffer size:  54043
Time Taken :  123.0  mins 25.33979606628418  seconds
[[[    0.     0.     0.     0.    21.    34.    35.    23.     9.     6.
       3.     0.     1.     5.     3.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   166.   876.   827.   643.   119.    42.    14.
      10.     1.    87.    14.     2.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3620.  2127.  1128.   640.   484.   162.    17.    27.
      15.   192.   158.    33.     3.     3.     2.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17804.  5439.  1494.   871.  1394.  1556.  1584.  1695.  1485.
    1389.   458.   133.   144.    18.    12.     7.     4.     1.     1.
       0.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   346.   326.   176.    78.     0.     0.     0.     0.
       0.    46.   170.    38.    10.    12.    11.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    15.    14.     6.     3.     3.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.708311
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2231, frames: 60159, time: 9169.156106948853
training steps:  7462
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2231 : -1.0
LR:  0.001
replay buffer size:  64572
Time Taken :  152.0  mins 49.15593886375427  seconds
[[[    0.     0.     0.     0.    24.    40.    44.    32.    12.     7.
       3.     0.     1.     5.     4.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   201.  1077.  1056.   858.   200.    49.    15.
      11.     1.    94.    17.     3.     0.     1.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  4399.  2594.  1321.   754.   674.   197.    26.    28.
      15.   321.   240.    43.     4.     3.     2.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 20557.  6267.  1742.  1118.  1701.  1879.  2053.  2073.  1876.
    1782.   621.   197.   178.    18.    16.    12.     8.     1.     1.
       0.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   370.   351.   201.    97.     0.     0.     0.     0.
       0.    65.   216.    44.    14.    15.    11.     6.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    24.    18.     7.     4.     3.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.71954507
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2587, frames: 70249, time: 10759.464478969574
training steps:  8659
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2587 : -1.0
LR:  0.001
replay buffer size:  75114
Time Taken :  179.0  mins 19.464311122894287  seconds
[[[    0.     0.     0.     0.    29.    46.    47.    34.    14.     9.
       4.     0.     1.     5.     6.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   223.  1177.  1215.  1064.   232.    58.    19.
      14.     1.   151.    25.     5.     0.     1.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  4911.  2913.  1426.   871.   827.   236.    32.    30.
      15.   417.   327.    60.     5.     3.     2.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 23056.  7263.  1966.  1339.  2115.  2255.  2723.  2621.  2426.
    2376.   833.   297.   241.    18.    17.    13.     8.     1.     1.
       0.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   406.   376.   228.   106.     0.     0.     0.     0.
       0.    92.   240.    58.    18.    16.    12.     7.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    27.    26.     9.     6.     3.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.73249453
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 2924, frames: 80351, time: 12326.750355958939
training steps:  9786
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2924 : -1.0
LR:  0.001
replay buffer size:  85915
Time Taken :  205.0  mins 26.75018882751465  seconds
[[[    0.     0.     0.     0.    33.    52.    54.    38.    16.    12.
       4.     0.     1.     8.     6.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   237.  1255.  1401.  1238.   288.    64.    26.
      17.     1.   211.    66.    11.     0.     1.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  5271.  3204.  1608.   991.  1073.   272.    35.    39.
      19.   665.   518.    95.    13.    13.    60.     4.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 25195.  8282.  2326.  1507.  2408.  2672.  3305.  3111.  3000.
    3008.  1084.   394.   290.    21.    20.    27.    13.     3.     1.
       0.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   431.   397.   247.   121.     0.     0.     0.     0.
       0.   119.   308.    66.    25.    18.    14.     8.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    30.    26.    10.     8.     4.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.73927325
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 3262, frames: 90196, time: 13816.81536412239
training steps:  10874
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3262 : -1.0
LR:  0.001
replay buffer size:  96218
Time Taken :  230.0  mins 16.815195083618164  seconds
[[[    0.     0.     0.     0.    36.    55.    63.    42.    18.    12.
       4.     0.     1.    11.    10.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   255.  1359.  1548.  1567.   305.    68.    32.
      23.     1.   341.   137.    19.     0.     2.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  5811.  3495.  1744.  1105.  1322.   305.    39.    40.
      21.   883.   720.   129.    14.    13.    61.     4.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 26990.  8976.  2561.  1698.  2743.  3102.  3783.  3706.  3546.
    3613.  1397.   583.   352.    23.    24.    27.    22.     4.     1.
       0.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   447.   422.   273.   130.     0.     0.     0.     0.
       0.   143.   464.   103.    35.    20.    16.     9.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    36.    33.    13.     9.     7.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9974599999999999
siam score:  -0.75173676
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9949264515999998
rdn probs:  [1.0]
Episodes: 3599, frames: 100393, time: 15382.917787790298
training steps:  12017
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3599 : -1.0
LR:  0.001
replay buffer size:  106999
Time Taken :  256.0  mins 22.91762399673462  seconds
[[[    0.     0.     0.     0.    36.    57.    67.    47.    21.    13.
       5.     0.     1.    12.    10.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   271.  1477.  1745.  1828.   381.   129.    78.
      33.     1.   417.   182.    27.     0.     3.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  6339.  3819.  1886.  1233.  1627.   337.    47.    43.
      23.   996.   910.   157.    15.    24.    62.     4.     1.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 28605.  9699.  2772.  1870.  3132.  3643.  4326.  4374.  4116.
    4409.  1704.   840.   417.    24.    32.    28.    25.     5.     2.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   459.   444.   286.   135.     0.     0.     0.     0.
       0.   184.   521.   138.    49.    25.    21.    16.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    42.    44.    16.    12.     7.     4.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9974599999999999
siam score:  -0.7558644
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9949264515999998
rdn probs:  [1.0]
Episodes: 3954, frames: 110314, time: 16919.73900103569
training steps:  13135
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3954 : -1.0
LR:  0.001
replay buffer size:  117467
Time Taken :  281.0  mins 59.73883104324341  seconds
[[[    0.     0.     0.     0.    39.    60.    75.    56.    25.    13.
       6.     0.     1.    14.    10.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   288.  1533.  1922.  2039.   415.   183.   144.
      48.     1.   508.   194.    35.     0.     3.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  6838.  4143.  2174.  1380.  2178.   383.    51.    45.
      24.  1156.  1059.   183.    16.    24.    74.     6.     2.    21.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 30364. 10359.  2985.  2085.  3469.  4098.  4730.  4870.  4606.
    4996.  2008.   955.   467.    26.    36.    31.    46.     7.     3.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   479.   464.   305.   147.     0.     0.     0.     0.
       0.   228.   739.   206.    59.    26.    27.    17.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    51.    48.    22.    12.     9.     6.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7642862
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 4311, frames: 120405, time: 18462.303149938583
training steps:  14259
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4311 : -1.0
LR:  0.001
replay buffer size:  128109
Time Taken :  307.0  mins 42.302984952926636  seconds
[[[    0.     0.     0.     0.    43.    66.    82.    60.    30.    17.
       7.     1.     1.    16.    11.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   297.  1657.  2046.  2331.   488.   236.   186.
      60.     2.   572.   214.    38.     0.     4.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  7291.  4431.  2392.  1610.  2603.   437.    55.    48.
      28.  1231.  1200.   217.    19.    27.    75.     6.     2.    21.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 32161. 11007.  3233.  2268.  3773.  4537.  5143.  5433.  5111.
    5655.  2480.  1106.   537.    26.    45.    32.    59.    12.     3.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   495.   486.   316.   157.     0.     0.     0.     0.
       0.   256.   924.   326.    92.    30.    30.    20.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    56.    58.    30.    16.    12.     6.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.74357444
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 4651, frames: 130358, time: 20033.193106889725
training steps:  15381
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4651 : -1.0
LR:  0.001
replay buffer size:  138938
Time Taken :  333.0  mins 53.192944049835205  seconds
[[[    0.     0.     0.     0.    45.    68.    84.    63.    34.    18.
       8.     1.     1.    17.    13.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   307.  1762.  2145.  2542.   513.   247.   194.
      67.     2.   636.   221.    40.     0.     4.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  7690.  4703.  2532.  1723.  3005.   478.    57.    55.
      30.  1351.  1367.   235.    20.    27.    75.     6.     2.    21.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 33808. 11559.  3543.  2476.  4183.  5015.  5674.  6087.  5697.
    6342.  3083.  1309.   613.    34.    54.    34.    61.    22.     4.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   504.   503.   336.   172.     0.     0.     0.     0.
       0.   297.  1058.   376.   111.    66.    36.    21.     0.     6.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    62.    70.    34.    19.    18.     6.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.72023714
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 5005, frames: 140429, time: 21654.727578878403
training steps:  16525
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5005 : -1.0
LR:  0.001
replay buffer size:  150001
Time Taken :  360.0  mins 54.727417945861816  seconds
[[[    0.     0.     0.     0.    50.    68.    91.    68.    38.    20.
       8.     1.     1.    17.    14.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   323.  1830.  2264.  2705.   530.   270.   199.
      72.     2.   713.   229.    44.     0.     4.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  8063.  5026.  2711.  1890.  3563.   525.    60.    61.
      32.  1506.  1540.   268.    21.    27.    75.     6.     2.    21.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 35439. 12213.  3733.  2671.  4544.  5500.  6118.  6604.  6270.
    7046.  4037.  1403.   688.    34.    54.    34.    61.    22.     4.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   522.   522.   344.   189.     0.     0.     0.     0.
       0.   337.  1178.   406.   126.    68.    38.    23.     0.     6.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    68.    76.    38.    20.    18.     7.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.71616626
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 5327, frames: 150216, time: 23205.45332288742
training steps:  17634
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5327 : -1.0
LR:  0.001
replay buffer size:  160619
Time Taken :  386.0  mins 45.45315384864807  seconds
[[[    0.     0.     0.     0.    53.    70.    96.    69.    43.    24.
       9.     1.     1.    17.    14.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   337.  1861.  2380.  3094.   582.   285.   203.
      77.     2.   808.   247.    48.     0.     4.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  8417.  5254.  2910.  2058.  3743.   570.    62.    62.
      33.  1853.  1706.   307.    22.    41.    76.     6.     2.    21.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 36873. 12700.  3901.  2869.  4911.  5944.  6576.  7078.  6966.
    7743.  5074.  1623.   761.    41.    55.    34.    73.    22.     4.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   531.   535.   360.   194.     0.     0.     0.     0.
       0.   358.  1231.   440.   130.    70.    39.    24.     0.     6.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    74.    84.    45.    21.    19.     7.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.72976595
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 5643, frames: 160309, time: 24928.610601902008
training steps:  18981
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5643 : -1.0
LR:  0.001
replay buffer size:  171459
Time Taken :  415.0  mins 28.610435962677002  seconds
[[[    0.     0.     0.     0.    53.    73.   100.    75.    47.    25.
      10.     1.     1.    19.    15.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   346.  1888.  2498.  3562.   648.   323.   214.
      83.     2.   821.   252.    50.     0.     4.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  8709.  5513.  3119.  2229.  4358.   613.    64.    70.
      42.  2153.  1849.   333.    22.    41.    76.     6.     2.    21.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 38397. 13142.  4009.  3077.  5241.  6495.  7116.  7539.  7792.
    8497.  5712.  1733.   853.    41.    63.    34.    80.    22.     4.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   536.   545.   373.   203.     0.     0.     0.     0.
       0.   382.  1354.   527.   144.    79.    42.    24.     0.     6.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    79.    89.    51.    22.    19.     9.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.736611
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 5943, frames: 170345, time: 26809.41382908821
training steps:  20498
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5943 : -1.0
LR:  0.001
replay buffer size:  182660
Time Taken :  446.0  mins 49.41366505622864  seconds
[[[    0.     0.     0.     0.    55.    76.   101.    77.    53.    27.
      12.     1.     1.    20.    15.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   356.  1923.  2600.  3851.   682.   338.   225.
      92.     2.   907.   258.    52.     0.     4.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  8958.  5720.  3268.  2364.  4900.   653.    67.    79.
      44.  2393.  1944.   354.    22.    41.    76.     6.     2.    21.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 39587. 13608.  4148.  3265.  5642.  6997.  7654.  7993.  8642.
    9501.  6870.  1926.   929.    42.    76.    34.    80.    22.     4.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   542.   559.   378.   205.     0.     0.     0.     0.
       0.   397.  1495.   546.   155.   103.    42.    24.     0.     6.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    85.    96.    53.    23.    19.     9.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.7260086
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 6265, frames: 180318, time: 28707.232387065887
training steps:  22020
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6265 : -1.0
LR:  0.001
replay buffer size:  193921
Time Taken :  478.0  mins 27.232222080230713  seconds
[[[    0.     0.     0.     0.    55.    79.   105.    83.    53.    28.
      12.     1.     1.    21.    17.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   367.  1942.  2654.  3926.   713.   352.   231.
      97.     2.   966.   268.    55.     0.     5.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  9152.  5916.  3389.  2489.  5426.   691.    70.   103.
      45.  2928.  2130.   396.    24.    41.    77.     6.     2.    21.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 40988. 14108.  4331.  3452.  5977.  7545.  8245.  8402.  9357.
   10298.  7808.  2128.   999.    42.    78.    61.    82.    25.     5.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   553.   575.   386.   217.     0.     0.     0.     0.
       0.   427.  1732.   610.   179.   107.    44.    26.     0.    16.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    89.   103.    59.    26.    20.     9.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.73689514
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 6579, frames: 190274, time: 30640.174618005753
training steps:  23531
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6579 : -1.0
LR:  0.001
replay buffer size:  200200
Time Taken :  510.0  mins 40.17445683479309  seconds
[[[    0.     0.     0.     0.    56.    81.   108.    91.    58.    30.
      13.     1.     1.    21.    18.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   375.  1996.  2758.  4252.   747.   375.   244.
     107.     2.  1044.   296.    60.     0.     5.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  9325.  6119.  3594.  2648.  6276.   739.    72.   109.
      49.  3330.  2327.   438.    24.    41.    77.     6.     2.    21.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 42164. 14599.  4454.  3673.  6325.  7962.  8770.  8761.  9908.
   11016.  8725.  2312.  1067.    42.    81.    62.    82.    25.     5.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   559.   587.   396.   229.     0.     0.     0.     0.
       0.   441.  1994.   706.   220.   138.    81.    26.     0.    16.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    92.   113.    66.    27.    21.     9.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9999
siam score:  -0.73955417
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9998000100000001
rdn probs:  [1.0]
Episodes: 6870, frames: 200420, time: 32664.56052184105
training steps:  25050
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6870 : -1.0
LR:  0.001
replay buffer size:  200500
Time Taken :  544.0  mins 24.56035804748535  seconds
[[[    0.     0.     0.     0.    56.    82.   109.    91.    62.    31.
      14.     1.     1.    23.    20.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   379.  2033.  2799.  4444.   773.   378.   250.
     112.     2.  1120.   326.    64.     0.     5.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  9511.  6244.  3740.  2811.  8340.   799.    75.   109.
      49.  3629.  2462.   468.    24.    41.    77.     6.     2.    21.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 43290. 15025.  4611.  3871.  6611.  8389.  9339.  9069. 10429.
   11578.  9701.  2617.  1125.    43.    81.    62.    82.    25.     5.
       1.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   571.   598.   406.   234.     0.     0.     0.     0.
       0.   457.  2147.   741.   238.   145.    82.    26.     0.    16.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    95.   124.    70.    28.    22.     9.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
