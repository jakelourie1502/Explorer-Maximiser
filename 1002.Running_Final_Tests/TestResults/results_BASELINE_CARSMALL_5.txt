EVALUATIONS AND MAIN RESULTS
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9881352941176471
siam score:  -0.0018435797886922956
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 72, frames: 1462, time: 26.27718186378479
training steps:  4
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
72 : -1.0
LR:  3e-06
replay buffer size:  1738
Time Taken :  0.0  mins 26.277015924453735  seconds
[[[  0.   0.   0.   0.   1.   0.   1.   0.   1.   1.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   2.   4.  22.   5.   3.   2.   2.   1.   2.   1.   4.
     1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  19.  41.  25.  17.   2.   4.   0.   0.   1.  12.   4.   3.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0. 318. 149.  41.  47. 106. 124. 131. 127.  61.  32.  13.   9.   3.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  10.  12.   9.   6.   0.   0.   0.   0.   0.   3.   7.   1.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9941533936651584
siam score:  -0.7449911
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9883409701359515
rdn probs:  [1.0]
Episodes: 402, frames: 10651, time: 1243.0494248867035
training steps:  1268
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
402 : -1.0
LR:  0.001
replay buffer size:  11770
Time Taken :  20.0  mins 43.049264907836914  seconds
[[[   0.    0.    0.    0.    5.    4.    9.   11.    5.    5.    3.
      0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   28.  165.  293.  429.  138.   43.   40.   11.
      3.   11.   11.    3.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  406.  405.  317.  273.  114.   49.    6.   21.    9.
     27.   76.   23.    0.    0.    0.    0.    0.    0.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 2403.  883.  265.  238.  494.  642.  644.  483.  469.  350.
    134.   46.   22.   14.    3.    0.    1.    2.    1.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   34.   48.   24.   18.    0.    0.    0.    0.    0.
      6.   31.   29.    6.    1.    2.    2.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    4.    1.    2.    1.    1.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -0.8695
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.99244
siam score:  -0.84950393
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.9849371536
rdn probs:  [1.0]
Episodes: 816, frames: 20324, time: 2813.267593860626
training steps:  2477
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
816 : -1.0
LR:  0.001
replay buffer size:  22046
Time Taken :  46.0  mins 53.26743197441101  seconds
[[[   0.    0.    0.    0.    9.   14.   20.   22.   13.    6.    4.
      0.    0.    0.    5.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   71.  359.  474.  610.  205.   58.   74.   20.
      3.   56.   39.    7.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  759.  741.  610.  424.  196.   85.   13.   24.   10.
    102.  120.   40.    0.    3.    1.    0.    0.    0.    2.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 4747. 1642.  639.  481.  942. 1049. 1168.  947.  936.  795.
    305.   81.   52.   20.   15.   24.    8.    8.    2.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   78.   93.   61.   38.    0.    0.    0.    0.    0.
     12.   69.   59.   10.    3.    4.    4.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    7.    6.    2.    1.    1.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -0.9355
Q value #end_state_>_threshold:  8
Q value #non_end_state_>threshold:  10
maxi score:  -0.98514
siam score:  -0.84209913
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.7560302500000001
rdn probs:  [1.0]
Episodes: 1189, frames: 30368, time: 4441.973044872284
training steps:  3712
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1189 : -1.0
LR:  0.001
replay buffer size:  32740
Time Taken :  74.0  mins 1.972886085510254  seconds
[[[   0.    0.    0.    0.   13.   22.   29.   28.   17.    6.    5.
      0.    0.    2.    7.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  100.  516.  731.  750.  293.   73.   82.   32.
      3.  205.   68.   13.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1127. 1075.  931.  591.  332.  136.   21.   27.   11.
    169.  227.   64.    3.    3.    4.    1.    0.    0.    3.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 6460. 2482.  947.  688. 1336. 1524. 1725. 1549. 1636. 1444.
    612.  171.   93.   21.   23.   32.   36.   16.    4.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   95.  122.   88.   43.    0.    0.    0.    0.    0.
     33.  110.  101.   20.    4.    8.    5.    0.    0.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    8.   11.    6.    3.    2.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -0.8800000000000001
Q value #end_state_>_threshold:  30
Q value #non_end_state_>threshold:  60
maxi score:  -0.9810800000000001
siam score:  -0.8265626
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.87516025
rdn probs:  [1.0]
Episodes: 1563, frames: 40329, time: 6041.22354388237
training steps:  4881
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1563 : -0.9435
LR:  0.001
replay buffer size:  43303
Time Taken :  100.0  mins 41.22338104248047  seconds
[[[   0.    0.    0.    0.   18.   30.   45.   34.   21.    6.    5.
      0.    0.    4.   10.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.  131.  660. 1008.  909.  374.   92.  114.   44.
      3.  299.  117.   18.    0.    0.    0.    0.    0.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1507. 1496. 1149.  758.  445.  184.   27.   31.   16.
    237.  314.   91.    5.    3.    4.    2.    0.    1.    4.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 8247. 3300. 1226.  880. 1835. 2004. 2342. 2098. 2184. 2116.
    833.  235.  137.   38.   34.   40.   48.   33.    7.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  113.  144.  109.   55.    0.    0.    0.    0.    0.
     50.  184.  143.   33.   10.   14.    8.    0.    3.    3.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   13.   13.   10.    4.    3.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -0.9215
Q value #end_state_>_threshold:  34
Q value #non_end_state_>threshold:  67
maxi score:  -0.98468
siam score:  -0.83554214
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.7744000000000002
rdn probs:  [1.0]
Episodes: 1938, frames: 50321, time: 7694.623495817184
training steps:  6033
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1938 : -1.0
LR:  0.001
replay buffer size:  54530
Time Taken :  128.0  mins 14.623335838317871  seconds
[[[    0.     0.     0.     0.    23.    39.    63.    45.    25.     8.
       5.     0.     0.     7.    13.     0.     0.     0.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   159.   778.  1247.  1066.   438.   102.   121.
      53.     3.   510.   146.    25.     0.     0.     2.     0.     0.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  1931.  1943.  1414.   874.   540.   228.    30.    32.
      16.   397.   430.   118.     6.     3.    12.     5.     0.     2.
       4.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 10181.  4043.  1543.  1097.  2269.  2437.  2792.  2551.  2831.
    2784.  1061.   296.   178.    63.    68.    44.    51.    33.     7.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   132.   170.   129.    73.     0.     0.     0.     0.
       0.    64.   254.   201.    49.    26.    17.    11.     0.     3.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    18.    17.    12.     6.     3.     1.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  -0.24200000000000008
Q value #end_state_>_threshold:  149
Q value #non_end_state_>threshold:  159
maxi score:  -0.9319000000000001
siam score:  -0.7565939
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.84916225
rdn probs:  [1.0]
Episodes: 2287, frames: 60279, time: 9281.74491596222
training steps:  7183
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2287 : -0.8755000000000001
LR:  0.001
replay buffer size:  65162
Time Taken :  154.0  mins 41.744754791259766  seconds
[[[    0.     0.     0.     0.    25.    44.    66.    50.    27.     9.
       6.     0.     0.    12.    15.     0.     0.     0.     1.     0.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   185.   853.  1405.  1149.   496.   122.   161.
      59.     3.   689.   205.    31.     0.     0.     4.    20.     4.
       2.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2179.  2210.  1767.  1006.   636.   257.    33.    32.
      17.   517.   608.   144.     7.     7.    31.    16.     2.     5.
       7.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 11701.  4680.  1799.  1354.  2673.  2976.  3411.  3218.  3539.
    3544.  1362.   442.   230.    86.    95.    65.    67.    51.    19.
       3.     5.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   148.   192.   151.    88.     0.     0.     0.     0.
       0.    79.   400.   255.    68.    42.    23.    15.     0.     4.
       5.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    25.    22.    17.     6.     3.     2.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6445
Q value #end_state_>_threshold:  606
Q value #non_end_state_>threshold:  536
maxi score:  -0.74464
siam score:  -0.7662721
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.05856400000000004
rdn probs:  [1.0]
Episodes: 2620, frames: 70081, time: 10820.860029935837
training steps:  8299
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2620 : -0.5165000000000002
LR:  0.001
replay buffer size:  75379
Time Taken :  180.0  mins 20.859867811203003  seconds
[[[    0.     0.     0.     0.    27.    49.    71.    56.    30.     9.
       6.     0.     1.    14.    16.     0.     0.     0.     1.     1.
       1.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   202.   894.  1553.  1224.   546.   129.   164.
      63.     3.   846.   245.    40.     0.     0.     8.    28.    12.
       6.     4.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2451.  2451.  1927.  1094.   733.   280.    34.    36.
      59.   640.   756.   161.     8.    61.    58.    27.    14.    24.
      26.     1.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 13002.  5253.  2083.  1594.  3134.  3447.  4050.  3913.  4218.
    4196.  1657.   591.   272.   117.   173.   106.   165.   147.    93.
      13.    17.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   166.   207.   164.    96.     0.     0.     0.     0.
       0.    91.   601.   327.   137.   108.    87.    24.     0.     8.
      13.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    32.    29.    20.    12.     5.     3.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6759999999999999
Q value #end_state_>_threshold:  1631
Q value #non_end_state_>threshold:  1278
maxi score:  -0.44294000000000017
siam score:  -0.8084213
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 2984, frames: 80104, time: 12410.948230981827
training steps:  9451
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2984 : -0.07600000000000019
LR:  0.001
replay buffer size:  85750
Time Taken :  206.0  mins 50.94810605049133  seconds
[[[    0.     0.     0.     0.    28.    51.    76.    60.    31.    11.
       6.     0.     1.    14.    17.     0.     0.     0.     1.     2.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   208.   970.  1670.  1247.   562.   139.   177.
      65.     3.   891.   270.    47.     0.     1.    14.    34.    22.
      12.     6.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2540.  2606.  2082.  1172.   815.   302.    34.    42.
      63.   749.   893.   186.     8.    98.   138.    56.    44.    48.
      62.     7.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 14139.  5880.  2311.  1869.  3699.  3954.  4782.  4637.  4867.
    4864.  1958.   772.   305.   176.   306.   154.   315.   317.   222.
      32.    50.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   179.   225.   176.   102.     0.     0.     0.     0.
       0.   103.   868.   447.   274.   152.   135.    38.     0.    58.
      44.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    43.    33.    23.    16.     6.     5.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6769999999999999
Q value #end_state_>_threshold:  3119
Q value #non_end_state_>threshold:  2656
maxi score:  -0.19468000000000016
siam score:  -0.8510466
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 3385, frames: 90193, time: 14020.37578701973
training steps:  10615
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3385 : -0.15250000000000016
LR:  0.001
replay buffer size:  96187
Time Taken :  233.0  mins 40.37562584877014  seconds
[[[    0.     0.     0.     0.    30.    53.    82.    60.    32.    11.
       7.     0.     1.    15.    18.     0.     0.     0.     1.     5.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   212.  1044.  1682.  1254.   586.   150.   198.
      66.     3.   923.   313.    54.     0.     4.    18.    51.    28.
      19.     7.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2697.  2722.  2167.  1232.   853.   314.    34.    44.
      63.   832.   973.   198.     9.   154.   220.    87.    92.   106.
     124.    10.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15035.  6416.  2523.  2165.  4326.  4607.  5476.  5276.  5499.
    5478.  2317.   931.   343.   201.   495.   240.   594.   585.   422.
      65.   107.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   186.   236.   186.   110.     0.     0.     0.     0.
       0.   110.  1197.   534.   464.   205.   192.    49.     0.   123.
      92.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    56.    49.    25.    19.     6.     7.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6805
Q value #end_state_>_threshold:  4859
Q value #non_end_state_>threshold:  4118
maxi score:  -0.07328000000000012
siam score:  -0.8736418
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 3821, frames: 100164, time: 15631.40119767189
training steps:  11777
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3821 : -0.14050000000000007
LR:  0.001
replay buffer size:  106501
Time Taken :  260.0  mins 31.401038885116577  seconds
[[[    0.     0.     0.     0.    30.    53.    82.    60.    32.    11.
       7.     0.     1.    15.    19.     0.     0.     0.     2.     6.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   215.  1048.  1716.  1261.   589.   152.   199.
      67.     3.   957.   346.    59.     0.     6.    25.    58.    45.
      31.     7.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2786.  2797.  2219.  1288.   907.   333.    34.    45.
      64.   872.  1037.   211.     9.   215.   337.   137.   144.   177.
     186.    19.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15611.  6952.  2692.  2524.  4993.  5290.  6189.  5877.  6077.
    6077.  2716.  1077.   372.   240.   720.   336.   914.   929.   657.
     119.   172.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   191.   254.   193.   120.     0.     0.     0.     0.
       0.   118.  1557.   638.   704.   259.   275.    60.     0.   171.
     144.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    70.    62.    33.    22.     8.     8.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6645
Q value #end_state_>_threshold:  6936
Q value #non_end_state_>threshold:  6767
maxi score:  0.08277999999999985
siam score:  -0.8823938
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 4257, frames: 110169, time: 17262.368228912354
training steps:  12956
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4257 : 0.1719999999999998
LR:  0.001
replay buffer size:  116857
Time Taken :  287.0  mins 42.36807084083557  seconds
[[[    0.     0.     0.     0.    31.    53.    83.    62.    32.    11.
       7.     0.     1.    16.    20.     0.     0.     0.     2.     6.
       3.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   217.  1049.  1754.  1271.   603.   155.   199.
      68.     3.   984.   351.    60.     0.     9.    30.    68.    63.
      42.    11.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2878.  2882.  2282.  1351.   921.   334.    34.    47.
      64.   989.  1061.   218.    10.   279.   451.   179.   203.   248.
     270.    26.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 15998.  7439.  2842.  2858.  5665.  5948.  6880.  6543.  6684.
    6666.  3132.  1241.   393.   251.   940.   442.  1369.  1369.   915.
     164.   248.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   197.   263.   205.   124.     0.     0.     0.     0.
       0.   126.  1900.   711.  1002.   310.   360.    66.     0.   207.
     224.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    78.    72.    44.    24.    12.     9.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.695
Q value #end_state_>_threshold:  9006
Q value #non_end_state_>threshold:  10191
maxi score:  0.09085999999999986
siam score:  -0.88946366
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 4676, frames: 120038, time: 18871.161379814148
training steps:  14118
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4676 : 0.018999999999999816
LR:  0.001
replay buffer size:  127060
Time Taken :  314.0  mins 31.161218881607056  seconds
[[[    0.     0.     0.     0.    31.    53.    83.    62.    32.    11.
       7.     0.     1.    16.    20.     0.     0.     0.     5.     8.
       6.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   220.  1051.  1763.  1289.   607.   156.   201.
      69.     3.   996.   353.    62.     0.    11.    32.    83.    73.
      48.    15.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2924.  2951.  2354.  1407.   941.   337.    35.    48.
      65.  1019.  1080.   226.    10.   353.   609.   245.   262.   356.
     355.    33.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 16326.  7947.  2979.  3193.  6313.  6624.  7558.  7233.  7299.
    7232.  3534.  1409.   414.   276.  1161.   565.  1780.  1766.  1192.
     222.   328.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   205.   274.   210.   125.     0.     0.     0.     0.
       0.   129.  2259.   785.  1279.   373.   454.    76.     0.   312.
     280.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    87.    83.    48.    29.    15.    11.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.698
Q value #end_state_>_threshold:  10931
Q value #non_end_state_>threshold:  13462
maxi score:  0.06857999999999985
siam score:  -0.892586
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 5106, frames: 130047, time: 20500.439446926117
training steps:  15297
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5106 : -0.0835000000000001
LR:  0.001
replay buffer size:  137405
Time Taken :  341.0  mins 40.43929886817932  seconds
[[[    0.     0.     0.     0.    31.    53.    83.    62.    32.    11.
       7.     0.     1.    18.    21.     0.     0.     0.     5.     9.
       6.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   221.  1075.  1766.  1293.   609.   157.   202.
      70.     3.  1003.   360.    64.     0.    15.    38.    91.    86.
      60.    20.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  2977.  3018.  2420.  1463.   963.   346.    35.    48.
      78.  1051.  1142.   233.    10.   424.   755.   307.   330.   444.
     434.    49.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 16721.  8464.  3117.  3544.  6955.  7263.  8258.  7969.  7968.
    7816.  3952.  1527.   442.   306.  1416.   697.  2173.  2154.  1461.
     289.   388.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   212.   278.   220.   128.     0.     0.     0.     0.
       0.   133.  2592.   870.  1562.   448.   511.    83.     0.   378.
     343.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.    98.    97.    51.    30.    17.    11.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6964999999999999
Q value #end_state_>_threshold:  13145
Q value #non_end_state_>threshold:  17416
maxi score:  0.10971999999999983
siam score:  -0.8861125
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 5541, frames: 140080, time: 22128.66604089737
training steps:  16478
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5541 : -0.019000000000000128
LR:  0.001
replay buffer size:  147773
Time Taken :  368.0  mins 48.66587996482849  seconds
[[[    0.     0.     0.     0.    31.    53.    83.    62.    32.    11.
       7.     0.     1.    19.    21.     0.     0.     0.     5.     9.
       6.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   224.  1078.  1789.  1302.   614.   159.   262.
      72.     3.  1011.   370.    66.     0.    16.    40.    99.    99.
      68.    26.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3011.  3075.  2445.  1519.   993.   351.    35.    53.
      80.  1089.  1182.   241.    10.   526.   872.   372.   401.   537.
     520.    60.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17030.  8978.  3257.  3904.  7625.  7925.  8956.  8622.  8605.
    8412.  4368.  1622.   462.   323.  1671.   813.  2640.  2590.  1785.
     345.   467.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   222.   283.   229.   138.     0.     0.     0.     0.
       0.   139.  2923.   965.  1849.   516.   579.    94.     0.   451.
     413.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.   106.   103.    55.    34.    19.    11.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6819999999999998
Q value #end_state_>_threshold:  15189
Q value #non_end_state_>threshold:  22148
maxi score:  0.07999999999999985
siam score:  -0.8727942
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 5971, frames: 150084, time: 23758.06615781784
training steps:  17652
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5971 : 0.03849999999999983
LR:  0.001
replay buffer size:  158117
Time Taken :  395.0  mins 58.06599402427673  seconds
[[[    0.     0.     0.     0.    31.    55.    83.    62.    32.    11.
       7.     0.     1.    20.    22.     0.     0.     0.     5.    11.
       6.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   227.  1083.  1791.  1312.   618.   160.   264.
      72.     3.  1051.   374.    66.     0.    18.    46.   107.   120.
      80.    30.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3077.  3152.  2530.  1598.  1028.   354.    35.    55.
      85.  1149.  1225.   248.    12.   594.   988.   429.   471.   635.
     601.    73.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17346.  9485.  3402.  4219.  8277.  8627.  9648.  9258.  9263.
    8990.  4794.  1700.   478.   345.  1901.   925.  3063.  3065.  2067.
     406.   539.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   227.   294.   236.   142.     0.     0.     0.     0.
       0.   148.  3270.  1035.  2150.   572.   706.   105.     0.   487.
     472.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.   119.   111.    62.    39.    20.    13.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6874999999999999
Q value #end_state_>_threshold:  17334
Q value #non_end_state_>threshold:  26825
maxi score:  0.14417999999999984
siam score:  -0.84629804
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 6379, frames: 160045, time: 25366.538807868958
training steps:  18828
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6379 : 0.04949999999999984
LR:  0.001
replay buffer size:  168415
Time Taken :  422.0  mins 46.538649797439575  seconds
[[[    0.     0.     0.     0.    31.    55.    83.    62.    32.    12.
       7.     0.     1.    22.    22.     0.     0.     0.     5.    11.
       7.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   228.  1084.  1804.  1318.   623.   167.   297.
      73.     3.  1057.   379.    69.     0.    20.    50.   117.   132.
      87.    36.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3127.  3216.  2633.  1686.  1077.   359.    35.    55.
      88.  1198.  1258.   256.    12.   664.  1129.   475.   553.   699.
     688.    92.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 17695.  9945.  3531.  4555.  8885.  9326. 10332.  9906.  9921.
    9569.  5204.  1745.   490.   372.  2152.  1101.  3549.  3520.  2350.
     465.   608.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   230.   301.   239.   145.     0.     0.     0.     0.
       0.   153.  3606.  1114.  2450.   630.   785.   113.     0.   557.
     538.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.   125.   118.    67.    41.    25.    14.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6984999999999999
Q value #end_state_>_threshold:  19598
Q value #non_end_state_>threshold:  31931
maxi score:  0.17393999999999982
siam score:  -0.84085464
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 6791, frames: 170066, time: 26975.795159816742
training steps:  20010
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6791 : 0.03649999999999983
LR:  0.001
replay buffer size:  178771
Time Taken :  449.0  mins 35.79500079154968  seconds
[[[    0.     0.     0.     0.    31.    56.    83.    62.    32.    12.
       7.     0.     2.    22.    22.     0.     0.     0.     5.    12.
       7.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   231.  1093.  1826.  1325.   626.   169.   298.
      75.     5.  1063.   390.    70.     0.    22.    52.   125.   158.
      95.    42.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3212.  3302.  2740.  1779.  1137.   366.    35.    56.
      88.  1259.  1305.   262.    12.   743.  1285.   529.   630.   788.
     767.   107.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 18006. 10431.  3655.  4876.  9479. 10007. 11013. 10568. 10559.
   10123.  5603.  1832.   507.   407.  2387.  1218.  4055.  3998.  2667.
     539.   688.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   235.   305.   245.   146.     0.     0.     0.     0.
       0.   158.  3954.  1194.  2739.   686.   848.   117.     0.   600.
     593.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.   130.   128.    72.    48.    25.    14.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7169999999999999
Q value #end_state_>_threshold:  21900
Q value #non_end_state_>threshold:  36767
maxi score:  0.1480399999999998
siam score:  -0.8110602
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 7209, frames: 180066, time: 28585.713356733322
training steps:  21186
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7209 : 0.04999999999999982
LR:  0.001
replay buffer size:  189103
Time Taken :  476.0  mins 25.7131929397583  seconds
[[[    0.     0.     0.     0.    31.    57.    83.    62.    32.    12.
       7.     0.     2.    22.    22.     0.     0.     0.     5.    12.
       8.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   234.  1099.  1839.  1333.   630.   171.   301.
      77.     5.  1065.   391.    71.     0.    24.    53.   138.   176.
     106.    47.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3286.  3404.  2808.  1869.  1190.   375.    35.    61.
      91.  1280.  1318.   265.    12.   831.  1449.   590.   705.   879.
     870.   120.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 18376. 10898.  3773.  5195. 10087. 10677. 11737. 11254. 11228.
   10681.  6005.  1896.   527.   443.  2640.  1373.  4505.  4452.  2950.
     611.   752.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   240.   310.   247.   152.     0.     0.     0.     0.
       0.   162.  4306.  1272.  3029.   748.   917.   122.     0.   650.
     642.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.   143.   135.    74.    52.    29.    14.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.6815
Q value #end_state_>_threshold:  24196
Q value #non_end_state_>threshold:  41915
maxi score:  0.15853999999999985
siam score:  -0.8074245
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 7634, frames: 190089, time: 30195.813047885895
training steps:  22365
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7634 : 0.20149999999999985
LR:  0.001
replay buffer size:  199467
Time Taken :  503.0  mins 15.812888860702515  seconds
[[[    0.     0.     0.     0.    31.    57.    83.    63.    32.    13.
       7.     0.     2.    23.    23.     0.     0.     0.     5.    13.
       9.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   235.  1108.  1846.  1349.   637.   174.   305.
      78.     5.  1106.   399.    73.     0.    26.    55.   159.   198.
     118.    54.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3344.  3509.  2863.  1979.  1263.   385.    35.    63.
      94.  1293.  1328.   267.    13.   967.  1615.   665.   809.   959.
     974.   134.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 18679. 11363.  3886.  5501. 10674. 11286. 12429. 11918. 11935.
   11260.  6420.  1984.   543.   463.  2909.  1545.  4921.  4883.  3216.
     665.   818.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   242.   316.   252.   155.     0.     0.     0.     0.
       0.   166.  4663.  1345.  3337.   818.   982.   128.     0.   720.
     710.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.   154.   143.    78.    57.    32.    14.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.7255
Q value #end_state_>_threshold:  26480
Q value #non_end_state_>threshold:  46787
maxi score:  0.1492599999999998
siam score:  -0.81430656
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
rdn probs:  [1.0]
Episodes: 8055, frames: 200122, time: 31842.822192907333
training steps:  23569
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8055 : 0.3369999999999997
LR:  0.001
replay buffer size:  200085
Time Taken :  530.0  mins 42.82202982902527  seconds
[[[    0.     0.     0.     0.    31.    57.    84.    63.    32.    14.
       7.     0.     2.    25.    23.     0.     0.     0.     5.    14.
       9.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.   239.  1110.  1871.  1357.   639.   181.   305.
      79.     5.  1117.   402.    74.     0.    30.    58.   167.   215.
     131.    58.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.  3422.  3627.  2965.  2099.  1318.   392.    35.    68.
      94.  1298.  1353.   271.    13.  1091.  1785.   741.   911.  1065.
    1084.   152.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0. 19022. 11838.  3993.  5799. 11296. 11889. 13133. 12609. 12545.
   11821.  6836.  2120.   558.   502.  3159.  1671.  5343.  5306.  3466.
     720.   892.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.   249.   325.   254.   159.     0.     0.     0.     0.
       0.   171.  5024.  1425.  3628.   881.  1074.   136.     0.   779.
     751.     0.     0.     0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.
       0.     0.   164.   151.    81.    62.    33.    14.     0.     0.
       0.     0.     0.     0.     0.     0.     0.     0.     0.     0.]]]
