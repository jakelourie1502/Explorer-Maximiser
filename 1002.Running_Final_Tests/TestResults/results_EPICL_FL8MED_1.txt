EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.004584444514025123
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 144, frames: 1438, time: 32.66355085372925
training steps:  6
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
144 : 0.0
LR:  5e-06
replay buffer size:  1746
Time Taken :  0.0  mins 32.663381814956665  seconds
[[[430. 182.  57.  20.   6.   0.   0.   0.]
  [212. 101.  16.   7.   2.   0.   0.   0.]
  [128.  28.   9.   3.   0.   0.   0.   0.]
  [ 43.  14.   5.   4.   0.   0.   0.   0.]
  [ 17.   6.   2.   1.   1.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.67695135
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 968, frames: 10071, time: 2754.8239200115204
training steps:  1235
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
968 : 0.0
LR:  0.001
replay buffer size:  10694
Time Taken :  45.0  mins 54.8237669467926  seconds
[[[2776. 1193.  381.  121.   32.    5.    1.    0.]
  [1624.  626.   98.   51.   16.    6.    1.    0.]
  [ 748.  177.   63.   52.   25.   13.    1.    3.]
  [ 322.  101.   39.   34.   18.   15.    4.    4.]
  [ 204.   47.   16.   18.   10.    5.   12.    6.]
  [  92.   13.    6.    3.    1.    4.    8.    5.]
  [  49.   17.    4.    2.    7.    1.    3.    1.]
  [  13.    0.    2.    2.    2.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.72939116
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1726, frames: 20059, time: 6568.033125162125
training steps:  2479
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1726 : 0.0
LR:  0.001
replay buffer size:  20971
Time Taken :  109.0  mins 28.03297185897827  seconds
[[[5533. 2278.  695.  248.   59.    6.    2.    0.]
  [3407. 1107.  161.  105.   33.   21.    7.    0.]
  [1709.  396.  157.  121.   53.   23.    2.    3.]
  [ 715.  187.   81.   82.   33.   23.    5.    4.]
  [ 408.   84.   43.   38.   17.    6.   13.    6.]
  [ 203.   42.   13.    7.    1.    4.    8.    5.]
  [ 101.   29.    6.    3.    7.    1.    3.    1.]
  [  22.    0.    2.    2.    2.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.73521596
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2324, frames: 30057, time: 9925.348995923996
training steps:  3657
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2324 : 0.0
LR:  0.001
replay buffer size:  31310
Time Taken :  165.0  mins 25.348838806152344  seconds
[[[8653. 3843. 1135.  371.   86.    6.    2.    0.]
  [5135. 1516.  219.  141.   47.   25.    7.    0.]
  [2626.  554.  214.  163.   64.   27.    5.    3.]
  [1002.  244.  100.   91.   34.   26.    7.    4.]
  [ 523.   90.   48.   40.   19.    8.   13.    6.]
  [ 275.   50.   17.    9.    1.    4.    8.    5.]
  [ 165.   46.    8.    3.    7.    1.    3.    1.]
  [  27.    0.    2.    2.    2.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.75851595
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2988, frames: 40104, time: 13101.407264947891
training steps:  4823
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2988 : 0.0
LR:  0.001
replay buffer size:  41603
Time Taken :  218.0  mins 21.407106637954712  seconds
[[[11338.  5269.  1650.   522.   111.    12.     3.     0.]
  [ 6774.  1934.   285.   192.    60.    32.     9.     2.]
  [ 3640.   726.   271.   212.    79.    30.     6.     3.]
  [ 1412.   317.   111.   103.    39.    26.     7.     4.]
  [  717.   109.    55.    48.    23.     8.    13.     6.]
  [  421.    62.    23.    14.     1.     4.     8.     5.]
  [  277.    68.    10.     3.     7.     1.     3.     1.]
  [   44.     0.     2.     2.     2.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.78262335
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3647, frames: 50081, time: 16377.013266801834
training steps:  6040
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3647 : 0.0
LR:  0.001
replay buffer size:  51910
Time Taken :  272.0  mins 57.013110876083374  seconds
[[[13649.  6560.  2118.   638.   127.    20.     5.     0.]
  [ 8465.  2347.   338.   260.    80.    44.    13.     4.]
  [ 4699.  1010.   385.   298.   102.    40.     9.     5.]
  [ 1861.   397.   138.   120.    43.    34.    10.     5.]
  [  931.   129.    70.    57.    25.    12.    14.     6.]
  [  584.    81.    30.    19.     3.     7.     8.     5.]
  [  417.    84.    18.     6.     9.     2.     3.     1.]
  [   69.     0.     5.     7.     8.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7927327
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4341, frames: 60049, time: 20003.870229005814
training steps:  7418
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4341 : 0.0
LR:  0.001
replay buffer size:  62085
Time Taken :  333.0  mins 23.870068788528442  seconds
[[[15909.  7679.  2525.   740.   145.    23.     7.     0.]
  [10017.  2735.   402.   310.    97.    52.    13.     4.]
  [ 5812.  1259.   495.   376.   121.    48.    11.     5.]
  [ 2455.   493.   174.   156.    62.    39.    10.     5.]
  [ 1276.   168.    95.    71.    28.    15.    14.     6.]
  [  808.   113.    51.    24.     3.     9.    10.     5.]
  [  567.   107.    26.     7.     9.     2.     4.     1.]
  [   90.     0.     5.     7.     8.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7838679
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4979, frames: 70074, time: 23047.735418081284
training steps:  8535
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4979 : 0.0
LR:  0.001
replay buffer size:  72305
Time Taken :  384.0  mins 7.735261917114258  seconds
[[[18256.  8857.  2928.   869.   161.    31.     8.     0.]
  [11671.  3111.   463.   372.   105.    56.    14.     4.]
  [ 7016.  1511.   602.   439.   131.    54.    13.     5.]
  [ 3127.   597.   209.   177.    71.    44.    10.     5.]
  [ 1519.   187.   113.    81.    32.    18.    15.     6.]
  [  984.   131.    59.    25.     3.     9.    10.     5.]
  [  673.   123.    31.     8.     9.     2.     4.     1.]
  [  109.     0.     6.     7.     8.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7971453
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 5664, frames: 80063, time: 25498.154055833817
training steps:  9456
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5664 : 0.0
LR:  0.001
replay buffer size:  82519
Time Taken :  424.0  mins 58.153897762298584  seconds
[[[20319.  9893.  3331.  1042.   176.    31.     9.     0.]
  [13213.  3482.   532.   482.   116.    59.    15.     4.]
  [ 8188.  1769.   716.   528.   148.    57.    14.     5.]
  [ 3804.   687.   240.   203.    77.    46.    11.     5.]
  [ 1884.   234.   141.    91.    38.    19.    15.     6.]
  [ 1278.   155.    75.    30.     3.     9.    10.     5.]
  [  828.   147.    41.    10.     9.     2.     4.     1.]
  [  139.     0.     8.     7.     8.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.78820246
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 6359, frames: 90035, time: 28744.699991941452
training steps:  10824
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6359 : 0.0
LR:  0.001
replay buffer size:  92749
Time Taken :  479.0  mins 4.69983983039856  seconds
[[[22403. 10907.  3732.  1173.   190.    38.    10.     0.]
  [14646.  3845.   605.   570.   135.    68.    16.     4.]
  [ 9275.  2025.   891.   629.   166.    65.    18.     5.]
  [ 4495.   787.   326.   250.    86.    52.    14.     5.]
  [ 2233.   276.   189.   111.    45.    22.    16.     6.]
  [ 1557.   182.   110.    37.     3.     9.    10.     5.]
  [  987.   168.    49.    13.     9.     2.     4.     1.]
  [  172.     0.    11.    10.     8.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7881175
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 7102, frames: 100044, time: 31945.346314907074
training steps:  12180
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7102 : 0.0
LR:  0.001
replay buffer size:  102960
Time Taken :  532.0  mins 25.34615397453308  seconds
[[[24315. 11941.  4140.  1335.   218.    43.    11.     0.]
  [16068.  4201.   705.   667.   162.    78.    18.     4.]
  [10412.  2336.  1081.   740.   200.    75.    21.     5.]
  [ 5174.   898.   406.   290.   106.    64.    14.     6.]
  [ 2588.   316.   247.   126.    52.    34.    18.     9.]
  [ 1746.   216.   156.    52.     4.    18.    12.     6.]
  [ 1078.   188.    61.    16.    13.    10.     4.     2.]
  [  197.     0.    13.    10.    10.     5.     1.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7767018
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 7770, frames: 110090, time: 34907.288561820984
training steps:  13515
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7770 : 0.0
LR:  0.001
replay buffer size:  113253
Time Taken :  581.0  mins 47.28839659690857  seconds
[[[26136. 12879.  4522.  1520.   245.    64.    14.     6.]
  [17389.  4504.   793.   820.   197.    97.    22.    11.]
  [11554.  2684.  1346.   905.   229.    89.    25.    11.]
  [ 5866.  1006.   544.   381.   121.    75.    19.     7.]
  [ 2968.   361.   333.   173.    63.    40.    21.    10.]
  [ 1939.   245.   220.    73.     5.    19.    12.     7.]
  [ 1161.   199.    83.    24.    13.    10.     4.     3.]
  [  207.     0.    20.    10.    10.     5.     1.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.78460234
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 8420, frames: 120145, time: 37251.99108982086
training steps:  14804
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8420 : 0.0
LR:  0.001
replay buffer size:  123581
Time Taken :  620.0  mins 51.990933895111084  seconds
[[[27916. 13741.  4916.  1718.   275.    85.    17.    11.]
  [18640.  4804.   882.   987.   221.   123.    32.    21.]
  [12798.  3056.  1619.  1101.   264.   109.    30.    15.]
  [ 6590.  1108.   692.   476.   142.    91.    22.    14.]
  [ 3246.   392.   473.   217.    69.    49.    27.    15.]
  [ 2071.   274.   312.    97.     9.    28.    12.     9.]
  [ 1209.   211.   113.    33.    27.    16.     4.     3.]
  [  218.     0.    27.    13.    15.    16.     4.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7833011
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 9082, frames: 130078, time: 39130.3812148571
training steps:  16019
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9082 : 0.0
LR:  0.001
replay buffer size:  133719
Time Taken :  652.0  mins 10.381050825119019  seconds
[[[29770. 14642.  5263.  1881.   302.   151.    22.    11.]
  [19988.  5131.   964.  1106.   244.   138.    34.    21.]
  [14033.  3435.  1916.  1267.   297.   126.    36.    18.]
  [ 7235.  1214.   868.   560.   161.   101.    28.    21.]
  [ 3496.   418.   606.   251.    72.    51.    31.    19.]
  [ 2163.   309.   420.   123.     9.    29.    12.     9.]
  [ 1232.   221.   144.    38.    30.    17.     4.     3.]
  [  222.     0.    32.    14.    17.    16.     4.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7883232
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 9727, frames: 140100, time: 41033.06994700432
training steps:  17246
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9727 : 0.0
LR:  0.001
replay buffer size:  143960
Time Taken :  683.0  mins 53.0697808265686  seconds
[[[31779. 15537.  5652.  2077.   331.   182.    23.    11.]
  [21355.  5440.  1060.  1244.   258.   153.    34.    21.]
  [15200.  3820.  2193.  1431.   332.   138.    37.    18.]
  [ 7855.  1315.  1027.   648.   178.   110.    29.    21.]
  [ 3687.   446.   751.   288.    74.    59.    33.    21.]
  [ 2243.   337.   522.   144.    17.    42.    12.    10.]
  [ 1271.   232.   188.    57.    48.    32.     5.     4.]
  [  230.     0.    40.    17.    24.    22.     8.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7948353
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 10369, frames: 150077, time: 42868.542540073395
training steps:  18449
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10369 : 0.0
LR:  0.001
replay buffer size:  154122
Time Taken :  714.0  mins 28.542380571365356  seconds
[[[33565. 16401.  6012.  2276.   353.   226.    26.    11.]
  [22807.  5768.  1140.  1385.   277.   175.    40.    22.]
  [16520.  4297.  2532.  1601.   352.   156.    42.    19.]
  [ 8450.  1440.  1221.   724.   187.   117.    34.    22.]
  [ 3863.   470.   871.   317.    76.    64.    42.    25.]
  [ 2302.   358.   619.   160.    17.    45.    15.    11.]
  [ 1284.   242.   224.    60.    49.    35.     5.     5.]
  [  230.     0.    45.    20.    25.    23.     8.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.80005264
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 10986, frames: 160036, time: 44710.33363986015
training steps:  19657
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10986 : 0.0
LR:  0.001
replay buffer size:  164337
Time Taken :  745.0  mins 10.333479881286621  seconds
[[[35385. 17173.  6346.  2406.   370.   230.    27.    15.]
  [24391.  6085.  1226.  1483.   285.   182.    43.    26.]
  [17963.  4801.  2861.  1715.   366.   160.    44.    20.]
  [ 9145.  1538.  1393.   786.   195.   118.    34.    22.]
  [ 4025.   498.  1009.   340.    79.    65.    42.    25.]
  [ 2371.   381.   734.   178.    18.    47.    15.    11.]
  [ 1302.   255.   286.    72.    52.    37.     6.     5.]
  [  232.     0.    51.    20.    28.    24.     8.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8073254
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 11599, frames: 170088, time: 46570.97491979599
training steps:  20875
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
11599 : 0.0
LR:  0.001
replay buffer size:  174612
Time Taken :  776.0  mins 10.974758863449097  seconds
[[[37131. 17966.  6642.  2557.   394.   271.    30.    15.]
  [25997.  6408.  1297.  1584.   299.   194.    43.    26.]
  [19405.  5408.  3230.  1844.   383.   169.    45.    20.]
  [ 9842.  1661.  1536.   838.   209.   123.    37.    22.]
  [ 4286.   525.  1088.   358.    83.    71.    44.    25.]
  [ 2441.   398.   797.   184.    20.    53.    15.    11.]
  [ 1315.   261.   321.    78.    53.    42.     6.     5.]
  [  235.     0.    56.    23.    31.    30.     8.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7948454
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 12188, frames: 180086, time: 48027.133425951004
training steps:  22012
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
12188 : 0.0
LR:  0.001
replay buffer size:  184815
Time Taken :  800.0  mins 27.133254766464233  seconds
[[[38956. 18710.  6954.  2679.   416.   273.    30.    15.]
  [27621.  6713.  1360.  1646.   319.   207.    46.    26.]
  [20909.  5935.  3535.  1940.   410.   186.    50.    20.]
  [10672.  1789.  1640.   873.   215.   132.    42.    24.]
  [ 4578.   552.  1165.   373.    86.    78.    46.    26.]
  [ 2524.   413.   863.   194.    21.    57.    17.    11.]
  [ 1342.   263.   351.    83.    56.    45.     7.     5.]
  [  238.     0.    60.    23.    34.    35.     9.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8006406
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 12740, frames: 190104, time: 49348.13998007774
training steps:  23119
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
12740 : 0.0
LR:  0.001
replay buffer size:  195108
Time Taken :  822.0  mins 28.139811754226685  seconds
[[[40774. 19461.  7271.  2789.   431.   275.    32.    21.]
  [29425.  7005.  1432.  1727.   330.   210.    46.    28.]
  [22602.  6496.  3808.  2023.   422.   189.    50.    21.]
  [11486.  1902.  1705.   900.   223.   136.    43.    25.]
  [ 4831.   581.  1218.   384.    86.    82.    49.    29.]
  [ 2567.   429.   911.   198.    21.    60.    19.    12.]
  [ 1351.   266.   371.    86.    58.    47.     7.     5.]
  [  238.     0.    61.    23.    39.    38.     9.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8218982
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 13307, frames: 200065, time: 50439.867394924164
training steps:  24172
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
13307 : 0.0
LR:  0.001
replay buffer size:  200054
Time Taken :  840.0  mins 39.86722183227539  seconds
[[[42709. 20240.  7579.  2904.   444.   286.    35.    21.]
  [31153.  7305.  1506.  1803.   347.   224.    47.    28.]
  [24239.  7122.  4090.  2112.   435.   193.    52.    23.]
  [12204.  2041.  1761.   912.   227.   139.    46.    26.]
  [ 5064.   597.  1246.   388.    86.    86.    54.    29.]
  [ 2643.   437.   923.   198.    21.    64.    21.    12.]
  [ 1373.   270.   375.    87.    59.    49.     7.     5.]
  [  240.     0.    62.    23.    39.    38.     9.     0.]]]
