EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.020724489780453343
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 95, frames: 1220, time: 38.13395094871521
training steps:  10
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
95 : 0.0
LR:  9e-06
replay buffer size:  1619
Time Taken :  0.0  mins 38.13375687599182  seconds
[[[339. 163.  73.  16.   5.   3.   0.   0.]
  [148.  57.  21.   8.   7.   3.   0.   0.]
  [ 91.  26.  15.  17.  14.   9.   0.   0.]
  [ 36.   8.   5.  13.   2.   0.   0.   0.]
  [ 23.   1.   2.   4.   1.   0.   0.   0.]
  [ 10.   2.   0.   0.   0.   0.   0.   0.]
  [  3.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7352445
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 838, frames: 10068, time: 2781.833041906357
training steps:  1246
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
838 : 0.0
LR:  0.001
replay buffer size:  10750
Time Taken :  46.0  mins 21.832870960235596  seconds
[[[2909. 1551.  540.  187.   45.    3.    0.    0.]
  [1348.  519.  137.   77.   21.    4.    0.    0.]
  [ 595.  166.  103.   78.   25.   12.    2.    0.]
  [ 327.   70.   42.   44.   12.    0.    0.    0.]
  [ 161.   25.   25.   14.    6.    0.    0.    0.]
  [  95.   23.    7.    2.    0.    0.    0.    0.]
  [  46.    3.    0.    0.    0.    0.    0.    0.]
  [   6.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7273421
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1635, frames: 20111, time: 6617.33987402916
training steps:  2490
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1635 : 0.0
LR:  0.001
replay buffer size:  21073
Time Taken :  110.0  mins 17.339751958847046  seconds
[[[5371. 2830.  999.  371.   81.    3.    1.    1.]
  [2886.  957.  252.  173.   56.   13.    9.    6.]
  [1472.  339.  195.  173.   55.   15.    5.    1.]
  [ 801.  175.   83.   92.   32.    2.    0.    0.]
  [ 433.   69.   49.   29.   10.    0.    0.    0.]
  [ 231.   52.   24.    5.    0.    0.    0.    0.]
  [  93.   13.    4.    0.    0.    0.    0.    0.]
  [  13.    0.    2.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.76563233
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2281, frames: 30083, time: 10032.934441804886
training steps:  3704
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2281 : 0.0
LR:  0.001
replay buffer size:  31313
Time Taken :  167.0  mins 12.934255838394165  seconds
[[[8052. 4097. 1466.  538.  107.    7.    5.    1.]
  [4642. 1355.  338.  274.   96.   31.   14.    6.]
  [2279.  503.  310.  276.   95.   26.    8.    1.]
  [1156.  237.  130.  155.   53.   13.    3.    0.]
  [ 612.   92.   84.   55.   16.    2.    3.    2.]
  [ 333.   68.   42.    8.    0.    2.    2.    3.]
  [ 151.   21.    8.    0.    0.    0.    0.    0.]
  [  19.    0.    5.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.76362425
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2935, frames: 40073, time: 12822.165611982346
training steps:  4710
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2935 : 0.0
LR:  0.001
replay buffer size:  41556
Time Taken :  213.0  mins 42.16542291641235  seconds
[[[10602.  5241.  1951.   692.   132.     7.     6.     1.]
  [ 6606.  1763.   426.   339.   111.    35.    15.     6.]
  [ 3241.   707.   402.   352.   112.    28.    11.     1.]
  [ 1575.   307.   150.   182.    59.    15.    10.     7.]
  [  804.   111.    97.    61.    17.     5.    15.     7.]
  [  453.    77.    52.    12.     0.     3.     6.     7.]
  [  237.    34.    10.     1.     0.     0.     1.     0.]
  [   31.     0.     5.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7845906
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3630, frames: 50064, time: 16584.384012937546
training steps:  6127
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3630 : 0.0
LR:  0.001
replay buffer size:  51740
Time Taken :  276.0  mins 24.38382387161255  seconds
[[[13152.  6489.  2389.   852.   156.     9.     8.     1.]
  [ 8564.  2215.   504.   400.   125.    43.    17.     6.]
  [ 4217.   893.   493.   413.   130.    35.    12.     1.]
  [ 1924.   376.   192.   215.    69.    22.    12.     8.]
  [  942.   133.   133.    71.    22.     6.    15.     7.]
  [  546.    84.    73.    21.     0.     3.     6.     7.]
  [  298.    43.    25.     4.     0.     0.     1.     0.]
  [   44.     0.     8.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7784204
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4311, frames: 60097, time: 20141.00570011139
training steps:  7462
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4311 : 0.0
LR:  0.001
replay buffer size:  62081
Time Taken :  335.0  mins 41.00551700592041  seconds
[[[15520.  7623.  2881.  1060.   187.    22.    11.     2.]
  [10354.  2628.   585.   505.   153.    61.    24.    14.]
  [ 5273.  1143.   641.   513.   154.    39.    13.     5.]
  [ 2338.   446.   234.   238.    76.    23.    13.    12.]
  [ 1101.   152.   169.    85.    24.     7.    16.     8.]
  [  634.    99.   100.    25.     0.     4.     6.     7.]
  [  363.    63.    37.    11.     4.     2.     1.     0.]
  [   63.     0.    11.     1.     2.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7592476
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.00199960002
rdn probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Episodes: 5004, frames: 70094, time: 22349.93311405182
training steps:  8229
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5004 : 0.0
LR:  0.001
replay buffer size:  72456
Time Taken :  372.0  mins 29.932925939559937  seconds
[[[17679.  8702.  3290.  1231.   216.    30.    13.     5.]
  [11965.  3010.   673.   622.   189.    76.    29.    20.]
  [ 6356.  1385.   781.   641.   192.    53.    18.     6.]
  [ 2843.   525.   275.   282.    90.    31.    13.    12.]
  [ 1333.   177.   218.   116.    29.    11.    17.     8.]
  [  820.   115.   132.    30.     0.     8.     7.     7.]
  [  510.    90.    58.    18.     6.     5.     1.     0.]
  [   85.     0.    17.     6.     8.     2.     2.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8513252
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.00199960002
rdn probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Episodes: 5697, frames: 80083, time: 26035.46029996872
training steps:  9669
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5697 : 0.0
LR:  0.001
replay buffer size:  82826
Time Taken :  433.0  mins 55.460110902786255  seconds
[[[19653.  9695.  3680.  1403.   244.    55.    21.     9.]
  [13546.  3358.   743.   770.   245.   127.    48.    36.]
  [ 7362.  1682.   998.   812.   237.    78.    27.    16.]
  [ 3397.   621.   317.   321.   107.    46.    20.    17.]
  [ 1576.   200.   254.   135.    37.    20.    24.     9.]
  [  977.   143.   160.    38.     4.    14.    12.     9.]
  [  659.   119.    86.    26.    10.     8.     3.     0.]
  [  116.     0.    22.    14.    13.     4.     2.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7767691
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 6424, frames: 90072, time: 29304.229859113693
training steps:  11054
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6424 : 0.0
LR:  0.001
replay buffer size:  93091
Time Taken :  488.0  mins 24.22967505455017  seconds
[[[21801. 10681.  4103.  1586.   274.    68.    22.     9.]
  [15029.  3704.   834.   871.   268.   141.    50.    40.]
  [ 8337.  1923.  1134.   934.   263.    88.    28.    18.]
  [ 3974.   712.   355.   357.   120.    52.    28.    22.]
  [ 1946.   238.   285.   154.    41.    22.    26.    13.]
  [ 1246.   172.   181.    45.     5.    15.    12.     9.]
  [  881.   155.    99.    28.    11.     9.     4.     0.]
  [  162.     0.    28.    15.    13.     4.     2.     1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  1
maxi score:  0.0001
siam score:  -0.7614833
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 7158, frames: 100097, time: 32556.838641881943
training steps:  12430
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7158 : 0.0
LR:  0.001
replay buffer size:  103376
Time Taken :  542.0  mins 36.83844995498657  seconds
[[[23757. 11596.  4473.  1720.   298.    68.    22.    14.]
  [16398.  4025.   902.   947.   279.   147.    54.    52.]
  [ 9292.  2089.  1236.  1020.   280.    96.    31.    29.]
  [ 4635.   805.   415.   403.   131.    55.    31.    28.]
  [ 2389.   272.   341.   175.    46.    22.    28.    16.]
  [ 1678.   200.   227.    52.     8.    17.    14.    12.]
  [ 1311.   203.   145.    46.    19.    11.     5.     1.]
  [  255.     0.    36.    30.    27.    16.     8.     1.]]]
Test reward:  0.4
Q value #end_state_>_threshold:  8
Q value #non_end_state_>threshold:  5
maxi score:  0.0161
siam score:  -0.86624914
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0021, '2.0': 0.0081}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.00774447368
rdn probs:  [0.07411775632393394, 0.07411775632393394, 0.07411775632393394, 0.07411775632393394, 0.18517644873521322, 0.5183525259690511]
Episodes: 7874, frames: 110082, time: 35398.6583108902
training steps:  13765
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7874 : 0.0
LR:  0.001
replay buffer size:  113765
Time Taken :  589.0  mins 58.65811777114868  seconds
[[[25487. 12446.  4798.  1885.   325.    72.    25.    16.]
  [17686.  4327.   954.  1070.   306.   161.    63.    69.]
  [10218.  2266.  1354.  1158.   310.   101.    34.    38.]
  [ 5269.   892.   494.   480.   147.    61.    35.    32.]
  [ 2868.   306.   431.   209.    46.    22.    28.    17.]
  [ 2128.   238.   310.    60.     8.    18.    15.    14.]
  [ 1735.   244.   203.    72.    32.    16.     7.     1.]
  [  348.     0.    57.    78.    60.    35.    17.     6.]]]
Test reward:  0.3
Q value #end_state_>_threshold:  171
Q value #non_end_state_>threshold:  424
maxi score:  0.0381
siam score:  -0.9028523
Scores:  {'0.333': 0.0021, '0.667': 0.0121, '1.0': 0.0121, '1.333': 0.0001, '1.667': 0.022099999999999998, '2.0': 0.040100000000000004}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.0144
rdn probs:  [0.06776376017051554, 0.14584500214116117, 0.14584500214116114, 0.052147511776386414, 0.22392624411180675, 0.3644724796589689]
Episodes: 8422, frames: 120266, time: 36949.18539595604
training steps:  14511
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8422 : 0.1
LR:  0.001
replay buffer size:  124262
Time Taken :  615.0  mins 49.18523597717285  seconds
[[[26776. 13066.  5118.  2124.   339.    74.    26.    17.]
  [18521.  4472.   998.  1267.   341.   174.    72.    85.]
  [10932.  2458.  1515.  1380.   345.   106.    38.    50.]
  [ 5744.   957.   662.   679.   179.    66.    37.    39.]
  [ 3169.   338.   683.   312.    53.    26.    29.    20.]
  [ 2322.   265.   559.    84.    19.    25.    17.    16.]
  [ 1911.   291.   467.   283.   130.    58.    19.     2.]
  [  375.     0.   110.   552.   482.   340.   179.    51.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  797
Q value #non_end_state_>threshold:  1929
maxi score:  0.1181
siam score:  -0.9074419
Scores:  {'0.333': 0.0121, '0.667': 0.0301, '1.0': 0.034100000000000005, '1.333': 0.018099999999999998, '1.667': 0.0901, '2.0': 0.10010000000000001}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.048999999999999995
rdn probs:  [0.048978402422552865, 0.10893280118842216, 0.1222560009141709, 0.06896320201117595, 0.30878079707465306, 0.34208879638902495]
Episodes: 8869, frames: 130042, time: 38260.54281592369
training steps:  15265
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8869 : 0.45
LR:  0.001
replay buffer size:  134441
Time Taken :  637.0  mins 40.542617082595825  seconds
[[[27478. 13577.  5517.  2462.   357.    83.    27.    26.]
  [18942.  4526.  1026.  1568.   375.   196.    81.   100.]
  [11221.  2588.  1650.  1703.   403.   121.    43.    67.]
  [ 5876.   984.   955.   983.   219.    84.    44.    49.]
  [ 3244.   360.  1055.   423.    64.    37.    32.    22.]
  [ 2376.   287.   966.   121.    45.    45.    21.    17.]
  [ 1954.   310.   851.   590.   277.   139.    46.     2.]
  [  381.     0.   160.  1183.  1031.   890.   743.   170.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1847
Q value #non_end_state_>threshold:  4436
maxi score:  0.2161
siam score:  -0.8873297
Scores:  {'0.333': 0.0641, '0.667': 0.0781, '1.0': 0.10010000000000001, '1.333': 0.0901, '1.667': 0.1661, '2.0': 0.14209999999999998}
best rdn ma / adv:  1.667 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 9348, frames: 140075, time: 40232.58724284172
training steps:  16537
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9348 : 0.6
LR:  0.001
replay buffer size:  144876
Time Taken :  670.0  mins 32.587064027786255  seconds
[[[27936. 14146.  6031.  2889.   379.    84.    30.    26.]
  [19164.  4580.  1063.  1946.   394.   204.    86.   107.]
  [11391.  2662.  1749.  2099.   432.   128.    45.    71.]
  [ 5933.   997.  1260.  1358.   251.    89.    47.    51.]
  [ 3273.   376.  1471.   579.    75.    41.    36.    23.]
  [ 2399.   305.  1387.   145.    65.    70.    24.    17.]
  [ 1968.   320.  1281.   983.   456.   226.    74.     2.]
  [  384.     0.   188.  1797.  1780.  1564.  1412.   378.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  3044
Q value #non_end_state_>threshold:  7454
maxi score:  0.35409999999999997
siam score:  -0.85623556
Scores:  {'0.333': 0.1121, '0.667': 0.1601, '1.0': 0.17609999999999998, '1.333': 0.1541, '1.667': 0.2021, '2.0': 0.17809999999999998}
best rdn ma / adv:  1.667 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 9777, frames: 150096, time: 42188.937355041504
training steps:  17800
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9777 : 0.6
LR:  0.001
replay buffer size:  155349
Time Taken :  703.0  mins 8.937158823013306  seconds
[[[28352. 14718.  6537.  3327.   393.    87.    30.    30.]
  [19281.  4602.  1091.  2320.   410.   216.    88.   109.]
  [11475.  2714.  1841.  2482.   469.   139.    46.    71.]
  [ 5946.  1010.  1550.  1754.   299.   104.    49.    51.]
  [ 3281.   385.  1895.   750.    84.    51.    36.    23.]
  [ 2402.   319.  1833.   177.    90.    92.    24.    17.]
  [ 1968.   326.  1757.  1460.   648.   324.    94.     2.]
  [  384.     0.   227.  2470.  2457.  2313.  2241.   598.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  4144
Q value #non_end_state_>threshold:  10795
maxi score:  0.4561
siam score:  -0.8299708
Scores:  {'0.333': 0.1601, '0.667': 0.2241, '1.0': 0.21409999999999998, '1.333': 0.20609999999999998, '1.667': 0.24209999999999998, '2.0': 0.23609999999999998}
best rdn ma / adv:  1.667 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 10176, frames: 160176, time: 44178.669056892395
training steps:  19075
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10176 : 0.55
LR:  0.001
replay buffer size:  166577
Time Taken :  736.0  mins 18.668860912322998  seconds
[[[28700. 15237.  7037.  3770.   402.    87.    30.    30.]
  [19362.  4624.  1114.  2720.   431.   216.    88.   109.]
  [11524.  2751.  1920.  2850.   500.   139.    46.    71.]
  [ 5955.  1021.  1864.  2115.   340.   107.    50.    51.]
  [ 3283.   397.  2320.   890.    90.    54.    39.    23.]
  [ 2402.   333.  2308.   199.   114.   108.    25.    17.]
  [ 1968.   338.  2351.  1961.   890.   444.   123.     2.]
  [  384.     0.   259.  3314.  3221.  3082.  2997.   803.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  5050
Q value #non_end_state_>threshold:  14299
maxi score:  0.5601
siam score:  -0.80987895
Scores:  {'0.333': 0.20609999999999998, '0.667': 0.2741, '1.0': 0.2521, '1.333': 0.24409999999999998, '1.667': 0.2801, '2.0': 0.2541}
best rdn ma / adv:  1.667 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 10533, frames: 170021, time: 46085.317080020905
training steps:  20316
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10533 : 0.55
LR:  0.001
replay buffer size:  176765
Time Taken :  768.0  mins 5.316885948181152  seconds
[[[29047. 15728.  7463.  4154.   414.    87.    30.    30.]
  [19488.  4647.  1134.  3047.   451.   218.    88.   109.]
  [11606.  2809.  2027.  3170.   531.   140.    46.    71.]
  [ 5965.  1028.  2179.  2418.   382.   113.    51.    51.]
  [ 3287.   410.  2765.  1011.    95.    62.    41.    23.]
  [ 2404.   345.  2844.   223.   137.   131.    26.    17.]
  [ 1968.   352.  3075.  2610.  1125.   564.   137.     2.]
  [  384.     0.   301.  4241.  3923.  3715.  3576.   972.]]]
