EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.0010349879714498377
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 77, frames: 901, time: 30.56360697746277
training steps:  5
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
77 : 0.0
LR:  4e-06
replay buffer size:  1247
Time Taken :  0.0  mins 30.56342911720276  seconds
[[[300. 119.  32.   4.   2.   0.   0.   0.]
  [160.  50.   9.   4.   0.   0.   0.   0.]
  [ 59.  12.   2.   0.   0.   0.   0.   0.]
  [ 31.  12.   0.   0.   0.   0.   0.   0.]
  [ 10.   1.   0.   0.   0.   0.   0.   0.]
  [ 12.   2.   0.   0.   0.   0.   0.   0.]
  [  2.   1.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.71094465
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 837, frames: 10071, time: 2788.166155099869
training steps:  1235
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
837 : 0.0
LR:  0.001
replay buffer size:  10667
Time Taken :  46.0  mins 28.166007041931152  seconds
[[[2568.  913.  269.   75.   12.    0.    0.    0.]
  [1753.  457.   77.   49.    5.    0.    0.    0.]
  [ 986.  182.   68.   29.    7.    0.    0.    0.]
  [ 577.  127.   43.   30.    7.    1.    0.    0.]
  [ 357.   54.   23.   13.    6.    0.    0.    0.]
  [ 266.   37.    8.    4.    0.    0.    0.    0.]
  [ 166.   22.    2.    0.    0.    0.    0.    0.]
  [  41.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7311156
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1651, frames: 20075, time: 6662.300358057022
training steps:  2496
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1651 : 0.0
LR:  0.001
replay buffer size:  20958
Time Taken :  111.0  mins 2.3001859188079834  seconds
[[[4718. 1777.  464.  151.   24.    4.    1.    0.]
  [3165.  842.  135.  100.   13.    3.    0.    0.]
  [2062.  395.  156.   96.   19.    4.    1.    0.]
  [1300.  268.  102.   81.   16.    3.    0.    0.]
  [ 807.  103.   78.   56.   11.    0.    0.    0.]
  [ 684.   80.   47.   17.    0.    0.    0.    0.]
  [ 444.   65.   18.    5.    0.    0.    0.    0.]
  [  98.    0.    6.    4.    1.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.71747816
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2451, frames: 30086, time: 10005.292757987976
training steps:  3669
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2451 : 0.0
LR:  0.001
replay buffer size:  31152
Time Taken :  166.0  mins 45.29258489608765  seconds
[[[6776. 2554.  698.  243.   37.    9.    1.    0.]
  [4666. 1233.  207.  150.   20.    5.    0.    0.]
  [3181.  604.  226.  151.   32.    9.    1.    0.]
  [2088.  390.  152.  129.   32.   11.    0.    0.]
  [1328.  162.  130.   85.   17.    2.    0.    0.]
  [1092.  122.   84.   27.    1.    0.    0.    0.]
  [ 685.   90.   29.    6.    1.    0.    0.    0.]
  [ 156.    0.    8.    4.    1.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.73298323
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3238, frames: 40087, time: 13094.864995002747
training steps:  4789
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3238 : 0.0
LR:  0.001
replay buffer size:  41370
Time Taken :  218.0  mins 14.864856958389282  seconds
[[[8791. 3322.  928.  336.   47.   10.    1.    0.]
  [6169. 1614.  293.  212.   30.   11.    0.    0.]
  [4217.  815.  321.  209.   53.   21.    3.    0.]
  [2792.  493.  221.  171.   47.   21.    1.    0.]
  [1848.  218.  199.  117.   22.    5.    0.    0.]
  [1558.  165.  122.   36.    1.    0.    0.    0.]
  [ 969.  126.   55.   18.    3.    0.    0.    0.]
  [ 204.    0.   16.   14.    4.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7463641
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4023, frames: 50062, time: 16524.766902923584
training steps:  6062
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4023 : 0.0
LR:  0.001
replay buffer size:  51606
Time Taken :  275.0  mins 24.766735792160034  seconds
[[[10672.  4125.  1197.   443.    59.    10.     1.     0.]
  [ 7513.  1984.   346.   291.    46.    13.     0.     0.]
  [ 5182.   992.   398.   278.    88.    27.     4.     0.]
  [ 3492.   591.   303.   225.    71.    27.     3.     0.]
  [ 2400.   259.   288.   154.    28.     5.     0.     0.]
  [ 2106.   219.   209.    60.     1.     0.     0.     0.]
  [ 1301.   174.   101.    26.     5.     1.     0.     0.]
  [  275.     0.    23.    18.     5.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.74463254
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4798, frames: 60061, time: 20259.85088992119
training steps:  7467
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4798 : 0.0
LR:  0.001
replay buffer size:  61855
Time Taken :  337.0  mins 39.85072207450867  seconds
[[[12551.  4946.  1437.   521.    71.    10.     1.     0.]
  [ 8979.  2332.   402.   331.    60.    18.     0.     0.]
  [ 6176.  1178.   468.   327.    99.    37.     5.     0.]
  [ 4197.   688.   354.   271.    78.    34.     4.     0.]
  [ 2967.   303.   356.   183.    30.    11.     0.     0.]
  [ 2637.   276.   286.    70.     7.     4.     1.     0.]
  [ 1696.   219.   131.    35.     9.     1.     0.     0.]
  [  370.     0.    30.    38.    24.     3.     1.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.74782825
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 5559, frames: 70095, time: 22827.040809869766
training steps:  8375
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5559 : 0.0
LR:  0.001
replay buffer size:  72116
Time Taken :  380.0  mins 27.04063892364502  seconds
[[[14324.  5785.  1728.   605.    87.    14.     1.     0.]
  [10298.  2655.   460.   385.    70.    26.     1.     0.]
  [ 7165.  1345.   567.   392.   124.    50.     7.     0.]
  [ 4976.   784.   426.   327.   102.    41.     7.     0.]
  [ 3623.   356.   438.   205.    34.    12.     0.     0.]
  [ 3206.   329.   351.    84.    10.     4.     1.     0.]
  [ 2044.   270.   165.    48.    17.     2.     0.     0.]
  [  447.     0.    44.    56.    34.     3.     1.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.76169324
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 6293, frames: 80055, time: 25892.162045240402
training steps:  9551
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6293 : 0.0
LR:  0.001
replay buffer size:  82298
Time Taken :  431.0  mins 32.16187906265259  seconds
[[[16200.  6608.  1972.   711.   101.    20.     2.     0.]
  [11574.  2974.   505.   442.    81.    34.     2.     0.]
  [ 8081.  1536.   683.   482.   143.    56.     9.     0.]
  [ 5661.   863.   514.   395.   114.    44.     7.     0.]
  [ 4243.   405.   555.   257.    42.    14.     0.     0.]
  [ 3772.   388.   436.   109.    12.     5.     1.     0.]
  [ 2404.   318.   201.    64.    24.     3.     1.     0.]
  [  521.     0.    54.    70.    41.     5.     3.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.76253325
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 7043, frames: 90044, time: 29236.455310106277
training steps:  10956
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7043 : 0.0
LR:  0.001
replay buffer size:  92499
Time Taken :  487.0  mins 16.45514178276062  seconds
[[[17952.  7405.  2288.   854.   117.    27.     4.     0.]
  [12809.  3299.   575.   543.   107.    48.     5.     1.]
  [ 8926.  1696.   766.   584.   177.    64.    10.     0.]
  [ 6250.   936.   588.   478.   143.    59.     8.     0.]
  [ 4869.   451.   681.   311.    50.    20.     1.     0.]
  [ 4349.   445.   546.   126.    24.    16.     1.     0.]
  [ 2785.   370.   271.    90.    43.    14.     3.     0.]
  [  588.     0.    68.    92.    53.    11.     4.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.76724076
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 7776, frames: 100076, time: 32567.9766561985
training steps:  12351
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7776 : 0.0
LR:  0.001
replay buffer size:  102810
Time Taken :  542.0  mins 47.976481914520264  seconds
[[[19869.  8190.  2570.   975.   132.    31.     4.     0.]
  [14079.  3614.   639.   633.   129.    52.     5.     1.]
  [ 9738.  1894.   879.   703.   205.    71.    12.     0.]
  [ 6777.  1020.   678.   578.   169.    69.     9.     0.]
  [ 5402.   503.   819.   383.    60.    26.     3.     0.]
  [ 4913.   501.   669.   147.    40.    25.     4.     0.]
  [ 3148.   419.   341.   124.    67.    21.     6.     0.]
  [  639.     0.    79.   119.    76.    31.    10.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7739328
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 8541, frames: 110121, time: 35454.990220069885
training steps:  13698
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8541 : 0.0
LR:  0.001
replay buffer size:  113102
Time Taken :  590.0  mins 54.99004888534546  seconds
[[[21641.  9036.  2897.  1139.   154.    33.     5.     0.]
  [15173.  3958.   715.   739.   148.    59.     7.     1.]
  [10457.  2091.  1018.   840.   236.    77.    13.     0.]
  [ 7282.  1107.   790.   713.   210.    84.    11.     0.]
  [ 5890.   554.   998.   475.    74.    38.    10.     1.]
  [ 5388.   548.   842.   173.    62.    51.    16.     1.]
  [ 3442.   467.   451.   187.   108.    34.     9.     0.]
  [  675.     0.    88.   202.   104.    45.    13.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.74785835
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0041, '2.0': 0.0001}
best rdn ma / adv:  1.667 1.667
best rdn adv:  0.00399920004
rdn probs:  [0.08337165004067143, 0.08337165004067143, 0.08337165004067143, 0.08337165004067143, 0.5831417497966427, 0.08337165004067143]
Episodes: 9201, frames: 120062, time: 37747.766067266464
training steps:  15005
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9201 : 0.0
LR:  0.001
replay buffer size:  123588
Time Taken :  629.0  mins 7.765933990478516  seconds
[[[23130.  9795.  3230.  1316.   178.    51.     9.     0.]
  [16092.  4200.   776.   864.   167.    76.    11.     1.]
  [11096.  2287.  1169.  1027.   284.    98.    15.     0.]
  [ 7692.  1174.   944.   921.   283.   122.    21.     0.]
  [ 6337.   606.  1271.   616.    93.    70.    19.     2.]
  [ 5899.   614.  1079.   205.   113.   102.    29.     2.]
  [ 3724.   511.   604.   312.   213.    78.    13.     0.]
  [  701.     0.   103.   293.   139.    62.    20.     2.]]]
Test reward:  0.25
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  6
maxi score:  0.0101
siam score:  -0.7532812
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0121, '2.0': 0.0001}
best rdn ma / adv:  1.667 1.667
best rdn adv:  0.01175882412
rdn probs:  [0.08336835279446767, 0.08336835279446767, 0.08336835279446767, 0.08336835279446767, 0.5831582360276618, 0.08336835279446767]
Episodes: 9882, frames: 130155, time: 39185.674438238144
training steps:  15829
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9882 : 0.0
LR:  0.001
replay buffer size:  134065
Time Taken :  653.0  mins 5.67427396774292  seconds
[[[24609. 10511.  3551.  1524.   191.    52.     9.     0.]
  [17067.  4462.   832.  1035.   192.    81.    11.     1.]
  [11833.  2518.  1331.  1222.   309.   100.    16.     0.]
  [ 8164.  1247.  1081.  1100.   317.   129.    23.     1.]
  [ 6810.   649.  1576.   761.   109.    78.    23.     7.]
  [ 6349.   679.  1380.   251.   148.   120.    32.     2.]
  [ 3930.   563.   817.   470.   314.   103.    14.     0.]
  [  725.     0.   127.   429.   180.    71.    30.     7.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  234
Q value #non_end_state_>threshold:  183
maxi score:  0.0301
siam score:  -0.9296238
Scores:  {'0.333': 0.0001, '0.667': 0.0041, '1.0': 0.0121, '1.333': 0.0101, '1.667': 0.08410000000000001, '2.0': 0.0041}
best rdn ma / adv:  1.667 1.667
best rdn adv:  0.04725
rdn probs:  [0.07075166311007101, 0.09094429543777535, 0.13132956009318406, 0.12123324392933188, 0.49479694199186225, 0.09094429543777535]
Episodes: 10502, frames: 140100, time: 40481.78837394714
training steps:  16552
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10502 : 0.25
LR:  0.001
replay buffer size:  144389
Time Taken :  674.0  mins 41.788196086883545  seconds
[[[25806. 11204.  3911.  1766.   210.    52.     9.     0.]
  [17801.  4660.   885.  1243.   213.    81.    11.     1.]
  [12385.  2735.  1524.  1485.   351.   101.    16.     0.]
  [ 8486.  1297.  1262.  1355.   393.   150.    26.     1.]
  [ 7095.   687.  1951.   926.   130.    93.    28.     8.]
  [ 6619.   727.  1758.   298.   194.   147.    42.     4.]
  [ 4071.   613.  1099.   691.   441.   139.    23.     1.]
  [  736.     0.   148.   586.   367.   286.   209.    61.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  990
Q value #non_end_state_>threshold:  1095
maxi score:  0.11610000000000001
siam score:  -0.91982836
Scores:  {'0.333': 0.0101, '0.667': 0.022099999999999998, '1.0': 0.042100000000000005, '1.333': 0.0541, '1.667': 0.18409999999999999, '2.0': 0.018099999999999998}
best rdn ma / adv:  1.667 1.667
best rdn adv:  0.046
rdn probs:  [0.06537598022373627, 0.09238682994185106, 0.1374049128053757, 0.16441576252349044, 0.45703330113640045, 0.08338321336914611]
Episodes: 11002, frames: 150072, time: 42257.307118177414
training steps:  17660
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
11002 : 0.25
LR:  0.001
replay buffer size:  154805
Time Taken :  704.0  mins 17.307004928588867  seconds
[[[26810. 11821.  4315.  2097.   228.    53.    10.     0.]
  [18378.  4759.   940.  1527.   262.    92.    17.     3.]
  [12741.  2955.  1791.  1843.   425.   116.    21.     2.]
  [ 8592.  1329.  1523.  1644.   471.   169.    27.     1.]
  [ 7154.   703.  2385.  1113.   143.   102.    31.    11.]
  [ 6655.   739.  2172.   340.   232.   158.    42.     4.]
  [ 4096.   639.  1465.  1022.   609.   190.    40.     1.]
  [  739.     0.   174.   866.   771.   729.   587.   196.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1954
Q value #non_end_state_>threshold:  4359
maxi score:  0.21209999999999998
siam score:  -0.9195729
Scores:  {'0.333': 0.056100000000000004, '0.667': 0.0741, '1.0': 0.0981, '1.333': 0.1101, '1.667': 0.2301, '2.0': 0.07010000000000001}
best rdn ma / adv:  1.667 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 11456, frames: 160099, time: 44229.340513944626
training steps:  18936
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
11456 : 0.45
LR:  0.001
replay buffer size:  165232
Time Taken :  737.0  mins 9.340338945388794  seconds
[[[27637. 12401.  4747.  2448.   243.    53.    10.     0.]
  [18807.  4820.   987.  1848.   292.    96.    17.     3.]
  [13020.  3150.  2047.  2248.   485.   133.    23.     2.]
  [ 8645.  1343.  1760.  1970.   525.   178.    30.     1.]
  [ 7181.   720.  2829.  1345.   153.   103.    33.    11.]
  [ 6673.   752.  2624.   371.   258.   161.    45.     6.]
  [ 4102.   656.  1906.  1407.   851.   256.    59.     1.]
  [  740.     0.   197.  1137.  1232.  1303.  1182.   380.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2974
Q value #non_end_state_>threshold:  8534
maxi score:  0.3081
siam score:  -0.89323545
Scores:  {'0.333': 0.1081, '0.667': 0.1261, '1.0': 0.14809999999999998, '1.333': 0.1661, '1.667': 0.2661, '2.0': 0.1281}
best rdn ma / adv:  1.667 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 11901, frames: 170118, time: 46197.71793818474
training steps:  20208
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
11901 : 0.45
LR:  0.001
replay buffer size:  175612
Time Taken :  769.0  mins 57.71776795387268  seconds
[[[28337. 12970.  5203.  2859.   254.    53.    10.     0.]
  [19144.  4863.  1026.  2193.   316.   100.    18.     3.]
  [13267.  3316.  2241.  2619.   545.   144.    23.     2.]
  [ 8720.  1363.  1996.  2292.   585.   190.    34.     2.]
  [ 7219.   736.  3323.  1589.   162.   105.    36.    11.]
  [ 6699.   767.  3159.   398.   278.   168.    45.     6.]
  [ 4109.   675.  2339.  1809.  1050.   316.    85.     1.]
  [  742.     0.   224.  1461.  1716.  1885.  1845.   571.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  4156
Q value #non_end_state_>threshold:  13124
maxi score:  0.4341
siam score:  -0.85289437
Scores:  {'0.333': 0.1641, '0.667': 0.2001, '1.0': 0.20809999999999998, '1.333': 0.2301, '1.667': 0.3061, '2.0': 0.17409999999999998}
best rdn ma / adv:  1.667 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 12332, frames: 180099, time: 47848.616700172424
training steps:  21416
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
12332 : 0.4
LR:  0.001
replay buffer size:  185987
Time Taken :  797.0  mins 28.616524934768677  seconds
[[[28879. 13577.  5699.  3317.   264.    54.    10.     0.]
  [19375.  4892.  1057.  2574.   347.   109.    20.     3.]
  [13428.  3453.  2437.  3024.   610.   163.    25.     2.]
  [ 8730.  1372.  2231.  2657.   658.   209.    34.     2.]
  [ 7225.   745.  3783.  1835.   178.   105.    36.    11.]
  [ 6700.   785.  3657.   430.   306.   175.    45.     6.]
  [ 4109.   687.  2804.  2240.  1300.   409.   109.     1.]
  [  742.     0.   244.  1771.  2232.  2538.  2557.   790.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  5288
Q value #non_end_state_>threshold:  19803
maxi score:  0.5141
siam score:  -0.8542908
Scores:  {'0.333': 0.2301, '0.667': 0.2641, '1.0': 0.2701, '1.333': 0.28809999999999997, '1.667': 0.3401, '2.0': 0.2201}
best rdn ma / adv:  1.667 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 12759, frames: 190022, time: 49253.65949630737
training steps:  22575
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
12759 : 0.55
LR:  0.001
replay buffer size:  196250
Time Taken :  820.0  mins 53.65931272506714  seconds
[[[29312. 14095.  6124.  3685.   273.    54.    10.     0.]
  [19663.  4931.  1076.  2900.   379.   113.    20.     3.]
  [13636.  3610.  2669.  3398.   669.   172.    26.     2.]
  [ 8747.  1386.  2500.  2988.   712.   218.    34.     2.]
  [ 7233.   760.  4233.  2041.   187.   106.    36.    11.]
  [ 6703.   796.  4122.   464.   354.   198.    45.     6.]
  [ 4111.   700.  3321.  2672.  1609.   570.   135.     1.]
  [  742.     0.   274.  2095.  2766.  3222.  3346.   997.]]]
