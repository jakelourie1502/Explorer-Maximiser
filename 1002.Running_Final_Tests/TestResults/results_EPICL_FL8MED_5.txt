EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  0.001315552210144233
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 55, frames: 663, time: 27.59714984893799
training steps:  4
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
55 : 0.0
LR:  3e-06
replay buffer size:  943
Time Taken :  0.0  mins 27.59670400619507  seconds
[[[218.  90.  33.   6.   2.   0.   0.   0.]
  [108.  33.   9.   2.   0.   0.   0.   0.]
  [ 52.   6.   3.   2.   0.   0.   0.   0.]
  [ 20.   6.   1.   2.   0.   0.   0.   0.]
  [  7.   2.   0.   2.   1.   0.   0.   0.]
  [  1.   1.   0.   1.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.6961224
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 946, frames: 10088, time: 2826.520805835724
training steps:  1243
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
946 : 0.0
LR:  0.001
replay buffer size:  10615
Time Taken :  47.0  mins 6.5203797817230225  seconds
[[[2475. 1362.  550.  248.   49.   11.    2.    0.]
  [1283.  556.  126.  109.   33.   12.    1.    1.]
  [ 716.  207.  101.   85.   33.   15.    5.    5.]
  [ 363.  115.   53.   71.   25.   16.    4.    1.]
  [ 184.   32.   31.   43.   10.    2.    1.    0.]
  [  99.   18.   15.   13.    0.    0.    0.    0.]
  [  38.    6.    3.    0.    0.    0.    0.    0.]
  [  13.    0.    1.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.71684
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1775, frames: 20069, time: 6613.958675861359
training steps:  2485
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1775 : 0.0
LR:  0.001
replay buffer size:  20794
Time Taken :  110.0  mins 13.958247900009155  seconds
[[[4776. 2558. 1064.  468.   95.   25.    3.    0.]
  [2573.  985.  218.  245.   75.   28.    4.    1.]
  [1462.  399.  201.  217.   67.   18.    6.    5.]
  [ 741.  218.  128.  185.   59.   22.    5.    2.]
  [ 416.   65.  127.  105.   19.    4.    7.    1.]
  [ 250.   55.   90.   36.    1.    0.    1.    0.]
  [ 128.   35.   43.   10.    1.    0.    2.    0.]
  [  28.    0.   10.    1.    2.    3.    1.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7200745
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2608, frames: 30026, time: 9858.324492931366
training steps:  3628
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2608 : 0.0
LR:  0.001
replay buffer size:  30956
Time Taken :  164.0  mins 18.324054718017578  seconds
[[[6873. 3655. 1527.  698.  137.   32.    3.    2.]
  [3689. 1363.  299.  396.  104.   38.    4.    3.]
  [2177.  605.  339.  366.  103.   35.   10.    8.]
  [1173.  326.  244.  302.   80.   35.    7.    4.]
  [ 692.  106.  266.  183.   30.   10.    8.    3.]
  [ 472.  107.  209.   62.    9.    7.    1.    0.]
  [ 273.   67.  112.   29.   13.    4.    2.    0.]
  [  62.    0.   34.    4.    7.    8.    1.    0.]]]
Test reward:  0.05
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  12
maxi score:  0.0021
siam score:  -0.81192887
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.002486634844868735, '1.333': 0.0061, '1.667': 0.0024584905660377356, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.00597482646
rdn probs:  [0.059776820691045465, 0.059776820691045465, 0.2022267342355437, 0.4178959033419142, 0.20054690034940573, 0.059776820691045465]
Episodes: 3421, frames: 40083, time: 13425.666252851486
training steps:  4942
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3421 : 0.05
LR:  0.001
replay buffer size:  41236
Time Taken :  223.0  mins 45.66582202911377  seconds
[[[8718. 4608. 1967.  912.  160.   41.    3.    2.]
  [4804. 1703.  376.  540.  124.   46.    4.    3.]
  [2987.  818.  474.  523.  138.   50.   12.    8.]
  [1674.  438.  342.  413.  109.   56.   11.    4.]
  [1091.  155.  377.  233.   46.   23.    9.    3.]
  [ 797.  143.  294.   77.   13.   18.    1.    0.]
  [ 595.  125.  173.   51.   31.   21.    5.    0.]
  [ 118.    0.   55.   16.   31.   64.   24.    5.]]]
Test reward:  0.15
Q value #end_state_>_threshold:  76
Q value #non_end_state_>threshold:  150
maxi score:  0.0121
siam score:  -0.9064342
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0101, '1.333': 0.0161, '1.667': 0.0041, '2.0': 0.0201}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.01805
rdn probs:  [0.04768793945666284, 0.04768793945666284, 0.19046241210866743, 0.27612709569987015, 0.10479772851746467, 0.333236884760672]
Episodes: 4216, frames: 50077, time: 16226.575479984283
training steps:  5969
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4216 : 0.2
LR:  0.001
replay buffer size:  51574
Time Taken :  270.0  mins 26.575039863586426  seconds
[[[10446.  5490.  2347.  1094.   179.    50.     4.     2.]
  [ 5851.  2020.   452.   675.   140.    59.     8.     3.]
  [ 3779.  1001.   625.   679.   161.    55.    14.     8.]
  [ 2265.   525.   453.   510.   120.    63.    12.     4.]
  [ 1477.   197.   507.   296.    57.    28.    10.     4.]
  [ 1095.   188.   417.    89.    19.    23.     1.     2.]
  [  884.   199.   280.   105.    72.    39.     8.     1.]
  [  170.     0.    83.    63.   131.   176.   116.    30.]]]
Test reward:  0.3
Q value #end_state_>_threshold:  590
Q value #non_end_state_>threshold:  704
maxi score:  0.042100000000000005
siam score:  -0.8778702
Scores:  {'0.333': 0.004346284501061571, '0.667': 0.015552538631346579, '1.0': 0.050100000000000006, '1.333': 0.1121, '1.667': 0.018099999999999998, '2.0': 0.0461}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.08091999999999999
rdn probs:  [0.05482436080825949, 0.08897185739752544, 0.19424426203322917, 0.3831695499947867, 0.09673443598855432, 0.18205553377764486]
Episodes: 4818, frames: 60084, time: 19942.646377801895
training steps:  7381
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4818 : 0.4
LR:  0.001
replay buffer size:  61913
Time Taken :  332.0  mins 22.645944833755493  seconds
[[[11621.  6202.  2726.  1340.   195.    50.     4.     2.]
  [ 6537.  2209.   501.   874.   161.    65.     8.     3.]
  [ 4294.  1199.   801.   909.   182.    61.    14.     8.]
  [ 2539.   569.   629.   737.   139.    73.    12.     4.]
  [ 1663.   237.   793.   456.    69.    40.    12.     4.]
  [ 1238.   220.   662.   112.    30.    40.     3.     2.]
  [  999.   227.   497.   331.   243.   139.    31.     1.]
  [  186.     0.   105.   265.   611.   753.   493.   136.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1356
Q value #non_end_state_>threshold:  1926
maxi score:  0.14209999999999998
siam score:  -0.9017955
Scores:  {'0.333': 0.016196579476861168, '0.667': 0.0461, '1.0': 0.1221, '1.333': 0.2221, '1.667': 0.0301, '2.0': 0.048100000000000004}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.10878
rdn probs:  [0.05790070370817415, 0.10825937392424662, 0.23624670344930981, 0.40465108440334047, 0.08131467297160175, 0.11162746154332723]
Episodes: 5309, frames: 70091, time: 23278.20602083206
training steps:  8606
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5309 : 0.3
LR:  0.001
replay buffer size:  72304
Time Taken :  387.0  mins 58.20559072494507  seconds
[[[12559.  6771.  3056.  1582.   210.    50.     4.     2.]
  [ 7059.  2298.   526.  1079.   176.    72.    11.     3.]
  [ 4696.  1411.   998.  1153.   216.    70.    17.     8.]
  [ 2711.   610.   862.   955.   178.   107.    13.     4.]
  [ 1755.   259.  1126.   591.    75.    70.    17.     5.]
  [ 1323.   234.   971.   138.    43.    70.     8.     2.]
  [ 1063.   246.   787.   616.   441.   239.    58.     1.]
  [  198.     0.   142.   629.  1395.  1500.  1026.   287.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2065
Q value #non_end_state_>threshold:  3634
maxi score:  0.2201
siam score:  -0.8733006
Scores:  {'0.333': 0.0781, '0.667': 0.1041, '1.0': 0.18209999999999998, '1.333': 0.28209999999999996, '1.667': 0.058100000000000006, '2.0': 0.0741}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 5766, frames: 80036, time: 25474.04142308235
training steps:  9412
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5766 : 0.25
LR:  0.001
replay buffer size:  82803
Time Taken :  424.0  mins 34.04098582267761  seconds
[[[13216.  7314.  3475.  1880.   232.    50.     4.     2.]
  [ 7364.  2348.   563.  1325.   192.    74.    11.     3.]
  [ 4948.  1597.  1191.  1392.   244.    79.    17.     8.]
  [ 2756.   633.  1156.  1184.   218.   135.    13.     4.]
  [ 1766.   276.  1552.   720.    88.   101.    19.     5.]
  [ 1327.   246.  1338.   164.    57.   100.     8.     2.]
  [ 1067.   262.  1151.  1061.   723.   362.    81.     1.]
  [  199.     0.   188.  1176.  2258.  2311.  1579.   454.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2830
Q value #non_end_state_>threshold:  5477
maxi score:  0.3061
siam score:  -0.8641178
Scores:  {'0.333': 0.1201, '0.667': 0.15209999999999999, '1.0': 0.2261, '1.333': 0.3241, '1.667': 0.0861, '2.0': 0.1041}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 6149, frames: 90009, time: 28859.871428012848
training steps:  10839
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6149 : 0.3
LR:  0.001
replay buffer size:  93085
Time Taken :  480.0  mins 59.87099075317383  seconds
[[[13606.  7741.  3809.  2152.   243.    50.     4.     2.]
  [ 7604.  2372.   586.  1567.   215.    75.    15.     4.]
  [ 5162.  1766.  1377.  1625.   277.    84.    19.    11.]
  [ 2787.   650.  1439.  1411.   260.   176.    21.     7.]
  [ 1772.   295.  1978.   859.    96.   142.    24.     5.]
  [ 1327.   258.  1711.   192.   104.   150.    11.     2.]
  [ 1067.   269.  1516.  1603.  1093.   521.   107.     1.]
  [  199.     0.   225.  1957.  3315.  3171.  2156.   617.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  3593
Q value #non_end_state_>threshold:  7726
maxi score:  0.4521
siam score:  -0.86695015
Scores:  {'0.333': 0.1901, '0.667': 0.20609999999999998, '1.0': 0.28809999999999997, '1.333': 0.34809999999999997, '1.667': 0.1261, '2.0': 0.1321}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 6554, frames: 100021, time: 32228.198519945145
training steps:  12261
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6554 : 0.65
LR:  0.001
replay buffer size:  103438
Time Taken :  537.0  mins 8.198080062866211  seconds
[[[13943.  8090.  4105.  2388.   247.    50.     4.     2.]
  [ 7865.  2399.   611.  1776.   229.    76.    15.     4.]
  [ 5402.  1972.  1593.  1851.   302.    91.    19.    11.]
  [ 2803.   665.  1743.  1631.   295.   205.    26.     7.]
  [ 1774.   311.  2428.   990.   111.   178.    28.     5.]
  [ 1328.   274.  2170.   222.   158.   206.    16.     2.]
  [ 1067.   277.  1954.  2219.  1485.   692.   126.     1.]
  [  199.     0.   260.  2751.  4295.  3955.  2757.   808.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  3963
Q value #non_end_state_>threshold:  10693
maxi score:  0.5700999999999999
siam score:  -0.8533938
Scores:  {'0.333': 0.2561, '0.667': 0.24209999999999998, '1.0': 0.34809999999999997, '1.333': 0.3681, '1.667': 0.1621, '2.0': 0.1581}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 6953, frames: 110047, time: 35195.30386185646
training steps:  13630
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6953 : 0.65
LR:  0.001
replay buffer size:  113804
Time Taken :  586.0  mins 35.303422927856445  seconds
[[[14330.  8424.  4394.  2644.   253.    50.     4.     2.]
  [ 8166.  2426.   633.  1982.   244.    76.    15.     4.]
  [ 5651.  2190.  1820.  2058.   332.   103.    20.    11.]
  [ 2824.   681.  2048.  1843.   333.   243.    31.     7.]
  [ 1779.   325.  2870.  1119.   121.   223.    36.     6.]
  [ 1331.   287.  2609.   256.   217.   263.    20.     2.]
  [ 1068.   286.  2396.  2849.  1893.   858.   147.     1.]
  [  199.     0.   292.  3491.  5232.  4740.  3336.  1000.]]]
