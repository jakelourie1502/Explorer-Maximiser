EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  3.587565151974559e-05
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 82, frames: 1013, time: 25.537986993789673
training steps:  3
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
82 : 0.0
LR:  2e-06
replay buffer size:  1201
Time Taken :  0.0  mins 25.5377459526062  seconds
[[[  9.   3.   0.   0.   0.   0.   0.]
  [ 45.  23.  13.   2.   0.   0.   0.]
  [122.  72.  22.   4.   3.   1.   0.]
  [166. 105.  28.   0.   1.   1.   0.]
  [ 83.  65.  13.   0.   0.   0.   0.]
  [ 43.  43.  12.   2.   0.   0.   0.]
  [ 14.  24.  11.   1.   0.   0.   0.]]

 [[  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.70032305
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 768, frames: 10044, time: 1844.684629201889
training steps:  1230
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
768 : 0.0
LR:  0.001
replay buffer size:  10433
Time Taken :  30.0  mins 44.68438696861267  seconds
[[[  92.   50.    0.    0.    8.   29.   72.]
  [ 510.  298.  106.   17.    9.   21.   15.]
  [1158.  724.  268.   99.   42.   28.   15.]
  [1548. 1000.  269.   18.    6.    6.    5.]
  [ 905.  580.  115.    8.    7.    4.    2.]
  [ 344.  290.   97.   61.   20.    2.    0.]
  [ 192.  163.   53.   15.    3.    2.    0.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7799494
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1182, frames: 20124, time: 4371.1056480407715
training steps:  2462
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1182 : 0.0
LR:  0.001
replay buffer size:  20670
Time Taken :  72.0  mins 51.10540199279785  seconds
[[[ 147.  103.    0.    0.   10.   37.   72.]
  [1000.  608.  164.   25.   24.   38.   19.]
  [2653. 1599.  434.  158.   80.   44.   18.]
  [3348. 2009.  406.   28.    9.    9.    5.]
  [1879. 1099.  158.   12.    8.    4.    2.]
  [ 869.  573.  136.   70.   22.    3.    1.]
  [ 628.  328.   77.   18.    4.    3.    1.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.80540866
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1610, frames: 30144, time: 6911.789573907852
training steps:  3584
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1610 : 0.0
LR:  0.001
replay buffer size:  30908
Time Taken :  115.0  mins 11.789328813552856  seconds
[[[ 206.  138.    0.    0.   15.   51.   91.]
  [1412.  822.  210.   33.   54.   65.   40.]
  [3802. 2349.  601.  227.  126.   69.   30.]
  [4934. 3074.  542.   36.   14.   14.    7.]
  [3031. 1751.  230.   17.   10.   11.    5.]
  [1504.  895.  223.  105.   34.    7.    7.]
  [1117.  484.  106.   22.    4.    6.    3.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81671214
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1960, frames: 40129, time: 9441.59831404686
training steps:  4837
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1960 : 0.0
LR:  0.001
replay buffer size:  41085
Time Taken :  157.0  mins 21.598064184188843  seconds
[[[ 244.  162.    0.    0.   21.   61.  101.]
  [1839. 1057.  249.   44.   67.   79.   46.]
  [5021. 3133.  746.  264.  144.   77.   31.]
  [6723. 4169.  666.   41.   17.   15.    8.]
  [4273. 2407.  281.   23.   12.   11.    8.]
  [2096. 1221.  288.  132.   41.    8.    9.]
  [1530.  634.  131.   24.    5.    7.    3.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.84638727
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 2338, frames: 50056, time: 10998.33201289177
training steps:  6041
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2338 : 0.0
LR:  0.001
replay buffer size:  51184
Time Taken :  183.0  mins 18.3317608833313  seconds
[[[ 307.  192.    0.    0.   25.   81.  140.]
  [2278. 1307.  293.   52.   90.  120.   88.]
  [6206. 4042.  924.  334.  193.  114.   73.]
  [8327. 5299.  791.   46.   20.   19.   13.]
  [5351. 2995.  335.   23.   14.   14.    8.]
  [2629. 1512.  326.  142.   47.   14.   10.]
  [1894.  766.  153.   25.    8.   12.    3.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    1.]
  [   0.    0.    0.    0.    1.    4.    7.]
  [   0.    0.    1.    2.    3.    7.    4.]
  [   0.    0.    1.    0.    5.   16.   11.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8708327
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 2684, frames: 60052, time: 12259.332267045975
training steps:  7398
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2684 : 0.0
LR:  0.001
replay buffer size:  61401
Time Taken :  204.0  mins 19.332016944885254  seconds
[[[ 334.  211.    0.    0.   36.  117.  158.]
  [2566. 1514.  335.   58.  109.  155.  109.]
  [7120. 4832. 1082.  403.  237.  144.  100.]
  [9743. 6446.  907.   52.   21.   24.   17.]
  [6480. 3736.  396.   31.   19.   27.   17.]
  [3341. 1982.  428.  187.   70.   30.   20.]
  [2451. 1005.  175.   32.    8.   15.   10.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    1.    1.]
  [   0.    0.    0.    0.    1.    6.   16.]
  [   0.    0.    1.    2.    3.   10.    4.]
  [   0.    0.    1.    0.    5.   16.   11.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8775436
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 3091, frames: 70099, time: 13282.474781990051
training steps:  8383
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3091 : 0.0
LR:  0.001
replay buffer size:  71681
Time Taken :  221.0  mins 22.474528074264526  seconds
[[[  374.   226.     0.     0.    45.   147.   180.]
  [ 2854.  1702.   374.    67.   123.   193.   122.]
  [ 7946.  5467.  1208.   472.   286.   195.   124.]
  [11015.  7505.  1013.    58.    32.    33.    24.]
  [ 7520.  4517.   471.    40.    37.    48.    43.]
  [ 4120.  2482.   570.   274.   136.    65.    63.]
  [ 3088.  1290.   225.    45.    29.    40.    31.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     1.     1.]
  [    0.     0.     0.     0.     1.     6.    16.]
  [    0.     0.     1.     3.     4.    12.     4.]
  [    0.     0.     1.     2.     8.    18.    11.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8822713
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.00199960002
Episodes: 3434, frames: 80295, time: 14492.831973075867
training steps:  9426
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3434 : 0.0
LR:  0.001
replay buffer size:  82953
Time Taken :  241.0  mins 32.83172082901001  seconds
[[[  397.   241.     0.     0.    52.   160.   224.]
  [ 3113.  1830.   397.    72.   133.   211.   163.]
  [ 8764.  6003.  1331.   530.   324.   235.   164.]
  [12290.  8389.  1090.    66.    35.    47.    41.]
  [ 8683.  5270.   546.    45.    56.   101.    85.]
  [ 4950.  3000.   692.   361.   221.   136.   120.]
  [ 3806.  1629.   276.    54.    55.    70.    78.]]

 [[    0.     0.     0.     0.     0.     0.     1.]
  [    1.     0.     0.     0.     0.     1.     3.]
  [   20.     9.     1.     1.     1.     1.     4.]
  [   14.    10.     0.     0.     2.     2.     1.]
  [   10.     9.     0.     1.     7.    21.    30.]
  [   11.    12.     7.    10.    12.    32.    15.]
  [    8.     2.     1.     3.    12.    24.    26.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  2
maxi score:  0.0001
siam score:  -0.9414897
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0061, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.005998800060000001
Episodes: 3757, frames: 90225, time: 15982.043982028961
training steps:  11018
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3757 : 0.0
LR:  0.001
replay buffer size:  93821
Time Taken :  266.0  mins 22.043734073638916  seconds
[[[  432.   249.     0.     0.    59.   202.   269.]
  [ 3335.  1961.   416.    77.   151.   257.   200.]
  [ 9379.  6461.  1447.   598.   384.   293.   206.]
  [13303.  9123.  1157.    73.    40.    53.    57.]
  [ 9603.  5878.   614.    55.    90.   182.   215.]
  [ 5683.  3495.   841.   478.   372.   272.   312.]
  [ 4570.  1997.   320.    65.    89.   145.   260.]]

 [[    0.     0.     0.     0.     0.     0.     3.]
  [    7.     5.     0.     0.     0.     1.     5.]
  [   37.    26.     6.     4.     4.     5.     9.]
  [   38.    28.     1.     0.     2.     2.     3.]
  [   39.    23.     1.     1.    13.    34.    57.]
  [   36.    30.    20.    22.    31.    70.    43.]
  [   32.     9.     3.     5.    17.    36.    42.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  5
Q value #non_end_state_>threshold:  26
maxi score:  0.0001
siam score:  -0.8759742
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0141, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.01399720014
Episodes: 4086, frames: 100436, time: 17404.216807127
training steps:  12436
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4086 : 0.0
LR:  0.001
replay buffer size:  105248
Time Taken :  290.0  mins 4.2165491580963135  seconds
[[[  461.   265.     0.     0.    62.   215.   308.]
  [ 3623.  2154.   448.    85.   167.   297.   241.]
  [10172.  7027.  1593.   683.   441.   346.   253.]
  [14371.  9851.  1234.    77.    43.    59.    71.]
  [10561.  6473.   667.    66.   117.   226.   270.]
  [ 6451.  3998.   987.   592.   479.   362.   406.]
  [ 5365.  2399.   363.    68.   105.   190.   315.]]

 [[    0.     1.     0.     0.     0.     2.     7.]
  [   20.    15.     1.     1.     2.     9.    20.]
  [   56.    49.    21.    15.    13.    14.    34.]
  [   55.    41.     2.     1.     2.     3.     6.]
  [   59.    37.     1.     2.    15.    53.    93.]
  [   51.    48.    35.    48.    64.   131.    89.]
  [   43.    20.     3.    10.    23.    61.    67.]]]
Test reward:  0.15
Q value #end_state_>_threshold:  28
Q value #non_end_state_>threshold:  92
maxi score:  0.0061
siam score:  -0.87572634
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0301, '1.667': 0.0081, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.0296351163
Episodes: 4425, frames: 110389, time: 18519.012682199478
training steps:  13444
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4425 : 0.0
LR:  0.001
replay buffer size:  116110
Time Taken :  308.0  mins 39.01242995262146  seconds
[[[  482.   282.     0.     0.    71.   254.   377.]
  [ 3905.  2331.   472.    90.   185.   360.   320.]
  [10785.  7446.  1696.   752.   518.   420.   325.]
  [15218. 10411.  1293.    80.    58.    68.    83.]
  [11435.  6961.   726.    75.   174.   312.   403.]
  [ 7148.  4459.  1161.   733.   634.   496.   553.]
  [ 6101.  2761.   419.    78.   142.   257.   439.]]

 [[    1.     1.     0.     0.     0.    20.    20.]
  [   34.    23.     1.     1.     3.    56.    61.]
  [   82.    80.    43.    29.    27.    39.    63.]
  [   78.    56.     3.     1.     2.     6.    10.]
  [   84.    54.     4.     4.    22.    78.   132.]
  [   79.    82.    68.    83.   117.   208.   136.]
  [   64.    33.     5.    10.    32.    79.   101.]]]
Test reward:  0.45
Q value #end_state_>_threshold:  133
Q value #non_end_state_>threshold:  246
maxi score:  0.026099999999999998
siam score:  -0.9312738
Scores:  {'0.333': 0.0021, '0.667': 0.0001, '1.0': 0.0021, '1.333': 0.050100000000000006, '1.667': 0.022099999999999998, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.03612499999999999
Episodes: 4733, frames: 120070, time: 19972.526147842407
training steps:  14408
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4733 : 0.05
LR:  0.001
replay buffer size:  126458
Time Taken :  332.0  mins 52.52590298652649  seconds
[[[  502.   288.     0.     0.    76.   276.   426.]
  [ 4134.  2485.   490.    94.   200.   404.   379.]
  [11297.  7748.  1775.   818.   570.   469.   362.]
  [15947. 10904.  1340.    83.    64.    76.    91.]
  [12061.  7404.   783.    91.   247.   412.   534.]
  [ 7690.  4942.  1413.   948.   842.   647.   683.]
  [ 6719.  3111.   459.    93.   212.   375.   564.]]

 [[    3.     4.     0.     0.     3.    60.    42.]
  [   73.    46.     2.     1.    10.   144.   141.]
  [  138.   127.    88.    76.    76.   103.   139.]
  [  118.    77.     4.     2.     3.     8.    14.]
  [  120.    79.     7.     7.    47.   117.   200.]
  [  130.   129.   118.   141.   193.   319.   207.]
  [   86.    42.     6.    13.    57.   134.   155.]]]
Test reward:  0.65
Q value #end_state_>_threshold:  473
Q value #non_end_state_>threshold:  1050
maxi score:  0.0641
siam score:  -0.9276248
Scores:  {'0.333': 0.0061, '0.667': 0.004310526315789474, '1.0': 0.0081, '1.333': 0.11410000000000001, '1.667': 0.0441, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.034485000000000016
Episodes: 5011, frames: 130199, time: 21798.15902709961
training steps:  15294
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5011 : 0.2
LR:  0.001
replay buffer size:  137066
Time Taken :  363.0  mins 18.15878915786743  seconds
[[[  513.   296.     0.     0.    78.   293.   436.]
  [ 4293.  2572.   501.    94.   205.   421.   393.]
  [11639.  7927.  1823.   840.   597.   494.   374.]
  [16475. 11189.  1364.    83.    69.    82.    95.]
  [12586.  7680.   816.   100.   314.   520.   640.]
  [ 8112.  5318.  1696.  1185.  1086.   854.   772.]
  [ 7065.  3303.   486.   104.   265.   455.   631.]]

 [[    4.     4.     0.     0.     6.   165.   102.]
  [  133.    94.     6.     4.    31.   368.   339.]
  [  333.   310.   235.   221.   250.   325.   243.]
  [  289.   167.    10.     5.     9.    17.    18.]
  [  262.   180.    10.    14.    87.   185.   306.]
  [  265.   305.   274.   314.   383.   581.   347.]
  [  160.    94.    10.    21.   116.   205.   247.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1029
Q value #non_end_state_>threshold:  2837
maxi score:  0.1401
siam score:  -0.92640555
Scores:  {'0.333': 0.0101, '0.667': 0.02241237322515213, '1.0': 0.0141, '1.333': 0.17409999999999998, '1.667': 0.0821, '2.0': 0.0081}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.021315
Episodes: 5245, frames: 140120, time: 23821.054368019104
training steps:  16736
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5245 : 0.5
LR:  0.001
replay buffer size:  147526
Time Taken :  397.0  mins 1.0541141033172607  seconds
[[[  518.   298.     0.     0.    78.   303.   447.]
  [ 4387.  2609.   504.    97.   208.   426.   401.]
  [11889.  8057.  1855.   861.   612.   502.   385.]
  [16858. 11419.  1376.    85.    74.    85.    96.]
  [12919.  7890.   838.   106.   375.   585.   705.]
  [ 8366.  5657.  1978.  1467.  1344.  1060.   835.]
  [ 7273.  3404.   503.   114.   334.   553.   688.]]

 [[    5.     6.     0.     0.     9.   379.   189.]
  [  220.   172.    10.     8.    88.   697.   544.]
  [  514.   577.   466.   465.   539.   671.   449.]
  [  454.   274.    14.     5.    14.    27.    23.]
  [  446.   288.    12.    20.   136.   246.   380.]
  [  449.   521.   462.   508.   607.   862.   455.]
  [  302.   149.    15.    26.   165.   273.   310.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1539
Q value #non_end_state_>threshold:  4880
maxi score:  0.2201
siam score:  -0.9174682
Scores:  {'0.333': 0.022099999999999998, '0.667': 0.0461, '1.0': 0.0461, '1.333': 0.20409999999999998, '1.667': 0.0961, '2.0': 0.0241}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
Episodes: 5473, frames: 150097, time: 25824.850871801376
training steps:  18304
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5473 : 0.55
LR:  0.001
replay buffer size:  158035
Time Taken :  430.0  mins 24.850619077682495  seconds
[[[  520.   300.     0.     0.    78.   306.   450.]
  [ 4440.  2631.   508.    97.   208.   427.   404.]
  [12010.  8112.  1866.   864.   614.   504.   389.]
  [17084. 11581.  1384.    85.    76.    92.    98.]
  [13152.  8081.   856.   114.   467.   711.   802.]
  [ 8560.  5987.  2259.  1746.  1661.  1321.   943.]
  [ 7407.  3481.   511.   119.   412.   663.   781.]]

 [[    5.     6.     0.     0.    13.   596.   274.]
  [  321.   281.    22.    11.   143.   976.   778.]
  [  732.   907.   692.   724.   832.   932.   625.]
  [  657.   462.    17.     7.    22.    37.    30.]
  [  647.   477.    17.    25.   200.   333.   467.]
  [  646.   787.   690.   726.   879.  1203.   578.]
  [  432.   240.    24.    29.   236.   357.   367.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2133
Q value #non_end_state_>threshold:  7455
maxi score:  0.3041
siam score:  -0.9079359
Scores:  {'0.333': 0.050100000000000006, '0.667': 0.0901, '1.0': 0.06810000000000001, '1.333': 0.2241, '1.667': 0.1181, '2.0': 0.0381}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
Episodes: 5718, frames: 160064, time: 27924.554723978043
training steps:  19932
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5718 : 0.3
LR:  0.001
replay buffer size:  168840
Time Taken :  465.0  mins 24.554470777511597  seconds
[[[  525.   303.     0.     0.    78.   307.   450.]
  [ 4491.  2651.   511.    97.   209.   431.   406.]
  [12140.  8161.  1874.   868.   618.   508.   391.]
  [17282. 11784.  1395.    85.    79.    94.   105.]
  [13385.  8342.   873.   120.   545.   826.   933.]
  [ 8729.  6360.  2591.  2040.  1987.  1617.  1074.]
  [ 7490.  3545.   522.   127.   492.   780.   868.]]

 [[    9.     8.     0.     0.    18.   801.   373.]
  [  413.   357.    22.    16.   209.  1263.  1055.]
  [  948.  1220.   900.   950.  1073.  1178.   860.]
  [  864.   675.    25.    13.    25.    45.    36.]
  [  836.   638.    21.    27.   255.   418.   558.]
  [  838.  1018.   903.   965.  1163.  1523.   682.]
  [  538.   284.    28.    38.   305.   433.   430.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2628
Q value #non_end_state_>threshold:  9628
maxi score:  0.3821
siam score:  -0.86874527
Scores:  {'0.333': 0.06810000000000001, '0.667': 0.1221, '1.0': 0.0881, '1.333': 0.2341, '1.667': 0.1361, '2.0': 0.0601}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
Episodes: 5943, frames: 170084, time: 29591.276432037354
training steps:  21085
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5943 : 0.4
LR:  0.001
replay buffer size:  179395
Time Taken :  493.0  mins 11.276180982589722  seconds
[[[  526.   303.     0.     0.    78.   307.   450.]
  [ 4543.  2675.   511.    97.   209.   431.   406.]
  [12245.  8222.  1886.   872.   621.   508.   391.]
  [17503. 12007.  1406.    85.    83.   100.   110.]
  [13612.  8586.   886.   129.   651.   984.  1065.]
  [ 8953.  6779.  2931.  2344.  2313.  1941.  1221.]
  [ 7616.  3663.   538.   134.   587.   945.  1026.]]

 [[   11.     8.     0.     0.    27.  1065.   454.]
  [  530.   473.    25.    21.   289.  1549.  1246.]
  [ 1138.  1538.  1109.  1180.  1300.  1372.  1027.]
  [ 1056.   898.    32.    16.    30.    51.    40.]
  [  977.   809.    29.    29.   300.   488.   617.]
  [  983.  1245.  1105.  1177.  1417.  1816.   790.]
  [  608.   338.    33.    45.   367.   508.   496.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  3144
Q value #non_end_state_>threshold:  11601
maxi score:  0.4481
siam score:  -0.849183
Scores:  {'0.333': 0.0921, '0.667': 0.14209999999999998, '1.0': 0.1021, '1.333': 0.2521, '1.667': 0.14809999999999998, '2.0': 0.0721}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
Episodes: 6134, frames: 180123, time: 31101.09222793579
training steps:  22123
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6134 : 0.2
LR:  0.001
replay buffer size:  189984
Time Taken :  518.0  mins 21.09197497367859  seconds
[[[  528.   303.     0.     0.    79.   322.   518.]
  [ 4610.  2698.   511.    97.   212.   445.   434.]
  [12389.  8305.  1905.   883.   630.   525.   403.]
  [17709. 12208.  1411.    85.    88.   104.   113.]
  [13866.  8835.   900.   133.   773.  1187.  1231.]
  [ 9188.  7183.  3247.  2627.  2633.  2243.  1401.]
  [ 7807.  3815.   549.   141.   691.  1116.  1150.]]

 [[   14.     9.     0.     0.    31.  1180.   522.]
  [  628.   566.    33.    23.   361.  1783.  1467.]
  [ 1371.  1857.  1321.  1375.  1516.  1558.  1197.]
  [ 1278.  1122.    38.    16.    34.    55.    48.]
  [ 1127.   977.    34.    35.   356.   544.   649.]
  [ 1140.  1449.  1287.  1375.  1672.  2082.   855.]
  [  705.   410.    38.    50.   436.   588.   546.]]]
