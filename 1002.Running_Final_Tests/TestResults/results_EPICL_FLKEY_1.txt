EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  0.00891029297445829
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 43, frames: 741, time: 26.485228061676025
training steps:  3
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
43 : 0.0
LR:  2e-06
replay buffer size:  916
Time Taken :  0.0  mins 26.484995126724243  seconds
[[[  6.   3.   0.   0.   0.   0.   0.]
  [ 28.  19.   4.   0.   0.   0.   0.]
  [ 67.  47.   7.   2.   0.   0.   0.]
  [113.  46.   8.   1.   0.   0.   0.]
  [101.  43.  11.   1.   0.   0.   0.]
  [ 47.  48.  15.   5.   0.   0.   0.]
  [ 38.  29.   8.   1.   0.   0.   0.]]

 [[  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.782917
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 553, frames: 10630, time: 2329.4645249843597
training steps:  1276
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
553 : 0.0
LR:  0.001
replay buffer size:  11618
Time Taken :  38.0  mins 49.46427607536316  seconds
[[[  51.   30.    0.    0.    5.   26.  228.]
  [ 264.  192.   61.   10.   12.   25.   57.]
  [ 728.  455.  121.   46.   29.   28.   28.]
  [1102.  634.  124.    7.    6.    3.    5.]
  [1192.  578.  118.   11.   10.    4.   10.]
  [1040.  530.  152.   57.   33.   10.   13.]
  [1411.  445.   96.   17.   19.    9.   25.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    1.]
  [   0.    0.    0.    0.    0.    3.    1.]
  [   0.    0.    0.    0.    0.    5.    2.]
  [   0.    0.    0.    0.    0.    7.    1.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8339821
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1007, frames: 20512, time: 5230.5090119838715
training steps:  2443
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1007 : 0.0
LR:  0.001
replay buffer size:  22121
Time Taken :  87.0  mins 10.508762121200562  seconds
[[[  78.   46.    0.    0.   14.   63.  292.]
  [ 443.  330.   95.   22.   39.   65.   91.]
  [1347.  897.  250.  110.  100.   80.   73.]
  [2144. 1295.  222.   10.   21.   11.   13.]
  [2224. 1190.  206.   47.   79.   30.   31.]
  [1869. 1181.  394.  208.  168.   78.   55.]
  [2097.  836.  167.   37.   85.   69.   99.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    3.    1.    2.]
  [   0.    0.    0.    1.    7.   22.   18.]
  [   0.    0.    2.    9.   14.   33.   22.]
  [   0.    0.    1.    2.   16.   29.   22.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.83743423
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1468, frames: 30276, time: 9801.467013835907
training steps:  3776
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1468 : 0.0
LR:  0.001
replay buffer size:  32538
Time Taken :  163.0  mins 21.466768980026245  seconds
[[[ 110.   64.    0.    0.   23.   80.  318.]
  [ 648.  489.  135.   31.   64.   88.  117.]
  [1872. 1275.  389.  173.  143.  103.   97.]
  [3067. 1899.  314.   15.   38.   26.   25.]
  [3234. 1760.  279.   62.  163.  102.   77.]
  [2705. 1841.  648.  357.  310.  155.  111.]
  [2954. 1349.  258.   63.  156.  139.  157.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   1.    0.    0.    0.    0.    0.    0.]
  [   3.    1.    0.    0.    0.    0.    0.]
  [   2.    4.    0.    0.    4.    2.    3.]
  [   4.    4.    1.    1.   11.   33.   28.]
  [   5.    3.    5.   11.   20.   51.   36.]
  [   3.    1.    2.    3.   20.   36.   27.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.84378713
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1980, frames: 40399, time: 14058.502597808838
training steps:  4789
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1980 : 0.0
LR:  0.001
replay buffer size:  43258
Time Taken :  234.0  mins 18.50235390663147  seconds
[[[ 147.   86.    0.    0.   27.   99.  328.]
  [ 861.  650.  169.   38.   81.  123.  126.]
  [2482. 1734.  518.  228.  172.  126.  105.]
  [4007. 2603.  440.   20.   47.   36.   34.]
  [4212. 2406.  387.   89.  229.  157.  120.]
  [3533. 2613.  916.  521.  443.  211.  171.]
  [3741. 1865.  345.   81.  202.  164.  199.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   1.    1.    0.    0.    0.    0.    0.]
  [  11.    8.    3.    0.    0.    0.    0.]
  [  15.   14.    1.    0.    6.    3.    6.]
  [  11.   10.    2.    1.   20.   43.   37.]
  [  15.   18.   11.   17.   35.   73.   46.]
  [  13.    2.    2.    4.   25.   41.   32.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81156677
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 2455, frames: 50081, time: 19561.240367889404
training steps:  6051
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2455 : 0.0
LR:  0.001
replay buffer size:  53325
Time Taken :  326.0  mins 1.2401270866394043  seconds
[[[ 171.   99.    0.    0.   30.  107.  350.]
  [1047.  793.  197.   51.  101.  138.  143.]
  [3007. 2124.  624.  295.  215.  149.  115.]
  [4886. 3205.  532.   28.   58.   44.   44.]
  [5163. 3094.  491.  118.  293.  210.  175.]
  [4360. 3406. 1223.  721.  595.  271.  212.]
  [4455. 2422.  441.  110.  265.  208.  242.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   2.    1.    1.    0.    0.    0.    0.]
  [  13.   10.    4.    0.    0.    0.    0.]
  [  20.   17.    1.    0.    6.    4.    9.]
  [  13.   11.    3.    2.   22.   51.   40.]
  [  16.   19.   13.   19.   38.   85.   47.]
  [  13.    2.    2.    4.   26.   47.   37.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8190867
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 2982, frames: 60104, time: 26252.690270900726
training steps:  7352
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2982 : 0.0
LR:  0.001
replay buffer size:  63617
Time Taken :  437.0  mins 32.690059185028076  seconds
[[[ 203.  116.    0.    0.   34.  125.  359.]
  [1284.  938.  227.   59.  117.  152.  158.]
  [3681. 2542.  742.  346.  257.  167.  131.]
  [5910. 3891.  629.   32.   75.   58.   53.]
  [6114. 3777.  612.  157.  374.  281.  216.]
  [5076. 4160. 1616.  958.  754.  342.  256.]
  [5063. 2855.  536.  143.  314.  243.  288.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   5.    3.    2.    0.    0.    0.    0.]
  [  15.   13.    6.    1.    0.    0.    0.]
  [  26.   17.    1.    1.    6.    5.   10.]
  [  20.   15.    4.    2.   24.   56.   43.]
  [  21.   23.   18.   23.   44.   97.   49.]
  [  15.    2.    2.    5.   31.   55.   41.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81514144
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 3494, frames: 70184, time: 32882.69181895256
training steps:  8686
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3494 : 0.0
LR:  0.001
replay buffer size:  74043
Time Taken :  548.0  mins 2.6915690898895264  seconds
[[[ 231.  135.    0.    0.   37.  141.  379.]
  [1480. 1062.  254.   70.  149.  179.  176.]
  [4295. 2973.  871.  406.  308.  205.  149.]
  [6934. 4568.  727.   35.   86.   72.   59.]
  [7148. 4470.  736.  188.  433.  321.  255.]
  [5895. 4989. 2030. 1188.  902.  403.  296.]
  [5587. 3272.  634.  174.  357.  275.  314.]]

 [[   1.    0.    0.    0.    0.    0.    0.]
  [   9.    6.    3.    0.    0.    0.    0.]
  [  21.   14.    6.    1.    0.    0.    0.]
  [  33.   18.    1.    1.    6.    5.   12.]
  [  28.   25.    5.    3.   28.   61.   48.]
  [  29.   37.   26.   32.   56.  110.   51.]
  [  18.    6.    4.    5.   32.   58.   43.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.82298815
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 4019, frames: 80101, time: 36805.49179792404
training steps:  9960
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4019 : 0.0
LR:  0.001
replay buffer size:  84301
Time Taken :  613.0  mins 25.491549015045166  seconds
[[[ 253.  156.    0.    0.   40.  170.  391.]
  [1674. 1209.  296.   75.  165.  215.  193.]
  [4874. 3416.  993.  470.  358.  238.  161.]
  [7880. 5283.  835.   39.   99.   83.   73.]
  [8127. 5234.  873.  210.  504.  380.  316.]
  [6634. 5748. 2396. 1402. 1067.  473.  354.]
  [6050. 3675.  719.  199.  382.  301.  333.]]

 [[   1.    0.    0.    0.    0.    0.    0.]
  [  10.    9.    3.    0.    0.    0.    0.]
  [  32.   25.    9.    3.    0.    0.    0.]
  [  49.   30.    2.    1.    7.    6.   16.]
  [  39.   36.    7.    6.   36.   71.   55.]
  [  37.   52.   40.   43.   68.  133.   55.]
  [  23.   15.    5.    5.   33.   61.   43.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8192574
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 4584, frames: 90207, time: 39940.90013384819
training steps:  10990
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4584 : 0.0
LR:  0.001
replay buffer size:  94745
Time Taken :  665.0  mins 40.89988303184509  seconds
[[[ 296.  178.    0.    0.   41.  183.  399.]
  [1915. 1369.  334.   83.  174.  229.  206.]
  [5543. 3892. 1129.  523.  379.  250.  170.]
  [8893. 5983.  948.   47.  111.   92.   84.]
  [9138. 6010. 1018.  240.  559.  446.  379.]
  [7387. 6549. 2784. 1623. 1205.  545.  400.]
  [6477. 4043.  801.  227.  411.  335.  365.]]

 [[   1.    0.    0.    0.    0.    0.    0.]
  [  10.    9.    3.    0.    0.    0.    0.]
  [  33.   26.    9.    3.    0.    0.    0.]
  [  53.   34.    4.    1.    8.   10.   19.]
  [  43.   37.    8.    7.   42.   85.   67.]
  [  38.   57.   48.   51.   78.  162.   68.]
  [  23.   16.    6.    6.   40.   73.   52.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.80252045
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 5147, frames: 100077, time: 42151.2520339489
training steps:  11735
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5147 : 0.0
LR:  0.001
replay buffer size:  104934
Time Taken :  702.0  mins 31.25178813934326  seconds
[[[  325.   194.     0.     0.    42.   187.   407.]
  [ 2124.  1521.   366.    90.   188.   240.   222.]
  [ 6126.  4348.  1279.   579.   402.   260.   180.]
  [ 9881.  6731.  1064.    56.   122.   104.    91.]
  [10111.  6826.  1173.   272.   612.   493.   429.]
  [ 7989.  7368.  3178.  1863.  1352.   628.   471.]
  [ 6843.  4405.   901.   251.   439.   370.   391.]]

 [[    1.     0.     0.     0.     0.     0.     0.]
  [   13.    10.     3.     0.     0.     0.     0.]
  [   39.    34.    14.     5.     0.     0.     0.]
  [   65.    39.     7.     1.     9.    10.    20.]
  [   59.    47.     9.    11.    46.    93.    69.]
  [   44.    73.    58.    64.    90.   184.    75.]
  [   24.    19.     6.     8.    42.    81.    64.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81020147
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 5710, frames: 110162, time: 45164.32925271988
training steps:  12916
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5710 : 0.0
LR:  0.001
replay buffer size:  115391
Time Taken :  752.0  mins 44.32900094985962  seconds
[[[  343.   218.     0.     0.    43.   198.   426.]
  [ 2269.  1705.   403.    97.   202.   259.   247.]
  [ 6667.  4822.  1414.   646.   435.   276.   194.]
  [10796.  7484.  1191.    63.   132.   113.    98.]
  [11118.  7651.  1328.   296.   668.   555.   511.]
  [ 8703.  8146.  3583.  2094.  1505.   711.   534.]
  [ 7267.  4804.   998.   280.   469.   392.   406.]]

 [[    1.     0.     0.     0.     0.     5.     0.]
  [   18.    11.     3.     1.     0.     2.     1.]
  [   50.    42.    17.     9.     2.     2.     1.]
  [   78.    52.     8.     2.    10.    11.    22.]
  [   76.    66.    11.    11.    49.   101.    81.]
  [   53.    86.    67.    76.   100.   204.    94.]
  [   27.    26.     6.    10.    43.    86.    71.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8074264
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 6253, frames: 120136, time: 48162.06272673607
training steps:  14089
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6253 : 0.0
LR:  0.001
replay buffer size:  125812
Time Taken :  802.0  mins 42.062480211257935  seconds
[[[  366.   235.     0.     0.    47.   209.   436.]
  [ 2467.  1865.   439.   102.   212.   275.   257.]
  [ 7274.  5284.  1556.   723.   466.   289.   200.]
  [11782.  8270.  1316.    75.   141.   116.   108.]
  [12105.  8445.  1466.   335.   720.   604.   573.]
  [ 9302.  8966.  4006.  2337.  1680.   804.   599.]
  [ 7591.  5204.  1075.   315.   518.   432.   440.]]

 [[    1.     0.     0.     0.     0.     5.     0.]
  [   18.    11.     3.     1.     0.     2.     1.]
  [   54.    47.    18.     9.     2.     2.     1.]
  [   90.    62.    10.     2.    10.    12.    22.]
  [   84.    73.    12.    14.    52.   106.    85.]
  [   58.    95.    77.    88.   114.   223.   103.]
  [   27.    29.     8.    11.    50.    92.    72.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81962115
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 6807, frames: 130203, time: 51149.6378159523
training steps:  15262
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6807 : 0.0
LR:  0.001
replay buffer size:  136160
Time Taken :  852.0  mins 29.637563228607178  seconds
[[[  392.   254.     0.     0.    48.   220.   437.]
  [ 2663.  1995.   474.   105.   220.   286.   263.]
  [ 7836.  5732.  1702.   792.   505.   303.   210.]
  [12732.  9015.  1427.    88.   152.   129.   115.]
  [13092.  9266.  1636.   370.   786.   680.   645.]
  [ 9902.  9785.  4468.  2615.  1879.   919.   699.]
  [ 7923.  5563.  1164.   327.   554.   478.   493.]]

 [[    1.     0.     0.     0.     0.     5.     0.]
  [   19.    12.     4.     1.     0.     2.     1.]
  [   61.    53.    21.     9.     2.     2.     1.]
  [   99.    69.    11.     2.    10.    12.    23.]
  [   96.    84.    14.    14.    52.   113.    91.]
  [   71.   111.    86.    95.   124.   242.   116.]
  [   28.    30.     8.    14.    58.   103.    87.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.83080107
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 7352, frames: 140216, time: 54122.727972745895
training steps:  16436
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7352 : 0.0
LR:  0.001
replay buffer size:  146532
Time Taken :  902.0  mins 2.7277252674102783  seconds
[[[  421.   270.     0.     0.    49.   225.   449.]
  [ 2862.  2158.   505.   107.   230.   298.   276.]
  [ 8415.  6204.  1838.   844.   535.   313.   222.]
  [13702.  9775.  1551.   101.   159.   135.   123.]
  [13995. 10081.  1786.   393.   834.   748.   715.]
  [10544. 10629.  4884.  2841.  2032.  1008.   773.]
  [ 8348.  5953.  1258.   359.   595.   510.   548.]]

 [[    1.     1.     0.     0.     0.     5.     0.]
  [   24.    17.     4.     1.     0.     2.     1.]
  [   68.    61.    21.     9.     2.     2.     1.]
  [  114.    81.    11.     2.    10.    12.    24.]
  [  104.   101.    15.    16.    52.   114.    96.]
  [   74.   125.    96.   111.   138.   261.   125.]
  [   30.    32.    10.    16.    62.   112.    99.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8156234
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 7937, frames: 150248, time: 57093.68557214737
training steps:  17614
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7937 : 0.0
LR:  0.001
replay buffer size:  156886
Time Taken :  951.0  mins 33.68531894683838  seconds
[[[  445.   294.     0.     0.    51.   229.   453.]
  [ 3058.  2335.   548.   112.   233.   305.   280.]
  [ 9011.  6707.  2004.   901.   554.   322.   224.]
  [14668. 10591.  1684.   108.   163.   142.   133.]
  [14896. 10922.  1946.   423.   887.   800.   779.]
  [11073. 11444.  5351.  3130.  2219.  1109.   876.]
  [ 8599.  6265.  1348.   395.   660.   578.   633.]]

 [[    1.     2.     0.     0.     0.     5.     0.]
  [   25.    21.     5.     1.     0.     2.     1.]
  [   71.    66.    22.     9.     2.     2.     1.]
  [  121.    88.    12.     2.    10.    14.    26.]
  [  112.   110.    16.    16.    54.   123.   107.]
  [   79.   132.   102.   119.   147.   279.   134.]
  [   32.    35.    11.    17.    63.   117.   109.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81400853
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 8496, frames: 160202, time: 60064.04116296768
training steps:  18779
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8496 : 0.0
LR:  0.001
replay buffer size:  167280
Time Taken :  1001.0  mins 4.040914058685303  seconds
[[[  462.   323.     0.     0.    51.   235.   457.]
  [ 3232.  2505.   588.   114.   234.   318.   296.]
  [ 9572.  7170.  2125.   950.   577.   344.   236.]
  [15623. 11398.  1815.   117.   168.   150.   139.]
  [15883. 11748.  2087.   461.   934.   864.   864.]
  [11652. 12211.  5760.  3399.  2405.  1221.   973.]
  [ 8870.  6567.  1433.   425.   707.   635.   722.]]

 [[    1.     2.     0.     0.     0.     5.     0.]
  [   25.    21.     5.     1.     0.     2.     1.]
  [   74.    68.    22.     9.     2.     2.     1.]
  [  125.   103.    13.     2.    10.    16.    28.]
  [  121.   134.    22.    16.    57.   137.   128.]
  [   82.   149.   121.   135.   167.   307.   143.]
  [   35.    43.    15.    20.    69.   128.   119.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81783694
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 9064, frames: 170190, time: 63058.23660492897
training steps:  19949
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9064 : 0.0
LR:  0.001
replay buffer size:  177575
Time Taken :  1050.0  mins 58.236356258392334  seconds
[[[  492.   342.     0.     0.    52.   252.   462.]
  [ 3442.  2667.   636.   118.   241.   326.   312.]
  [10143.  7641.  2295.  1016.   611.   359.   254.]
  [16695. 12210.  1939.   126.   174.   157.   157.]
  [16778. 12544.  2243.   484.   971.   930.   947.]
  [12146. 12977.  6155.  3609.  2538.  1316.  1062.]
  [ 9142.  6917.  1521.   448.   746.   677.   804.]]

 [[    1.     2.     0.     0.     0.     5.     0.]
  [   28.    24.     5.     1.     0.     2.     1.]
  [   88.    83.    22.     9.     2.     2.     1.]
  [  141.   130.    14.     2.    10.    16.    30.]
  [  144.   168.    26.    18.    61.   152.   147.]
  [   87.   181.   141.   152.   192.   339.   159.]
  [   36.    48.    16.    21.    74.   141.   130.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8008934
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 9649, frames: 180188, time: 66069.3948879242
training steps:  21120
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9649 : 0.0
LR:  0.001
replay buffer size:  187821
Time Taken :  1101.0  mins 9.39463210105896  seconds
[[[  521.   359.     0.     0.    53.   255.   468.]
  [ 3612.  2823.   688.   129.   244.   328.   316.]
  [10841.  8176.  2462.  1089.   633.   371.   258.]
  [17780. 13082.  2069.   135.   181.   162.   168.]
  [17712. 13372.  2404.   505.  1004.   983.  1021.]
  [12674. 13724.  6558.  3832.  2673.  1389.  1132.]
  [ 9383.  7236.  1609.   481.   785.   707.   883.]]

 [[    1.     2.     0.     0.     0.     5.     0.]
  [   28.    24.     5.     1.     0.     2.     1.]
  [   91.    86.    22.     9.     2.     2.     1.]
  [  145.   135.    14.     2.    10.    17.    31.]
  [  146.   175.    28.    21.    61.   158.   165.]
  [   93.   193.   146.   165.   212.   364.   183.]
  [   40.    51.    16.    24.    84.   154.   154.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.80399823
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 10228, frames: 190243, time: 69180.27834582329
training steps:  22295
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10228 : 0.0
LR:  0.001
replay buffer size:  198257
Time Taken :  1153.0  mins 0.2781052589416504  seconds
[[[  554.   365.     0.     0.    55.   266.   475.]
  [ 3783.  2947.   729.   132.   247.   337.   320.]
  [11394.  8584.  2584.  1134.   654.   382.   264.]
  [18798. 13899.  2216.   142.   185.   171.   189.]
  [18627. 14193.  2556.   528.  1045.  1053.  1123.]
  [13240. 14548.  6995.  4093.  2870.  1525.  1243.]
  [ 9722.  7590.  1699.   509.   825.   770.   995.]]

 [[    1.     2.     0.     0.     0.     5.     0.]
  [   28.    24.     5.     1.     0.     2.     1.]
  [   94.    90.    22.     9.     2.     2.     1.]
  [  153.   145.    15.     2.    10.    19.    32.]
  [  150.   183.    30.    23.    62.   166.   178.]
  [   95.   201.   155.   175.   229.   388.   202.]
  [   42.    56.    19.    25.    87.   161.   168.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81047404
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 10810, frames: 200118, time: 71857.71414089203
training steps:  23845
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10810 : 0.0
LR:  0.001
replay buffer size:  200031
Time Taken :  1197.0  mins 37.71393418312073  seconds
[[[  580.   388.     0.     0.    57.   273.   490.]
  [ 3978.  3098.   763.   136.   254.   345.   329.]
  [12001.  9050.  2705.  1185.   674.   391.   268.]
  [19911. 14732.  2353.   144.   191.   178.   201.]
  [19456. 14950.  2719.   576.  1107.  1119.  1208.]
  [13743. 15311.  7402.  4344.  3047.  1635.  1352.]
  [ 9998.  7904.  1774.   539.   855.   817.  1077.]]

 [[    1.     3.     0.     0.     0.     5.     0.]
  [   28.    29.     5.     1.     0.     2.     1.]
  [   96.   101.    22.     9.     2.     2.     1.]
  [  171.   158.    18.     2.    10.    19.    33.]
  [  157.   196.    32.    28.    67.   177.   184.]
  [  100.   218.   172.   191.   243.   409.   219.]
  [   44.    57.    20.    25.    89.   168.   185.]]]
