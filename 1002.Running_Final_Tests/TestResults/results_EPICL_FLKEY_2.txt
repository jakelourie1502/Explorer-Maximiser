EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  0.00350993248866871
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 82, frames: 1255, time: 23.58349609375
training steps:  2
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
82 : 0.0
LR:  1e-06
replay buffer size:  1403
Time Taken :  0.0  mins 23.583314180374146  seconds
[[[ 11.   7.   0.   0.   0.   0.   0.]
  [ 68.  31.   9.   1.   0.   0.   0.]
  [132.  71.  14.   2.   0.   0.   0.]
  [144.  84.  26.   0.   0.   0.   0.]
  [139.  86.  20.   1.   0.   0.   0.]
  [127.  79.  14.   4.   0.   0.   0.]
  [ 53.  43.   6.   1.   0.   0.   0.]]

 [[  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.75172484
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 745, frames: 10191, time: 1689.1026470661163
training steps:  1236
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
745 : 0.0
LR:  0.001
replay buffer size:  10582
Time Taken :  28.0  mins 9.102472305297852  seconds
[[[  79.   62.    0.    0.    0.    0.    0.]
  [ 443.  237.   88.    7.    4.    5.    2.]
  [1005.  576.  152.   26.    8.    1.    0.]
  [1398.  947.  229.    3.    6.    2.    1.]
  [1012.  737.  174.    8.   11.   13.   10.]
  [ 568.  510.  168.   66.   27.   16.   22.]
  [ 330.  269.   63.   21.   11.   27.   62.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    1.    1.]
  [   0.    0.    0.    0.    0.    2.    2.]
  [   0.    0.    0.    0.    0.    4.   10.]
  [   0.    0.    0.    0.    0.    2.   18.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.77721024
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1312, frames: 20147, time: 3691.3674330711365
training steps:  2377
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1312 : 0.0
LR:  0.001
replay buffer size:  20817
Time Taken :  61.0  mins 31.367255210876465  seconds
[[[ 131.  114.    0.    0.    2.    3.    0.]
  [ 771.  544.  166.   13.   13.   12.    5.]
  [1945. 1413.  337.   70.   23.    7.    1.]
  [2824. 2150.  407.   14.   12.    7.    6.]
  [2003. 1622.  298.   15.   31.   30.   19.]
  [ 970.  968.  283.  128.   73.   48.   42.]
  [ 496.  438.   95.   27.   34.   72.   81.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    1.    3.]
  [   0.    0.    1.    0.    2.    7.    6.]
  [   0.    0.    1.    3.    4.   10.   10.]
  [   0.    0.    0.    0.    3.    3.   18.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7852472
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1829, frames: 30137, time: 5681.344717979431
training steps:  3542
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1829 : 0.0
LR:  0.001
replay buffer size:  31110
Time Taken :  94.0  mins 41.34453725814819  seconds
[[[ 165.  151.    0.    0.    5.    9.    9.]
  [1045.  804.  221.   14.   21.   21.   12.]
  [2765. 2193.  487.  116.   46.   19.    7.]
  [4048. 3366.  567.   23.   24.   14.    8.]
  [2945. 2631.  432.   25.   57.   59.   27.]
  [1482. 1558.  424.  189.  113.   78.   52.]
  [ 694.  681.  135.   32.   61.  116.  135.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    4.    6.]
  [   0.    0.    1.    0.    6.   27.   16.]
  [   0.    0.    1.    3.    5.   42.   23.]
  [   0.    0.    0.    0.   11.   39.   38.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.80061036
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2314, frames: 40202, time: 7726.9815311431885
training steps:  4751
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2314 : 0.0
LR:  0.001
replay buffer size:  41475
Time Taken :  128.0  mins 46.98134708404541  seconds
[[[ 206.  189.    0.    0.    8.    9.   16.]
  [1414. 1076.  269.   19.   39.   37.   25.]
  [3609. 3022.  643.  155.   69.   31.   14.]
  [5272. 4590.  737.   29.   30.   17.   11.]
  [3977. 3576.  540.   29.   71.   66.   33.]
  [2090. 2188.  535.  215.  133.   91.   60.]
  [ 982.  932.  179.   35.   72.  142.  184.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    4.    6.]
  [   0.    0.    1.    0.    6.   27.   16.]
  [   0.    0.    1.    3.    5.   42.   23.]
  [   0.    0.    0.    0.   11.   39.   38.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.79553515
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2856, frames: 50119, time: 9679.643005132675
training steps:  5902
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2856 : 0.0
LR:  0.001
replay buffer size:  51597
Time Taken :  161.0  mins 19.642827033996582  seconds
[[[ 251.  214.    0.    0.    9.    9.   16.]
  [1662. 1266.  313.   35.   51.   43.   25.]
  [4297. 3661.  796.  227.  102.   45.   18.]
  [6327. 5627.  895.   39.   37.   28.   17.]
  [4787. 4449.  654.   42.  108.   98.   76.]
  [2623. 2816.  720.  313.  206.  154.  114.]
  [1407. 1295.  246.   51.  112.  292.  348.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    7.    7.]
  [   0.    0.    1.    0.    7.   36.   18.]
  [   0.    0.    1.    3.    5.   64.   28.]
  [   0.    0.    0.    4.   23.   70.   68.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81761
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3374, frames: 60063, time: 11716.720955133438
training steps:  7097
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3374 : 0.0
LR:  0.001
replay buffer size:  61798
Time Taken :  195.0  mins 16.72077512741089  seconds
[[[ 283.  237.    0.    0.   14.   29.   23.]
  [1889. 1437.  354.   44.   71.   75.   48.]
  [4942. 4178.  968.  309.  163.   84.   41.]
  [7296. 6437. 1020.   47.   51.   44.   24.]
  [5571. 5241.  768.   61.  169.  172.  135.]
  [3098. 3441.  950.  451.  362.  279.  214.]
  [1736. 1644.  316.   73.  220.  526.  595.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    1.    9.    9.]
  [   0.    0.    1.    3.   15.   51.   28.]
  [   0.    0.    1.    6.   19.   95.   45.]
  [   0.    0.    0.    9.   42.  114.  111.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8226637
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3910, frames: 70209, time: 13711.960675954819
training steps:  8272
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3910 : 0.0
LR:  0.001
replay buffer size:  72237
Time Taken :  228.0  mins 31.96049404144287  seconds
[[[ 325.  272.    0.    0.   15.   37.   32.]
  [2143. 1664.  392.   50.   79.   88.   61.]
  [5608. 4746. 1096.  352.  197.  105.   53.]
  [8285. 7388. 1155.   53.   61.   56.   31.]
  [6364. 6126.  889.   76.  211.  208.  175.]
  [3670. 4204. 1218.  603.  498.  364.  286.]
  [2108. 2045.  390.   95.  295.  632.  653.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   2.    5.    2.    0.    0.    0.    0.]
  [  10.   10.    1.    1.    1.    1.    3.]
  [  10.   14.    1.    0.    2.    9.   10.]
  [  10.   12.    3.    5.   29.   61.   33.]
  [   8.   15.   16.   15.   35.  125.   52.]
  [   1.    3.    0.   10.   58.  142.  130.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.82463294
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4420, frames: 80165, time: 15760.54369711876
training steps:  9502
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4420 : 0.0
LR:  0.001
replay buffer size:  82393
Time Taken :  262.0  mins 40.54352307319641  seconds
[[[ 352.  291.    0.    0.   15.   42.   37.]
  [2370. 1828.  428.   53.   85.   95.   67.]
  [6152. 5197. 1207.  393.  224.  124.   67.]
  [9112. 8161. 1273.   55.   68.   61.   37.]
  [7111. 6896.  997.  104.  243.  245.  209.]
  [4239. 5050. 1535.  810.  652.  471.  368.]
  [2651. 2611.  498.  124.  401.  786.  796.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   5.    6.    3.    0.    0.    0.    0.]
  [  17.   14.    1.    1.    1.    1.    3.]
  [  23.   23.    3.    0.    3.   12.   11.]
  [  23.   29.    6.    5.   40.   72.   39.]
  [  18.   36.   33.   29.   54.  153.   58.]
  [  14.   16.    2.   10.   71.  173.  146.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8487089
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4848, frames: 90154, time: 17805.716247081757
training steps:  10698
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4848 : 0.0
LR:  0.001
replay buffer size:  92659
Time Taken :  296.0  mins 45.71606922149658  seconds
[[[ 384.  307.    0.    0.   17.   43.   47.]
  [2659. 2010.  466.   55.   96.  109.   86.]
  [6753. 5624. 1299.  429.  253.  150.   94.]
  [9984. 8832. 1368.   60.   73.   67.   46.]
  [7923. 7635. 1085.  119.  282.  309.  277.]
  [4856. 5856. 1827. 1002.  834.  613.  521.]
  [3189. 3098.  577.  148.  494.  914.  972.]]

 [[   2.    0.    0.    0.    0.    0.    0.]
  [  14.   11.    4.    0.    0.    0.    0.]
  [  31.   20.    1.    1.    1.    1.    3.]
  [  45.   31.    3.    0.    3.   13.   12.]
  [  47.   43.    7.    5.   43.   80.   41.]
  [  38.   61.   42.   38.   70.  178.   71.]
  [  25.   27.    2.   13.   83.  192.  162.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8445097
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 5325, frames: 100149, time: 19826.80130290985
training steps:  11914
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5325 : 0.0
LR:  0.001
replay buffer size:  102918
Time Taken :  330.0  mins 26.80112624168396  seconds
[[[  412.   330.     0.     0.    18.    46.    57.]
  [ 2858.  2168.   503.    58.    98.   116.   103.]
  [ 7252.  5987.  1384.   458.   275.   179.   115.]
  [10866.  9516.  1471.    61.    83.    75.    57.]
  [ 8629.  8298.  1187.   143.   346.   369.   353.]
  [ 5375.  6568.  2145.  1225.  1066.   788.   697.]
  [ 3623.  3515.   650.   178.   611.  1081.  1156.]]

 [[    3.     0.     0.     0.     0.     0.     0.]
  [   22.    13.     4.     0.     0.     0.     0.]
  [   40.    24.     2.     2.     2.     2.     4.]
  [   56.    39.     4.     0.     6.    15.    14.]
  [   68.    60.     8.     5.    60.   108.    67.]
  [   58.   101.    82.    75.   129.   265.   132.]
  [   54.    45.     5.    21.   159.   277.   244.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.84704584
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 5734, frames: 110049, time: 21885.47488808632
training steps:  13128
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5734 : 0.0
LR:  0.001
replay buffer size:  113065
Time Taken :  364.0  mins 45.47470808029175  seconds
[[[  441.   345.     0.     0.    20.    54.    70.]
  [ 3069.  2319.   534.    64.   106.   134.   133.]
  [ 7762.  6339.  1489.   534.   352.   251.   182.]
  [11584. 10090.  1537.    66.    99.    80.    62.]
  [ 9269.  8909.  1277.   162.   397.   420.   423.]
  [ 5950.  7327.  2491.  1489.  1334.   994.   892.]
  [ 4185.  4032.   717.   209.   735.  1265.  1342.]]

 [[    3.     1.     0.     0.     0.     0.     0.]
  [   23.    16.     4.     0.     0.     0.     0.]
  [   49.    32.     2.     2.     2.     2.     4.]
  [   77.    62.     6.     0.     6.    17.    16.]
  [   93.    94.    10.     7.    66.   121.    80.]
  [   71.   138.   110.   105.   162.   310.   165.]
  [   74.    66.     7.    24.   174.   304.   275.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8491067
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 6165, frames: 120183, time: 23954.799347877502
training steps:  14284
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6165 : 0.0
LR:  0.001
replay buffer size:  123664
Time Taken :  399.0  mins 14.79917311668396  seconds
[[[  471.   366.     0.     0.    21.    57.    74.]
  [ 3265.  2441.   557.    68.   110.   142.   147.]
  [ 8225.  6645.  1560.   582.   402.   289.   217.]
  [12331. 10677.  1614.    70.   110.    85.    71.]
  [10025.  9585.  1380.   185.   437.   493.   510.]
  [ 6540.  8173.  2885.  1749.  1574.  1188.  1060.]
  [ 4792.  4627.   798.   229.   837.  1447.  1545.]]

 [[    4.     2.     0.     0.     0.     0.     0.]
  [   33.    23.     5.     0.     0.     1.     1.]
  [   66.    42.     6.     7.     6.     6.     8.]
  [   97.    80.     7.     0.     6.    17.    18.]
  [  107.   115.    12.     8.    76.   132.    92.]
  [   88.   172.   133.   130.   200.   367.   195.]
  [  112.   102.    10.    28.   196.   343.   309.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8660527
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 6611, frames: 130168, time: 25998.885080099106
training steps:  15489
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6611 : 0.0
LR:  0.001
replay buffer size:  133996
Time Taken :  433.0  mins 18.884899139404297  seconds
[[[  507.   384.     0.     0.    24.    66.    89.]
  [ 3513.  2580.   581.    71.   122.   168.   180.]
  [ 8781.  7010.  1648.   644.   465.   348.   262.]
  [13130. 11282.  1704.    80.   117.    95.    96.]
  [10788. 10224.  1458.   202.   477.   581.   638.]
  [ 7194.  9020.  3209.  1945.  1776.  1360.  1208.]
  [ 5338.  5193.   887.   244.   889.  1537.  1641.]]

 [[    4.     2.     0.     0.     0.     0.     0.]
  [   45.    28.     8.     0.     0.     1.     1.]
  [   78.    49.     8.     7.     6.     6.     8.]
  [  108.    87.     8.     0.     7.    17.    20.]
  [  116.   127.    13.     8.    78.   150.   119.]
  [  103.   198.   154.   157.   236.   417.   226.]
  [  124.   118.    14.    33.   214.   369.   329.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8531808
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 7042, frames: 140090, time: 28020.73740005493
training steps:  16685
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7042 : 0.0
LR:  0.001
replay buffer size:  144172
Time Taken :  467.0  mins 0.7372252941131592  seconds
[[[  532.   401.     0.     0.    28.    79.   128.]
  [ 3718.  2708.   615.    76.   135.   205.   250.]
  [ 9342.  7388.  1795.   746.   571.   460.   366.]
  [13984. 11863.  1787.    83.   128.   107.   118.]
  [11438. 10782.  1540.   219.   523.   677.   770.]
  [ 7708.  9707.  3499.  2170.  1996.  1578.  1397.]
  [ 5714.  5555.   948.   272.   957.  1662.  1766.]]

 [[    6.     2.     0.     0.     0.     0.     0.]
  [   75.    41.     8.     2.     1.     3.     4.]
  [   97.    69.    16.    13.    16.    14.    13.]
  [  130.   109.    10.     0.    10.    19.    24.]
  [  137.   154.    14.     9.    86.   181.   148.]
  [  127.   246.   183.   194.   287.   497.   275.]
  [  141.   146.    16.    36.   237.   394.   367.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.86575866
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 7503, frames: 150160, time: 30042.633517980576
training steps:  17872
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7503 : 0.0
LR:  0.001
replay buffer size:  154503
Time Taken :  500.0  mins 42.633339166641235  seconds
[[[  563.   415.     0.     0.    31.    95.   165.]
  [ 3946.  2846.   649.    79.   144.   236.   321.]
  [ 9920.  7791.  1947.   859.   679.   565.   472.]
  [14813. 12485.  1896.    93.   143.   121.   143.]
  [12210. 11386.  1618.   244.   573.   764.   875.]
  [ 8323. 10465.  3826.  2368.  2188.  1761.  1559.]
  [ 6163.  5992.  1014.   287.  1017.  1785.  1893.]]

 [[    8.     2.     0.     0.     0.     0.     0.]
  [   87.    42.     8.     3.     1.     3.     4.]
  [  111.    75.    18.    15.    18.    16.    13.]
  [  143.   113.    10.     0.    10.    21.    27.]
  [  151.   164.    16.    11.    88.   195.   155.]
  [  137.   263.   200.   211.   317.   541.   300.]
  [  145.   150.    18.    40.   266.   420.   393.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.84865767
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 7965, frames: 160184, time: 32054.00627708435
training steps:  19046
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7965 : 0.0
LR:  0.001
replay buffer size:  164794
Time Taken :  534.0  mins 14.00609827041626  seconds
[[[  601.   427.     0.     0.    31.   108.   190.]
  [ 4219.  3019.   684.    86.   157.   272.   372.]
  [10559.  8206.  2087.   958.   781.   652.   540.]
  [15675. 13025.  1972.   100.   162.   138.   166.]
  [12954. 11908.  1707.   271.   631.   875.   973.]
  [ 8864. 11104.  4156.  2604.  2420.  1981.  1761.]
  [ 6503.  6296.  1084.   308.  1097.  1918.  2040.]]

 [[    8.     3.     0.     0.     0.     0.     0.]
  [  106.    58.    11.     4.     2.     5.     8.]
  [  142.    94.    28.    24.    24.    21.    18.]
  [  165.   128.    10.     1.    13.    21.    28.]
  [  172.   181.    19.    15.   100.   221.   182.]
  [  175.   303.   231.   247.   363.   602.   338.]
  [  160.   162.    18.    42.   272.   434.   418.]]]
Test reward:  0.05
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  10
maxi score:  0.0021
siam score:  -0.9466567
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0041}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.00398321764
rdn probs:  [0.08337167008840367, 0.08337167008840367, 0.08337167008840367, 0.08337167008840367, 0.08337167008840367, 0.5831416495579818]
Episodes: 8398, frames: 170263, time: 34261.20900297165
training steps:  20244
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8398 : 0.0
LR:  0.001
replay buffer size:  176643
Time Taken :  571.0  mins 1.2088251113891602  seconds
[[[  635.   441.     0.     0.    36.   140.   258.]
  [ 4495.  3218.   726.    98.   196.   346.   505.]
  [11201.  8677.  2299.  1114.   941.   810.   671.]
  [16548. 13576.  2053.   106.   176.   158.   192.]
  [13681. 12417.  1783.   294.   687.   964.  1083.]
  [ 9432. 11726.  4411.  2794.  2601.  2149.  1915.]
  [ 6910.  6646.  1134.   322.  1142.  1996.  2142.]]

 [[    9.     4.     0.     0.     0.     0.     2.]
  [  124.    67.    13.     4.     3.     6.    12.]
  [  159.   104.    31.    26.    28.    25.    22.]
  [  181.   137.    10.     1.    13.    21.    30.]
  [  193.   192.    23.    16.   109.   234.   200.]
  [  192.   326.   250.   267.   396.   648.   376.]
  [  168.   172.    18.    43.   281.   448.   436.]]]
Test reward:  0.05
Q value #end_state_>_threshold:  1
Q value #non_end_state_>threshold:  19
maxi score:  0.0041
siam score:  -0.94580126
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0061}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.005415
rdn probs:  [0.0714757035746026, 0.0714757035746026, 0.0714757035746026, 0.2142621482126987, 0.0714757035746026, 0.49983503748889085]
Episodes: 8765, frames: 180118, time: 36408.71747088432
training steps:  21582
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8765 : 0.0
LR:  0.001
replay buffer size:  187165
Time Taken :  606.0  mins 48.717292070388794  seconds
[[[  661.   461.     0.     0.    43.   171.   328.]
  [ 4803.  3393.   760.   107.   220.   423.   640.]
  [11815.  9050.  2514.  1302.  1114.   989.   833.]
  [17193. 13995.  2108.   114.   185.   172.   219.]
  [14295. 12815.  1836.   316.   741.  1073.  1230.]
  [ 9932. 12331.  4707.  3033.  2847.  2362.  2160.]
  [ 7303.  6970.  1165.   341.  1195.  2085.  2259.]]

 [[   12.     9.     0.     0.     1.     1.     4.]
  [  138.    81.    14.     4.     6.    12.    19.]
  [  178.   121.    43.    37.    36.    38.    33.]
  [  203.   148.    10.     2.    14.    24.    31.]
  [  212.   208.    24.    22.   126.   268.   226.]
  [  216.   362.   272.   300.   443.   725.   430.]
  [  183.   192.    18.    47.   297.   482.   472.]]]
Test reward:  0.2
Q value #end_state_>_threshold:  14
Q value #non_end_state_>threshold:  53
maxi score:  0.0141
siam score:  -0.9263692
Scores:  {'0.333': 0.0001, '0.667': 0.0021, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0021, '2.0': 0.0121}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.01083
rdn probs:  [0.0667164147588074, 0.13334991603071358, 0.0667164147588074, 0.13334991603071358, 0.13334991603071358, 0.46651742239024446]
Episodes: 9149, frames: 190210, time: 38489.4427189827
training steps:  23084
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9149 : 0.0
LR:  0.001
replay buffer size:  197905
Time Taken :  641.0  mins 29.442541122436523  seconds
[[[  698.   476.     0.     0.    51.   195.   392.]
  [ 5161.  3596.   792.   116.   242.   492.   767.]
  [12431.  9436.  2712.  1485.  1265.  1139.   996.]
  [17939. 14424.  2177.   123.   193.   192.   247.]
  [14862. 13180.  1885.   330.   788.  1191.  1400.]
  [10428. 12885.  4970.  3223.  3034.  2562.  2362.]
  [ 7641.  7274.  1197.   353.  1237.  2159.  2392.]]

 [[   14.    11.     0.     0.     4.     8.    10.]
  [  177.   106.    15.     6.     7.    23.    46.]
  [  214.   156.    70.    64.    63.    73.    74.]
  [  245.   168.    11.     3.    17.    26.    34.]
  [  260.   227.    24.    25.   142.   317.   284.]
  [  264.   400.   302.   333.   499.   842.   540.]
  [  203.   204.    20.    50.   318.   534.   538.]]]
Test reward:  0.35
Q value #end_state_>_threshold:  118
Q value #non_end_state_>threshold:  193
maxi score:  0.032100000000000004
siam score:  -0.9284025
Scores:  {'0.333': 0.0001, '0.667': 0.0061, '1.0': 0.0141, '1.333': 0.0121, '1.667': 0.0021, '2.0': 0.0161}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.010240000000000003
rdn probs:  [0.04048194990719114, 0.13133494597401352, 0.25247227406310996, 0.22218794204083586, 0.07076628192946527, 0.28275660608538417]
Episodes: 9484, frames: 200109, time: 40595.08303809166
training steps:  24575
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9484 : 0.1
LR:  0.001
replay buffer size:  200102
Time Taken :  676.0  mins 35.08286118507385  seconds
[[[  717.   491.     0.     0.    56.   234.   473.]
  [ 5414.  3753.   816.   123.   261.   556.   913.]
  [12810.  9757.  2868.  1614.  1388.  1293.  1173.]
  [18520. 14781.  2216.   130.   202.   204.   271.]
  [15460. 13518.  1932.   344.   839.  1280.  1530.]
  [10932. 13350.  5203.  3408.  3214.  2741.  2531.]
  [ 7923.  7513.  1225.   370.  1275.  2244.  2509.]]

 [[   17.    11.     0.     0.     4.    19.    28.]
  [  233.   157.    15.     7.    13.    44.   107.]
  [  275.   228.   134.   131.   132.   159.   223.]
  [  309.   205.    14.     3.    24.    37.    41.]
  [  305.   260.    26.    29.   204.   411.   375.]
  [  317.   479.   364.   403.   634.  1051.   702.]
  [  225.   227.    24.    56.   363.   601.   624.]]]
Test reward:  0.8
Q value #end_state_>_threshold:  484
Q value #non_end_state_>threshold:  1121
maxi score:  0.0721
siam score:  -0.90932757
Scores:  {'0.333': 0.0061, '0.667': 0.0141, '1.0': 0.0621, '1.333': 0.048100000000000004, '1.667': 0.0061, '2.0': 0.022099999999999998}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.026195
rdn probs:  [0.05251624512529311, 0.09742788638747289, 0.3668977339605515, 0.2883023617517368, 0.05251624512529311, 0.14233952764965266]
Episodes: 9754, frames: 210148, time: 42732.4629471302
training steps:  26079
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9754 : 0.3
LR:  0.001
replay buffer size:  200088
Time Taken :  712.0  mins 12.462773084640503  seconds
[[[  725.   494.     0.     0.    61.   255.   522.]
  [ 5540.  3848.   835.   128.   267.   586.   976.]
  [13112.  9984.  2956.  1689.  1470.  1379.  1273.]
  [18987. 15057.  2242.   132.   208.   210.   286.]
  [15872. 13785.  1960.   355.   880.  1357.  1625.]
  [11280. 13768.  5459.  3612.  3419.  2940.  2658.]
  [ 8167.  7703.  1240.   374.  1296.  2291.  2576.]]

 [[   17.    14.     0.     0.     6.    42.    89.]
  [  358.   267.    18.    10.    27.   112.   312.]
  [  436.   431.   252.   241.   275.   358.   521.]
  [  435.   313.    18.     6.    28.    42.    47.]
  [  435.   354.    29.    34.   282.   538.   500.]
  [  429.   636.   498.   534.   834.  1366.   937.]
  [  270.   266.    31.    61.   418.   681.   747.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1032
Q value #non_end_state_>threshold:  3217
maxi score:  0.14809999999999998
siam score:  -0.9200684
Scores:  {'0.333': 0.0121, '0.667': 0.0281, '1.0': 0.1401, '1.333': 0.0801, '1.667': 0.0161, '2.0': 0.026099999999999998}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.005599999999999997
rdn probs:  [0.05966611361337332, 0.10432721401822619, 0.4169549168521963, 0.24947579033399797, 0.07083138871458654, 0.0987445764676196]
Episodes: 10000, frames: 220102, time: 44737.460487127304
training steps:  27440
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10000 : 0.4
LR:  0.001
replay buffer size:  200045
Time Taken :  745.0  mins 37.460307359695435  seconds
[[[  731.   495.     0.     0.    61.   255.   522.]
  [ 5604.  3891.   840.   131.   269.   590.   989.]
  [13263. 10075.  2986.  1712.  1482.  1391.  1297.]
  [19253. 15237.  2253.   134.   209.   216.   293.]
  [16217. 13964.  1971.   364.   942.  1478.  1789.]
  [11572. 14132.  5762.  3869.  3683.  3238.  2865.]
  [ 8269.  7784.  1249.   382.  1323.  2381.  2678.]]

 [[   19.    18.     0.     0.     9.   112.   179.]
  [  514.   410.    23.    11.    69.   288.   662.]
  [  588.   677.   414.   421.   480.   624.   890.]
  [  572.   454.    23.     8.    28.    51.    66.]
  [  560.   499.    40.    39.   321.   663.   618.]
  [  543.   851.   695.   739.  1082.  1752.  1128.]
  [  317.   310.    35.    67.   483.   805.   854.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1597
Q value #non_end_state_>threshold:  6518
maxi score:  0.20609999999999998
siam score:  -0.91306084
Scores:  {'0.333': 0.040100000000000004, '0.667': 0.0621, '1.0': 0.17609999999999998, '1.333': 0.1041, '1.667': 0.040100000000000004, '2.0': 0.0521}
best rdn ma / adv:  1.0 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 10226, frames: 230124, time: 46269.11831498146
training steps:  28396
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10226 : 0.5
LR:  0.001
replay buffer size:  200074
Time Taken :  771.0  mins 9.118136167526245  seconds
[[[  732.   496.     0.     0.    61.   256.   528.]
  [ 5649.  3905.   842.   132.   271.   592.   994.]
  [13345. 10123.  3000.  1721.  1489.  1396.  1303.]
  [19439. 15372.  2256.   134.   211.   224.   299.]
  [16469. 14168.  1983.   376.   996.  1628.  2000.]
  [11818. 14504.  6057.  4161.  3973.  3577.  3112.]
  [ 8359.  7858.  1252.   387.  1353.  2463.  2792.]]

 [[   22.    23.     0.     0.    17.   214.   276.]
  [  725.   590.    26.    16.   131.   498.   965.]
  [  785.   982.   637.   651.   722.   918.  1236.]
  [  753.   606.    27.    11.    32.    58.    81.]
  [  725.   654.    43.    48.   375.   756.   710.]
  [  666.  1065.   898.   957.  1350.  2132.  1297.]
  [  354.   338.    37.    69.   551.   891.   924.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2170
Q value #non_end_state_>threshold:  9379
maxi score:  0.28609999999999997
siam score:  -0.8913448
Scores:  {'0.333': 0.0601, '0.667': 0.0821, '1.0': 0.20809999999999998, '1.333': 0.1261, '1.667': 0.07010000000000001, '2.0': 0.0801}
best rdn ma / adv:  1.0 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 10457, frames: 240119, time: 47710.34564614296
training steps:  29270
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10457 : 0.4
LR:  0.001
replay buffer size:  200031
Time Taken :  795.0  mins 10.345461130142212  seconds
[[[  733.   497.     0.     0.    61.   261.   535.]
  [ 5670.  3922.   843.   133.   271.   599.  1002.]
  [13429. 10191.  3013.  1735.  1501.  1412.  1311.]
  [19590. 15520.  2261.   135.   211.   228.   306.]
  [16724. 14363.  1999.   382.  1037.  1758.  2153.]
  [12049. 14899.  6376.  4448.  4261.  3902.  3346.]
  [ 8445.  7958.  1260.   392.  1395.  2553.  2924.]]

 [[   26.    29.     0.     0.    23.   354.   371.]
  [  898.   706.    34.    23.   186.   688.  1273.]
  [  966.  1255.   839.   846.   990.  1183.  1555.]
  [  930.   771.    30.    14.    33.    65.    89.]
  [  885.   822.    50.    56.   436.   892.   800.]
  [  789.  1331.  1134.  1205.  1637.  2490.  1444.]
  [  428.   393.    41.    76.   614.   988.   980.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2804
Q value #non_end_state_>threshold:  12740
maxi score:  0.3741
siam score:  -0.856629
Scores:  {'0.333': 0.0821, '0.667': 0.1101, '1.0': 0.2301, '1.333': 0.14609999999999998, '1.667': 0.1041, '2.0': 0.11410000000000001}
best rdn ma / adv:  1.0 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 10692, frames: 250174, time: 49189.80772399902
training steps:  30144
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10692 : 0.5
LR:  0.001
replay buffer size:  200054
Time Taken :  819.0  mins 49.80754518508911  seconds
[[[  735.   497.     0.     0.    61.   261.   535.]
  [ 5703.  3939.   843.   133.   271.   599.  1002.]
  [13518. 10236.  3015.  1735.  1501.  1412.  1311.]
  [19795. 15689.  2266.   135.   214.   232.   310.]
  [17024. 14578.  2014.   389.  1098.  1893.  2327.]
  [12265. 15277.  6691.  4752.  4561.  4253.  3587.]
  [ 8502.  8039.  1263.   398.  1442.  2678.  3072.]]

 [[   27.    31.     0.     0.    32.   524.   478.]
  [ 1055.   852.    41.    28.   240.   908.  1599.]
  [ 1138.  1555.  1038.  1073.  1259.  1453.  1841.]
  [ 1063.   977.    41.    17.    38.    75.    94.]
  [  988.  1013.    58.    63.   497.   971.   875.]
  [  885.  1591.  1378.  1451.  1962.  2846.  1558.]
  [  475.   440.    43.    80.   687.  1067.  1026.]]]
