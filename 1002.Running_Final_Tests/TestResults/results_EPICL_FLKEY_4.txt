EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  0.008257237950932573
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 98, frames: 1449, time: 23.975815057754517
training steps:  2
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
98 : 0.0
LR:  1e-06
replay buffer size:  1619
Time Taken :  0.0  mins 23.975643157958984  seconds
[[[ 10.   4.   0.   0.   1.   0.   0.]
  [ 41.  35.  12.   3.   4.   0.   0.]
  [149.  90.  25.  11.   2.   0.   0.]
  [208. 120.  27.   2.   1.   0.   0.]
  [163.  79.  25.   1.   0.   0.   0.]
  [105.  59.  27.   4.   1.   0.   0.]
  [ 93.  37.  11.   1.   0.   0.   0.]]

 [[  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81037325
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 504, frames: 10086, time: 1331.173448085785
training steps:  1245
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
504 : 0.0
LR:  0.001
replay buffer size:  10568
Time Taken :  22.0  mins 11.173285245895386  seconds
[[[  44.   25.    0.    0.    2.    0.    0.]
  [ 243.  147.   40.    7.    6.    0.    0.]
  [ 780.  391.  106.   47.   16.    3.    0.]
  [1429.  670.  144.    7.    1.    2.    0.]
  [1670.  599.  115.    6.    3.    2.    0.]
  [1023.  455.  142.   32.   20.    9.    1.]
  [ 904.  326.   90.   12.   30.   33.    0.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.85692424
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 797, frames: 20230, time: 3103.427919149399
training steps:  2405
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
797 : 0.0
LR:  0.001
replay buffer size:  20934
Time Taken :  51.0  mins 43.427749156951904  seconds
[[[  69.   31.    0.    0.    3.    3.    1.]
  [ 437.  230.   60.   11.   10.    3.    3.]
  [1427.  756.  179.   95.   33.    9.    7.]
  [2932. 1384.  210.   15.    8.    8.    4.]
  [3622. 1349.  183.    9.   16.   13.    1.]
  [2295.  934.  248.   83.   51.   28.    9.]
  [1753.  614.  133.   24.   50.   84.    6.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.85085374
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1144, frames: 30112, time: 5177.4519991874695
training steps:  3756
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1144 : 0.0
LR:  0.001
replay buffer size:  31084
Time Taken :  86.0  mins 17.451828956604004  seconds
[[[ 109.   50.    0.    0.    3.    5.    4.]
  [ 704.  374.   85.   16.   12.    4.    6.]
  [2255. 1122.  234.  111.   48.   17.   12.]
  [4452. 1993.  308.   18.   10.   11.    6.]
  [5330. 1939.  252.   14.   27.   21.    5.]
  [3417. 1388.  353.  131.   75.   39.   15.]
  [2644.  946.  179.   39.   70.   95.   20.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.85172975
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1532, frames: 40131, time: 7278.068866968155
training steps:  4735
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1532 : 0.0
LR:  0.001
replay buffer size:  41322
Time Taken :  121.0  mins 18.068695068359375  seconds
[[[ 140.   72.    0.    0.    5.   10.    5.]
  [1046.  549.  126.   22.   15.    8.    6.]
  [3089. 1571.  329.  137.   60.   21.   13.]
  [5765. 2658.  403.   23.   17.   15.    8.]
  [6739. 2537.  331.   26.   46.   43.   17.]
  [4406. 1903.  495.  212.  129.   69.   35.]
  [3530. 1327.  240.   54.  132.  141.   45.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    1.    0.    1.]
  [   0.    0.    0.    0.    4.    4.    2.]
  [   0.    0.    0.    0.    2.    4.    2.]
  [   0.    0.    0.    0.    1.    3.    5.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.87644625
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1923, frames: 50153, time: 9799.43518614769
training steps:  6012
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1923 : 0.0
LR:  0.001
replay buffer size:  51717
Time Taken :  163.0  mins 19.435026168823242  seconds
[[[ 180.   92.    0.    0.   10.   15.   12.]
  [1362.  747.  160.   28.   24.   21.   21.]
  [3942. 2067.  434.  173.   86.   31.   21.]
  [7086. 3336.  498.   29.   27.   21.   10.]
  [8016. 3160.  407.   44.   74.   73.   28.]
  [5410. 2497.  638.  301.  192.  103.   45.]
  [4225. 1729.  290.   66.  167.  177.   58.]]

 [[   0.    1.    0.    0.    0.    0.    0.]
  [   0.    1.    0.    0.    0.    0.    0.]
  [   0.    2.    0.    0.    0.    0.    0.]
  [   0.    2.    0.    0.    1.    2.    1.]
  [   0.    2.    0.    0.    7.   11.    4.]
  [   0.    2.    3.    2.   10.   14.    3.]
  [   0.    0.    1.    2.    7.    9.   10.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.86347663
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2352, frames: 60121, time: 12179.828967094421
training steps:  7243
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2352 : 0.0
LR:  0.001
replay buffer size:  62015
Time Taken :  202.0  mins 59.82880210876465  seconds
[[[ 216.  119.    0.    0.   15.   30.   16.]
  [1618.  900.  190.   35.   31.   32.   32.]
  [4646. 2449.  505.  207.  108.   41.   31.]
  [8283. 4024.  603.   34.   32.   25.   11.]
  [9201. 3844.  503.   56.  106.  110.   41.]
  [6290. 3146.  826.  404.  284.  152.   74.]
  [5006. 2233.  361.   83.  231.  222.  106.]]

 [[   0.    1.    0.    0.    0.    0.    0.]
  [   1.    3.    0.    0.    0.    0.    0.]
  [   2.    7.    0.    0.    0.    0.    0.]
  [   3.    6.    0.    0.    2.    4.    3.]
  [  10.    9.    0.    1.    8.   23.   11.]
  [   4.    6.    6.    6.   14.   37.   15.]
  [   4.    1.    1.    3.   15.   25.   26.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8668721
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2731, frames: 70080, time: 14371.194991111755
training steps:  8587
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2731 : 0.0
LR:  0.001
replay buffer size:  72193
Time Taken :  239.0  mins 31.194822311401367  seconds
[[[  258.   137.     0.     0.    16.    36.    19.]
  [ 1865.  1023.   211.    43.    35.    39.    33.]
  [ 5346.  2843.   583.   242.   123.    46.    32.]
  [ 9522.  4680.   682.    41.    45.    27.    11.]
  [10571.  4494.   580.    69.   148.   141.    56.]
  [ 7310.  3810.   997.   519.   395.   209.   109.]
  [ 5724.  2664.   429.   102.   325.   296.   155.]]

 [[    0.     1.     0.     0.     0.     0.     0.]
  [    1.     3.     0.     0.     0.     0.     0.]
  [    2.     7.     0.     0.     0.     0.     0.]
  [    3.     6.     0.     0.     2.     4.     3.]
  [   10.     9.     0.     1.     9.    26.    11.]
  [    4.     6.     6.     7.    20.    46.    22.]
  [    4.     1.     1.     6.    20.    33.    34.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8676085
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3162, frames: 80058, time: 16554.70558810234
training steps:  9912
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3162 : 0.0
LR:  0.001
replay buffer size:  82440
Time Taken :  275.0  mins 54.705419063568115  seconds
[[[  288.   159.     0.     0.    18.    42.    20.]
  [ 2153.  1214.   257.    48.    40.    42.    40.]
  [ 6105.  3325.   649.   260.   136.    53.    37.]
  [10796.  5430.   790.    42.    56.    32.    15.]
  [11757.  5128.   658.    86.   192.   175.    81.]
  [ 8212.  4376.  1179.   639.   478.   253.   136.]
  [ 6428.  3050.   506.   115.   347.   325.   173.]]

 [[    0.     2.     0.     0.     0.     0.     0.]
  [   12.    10.     1.     0.     0.     0.     0.]
  [   12.    13.     0.     0.     0.     0.     0.]
  [   21.    16.     0.     0.     3.     4.     4.]
  [   20.    20.     1.     3.    14.    31.    16.]
  [   18.    19.    11.    13.    30.    71.    38.]
  [   14.     3.     2.     7.    27.    46.    53.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.86275154
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3582, frames: 90176, time: 18971.53402209282
training steps:  11252
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3582 : 0.0
LR:  0.001
replay buffer size:  92784
Time Taken :  316.0  mins 11.533857107162476  seconds
[[[  323.   171.     0.     0.    19.    43.    20.]
  [ 2389.  1385.   295.    51.    42.    45.    48.]
  [ 6745.  3758.   743.   298.   153.    62.    50.]
  [11887.  6110.   876.    48.    63.    38.    19.]
  [12910.  5827.   748.   104.   229.   200.    94.]
  [ 9168.  5120.  1433.   803.   589.   319.   173.]
  [ 7151.  3557.   590.   135.   381.   388.   229.]]

 [[    1.     2.     0.     0.     0.     0.     0.]
  [   15.    13.     1.     0.     0.     0.     0.]
  [   22.    19.     0.     0.     0.     0.     0.]
  [   38.    24.     0.     0.     4.     4.     4.]
  [   41.    30.     3.     3.    25.    35.    17.]
  [   36.    31.    18.    22.    41.    81.    41.]
  [   27.    13.     2.     7.    36.    51.    58.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.86612964
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3962, frames: 100103, time: 20918.47257208824
training steps:  12215
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3962 : 0.0
LR:  0.001
replay buffer size:  102968
Time Taken :  348.0  mins 38.47240614891052  seconds
[[[  351.   189.     0.     0.    19.    49.    24.]
  [ 2613.  1510.   327.    57.    46.    53.    49.]
  [ 7367.  4126.   844.   326.   171.    71.    59.]
  [12988.  6678.   967.    50.    69.    41.    23.]
  [14171.  6421.   822.   115.   246.   216.   120.]
  [10154.  5828.  1677.   957.   692.   372.   205.]
  [ 8055.  4137.   665.   152.   422.   441.   286.]]

 [[    1.     2.     0.     0.     0.     0.     0.]
  [   23.    14.     2.     0.     0.     0.     0.]
  [   32.    20.     1.     2.     2.     1.     0.]
  [   49.    27.     0.     0.     4.     5.     4.]
  [   50.    37.     4.     3.    27.    39.    18.]
  [   47.    39.    24.    31.    49.    94.    42.]
  [   40.    17.     2.     8.    38.    60.    62.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.86934906
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4330, frames: 110081, time: 22850.208970308304
training steps:  13130
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4330 : 0.0
LR:  0.001
replay buffer size:  113161
Time Taken :  380.0  mins 50.208800077438354  seconds
[[[  375.   204.     0.     0.    23.    55.    41.]
  [ 2831.  1626.   355.    64.    54.    64.    58.]
  [ 8020.  4490.   948.   384.   209.   100.    79.]
  [13957.  7280.  1045.    53.    77.    44.    26.]
  [15102.  6977.   891.   131.   276.   246.   144.]
  [11012.  6516.  1966.  1158.   843.   461.   258.]
  [ 8992.  4660.   737.   171.   494.   542.   396.]]

 [[    1.     2.     0.     0.     0.     0.     0.]
  [   32.    16.     2.     1.     0.     0.     0.]
  [   49.    26.     3.     5.     2.     1.     0.]
  [   74.    39.     0.     0.     4.     5.     5.]
  [   83.    57.    10.     5.    30.    42.    20.]
  [   85.    66.    44.    54.    69.   114.    55.]
  [   82.    28.     3.    11.    49.    70.    72.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8696794
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4755, frames: 120143, time: 24635.346513032913
training steps:  14104
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4755 : 0.0
LR:  0.001
replay buffer size:  123499
Time Taken :  410.0  mins 35.346351146698  seconds
[[[  400.   218.     0.     0.    23.    60.    43.]
  [ 3076.  1770.   378.    74.    60.    73.    67.]
  [ 8738.  4913.  1052.   447.   251.   140.   114.]
  [14975.  7932.  1145.    60.    82.    53.    35.]
  [16015.  7591.   979.   144.   308.   278.   173.]
  [11802.  7252.  2295.  1333.   969.   519.   301.]
  [ 9831.  5210.   823.   195.   540.   588.   448.]]

 [[    2.     2.     0.     0.     0.     0.     0.]
  [   37.    17.     2.     2.     2.     5.     0.]
  [   60.    33.     5.     6.     7.     6.     2.]
  [   84.    44.     1.     0.     4.     5.     6.]
  [  101.    67.    12.     5.    35.    50.    23.]
  [   99.    86.    60.    71.    89.   136.    66.]
  [   99.    38.     5.    13.    57.    82.    89.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8693907
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 5157, frames: 130224, time: 26892.66803908348
training steps:  15473
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5157 : 0.0
LR:  0.001
replay buffer size:  133929
Time Taken :  448.0  mins 12.667871952056885  seconds
[[[  418.   236.     0.     0.    29.    79.    70.]
  [ 3307.  1936.   415.    80.    76.   111.   108.]
  [ 9359.  5332.  1178.   518.   319.   204.   167.]
  [15877.  8542.  1240.    63.    93.    65.    43.]
  [16893.  8135.  1056.   161.   376.   344.   235.]
  [12549.  7942.  2567.  1506.  1122.   598.   377.]
  [10939.  5802.   895.   206.   579.   650.   516.]]

 [[    3.     2.     0.     0.     0.     0.     0.]
  [   43.    18.     3.     2.     2.     5.     0.]
  [   70.    37.     8.     6.     7.     6.     2.]
  [   91.    47.     1.     0.     4.     5.     6.]
  [  116.    70.    12.     6.    39.    53.    29.]
  [  105.    95.    65.    73.    97.   142.    71.]
  [  108.    42.     5.    14.    62.    86.    96.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8695355
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 5556, frames: 140141, time: 29091.24040913582
training steps:  16830
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5556 : 0.0
LR:  0.001
replay buffer size:  144087
Time Taken :  484.0  mins 51.240241289138794  seconds
[[[  452.   250.     0.     0.    35.   110.   121.]
  [ 3541.  2063.   446.    92.    96.   142.   156.]
  [10021.  5788.  1358.   644.   429.   308.   280.]
  [16747.  9103.  1331.    69.   106.    76.    53.]
  [17766.  8668.  1127.   181.   444.   405.   287.]
  [13198.  8616.  2863.  1712.  1287.   671.   452.]
  [11814.  6317.   953.   220.   616.   703.   560.]]

 [[    3.     2.     0.     0.     0.     0.     0.]
  [   45.    18.     3.     2.     2.     5.     0.]
  [   82.    40.     9.     7.     9.     7.     3.]
  [   93.    48.     1.     0.     5.     6.     9.]
  [  120.    74.    13.     7.    43.    61.    39.]
  [  110.   101.    71.    79.   104.   159.    82.]
  [  115.    49.     5.    14.    65.    97.   101.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.87072676
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 5923, frames: 150092, time: 31189.084240198135
training steps:  18200
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5923 : 0.0
LR:  0.001
replay buffer size:  154298
Time Taken :  519.0  mins 49.08407497406006  seconds
[[[  474.   270.     0.     0.    42.   141.   160.]
  [ 3750.  2199.   476.    99.   120.   186.   205.]
  [10724.  6281.  1577.   815.   603.   458.   406.]
  [17614.  9677.  1407.    74.   115.    85.    69.]
  [18499.  9195.  1189.   195.   491.   454.   343.]
  [13795.  9231.  3101.  1880.  1437.   737.   511.]
  [12788.  6875.  1020.   231.   668.   762.   605.]]

 [[    4.     2.     0.     0.     0.     0.     0.]
  [   49.    18.     3.     2.     2.     5.     0.]
  [   87.    45.    11.     8.    10.     8.     4.]
  [   99.    52.     1.     0.     5.     6.    10.]
  [  125.    78.    13.     7.    48.    67.    47.]
  [  115.   112.    81.    94.   126.   178.    91.]
  [  132.    59.     7.    16.    79.   113.   116.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.86281085
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 6334, frames: 160089, time: 33268.396757125854
training steps:  19540
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6334 : 0.0
LR:  0.001
replay buffer size:  164547
Time Taken :  554.0  mins 28.396594047546387  seconds
[[[  514.   290.     0.     0.    50.   163.   203.]
  [ 4020.  2365.   513.   113.   144.   209.   246.]
  [11440.  6799.  1796.   994.   787.   625.   557.]
  [18501. 10237.  1493.    83.   124.    94.    87.]
  [19268.  9689.  1246.   216.   554.   519.   421.]
  [14347.  9821.  3360.  2064.  1576.   788.   579.]
  [13707.  7417.  1080.   248.   717.   818.   666.]]

 [[    4.     2.     0.     0.     0.     0.     0.]
  [   49.    18.     3.     3.     2.     5.     0.]
  [   87.    46.    12.     9.    10.     8.     4.]
  [   99.    54.     1.     0.     5.     6.    10.]
  [  125.    81.    13.     7.    50.    69.    51.]
  [  116.   114.    84.    99.   131.   186.    99.]
  [  136.    60.     7.    18.    83.   116.   125.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8731617
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 6733, frames: 170166, time: 35342.21960020065
training steps:  20881
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6733 : 0.0
LR:  0.001
replay buffer size:  174869
Time Taken :  589.0  mins 2.219426155090332  seconds
[[[  546.   303.     0.     0.    61.   192.   253.]
  [ 4223.  2499.   540.   121.   177.   263.   317.]
  [12110.  7327.  2030.  1209.   999.   807.   742.]
  [19350. 10753.  1575.    94.   138.   106.   107.]
  [20052. 10164.  1300.   240.   616.   582.   501.]
  [15043. 10461.  3621.  2259.  1735.   851.   654.]
  [14566.  7929.  1147.   261.   765.   877.   725.]]

 [[    4.     2.     0.     0.     0.     0.     0.]
  [   49.    18.     3.     3.     2.     5.     0.]
  [   87.    46.    12.     9.    10.     8.     4.]
  [  100.    54.     1.     0.     5.     8.    11.]
  [  126.    81.    13.     7.    51.    75.    57.]
  [  117.   117.    87.   101.   132.   191.   101.]
  [  136.    60.     7.    18.    83.   116.   125.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8720158
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 7138, frames: 180153, time: 37740.49385690689
training steps:  22273
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7138 : 0.0
LR:  0.001
replay buffer size:  185115
Time Taken :  629.0  mins 0.4936959743499756  seconds
[[[  578.   321.     0.     0.    67.   238.   315.]
  [ 4391.  2625.   565.   132.   221.   337.   414.]
  [12722.  7811.  2257.  1424.  1248.  1016.   943.]
  [20235. 11270.  1667.   106.   157.   124.   131.]
  [20801. 10584.  1356.   258.   682.   665.   585.]
  [15603. 10965.  3856.  2465.  1897.   922.   731.]
  [15357.  8364.  1193.   278.   818.   966.   803.]]

 [[    5.     2.     0.     0.     1.     0.     0.]
  [   52.    21.     3.     3.     6.    10.     0.]
  [   95.    50.    17.    13.    13.    13.     8.]
  [  117.    58.     1.     0.     5.     8.    11.]
  [  145.    91.    14.     8.    58.    84.    66.]
  [  138.   141.   102.   114.   146.   203.   117.]
  [  161.    75.    10.    19.    89.   123.   135.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.87084913
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 7505, frames: 190036, time: 40062.01797699928
training steps:  23526
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7505 : 0.0
LR:  0.001
replay buffer size:  195270
Time Taken :  667.0  mins 42.017810106277466  seconds
[[[  590.   335.     0.     0.    73.   252.   358.]
  [ 4555.  2717.   584.   155.   261.   403.   487.]
  [13316.  8233.  2502.  1651.  1477.  1222.  1132.]
  [21130. 11734.  1740.   116.   172.   138.   159.]
  [21607. 11005.  1418.   270.   744.   739.   646.]
  [16218. 11505.  4098.  2654.  2074.  1005.   836.]
  [16133.  8782.  1238.   296.   882.  1033.   920.]]

 [[    5.     3.     0.     0.     1.     0.     0.]
  [   57.    24.     4.     3.     7.    13.     3.]
  [  108.    63.    29.    23.    22.    25.    15.]
  [  132.    63.     1.     0.     7.     9.    12.]
  [  160.   101.    14.    10.    66.    93.    77.]
  [  148.   162.   118.   133.   167.   221.   138.]
  [  197.    94.    11.    21.   102.   131.   143.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8515126
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.00199960002
rdn probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Episodes: 7886, frames: 200238, time: 42303.631444215775
training steps:  24876
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7886 : 0.0
LR:  0.001
replay buffer size:  200360
Time Taken :  705.0  mins 3.6312692165374756  seconds
[[[  612.   347.     0.     0.    78.   279.   426.]
  [ 4739.  2847.   606.   180.   325.   494.   593.]
  [14000.  8781.  2846.  1926.  1791.  1493.  1386.]
  [21947. 12159.  1802.   129.   191.   163.   184.]
  [22347. 11414.  1481.   283.   805.   819.   724.]
  [16756. 12055.  4379.  2881.  2261.  1101.   922.]
  [16850.  9229.  1286.   310.   933.  1114.  1007.]]

 [[    5.     3.     0.     0.     1.     0.     1.]
  [   57.    24.     4.     3.     7.    13.     4.]
  [  111.    65.    30.    24.    24.    26.    19.]
  [  135.    64.     1.     0.     8.     9.    12.]
  [  165.   103.    14.    12.    72.   100.    88.]
  [  152.   171.   126.   143.   177.   231.   145.]
  [  202.    97.    11.    22.   104.   138.   148.]]]
Test reward:  0.2
Q value #end_state_>_threshold:  31
Q value #non_end_state_>threshold:  4
maxi score:  0.0081
siam score:  -0.951959
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.0019677312200000003
rdn probs:  [0.08337680796408094, 0.08337680796408094, 0.08337680796408094, 0.5831159601795954, 0.08337680796408094, 0.08337680796408094]
Episodes: 8218, frames: 210112, time: 44542.0692691803
training steps:  26198
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8218 : 0.0
LR:  0.001
replay buffer size:  200720
Time Taken :  742.0  mins 22.069098949432373  seconds
[[[  625.   356.     0.     0.    89.   326.   515.]
  [ 4919.  2938.   631.   190.   372.   568.   678.]
  [14592.  9210.  3098.  2128.  2033.  1701.  1553.]
  [22727. 12608.  1858.   136.   203.   177.   206.]
  [23079. 11868.  1539.   300.   871.   899.   831.]
  [17311. 12627.  4693.  3143.  2462.  1181.  1035.]
  [17662.  9727.  1335.   328.  1005.  1206.  1110.]]

 [[    5.     3.     0.     0.     1.     0.     1.]
  [   58.    25.     4.     3.     7.    13.     4.]
  [  116.    71.    33.    26.    28.    28.    19.]
  [  140.    68.     1.     0.     8.     9.    12.]
  [  171.   109.    17.    12.    75.   105.    95.]
  [  159.   181.   134.   152.   194.   246.   153.]
  [  209.   101.    12.    22.   109.   147.   159.]]]
Test reward:  0.35
Q value #end_state_>_threshold:  118
Q value #non_end_state_>threshold:  65
maxi score:  0.0201
siam score:  -0.9427853
Scores:  {'0.333': 0.0001, '0.667': 0.0021, '1.0': 0.0041, '1.333': 0.026099999999999998, '1.667': 0.0021, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.016640000000000005
rdn probs:  [0.07226619710762515, 0.10558400989316921, 0.1389018226787133, 0.5053977633196981, 0.10558400989316921, 0.07226619710762515]
Episodes: 8535, frames: 220244, time: 46662.80844306946
training steps:  27513
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8535 : 0.1
LR:  0.001
replay buffer size:  200080
Time Taken :  777.0  mins 42.80827331542969  seconds
[[[  637.   364.     0.     0.    99.   367.   583.]
  [ 5047.  3033.   644.   198.   415.   649.   785.]
  [15006.  9581.  3357.  2347.  2304.  1957.  1741.]
  [23341. 12978.  1910.   143.   213.   199.   234.]
  [23681. 12219.  1578.   314.   936.   979.   943.]
  [17763. 13128.  4967.  3365.  2665.  1285.  1141.]
  [18307. 10157.  1361.   342.  1073.  1283.  1213.]]

 [[    5.     4.     0.     0.     1.     4.    17.]
  [   65.    36.     6.     5.    13.    24.    42.]
  [  161.   118.    69.    60.    71.    67.    69.]
  [  219.    87.     3.     1.    10.    15.    17.]
  [  256.   152.    18.    16.   107.   153.   160.]
  [  232.   269.   199.   221.   275.   346.   239.]
  [  264.   134.    16.    23.   146.   215.   247.]]]
Test reward:  0.85
Q value #end_state_>_threshold:  522
Q value #non_end_state_>threshold:  837
maxi score:  0.0601
siam score:  -0.935027
Scores:  {'0.333': 0.0061, '0.667': 0.0101, '1.0': 0.0361, '1.333': 0.0781, '1.667': 0.0121, '2.0': 0.0041}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.032955
rdn probs:  [0.07318550069884286, 0.09358139145545898, 0.22615468137346365, 0.44031153431793274, 0.10377933683376701, 0.06298755532053482]
Episodes: 8777, frames: 230416, time: 48469.70563411713
training steps:  28511
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8777 : 0.2
LR:  0.001
replay buffer size:  200097
Time Taken :  807.0  mins 49.70546817779541  seconds
[[[  642.   367.     0.     0.   103.   383.   631.]
  [ 5117.  3084.   650.   201.   449.   695.   839.]
  [15346.  9808.  3479.  2470.  2468.  2080.  1860.]
  [23817. 13195.  1935.   146.   227.   205.   241.]
  [24125. 12431.  1595.   321.   968.  1028.  1003.]
  [18142. 13544.  5215.  3583.  2879.  1437.  1214.]
  [18858. 10511.  1380.   349.  1114.  1326.  1284.]]

 [[    5.     6.     0.     0.     2.    16.    76.]
  [   94.    55.     9.     7.    28.   103.   293.]
  [  269.   261.   180.   170.   205.   269.   358.]
  [  351.   148.    11.     1.    13.    23.    22.]
  [  405.   232.    22.    24.   178.   274.   291.]
  [  371.   423.   345.   359.   445.   564.   424.]
  [  370.   184.    23.    26.   205.   335.   419.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1008
Q value #non_end_state_>threshold:  2609
maxi score:  0.1201
siam score:  -0.9372174
Scores:  {'0.333': 0.0101, '0.667': 0.0301, '1.0': 0.0601, '1.333': 0.1321, '1.667': 0.0281, '2.0': 0.0201}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.0029700000000000013
rdn probs:  [0.059531044656724486, 0.11796865666214751, 0.20562507467028202, 0.4160004778898049, 0.11212489546160521, 0.08874985065943601]
Episodes: 8995, frames: 240204, time: 49916.247864961624
training steps:  29254
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
8995 : 0.35
LR:  0.001
replay buffer size:  200053
Time Taken :  831.0  mins 56.24769997596741  seconds
[[[  646.   368.     0.     0.   104.   389.   653.]
  [ 5166.  3107.   656.   202.   459.   719.   866.]
  [15526.  9938.  3537.  2519.  2516.  2131.  1894.]
  [24154. 13385.  1945.   146.   228.   208.   241.]
  [24419. 12647.  1604.   328.   989.  1059.  1021.]
  [18347. 13916.  5476.  3804.  3090.  1622.  1274.]
  [19160. 10735.  1398.   356.  1133.  1348.  1339.]]

 [[    7.     7.     0.     0.     3.    44.   154.]
  [  160.    91.    12.     8.    63.   251.   620.]
  [  446.   461.   324.   358.   401.   540.   665.]
  [  533.   269.    16.     2.    22.    30.    31.]
  [  607.   363.    30.    28.   254.   413.   426.]
  [  637.   644.   539.   569.   678.   855.   621.]
  [  543.   275.    30.    36.   290.   487.   598.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1558
Q value #non_end_state_>threshold:  3906
maxi score:  0.17809999999999998
siam score:  -0.9163431
Scores:  {'0.333': 0.034100000000000005, '0.667': 0.0541, '1.0': 0.0881, '1.333': 0.1701, '1.667': 0.0621, '2.0': 0.0361}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 9225, frames: 250135, time: 51342.808358192444
training steps:  29994
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9225 : 0.5
LR:  0.001
replay buffer size:  200044
Time Taken :  855.0  mins 42.808186054229736  seconds
[[[  649.   368.     0.     0.   106.   398.   661.]
  [ 5194.  3125.   657.   204.   469.   732.   886.]
  [15664. 10021.  3583.  2555.  2560.  2165.  1931.]
  [24400. 13554.  1953.   149.   230.   209.   243.]
  [24720. 12830.  1620.   331.  1015.  1096.  1061.]
  [18614. 14304.  5754.  4057.  3337.  1826.  1343.]
  [19434. 10931.  1417.   366.  1159.  1392.  1414.]]

 [[    9.     7.     0.     0.     3.    73.   245.]
  [  187.   128.    17.    13.    99.   381.   951.]
  [  596.   701.   483.   547.   643.   816.  1056.]
  [  711.   441.    19.     5.    27.    39.    42.]
  [  834.   519.    39.    35.   334.   533.   568.]
  [  899.   896.   716.   776.   952.  1140.   817.]
  [  732.   365.    32.    40.   386.   619.   752.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2165
Q value #non_end_state_>threshold:  5704
maxi score:  0.24409999999999998
siam score:  -0.9006996
Scores:  {'0.333': 0.0661, '0.667': 0.08410000000000001, '1.0': 0.1201, '1.333': 0.20409999999999998, '1.667': 0.0941, '2.0': 0.056100000000000004}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 9434, frames: 260114, time: 52769.66112303734
training steps:  30747
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9434 : 0.5
LR:  0.001
replay buffer size:  200030
Time Taken :  879.0  mins 29.66095209121704  seconds
[[[  649.   368.     0.     0.   107.   400.   662.]
  [ 5213.  3136.   658.   206.   471.   738.   890.]
  [15771. 10085.  3604.  2571.  2578.  2190.  1942.]
  [24653. 13686.  1958.   149.   230.   210.   245.]
  [24995. 13031.  1634.   335.  1036.  1124.  1095.]
  [18852. 14679.  6052.  4320.  3610.  2060.  1424.]
  [19718. 11107.  1423.   374.  1204.  1473.  1498.]]

 [[   10.     9.     0.     0.     5.    97.   349.]
  [  238.   167.    18.    18.   145.   513.  1332.]
  [  807.   974.   683.   756.   902.  1135.  1566.]
  [  892.   616.    24.     9.    31.    43.    54.]
  [ 1044.   686.    41.    36.   402.   620.   659.]
  [ 1085.  1155.   931.  1003.  1227.  1422.   977.]
  [  861.   462.    43.    44.   488.   775.   912.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  2710
Q value #non_end_state_>threshold:  7495
maxi score:  0.3121
siam score:  -0.8782286
Scores:  {'0.333': 0.0881, '0.667': 0.1041, '1.0': 0.15009999999999998, '1.333': 0.2341, '1.667': 0.1241, '2.0': 0.0761}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 9655, frames: 270069, time: 54195.990200042725
training steps:  31759
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9655 : 0.4
LR:  0.001
replay buffer size:  200033
Time Taken :  903.0  mins 15.990021228790283  seconds
[[[  650.   369.     0.     0.   108.   400.   663.]
  [ 5243.  3148.   659.   207.   477.   742.   894.]
  [15904. 10166.  3631.  2587.  2604.  2211.  1960.]
  [24892. 13856.  1967.   149.   234.   210.   249.]
  [25276. 13257.  1646.   341.  1103.  1208.  1222.]
  [19075. 15085.  6356.  4604.  3923.  2329.  1591.]
  [20015. 11323.  1440.   387.  1285.  1622.  1687.]]

 [[   11.    11.     0.     0.    10.   159.   438.]
  [  279.   197.    21.    25.   181.   674.  1699.]
  [  974.  1237.   866.   959.  1129.  1403.  1982.]
  [ 1028.   758.    27.    11.    33.    47.    63.]
  [ 1189.   821.    49.    38.   453.   696.   753.]
  [ 1242.  1376.  1116.  1178.  1458.  1695.  1102.]
  [  976.   537.    46.    51.   560.   886.  1015.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  3270
Q value #non_end_state_>threshold:  10006
maxi score:  0.3641
siam score:  -0.85246396
Scores:  {'0.333': 0.1121, '0.667': 0.1281, '1.0': 0.1881, '1.333': 0.2601, '1.667': 0.14609999999999998, '2.0': 0.0981}
best rdn ma / adv:  1.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 9861, frames: 280009, time: 55659.01497912407
training steps:  33372
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9861 : 0.4
LR:  0.001
replay buffer size:  200218
Time Taken :  927.0  mins 39.01479911804199  seconds
[[[  651.   370.     0.     0.   109.   401.   666.]
  [ 5271.  3162.   660.   207.   480.   746.   895.]
  [16013. 10229.  3649.  2596.  2616.  2227.  1975.]
  [25118. 14002.  1971.   149.   235.   212.   250.]
  [25565. 13453.  1654.   346.  1155.  1298.  1350.]
  [19350. 15500.  6641.  4882.  4225.  2598.  1769.]
  [20355. 11562.  1452.   399.  1354.  1727.  1852.]]

 [[   11.    12.     0.     0.    15.   292.   530.]
  [  311.   235.    27.    28.   230.   880.  2005.]
  [ 1139.  1495.  1076.  1165.  1390.  1757.  2436.]
  [ 1165.   912.    30.    17.    40.    57.    67.]
  [ 1318.   962.    53.    44.   488.   762.   863.]
  [ 1360.  1592.  1294.  1367.  1696.  1952.  1239.]
  [ 1035.   577.    48.    58.   641.   989.  1141.]]]
