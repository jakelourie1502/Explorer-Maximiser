EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  0.0029662597755139523
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 109, frames: 1537, time: 24.143157958984375
training steps:  2
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
109 : 0.0
LR:  1e-06
replay buffer size:  1707
Time Taken :  0.0  mins 24.14298391342163  seconds
[[[ 16.   7.   0.   0.   0.   0.   0.]
  [ 65.  39.  14.   0.   0.   0.   0.]
  [151.  73.  16.   2.   0.   0.   0.]
  [232. 138.  33.   2.   0.   0.   0.]
  [173.  97.  21.   2.   2.   0.   0.]
  [125.  68.  19.   8.   3.   0.   0.]
  [ 70.  37.  11.   3.   1.   0.   0.]]

 [[  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7422655
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 596, frames: 10141, time: 1334.4590740203857
training steps:  1242
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
596 : 0.0
LR:  0.001
replay buffer size:  10610
Time Taken :  22.0  mins 14.458904027938843  seconds
[[[  55.   28.    0.    0.    0.    0.    0.]
  [ 248.  155.   48.    2.    0.    0.    0.]
  [ 692.  416.  111.   24.    2.    0.    0.]
  [1310.  794.  177.   10.    1.    0.    0.]
  [1214.  674.  125.    8.    5.    0.    0.]
  [ 900.  537.  102.   37.   18.    4.    0.]
  [ 969.  683.  121.   17.   28.    3.    0.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   1.    1.    0.    0.    0.    0.    0.]
  [   1.    2.    1.    1.    1.    4.    4.]
  [   4.    5.    1.    0.    0.    1.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.80361056
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 891, frames: 20242, time: 3099.4996151924133
training steps:  2405
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
891 : 0.0
LR:  0.001
replay buffer size:  21014
Time Taken :  51.0  mins 39.49944996833801  seconds
[[[  76.   40.    0.    0.    0.    0.    0.]
  [ 456.  261.   66.    5.    1.    1.    2.]
  [1537.  780.  162.   46.    8.    0.    1.]
  [3522. 1623.  263.   18.    5.    1.    1.]
  [3190. 1398.  192.    8.    8.    1.    0.]
  [1775.  912.  170.   54.   29.   10.    1.]
  [1530.  922.  162.   21.   34.   21.    6.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   1.    1.    0.    0.    0.    0.    0.]
  [   1.    2.    1.    1.    2.    5.    4.]
  [   4.    5.    1.    1.    2.    1.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8204146
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1190, frames: 30119, time: 5273.772777080536
training steps:  3732
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1190 : 0.0
LR:  0.001
replay buffer size:  31137
Time Taken :  87.0  mins 53.772605895996094  seconds
[[[  93.   52.    0.    0.    1.    0.    0.]
  [ 611.  359.   92.    9.    2.    1.    2.]
  [2240. 1138.  211.   54.    9.    0.    1.]
  [5318. 2471.  349.   20.    5.    2.    4.]
  [4966. 2077.  256.   10.   10.    7.    7.]
  [2781. 1345.  237.   74.   39.   14.    4.]
  [2389. 1279.  214.   26.   44.   45.   29.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   1.    1.    0.    0.    0.    0.    0.]
  [   1.    2.    1.    1.    2.    5.    4.]
  [   4.    5.    1.    1.    2.    1.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8287653
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1430, frames: 40170, time: 7438.69691991806
training steps:  4758
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1430 : 0.0
LR:  0.001
replay buffer size:  41363
Time Taken :  123.0  mins 58.6967511177063  seconds
[[[ 108.   58.    0.    0.    1.    0.    0.]
  [ 696.  405.  107.   10.    2.    1.    2.]
  [2787. 1384.  246.   65.   13.    3.    1.]
  [6970. 3379.  409.   21.    6.    3.    5.]
  [6771. 2982.  309.   13.   12.   10.    9.]
  [4059. 1927.  298.   93.   57.   20.    6.]
  [3328. 1697.  257.   30.   53.   49.   40.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    1.    0.]
  [   1.    1.    0.    0.    1.    2.    0.]
  [   1.    2.    1.    1.    2.    7.    4.]
  [   4.    5.    1.    1.    2.    1.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.87208825
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1665, frames: 50144, time: 9987.933745145798
training steps:  6038
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1665 : 0.0
LR:  0.001
replay buffer size:  51575
Time Taken :  166.0  mins 27.933576822280884  seconds
[[[ 125.   67.    0.    0.    1.    0.    0.]
  [ 820.  461.  115.   11.    2.    1.    2.]
  [3344. 1589.  279.   67.   14.    3.    1.]
  [8540. 4035.  471.   21.    8.    3.    5.]
  [8954. 3752.  377.   16.   14.   10.    9.]
  [5513. 2453.  365.  115.   63.   23.    6.]
  [4317. 1993.  289.   31.   53.   50.   40.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    1.    0.]
  [   1.    1.    0.    0.    1.    3.    0.]
  [   1.    2.    1.    1.    2.   10.    4.]
  [   4.    5.    1.    2.    5.    6.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.9088519
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 1870, frames: 60095, time: 12405.004637002945
training steps:  7316
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1870 : 0.0
LR:  0.001
replay buffer size:  61769
Time Taken :  206.0  mins 45.00448679924011  seconds
[[[  138.    69.     0.     0.     1.     0.     3.]
  [  917.   498.   125.    12.     2.     7.    11.]
  [ 3736.  1730.   295.    71.    16.    10.     2.]
  [10092.  4557.   520.    21.     9.     3.     6.]
  [11467.  4401.   430.    18.    20.    11.     9.]
  [ 7270.  2926.   427.   127.    67.    23.     6.]
  [ 5367.  2255.   324.    32.    53.    50.    40.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     1.     0.]
  [    1.     1.     0.     0.     1.     3.     0.]
  [    1.     2.     1.     1.     2.    10.     4.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.91538817
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2080, frames: 70048, time: 14636.496959924698
training steps:  8686
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2080 : 0.0
LR:  0.001
replay buffer size:  71948
Time Taken :  243.0  mins 56.49679112434387  seconds
[[[  152.    69.     0.     0.     1.     0.     3.]
  [ 1012.   530.   136.    13.     3.     7.    11.]
  [ 4177.  1888.   321.    78.    17.    10.     2.]
  [11719.  5229.   578.    21.    10.     4.     6.]
  [14082.  5279.   487.    21.    21.    14.     9.]
  [ 8825.  3438.   483.   142.    73.    24.     6.]
  [ 6019.  2468.   353.    33.    53.    50.    40.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     1.     0.]
  [    1.     1.     0.     0.     1.     3.     0.]
  [    1.     2.     1.     1.     2.    10.     4.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.91597426
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2295, frames: 80046, time: 16731.848999023438
training steps:  9876
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2295 : 0.0
LR:  0.001
replay buffer size:  82210
Time Taken :  278.0  mins 51.84883403778076  seconds
[[[  172.    72.     0.     0.     1.     0.     3.]
  [ 1161.   576.   146.    14.     3.     7.    11.]
  [ 4687.  2095.   355.    88.    19.    12.     2.]
  [13333.  5897.   627.    24.    10.     6.     6.]
  [16637.  6101.   550.    22.    21.    14.     9.]
  [10296.  3994.   542.   158.    77.    25.     6.]
  [ 6657.  2703.   372.    36.    54.    50.    40.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     2.     0.]
  [    1.     1.     0.     0.     1.     4.     1.]
  [    1.     2.     1.     1.     3.    13.     6.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.9301085
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2485, frames: 90012, time: 18682.103683948517
training steps:  10802
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2485 : 0.0
LR:  0.001
replay buffer size:  92469
Time Taken :  311.0  mins 22.10354208946228  seconds
[[[  183.    77.     0.     0.     1.     0.     3.]
  [ 1338.   626.   160.    15.     4.     8.    16.]
  [ 5326.  2274.   385.    90.    24.    16.     9.]
  [15084.  6362.   670.    24.    10.     6.     6.]
  [19298.  6722.   587.    24.    21.    14.     9.]
  [11885.  4409.   596.   167.    77.    25.     6.]
  [ 7415.  2910.   405.    36.    54.    50.    40.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     2.     0.]
  [    1.     1.     0.     0.     1.     4.     1.]
  [    1.     2.     1.     1.     3.    13.     6.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.9187515
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2680, frames: 100025, time: 20585.897343158722
training steps:  11745
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2680 : 0.0
LR:  0.001
replay buffer size:  102709
Time Taken :  343.0  mins 5.897176027297974  seconds
[[[  202.    82.     0.     0.     2.     0.     3.]
  [ 1599.   691.   168.    15.     5.     8.    16.]
  [ 5934.  2429.   411.    97.    27.    16.     9.]
  [16803.  6816.   715.    25.    11.     6.     6.]
  [21739.  7298.   633.    26.    21.    14.     9.]
  [13452.  4840.   645.   175.    77.    25.     6.]
  [ 8458.  3165.   424.    38.    54.    50.    40.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     2.     0.]
  [    1.     1.     0.     0.     1.     4.     1.]
  [    1.     2.     1.     1.     3.    13.     6.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.9228324
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 2882, frames: 110116, time: 23082.46618103981
training steps:  13109
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2882 : 0.0
LR:  0.001
replay buffer size:  113023
Time Taken :  384.0  mins 42.46601486206055  seconds
[[[  225.    89.     0.     0.     2.     0.     5.]
  [ 2053.   827.   179.    16.     6.    10.    20.]
  [ 6561.  2713.   441.   108.    34.    18.    11.]
  [18588.  7372.   757.    25.    12.     6.     6.]
  [24089.  7899.   686.    26.    21.    14.     9.]
  [14701.  5241.   688.   179.    77.    25.     6.]
  [ 9383.  3415.   449.    38.    54.    50.    40.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     2.     0.]
  [    1.     1.     0.     0.     1.     4.     1.]
  [    1.     2.     1.     1.     3.    13.     6.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.93154776
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3088, frames: 120087, time: 25351.97076010704
training steps:  14510
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3088 : 0.0
LR:  0.001
replay buffer size:  123315
Time Taken :  422.0  mins 31.97059202194214  seconds
[[[  253.    91.     0.     0.     2.     0.     5.]
  [ 2582.   944.   200.    17.     6.    10.    20.]
  [ 7213.  2957.   476.   112.    36.    19.    11.]
  [20183.  7818.   801.    25.    13.     7.     6.]
  [26420.  8449.   743.    27.    22.    14.     9.]
  [16109.  5622.   767.   197.    80.    25.     6.]
  [10376.  3620.   462.    40.    54.    50.    40.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     2.     0.]
  [    1.     1.     0.     0.     1.     4.     1.]
  [    1.     2.     1.     1.     3.    13.     6.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.93197656
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3280, frames: 130121, time: 27705.971832990646
training steps:  15908
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3280 : 0.0
LR:  0.001
replay buffer size:  133684
Time Taken :  461.0  mins 45.97167682647705  seconds
[[[  286.    98.     0.     0.     2.     0.     5.]
  [ 3242.  1053.   213.    18.     6.    10.    20.]
  [ 7844.  3164.   512.   123.    36.    19.    11.]
  [21692.  8198.   837.    29.    13.     7.     6.]
  [28645.  8885.   782.    27.    22.    14.     9.]
  [17686.  5969.   820.   206.    81.    25.     6.]
  [11614.  3876.   486.    40.    54.    50.    40.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     2.     0.]
  [    1.     1.     0.     0.     1.     4.     1.]
  [    1.     2.     1.     1.     3.    13.     6.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.9217583
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3497, frames: 140143, time: 29919.998353004456
training steps:  17309
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3497 : 0.0
LR:  0.001
replay buffer size:  144000
Time Taken :  498.0  mins 39.998191118240356  seconds
[[[  326.   104.     0.     0.     2.     0.     5.]
  [ 3900.  1158.   225.    20.     6.    10.    20.]
  [ 8468.  3377.   543.   130.    37.    19.    11.]
  [23043.  8572.   872.    29.    14.     7.     6.]
  [30871.  9366.   832.    30.    22.    14.     9.]
  [19188.  6360.   885.   224.    84.    25.     6.]
  [12933.  4132.   516.    41.    54.    50.    40.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     2.     0.]
  [    1.     1.     0.     0.     1.     4.     1.]
  [    1.     2.     1.     1.     3.    13.     6.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.92073387
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3720, frames: 150089, time: 32071.8249270916
training steps:  18688
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3720 : 0.0
LR:  0.001
replay buffer size:  154295
Time Taken :  534.0  mins 31.82476305961609  seconds
[[[  367.   122.     0.     0.     5.     1.     8.]
  [ 4685.  1305.   231.    20.    10.    12.    23.]
  [ 9136.  3627.   567.   135.    41.    22.    16.]
  [24365.  9006.   914.    31.    14.     7.     6.]
  [32741.  9886.   882.    33.    25.    15.     9.]
  [20556.  6731.   943.   247.    88.    25.     6.]
  [14309.  4409.   541.    43.    54.    50.    40.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     2.     0.]
  [    1.     1.     0.     0.     1.     4.     1.]
  [    1.     2.     1.     1.     3.    13.     6.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.92275816
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 3969, frames: 160269, time: 34038.57477211952
training steps:  19878
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3969 : 0.0
LR:  0.001
replay buffer size:  164770
Time Taken :  567.0  mins 18.574604034423828  seconds
[[[  411.   136.     0.     0.     6.     4.    18.]
  [ 5333.  1455.   245.    22.    13.    17.    27.]
  [ 9898.  3935.   636.   150.    45.    23.    16.]
  [25792.  9420.   963.    34.    15.     9.     7.]
  [34478. 10339.   930.    36.    28.    23.    15.]
  [22063.  7130.  1055.   280.   106.    36.    28.]
  [15590.  4678.   578.    49.    64.    58.    46.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     2.     0.]
  [    1.     1.     0.     0.     1.     4.     1.]
  [    1.     2.     1.     1.     3.    13.     6.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.92069507
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4252, frames: 170120, time: 35678.33436894417
training steps:  20805
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4252 : 0.0
LR:  0.001
replay buffer size:  174901
Time Taken :  594.0  mins 38.33420014381409  seconds
[[[  443.   149.     0.     0.     8.     7.    28.]
  [ 5911.  1658.   275.    25.    19.    22.    34.]
  [10687.  4378.   702.   164.    54.    24.    19.]
  [27156. 10014.  1029.    36.    15.     9.     7.]
  [35990. 10897.   999.    41.    30.    25.    16.]
  [23278.  7620.  1187.   320.   115.    40.    31.]
  [16514.  4981.   611.    55.    64.    58.    46.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     1.     0.     0.     0.     2.     0.]
  [    1.     3.     1.     0.     1.     5.     1.]
  [    1.     4.     3.     5.     5.    15.     6.]
  [    4.     5.     1.     2.     5.     6.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.90900916
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
rdn probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Episodes: 4570, frames: 180248, time: 37603.198410987854
training steps:  21748
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4570 : 0.0
LR:  0.001
replay buffer size:  185366
Time Taken :  626.0  mins 43.19825100898743  seconds
[[[  482.   174.     0.     0.    10.     7.    28.]
  [ 6340.  1978.   309.    27.    22.    23.    34.]
  [11521.  4980.   824.   203.    62.    26.    20.]
  [28294. 10712.  1100.    40.    18.    12.    10.]
  [37022. 11513.  1062.    49.    54.    82.    48.]
  [24112.  8206.  1387.   440.   191.    98.    45.]
  [17230.  5330.   639.    62.    67.    68.    52.]]

 [[    2.     1.     0.     0.     0.     0.     0.]
  [   32.    24.     2.     0.     0.     0.     0.]
  [   29.    30.     1.     0.     0.     0.     0.]
  [   36.    33.     0.     0.     0.     2.     2.]
  [   38.    37.     4.     1.     4.    27.    13.]
  [   48.    55.    27.    30.    27.    58.    10.]
  [   36.    33.     3.     2.     6.    10.     2.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.863852
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.00199960002
rdn probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Episodes: 4876, frames: 190325, time: 39855.503652095795
training steps:  22664
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4876 : 0.0
LR:  0.001
replay buffer size:  197790
Time Taken :  664.0  mins 15.503479957580566  seconds
[[[  519.   196.     0.     0.    14.    19.    36.]
  [ 6770.  2207.   338.    30.    36.    42.    41.]
  [12310.  5439.   902.   238.    82.    34.    21.]
  [29435. 11306.  1156.    44.    21.    21.    15.]
  [38052. 12084.  1111.    56.    68.   140.   138.]
  [24959.  8815.  1584.   567.   284.   194.    97.]
  [17958.  5724.   674.    73.    82.   101.    73.]]

 [[    3.     2.     0.     0.     0.     1.     1.]
  [   61.    42.     4.     0.     1.     2.     1.]
  [   61.    58.     3.     1.     1.     0.     0.]
  [   66.    57.     1.     0.     0.     5.     3.]
  [   75.    57.     8.     2.    11.    67.    32.]
  [   88.    95.    58.    60.    63.   142.    36.]
  [   62.    54.     4.     5.    16.    28.     6.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.87159395
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  1.333 1.333
best rdn adv:  0.00199960002
rdn probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Episodes: 5203, frames: 200370, time: 41488.61166405678
training steps:  23502
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5203 : 0.0
LR:  0.001
replay buffer size:  200240
Time Taken :  691.0  mins 28.611500024795532  seconds
[[[  558.   213.     0.     0.    18.    36.    47.]
  [ 7242.  2409.   359.    36.    60.    69.    51.]
  [13066.  5852.  1019.   314.   142.    72.    35.]
  [30490. 11825.  1212.    46.    30.    30.    32.]
  [39198. 12585.  1164.    72.    93.   223.   245.]
  [25838.  9367.  1813.   756.   446.   327.   184.]
  [18595.  6039.   704.    81.    99.   127.   102.]]

 [[    3.     2.     0.     0.     0.     1.     1.]
  [   71.    46.     5.     1.     1.     2.     1.]
  [   81.    62.     5.     2.     1.     0.     0.]
  [   82.    61.     1.     0.     2.    11.    14.]
  [   94.    63.    14.     2.    20.   112.    85.]
  [  107.   109.    80.    83.    94.   224.    78.]
  [   71.    57.     6.     9.    21.    40.    21.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8608577
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0041}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.00399920004
rdn probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Episodes: 5538, frames: 210283, time: 43590.77844905853
training steps:  24784
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5538 : 0.0
LR:  0.001
replay buffer size:  200120
Time Taken :  726.0  mins 30.778275966644287  seconds
[[[  599.   236.     0.     0.    25.   121.   164.]
  [ 7648.  2648.   387.    40.    73.   127.   117.]
  [13719.  6252.  1120.   387.   211.   142.   100.]
  [31355. 12315.  1263.    49.    32.    38.    57.]
  [39908. 12963.  1205.    90.   135.   377.   533.]
  [26366.  9783.  2023.   949.   643.   533.   396.]
  [19033.  6227.   733.    93.   122.   167.   171.]]

 [[    4.     3.     0.     0.     0.     5.     3.]
  [  106.    65.     6.     1.     6.    17.    10.]
  [  124.    94.    12.     9.     9.    12.     7.]
  [  120.    83.     2.     0.     4.    14.    26.]
  [  132.    77.    14.     7.    38.   208.   248.]
  [  150.   153.   128.   130.   148.   350.   189.]
  [  107.    75.     9.    11.    28.    68.    58.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.9009701
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0061}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.005998800060000001
rdn probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Episodes: 5827, frames: 220188, time: 45718.57973790169
training steps:  26097
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5827 : 0.05
LR:  0.001
replay buffer size:  200120
Time Taken :  761.0  mins 58.57956290245056  seconds
[[[  627.   243.     0.     0.    34.   232.   299.]
  [ 8006.  2815.   409.    45.    88.   186.   208.]
  [14361.  6614.  1217.   466.   286.   224.   192.]
  [32127. 12707.  1295.    53.    38.    56.    82.]
  [40563. 13317.  1243.   103.   190.   596.   874.]
  [26842. 10237.  2312.  1204.   917.   839.   732.]
  [19426.  6438.   765.   106.   140.   230.   301.]]

 [[    6.     4.     0.     0.     3.    12.     4.]
  [  145.    86.    10.     2.    12.    30.    25.]
  [  174.   125.    21.    16.    15.    22.    27.]
  [  155.   100.     3.     0.     6.    17.    30.]
  [  168.    92.    16.     9.    54.   269.   336.]
  [  189.   188.   162.   167.   201.   445.   279.]
  [  131.    81.    10.    13.    35.    84.    97.]]]
Test reward:  0.1
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0041
siam score:  -0.91378736
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0061}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.00595090086
rdn probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
Episodes: 6137, frames: 230246, time: 47935.87130904198
training steps:  27452
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6137 : 0.0
LR:  0.001
replay buffer size:  200240
Time Taken :  798.0  mins 55.87113904953003  seconds
[[[  649.   261.     0.     0.    44.   273.   423.]
  [ 8392.  3007.   427.    50.   103.   234.   308.]
  [14998.  6956.  1305.   533.   353.   298.   285.]
  [32867. 13119.  1340.    54.    48.    72.   103.]
  [41220. 13701.  1286.   118.   271.   809.  1206.]
  [27326. 10707.  2589.  1461.  1197.  1121.  1119.]
  [19865.  6669.   803.   117.   190.   334.   513.]]

 [[    6.     5.     0.     0.     4.    21.     4.]
  [  170.   107.    12.     2.    15.    46.    33.]
  [  210.   147.    28.    21.    19.    29.    37.]
  [  194.   115.     5.     1.     7.    21.    34.]
  [  195.   108.    20.    16.    73.   322.   423.]
  [  217.   223.   196.   212.   252.   537.   371.]
  [  142.    88.    11.    15.    43.   103.   125.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0041
siam score:  -0.95562303
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0021, '1.667': 0.0001, '2.0': 0.0081}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.0064800000000000005
rdn probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Episodes: 6455, frames: 240223, time: 50106.724073171616
training steps:  28805
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6455 : 0.0
LR:  0.001
replay buffer size:  200191
Time Taken :  835.0  mins 6.7239038944244385  seconds
[[[  678.   271.     0.     0.    47.   367.   650.]
  [ 8712.  3173.   446.    60.   123.   312.   407.]
  [15581.  7287.  1430.   647.   466.   401.   407.]
  [33576. 13481.  1390.    59.    63.    91.   125.]
  [41813. 13966.  1325.   140.   375.  1059.  1571.]
  [27729. 11118.  2913.  1744.  1560.  1473.  1542.]
  [20168.  6829.   838.   129.   268.   493.   764.]]

 [[    7.     6.     0.     0.     4.    34.     6.]
  [  192.   125.    13.     3.    18.    62.    44.]
  [  235.   174.    41.    31.    30.    49.    56.]
  [  224.   129.     7.     1.     8.    25.    36.]
  [  221.   119.    20.    17.    90.   355.   461.]
  [  249.   255.   221.   245.   296.   591.   398.]
  [  155.    99.    12.    17.    62.   120.   138.]]]
Test reward:  0.1
Q value #end_state_>_threshold:  78
Q value #non_end_state_>threshold:  110
maxi score:  0.0081
siam score:  -0.9139658
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0021, '1.333': 0.0081, '1.667': 0.0021, '2.0': 0.0101}
best rdn ma / adv:  2.0 2.0
best rdn adv:  0.0098386561
rdn probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
Episodes: 6746, frames: 250249, time: 52433.20190882683
training steps:  30175
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6746 : 0.05
LR:  0.001
replay buffer size:  200120
Time Taken :  873.0  mins 53.20173478126526  seconds
[[[  702.   286.     0.     0.    50.   438.   802.]
  [ 8997.  3339.   461.    63.   150.   393.   525.]
  [16099.  7625.  1550.   754.   567.   512.   515.]
  [34212. 13850.  1432.    64.    75.   106.   147.]
  [42319. 14264.  1353.   164.   504.  1329.  1983.]
  [28105. 11550.  3176.  2010.  1896.  1775.  1892.]
  [20512.  7036.   867.   140.   337.   623.  1021.]]

 [[    7.     7.     0.     0.     4.    45.    13.]
  [  225.   153.    15.     3.    23.    76.    61.]
  [  282.   206.    61.    51.    49.    68.    80.]
  [  262.   143.     8.     1.    10.    29.    42.]
  [  266.   136.    20.    22.   121.   450.   569.]
  [  285.   301.   263.   290.   374.   703.   483.]
  [  170.   107.    13.    20.    81.   147.   188.]]]
