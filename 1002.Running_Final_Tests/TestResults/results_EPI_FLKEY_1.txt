EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  0.01003606041194871
Scores:  {'1.0': 0.0001, '1.5': 0.0001, '2.0': 0.0001, '2.5': 0.0001, '3.0': 0.0001}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.0
Episodes: 78, frames: 1135, time: 25.49354887008667
training steps:  2
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
78 : 0.0
LR:  1e-06
replay buffer size:  1315
Time Taken :  0.0  mins 25.493353843688965  seconds
[[[ 12.   7.   0.   0.   0.   0.   0.]
  [ 48.  24.  10.   0.   0.   0.   0.]
  [139.  60.  17.   1.   0.   0.   0.]
  [165.  84.  23.   0.   0.   0.   0.]
  [136.  61.  15.   0.   0.   0.   0.]
  [ 78.  45.   5.   0.   0.   0.   0.]
  [ 77.  39.  11.   0.   0.   0.   0.]]

 [[  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7854904
Scores:  {'1.0': 0.0001, '1.5': 0.0001, '2.0': 0.0001, '2.5': 0.0001, '3.0': 0.0001}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.0
Episodes: 457, frames: 10153, time: 2016.8525557518005
training steps:  1200
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
457 : 0.0
LR:  0.001
replay buffer size:  10527
Time Taken :  33.0  mins 36.852362871170044  seconds
[[[  60.   26.    0.    0.    0.    0.    0.]
  [ 261.  152.   46.    0.    0.    0.    0.]
  [ 814.  407.   84.   12.    1.    0.    0.]
  [2577.  822.  117.    5.    1.    0.    0.]
  [1720.  738.  131.    5.    1.    0.    0.]
  [ 621.  389.   88.   23.   11.    2.    0.]
  [ 336.  198.   47.    1.    0.    0.    0.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8574962
Scores:  {'1.0': 0.0001, '1.5': 0.0001, '2.0': 0.0001, '2.5': 0.0001, '3.0': 0.0001}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.0
Episodes: 652, frames: 20015, time: 4792.695330858231
training steps:  2349
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
652 : 0.0
LR:  0.001
replay buffer size:  20619
Time Taken :  79.0  mins 52.69513487815857  seconds
[[[  79.   32.    0.    0.    0.    0.    0.]
  [ 394.  200.   56.    0.    0.    0.    0.]
  [1588.  554.  106.   15.    2.    0.    0.]
  [7955. 1335.  170.    5.    4.    1.    0.]
  [3297.  991.  161.    8.    9.    6.    0.]
  [ 952.  492.  118.   37.   28.   10.    2.]
  [ 462.  226.   50.    3.    3.    4.    0.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    1.    0.    0.]
  [   0.    0.    0.    0.    2.    2.    0.]
  [   0.    0.    0.    0.    2.    1.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8727901
Scores:  {'1.0': 0.0001, '1.5': 0.0001, '2.0': 0.0001, '2.5': 0.0001, '3.0': 0.0001}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.0
Episodes: 832, frames: 30219, time: 7629.640837907791
training steps:  3538
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
832 : 0.0
LR:  0.001
replay buffer size:  31115
Time Taken :  127.0  mins 9.640640020370483  seconds
[[[   92.    36.     0.     0.     0.     0.     0.]
  [  516.   234.    63.     1.     0.     0.     0.]
  [ 2319.   680.   118.    21.     4.     1.     0.]
  [13461.  1922.   203.     6.     6.     4.     0.]
  [ 4882.  1250.   187.    13.    21.    23.     8.]
  [ 1348.   624.   163.    65.    51.    20.    11.]
  [  623.   285.    63.     7.     9.     9.     1.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     1.     2.     0.]
  [    0.     0.     0.     1.     4.    10.     6.]
  [    0.     0.     0.     0.     3.     7.     3.]
  [    0.     0.     0.     0.     0.     0.     0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8605342
Scores:  {'1.0': 0.0001, '1.5': 0.0001, '2.0': 0.0001, '2.5': 0.0001, '3.0': 0.0001}
best rdn ma / adv:  1.0 1.0
best rdn adv:  0.0
Episodes: 1146, frames: 40114, time: 10356.354001998901
training steps:  4708
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1146 : 0.0
LR:  0.001
replay buffer size:  41235
Time Taken :  172.0  mins 36.353808879852295  seconds
[[[  113.    47.     0.     0.     0.     0.     0.]
  [  717.   323.    83.     2.     0.     0.     0.]
  [ 3107.   927.   157.    32.     5.     1.     0.]
  [16121.  2635.   274.     9.    17.     9.     3.]
  [ 6369.  1774.   264.    35.    84.    64.    25.]
  [ 1967.   966.   314.   210.   200.    79.    31.]
  [  999.   432.    82.    29.    86.    59.    19.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    3.     0.     0.     0.     0.     0.     0.]
  [    5.     0.     0.     0.     0.     0.     0.]
  [   42.     3.     1.     0.     4.     4.     0.]
  [   17.     1.     0.     3.    21.    33.    14.]
  [    8.     4.     6.     9.    28.    36.     7.]
  [    7.     2.     2.     3.    21.    12.     2.]]]
