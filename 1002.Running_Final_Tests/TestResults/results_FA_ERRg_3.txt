EVALUATIONS AND MAIN RESULTS
Test reward:  0.02
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.057242857142857144
siam score:  -0.014059195228779287
Scores:  {'0.167': 0.0001, '0.333': 0.08343333333333333, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.21375367165318476
Episodes: 74, frames: 1397, time: 45.62564396858215
training steps:  10
retraining steps:  0
RDN obj mus: [0.0249310187491447, 0.013674271617642522, 0.00389442794645826, 0.00483369439219435, 0.0]
RDN obj sigmas: [0.0027115124906001505, 0.002716471277513887, 0.002753867849115384, 0.0034179391946118466, 0.0]
74 : 0.04054054054054054
LR:  9e-06
replay buffer size:  2033
Time Taken :  0.0  mins 45.625438928604126  seconds
[[[365. 184.  34.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
  [176.  96.  22.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
  [112.  61.  13.   1.   0.   0.   0.   0.   0.   0.   0.   0.]
  [ 96.  48.  11.   1.   0.   0.   0.   0.   0.   0.   0.   0.]
  [ 60.  37.   6.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.22145416666666665
siam score:  -0.63607794
Scores:  {'0.167': 0.2223222222222222, '0.333': 0.2218391304347826, '0.5': 0.18701588785046727, '0.667': 0.13746263736263736, '0.833': 0.12729298245614035, '1.0': 0.1263135922330097}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.339126021233296
Episodes: 790, frames: 10122, time: 1300.2820239067078
training steps:  1191
retraining steps:  0
RDN obj mus: [-0.9312482711613178, -0.9180562760055065, -0.9179196630716324, -0.9131036069836674, -0.9014135325607558]
RDN obj sigmas: [0.05034709228039375, 0.05570398857656018, 0.052216355213170716, 0.05262812300253192, 0.04913688155636231]
790 : 0.3541666666666667
LR:  0.001
replay buffer size:  10935
Time Taken :  21.0  mins 40.281824827194214  seconds
[[[1865. 1170.  263.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]
  [1238.  663.  142.    5.    1.    1.    0.    0.    0.    0.    0.
      0.]
  [ 781.  467.  102.   25.   12.    5.    2.    0.    0.    0.    0.
      0.]
  [ 608.  421.   70.    4.    2.    1.    1.    0.    0.    0.    0.
      0.]
  [ 551.  632.  300.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  36
maxi score:  0.31111190476190476
siam score:  -0.84122366
Scores:  {'0.167': 0.30347078651685394, '0.333': 0.28326326530612245, '0.5': 0.2655639175257732, '0.667': 0.23224285714285714, '0.833': 0.1951, '1.0': 0.16314347826086956}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 1400, frames: 20181, time: 2938.2861847877502
training steps:  2364
retraining steps:  0
RDN obj mus: [-0.9510921648979187, -0.9522915260612964, -0.9495100907802582, -0.9565793558835983, -0.9533860618829727]
RDN obj sigmas: [0.03623337336637271, 0.03776709996921077, 0.03806532314983276, 0.03543275724861873, 0.03565476894969964]
1400 : 0.22083333333333333
LR:  0.001
replay buffer size:  21224
Time Taken :  48.0  mins 58.285985708236694  seconds
[[[2828. 1554.  299.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]
  [2341. 1116.  180.   16.    5.    4.    4.    0.    0.    0.    0.
      0.]
  [1706. 1038.  275.  137.   84.   61.   34.    8.    0.    0.    0.
      0.]
  [1544. 1022.  130.   13.    9.    9.    4.    0.    0.    0.    0.
      0.]
  [1860. 1778.  722.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  67
maxi score:  0.3452417004048583
siam score:  -0.81074643
Scores:  {'0.167': 0.3376912408759124, '0.333': 0.28398278388278386, '0.5': 0.225007063197026, '0.667': 0.16939133858267716, '0.833': 0.1427056338028169, '1.0': 0.11121111111111111}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 2041, frames: 30087, time: 4598.65841794014
training steps:  3526
retraining steps:  0
RDN obj mus: [-0.9460880287289619, -0.9657925833821297, -0.9539263172924518, -0.9394786573112011, -0.9290885602831841]
RDN obj sigmas: [0.05029278054459761, 0.025113210107411996, 0.04606370949631272, 0.05557121871394163, 0.052312086045712476]
2041 : 0.20416666666666666
LR:  0.001
replay buffer size:  31363
Time Taken :  76.0  mins 38.658222675323486  seconds
[[[4073. 2461.  423.    0.    0.    0.    6.    1.    2.    1.    1.
      0.]
  [3272. 1735.  264.   25.   19.   28.   96.   42.   52.   19.    4.
      0.]
  [2346. 1674.  653.  451.  345.  284.  189.   32.    3.    1.    0.
      0.]
  [2029. 1422.  174.   29.   17.   21.   17.    0.    0.    0.    0.
      0.]
  [2478. 2381.  976.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  95
maxi score:  0.41609999999999997
siam score:  -0.77504367
Scores:  {'0.167': 0.3456056179775281, '0.333': 0.2939718662952646, '0.5': 0.20680391061452513, '0.667': 0.1463686567164179, '0.833': 0.12172162162162163, '1.0': 0.09673865546218488}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.008610763249282666
Episodes: 2650, frames: 40109, time: 6320.5838351249695
training steps:  4696
retraining steps:  0
RDN obj mus: [-0.9546684091448784, -0.9625870822012424, -0.9562398740231991, -0.9439821593463421, -0.9270451415359974]
RDN obj sigmas: [0.02986539277080698, 0.02756622375575724, 0.03655835713774673, 0.050286759264936184, 0.06284939528938302]
2650 : 0.20833333333333334
LR:  0.001
replay buffer size:  41647
Time Taken :  105.0  mins 20.58364486694336  seconds
[[[5339. 3631.  537.    0.    0.    0.   10.    7.    7.    2.    3.
      0.]
  [4131. 2366.  340.   31.   26.   42.  170.  133.  151.   86.   29.
      4.]
  [3011. 2249.  961.  665.  554.  424.  275.   45.    6.    1.    1.
      0.]
  [2621. 1844.  240.   41.   29.   32.   21.    0.    0.    0.    0.
      0.]
  [3132. 3038. 1224.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  8
Q value #non_end_state_>threshold:  101
maxi score:  0.41509999999999997
siam score:  -0.7698087
Scores:  {'0.167': 0.3534007334963325, '0.333': 0.29442624113475174, '0.5': 0.1967019417475728, '0.667': 0.13219876543209874, '0.833': 0.10845214446952596, '1.0': 0.08751258741258741}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.017914000466164988
Episodes: 3150, frames: 50179, time: 8021.9143080711365
training steps:  5877
retraining steps:  0
RDN obj mus: [-0.9453959575414658, -0.960788576734066, -0.9594203135251999, -0.9530029233753681, -0.9242833771586418]
RDN obj sigmas: [0.029873017309856684, 0.028894865480700853, 0.029145065889058335, 0.04326187206985823, 0.06395877961572355]
3150 : 0.225
LR:  0.001
replay buffer size:  51952
Time Taken :  133.0  mins 41.914121866226196  seconds
[[[6491. 4549.  601.    0.    0.    0.   17.   16.   16.    7.    9.
      0.]
  [4934. 2942.  396.   42.   36.   61.  388.  410.  451.  283.  131.
     14.]
  [3672. 2848. 1299.  954.  798.  617.  467.   58.   15.    3.    7.
      0.]
  [3194. 2228.  284.   56.   37.   39.   25.    0.    0.    0.    0.
      0.]
  [3706. 3521. 1407.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  24
Q value #non_end_state_>threshold:  112
maxi score:  0.41309999999999997
siam score:  -0.7211581
Scores:  {'0.167': 0.36151906873614187, '0.333': 0.2969421052631579, '0.5': 0.19575217391304348, '0.667': 0.11580247933884298, '0.833': 0.10151987829614605, '1.0': 0.07726049382716049}
best rdn ma / adv:  0.167 0.833
best rdn adv:  0.021823830993871585
Episodes: 3574, frames: 60084, time: 9989.354808092117
training steps:  7038
retraining steps:  0
RDN obj mus: [-0.957943972748518, -0.9676408803284168, -0.9618928276002408, -0.9524383498132228, -0.9249173857867717]
RDN obj sigmas: [0.021504996433624118, 0.023194606702852935, 0.0294496020539905, 0.042516834468032914, 0.066674193937491]
3574 : 0.21666666666666667
LR:  0.001
replay buffer size:  62133
Time Taken :  166.0  mins 29.354622840881348  seconds
[[[8047. 5350.  652.    0.    0.    0.   20.   20.   19.    8.   11.
      0.]
  [5699. 3479.  462.   53.   45.   71.  469.  516.  577.  382.  176.
     19.]
  [4505. 3437. 1602. 1183.  975.  806.  597.   70.   16.   10.    9.
      0.]
  [4090. 2652.  317.   68.   51.   46.   29.    0.    0.    0.    0.
      0.]
  [4444. 3958. 1570.    0.    0.    0.    0.    0.    0.    0.    0.
      0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  42
Q value #non_end_state_>threshold:  145
maxi score:  0.40809999999999996
siam score:  -0.7420663
Scores:  {'0.167': 0.3671103092783505, '0.333': 0.3081, '0.5': 0.1914827655310621, '0.667': 0.1191, '0.833': 0.10110000000000001, '1.0': 0.0801}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.024592339839951297
Episodes: 3869, frames: 70024, time: 11895.91119503975
training steps:  8203
retraining steps:  0
RDN obj mus: [-0.9643294544935227, -0.9752439149618148, -0.967520050162077, -0.9529163481593133, -0.9154099871873855]
RDN obj sigmas: [0.021191055728452764, 0.017853234084558627, 0.027761360111069503, 0.039814054267971646, 0.06640150467650051]
3869 : 0.21666666666666667
LR:  0.001
replay buffer size:  72380
Time Taken :  198.0  mins 15.911008834838867  seconds
[[[11135.  6137.   693.     0.     0.     0.    22.    21.    20.     9.
      13.     0.]
  [ 6743.  3835.   499.    59.    50.    76.   537.   587.   642.   446.
     253.    26.]
  [ 5301.  3832.  1753.  1293.  1068.   894.   668.    74.    18.    14.
      11.     0.]
  [ 4799.  2907.   343.    71.    56.    49.    31.     0.     0.     0.
       0.     0.]
  [ 5160.  4321.  1689.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  45
Q value #non_end_state_>threshold:  169
maxi score:  0.3961
siam score:  -0.73939633
Scores:  {'0.167': 0.3891, '0.333': 0.3201, '0.5': 0.1981, '0.667': 0.1101, '0.833': 0.0941, '1.0': 0.0741}
best rdn ma / adv:  0.167 0.833
best rdn adv:  0.0245923398399513
Episodes: 4183, frames: 80025, time: 13677.05946111679
training steps:  9380
retraining steps:  0
RDN obj mus: [-0.9637327874064445, -0.9697615145802498, -0.9652022495150566, -0.9560168567538262, -0.9236999863028527]
RDN obj sigmas: [0.02767104000338763, 0.023079099356895616, 0.028316888318596342, 0.03632961525462177, 0.05426415635055406]
4183 : 0.17083333333333334
LR:  0.001
replay buffer size:  82648
Time Taken :  227.0  mins 57.059266805648804  seconds
[[[14053.  7010.   764.     0.     0.     0.    22.    22.    20.    12.
      13.     0.]
  [ 8253.  4231.   546.    65.    54.    76.   561.   607.   658.   468.
     261.    27.]
  [ 6091.  4190.  1874.  1344.  1118.   930.   702.    78.    18.    14.
      11.     0.]
  [ 5543.  3187.   372.    77.    60.    50.    33.     0.     0.     0.
       0.     0.]
  [ 5941.  4681.  1805.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  54
Q value #non_end_state_>threshold:  175
maxi score:  0.3891
siam score:  -0.7752313
Scores:  {'0.167': 0.4021, '0.333': 0.3241, '0.5': 0.1861, '0.667': 0.0921, '0.833': 0.0811, '1.0': 0.0591}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.02766638231994521
Episodes: 4471, frames: 90189, time: 15830.204715013504
training steps:  10571
retraining steps:  0
RDN obj mus: [-0.9772629596292972, -0.9769442243039608, -0.9764654231846333, -0.9635659395992756, -0.9396601297557354]
RDN obj sigmas: [0.012294128034583416, 0.020508171997459364, 0.022142726520287336, 0.029839016308397186, 0.05569882495255066]
4471 : 0.15833333333333333
LR:  0.001
replay buffer size:  93089
Time Taken :  263.0  mins 50.204529762268066  seconds
[[[16625.  7647.   804.     0.     0.     0.    25.    23.    22.    13.
      13.     0.]
  [10346.  4583.   596.    73.    59.    80.   589.   630.   678.   488.
     267.    30.]
  [ 7190.  4510.  1983.  1406.  1164.   964.   738.    80.    18.    14.
      11.     0.]
  [ 6367.  3434.   404.    85.    63.    52.    34.     0.     0.     0.
       0.     0.]
  [ 6698.  5010.  1902.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  57
Q value #non_end_state_>threshold:  183
maxi score:  0.3931
siam score:  -0.7934001
Scores:  {'0.167': 0.4041, '0.333': 0.3191, '0.5': 0.17209999999999998, '0.667': 0.0551, '0.833': 0.057100000000000005, '1.0': 0.034100000000000005}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.02766638231994521
Episodes: 4765, frames: 100217, time: 18318.32595705986
training steps:  11746
retraining steps:  0
RDN obj mus: [-0.972637563598156, -0.97751231264472, -0.968209192353487, -0.9648615490615368, -0.9524818180263043]
RDN obj sigmas: [0.025911964553752026, 0.029323066449308672, 0.03445397396309043, 0.03626015201614284, 0.044404066082477954]
4765 : 0.16666666666666666
LR:  0.001
replay buffer size:  103380
Time Taken :  305.0  mins 18.325772762298584  seconds
[[[18986.  8239.   842.     0.     0.     0.    26.    25.    24.    13.
      13.     0.]
  [12533.  4955.   645.    82.    67.    83.   625.   657.   714.   513.
     278.    32.]
  [ 8178.  4809.  2106.  1490.  1211.   986.   773.    83.    20.    15.
      11.     0.]
  [ 7212.  3731.   435.   100.    68.    54.    35.     0.     0.     0.
       0.     0.]
  [ 7423.  5350.  2010.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  62
Q value #non_end_state_>threshold:  194
maxi score:  0.3881
siam score:  -0.80603147
Scores:  {'0.167': 0.4041, '0.333': 0.3041, '0.5': 0.1551, '0.667': 0.0531, '0.833': 0.0361, '1.0': 0.026099999999999998}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.03074042479993912
Episodes: 5035, frames: 110075, time: 20769.771546125412
training steps:  12901
retraining steps:  0
RDN obj mus: [-0.964019425535202, -0.9509562071502209, -0.9662175541877747, -0.9670018066108227, -0.9468556824982166]
RDN obj sigmas: [0.027939810559312002, 0.03429313999678858, 0.03215319841575929, 0.031659448340519314, 0.0451674536609369]
5035 : 0.20833333333333334
LR:  0.001
replay buffer size:  113547
Time Taken :  346.0  mins 9.771359920501709  seconds
[[[21814.  8791.   892.     0.     0.     0.    26.    25.    25.    13.
      13.     0.]
  [14142.  5253.   678.    93.    68.    87.   654.   673.   741.   564.
     310.    34.]
  [ 9109.  5072.  2196.  1541.  1235.  1012.   802.    85.    20.    17.
      13.     0.]
  [ 7981.  3980.   454.   114.    69.    55.    35.     0.     0.     0.
       0.     0.]
  [ 8543.  5699.  2112.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  198
maxi score:  0.3841
siam score:  -0.7977999
Scores:  {'0.167': 0.4011, '0.333': 0.3011, '0.5': 0.1331, '0.667': 0.058100000000000006, '0.833': 0.032100000000000004, '1.0': 0.0251}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.03074042479993912
Episodes: 5339, frames: 120092, time: 23202.773968696594
training steps:  14076
retraining steps:  0
RDN obj mus: [-0.9774608293652535, -0.9822753380656243, -0.9793510280430316, -0.9695646079838276, -0.9557757539510727]
RDN obj sigmas: [0.019879307461391774, 0.013909079431720088, 0.020378849701629228, 0.031326141068909893, 0.04212859312151318]
5339 : 0.175
LR:  0.001
replay buffer size:  123893
Time Taken :  386.0  mins 42.77377676963806  seconds
[[[24794.  9605.   959.     0.     0.     0.    26.    25.    26.    14.
      14.     0.]
  [15740.  5688.   720.    99.    74.    96.   699.   691.   771.   607.
     331.    35.]
  [ 9987.  5408.  2315.  1617.  1289.  1058.   842.    91.    22.    17.
      14.     0.]
  [ 8662.  4211.   478.   121.    73.    58.    37.     0.     0.     0.
       0.     0.]
  [ 9245.  5975.  2219.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  205
maxi score:  0.3801
siam score:  -0.77507216
Scores:  {'0.167': 0.3991, '0.333': 0.2991, '0.5': 0.1261, '0.667': 0.0551, '0.833': 0.0311, '1.0': 0.026099999999999998}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.03074042479993912
Episodes: 5570, frames: 130091, time: 25616.645640850067
training steps:  15262
retraining steps:  0
RDN obj mus: [-0.9737385100185871, -0.9761566374480725, -0.9757063823223114, -0.9722506773173809, -0.9495491106748581]
RDN obj sigmas: [0.01546688557229903, 0.019816800819898384, 0.01879885018503779, 0.02499493101140753, 0.04261859930620593]
5570 : 0.125
LR:  0.001
replay buffer size:  134384
Time Taken :  426.0  mins 56.645447731018066  seconds
[[[28186. 10458.  1007.     0.     0.     0.    26.    25.    26.    14.
      14.     0.]
  [17781.  6046.   753.   109.    77.    98.   703.   692.   771.   607.
     331.    35.]
  [10859.  5659.  2397.  1664.  1308.  1068.   848.    95.    22.    17.
      14.     0.]
  [ 9362.  4437.   495.   125.    76.    58.    37.     0.     0.     0.
       0.     0.]
  [ 9768.  6166.  2287.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  205
maxi score:  0.3851
siam score:  -0.78368074
Scores:  {'0.167': 0.3981, '0.333': 0.29009999999999997, '0.5': 0.1291, '0.667': 0.0531, '0.833': 0.0301, '1.0': 0.0251}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.03074042479993912
Episodes: 5816, frames: 140054, time: 28094.927761793137
training steps:  16424
retraining steps:  0
RDN obj mus: [-0.9737410602807999, -0.9689632462203502, -0.9767182012200355, -0.9761218146264553, -0.9552937825739384]
RDN obj sigmas: [0.016377648971711685, 0.01912608748953591, 0.018221623669750827, 0.020321989141497066, 0.03885014758598661]
5816 : 0.16666666666666666
LR:  0.001
replay buffer size:  144702
Time Taken :  468.0  mins 14.927572965621948  seconds
[[[31063. 11306.  1066.     0.     0.     0.    26.    25.    27.    14.
      14.     0.]
  [19534.  6453.   787.   118.    81.    99.   707.   694.   775.   614.
     332.    35.]
  [11941.  6003.  2516.  1720.  1321.  1073.   851.    95.    22.    18.
      14.     0.]
  [10226.  4678.   518.   133.    78.    58.    38.     0.     0.     0.
       0.     0.]
  [10400.  6403.  2362.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  205
maxi score:  0.3821
siam score:  -0.773325
Scores:  {'0.167': 0.4011, '0.333': 0.28909999999999997, '0.5': 0.1251, '0.667': 0.050100000000000006, '0.833': 0.0291, '1.0': 0.0281}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.033814467279933036
Episodes: 6050, frames: 150064, time: 30501.559134960175
training steps:  17592
retraining steps:  0
RDN obj mus: [-0.9754874360918999, -0.9823363148510456, -0.9799793910264969, -0.9665365387022495, -0.9417413098454476]
RDN obj sigmas: [0.01973490251631368, 0.012249210730403137, 0.014480097543032797, 0.022801717008142385, 0.0368504367450222]
6050 : 0.17916666666666667
LR:  0.001
replay buffer size:  154968
Time Taken :  508.0  mins 21.55895972251892  seconds
[[[34697. 12306.  1122.     0.     0.     0.    26.    25.    27.    14.
      14.     0.]
  [21087.  6820.   816.   125.    84.   101.   712.   698.   778.   620.
     335.    36.]
  [12766.  6288.  2606.  1768.  1350.  1078.   853.    95.    22.    18.
      14.     0.]
  [10910.  4925.   534.   138.    81.    58.    38.     0.     0.     0.
       0.     0.]
  [10960.  6625.  2444.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  205
maxi score:  0.3801
siam score:  -0.75257486
Scores:  {'0.167': 0.4051, '0.333': 0.2781, '0.5': 0.1181, '0.667': 0.0471, '0.833': 0.026099999999999998, '1.0': 0.0231}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.02766638231994521
Episodes: 6309, frames: 160011, time: 32949.876584768295
training steps:  18758
retraining steps:  0
RDN obj mus: [-0.9736551425993443, -0.9791026997447014, -0.9732954517841339, -0.9644257013738156, -0.9485596714735031]
RDN obj sigmas: [0.01517601316244004, 0.015399395313094586, 0.01663604560523147, 0.022627075553702358, 0.02944941822033818]
6309 : 0.14166666666666666
LR:  0.001
replay buffer size:  165408
Time Taken :  549.0  mins 9.876401901245117  seconds
[[[38037. 13419.  1184.     0.     0.     0.    26.    25.    27.    15.
      14.     0.]
  [22757.  7225.   858.   134.    87.   104.   714.   701.   783.   632.
     352.    36.]
  [13839.  6617.  2718.  1817.  1367.  1084.   858.    96.    22.    18.
      15.     0.]
  [11358.  5090.   551.   144.    85.    58.    38.     0.     0.     0.
       0.     0.]
  [11464.  6817.  2516.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  205
maxi score:  0.3691
siam score:  -0.7688408
Scores:  {'0.167': 0.3941, '0.333': 0.2731, '0.5': 0.1091, '0.667': 0.0471, '0.833': 0.0231, '1.0': 0.0201}
best rdn ma / adv:  0.167 0.667
best rdn adv:  0.0245923398399513
Episodes: 6577, frames: 170073, time: 35262.1491959095
training steps:  19939
retraining steps:  0
RDN obj mus: [-0.9507082664430141, -0.9779815351009369, -0.9729187154650688, -0.9502342219829559, -0.8977129070818424]
RDN obj sigmas: [0.0665967454980463, 0.016540105637320127, 0.021084380088434385, 0.05769155879137795, 0.0814542740677463]
6577 : 0.1625
LR:  0.001
replay buffer size:  175946
Time Taken :  587.0  mins 42.149006843566895  seconds
[[[41286. 14425.  1263.     0.     0.     0.    26.    25.    27.    15.
      14.     0.]
  [24444.  7686.   914.   139.    91.   106.   714.   701.   783.   632.
     352.    36.]
  [14776.  6904.  2793.  1842.  1378.  1089.   858.    96.    22.    18.
      15.     0.]
  [12012.  5278.   569.   146.    85.    59.    38.     0.     0.     0.
       0.     0.]
  [12248.  7005.  2586.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  207
maxi score:  0.35409999999999997
siam score:  -0.75026536
Scores:  {'0.167': 0.3951, '0.333': 0.2561, '0.5': 0.1021, '0.667': 0.042100000000000005, '0.833': 0.0191, '1.0': 0.0201}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.024592339839951297
Episodes: 6837, frames: 180121, time: 37579.4292447567
training steps:  21112
retraining steps:  0
RDN obj mus: [-0.9780691169857979, -0.9780133158385753, -0.9755780704498291, -0.9682951977670192, -0.9421157271206378]
RDN obj sigmas: [0.013302619120282083, 0.015604062303533072, 0.015865995037941425, 0.022743167640697434, 0.06422958679893997]
6837 : 0.10833333333333334
LR:  0.001
replay buffer size:  186353
Time Taken :  626.0  mins 19.42905592918396  seconds
[[[44530. 15510.  1342.     0.     0.     0.    27.    25.    27.    15.
      14.     0.]
  [26132.  8122.   961.   140.    95.   107.   720.   702.   784.   638.
     356.    37.]
  [15689.  7239.  2873.  1884.  1396.  1100.   863.    96.    22.    18.
      15.     0.]
  [12688.  5504.   588.   150.    85.    59.    38.     0.     0.     0.
       0.     0.]
  [12830.  7211.  2652.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  207
maxi score:  0.3581
siam score:  -0.75381833
Scores:  {'0.167': 0.3881, '0.333': 0.2481, '0.5': 0.1021, '0.667': 0.041100000000000005, '0.833': 0.0171, '1.0': 0.0171}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.018444254879963474
Episodes: 7094, frames: 190182, time: 40060.77405881882
training steps:  22299
retraining steps:  0
RDN obj mus: [-0.9735128370165825, -0.9693670190811158, -0.9711440749526024, -0.9680540811896324, -0.9412918070614338]
RDN obj sigmas: [0.013006556359952891, 0.02009036369593324, 0.016065673283167558, 0.023299507968903753, 0.0456829183687671]
7094 : 0.13333333333333333
LR:  0.001
replay buffer size:  196798
Time Taken :  667.0  mins 40.77387595176697  seconds
[[[47191. 16514.  1409.     0.     0.     0.    27.    25.    27.    15.
      14.     0.]
  [27939.  8570.  1009.   144.    95.   107.   720.   702.   784.   638.
     356.    37.]
  [16799.  7596.  2949.  1904.  1400.  1100.   863.    96.    22.    18.
      15.     0.]
  [13398.  5747.   609.   151.    88.    59.    38.     0.     0.     0.
       0.     0.]
  [13629.  7554.  2730.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  207
maxi score:  0.35609999999999997
siam score:  -0.74039793
Scores:  {'0.167': 0.3871, '0.333': 0.2341, '0.5': 0.0931, '0.667': 0.0371, '0.833': 0.0161, '1.0': 0.0171}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.018444254879963474
Episodes: 7360, frames: 200035, time: 42410.76555109024
training steps:  23448
retraining steps:  0
RDN obj mus: [-0.9804123338937759, -0.9839713909089566, -0.9791627288639545, -0.9665425677597522, -0.9496237955272198]
RDN obj sigmas: [0.009509140182593778, 0.012356163059553234, 0.016522934251585228, 0.02498162134218919, 0.032365845611492305]
7360 : 0.1625
LR:  0.001
replay buffer size:  200020
Time Taken :  706.0  mins 50.76536583900452  seconds
[[[50090. 17799.  1486.     0.     0.     0.    27.    25.    27.    15.
      14.     0.]
  [29391.  9047.  1055.   146.    96.   107.   720.   702.   784.   638.
     356.    37.]
  [17632.  7892.  2997.  1918.  1407.  1101.   864.    97.    22.    18.
      15.     0.]
  [13920.  5976.   634.   153.    90.    59.    38.     0.     0.     0.
       0.     0.]
  [14552.  7915.  2813.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  207
maxi score:  0.3591
siam score:  -0.74607736
Scores:  {'0.167': 0.3821, '0.333': 0.2251, '0.5': 0.08510000000000001, '0.667': 0.033100000000000004, '0.833': 0.0161, '1.0': 0.015099999999999999}
best rdn ma / adv:  0.167 1.0
best rdn adv:  0.01537021239996956
Episodes: 7604, frames: 210109, time: 44991.55133795738
training steps:  24636
retraining steps:  0
RDN obj mus: [-0.9771495509326458, -0.9779281066775322, -0.9761818842589856, -0.9713350042283535, -0.9498752652704716]
RDN obj sigmas: [0.011134534010498302, 0.01570774799074069, 0.01608112794830615, 0.0191165428623451, 0.05272712128280053]
7604 : 0.15
LR:  0.001
replay buffer size:  200057
Time Taken :  749.0  mins 51.55115485191345  seconds
[[[53569. 18904.  1562.     0.     0.     0.    27.    25.    27.    15.
      14.     0.]
  [30936.  9517.  1104.   151.    96.   107.   721.   702.   784.   638.
     356.    37.]
  [18488.  8221.  3069.  1961.  1412.  1103.   866.    97.    22.    18.
      15.     0.]
  [14502.  6174.   647.   157.    90.    59.    39.     0.     0.     0.
       0.     0.]
  [15200.  8194.  2879.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  207
maxi score:  0.35209999999999997
siam score:  -0.71412253
Scores:  {'0.167': 0.3771, '0.333': 0.2161, '0.5': 0.0791, '0.667': 0.0291, '0.833': 0.015099999999999999, '1.0': 0.0101}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.009222127439981737
Episodes: 7934, frames: 220032, time: 47608.21246981621
training steps:  25798
retraining steps:  0
RDN obj mus: [-0.9759671056509018, -0.980009705632925, -0.9723308506071567, -0.9675615874409675, -0.9375487410187722]
RDN obj sigmas: [0.01068158937781465, 0.010950078321643412, 0.013740914695709185, 0.020882911401564987, 0.06616114518730835]
7934 : 0.14583333333333334
LR:  0.001
replay buffer size:  200091
Time Taken :  793.0  mins 28.21228265762329  seconds
[[[56152. 20155.  1679.     0.     0.     0.    27.    25.    27.    15.
      14.     0.]
  [32347. 10060.  1169.   156.    96.   107.   721.   702.   784.   638.
     356.    37.]
  [19255.  8562.  3156.  2019.  1425.  1103.   866.    97.    22.    18.
      15.     0.]
  [15140.  6458.   678.   159.    90.    59.    39.     0.     0.     0.
       0.     0.]
  [16102.  8593.  2975.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  67
Q value #non_end_state_>threshold:  234
maxi score:  0.35109999999999997
siam score:  -0.7288045
Scores:  {'0.167': 0.3771, '0.333': 0.20609999999999998, '0.5': 0.0761, '0.667': 0.0291, '0.833': 0.013099999999999999, '1.0': 0.009099999999999999}
best rdn ma / adv:  0.167 0.5
best rdn adv:  0.006148084959987824
Episodes: 8210, frames: 230039, time: 50753.752676963806
training steps:  26966
retraining steps:  0
RDN obj mus: [-0.9752583844542503, -0.9789671256363391, -0.9758917869389058, -0.9608138258874417, -0.94839505443573]
RDN obj sigmas: [0.012780551827587187, 0.009453870015459814, 0.01534610011515589, 0.023416115915377022, 0.033294695961273865]
8210 : 0.14583333333333334
LR:  0.001
replay buffer size:  200062
Time Taken :  845.0  mins 53.752506732940674  seconds
[[[58482. 21088.  1737.     0.     0.     0.    27.    25.    27.    15.
      14.     0.]
  [33909. 10617.  1242.   159.    98.   107.   721.   702.   784.   638.
     356.    37.]
  [20086.  8925.  3290.  2119.  1454.  1105.   866.    97.    22.    18.
      15.     0.]
  [15808.  6659.   707.   166.    90.    60.    39.     0.     0.     0.
       0.     0.]
  [17537.  8929.  3052.     0.     0.     0.     0.     0.     0.     0.
       0.     0.]]]
