EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.0033478812547400594
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 94, frames: 1057, time: 31.844524145126343
training steps:  3
retraining steps:  0
RDN obj mus: [0.056453576717331276, 0.0736608717735134, 0.0, 0.0, 0.0]
RDN obj sigmas: [0.009633228594666846, 0.007100430276611262, 0.0, 0.0, 0.0]
94 : 0.0
LR:  2e-06
replay buffer size:  1370
Time Taken :  0.0  mins 31.84423017501831  seconds
[[[296. 144.  53.  17.   6.   0.   0.   0.]
  [156.  65.  10.   3.   0.   0.   0.   0.]
  [105.  26.  11.   0.   0.   0.   0.   0.]
  [ 42.  11.   7.   0.   0.   0.   0.   0.]
  [  9.   2.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.66896486
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 901, frames: 10050, time: 1618.3215789794922
training steps:  1179
retraining steps:  0
RDN obj mus: [-0.9646270968198776, -0.9657426611125469, -0.9555896142780781, -0.946778027698855, -0.6501509547233582]
RDN obj sigmas: [0.02459291265986899, 0.021567382897670583, 0.022555072464251678, 0.06235594708021772, 0.45974420031946134]
901 : 0.0
LR:  0.001
replay buffer size:  10605
Time Taken :  26.0  mins 58.32129502296448  seconds
[[[2973. 1360.  496.  208.   41.    2.    2.    0.]
  [1510.  611.  115.   65.   27.   12.    5.    0.]
  [ 757.  217.   71.   27.   13.    5.    4.    0.]
  [ 294.   93.   35.   19.    5.    1.    0.    0.]
  [  89.   13.   10.   11.    6.    1.    0.    0.]
  [  26.   10.    6.    3.    0.    0.    0.    0.]
  [   3.    2.    0.    0.    0.    0.    0.    0.]
  [   1.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.71057695
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 1669, frames: 20071, time: 4649.094322919846
training steps:  2347
retraining steps:  0
RDN obj mus: [-0.9600162070214748, -0.9602360798954964, -0.9643945073902607, -0.9413989545151942, -0.9172588403408344]
RDN obj sigmas: [0.01754531364355646, 0.016069673212610578, 0.020959682060476294, 0.05585865569474144, 0.14984288762057185]
1669 : 0.0
LR:  0.001
replay buffer size:  20887
Time Taken :  77.0  mins 29.094032049179077  seconds
[[[6062. 2906. 1051.  434.   83.    5.    7.    5.]
  [2946. 1095.  236.  150.   63.   20.    8.   10.]
  [1422.  409.  144.   80.   55.   12.    4.    4.]
  [ 511.  173.   55.   33.   17.    5.    2.    3.]
  [ 185.   31.   21.   19.   11.    1.    0.    0.]
  [  66.   21.   11.    3.    0.    0.    0.    0.]
  [  18.    2.    0.    0.    0.    0.    0.    0.]
  [   3.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7049678
Scores:  {'0.167': 0.0001, '0.333': 0.0021, '0.5': 0.0001, '0.667': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.00199960002
Episodes: 2230, frames: 30183, time: 8392.078295946121
training steps:  3529
retraining steps:  0
RDN obj mus: [-0.9483907532393933, -0.9522664990901947, -0.9481609553098679, -0.943075704395771, -0.9358601016814431]
RDN obj sigmas: [0.02230298822164165, 0.02147168309211622, 0.021696882780667125, 0.020331107050773647, 0.025362219033190997]
2230 : 0.0
LR:  0.001
replay buffer size:  31169
Time Taken :  139.0  mins 52.07800221443176  seconds
[[[7192. 3601. 1504.  833.  124.   67.   40.  267.]
  [3595. 1295.  292.  457.  286.  270.  126.  271.]
  [1824.  568.  327.  398.  404.  192.   41.  146.]
  [ 703.  234.  186.  243.  221.  147.  117.  208.]
  [ 316.   54.   87.  109.   39.   90.  113.  194.]
  [ 169.   35.   69.   16.    2.   54.   75.  148.]
  [  52.   13.   18.    3.   10.   37.   15.   13.]
  [   6.    0.    6.    5.   10.    7.    8.    1.]]]
Test reward:  0.05
Q value #end_state_>_threshold:  7
Q value #non_end_state_>threshold:  17
maxi score:  0.0021
siam score:  -0.84339356
Scores:  {'0.167': 0.0001, '0.333': 0.022099999999999998, '0.5': 0.004447826086956522, '0.667': 0.0021283975659229207}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.021907697020000002
Episodes: 2791, frames: 40052, time: 10919.623342990875
training steps:  4697
retraining steps:  0
RDN obj mus: [-0.9514868601679802, -0.9607852461397648, -0.95423350558877, -0.9455460190176964, -0.9356561118066311]
RDN obj sigmas: [0.019009339302352858, 0.01645854220381617, 0.018247515151344033, 0.02128232592715617, 0.024147955773272736]
2791 : 0.0
LR:  0.001
replay buffer size:  41418
Time Taken :  181.0  mins 59.623050928115845  seconds
[[[8032. 4202. 1894. 1089.  151.  294.   66.  684.]
  [4169. 1498.  353.  662.  453.  448.  182.  413.]
  [2265.  723.  465.  533.  510.  267.   60.  269.]
  [ 965.  287.  321.  331.  310.  257.  200.  314.]
  [ 501.   72.  215.  146.   56.  163.  217.  325.]
  [ 407.   67.  181.   45.   64.  156.  159.  278.]
  [ 185.   26.   77.   79.  215.  140.   27.   17.]
  [  21.    0.   14.  110.  324.  203.   90.   14.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  52
Q value #non_end_state_>threshold:  39
maxi score:  0.0041
siam score:  -0.864332
Scores:  {'0.167': 0.0001, '0.333': 0.0301, '0.5': 0.0061, '0.667': 0.0021}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.027075000000000002
Episodes: 3438, frames: 50203, time: 13499.369900941849
training steps:  5880
retraining steps:  0
RDN obj mus: [-0.9509192137539387, -0.9561058691322804, -0.9588761601388455, -0.9531727923870087, -0.938253178948164]
RDN obj sigmas: [0.0172877749364671, 0.019501182462815205, 0.01872924123112827, 0.020598866158759995, 0.027882923169599543]
3438 : 0.1
LR:  0.001
replay buffer size:  51821
Time Taken :  224.0  mins 59.36960816383362  seconds
[[[8893. 4667. 2163. 1316.  187.  375.   74.  684.]
  [4915. 1724.  397.  741.  514.  522.  197.  415.]
  [2934.  910.  622.  588.  545.  304.   70.  274.]
  [1532.  359.  478.  388.  330.  295.  216.  323.]
  [1000.  109.  414.  184.   68.  206.  246.  352.]
  [1002.  125.  333.   70.  213.  306.  186.  308.]
  [ 662.   62.  197.  322.  505.  262.   35.   18.]
  [  60.    0.   29.  432.  597.  313.  169.   28.]]]
Test reward:  0.5
Q value #end_state_>_threshold:  233
Q value #non_end_state_>threshold:  167
maxi score:  0.026099999999999998
siam score:  -0.8918011
Scores:  {'0.167': 0.0201, '0.333': 0.0901, '0.5': 0.0061, '0.667': 0.0041}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0853633089
Episodes: 3919, frames: 60245, time: 16215.108382940292
training steps:  7062
retraining steps:  0
RDN obj mus: [-0.9464183516144753, -0.9640577752768993, -0.9661126315295696, -0.9605978685557842, -0.9506810305178165]
RDN obj sigmas: [0.01628518981098995, 0.01486152277645936, 0.013202832834775254, 0.017366000222875964, 0.019073708513661015]
3919 : 0.1
LR:  0.001
replay buffer size:  62868
Time Taken :  270.0  mins 15.108093023300171  seconds
[[[9479. 5216. 2580. 1721.  235.  589.   92.  684.]
  [5349. 1846.  441.  913.  630.  704.  247.  422.]
  [3297. 1082.  806.  727.  635.  431.   80.  295.]
  [1722.  406.  705.  524.  424.  535.  315.  390.]
  [1128.  129.  693.  328.   87.  372.  436.  466.]
  [1110.  143.  550.   96.  366.  569.  281.  404.]
  [ 735.   75.  329.  624.  738.  386.   47.   24.]
  [  69.    0.   43.  823.  887.  538.  253.   75.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  389
Q value #non_end_state_>threshold:  759
maxi score:  0.0801
siam score:  -0.96210366
Scores:  {'0.167': 0.0781, '0.333': 0.1321, '0.5': 0.0081, '0.667': 0.0041}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.033
Episodes: 4278, frames: 70032, time: 18795.854542016983
training steps:  8204
retraining steps:  0
RDN obj mus: [-0.9547102412641049, -0.9685060034632683, -0.9700891043543816, -0.9644924219369888, -0.9532085435450077]
RDN obj sigmas: [0.016917117802261794, 0.012205074477794356, 0.013004770795179196, 0.01851557802031574, 0.03057551603540292]
4278 : 0.2
LR:  0.001
replay buffer size:  73030
Time Taken :  313.0  mins 15.854249954223633  seconds
[[[10010.  5624.  2890.  2026.   259.   649.    98.   712.]
  [ 5699.  1907.   465.  1068.   744.   794.   259.   429.]
  [ 3644.  1254.   982.   908.   822.   579.    91.   300.]
  [ 1943.   436.   874.   634.   546.   769.   404.   485.]
  [ 1273.   140.   891.   394.   105.   571.   612.   774.]
  [ 1242.   152.   697.   121.   515.   762.   365.   511.]
  [  861.    86.   456.   914.  1070.   580.    60.    26.]
  [   86.     0.    53.  1196.  1444.   964.   387.   142.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  627
Q value #non_end_state_>threshold:  1788
maxi score:  0.1561
siam score:  -0.93033063
Scores:  {'0.167': 0.1281, '0.333': 0.14809999999999998, '0.5': 0.0081, '0.667': 0.0081}
best rdn ma / adv:  0.333 0.167
best rdn adv:  0.0
Episodes: 4541, frames: 80182, time: 21502.138431072235
training steps:  9388
retraining steps:  0
RDN obj mus: [-0.9536589034199715, -0.9762253480195999, -0.9731046264111995, -0.9719345087826252, -0.9615631104111672]
RDN obj sigmas: [0.022354883298901194, 0.012129507845404572, 0.013526885889079706, 0.014554444978024893, 0.02296405100223118]
4541 : 0.15
LR:  0.001
replay buffer size:  83751
Time Taken :  358.0  mins 22.13813805580139  seconds
[[[10431.  6023.  3325.  2453.   285.   709.   105.   781.]
  [ 5874.  1928.   482.  1232.   877.   913.   318.   528.]
  [ 3807.  1377.  1136.  1101.  1162.   909.   110.   395.]
  [ 1966.   450.  1052.   795.   675.  1266.   555.   650.]
  [ 1288.   142.  1080.   471.   119.   839.   813.  1191.]
  [ 1314.   157.   854.   141.   688.  1097.   461.   676.]
  [  893.    96.   622.  1316.  1510.   824.    72.    31.]
  [   86.     0.    63.  1442.  1793.  1190.   505.   197.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  968
Q value #non_end_state_>threshold:  2526
maxi score:  0.2221
siam score:  -0.8998078
Scores:  {'0.167': 0.17409999999999998, '0.333': 0.1621, '0.5': 0.0101, '0.667': 0.0081}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 4804, frames: 90074, time: 24191.23290205002
training steps:  10548
retraining steps:  0
RDN obj mus: [-0.9644637531876564, -0.9749086204051971, -0.9763700274467468, -0.9716704646468163, -0.9574171889960765]
RDN obj sigmas: [0.021335786587790027, 0.012781493923277237, 0.012932040667897155, 0.015564536811333778, 0.03811052225649253]
4804 : 0.25
LR:  0.001
replay buffer size:  93988
Time Taken :  403.0  mins 11.23261308670044  seconds
[[[11395.  6506.  3805.  3045.   310.   971.   115.   867.]
  [ 6028.  1954.   501.  1421.  1054.  1123.   349.   572.]
  [ 3967.  1474.  1260.  1354.  1464.  1271.   126.   505.]
  [ 2012.   461.  1223.   890.   813.  1726.   665.   748.]
  [ 1326.   150.  1305.   508.   131.  1151.   964.  1334.]
  [ 1423.   164.  1034.   151.   796.  1447.   588.   725.]
  [ 1007.   107.   771.  1464.  1701.  1000.    86.    33.]
  [   86.     0.    71.  1575.  2001.  1346.   594.   256.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1440
Q value #non_end_state_>threshold:  3623
maxi score:  0.3141
siam score:  -0.8832048
Scores:  {'0.167': 0.2341, '0.333': 0.18409999999999999, '0.5': 0.0141, '0.667': 0.0081}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 5095, frames: 100077, time: 26931.55681324005
training steps:  11732
retraining steps:  0
RDN obj mus: [-0.9742096030175685, -0.9798766248941422, -0.9808220021188259, -0.9794149226784706, -0.9738916718304157]
RDN obj sigmas: [0.01395218295713233, 0.009857445570373852, 0.011391465798559743, 0.01199857935523189, 0.02017117703117022]
5095 : 0.5
LR:  0.001
replay buffer size:  104313
Time Taken :  448.0  mins 51.556522846221924  seconds
[[[11786.  6901.  4217.  3414.   343.  1501.   134.   879.]
  [ 6172.  1978.   517.  1668.  1251.  1450.   442.   668.]
  [ 4115.  1580.  1387.  1652.  1915.  1672.   141.   698.]
  [ 2018.   473.  1367.  1053.  1068.  2104.   861.  1002.]
  [ 1328.   158.  1493.   621.   145.  1494.  1110.  1468.]
  [ 1423.   173.  1284.   165.   888.  1795.   694.   798.]
  [ 1007.   111.  1090.  1606.  1824.  1175.    97.    34.]
  [   86.     0.    80.  1691.  2127.  1526.   726.   338.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1810
Q value #non_end_state_>threshold:  4492
maxi score:  0.4381
siam score:  -0.8460826
Scores:  {'0.167': 0.2701, '0.333': 0.17409999999999998, '0.5': 0.0141, '0.667': 0.0081}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 5334, frames: 110019, time: 29651.39965081215
training steps:  12893
retraining steps:  0
RDN obj mus: [-0.9780031974136829, -0.982350669825077, -0.9832295005738735, -0.9799243755698204, -0.9758458504915237]
RDN obj sigmas: [0.011743995929922665, 0.009081294204556932, 0.00909769757061693, 0.010658042249205697, 0.013044560550379242]
5334 : 0.1
LR:  0.001
replay buffer size:  114573
Time Taken :  494.0  mins 11.39936089515686  seconds
[[[12380.  7288.  4607.  3840.   363.  1982.   160.   926.]
  [ 6268.  1986.   540.  2002.  1663.  2078.   711.   987.]
  [ 4210.  1672.  1532.  2034.  2565.  2225.   165.   758.]
  [ 2032.   480.  1514.  1284.  1308.  2465.   966.  1040.]
  [ 1329.   166.  1659.   691.   156.  1721.  1172.  1493.]
  [ 1427.   181.  1476.   173.   934.  2014.   748.   832.]
  [ 1011.   114.  1283.  1716.  1891.  1322.   101.    34.]
  [   86.     0.    85.  1746.  2207.  1669.   819.   398.]]]
