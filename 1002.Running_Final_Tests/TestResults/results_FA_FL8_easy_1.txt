EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.00466196615404139
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 173, frames: 970, time: 25.391539812088013
training steps:  1
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
173 : 0.0
LR:  0.0
replay buffer size:  1129
Time Taken :  0.0  mins 25.391093015670776  seconds
[[[369. 130.   4.   3.   0.   0.   0.   0.]
  [154.  39.  30.   7.   0.   0.   0.   0.]
  [ 31.   9.   9.   3.   0.   0.   0.   0.]
  [  1.   2.   0.   0.   0.   0.   0.   0.]
  [  0.   3.   1.   0.   0.   0.   0.   0.]
  [  1.   1.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.24419384
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 1696, frames: 10100, time: 21331.39497280121
training steps:  871
retraining steps:  0
RDN obj mus: [-0.9508753075838089, -0.9685077496945858, -0.9619273956239224, -0.9303571422286973, -0.4771052300930023]
RDN obj sigmas: [0.017082896585827397, 0.010058680375197143, 0.017280385219576637, 0.04998672707967954, 0.4771052300930023]
1696 : 0.0
LR:  0.00087
replay buffer size:  10408
Time Taken :  355.0  mins 31.39456295967102  seconds
[[[3241. 1180.   42.   22.    5.    0.    0.    0.]
  [1884.  605.  202.   48.    3.    0.    0.    0.]
  [ 400.  191.  124.   27.    1.    3.    3.    0.]
  [  12.   90.   61.    7.    3.    1.    0.    0.]
  [  13.   53.   35.    7.    0.    0.    0.    0.]
  [   9.   22.   16.    6.    1.    1.    0.    0.]
  [   2.   12.   16.    4.    2.    1.    0.    0.]
  [   8.    7.   15.   16.    3.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.45906138
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 3333, frames: 20176, time: 23131.96237373352
training steps:  1735
retraining steps:  0
RDN obj mus: [-0.9399140145838261, -0.9508651516675949, -0.9546478036284447, -0.929818073824086, -0.9115717635359816]
RDN obj sigmas: [0.02644374262015591, 0.0250879763840419, 0.02656488539735819, 0.0482412276815604, 0.09864305725126804]
3333 : 0.0
LR:  0.001
replay buffer size:  20628
Time Taken :  385.0  mins 31.9619460105896  seconds
[[[6863. 2325.  108.   56.   14.    4.    0.    0.]
  [3687. 1157.  376.   88.    3.    0.    0.    0.]
  [ 783.  375.  228.   57.    1.    3.    3.    0.]
  [  32.  163.  130.   29.    7.    1.    0.    0.]
  [  23.   77.   58.   12.    0.    0.    0.    0.]
  [  12.   26.   23.    6.    1.    1.    0.    0.]
  [   6.   13.   19.    6.    2.    1.    0.    0.]
  [  12.    9.   21.   18.    4.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.5487064
Scores:  {'0.167': 0.0001, '0.333': 0.0001, '0.5': 0.0001, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0001}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 4497, frames: 30026, time: 26343.079090833664
training steps:  2575
retraining steps:  0
RDN obj mus: [-0.951545567214489, -0.9621957856893539, -0.9486492471754551, -0.9431833760440349, -0.9344045644575469]
RDN obj sigmas: [0.024584781101482905, 0.02052927498283223, 0.0238454199135797, 0.027701037915210922, 0.03677445292603094]
4497 : 0.0
LR:  0.001
replay buffer size:  30622
Time Taken :  439.0  mins 3.078700065612793  seconds
[[[9597. 3007.  234.  121.   41.    7.    0.    0.]
  [5653. 1763.  699.  148.   12.    2.    0.    0.]
  [1103.  705.  496.   84.    5.    3.    3.    0.]
  [  47.  330.  306.   88.   14.    1.    0.    0.]
  [  44.  170.  157.   25.    0.    0.    0.    0.]
  [  27.   84.  104.   18.    2.    1.    0.    0.]
  [  82.  101.   55.   12.    2.    1.    0.    0.]
  [  63.   28.   58.   21.    5.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.79566073
Scores:  {'0.167': 0.0001, '0.333': 0.0021, '0.5': 0.0041, '0.667': 0.0001, '0.833': 0.0001, '1.0': 0.0041}
best rdn ma / adv:  0.5 0.5
best rdn adv:  0.00399920004
Episodes: 5339, frames: 40128, time: 29587.189381837845
training steps:  3453
retraining steps:  0
RDN obj mus: [-0.9418244506835938, -0.9546361186861992, -0.9542369080722332, -0.9494374851822853, -0.9417249251604081]
RDN obj sigmas: [0.029642267671666278, 0.01781207961379831, 0.017755343162736914, 0.022415906043017783, 0.026184579785521384]
5339 : 0.0
LR:  0.001
replay buffer size:  41254
Time Taken :  493.0  mins 7.18906307220459  seconds
[[[11791.  3453.   350.   203.    75.    10.     0.     0.]
  [ 6749.  2209.   943.   175.    26.     2.     0.     0.]
  [ 1294.  1059.   721.   108.    13.     3.     3.     0.]
  [   66.   693.   594.   227.    24.     1.     0.     0.]
  [  162.   541.   487.    63.     4.    15.     4.     0.]
  [   53.   243.   328.   154.    38.    40.    38.     0.]
  [  211.   233.   193.   220.   147.   119.    60.    10.]
  [  181.    60.   176.   127.    16.    43.    26.     5.]]]
Test reward:  0.2
Q value #end_state_>_threshold:  2
Q value #non_end_state_>threshold:  223
maxi score:  0.0101
siam score:  -0.7802776
Scores:  {'0.167': 0.0001, '0.333': 0.0121, '0.5': 0.0201, '0.667': 0.034100000000000005, '0.833': 0.0101, '1.0': 0.0141}
best rdn ma / adv:  0.667 0.667
best rdn adv:  0.03331666834
Episodes: 6659, frames: 50088, time: 32293.807726860046
training steps:  4307
retraining steps:  0
RDN obj mus: [-0.9704040354013443, -0.9695251864552498, -0.9603534090936184, -0.9445068851351738, -0.923356157797575]
RDN obj sigmas: [0.014361024245511151, 0.018220222068127564, 0.021384072984342296, 0.022277895958340406, 0.030874104987365578]
6659 : 0.0
LR:  0.001
replay buffer size:  51499
Time Taken :  538.0  mins 13.80736517906189  seconds
[[[13712.  4192.   419.   259.   118.    15.     0.     0.]
  [ 7993.  2663.  1134.   213.    30.     4.     0.     0.]
  [ 1672.  1321.   882.   132.    13.     3.     3.     0.]
  [   75.   868.   772.   255.    29.    10.     1.     0.]
  [  179.   637.   605.    76.    13.   108.    18.    12.]
  [   65.   302.   445.   247.   143.   247.   236.   101.]
  [  211.   240.   235.   316.   254.   344.   264.   226.]
  [  181.    62.   210.   237.    42.   163.   175.    47.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  103
Q value #non_end_state_>threshold:  596
maxi score:  0.0301
siam score:  -0.8048851
Scores:  {'0.167': 0.0241, '0.333': 0.0461, '0.5': 0.0441, '0.667': 0.0461, '0.833': 0.0201, '1.0': 0.0201}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.029440000000000008
Episodes: 8008, frames: 60104, time: 34681.69282197952
training steps:  5167
retraining steps:  0
RDN obj mus: [-0.9571075652718544, -0.9605391174018383, -0.9508814057052135, -0.946470804464817, -0.9390280411481857]
RDN obj sigmas: [0.015782496295864423, 0.02012566289318833, 0.020979530611588287, 0.02342204497138296, 0.02346809423935367]
8008 : 0.0
LR:  0.001
replay buffer size:  61683
Time Taken :  578.0  mins 1.6924028396606445  seconds
[[[15312.  4991.   460.   271.   133.    20.     0.     0.]
  [ 9262.  3128.  1308.   233.    43.     6.     1.     0.]
  [ 2013.  1632.  1062.   152.    16.     5.     4.     0.]
  [   97.  1068.   913.   271.    33.    29.     2.     6.]
  [  239.   772.   728.    87.    17.   121.    31.    43.]
  [   76.   369.   580.   327.   228.   373.   384.   328.]
  [  220.   265.   348.   520.   451.   510.   473.   380.]
  [  191.    69.   261.   378.    62.   283.   401.   110.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  393
Q value #non_end_state_>threshold:  2498
maxi score:  0.1101
siam score:  -0.91516274
Scores:  {'0.167': 0.1021, '0.333': 0.1121, '0.5': 0.06810000000000001, '0.667': 0.0601, '0.833': 0.026099999999999998, '1.0': 0.022099999999999998}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.08869526512000002
Episodes: 8762, frames: 70176, time: 37387.06221175194
training steps:  6028
retraining steps:  0
RDN obj mus: [-0.9507274107158185, -0.9703188730478287, -0.9689287593126297, -0.9588559424042702, -0.9549363819122314]
RDN obj sigmas: [0.01778132399559847, 0.013507941129699459, 0.011912320256513785, 0.017182796103296066, 0.017481754646518053]
8762 : 0.05
LR:  0.001
replay buffer size:  73120
Time Taken :  623.0  mins 7.061797142028809  seconds
[[[16036.  5305.   483.   290.   203.    22.     0.     0.]
  [ 9953.  3500.  1393.   241.    46.     7.     1.     0.]
  [ 2201.  1896.  1173.   159.    17.     8.     5.     6.]
  [  112.  1300.  1056.   281.    34.    60.    10.   163.]
  [  545.  1063.   920.    99.    25.   194.    51.   227.]
  [   96.   489.   863.   578.   452.   672.   672.   695.]
  [  236.   301.   583.   887.   754.   835.   843.   719.]
  [  191.    77.   386.   491.    78.   586.   619.   226.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  775
Q value #non_end_state_>threshold:  6860
maxi score:  0.1661
siam score:  -0.9035817
Scores:  {'0.167': 0.1621, '0.333': 0.1401, '0.5': 0.06810000000000001, '0.667': 0.0601, '0.833': 0.0301, '1.0': 0.0201}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 9226, frames: 80119, time: 39678.65280890465
training steps:  6888
retraining steps:  0
RDN obj mus: [-0.9542903663575649, -0.9604266712665558, -0.9599568879485131, -0.9606815641283989, -0.9632053653478623]
RDN obj sigmas: [0.02650457006232794, 0.02455151325700828, 0.028793749398366937, 0.02815906861923628, 0.021376396345965575]
9226 : 0.2
LR:  0.001
replay buffer size:  83468
Time Taken :  661.0  mins 18.652387142181396  seconds
[[[16561.  5473.   506.   312.   436.    26.     0.     0.]
  [10407.  3847.  1467.   250.    65.    20.     1.     0.]
  [ 2248.  2169.  1261.   163.    32.   147.    15.    15.]
  [  122.  1559.  1209.   290.    45.   304.    62.   353.]
  [  620.  1361.  1209.   119.    42.   330.    81.   504.]
  [  100.   612.  1254.   918.   756.  1144.  1108.  1174.]
  [  239.   345.   848.  1283.  1034.  1200.  1106.   913.]
  [  191.    81.   442.   585.   101.   731.   795.   302.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1072
Q value #non_end_state_>threshold:  11150
maxi score:  0.3021
siam score:  -0.8962784
Scores:  {'0.167': 0.2161, '0.333': 0.17409999999999998, '0.5': 0.07010000000000001, '0.667': 0.0521, '0.833': 0.0301, '1.0': 0.018099999999999998}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 9557, frames: 90029, time: 41825.81933784485
training steps:  7736
retraining steps:  0
RDN obj mus: [-0.9625168243169785, -0.9662475324809551, -0.9702312144815922, -0.9692853927314281, -0.9688423355877399]
RDN obj sigmas: [0.01971680438905733, 0.017825312860152546, 0.016506894065241143, 0.016532557714011742, 0.01810864213925838]
9557 : 0.35
LR:  0.001
replay buffer size:  93767
Time Taken :  697.0  mins 5.818912029266357  seconds
[[[16810.  5512.   522.   408.   608.    37.     0.     0.]
  [10802.  4187.  1561.   257.    79.    27.     3.     0.]
  [ 2275.  2417.  1402.   171.    50.   357.    27.    33.]
  [  133.  1810.  1454.   301.    59.   540.   157.   976.]
  [  767.  1647.  1548.   132.    52.   514.   100.   808.]
  [  109.   738.  1637.  1209.  1051.  1557.  1489.  1632.]
  [  239.   396.  1092.  1561.  1244.  1559.  1338.  1103.]
  [  191.    93.   631.   691.   122.   895.   963.   389.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1502
Q value #non_end_state_>threshold:  15435
maxi score:  0.4321
siam score:  -0.881494
Scores:  {'0.167': 0.29009999999999997, '0.333': 0.21009999999999998, '0.5': 0.0741, '0.667': 0.0441, '0.833': 0.026099999999999998, '1.0': 0.0141}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 9893, frames: 100048, time: 44039.75097966194
training steps:  8606
retraining steps:  0
RDN obj mus: [-0.9627986011266708, -0.9713742255210877, -0.9715121071875096, -0.9694339989423751, -0.9651920976579189]
RDN obj sigmas: [0.023294609289561556, 0.015411940690056523, 0.016025592654291806, 0.016924500744465207, 0.018020315454877863]
9893 : 0.4
LR:  0.001
replay buffer size:  104185
Time Taken :  733.0  mins 59.7505521774292  seconds
[[[16979.  5548.   557.   566.   827.    43.     0.     0.]
  [11249.  4548.  1652.   266.   127.    48.     4.     0.]
  [ 2308.  2711.  1540.   179.   116.   841.   173.    39.]
  [  151.  2094.  1671.   311.    66.   916.   281.  1051.]
  [ 1058.  2018.  1895.   148.    63.   676.   122.   895.]
  [  129.   939.  1991.  1451.  1347.  2081.  1900.  1880.]
  [  266.   478.  1256.  1726.  1410.  1896.  1726.  1397.]
  [  191.    96.   724.   789.   128.   996.  1135.   486.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  1980
Q value #non_end_state_>threshold:  19171
maxi score:  0.5381
siam score:  -0.871716
Scores:  {'0.167': 0.34609999999999996, '0.333': 0.2301, '0.5': 0.0721, '0.667': 0.034100000000000005, '0.833': 0.022099999999999998, '1.0': 0.0141}
best rdn ma / adv:  0.167 0.167
best rdn adv:  0.0
Episodes: 10189, frames: 110042, time: 46235.40631866455
training steps:  9464
retraining steps:  0
RDN obj mus: [-0.9522407681941986, -0.9727842866420746, -0.9750540156662464, -0.9726383393585681, -0.9703767643153668]
RDN obj sigmas: [0.019493507474300897, 0.016005833822507004, 0.015259184838934275, 0.015081654930815015, 0.01696467128118202]
10189 : 0.35
LR:  0.001
replay buffer size:  114590
Time Taken :  770.0  mins 35.4058952331543  seconds
[[[17220.  5579.   617.   893.  1164.    47.     0.     0.]
  [11594.  4866.  1752.   277.   197.    61.     5.     0.]
  [ 2324.  3001.  1655.   184.   206.  1182.   298.    55.]
  [  173.  2420.  1868.   329.    77.  1118.   438.  1386.]
  [ 1360.  2474.  2178.   165.    68.   782.   147.  1154.]
  [  141.  1084.  2312.  1678.  1519.  2394.  2257.  2407.]
  [  285.   597.  1442.  1906.  1575.  2165.  1997.  1656.]
  [  191.   101.   764.   844.   135.  1206.  1319.   564.]]]
