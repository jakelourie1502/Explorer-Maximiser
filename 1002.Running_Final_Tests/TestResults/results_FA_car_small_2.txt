EVALUATIONS AND MAIN RESULTS
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9721222222222222
siam score:  -0.0007597976779964354
Scores:  {'0.167': -0.8749, '0.333': -0.8570428571428571, '0.5': -0.9089909090909091, '0.667': -0.8570428571428571, '0.833': -0.8332333333333334, '1.0': -0.8570428571428571}
best rdn ma / adv:  1 0.167
best rdn adv:  0.0
Episodes: 51, frames: 1023, time: 54.11631512641907
training steps:  5
retraining steps:  0
RDN obj mus: [-0.04633370144643913, -0.0735635286983725, -0.06762138418853283, 0.0, 0.0]
RDN obj sigmas: [0.009095370374577767, 0.007334763871217454, 0.01600823081269533, 0.0, 0.0]
51 : -1.0
LR:  4e-06
replay buffer size:  1629
Time Taken :  0.0  mins 54.11607027053833  seconds
[[[  0.   0.   0.   0.   0.   1.   0.   1.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   3.   8.   1.   3.   2.   1.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.  74.  11.  14.   5.   4.   2.   1.   0.   0.   0.   0.   2.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0. 264. 103.  37.  15.  82.  91.  73.  50.  42.  40.   7.   2.   2.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   9.  15.   4.   1.   0.   0.   0.   0.   0.   2.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]
  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
     0.   0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9918354838709678
siam score:  -0.8105098
Scores:  {'0.167': -0.9806692307692307, '0.333': -0.9786234042553191, '0.5': -0.9781608695652174, '0.667': -0.9776777777777778, '0.833': -0.9776777777777778, '1.0': -0.9749}
best rdn ma / adv:  1 1.0
best rdn adv:  0.1820065128958644
Episodes: 343, frames: 10522, time: 5234.261714220047
training steps:  1251
retraining steps:  0
RDN obj mus: [-0.9073329585492611, -0.9188857464194298, -0.9122300522983074, -0.8643296914866482, -0.7505816992591409]
RDN obj sigmas: [0.019660552490441595, 0.02436636605530159, 0.025592537490218226, 0.05154448522094207, 0.19652881000746064]
343 : -1.0
LR:  0.001
replay buffer size:  13080
Time Taken :  87.0  mins 14.261471033096313  seconds
[[[   0.    0.    0.    0.    3.    8.   13.    2.    7.    2.    1.
      0.    0.    0.    1.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   14.  226.  126.  102.   36.   16.    6.    4.
      0.    2.    2.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  732.  771.  327.  154.  107.   34.    3.    1.    1.
     30.   29.    9.    0.    0.   15.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 2371.  926.  415.  309.  597.  761.  604.  550.  322.  244.
     85.   13.    8.    0.    3.    1.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   39.   50.   19.    8.    0.    0.    0.    0.    0.
     14.   26.    8.    1.    3.    9.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    2.    4.    1.    1.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9952271028037384
siam score:  -0.8687281
Scores:  {'0.167': -0.9895907216494846, '0.333': -0.9879952380952381, '0.5': -0.9886640449438202, '0.667': -0.9890304347826087, '0.833': -0.9885363636363637, '1.0': -0.9879952380952381}
best rdn ma / adv:  1 0.333
best rdn adv:  0.08760432489158629
Episodes: 671, frames: 20451, time: 10589.707200050354
training steps:  2442
retraining steps:  0
RDN obj mus: [-0.9322616337656975, -0.9304327600419521, -0.9230139390528203, -0.8771592656731606, -0.857345323858892]
RDN obj sigmas: [0.02185667216176495, 0.03030349072478604, 0.04368386923755582, 0.04527911795395022, 0.04345125819757187]
671 : -1.0
LR:  0.001
replay buffer size:  24840
Time Taken :  176.0  mins 29.70697021484375  seconds
[[[   0.    0.    0.    0.    6.   14.   22.   17.   18.    7.    2.
      1.    0.    0.    2.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   30.  469.  632.  785.  534.  191.  109.   29.
      1.   72.   14.    8.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  959. 1023.  727.  932.  653.   99.   14.   74.   24.
    232.  330.   23.    0.    0.   15.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 3399. 1495.  700.  489.  908. 1100.  994.  818.  595.  504.
    306.  110.   24.    0.    3.    1.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   47.   80.   29.   17.    0.    0.    0.    0.    0.
     20.   39.    9.    1.    3.    9.    1.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    3.    6.    1.    1.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9967051118210862
siam score:  -0.82891446
Scores:  {'0.167': -0.9934064935064936, '0.333': -0.9762636363636364, '0.5': -0.9929555555555556, '0.667': -0.983870588235294, '0.833': -0.9930972789115646, '1.0': -0.992906993006993}
best rdn ma / adv:  1 0.333
best rdn adv:  0.25905195590322594
Episodes: 1078, frames: 30456, time: 16358.824791193008
training steps:  3744
retraining steps:  0
RDN obj mus: [-0.9466038330614567, -0.9547900477409362, -0.942661740630865, -0.8930630863070488, -0.8492518977105618]
RDN obj sigmas: [0.019819027399314335, 0.026346513799185234, 0.03598151503980567, 0.04604401738948535, 0.05310381674269712]
1078 : -0.9703333333333333
LR:  0.001
replay buffer size:  36193
Time Taken :  272.0  mins 38.82454514503479  seconds
[[[   0.    0.    0.    0.    9.   24.   38.   29.   33.   11.    5.
      1.    0.    3.    5.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   48.  744.  951.  974.  841.  320.  356.   80.
     61.  298.   61.   20.    0.    0.    0.    5.    1.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1178. 1323. 1140. 1140.  806.  152.   27.  113.   64.
    423.  764.   43.    1.    0.   29.    2.    2.    1.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 4234. 2047.  915.  689. 1179. 1374. 1336. 1145.  973. 1045.
    624.  656.   56.   17.   41.    6.    9.   12.    1.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.   64.  102.   45.   23.    0.    0.    0.    0.    0.
     37.  308.  161.   83.   22.   20.    5.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    4.   10.    3.    2.    1.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -1.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  -0.9975689976689976
siam score:  -0.82080877
Scores:  {'0.167': -0.9952488372093024, '0.333': -0.9768230769230769, '0.5': -0.9873162679425838, '0.667': -0.9893174757281553, '0.833': -0.9952703703703704, '1.0': -0.9952917050691245}
best rdn ma / adv:  1 0.333
best rdn adv:  0.3130998447141999
Episodes: 1570, frames: 40394, time: 20838.715413093567
training steps:  4747
retraining steps:  0
RDN obj mus: [-0.944112305957079, -0.9556757011950016, -0.9481020965218544, -0.8883349245250225, -0.8620260735809803]
RDN obj sigmas: [0.021631936814690063, 0.024095894641108638, 0.02813857293988677, 0.04743834929469282, 0.05088803634890006]
1570 : -1.0
LR:  0.001
replay buffer size:  47471
Time Taken :  347.0  mins 18.71516704559326  seconds
[[[   0.    0.    0.    0.   15.   32.   51.   43.   41.   21.   11.
      3.    0.    6.    8.    0.    0.    0.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   67.  931. 1177. 1266. 1061.  638.  545.  122.
     86.  416.  309.   51.    0.    0.    0.    5.    1.    2.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1482. 1667. 1407. 1394.  906.  217.   44.  507.  204.
    559.  958.   82.    4.    0.   29.    4.    2.    3.    1.    1.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 5300. 2641. 1124.  868. 1440. 1629. 1639. 1449. 1293. 1569.
    846.  844.  106.   58.  142.   59.   30.   20.    1.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  100.  130.   60.   34.    0.    0.    0.    0.    0.
     50.  424.  304.  163.   33.   46.    5.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.    9.   15.    5.    3.    3.    2.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -0.9420000000000001
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  2
maxi score:  -0.997
siam score:  -0.7525444
Scores:  {'0.167': -0.987709187279152, '0.333': -0.9660851851851852, '0.5': -0.9802472222222224, '0.667': -0.9860089494163424, '0.833': -0.9916582417582418, '1.0': -0.9834664335664336}
best rdn ma / adv:  1 0.333
best rdn adv:  0.6083723460932376
Episodes: 2038, frames: 50300, time: 26950.65218424797
training steps:  6094
retraining steps:  0
RDN obj mus: [-0.9532356879711151, -0.9655864956974983, -0.9581436166465283, -0.9132420669674873, -0.8887362936973572]
RDN obj sigmas: [0.017135943994818922, 0.021322701665279484, 0.02945944251847669, 0.040248831636981716, 0.04574913413062818]
2038 : -0.89575
LR:  0.001
replay buffer size:  59005
Time Taken :  449.0  mins 10.651936054229736  seconds
[[[   0.    0.    0.    0.   20.   41.   60.   65.   50.   27.   12.
      5.    1.   10.   17.    0.    0.    0.    1.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   83. 1115. 1472. 1550. 1232.  806.  661.  153.
    129.  537.  366.   80.    0.    2.    1.   18.    3.    5.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1721. 2000. 1729. 1608. 1023.  263.   56.  783.  407.
    770. 1346.  133.    8.   10.   33.   31.    3.    4.    2.    1.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 6109. 3220. 1353. 1103. 1647. 1881. 1934. 1758. 1609. 2088.
   1117. 1054.  139.  133.  197.  225.   68.   45.   34.    6.    3.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  120.  152.   76.   40.    0.    0.    0.    0.    0.
     67.  488.  392.  305.  168.  192.   22.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   15.   23.   10.    6.    7.    3.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  -0.41120000000000007
Q value #end_state_>_threshold:  78
Q value #non_end_state_>threshold:  195
maxi score:  -0.96026
siam score:  -0.66063994
Scores:  {'0.167': -0.9420508379888269, '0.333': -0.9345991404011462, '0.5': -0.9430142857142858, '0.667': -0.9524993883792049, '0.833': -0.9277491620111732, '1.0': -0.9794054945054945}
best rdn ma / adv:  1 0.5
best rdn adv:  1.53229886636233
Episodes: 2584, frames: 60300, time: 32536.52353310585
training steps:  7385
retraining steps:  0
RDN obj mus: [-0.928120990973711, -0.9604292265534401, -0.9420446104109287, -0.9102438240349293, -0.8880279035866261]
RDN obj sigmas: [0.022230005248630787, 0.019702093815857216, 0.030703606482071117, 0.039080328989868844, 0.041818314461290626]
2584 : -0.6391666666666667
LR:  0.001
replay buffer size:  70299
Time Taken :  542.0  mins 16.523292064666748  seconds
[[[   0.    0.    0.    0.   29.   45.   81.   80.   68.   40.   18.
      5.    4.   16.   19.    0.    0.    0.    1.    1.    1.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.   98. 1351. 1770. 1905. 1452. 1028.  797.  185.
    157.  667.  473.   98.    0.    2.    2.   22.   26.   16.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0. 1905. 2393. 2049. 1823. 1124.  313.   76.  931.  523.
    925. 1510.  157.   12.   12.   46.   58.   11.   28.   11.    8.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0. 7308. 3839. 1564. 1342. 1960. 2187. 2231. 2066. 1877. 2527.
   1315. 1203.  177.  149.  266.  320.  134.  123.   82.   22.   12.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.  157.  194.   95.   61.    0.    0.    0.    0.    0.
     76.  607.  493.  366.  221.  236.   31.    0.    6.    6.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
      0.   19.   27.   18.   11.   12.    4.    0.    0.    0.    0.
      0.    0.    0.    0.    0.    0.    0.    0.]]]
