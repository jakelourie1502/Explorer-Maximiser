EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0
siam score:  0.0
Scores:  {'0.0': 0}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0
Episodes: 14, frames: 93, time: 6.409556865692139
training steps:  0
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
14 : 0.0
LR:  0
replay buffer size:  268
Time Taken :  0.0  mins 6.409324884414673  seconds
[[[20.  7.  0.  0.  0.]
  [15.  5.  3.  0.  0.]
  [12.  4.  0.  0.  0.]
  [ 5.  1.  0.  0.  0.]
  [ 3.  4.  0.  0.  0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0041
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 1625, frames: 10157, time: 1539.4374458789825
training steps:  784
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1625 : 0.0
LR:  0.0007830000000000001
replay buffer size:  10438
Time Taken :  25.0  mins 39.43722486495972  seconds
[[[2608. 1293.    2.    6.    2.]
  [1622.  570.  221.   19.   10.]
  [ 681.  384.  174.   58.   16.]
  [ 301.  163.   97.   33.   16.]
  [ 135.   74.   28.   13.    6.]]]
Test reward:  0.05
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  4
maxi score:  0.0161
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 3206, frames: 20138, time: 3602.349804878235
training steps:  1471
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3206 : 0.0
LR:  0.001
replay buffer size:  20544
Time Taken :  60.0  mins 2.3495757579803467  seconds
[[[5097. 2541.    5.   10.    2.]
  [3162. 1065.  405.   35.   26.]
  [1361.  790.  335.  127.   53.]
  [ 618.  377.  218.   80.   38.]
  [ 285.  171.   76.   38.   17.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  295
Q value #non_end_state_>threshold:  292
maxi score:  0.0141
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 4719, frames: 30150, time: 5742.768154859543
training steps:  2143
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4719 : 0.0
LR:  0.001
replay buffer size:  30670
Time Taken :  95.0  mins 42.767924785614014  seconds
[[[7521. 3719.    6.   16.   12.]
  [4704. 1571.  576.   53.   34.]
  [2143. 1224.  449.  165.   63.]
  [1002.  655.  341.  124.   51.]
  [ 458.  297.  137.   78.   32.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  316
Q value #non_end_state_>threshold:  412
maxi score:  0.0041
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 6204, frames: 40128, time: 8169.295253992081
training steps:  2881
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6204 : 0.05
LR:  0.001
replay buffer size:  40804
Time Taken :  136.0  mins 9.2950279712677  seconds
[[[9744. 4814.    9.   21.   17.]
  [6362. 2110.  760.   66.   40.]
  [2955. 1636.  583.  222.   84.]
  [1402.  908.  466.  174.   77.]
  [ 658.  454.  203.  116.   43.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  1697
Q value #non_end_state_>threshold:  588
maxi score:  0.026099999999999998
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 7670, frames: 50067, time: 10484.50241780281
training steps:  3546
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
7670 : 0.0
LR:  0.001
replay buffer size:  50826
Time Taken :  174.0  mins 44.50218892097473  seconds
[[[12333.  5963.     9.    26.    18.]
  [ 7958.  2608.   920.    79.    49.]
  [ 3727.  2047.   718.   277.   106.]
  [ 1748.  1110.   564.   220.    98.]
  [  798.   545.   247.   156.    73.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  2632
Q value #non_end_state_>threshold:  1103
maxi score:  0.042100000000000005
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 9265, frames: 60134, time: 13310.782693862915
training steps:  4313
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
9265 : 0.0
LR:  0.001
replay buffer size:  61054
Time Taken :  221.0  mins 50.7824649810791  seconds
[[[14618.  7158.    10.    30.    21.]
  [ 9560.  3126.  1103.    92.    57.]
  [ 4395.  2444.   879.   341.   136.]
  [ 2056.  1333.   717.   287.   128.]
  [  933.   667.   376.   273.   129.]]]
Test reward:  0.15
Q value #end_state_>_threshold:  4093
Q value #non_end_state_>threshold:  1869
maxi score:  0.0861
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 10760, frames: 70066, time: 16470.73826098442
training steps:  5176
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
10760 : 0.15
LR:  0.001
replay buffer size:  71103
Time Taken :  274.0  mins 30.738070964813232  seconds
[[[16978.  8225.    12.    34.    22.]
  [11045.  3563.  1249.   111.    72.]
  [ 5107.  2829.  1046.   432.   177.]
  [ 2350.  1577.   904.   420.   183.]
  [ 1065.   776.   477.   422.   230.]]]
Test reward:  0.25
Q value #end_state_>_threshold:  4412
Q value #non_end_state_>threshold:  2931
maxi score:  0.1261
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 12183, frames: 80186, time: 18825.39422082901
training steps:  5998
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
12183 : 0.1
LR:  0.001
replay buffer size:  81546
Time Taken :  313.0  mins 45.39398694038391  seconds
[[[18936.  9126.    12.    35.    22.]
  [12620.  4008.  1380.   122.    84.]
  [ 6004.  3295.  1212.   496.   203.]
  [ 2786.  1934.  1124.   518.   209.]
  [ 1295.   986.   617.   607.   372.]]]
Test reward:  0.3
Q value #end_state_>_threshold:  4453
Q value #non_end_state_>threshold:  4816
maxi score:  0.1701
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 13551, frames: 90282, time: 20367.964067697525
training steps:  6748
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
13551 : 0.25
LR:  0.001
replay buffer size:  91833
Time Taken :  339.0  mins 27.963831901550293  seconds
[[[20794.  9908.    12.    35.    22.]
  [14073.  4356.  1502.   125.    87.]
  [ 6815.  3707.  1357.   542.   216.]
  [ 3263.  2358.  1439.   637.   223.]
  [ 1511.  1200.   908.  1036.   605.]]]
Test reward:  0.6
Q value #end_state_>_threshold:  4462
Q value #non_end_state_>threshold:  7552
maxi score:  0.21009999999999998
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 14949, frames: 100162, time: 21517.72356390953
training steps:  7437
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
14949 : 0.6
LR:  0.001
replay buffer size:  101842
Time Taken :  358.0  mins 37.72332787513733  seconds
[[[22196. 10685.    12.    36.    23.]
  [15290.  4658.  1603.   129.    90.]
  [ 7543.  4040.  1477.   593.   224.]
  [ 3741.  2827.  1823.   782.   239.]
  [ 1702.  1408.  1322.  1873.   897.]]]
Test reward:  0.75
Q value #end_state_>_threshold:  4482
Q value #non_end_state_>threshold:  12357
maxi score:  0.4821
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 15975, frames: 110038, time: 22672.581550836563
training steps:  8137
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
15975 : 0.6
LR:  0.001
replay buffer size:  111905
Time Taken :  377.0  mins 52.58131814002991  seconds
[[[23007. 10990.    12.    36.    23.]
  [16484.  4900.  1639.   133.    92.]
  [ 8499.  4480.  1660.   648.   225.]
  [ 4355.  3423.  2391.   948.   250.]
  [ 2008.  1622.  1900.  2984.  1354.]]]
Test reward:  0.65
Q value #end_state_>_threshold:  4499
Q value #non_end_state_>threshold:  18319
maxi score:  0.5301
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 16995, frames: 120060, time: 23842.24362874031
training steps:  8840
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
16995 : 0.5
LR:  0.001
replay buffer size:  122058
Time Taken :  397.0  mins 22.2434720993042  seconds
[[[23655. 11273.    12.    36.    23.]
  [17552.  5054.  1673.   137.    94.]
  [ 9416.  4866.  1818.   698.   230.]
  [ 4977.  4100.  3066.  1153.   259.]
  [ 2163.  1773.  2602.  4542.  1893.]]]
Test reward:  0.75
Q value #end_state_>_threshold:  4751
Q value #non_end_state_>threshold:  23843
maxi score:  0.6161
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 17970, frames: 130086, time: 25014.058624982834
training steps:  9545
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
17970 : 0.8
LR:  0.001
replay buffer size:  132243
Time Taken :  416.0  mins 54.05839204788208  seconds
[[[24481. 11487.    12.    36.    23.]
  [18745.  5217.  1691.   138.    95.]
  [10504.  5278.  1965.   736.   233.]
  [ 5637.  4807.  3753.  1300.   266.]
  [ 2301.  1916.  3323.  5691.  2481.]]]
Test reward:  0.95
Q value #end_state_>_threshold:  5245
Q value #non_end_state_>threshold:  30418
maxi score:  0.6681
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 18943, frames: 140218, time: 26205.67616200447
training steps:  10255
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
18943 : 0.7
LR:  0.001
replay buffer size:  142548
Time Taken :  436.0  mins 45.67593002319336  seconds
[[[25539. 11670.    12.    37.    24.]
  [20135.  5431.  1721.   144.    99.]
  [11530.  5859.  2128.   787.   246.]
  [ 6101.  5542.  4484.  1423.   276.]
  [ 2352.  2022.  4031.  6562.  3120.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  5554
Q value #non_end_state_>threshold:  39138
maxi score:  0.7941
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 19862, frames: 150066, time: 27317.91384291649
training steps:  10954
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
19862 : 0.8
LR:  0.001
replay buffer size:  152576
Time Taken :  455.0  mins 17.913611888885498  seconds
[[[26562. 11792.    12.    37.    24.]
  [21444.  5606.  1733.   146.   100.]
  [12509.  6322.  2266.   818.   247.]
  [ 6640.  6299.  5289.  1516.   280.]
  [ 2379.  2072.  4828.  7433.  3850.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  5777
Q value #non_end_state_>threshold:  49593
maxi score:  0.7961
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 20798, frames: 160045, time: 28310.485957860947
training steps:  11672
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
20798 : 0.95
LR:  0.001
replay buffer size:  162735
Time Taken :  471.0  mins 50.4857759475708  seconds
[[[27812. 11919.    12.    37.    24.]
  [22749.  5760.  1742.   148.   100.]
  [13427.  6825.  2359.   841.   247.]
  [ 7114.  7118.  6108.  1595.   282.]
  [ 2403.  2143.  5630.  8275.  4577.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  6105
Q value #non_end_state_>threshold:  60096
maxi score:  0.7921
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 21733, frames: 170228, time: 29325.978281021118
training steps:  12407
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
21733 : 0.8
LR:  0.001
replay buffer size:  173120
Time Taken :  488.0  mins 45.97805094718933  seconds
[[[29191. 12033.    12.    37.    24.]
  [24073.  5937.  1751.   149.   101.]
  [14329.  7344.  2477.   871.   247.]
  [ 7619.  7939.  6931.  1679.   284.]
  [ 2414.  2227.  6438.  9086.  5302.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  6778
Q value #non_end_state_>threshold:  69577
maxi score:  0.7361
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 22610, frames: 180266, time: 30329.30925798416
training steps:  13133
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
22610 : 0.8
LR:  0.001
replay buffer size:  183404
Time Taken :  505.0  mins 29.309022903442383  seconds
[[[30956. 12161.    12.    37.    24.]
  [25382.  6114.  1764.   149.   101.]
  [15171.  7834.  2593.   892.   248.]
  [ 8099.  8729.  7688.  1739.   289.]
  [ 2430.  2311.  7177.  9808.  5948.]]]
Test reward:  1.0
Q value #end_state_>_threshold:  7936
Q value #non_end_state_>threshold:  79446
maxi score:  0.7781
siam score:  0.0
Scores:  {'0.0': 0.0001}
best rdn ma / adv:  0.0 0.0
best rdn adv:  0.0
Episodes: 23429, frames: 190051, time: 31448.715216875076
training steps:  13852
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
23429 : 0.8
LR:  0.001
replay buffer size:  193392
Time Taken :  524.0  mins 8.7150239944458  seconds
[[[32831. 12261.    12.    37.    24.]
  [26633.  6326.  1779.   150.   102.]
  [15913.  8399.  2714.   912.   249.]
  [ 8407.  9465.  8453.  1811.   291.]
  [ 2447.  2369.  7903. 10543.  6591.]]]
