EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  0.00032942571366826695
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 35, frames: 516, time: 23.950328826904297
training steps:  1
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
35 : 0.0
LR:  0.0
replay buffer size:  656
Time Taken :  0.0  mins 23.95004105567932  seconds
[[[ 1.  2.  0.  0.  0.  0.  0.]
  [10. 11.  4.  2.  0.  0.  0.]
  [31. 23. 11.  3.  0.  0.  0.]
  [66. 43. 13.  1.  0.  0.  0.]
  [61. 34.  7.  0.  0.  0.  0.]
  [53. 33.  7.  1.  0.  0.  0.]
  [34. 25.  4.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7846699
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 490, frames: 10009, time: 3031.180011034012
training steps:  1226
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
490 : 0.0
LR:  0.001
replay buffer size:  10328
Time Taken :  50.0  mins 31.17973303794861  seconds
[[[  58.   50.    0.    0.    1.    9.   10.]
  [ 396.  214.   67.   14.    3.    6.    4.]
  [1004.  503.  136.   39.   17.    5.    0.]
  [1585.  704.  129.    5.    3.    0.    0.]
  [1398.  496.   98.    2.    0.    0.    0.]
  [ 846.  361.   97.   12.    0.    0.    0.]
  [ 871.  321.   52.    3.    0.    0.    0.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.85068613
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 746, frames: 20031, time: 7454.132167816162
training steps:  2393
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
746 : 0.0
LR:  0.001
replay buffer size:  20514
Time Taken :  124.0  mins 14.131885051727295  seconds
[[[  79.   60.    0.    0.    4.   13.   20.]
  [ 586.  304.   84.   17.    4.   10.   15.]
  [1664.  726.  170.   53.   22.   10.    1.]
  [4022. 1345.  212.    7.    5.    0.    0.]
  [3615. 1018.  153.    8.    4.    0.    0.]
  [1743.  616.  161.   43.   16.    0.    0.]
  [1841.  542.   73.    5.    6.    6.    2.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8782917
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 957, frames: 30086, time: 13487.213182926178
training steps:  3728
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
957 : 0.0
LR:  0.001
replay buffer size:  30790
Time Taken :  224.0  mins 47.21290898323059  seconds
[[[  98.   67.    0.    0.    4.   13.   20.]
  [ 708.  359.  104.   17.    4.   10.   15.]
  [2158.  894.  213.   68.   24.   10.    1.]
  [6150. 1877.  257.   10.    5.    1.    0.]
  [5969. 1564.  195.   12.    5.    2.    4.]
  [3175.  990.  233.   78.   20.    2.    7.]
  [2868.  771.  107.    9.    8.   11.    7.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    1.    0.    0.    0.]
  [   0.    0.    0.    1.    1.    2.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8779482
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1262, frames: 40117, time: 19404.122271060944
training steps:  4969
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1262 : 0.0
LR:  0.001
replay buffer size:  41024
Time Taken :  323.0  mins 24.122019052505493  seconds
[[[ 129.   74.    0.    0.    5.   19.   27.]
  [ 860.  413.  124.   19.    5.   16.   19.]
  [2757. 1125.  255.   75.   26.   11.    2.]
  [8049. 2512.  320.   10.   11.    2.    7.]
  [7855. 2138.  274.   21.   24.   14.   18.]
  [4323. 1420.  408.  178.   68.   26.   23.]
  [3836. 1079.  153.   23.   28.   33.   15.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    2.]
  [   0.    0.    0.    1.    0.    0.    6.]
  [   0.    0.    0.    1.    1.    6.    3.]
  [   0.    0.    0.    1.    1.    2.    2.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.89671814
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1503, frames: 50193, time: 23174.674102783203
training steps:  6055
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1503 : 0.0
LR:  0.001
replay buffer size:  51328
Time Taken :  386.0  mins 14.673810958862305  seconds
[[[ 140.   82.    0.    0.    6.   27.   49.]
  [1024.  479.  142.   20.    6.   21.   29.]
  [3351. 1346.  285.   79.   28.   11.    2.]
  [9999. 2940.  351.   10.   15.   10.    7.]
  [9792. 2538.  334.   32.   46.   40.   24.]
  [5632. 1801.  592.  311.  149.   69.   38.]
  [5019. 1374.  194.   41.   54.   65.   23.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    2.    2.]
  [   0.    0.    1.    3.    4.    4.    6.]
  [   0.    0.    5.    4.    7.   14.    3.]
  [   0.    0.    0.    1.    3.    2.    2.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.90098876
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1800, frames: 60045, time: 25974.99817085266
training steps:  7119
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1800 : 0.0
LR:  0.001
replay buffer size:  61439
Time Taken :  432.0  mins 54.997885942459106  seconds
[[[  170.    91.     0.     0.     6.    27.    49.]
  [ 1199.   544.   156.    21.     7.    21.    29.]
  [ 3863.  1540.   326.    88.    31.    11.     2.]
  [11422.  3377.   397.    13.    20.    21.    13.]
  [11282.  3007.   396.    52.   101.   110.    68.]
  [ 6780.  2310.   886.   522.   309.   169.   110.]
  [ 6008.  1651.   244.    62.   127.   142.    68.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    0.     0.     0.     0.     0.     0.     0.]
  [    6.     0.     0.     0.     0.     0.     0.]
  [   38.     5.     0.     0.     0.     2.     2.]
  [   43.    11.     2.     5.     8.     7.     6.]
  [   34.    24.    23.    16.    23.    37.     8.]
  [   38.     8.     4.     1.     9.    18.    19.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.9090933
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 2112, frames: 70086, time: 29788.083288908005
training steps:  8667
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2112 : 0.0
LR:  0.001
replay buffer size:  71759
Time Taken :  496.0  mins 28.082993984222412  seconds
[[[  196.   100.     0.     0.     8.    29.    56.]
  [ 1340.   609.   167.    22.    10.    26.    32.]
  [ 4301.  1716.   380.   112.    52.    29.     5.]
  [12392.  3762.   448.    15.    26.    36.    25.]
  [12361.  3422.   441.    69.   176.   210.   159.]
  [ 7821.  2912.  1259.   826.   556.   358.   293.]
  [ 6965.  2077.   305.    93.   183.   286.   223.]]

 [[    0.     0.     0.     0.     0.     0.     0.]
  [    2.     2.     1.     0.     0.     0.     0.]
  [   11.     2.     1.     0.     0.     0.     0.]
  [   73.    13.     1.     0.     0.     6.     3.]
  [  101.    22.     3.     8.    23.    32.    21.]
  [  130.    73.    65.    68.    70.    79.    34.]
  [   95.    28.     5.     1.    19.    40.    53.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8995516
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 2419, frames: 80102, time: 31692.263276815414
training steps:  9395
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2419 : 0.0
LR:  0.001
replay buffer size:  81972
Time Taken :  528.0  mins 12.262990236282349  seconds
[[[  222.   110.     0.     0.     9.    34.    59.]
  [ 1556.   702.   178.    26.    12.    31.    37.]
  [ 4765.  1911.   426.   138.    64.    45.    24.]
  [13285.  4156.   513.    15.    33.    49.    41.]
  [13358.  3812.   492.    87.   248.   311.   286.]
  [ 9007.  3495.  1584.  1073.   788.   532.   494.]
  [ 7964.  2422.   346.   110.   254.   403.   389.]]

 [[    1.     0.     0.     0.     0.     0.     0.]
  [    6.     6.     1.     0.     0.     0.     0.]
  [   26.    10.     1.     0.     0.     0.     0.]
  [  115.    26.     1.     0.     2.     9.     4.]
  [  151.    34.     6.    11.    29.    55.    38.]
  [  201.   117.   107.   106.   110.   136.    76.]
  [  168.    49.     6.     3.    32.    65.    79.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8969972
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 2750, frames: 90139, time: 34405.4859559536
training steps:  10575
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2750 : 0.0
LR:  0.001
replay buffer size:  92206
Time Taken :  573.0  mins 25.485666036605835  seconds
[[[  250.   123.     0.     0.    11.    43.    79.]
  [ 1743.   764.   193.    27.    17.    41.    55.]
  [ 5238.  2094.   477.   171.    98.    75.    43.]
  [14182.  4554.   561.    20.    44.    58.    54.]
  [14353.  4239.   561.   102.   326.   418.   389.]
  [10017.  4160.  1956.  1356.  1045.   710.   679.]
  [ 8926.  2872.   397.   135.   333.   530.   535.]]

 [[    1.     1.     0.     0.     0.     0.     0.]
  [    8.     8.     1.     0.     0.     0.     0.]
  [   31.    14.     2.     0.     0.     0.     0.]
  [  137.    30.     1.     0.     3.    10.     8.]
  [  182.    52.     9.    15.    35.    64.    49.]
  [  251.   168.   142.   142.   143.   188.   105.]
  [  214.    67.     7.     5.    42.    96.   104.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.88800216
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 3098, frames: 100090, time: 37121.75500178337
training steps:  11743
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3098 : 0.0
LR:  0.001
replay buffer size:  102375
Time Taken :  618.0  mins 41.75471305847168  seconds
[[[  263.   134.     0.     0.    15.    52.    95.]
  [ 1880.   820.   214.    30.    25.    49.    68.]
  [ 5655.  2287.   550.   203.   129.    92.    55.]
  [14950.  4921.   614.    24.    52.    70.    65.]
  [15243.  4660.   627.   127.   427.   542.   504.]
  [11100.  4965.  2380.  1671.  1321.   881.   825.]
  [ 9929.  3449.   475.   160.   418.   657.   680.]]

 [[    1.     1.     0.     0.     0.     0.     0.]
  [   14.     8.     1.     0.     0.     0.     0.]
  [   36.    14.     2.     0.     0.     0.     0.]
  [  144.    33.     2.     0.     4.    10.     8.]
  [  196.    61.     9.    15.    43.    75.    56.]
  [  286.   198.   160.   167.   166.   210.   119.]
  [  232.    81.     7.    10.    49.   102.   119.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8923368
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 3453, frames: 110114, time: 39814.66249990463
training steps:  12912
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3453 : 0.0
LR:  0.001
replay buffer size:  112634
Time Taken :  663.0  mins 34.66220808029175  seconds
[[[  293.   143.     0.     0.    15.    52.    95.]
  [ 2065.   912.   230.    33.    27.    50.    71.]
  [ 6065.  2493.   588.   223.   139.    99.    56.]
  [15751.  5319.   676.    27.    68.    87.    72.]
  [16141.  5080.   698.   151.   552.   687.   637.]
  [12206.  5698.  2763.  2009.  1625.  1041.   978.]
  [10911.  3952.   526.   183.   531.   799.   824.]]

 [[    1.     1.     0.     0.     0.     0.     0.]
  [   25.    12.     2.     1.     0.     0.     0.]
  [   49.    21.     8.     4.     2.     2.     0.]
  [  157.    39.     3.     0.     7.    12.    11.]
  [  213.    70.    10.    17.    48.    86.    69.]
  [  317.   232.   180.   180.   185.   243.   137.]
  [  253.   101.     9.    13.    60.   112.   128.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.88899773
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 3762, frames: 120140, time: 42497.94246983528
training steps:  14083
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3762 : 0.0
LR:  0.001
replay buffer size:  122886
Time Taken :  708.0  mins 17.942177057266235  seconds
[[[  315.   152.     0.     0.    18.    61.   104.]
  [ 2232.   988.   248.    36.    33.    63.    84.]
  [ 6466.  2673.   649.   262.   173.   133.    72.]
  [16492.  5638.   719.    28.    75.    92.    87.]
  [17017.  5453.   769.   172.   675.   808.   738.]
  [13370.  6475.  3167.  2340.  1928.  1195.  1106.]
  [11759.  4450.   572.   200.   629.   949.   954.]]

 [[    3.     1.     0.     0.     1.     2.     0.]
  [   39.    22.     3.     1.     0.     1.     0.]
  [   63.    29.    15.    13.     7.     8.     2.]
  [  207.    48.     3.     0.     8.    16.    11.]
  [  276.    87.    10.    18.    63.   103.    80.]
  [  406.   280.   223.   229.   229.   282.   162.]
  [  293.   120.    10.    16.    76.   139.   154.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8837779
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 4128, frames: 130079, time: 45169.64518094063
training steps:  15247
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4128 : 0.0
LR:  0.001
replay buffer size:  133069
Time Taken :  752.0  mins 49.64489507675171  seconds
[[[  345.   165.     0.     0.    23.    69.   121.]
  [ 2431.  1081.   268.    44.    40.    77.   113.]
  [ 6943.  2962.   759.   337.   229.   178.   109.]
  [17290.  6131.   782.    35.    89.    97.   104.]
  [17876.  5915.   834.   193.   783.   933.   848.]
  [14444.  7277.  3548.  2630.  2175.  1316.  1216.]
  [12448.  4903.   635.   217.   693.  1045.  1055.]]

 [[    4.     1.     0.     0.     1.     2.     0.]
  [   44.    25.     3.     1.     0.     1.     0.]
  [   66.    34.    19.    19.    11.    12.     6.]
  [  219.    54.     3.     0.     8.    18.    12.]
  [  293.    96.    12.    22.    66.   108.    90.]
  [  442.   314.   257.   260.   254.   309.   178.]
  [  310.   133.    12.    16.    87.   153.   170.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8767351
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 4514, frames: 140176, time: 47907.234157800674
training steps:  16442
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4514 : 0.0
LR:  0.001
replay buffer size:  143402
Time Taken :  798.0  mins 27.23390793800354  seconds
[[[  375.   174.     0.     0.    25.    77.   135.]
  [ 2677.  1203.   294.    57.    59.   104.   142.]
  [ 7477.  3298.   892.   450.   328.   254.   174.]
  [18091.  6611.   856.    40.   110.   105.   113.]
  [18775.  6356.   899.   213.   887.  1020.   929.]
  [15536.  8030.  3900.  2897.  2421.  1415.  1297.]
  [13247.  5328.   696.   245.   778.  1139.  1136.]]

 [[    4.     1.     0.     0.     1.     2.     0.]
  [   44.    25.     3.     1.     0.     1.     0.]
  [   71.    38.    20.    21.    11.    12.     6.]
  [  224.    59.     5.     1.     9.    19.    12.]
  [  297.   102.    13.    25.    71.   123.   103.]
  [  451.   333.   274.   278.   276.   340.   196.]
  [  317.   142.    12.    18.    95.   167.   174.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.882442
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 4854, frames: 150143, time: 50609.866491794586
training steps:  17602
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4854 : 0.0
LR:  0.001
replay buffer size:  153611
Time Taken :  843.0  mins 29.86621403694153  seconds
[[[  396.   190.     0.     0.    27.    91.   165.]
  [ 2903.  1344.   318.    66.    82.   144.   185.]
  [ 7949.  3639.  1076.   597.   482.   373.   260.]
  [18713.  7006.   912.    45.   120.   117.   126.]
  [19491.  6726.   953.   236.   981.  1112.  1018.]
  [16586.  8865.  4328.  3211.  2686.  1554.  1438.]
  [14011.  5762.   750.   265.   850.  1247.  1250.]]

 [[    4.     1.     0.     0.     1.     2.     0.]
  [   50.    29.     4.     1.     0.     1.     3.]
  [   75.    43.    27.    28.    15.    14.    11.]
  [  232.    62.     5.     1.     9.    20.    12.]
  [  303.   104.    16.    25.    76.   131.   114.]
  [  463.   350.   292.   297.   296.   360.   202.]
  [  328.   148.    14.    20.   101.   170.   183.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.88545054
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 5157, frames: 160159, time: 53345.36161899567
training steps:  18772
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5157 : 0.0
LR:  0.001
replay buffer size:  163839
Time Taken :  889.0  mins 5.361328840255737  seconds
[[[  410.   197.     0.     0.    27.    93.   168.]
  [ 3076.  1438.   332.    73.    94.   160.   199.]
  [ 8327.  3855.  1198.   683.   554.   435.   294.]
  [19479.  7364.   963.    48.   131.   124.   140.]
  [20571.  7233.  1011.   257.  1091.  1203.  1093.]
  [17859.  9663.  4713.  3513.  2952.  1673.  1531.]
  [14877.  6261.   810.   279.   932.  1356.  1352.]]

 [[    4.     2.     0.     0.     1.     2.     0.]
  [   54.    31.     4.     1.     0.     1.     3.]
  [   76.    45.    27.    28.    15.    14.    11.]
  [  235.    66.     6.     1.    10.    21.    12.]
  [  318.   114.    18.    25.    82.   136.   119.]
  [  492.   375.   308.   313.   315.   379.   208.]
  [  345.   162.    18.    22.   115.   187.   189.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.88236773
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 5530, frames: 170094, time: 56124.406297922134
training steps:  19948
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5530 : 0.0
LR:  0.001
replay buffer size:  174104
Time Taken :  935.0  mins 24.406009912490845  seconds
[[[  443.   208.     0.     0.    28.   101.   186.]
  [ 3316.  1551.   358.    86.   111.   186.   228.]
  [ 8875.  4156.  1348.   827.   687.   535.   350.]
  [20367.  7777.  1024.    52.   145.   134.   153.]
  [21561.  7686.  1079.   287.  1175.  1264.  1158.]
  [18802. 10355.  5071.  3777.  3168.  1762.  1614.]
  [15537.  6646.   861.   300.  1013.  1450.  1442.]]

 [[    4.     2.     0.     0.     1.     2.     0.]
  [   64.    32.     4.     1.     0.     1.     3.]
  [   89.    53.    33.    37.    26.    19.    14.]
  [  254.    78.     8.     2.    13.    21.    12.]
  [  349.   128.    19.    27.    93.   145.   123.]
  [  520.   406.   331.   337.   345.   402.   219.]
  [  367.   183.    22.    22.   125.   194.   194.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.87703764
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 5888, frames: 180150, time: 58866.83450770378
training steps:  21464
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5888 : 0.0
LR:  0.001
replay buffer size:  184435
Time Taken :  981.0  mins 6.834217071533203  seconds
[[[  473.   220.     0.     0.    31.   139.   258.]
  [ 3542.  1707.   388.    93.   145.   245.   324.]
  [ 9390.  4524.  1541.   996.   869.   699.   479.]
  [21121.  8228.  1087.    59.   162.   146.   163.]
  [22275.  8139.  1127.   313.  1253.  1351.  1257.]
  [19534. 10999.  5381.  4027.  3388.  1896.  1791.]
  [16085.  7028.   910.   319.  1090.  1567.  1575.]]

 [[    5.     2.     0.     0.     1.     2.     0.]
  [   81.    38.     4.     3.     1.     2.     4.]
  [  105.    62.    40.    41.    32.    24.    18.]
  [  272.    85.     8.     2.    13.    22.    15.]
  [  382.   151.    22.    29.   107.   167.   148.]
  [  572.   451.   366.   367.   375.   441.   247.]
  [  401.   203.    24.    25.   142.   213.   213.]]]
