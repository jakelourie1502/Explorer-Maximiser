EVALUATIONS AND MAIN RESULTS
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.0009048183759053549
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 30, frames: 417, time: 24.0103497505188
training steps:  1
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
30 : 0.0
LR:  0.0
replay buffer size:  559
Time Taken :  0.0  mins 24.01012372970581  seconds
[[[ 2.  3.  0.  0.  0.  0.  0.]
  [10. 20.  3.  0.  0.  0.  0.]
  [37. 38.  7.  3.  0.  0.  0.]
  [63. 32.  6.  2.  0.  0.  0.]
  [36. 13.  5.  0.  0.  0.  0.]
  [35. 15.  8.  3.  0.  0.  0.]
  [24. 13.  8.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0.  0.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.7626394
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 554, frames: 10135, time: 2936.9782416820526
training steps:  1186
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
554 : 0.0
LR:  0.001
replay buffer size:  10529
Time Taken :  48.0  mins 56.978033781051636  seconds
[[[  59.   26.    0.    0.    0.    0.    0.]
  [ 301.  160.   56.    5.    3.    0.    0.]
  [ 725.  403.  105.   32.    8.    1.    0.]
  [1045.  651.  125.   10.    7.    1.    1.]
  [ 924.  525.  109.    8.   10.    7.    5.]
  [ 762.  558.  167.   76.   51.   25.   37.]
  [ 960.  750.  125.   15.  143.  146.  233.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    1.    0.]
  [   0.    0.    0.    0.    0.    5.    1.]
  [   0.    0.    0.    0.    3.   18.   35.]
  [   0.    0.    0.    2.   29.   34.   93.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.81316066
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 929, frames: 20275, time: 7853.023095846176
training steps:  2454
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
929 : 0.0
LR:  0.001
replay buffer size:  20974
Time Taken :  130.0  mins 53.022867918014526  seconds
[[[  99.   35.    0.    0.    1.    0.    0.]
  [ 474.  234.   67.    8.    5.    0.    0.]
  [1178.  616.  154.   45.   10.    2.    0.]
  [1999. 1202.  198.   11.    8.    5.    1.]
  [2155. 1252.  204.   20.   18.   13.   11.]
  [1860. 1319.  334.  157.  114.   54.   66.]
  [2307. 1617.  222.   32.  282.  290.  401.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    2.    0.]
  [   0.    0.    0.    0.    0.    6.    1.]
  [   0.    0.    0.    0.    5.   22.   35.]
  [   0.    0.    0.    3.   43.   54.   95.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8199436
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1265, frames: 30184, time: 13895.521668672562
training steps:  3745
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1265 : 0.0
LR:  0.001
replay buffer size:  31103
Time Taken :  231.0  mins 35.52146673202515  seconds
[[[ 126.   51.    0.    0.    2.    5.    4.]
  [ 637.  302.   82.   10.    6.    5.    0.]
  [1663.  878.  199.   60.   18.    5.    0.]
  [2991. 1741.  267.   12.   13.    6.    5.]
  [3327. 1894.  274.   37.   59.   36.   26.]
  [3041. 2044.  524.  264.  207.   99.   85.]
  [3506. 2389.  302.   50.  403.  408.  453.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    1.    2.    0.]
  [   0.    0.    0.    2.    7.   13.    2.]
  [   2.    2.    2.    6.   16.   37.   39.]
  [   4.    3.    1.    4.   67.   77.  116.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8460552
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1574, frames: 40154, time: 18894.75167798996
training steps:  4782
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1574 : 0.0
LR:  0.001
replay buffer size:  41371
Time Taken :  314.0  mins 54.75146961212158  seconds
[[[ 152.   73.    0.    0.    5.    5.    4.]
  [ 861.  418.  103.   11.   10.    6.    0.]
  [2391. 1252.  286.   91.   32.    8.    0.]
  [4233. 2314.  332.   17.   18.   10.    8.]
  [4607. 2418.  327.   47.   79.   47.   36.]
  [4257. 2628.  671.  339.  273.  124.  103.]
  [4653. 2934.  359.   65.  478.  456.  476.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [   5.    4.    0.    0.    0.    0.    0.]
  [  12.    4.    0.    0.    1.    2.    1.]
  [  23.    9.    1.    2.   11.   14.    5.]
  [  19.    9.    4.    8.   26.   46.   45.]
  [  16.    3.    1.    4.   77.   86.  125.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8770044
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 1884, frames: 50230, time: 23286.571027994156
training steps:  6068
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
1884 : 0.0
LR:  0.001
replay buffer size:  51736
Time Taken :  388.0  mins 6.570805549621582  seconds
[[[ 183.   86.    0.    0.    7.    6.    4.]
  [1065.  508.  123.   15.   23.   22.    3.]
  [3140. 1538.  373.  126.   54.   21.    0.]
  [5476. 2756.  388.   21.   26.   14.   10.]
  [5946. 2871.  389.   61.  113.   77.   51.]
  [5514. 3212.  847.  465.  386.  174.  119.]
  [5762. 3397.  409.   88.  628.  560.  514.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   0.    0.    0.    0.    0.    0.    0.]
  [  10.    4.    0.    0.    0.    0.    0.]
  [  23.    5.    0.    0.    1.    4.    1.]
  [  39.   19.    2.    3.   18.   22.   13.]
  [  31.   22.   10.   16.   45.   64.   63.]
  [  22.    7.    1.    6.   95.   99.  130.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.87932146
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 2195, frames: 60150, time: 26762.444160699844
training steps:  7349
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2195 : 0.0
LR:  0.001
replay buffer size:  61943
Time Taken :  446.0  mins 2.4439308643341064  seconds
[[[ 219.   95.    0.    0.   11.   16.    6.]
  [1338.  624.  147.   21.   40.   39.    4.]
  [3961. 1849.  491.  189.   80.   28.    0.]
  [6623. 3227.  436.   26.   31.   17.   11.]
  [7044. 3383.  451.   73.  180.  125.   72.]
  [6482. 3782. 1096.  663.  596.  253.  157.]
  [6587. 3838.  466.  114.  832.  713.  610.]]

 [[   0.    0.    0.    0.    0.    0.    0.]
  [   1.    0.    0.    0.    0.    0.    0.]
  [  13.    4.    0.    0.    0.    0.    0.]
  [  26.    6.    0.    0.    2.    4.    1.]
  [  45.   21.    2.    4.   24.   29.   15.]
  [  37.   26.   15.   28.   64.   85.   70.]
  [  27.    8.    1.    9.  101.  105.  136.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8885324
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 2511, frames: 70184, time: 29227.94215297699
training steps:  8257
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2511 : 0.0
LR:  0.001
replay buffer size:  72221
Time Taken :  487.0  mins 7.9419238567352295  seconds
[[[ 245.  107.    0.    0.   14.   28.   13.]
  [1633.  744.  166.   26.   77.   71.   17.]
  [4621. 2177.  637.  292.  141.   50.    3.]
  [7580. 3667.  494.   30.   37.   23.   12.]
  [8011. 3827.  500.   93.  240.  175.   87.]
  [7374. 4387. 1337.  857.  815.  369.  205.]
  [7374. 4346.  534.  133. 1113.  930.  729.]]

 [[   0.    1.    0.    0.    0.    0.    0.]
  [   7.    5.    1.    0.    0.    0.    0.]
  [  36.   19.   10.    7.    1.    0.    0.]
  [  48.   12.    1.    0.    2.    4.    1.]
  [  64.   28.    4.    7.   37.   40.   17.]
  [  58.   40.   37.   58.  114.  122.   80.]
  [  28.   10.    2.   11.  130.  136.  154.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8936632
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 2884, frames: 80135, time: 31914.408633708954
training steps:  9398
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
2884 : 0.0
LR:  0.001
replay buffer size:  82498
Time Taken :  531.0  mins 54.408413887023926  seconds
[[[ 283.  126.    0.    0.   17.   37.   18.]
  [1915.  878.  196.   43.  108.   97.   25.]
  [5436. 2595.  808.  416.  222.   85.   17.]
  [8680. 4136.  566.   39.   50.   29.   14.]
  [8999. 4238.  560.  108.  294.  233.  113.]
  [8243. 4938. 1538.  985.  980.  450.  241.]
  [8251. 4847.  596.  149. 1281. 1066.  812.]]

 [[   0.    1.    0.    0.    0.    0.    0.]
  [   7.    5.    1.    0.    0.    0.    0.]
  [  36.   19.   10.    7.    1.    0.    0.]
  [  48.   12.    1.    0.    2.    4.    1.]
  [  64.   28.    5.   11.   46.   47.   18.]
  [  58.   40.   40.   73.  144.  150.   86.]
  [  28.   10.    2.   13.  148.  165.  162.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8692291
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 3257, frames: 90099, time: 34620.37898182869
training steps:  10570
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3257 : 0.0
LR:  0.001
replay buffer size:  92794
Time Taken :  577.0  mins 0.37874889373779297  seconds
[[[ 318.  148.    0.    0.   24.   42.   19.]
  [2171. 1042.  227.   57.  172.  133.   36.]
  [6255. 3070. 1050.  632.  381.  145.   25.]
  [9804. 4625.  639.   50.   66.   35.   17.]
  [9955. 4630.  613.  119.  339.  278.  131.]
  [9071. 5449. 1744. 1115. 1135.  509.  264.]
  [9039. 5286.  657.  166. 1422. 1191.  889.]]

 [[   0.    1.    0.    0.    0.    0.    0.]
  [   8.    5.    1.    0.    0.    0.    0.]
  [  51.   24.   11.    7.    1.    0.    0.]
  [  60.   15.    1.    0.    2.    4.    1.]
  [  69.   40.    7.   13.   55.   52.   20.]
  [  61.   47.   50.   86.  157.  165.   88.]
  [  28.   10.    3.   14.  160.  177.  163.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.87723494
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 3640, frames: 100164, time: 37366.249748945236
training steps:  11745
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
3640 : 0.0
LR:  0.001
replay buffer size:  103208
Time Taken :  622.0  mins 46.24951672554016  seconds
[[[  356.   168.     0.     0.    31.    67.    25.]
  [ 2422.  1182.   269.    74.   285.   211.    58.]
  [ 7157.  3643.  1421.   937.   623.   233.    45.]
  [10911.  5132.   721.    65.    83.    37.    22.]
  [10807.  5036.   654.   129.   378.   310.   148.]
  [ 9727.  5923.  1924.  1261.  1265.   571.   300.]
  [ 9711.  5673.   710.   182.  1534.  1286.   964.]]

 [[    0.     1.     0.     0.     0.     0.     0.]
  [    8.     5.     1.     0.     0.     0.     0.]
  [   51.    24.    11.     7.     1.     0.     0.]
  [   61.    15.     1.     0.     3.     4.     2.]
  [   71.    41.     9.    14.    64.    63.    27.]
  [   64.    49.    52.    93.   183.   195.   101.]
  [   28.    10.     3.    21.   184.   205.   181.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8770041
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 4071, frames: 110181, time: 40092.63569164276
training steps:  12924
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4071 : 0.0
LR:  0.001
replay buffer size:  113549
Time Taken :  668.0  mins 12.635458707809448  seconds
[[[  381.   190.     0.     0.    40.    87.    42.]
  [ 2659.  1361.   315.   101.   391.   291.    81.]
  [ 8044.  4329.  1822.  1253.   900.   342.    70.]
  [12081.  5782.   827.    83.   109.    40.    23.]
  [11626.  5440.   713.   146.   404.   331.   158.]
  [10285.  6356.  2096.  1374.  1356.   617.   327.]
  [10252.  6047.   753.   202.  1630.  1367.  1021.]]

 [[    0.     1.     0.     0.     0.     0.     0.]
  [    8.     5.     1.     0.     0.     0.     0.]
  [   51.    24.    11.     7.     1.     0.     0.]
  [   61.    15.     1.     0.     4.     5.     2.]
  [   71.    41.     9.    17.    73.    73.    28.]
  [   64.    52.    55.   100.   194.   215.   104.]
  [   31.    13.     3.    23.   193.   220.   189.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.865337
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 4479, frames: 120066, time: 42757.63936376572
training steps:  14087
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4479 : 0.0
LR:  0.001
replay buffer size:  123712
Time Taken :  712.0  mins 37.63913083076477  seconds
[[[  407.   212.     0.     0.    44.   112.    49.]
  [ 2898.  1546.   348.   125.   457.   355.   111.]
  [ 8956.  5021.  2214.  1561.  1116.   439.   101.]
  [13192.  6351.   932.   109.   132.    47.    30.]
  [12471.  5811.   767.   163.   436.   376.   193.]
  [10864.  6804.  2268.  1497.  1468.   668.   366.]
  [10766.  6372.   789.   218.  1752.  1472.  1085.]]

 [[    0.     1.     0.     0.     0.     0.     0.]
  [    8.     5.     1.     0.     0.     0.     0.]
  [   51.    24.    11.     7.     1.     0.     0.]
  [   61.    15.     1.     0.     5.     5.     2.]
  [   71.    41.     9.    18.    78.    76.    30.]
  [   64.    56.    60.   108.   216.   230.   115.]
  [   36.    18.     4.    25.   217.   240.   206.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8467952
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 4878, frames: 130230, time: 45455.687161684036
training steps:  15267
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
4878 : 0.0
LR:  0.001
replay buffer size:  134113
Time Taken :  757.0  mins 35.686930894851685  seconds
[[[  440.   224.     0.     0.    53.   141.    61.]
  [ 3148.  1711.   382.   149.   553.   450.   164.]
  [ 9813.  5657.  2609.  1910.  1406.   581.   163.]
  [14240.  6906.  1016.   127.   164.    52.    37.]
  [13242.  6243.   819.   183.   491.   420.   224.]
  [11412.  7252.  2496.  1672.  1625.   743.   417.]
  [11314.  6753.   829.   242.  1882.  1609.  1148.]]

 [[    0.     1.     0.     0.     0.     0.     0.]
  [    8.     5.     1.     0.     0.     0.     0.]
  [   51.    24.    11.     7.     1.     0.     0.]
  [   61.    15.     1.     0.     5.     5.     2.]
  [   71.    41.     9.    20.    84.    77.    30.]
  [   64.    56.    62.   113.   227.   239.   117.]
  [   36.    18.     4.    26.   229.   247.   211.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.8598186
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 5284, frames: 140240, time: 48195.88167095184
training steps:  16447
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5284 : 0.0
LR:  0.001
replay buffer size:  144424
Time Taken :  803.0  mins 15.881441593170166  seconds
[[[  481.   245.     0.     0.    61.   162.    85.]
  [ 3483.  1919.   426.   167.   633.   523.   192.]
  [10775.  6310.  2931.  2155.  1628.   692.   207.]
  [15523.  7515.  1099.   142.   188.    59.    42.]
  [14138.  6655.   878.   200.   537.   456.   244.]
  [11943.  7661.  2663.  1801.  1759.   806.   459.]
  [11714.  7017.   868.   259.  1975.  1690.  1209.]]

 [[    0.     1.     0.     0.     0.     0.     0.]
  [   10.     5.     1.     0.     0.     0.     0.]
  [   61.    28.    13.     9.     2.     0.     0.]
  [   80.    24.     1.     0.     7.     6.     3.]
  [   84.    45.     9.    21.    91.    89.    37.]
  [   70.    62.    68.   122.   241.   248.   124.]
  [   42.    21.     4.    27.   244.   259.   222.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.86563295
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 5689, frames: 150305, time: 50936.0071618557
training steps:  17623
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
5689 : 0.0
LR:  0.001
replay buffer size:  154807
Time Taken :  848.0  mins 56.00693082809448  seconds
[[[  516.   265.     0.     0.    67.   188.   109.]
  [ 3833.  2086.   470.   189.   727.   598.   240.]
  [11885.  7035.  3374.  2484.  1875.   792.   246.]
  [16928.  8157.  1206.   165.   209.    74.    48.]
  [15014.  7096.   924.   212.   568.   491.   270.]
  [12365.  8026.  2853.  1913.  1831.   840.   489.]
  [12047.  7220.   892.   271.  2027.  1743.  1244.]]

 [[    0.     1.     0.     0.     0.     0.     0.]
  [   13.    11.     1.     0.     0.     0.     0.]
  [   67.    33.    13.     9.     2.     0.     0.]
  [   86.    24.     1.     0.     7.     6.     3.]
  [   88.    47.     9.    23.    94.    95.    43.]
  [   71.    63.    73.   129.   252.   270.   136.]
  [   42.    21.     4.    30.   250.   268.   229.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.86552155
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 6094, frames: 160010, time: 53596.04229283333
training steps:  18759
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6094 : 0.0
LR:  0.001
replay buffer size:  164712
Time Taken :  893.0  mins 16.04206681251526  seconds
[[[  539.   288.     0.     0.    74.   205.   118.]
  [ 4103.  2275.   528.   213.   834.   660.   259.]
  [12857.  7732.  3772.  2748.  2065.   873.   285.]
  [18191.  8800.  1307.   189.   233.    83.    53.]
  [15877.  7511.   973.   220.   602.   509.   288.]
  [12818.  8405.  3045.  2036.  1926.   886.   534.]
  [12400.  7441.   917.   283.  2085.  1805.  1299.]]

 [[    1.     1.     0.     0.     0.     0.     0.]
  [   19.    12.     1.     0.     0.     0.     0.]
  [   89.    39.    16.     9.     2.     0.     0.]
  [  110.    34.     1.     0.     8.     8.     5.]
  [  100.    49.     9.    24.   103.   108.    52.]
  [   78.    72.    82.   138.   265.   301.   151.]
  [   42.    21.     4.    30.   259.   289.   240.]]]
Test reward:  0.0
Q value #end_state_>_threshold:  0
Q value #non_end_state_>threshold:  0
maxi score:  0.0001
siam score:  -0.867281
Scores:  {'0.333': 0.0001, '0.667': 0.0001, '1.0': 0.0001, '1.333': 0.0001, '1.667': 0.0001, '2.0': 0.0001}
best rdn ma / adv:  0.333 0.333
best rdn adv:  0.0
Episodes: 6541, frames: 170336, time: 56468.60595679283
training steps:  19968
retraining steps:  0
RDN obj mus: [0, 0, 0, 0, 0]
RDN obj sigmas: [1, 1, 1, 1, 1]
6541 : 0.0
LR:  0.001
replay buffer size:  175387
Time Taken :  941.0  mins 8.605724811553955  seconds
[[[  571.   314.     0.     0.    84.   252.   161.]
  [ 4420.  2505.   578.   238.   937.   759.   316.]
  [13842.  8546.  4221.  3090.  2294.   961.   345.]
  [19498.  9572.  1412.   213.   255.   101.    58.]
  [16688.  8009.  1037.   229.   620.   543.   325.]
  [13228.  8808.  3223.  2149.  2014.   934.   584.]
  [12723.  7680.   951.   300.  2146.  1861.  1356.]]

 [[    1.     1.     0.     0.     0.     0.     0.]
  [   22.    14.     1.     0.     0.     0.     0.]
  [   95.    45.    16.     9.     2.     0.     0.]
  [  113.    36.     2.     0.     8.     8.     6.]
  [  104.    49.     9.    26.   106.   108.    53.]
  [   79.    73.    83.   140.   271.   311.   158.]
  [   42.    21.     4.    30.   261.   292.   245.]]]
