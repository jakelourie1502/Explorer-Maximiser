append_mcts_svs:False
dirichlet_alpha:0.3
noise:0.3
dirichlet_alpha:0.5
noise:0.5
sims:{-1: 6, 6000: 50}
c1:1
c2:19652
temperature_init:1
temperature_changes:{-1: 1, 3000000.0: 0.5}
manual_over_ride_play_limit:None
exponent_node_n:1
ucb_denom_k:1
use_policy:True
model_expV_on_dones:True
norm_Qs_OnMaxi:True
norm_Qs_OnAll:True
norm_each_turn:False
state_channels:64
res_block_kernel_size:3
res_block_channels:[32, 32, 64, 64, 64]
res_block_ds:[False, True, False, False, False]
conv1:{'channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1}
conv2:{'channels': 64, 'kernel_size': 3, 'stride': 2, 'padding': 1}
reward_support:[-1, 1, 51]
conv1:{'kernel_size': 3, 'stride': 1, 'padding': 1}
res_blocks:[64]
reward_conv_channels:32
reward_hidden_dim:128
terminal_conv_channels:32
terminal_hidden_dim:64
value_support:[-1, 1, 51]
res_block:[64]
value_conv_channels:32
value_hidden_dim:128
policy_conv_channels:32
policy_hidden_dim:128
expV_conv_channels:32
expV_hidden_dim:128
expV_support:[-10, 10, 51]
proj_l1:256
proj_out:128
pred_hid:256
replay_buffer_size:50000
replay_buffer_size_exploration:200000
all_time_buffer_size:200000
batch_size:128
play_workers:2
min_workers:1
max_workers:6
lr:0.001
lr_warmup:1000
lr_decay:1
lr_decay_step:100000
optimizer:<class 'torch.optim.rmsprop.RMSprop'>
momentum:0.9
l2:0.0001
rho:0.99
k:5
value:0.25
dones:2.0
siam:2
rdn:0.5
expV:0.5
train_start_batch_multiple:2
prioritised_replay:True
ep_to_batch_ratio:[15, 16]
main_to_rdn_ratio:2
train_to_RS_ratio:4
on_policy_expV:False
rgb_im:True
channels:3
state_size:[6, 6]
timesteps_in_obs:2
store_prev_actions:True
env:<class 'game_play.Car_Driving_Env.RaceWorld'>
same_env_each_time:True
env_size:[6, 30]
observable_size:[6, 9]
game_modes:1
env_map:[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 3. 3. 3. 3.
  3. 3. 3. 3. 3. 3.]
 [1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 3. 3. 3. 3.
  3. 3. 3. 3. 3. 3.]
 [1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2. 1. 1. 2. 2. 1. 3. 3. 3. 3.
  3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 3. 3. 3. 3.
  3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]]
max_steps:100
actions_size:7
optimal_score:0.86
total_frames:205000
exp_gamma:0.95
atari_env:False
memory_size:30
reward_clipping:False
image_size:[48, 48]
deque_length:3
PRESET_CONFIG:4
VK:False
follow_better_policy:0.0
use_two_heads:False
use_siam:True
exploration_type:none
rdn_beta:[0, 0.0, 1]
explorer_percentage:0.0
reward_exploration:False
train_dones:True
norm_state_vecs:False
RND_output_vector:256
RND_loss:cosine
prediction_bias:True
distance_measure:False
update_play_model:16
gamma:0.99
calc_n_step_rewards_after_frames:10000
N_steps_reward:5
start_frame_count:0
load_in_model:False
log_states:True
log_metrics:False
exploration_logger_dims:(1, 180)
device_train:cpu
device_selfplay:cpu
eval_x_frames:10000
eval_count:20
detach_expV_calc:True
use_new_episode_expV:False
start_training_expV_min:10000
start_training_expV_max:20000
start_training_expV_siam_override:0.8
value_only:False
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 3. 3. 3. 3.
  3. 3. 3. 3. 3. 3.]
 [1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 3. 3. 3. 3.
  3. 3. 3. 3. 3. 3.]
 [1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 0. 2. 1. 1. 2. 2. 1. 3. 3. 3. 3.
  3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 3. 3. 3. 3.
  3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
Starting evaluation
siam score:  -0.0026376981034197593
maxi score, test score, baseline:  -0.9881352941176471 0.0 0.0
probs:  [1.0]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [1.0]
maxi score, test score, baseline:  -0.9901912621359223 -1.0 -0.9901912621359223
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
siam score:  -0.24409725
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
deleting a thread, now have 2 threads
Frames:  1676 train batches done:  56 episodes:  87
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  205000
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
siam score:  -0.39905548
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
deleting a thread, now have 1 threads
Frames:  1676 train batches done:  151 episodes:  87
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
siam score:  -0.40594637
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [1.0]
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [1.0]
siam score:  -0.4059853
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [1.0]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
probs:  [1.0]
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
probs:  [1.0]
maxi score, test score, baseline:  -0.9919 -1.0 -0.9919
probs:  [1.0]
maxi score, test score, baseline:  -0.9919 -1.0 -0.9919
probs:  [1.0]
maxi score, test score, baseline:  -0.9919 -1.0 -0.9919
probs:  [1.0]
maxi score, test score, baseline:  -0.9919 -1.0 -0.9919
probs:  [1.0]
maxi score, test score, baseline:  -0.9919 -1.0 -0.9919
probs:  [1.0]
maxi score, test score, baseline:  -0.9919 -1.0 -0.9919
probs:  [1.0]
maxi score, test score, baseline:  -0.9919634920634921 -1.0 -0.9919634920634921
probs:  [1.0]
maxi score, test score, baseline:  -0.9922076923076923 -1.0 -0.9922076923076923
probs:  [1.0]
maxi score, test score, baseline:  -0.9926536231884058 -1.0 -0.9926536231884058
probs:  [1.0]
siam score:  -0.46376213
maxi score, test score, baseline:  -0.9927057553956835 -1.0 -0.9927057553956835
probs:  [1.0]
maxi score, test score, baseline:  -0.9927571428571429 -1.0 -0.9927571428571429
probs:  [1.0]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [1.0]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [1.0]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [1.0]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [1.0]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [1.0]
maxi score, test score, baseline:  -0.9931432432432432 -1.0 -0.9931432432432432
maxi score, test score, baseline:  -0.9931432432432432 -1.0 -0.9931432432432432
probs:  [1.0]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [1.0]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [1.0]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [1.0]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [1.0]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [1.0]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [1.0]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [1.0]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [1.0]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [1.0]
siam score:  -0.47919863
maxi score, test score, baseline:  -0.9937650306748467 -1.0 -0.9937650306748467
probs:  [1.0]
maxi score, test score, baseline:  -0.9937650306748467 -1.0 -0.9937650306748467
probs:  [1.0]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [1.0]
maxi score, test score, baseline:  -0.9940860465116279 -1.0 -0.9940860465116279
maxi score, test score, baseline:  -0.9940860465116279 -1.0 -0.9940860465116279
probs:  [1.0]
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [1.0]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [1.0]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [1.0]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [1.0]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [1.0]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [1.0]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [1.0]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [1.0]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [1.0]
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
probs:  [1.0]
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [1.0]
maxi score, test score, baseline:  -0.9944054945054945 -1.0 -0.9944054945054945
probs:  [1.0]
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
maxi score, test score, baseline:  -0.9947186528497409 -1.0 -0.9947186528497409
probs:  [1.0]
maxi score, test score, baseline:  -0.9949 -1.0 -0.9949
probs:  [1.0]
maxi score, test score, baseline:  -0.9949 -1.0 -0.9949
probs:  [1.0]
maxi score, test score, baseline:  -0.9949 -1.0 -0.9949
probs:  [1.0]
maxi score, test score, baseline:  -0.9949 -1.0 -0.9949
probs:  [1.0]
maxi score, test score, baseline:  -0.9949 -1.0 -0.9949
probs:  [1.0]
siam score:  -0.53804225
maxi score, test score, baseline:  -0.9949 -1.0 -0.9949
probs:  [1.0]
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [1.0]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  205000
Printing some Q and Qe and total Qs values:  [[0.607]
 [0.676]
 [0.676]
 [0.508]
 [0.676]
 [0.676]
 [0.676]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.607]
 [0.676]
 [0.676]
 [0.508]
 [0.676]
 [0.676]
 [0.676]]
actor:  0 policy actor:  0  step number:  41 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9887105726872247 -1.0 -0.9887105726872247
probs:  [1.0]
maxi score, test score, baseline:  -0.9888565217391305 -1.0 -0.9888565217391305
probs:  [1.0]
maxi score, test score, baseline:  -0.9890452991452992 -1.0 -0.9890452991452992
probs:  [1.0]
maxi score, test score, baseline:  -0.9890452991452992 -1.0 -0.9890452991452992
probs:  [1.0]
maxi score, test score, baseline:  -0.9890452991452992 -1.0 -0.9890452991452992
probs:  [1.0]
maxi score, test score, baseline:  -0.9890452991452992 -1.0 -0.9890452991452992
probs:  [1.0]
maxi score, test score, baseline:  -0.9890452991452992 -1.0 -0.9890452991452992
maxi score, test score, baseline:  -0.9890452991452992 -1.0 -0.9890452991452992
probs:  [1.0]
maxi score, test score, baseline:  -0.9890452991452992 -1.0 -0.9890452991452992
probs:  [1.0]
siam score:  -0.57089376
maxi score, test score, baseline:  -0.9890452991452992 -1.0 -0.9890452991452992
probs:  [1.0]
maxi score, test score, baseline:  -0.9890452991452992 -1.0 -0.9890452991452992
probs:  [1.0]
maxi score, test score, baseline:  -0.9890914893617022 -1.0 -0.9890914893617022
probs:  [1.0]
maxi score, test score, baseline:  -0.9890914893617022 -1.0 -0.9890914893617022
probs:  [1.0]
maxi score, test score, baseline:  -0.989227731092437 -1.0 -0.989227731092437
probs:  [1.0]
maxi score, test score, baseline:  -0.9894473251028807 -1.0 -0.9894473251028807
maxi score, test score, baseline:  -0.9894473251028807 -1.0 -0.9894473251028807
probs:  [1.0]
maxi score, test score, baseline:  -0.9896165991902834 -1.0 -0.9896165991902834
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
siam score:  -0.57912755
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9897400000000001 -1.0 -0.9897400000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.989978125 -1.0 -0.989978125
maxi score, test score, baseline:  -0.989978125 -1.0 -0.989978125
probs:  [1.0]
maxi score, test score, baseline:  -0.9901681992337166 -1.0 -0.9901681992337166
probs:  [1.0]
maxi score, test score, baseline:  -0.9902422053231941 -1.0 -0.9902422053231941
probs:  [1.0]
maxi score, test score, baseline:  -0.990278787878788 -1.0 -0.990278787878788
maxi score, test score, baseline:  -0.990278787878788 -1.0 -0.990278787878788
probs:  [1.0]
maxi score, test score, baseline:  -0.9904223880597016 -1.0 -0.9904223880597016
maxi score, test score, baseline:  -0.990457620817844 -1.0 -0.990457620817844
maxi score, test score, baseline:  -0.990457620817844 -1.0 -0.990457620817844
probs:  [1.0]
maxi score, test score, baseline:  -0.9905273062730628 -1.0 -0.9905273062730628
probs:  [1.0]
maxi score, test score, baseline:  -0.9907303249097474 -1.0 -0.9907303249097474
maxi score, test score, baseline:  -0.9909247349823322 -1.0 -0.9909247349823322
maxi score, test score, baseline:  -0.9909563380281692 -1.0 -0.9909563380281692
probs:  [1.0]
maxi score, test score, baseline:  -0.9909877192982458 -1.0 -0.9909877192982458
probs:  [1.0]
maxi score, test score, baseline:  -0.9909877192982458 -1.0 -0.9909877192982458
probs:  [1.0]
maxi score, test score, baseline:  -0.9909877192982458 -1.0 -0.9909877192982458
probs:  [1.0]
maxi score, test score, baseline:  -0.9909877192982458 -1.0 -0.9909877192982458
probs:  [1.0]
maxi score, test score, baseline:  -0.9909877192982458 -1.0 -0.9909877192982458
probs:  [1.0]
maxi score, test score, baseline:  -0.9909877192982458 -1.0 -0.9909877192982458
probs:  [1.0]
maxi score, test score, baseline:  -0.9910498257839723 -1.0 -0.9910498257839723
probs:  [1.0]
maxi score, test score, baseline:  -0.9912605442176872 -1.0 -0.9912605442176872
probs:  [1.0]
maxi score, test score, baseline:  -0.9914050167224081 -1.0 -0.9914050167224081
probs:  [1.0]
siam score:  -0.60219514
maxi score, test score, baseline:  -0.9914333333333335 -1.0 -0.9914333333333335
maxi score, test score, baseline:  -0.9914333333333335 -1.0 -0.9914333333333335
probs:  [1.0]
maxi score, test score, baseline:  -0.9914333333333335 -1.0 -0.9914333333333335
probs:  [1.0]
maxi score, test score, baseline:  -0.9914333333333335 -1.0 -0.9914333333333335
probs:  [1.0]
maxi score, test score, baseline:  -0.9914333333333335 -1.0 -0.9914333333333335
probs:  [1.0]
maxi score, test score, baseline:  -0.9914614617940201 -1.0 -0.9914614617940201
probs:  [1.0]
maxi score, test score, baseline:  -0.9914614617940201 -1.0 -0.9914614617940201
probs:  [1.0]
siam score:  -0.61331797
maxi score, test score, baseline:  -0.99148940397351 -1.0 -0.99148940397351
probs:  [1.0]
maxi score, test score, baseline:  -0.99148940397351 -1.0 -0.99148940397351
probs:  [1.0]
maxi score, test score, baseline:  -0.99148940397351 -1.0 -0.99148940397351
probs:  [1.0]
maxi score, test score, baseline:  -0.99148940397351 -1.0 -0.99148940397351
probs:  [1.0]
maxi score, test score, baseline:  -0.99148940397351 -1.0 -0.99148940397351
probs:  [1.0]
siam score:  -0.61045885
maxi score, test score, baseline:  -0.99148940397351 -1.0 -0.99148940397351
probs:  [1.0]
maxi score, test score, baseline:  -0.99148940397351 -1.0 -0.99148940397351
maxi score, test score, baseline:  -0.99148940397351 -1.0 -0.99148940397351
probs:  [1.0]
maxi score, test score, baseline:  -0.9915171617161718 -1.0 -0.9915171617161718
probs:  [1.0]
maxi score, test score, baseline:  -0.9915171617161718 -1.0 -0.9915171617161718
probs:  [1.0]
maxi score, test score, baseline:  -0.9915171617161718 -1.0 -0.9915171617161718
probs:  [1.0]
maxi score, test score, baseline:  -0.9915171617161718 -1.0 -0.9915171617161718
probs:  [1.0]
maxi score, test score, baseline:  -0.9915171617161718 -1.0 -0.9915171617161718
probs:  [1.0]
maxi score, test score, baseline:  -0.9915447368421054 -1.0 -0.9915447368421054
probs:  [1.0]
maxi score, test score, baseline:  -0.9915447368421054 -1.0 -0.9915447368421054
probs:  [1.0]
maxi score, test score, baseline:  -0.9915721311475412 -1.0 -0.9915721311475412
probs:  [1.0]
main train batch thing paused
add a thread
Adding thread: now have 2 threads
line 256 mcts: sample exp_bonus 0.0
main train batch thing paused
add a thread
Adding thread: now have 3 threads
Printing some Q and Qe and total Qs values:  [[0.37 ]
 [0.097]
 [0.581]
 [0.606]
 [0.602]
 [0.602]
 [0.602]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.37 ]
 [0.097]
 [0.581]
 [0.606]
 [0.602]
 [0.602]
 [0.602]]
maxi score, test score, baseline:  -0.9918620253164558 -1.0 -0.9918620253164558
probs:  [1.0]
maxi score, test score, baseline:  -0.9918620253164558 -1.0 -0.9918620253164558
probs:  [1.0]
maxi score, test score, baseline:  -0.9918620253164558 -1.0 -0.9918620253164558
maxi score, test score, baseline:  -0.9918620253164558 -1.0 -0.9918620253164558
probs:  [1.0]
siam score:  -0.6589914
maxi score, test score, baseline:  -0.9918620253164558 -1.0 -0.9918620253164558
probs:  [1.0]
maxi score, test score, baseline:  -0.9918620253164558 -1.0 -0.9918620253164558
probs:  [1.0]
maxi score, test score, baseline:  -0.9918620253164558 -1.0 -0.9918620253164558
probs:  [1.0]
maxi score, test score, baseline:  -0.9918620253164558 -1.0 -0.9918620253164558
maxi score, test score, baseline:  -0.9919125786163523 -1.0 -0.9919125786163523
probs:  [1.0]
maxi score, test score, baseline:  -0.9919376175548591 -1.0 -0.9919376175548591
probs:  [1.0]
maxi score, test score, baseline:  -0.9919625000000001 -1.0 -0.9919625000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9919625000000001 -1.0 -0.9919625000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9919625000000001 -1.0 -0.9919625000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9920118012422362 -1.0 -0.9920118012422362
probs:  [1.0]
maxi score, test score, baseline:  -0.9920118012422362 -1.0 -0.9920118012422362
probs:  [1.0]
maxi score, test score, baseline:  -0.9920118012422362 -1.0 -0.9920118012422362
probs:  [1.0]
maxi score, test score, baseline:  -0.9920362229102169 -1.0 -0.9920362229102169
probs:  [1.0]
maxi score, test score, baseline:  -0.9920604938271607 -1.0 -0.9920604938271607
probs:  [1.0]
maxi score, test score, baseline:  -0.9920604938271607 -1.0 -0.9920604938271607
probs:  [1.0]
maxi score, test score, baseline:  -0.9920846153846155 -1.0 -0.9920846153846155
maxi score, test score, baseline:  -0.9921085889570553 -1.0 -0.9921085889570553
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.71 ]
 [0.435]
 [0.71 ]
 [0.736]
 [0.71 ]
 [0.71 ]
 [0.71 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.71 ]
 [0.435]
 [0.71 ]
 [0.736]
 [0.71 ]
 [0.71 ]
 [0.71 ]]
maxi score, test score, baseline:  -0.9921085889570553 -1.0 -0.9921085889570553
siam score:  -0.6570276
Printing some Q and Qe and total Qs values:  [[0.769]
 [0.686]
 [0.766]
 [0.722]
 [0.766]
 [0.766]
 [0.766]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.769]
 [0.686]
 [0.766]
 [0.722]
 [0.766]
 [0.766]
 [0.766]]
Training Flag: False
Self play flag: True
add more workers flag:  True
expV_train_flag:  False
expV_train_start_flag:  205000
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Printing some Q and Qe and total Qs values:  [[0.592]
 [0.623]
 [0.667]
 [0.663]
 [0.678]
 [0.586]
 [0.622]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.592]
 [0.623]
 [0.667]
 [0.663]
 [0.678]
 [0.586]
 [0.622]]
maxi score, test score, baseline:  -0.9922952095808384 -1.0 -0.9922952095808384
probs:  [1.0]
maxi score, test score, baseline:  -0.9923179104477613 -1.0 -0.9923179104477613
probs:  [1.0]
maxi score, test score, baseline:  -0.9923404761904763 -1.0 -0.9923404761904763
maxi score, test score, baseline:  -0.9923404761904763 -1.0 -0.9923404761904763
probs:  [1.0]
maxi score, test score, baseline:  -0.9923404761904763 -1.0 -0.9923404761904763
maxi score, test score, baseline:  -0.9923404761904763 -1.0 -0.9923404761904763
probs:  [1.0]
maxi score, test score, baseline:  -0.9924073746312686 -1.0 -0.9924073746312686
probs:  [1.0]
maxi score, test score, baseline:  -0.992429411764706 -1.0 -0.992429411764706
maxi score, test score, baseline:  -0.992429411764706 -1.0 -0.992429411764706
probs:  [1.0]
maxi score, test score, baseline:  -0.992429411764706 -1.0 -0.992429411764706
probs:  [1.0]
maxi score, test score, baseline:  -0.992429411764706 -1.0 -0.992429411764706
maxi score, test score, baseline:  -0.992429411764706 -1.0 -0.992429411764706
probs:  [1.0]
maxi score, test score, baseline:  -0.992451319648094 -1.0 -0.992451319648094
probs:  [1.0]
maxi score, test score, baseline:  -0.9924730994152048 -1.0 -0.9924730994152048
probs:  [1.0]
maxi score, test score, baseline:  -0.9925162790697676 -1.0 -0.9925162790697676
probs:  [1.0]
maxi score, test score, baseline:  -0.9925376811594204 -1.0 -0.9925376811594204
probs:  [1.0]
maxi score, test score, baseline:  -0.9925376811594204 -1.0 -0.9925376811594204
probs:  [1.0]
maxi score, test score, baseline:  -0.9925376811594204 -1.0 -0.9925376811594204
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.603]
 [0.603]
 [0.603]
 [0.656]
 [0.603]
 [0.603]
 [0.603]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.603]
 [0.603]
 [0.603]
 [0.656]
 [0.603]
 [0.603]
 [0.603]]
maxi score, test score, baseline:  -0.9925376811594204 -1.0 -0.9925376811594204
probs:  [1.0]
maxi score, test score, baseline:  -0.9925589595375723 -1.0 -0.9925589595375723
probs:  [1.0]
maxi score, test score, baseline:  -0.9925589595375723 -1.0 -0.9925589595375723
probs:  [1.0]
maxi score, test score, baseline:  -0.9925801152737753 -1.0 -0.9925801152737753
maxi score, test score, baseline:  -0.9925801152737753 -1.0 -0.9925801152737753
probs:  [1.0]
maxi score, test score, baseline:  -0.9926011494252874 -1.0 -0.9926011494252874
probs:  [1.0]
maxi score, test score, baseline:  -0.9926220630372494 -1.0 -0.9926220630372494
probs:  [1.0]
maxi score, test score, baseline:  -0.9926220630372494 -1.0 -0.9926220630372494
probs:  [1.0]
maxi score, test score, baseline:  -0.9926220630372494 -1.0 -0.9926220630372494
probs:  [1.0]
maxi score, test score, baseline:  -0.9926220630372494 -1.0 -0.9926220630372494
probs:  [1.0]
maxi score, test score, baseline:  -0.9926428571428573 -1.0 -0.9926428571428573
probs:  [1.0]
maxi score, test score, baseline:  -0.992684090909091 -1.0 -0.992684090909091
probs:  [1.0]
maxi score, test score, baseline:  -0.992684090909091 -1.0 -0.992684090909091
maxi score, test score, baseline:  -0.992684090909091 -1.0 -0.992684090909091
probs:  [1.0]
maxi score, test score, baseline:  -0.992684090909091 -1.0 -0.992684090909091
probs:  [1.0]
maxi score, test score, baseline:  -0.9927045325779038 -1.0 -0.9927045325779038
probs:  [1.0]
maxi score, test score, baseline:  -0.9927045325779038 -1.0 -0.9927045325779038
probs:  [1.0]
siam score:  -0.6734551
maxi score, test score, baseline:  -0.9927450704225353 -1.0 -0.9927450704225353
probs:  [1.0]
maxi score, test score, baseline:  -0.992765168539326 -1.0 -0.992765168539326
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.756]
 [0.587]
 [0.669]
 [0.683]
 [0.632]
 [0.672]
 [0.633]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.756]
 [0.587]
 [0.669]
 [0.683]
 [0.632]
 [0.672]
 [0.633]]
maxi score, test score, baseline:  -0.9927851540616247 -1.0 -0.9927851540616247
probs:  [1.0]
maxi score, test score, baseline:  -0.9928444444444445 -1.0 -0.9928444444444445
probs:  [1.0]
maxi score, test score, baseline:  -0.9928444444444445 -1.0 -0.9928444444444445
probs:  [1.0]
maxi score, test score, baseline:  -0.9928444444444445 -1.0 -0.9928444444444445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.775]
 [0.775]
 [0.775]
 [0.772]
 [0.775]
 [0.775]
 [0.775]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.775]
 [0.775]
 [0.775]
 [0.772]
 [0.775]
 [0.775]
 [0.775]]
maxi score, test score, baseline:  -0.9928444444444445 -1.0 -0.9928444444444445
probs:  [1.0]
maxi score, test score, baseline:  -0.9928444444444445 -1.0 -0.9928444444444445
probs:  [1.0]
maxi score, test score, baseline:  -0.9928639889196677 -1.0 -0.9928639889196677
probs:  [1.0]
maxi score, test score, baseline:  -0.9928639889196677 -1.0 -0.9928639889196677
probs:  [1.0]
maxi score, test score, baseline:  -0.9928834254143648 -1.0 -0.9928834254143648
probs:  [1.0]
maxi score, test score, baseline:  -0.9929027548209367 -1.0 -0.9929027548209367
probs:  [1.0]
maxi score, test score, baseline:  -0.9929219780219781 -1.0 -0.9929219780219781
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]]
main train batch thing paused
add a thread
Adding thread: now have 5 threads
Printing some Q and Qe and total Qs values:  [[0.737]
 [0.737]
 [0.737]
 [0.778]
 [0.737]
 [0.737]
 [0.737]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.737]
 [0.737]
 [0.737]
 [0.778]
 [0.737]
 [0.737]
 [0.737]]
maxi score, test score, baseline:  -0.9929790190735696 -1.0 -0.9929790190735696
probs:  [1.0]
siam score:  -0.67781186
Printing some Q and Qe and total Qs values:  [[0.715]
 [0.652]
 [0.733]
 [0.72 ]
 [0.719]
 [0.728]
 [0.699]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.715]
 [0.652]
 [0.733]
 [0.72 ]
 [0.719]
 [0.728]
 [0.699]]
maxi score, test score, baseline:  -0.9929790190735696 -1.0 -0.9929790190735696
probs:  [1.0]
maxi score, test score, baseline:  -0.9929790190735696 -1.0 -0.9929790190735696
maxi score, test score, baseline:  -0.9929790190735696 -1.0 -0.9929790190735696
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.666]
 [0.662]
 [0.664]
 [0.658]
 [0.668]
 [0.669]
 [0.653]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.666]
 [0.662]
 [0.664]
 [0.658]
 [0.668]
 [0.669]
 [0.653]]
maxi score, test score, baseline:  -0.9929790190735696 -1.0 -0.9929790190735696
probs:  [1.0]
maxi score, test score, baseline:  -0.9929790190735696 -1.0 -0.9929790190735696
probs:  [1.0]
maxi score, test score, baseline:  -0.9930351351351352 -1.0 -0.9930351351351352
probs:  [1.0]
maxi score, test score, baseline:  -0.9930536388140163 -1.0 -0.9930536388140163
probs:  [1.0]
maxi score, test score, baseline:  -0.9930720430107528 -1.0 -0.9930720430107528
probs:  [1.0]
maxi score, test score, baseline:  -0.9930903485254693 -1.0 -0.9930903485254693
probs:  [1.0]
maxi score, test score, baseline:  -0.9931266666666668 -1.0 -0.9931266666666668
probs:  [1.0]
maxi score, test score, baseline:  -0.9931266666666668 -1.0 -0.9931266666666668
probs:  [1.0]
maxi score, test score, baseline:  -0.9931446808510639 -1.0 -0.9931446808510639
probs:  [1.0]
main train batch thing paused
add a thread
Adding thread: now have 6 threads
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9932157894736843 -1.0 -0.9932157894736843
probs:  [1.0]
maxi score, test score, baseline:  -0.9932157894736843 -1.0 -0.9932157894736843
probs:  [1.0]
maxi score, test score, baseline:  -0.9932333333333334 -1.0 -0.9932333333333334
maxi score, test score, baseline:  -0.9932333333333334 -1.0 -0.9932333333333334
probs:  [1.0]
maxi score, test score, baseline:  -0.9932333333333334 -1.0 -0.9932333333333334
maxi score, test score, baseline:  -0.9932333333333334 -1.0 -0.9932333333333334
probs:  [1.0]
maxi score, test score, baseline:  -0.9933025974025975 -1.0 -0.9933025974025975
probs:  [1.0]
maxi score, test score, baseline:  -0.9933025974025975 -1.0 -0.9933025974025975
probs:  [1.0]
siam score:  -0.7052443
maxi score, test score, baseline:  -0.9933025974025975 -1.0 -0.9933025974025975
probs:  [1.0]
maxi score, test score, baseline:  -0.9933366925064601 -1.0 -0.9933366925064601
maxi score, test score, baseline:  -0.9933366925064601 -1.0 -0.9933366925064601
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]]
maxi score, test score, baseline:  -0.9933871794871796 -1.0 -0.9933871794871796
probs:  [1.0]
maxi score, test score, baseline:  -0.9933871794871796 -1.0 -0.9933871794871796
maxi score, test score, baseline:  -0.9934368956743004 -1.0 -0.9934368956743004
probs:  [1.0]
maxi score, test score, baseline:  -0.9934368956743004 -1.0 -0.9934368956743004
probs:  [1.0]
maxi score, test score, baseline:  -0.9934368956743004 -1.0 -0.9934368956743004
probs:  [1.0]
maxi score, test score, baseline:  -0.9934368956743004 -1.0 -0.9934368956743004
probs:  [1.0]
maxi score, test score, baseline:  -0.9934368956743004 -1.0 -0.9934368956743004
probs:  [1.0]
maxi score, test score, baseline:  -0.9934368956743004 -1.0 -0.9934368956743004
probs:  [1.0]
maxi score, test score, baseline:  -0.9934368956743004 -1.0 -0.9934368956743004
probs:  [1.0]
maxi score, test score, baseline:  -0.9934532994923859 -1.0 -0.9934532994923859
maxi score, test score, baseline:  -0.9934532994923859 -1.0 -0.9934532994923859
probs:  [1.0]
maxi score, test score, baseline:  -0.9934532994923859 -1.0 -0.9934532994923859
probs:  [1.0]
maxi score, test score, baseline:  -0.9934696202531647 -1.0 -0.9934696202531647
probs:  [1.0]
maxi score, test score, baseline:  -0.9934858585858587 -1.0 -0.9934858585858587
probs:  [1.0]
maxi score, test score, baseline:  -0.9935180904522614 -1.0 -0.9935180904522614
probs:  [1.0]
maxi score, test score, baseline:  -0.9935340852130327 -1.0 -0.9935340852130327
probs:  [1.0]
maxi score, test score, baseline:  -0.9935340852130327 -1.0 -0.9935340852130327
maxi score, test score, baseline:  -0.9935340852130327 -1.0 -0.9935340852130327
maxi score, test score, baseline:  -0.9935340852130327 -1.0 -0.9935340852130327
probs:  [1.0]
maxi score, test score, baseline:  -0.9935500000000002 -1.0 -0.9935500000000002
probs:  [1.0]
maxi score, test score, baseline:  -0.9935658354114715 -1.0 -0.9935658354114715
probs:  [1.0]
maxi score, test score, baseline:  -0.9935658354114715 -1.0 -0.9935658354114715
probs:  [1.0]
maxi score, test score, baseline:  -0.9935658354114715 -1.0 -0.9935658354114715
probs:  [1.0]
maxi score, test score, baseline:  -0.9935658354114715 -1.0 -0.9935658354114715
maxi score, test score, baseline:  -0.9935658354114715 -1.0 -0.9935658354114715
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.723]
 [0.72 ]
 [0.75 ]
 [0.756]
 [0.804]
 [0.807]
 [0.772]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.723]
 [0.72 ]
 [0.75 ]
 [0.756]
 [0.804]
 [0.807]
 [0.772]]
maxi score, test score, baseline:  -0.9935815920398011 -1.0 -0.9935815920398011
probs:  [1.0]
maxi score, test score, baseline:  -0.9935815920398011 -1.0 -0.9935815920398011
probs:  [1.0]
maxi score, test score, baseline:  -0.9935815920398011 -1.0 -0.9935815920398011
probs:  [1.0]
maxi score, test score, baseline:  -0.9935815920398011 -1.0 -0.9935815920398011
probs:  [1.0]
maxi score, test score, baseline:  -0.9935972704714641 -1.0 -0.9935972704714641
probs:  [1.0]
maxi score, test score, baseline:  -0.9936128712871288 -1.0 -0.9936128712871288
probs:  [1.0]
maxi score, test score, baseline:  -0.9936438423645321 -1.0 -0.9936438423645321
probs:  [1.0]
maxi score, test score, baseline:  -0.9936438423645321 -1.0 -0.9936438423645321
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Starting evaluation
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.492]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.492]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]]
Printing some Q and Qe and total Qs values:  [[0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]]
Printing some Q and Qe and total Qs values:  [[-0.007]
 [ 0.204]
 [ 0.216]
 [ 0.433]
 [ 0.338]
 [ 0.157]
 [ 0.258]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.007]
 [ 0.204]
 [ 0.216]
 [ 0.433]
 [ 0.338]
 [ 0.157]
 [ 0.258]]
maxi score, test score, baseline:  -0.9936592137592138 -1.0 -0.9936592137592138
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.594]
 [0.561]
 [0.572]
 [0.59 ]
 [0.609]
 [0.621]
 [0.469]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.594]
 [0.561]
 [0.572]
 [0.59 ]
 [0.609]
 [0.621]
 [0.469]]
maxi score, test score, baseline:  -0.9936745098039217 -1.0 -0.9936745098039217
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]]
Printing some Q and Qe and total Qs values:  [[0.193]
 [0.329]
 [0.428]
 [0.487]
 [0.428]
 [0.428]
 [0.368]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.193]
 [0.329]
 [0.428]
 [0.487]
 [0.428]
 [0.428]
 [0.368]]
maxi score, test score, baseline:  -0.9936897310513448 -1.0 -0.9936897310513448
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.362]
 [0.362]
 [0.362]
 [0.362]
 [0.362]
 [0.362]
 [0.362]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.362]
 [0.362]
 [0.362]
 [0.362]
 [0.362]
 [0.362]
 [0.362]]
maxi score, test score, baseline:  -0.9937048780487806 -1.0 -0.9937048780487806
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.395]
 [0.387]
 [0.379]
 [0.376]
 [0.378]
 [0.378]
 [0.384]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.395]
 [0.387]
 [0.379]
 [0.376]
 [0.378]
 [0.378]
 [0.384]]
Printing some Q and Qe and total Qs values:  [[0.383]
 [0.372]
 [0.375]
 [0.375]
 [0.375]
 [0.38 ]
 [0.38 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.383]
 [0.372]
 [0.375]
 [0.375]
 [0.375]
 [0.38 ]
 [0.38 ]]
maxi score, test score, baseline:  -0.9937942307692309 -1.0 -0.9937942307692309
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]]
maxi score, test score, baseline:  -0.9938810426540285 -1.0 -0.9938810426540285
probs:  [1.0]
maxi score, test score, baseline:  -0.9938810426540285 -1.0 -0.9938810426540285
probs:  [1.0]
maxi score, test score, baseline:  -0.9938810426540285 -1.0 -0.9938810426540285
probs:  [1.0]
maxi score, test score, baseline:  -0.9938810426540285 -1.0 -0.9938810426540285
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.47 ]
 [0.468]
 [0.445]
 [0.447]
 [0.445]
 [0.445]
 [0.445]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.47 ]
 [0.468]
 [0.445]
 [0.447]
 [0.445]
 [0.445]
 [0.445]]
Printing some Q and Qe and total Qs values:  [[0.367]
 [0.358]
 [0.358]
 [0.361]
 [0.358]
 [0.358]
 [0.358]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.367]
 [0.358]
 [0.358]
 [0.361]
 [0.358]
 [0.358]
 [0.358]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9939930232558141 -1.0 -0.9939930232558141
probs:  [1.0]
siam score:  -0.72323346
maxi score, test score, baseline:  -0.9940474654377881 -1.0 -0.9940474654377881
probs:  [1.0]
maxi score, test score, baseline:  -0.9941141230068338 -1.0 -0.9941141230068338
probs:  [1.0]
maxi score, test score, baseline:  -0.9941272727272729 -1.0 -0.9941272727272729
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.271]
 [0.264]
 [0.273]
 [0.265]
 [0.263]
 [0.26 ]
 [0.277]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.271]
 [0.264]
 [0.273]
 [0.265]
 [0.263]
 [0.26 ]
 [0.277]]
maxi score, test score, baseline:  -0.9941663656884877 -1.0 -0.9941663656884877
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.316]
 [0.289]
 [0.285]
 [0.286]
 [0.299]
 [0.293]
 [0.298]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.316]
 [0.289]
 [0.285]
 [0.286]
 [0.299]
 [0.293]
 [0.298]]
Printing some Q and Qe and total Qs values:  [[0.1  ]
 [0.053]
 [0.085]
 [0.099]
 [0.094]
 [0.085]
 [0.074]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.1  ]
 [0.053]
 [0.085]
 [0.099]
 [0.094]
 [0.085]
 [0.074]]
maxi score, test score, baseline:  -0.9942805309734514 -1.0 -0.9942805309734514
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9944021645021646 -1.0 -0.9944021645021646
probs:  [1.0]
siam score:  -0.7976721
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  205000
maxi score, test score, baseline:  -0.9944610278372592 -1.0 -0.9944610278372592
maxi score, test score, baseline:  -0.9944610278372592 -1.0 -0.9944610278372592
STARTED EXPV TRAINING ON FRAME NO.  11176
maxi score, test score, baseline:  -0.9945186440677967 -1.0 -0.9945186440677967
deleting a thread, now have 5 threads
Frames:  11179 train batches done:  1309 episodes:  432
Printing some Q and Qe and total Qs values:  [[0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]]
maxi score, test score, baseline:  -0.9945526315789475 -1.0 -0.9945526315789475
probs:  [1.0]
maxi score, test score, baseline:  -0.9945750524109016 -1.0 -0.9945750524109016
probs:  [1.0]
maxi score, test score, baseline:  -0.9945750524109016 -1.0 -0.9945750524109016
siam score:  -0.7991238
maxi score, test score, baseline:  -0.9945861924686193 -1.0 -0.9945861924686193
probs:  [1.0]
maxi score, test score, baseline:  -0.9945861924686193 -1.0 -0.9945861924686193
probs:  [1.0]
maxi score, test score, baseline:  -0.9945861924686193 -1.0 -0.9945861924686193
maxi score, test score, baseline:  -0.9945861924686193 -1.0 -0.9945861924686193
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.353]
 [0.237]
 [0.139]
 [0.242]
 [0.246]
 [0.123]
 [0.24 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.353]
 [0.237]
 [0.139]
 [0.242]
 [0.246]
 [0.123]
 [0.24 ]]
maxi score, test score, baseline:  -0.9945972860125262 -1.0 -0.9945972860125262
probs:  [1.0]
maxi score, test score, baseline:  -0.9945972860125262 -1.0 -0.9945972860125262
maxi score, test score, baseline:  -0.9945972860125262 -1.0 -0.9945972860125262
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.33 ]
 [0.33 ]
 [0.332]
 [0.325]
 [0.307]
 [0.315]
 [0.323]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.33 ]
 [0.33 ]
 [0.332]
 [0.325]
 [0.307]
 [0.315]
 [0.323]]
maxi score, test score, baseline:  -0.9946083333333334 -1.0 -0.9946083333333334
probs:  [1.0]
maxi score, test score, baseline:  -0.9946302904564316 -1.0 -0.9946302904564316
probs:  [1.0]
siam score:  -0.82040316
maxi score, test score, baseline:  -0.9946843942505135 -1.0 -0.9946843942505135
maxi score, test score, baseline:  -0.9946843942505135 -1.0 -0.9946843942505135
siam score:  -0.83077234
maxi score, test score, baseline:  -0.9947057259713702 -1.0 -0.9947057259713702
maxi score, test score, baseline:  -0.9947163265306124 -1.0 -0.9947163265306124
probs:  [1.0]
maxi score, test score, baseline:  -0.9947163265306124 -1.0 -0.9947163265306124
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.84 ]
 [0.731]
 [0.796]
 [0.851]
 [0.731]
 [0.73 ]
 [0.729]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.84 ]
 [0.731]
 [0.796]
 [0.851]
 [0.731]
 [0.73 ]
 [0.729]]
maxi score, test score, baseline:  -0.9947373983739838 -1.0 -0.9947373983739838
Printing some Q and Qe and total Qs values:  [[0.377]
 [0.372]
 [0.397]
 [0.371]
 [0.397]
 [0.397]
 [0.397]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.377]
 [0.372]
 [0.397]
 [0.371]
 [0.397]
 [0.397]
 [0.397]]
Printing some Q and Qe and total Qs values:  [[0.84]
 [0.84]
 [0.84]
 [0.84]
 [0.84]
 [0.84]
 [0.84]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.84]
 [0.84]
 [0.84]
 [0.84]
 [0.84]
 [0.84]
 [0.84]]
siam score:  -0.8508554
maxi score, test score, baseline:  -0.9947582995951418 -1.0 -0.9947582995951418
maxi score, test score, baseline:  -0.9947582995951418 -1.0 -0.9947582995951418
probs:  [1.0]
maxi score, test score, baseline:  -0.9947995983935743 -1.0 -0.9947995983935743
probs:  [1.0]
siam score:  -0.85396177
maxi score, test score, baseline:  -0.9948098196392786 -1.0 -0.9948098196392786
probs:  [1.0]
maxi score, test score, baseline:  -0.99482 -1.0 -0.99482
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
Printing some Q and Qe and total Qs values:  [[-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
deleting a thread, now have 4 threads
Frames:  11846 train batches done:  1390 episodes:  470
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[ 0.004]
 [ 0.042]
 [ 0.007]
 [ 0.006]
 [-0.001]
 [ 0.01 ]
 [ 0.014]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.004]
 [ 0.042]
 [ 0.007]
 [ 0.006]
 [-0.001]
 [ 0.01 ]
 [ 0.014]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.86017936
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.86100787
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.525]
 [0.546]
 [0.534]
 [0.538]
 [0.548]
 [0.533]
 [0.529]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.525]
 [0.546]
 [0.534]
 [0.538]
 [0.548]
 [0.533]
 [0.529]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.8649303
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
Printing some Q and Qe and total Qs values:  [[0.057]
 [0.094]
 [0.06 ]
 [0.058]
 [0.059]
 [0.062]
 [0.062]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.057]
 [0.094]
 [0.06 ]
 [0.058]
 [0.059]
 [0.062]
 [0.062]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.118]
 [0.183]
 [0.119]
 [0.109]
 [0.119]
 [0.119]
 [0.119]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.118]
 [0.183]
 [0.119]
 [0.109]
 [0.119]
 [0.119]
 [0.119]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.347 0.143 0.122 0.184 0.102 0.041 0.061]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.54 ]
 [0.598]
 [0.54 ]
 [0.54 ]
 [0.54 ]
 [0.54 ]
 [0.54 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.54 ]
 [0.598]
 [0.54 ]
 [0.54 ]
 [0.54 ]
 [0.54 ]
 [0.54 ]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
deleting a thread, now have 3 threads
Frames:  13457 train batches done:  1573 episodes:  544
siam score:  -0.857242
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.242]
 [0.273]
 [0.273]
 [0.244]
 [0.244]
 [0.273]
 [0.273]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.242]
 [0.273]
 [0.273]
 [0.244]
 [0.244]
 [0.273]
 [0.273]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.85673994
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.121]
 [0.112]
 [0.104]
 [0.107]
 [0.116]
 [0.104]
 [0.104]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.121]
 [0.112]
 [0.104]
 [0.107]
 [0.116]
 [0.104]
 [0.104]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
Printing some Q and Qe and total Qs values:  [[0.135]
 [0.141]
 [0.132]
 [0.133]
 [0.132]
 [0.132]
 [0.132]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.135]
 [0.141]
 [0.132]
 [0.133]
 [0.132]
 [0.132]
 [0.132]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.184 0.122 0.102 0.184 0.102 0.224 0.082]
Printing some Q and Qe and total Qs values:  [[0.338]
 [0.333]
 [0.306]
 [0.304]
 [0.306]
 [0.306]
 [0.306]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.338]
 [0.333]
 [0.306]
 [0.304]
 [0.306]
 [0.306]
 [0.306]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.151]
 [0.174]
 [0.151]
 [0.15 ]
 [0.163]
 [0.151]
 [0.151]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.151]
 [0.174]
 [0.151]
 [0.15 ]
 [0.163]
 [0.151]
 [0.151]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.8552695
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.216]
 [0.203]
 [0.205]
 [0.222]
 [0.232]
 [0.28 ]
 [0.188]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.216]
 [0.203]
 [0.205]
 [0.222]
 [0.232]
 [0.28 ]
 [0.188]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.131]
 [0.124]
 [0.14 ]
 [0.137]
 [0.135]
 [0.128]
 [0.122]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.131]
 [0.124]
 [0.14 ]
 [0.137]
 [0.135]
 [0.128]
 [0.122]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.324]
 [0.324]
 [0.324]
 [0.314]
 [0.324]
 [0.324]
 [0.324]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.324]
 [0.324]
 [0.324]
 [0.314]
 [0.324]
 [0.324]
 [0.324]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.8639542
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.8525984
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.599]
 [0.609]
 [0.592]
 [0.603]
 [0.608]
 [0.603]
 [0.599]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.599]
 [0.609]
 [0.592]
 [0.603]
 [0.608]
 [0.603]
 [0.599]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.847146
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.347]
 [0.375]
 [0.381]
 [0.341]
 [0.344]
 [0.325]
 [0.328]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.347]
 [0.375]
 [0.381]
 [0.341]
 [0.344]
 [0.325]
 [0.328]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.84356856
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.8348288
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.643]
 [0.617]
 [0.593]
 [0.617]
 [0.617]
 [0.617]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.617]
 [0.643]
 [0.617]
 [0.593]
 [0.617]
 [0.617]
 [0.617]]
siam score:  -0.83233446
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.409]
 [0.406]
 [0.416]
 [0.415]
 [0.414]
 [0.416]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.422]
 [0.409]
 [0.406]
 [0.416]
 [0.415]
 [0.414]
 [0.416]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
Printing some Q and Qe and total Qs values:  [[0.29]
 [0.29]
 [0.29]
 [0.29]
 [0.29]
 [0.29]
 [0.29]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.29]
 [0.29]
 [0.29]
 [0.29]
 [0.29]
 [0.29]
 [0.29]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
siam score:  -0.8341102
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.585]
 [0.595]
 [0.579]
 [0.544]
 [0.556]
 [0.594]
 [0.589]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.585]
 [0.595]
 [0.579]
 [0.544]
 [0.556]
 [0.594]
 [0.589]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.622]
 [0.649]
 [0.65 ]
 [0.636]
 [0.65 ]
 [0.646]
 [0.65 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.622]
 [0.649]
 [0.65 ]
 [0.636]
 [0.65 ]
 [0.646]
 [0.65 ]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.808]
 [0.717]
 [0.769]
 [0.8  ]
 [0.372]
 [0.372]
 [0.57 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.808]
 [0.717]
 [0.769]
 [0.8  ]
 [0.372]
 [0.372]
 [0.57 ]]
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99682 -1.0 -0.99682
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.8497061
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.315]
 [0.318]
 [0.31 ]
 [0.313]
 [0.312]
 [0.312]
 [0.311]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.315]
 [0.318]
 [0.31 ]
 [0.313]
 [0.312]
 [0.312]
 [0.311]]
siam score:  -0.85255384
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.645]
 [0.647]
 [0.627]
 [0.609]
 [0.611]
 [0.632]
 [0.632]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.645]
 [0.647]
 [0.627]
 [0.609]
 [0.611]
 [0.632]
 [0.632]]
Printing some Q and Qe and total Qs values:  [[0.646]
 [0.652]
 [0.634]
 [0.613]
 [0.619]
 [0.629]
 [0.634]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.646]
 [0.652]
 [0.634]
 [0.613]
 [0.619]
 [0.629]
 [0.634]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
siam score:  -0.84901464
Printing some Q and Qe and total Qs values:  [[0.183]
 [0.203]
 [0.179]
 [0.182]
 [0.182]
 [0.183]
 [0.181]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.183]
 [0.203]
 [0.179]
 [0.182]
 [0.182]
 [0.183]
 [0.181]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
siam score:  -0.850772
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.497]
 [0.22 ]
 [0.661]
 [0.671]
 [0.553]
 [0.493]
 [0.71 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.497]
 [0.22 ]
 [0.661]
 [0.671]
 [0.553]
 [0.493]
 [0.71 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.556]
 [0.558]
 [0.606]
 [0.59 ]
 [0.555]
 [0.53 ]
 [0.555]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.556]
 [0.558]
 [0.606]
 [0.59 ]
 [0.555]
 [0.53 ]
 [0.555]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.352]
 [0.372]
 [0.346]
 [0.326]
 [0.346]
 [0.346]
 [0.346]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.352]
 [0.372]
 [0.346]
 [0.326]
 [0.346]
 [0.346]
 [0.346]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.552]
 [0.539]
 [0.571]
 [0.566]
 [0.5  ]
 [0.5  ]
 [0.5  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.552]
 [0.539]
 [0.571]
 [0.566]
 [0.5  ]
 [0.5  ]
 [0.5  ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
siam score:  -0.84458953
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.656]
 [0.528]
 [0.634]
 [0.649]
 [0.638]
 [0.627]
 [0.625]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.656]
 [0.528]
 [0.634]
 [0.649]
 [0.638]
 [0.627]
 [0.625]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.624]
 [0.626]
 [0.644]
 [0.642]
 [0.655]
 [0.683]
 [0.698]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.624]
 [0.626]
 [0.644]
 [0.642]
 [0.655]
 [0.683]
 [0.698]]
siam score:  -0.84694046
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
siam score:  -0.85075057
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
siam score:  -0.8486481
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.564]
 [0.549]
 [0.549]
 [0.563]
 [0.549]
 [0.549]
 [0.549]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.564]
 [0.549]
 [0.549]
 [0.563]
 [0.549]
 [0.549]
 [0.549]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
actor:  0 policy actor:  0  step number:  57 total reward:  0.11999999999999944  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.16]
 [0.16]
 [0.16]
 [0.16]
 [0.16]
 [0.16]
 [0.16]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.16]
 [0.16]
 [0.16]
 [0.16]
 [0.16]
 [0.16]
 [0.16]]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.133]
 [0.137]
 [0.137]
 [0.135]
 [0.136]
 [0.138]
 [0.141]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.133]
 [0.137]
 [0.137]
 [0.135]
 [0.136]
 [0.138]
 [0.141]]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.256]
 [0.313]
 [0.261]
 [0.266]
 [0.263]
 [0.269]
 [0.274]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.256]
 [0.313]
 [0.261]
 [0.266]
 [0.263]
 [0.269]
 [0.274]]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.097]
 [0.097]
 [0.097]
 [0.097]
 [0.097]
 [0.097]
 [0.097]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.097]
 [0.097]
 [0.097]
 [0.097]
 [0.097]
 [0.097]
 [0.097]]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]] [[0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]] [[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.435]
 [0.467]
 [0.431]
 [0.447]
 [0.435]
 [0.435]
 [0.436]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.435]
 [0.467]
 [0.431]
 [0.447]
 [0.435]
 [0.435]
 [0.436]]
Printing some Q and Qe and total Qs values:  [[0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]]
maxi score, test score, baseline:  -0.99766 -1.0 -0.99766
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9948400000000001 -1.0 -0.9948400000000001
actor:  0 policy actor:  0  step number:  41 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.99244 -1.0 -0.99244
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.146]
 [0.167]
 [0.149]
 [0.144]
 [0.145]
 [0.145]
 [0.153]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.146]
 [0.167]
 [0.149]
 [0.144]
 [0.145]
 [0.145]
 [0.153]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.153]
 [0.153]
 [0.153]
 [0.153]
 [0.153]
 [0.153]
 [0.153]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.153]
 [0.153]
 [0.153]
 [0.153]
 [0.153]
 [0.153]
 [0.153]]
siam score:  -0.8501726
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
Printing some Q and Qe and total Qs values:  [[0.58 ]
 [0.559]
 [0.553]
 [0.571]
 [0.577]
 [0.588]
 [0.584]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.58 ]
 [0.559]
 [0.553]
 [0.571]
 [0.577]
 [0.588]
 [0.584]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.164]
 [0.164]
 [0.164]
 [0.163]
 [0.164]
 [0.164]
 [0.164]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.164]
 [0.164]
 [0.164]
 [0.163]
 [0.164]
 [0.164]
 [0.164]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.042]
 [0.042]
 [0.042]
 [0.044]
 [0.042]
 [0.042]
 [0.042]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.042]
 [0.042]
 [0.042]
 [0.044]
 [0.042]
 [0.042]
 [0.042]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.84660506
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.285]
 [0.285]
 [0.285]
 [0.285]
 [0.285]
 [0.285]
 [0.285]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.285]
 [0.285]
 [0.285]
 [0.285]
 [0.285]
 [0.285]
 [0.285]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
Printing some Q and Qe and total Qs values:  [[0.308]
 [0.341]
 [0.317]
 [0.317]
 [0.313]
 [0.311]
 [0.31 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.308]
 [0.341]
 [0.317]
 [0.317]
 [0.313]
 [0.311]
 [0.31 ]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.679]
 [0.718]
 [0.693]
 [0.692]
 [0.707]
 [0.693]
 [0.693]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.679]
 [0.718]
 [0.693]
 [0.692]
 [0.707]
 [0.693]
 [0.693]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.849851
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.119]
 [0.139]
 [0.12 ]
 [0.12 ]
 [0.12 ]
 [0.118]
 [0.119]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.119]
 [0.139]
 [0.12 ]
 [0.12 ]
 [0.12 ]
 [0.118]
 [0.119]]
Printing some Q and Qe and total Qs values:  [[0.388]
 [0.446]
 [0.41 ]
 [0.397]
 [0.39 ]
 [0.39 ]
 [0.381]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.388]
 [0.446]
 [0.41 ]
 [0.397]
 [0.39 ]
 [0.39 ]
 [0.381]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.84403837
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.8438295
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[ 0.075]
 [-0.009]
 [ 0.093]
 [ 0.096]
 [ 0.101]
 [ 0.091]
 [ 0.107]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.075]
 [-0.009]
 [ 0.093]
 [ 0.096]
 [ 0.101]
 [ 0.091]
 [ 0.107]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.375]
 [0.406]
 [0.376]
 [0.373]
 [0.372]
 [0.376]
 [0.376]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.375]
 [0.406]
 [0.376]
 [0.373]
 [0.372]
 [0.376]
 [0.376]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.535]
 [0.489]
 [0.464]
 [0.486]
 [0.469]
 [0.48 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.467]
 [0.535]
 [0.489]
 [0.464]
 [0.486]
 [0.469]
 [0.48 ]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.066]
 [0.066]
 [0.066]
 [0.066]
 [0.066]
 [0.066]
 [0.066]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.066]
 [0.066]
 [0.066]
 [0.066]
 [0.066]
 [0.066]
 [0.066]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.8336926
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.323]
 [0.414]
 [0.323]
 [0.323]
 [0.323]
 [0.323]
 [0.323]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.323]
 [0.414]
 [0.323]
 [0.323]
 [0.323]
 [0.323]
 [0.323]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.8428393
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[ 0.067]
 [ 0.159]
 [-0.009]
 [ 0.137]
 [ 0.13 ]
 [ 0.011]
 [ 0.157]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.067]
 [ 0.159]
 [-0.009]
 [ 0.137]
 [ 0.13 ]
 [ 0.011]
 [ 0.157]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
Printing some Q and Qe and total Qs values:  [[ 0.101]
 [ 0.137]
 [-0.003]
 [ 0.133]
 [ 0.12 ]
 [ 0.028]
 [ 0.131]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.101]
 [ 0.137]
 [-0.003]
 [ 0.133]
 [ 0.12 ]
 [ 0.028]
 [ 0.131]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.592]
 [0.568]
 [0.561]
 [0.558]
 [0.573]
 [0.575]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.566]
 [0.592]
 [0.568]
 [0.561]
 [0.558]
 [0.573]
 [0.575]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.142]
 [0.177]
 [0.137]
 [0.139]
 [0.147]
 [0.139]
 [0.147]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.142]
 [0.177]
 [0.137]
 [0.139]
 [0.147]
 [0.139]
 [0.147]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.399]
 [0.123]
 [0.123]
 [0.123]
 [0.123]
 [0.123]
 [0.123]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.399]
 [0.123]
 [0.123]
 [0.123]
 [0.123]
 [0.123]
 [0.123]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.498]
 [0.567]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.498]
 [0.567]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]]
siam score:  -0.8378225
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.104]
 [0.122]
 [0.103]
 [0.101]
 [0.101]
 [0.106]
 [0.108]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.104]
 [0.122]
 [0.103]
 [0.101]
 [0.101]
 [0.106]
 [0.108]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
Printing some Q and Qe and total Qs values:  [[ 0.041]
 [-0.006]
 [ 0.042]
 [ 0.041]
 [ 0.041]
 [ 0.024]
 [ 0.024]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.041]
 [-0.006]
 [ 0.042]
 [ 0.041]
 [ 0.041]
 [ 0.024]
 [ 0.024]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.135]
 [0.182]
 [0.136]
 [0.129]
 [0.129]
 [0.131]
 [0.133]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.135]
 [0.182]
 [0.136]
 [0.129]
 [0.129]
 [0.131]
 [0.133]]
Printing some Q and Qe and total Qs values:  [[0.68 ]
 [0.693]
 [0.68 ]
 [0.685]
 [0.68 ]
 [0.68 ]
 [0.68 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.68 ]
 [0.693]
 [0.68 ]
 [0.685]
 [0.68 ]
 [0.68 ]
 [0.68 ]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.189]
 [0.215]
 [0.185]
 [0.182]
 [0.185]
 [0.185]
 [0.185]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.189]
 [0.215]
 [0.185]
 [0.182]
 [0.185]
 [0.185]
 [0.185]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
siam score:  -0.84204817
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
siam score:  -0.8432362
Printing some Q and Qe and total Qs values:  [[0.619]
 [0.656]
 [0.619]
 [0.63 ]
 [0.619]
 [0.619]
 [0.619]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.619]
 [0.656]
 [0.619]
 [0.63 ]
 [0.619]
 [0.619]
 [0.619]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.05 ]
 [0.044]
 [0.144]
 [0.067]
 [0.144]
 [0.046]
 [0.144]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.05 ]
 [0.044]
 [0.144]
 [0.067]
 [0.144]
 [0.046]
 [0.144]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.219]
 [0.249]
 [0.19 ]
 [0.192]
 [0.19 ]
 [0.19 ]
 [0.201]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.219]
 [0.249]
 [0.19 ]
 [0.192]
 [0.19 ]
 [0.19 ]
 [0.201]]
UNIT TEST: sample policy line 217 mcts : [0.143 0.184 0.061 0.327 0.061 0.061 0.163]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.8278027
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.8327978
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.83857363
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.6177],
        [-0.0000],
        [-0.3884],
        [-0.0000],
        [-0.7088],
        [-0.7129],
        [-0.0000],
        [-0.0000],
        [-0.5147],
        [-0.5644]], dtype=torch.float64)
-0.048519850599000006 -0.6662677957895986
-0.8459105984999999 -0.8459105984999999
-0.145559551797 -0.533986302625077
-0.9234306965069998 -0.9234306965069998
-0.048519850599000006 -0.7572843331443833
-0.048519850599000006 -0.7614128224525406
-0.8415 -0.8415
-0.8949009950099999 -0.8949009950099999
-0.048519850599000006 -0.5631986118232284
-0.125759551797 -0.6901353676334168
siam score:  -0.8343797
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.8362286
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[ 0.21 ]
 [ 0.208]
 [ 0.061]
 [ 0.19 ]
 [ 0.215]
 [-0.006]
 [ 0.143]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.21 ]
 [ 0.208]
 [ 0.061]
 [ 0.19 ]
 [ 0.215]
 [-0.006]
 [ 0.143]]
siam score:  -0.83193225
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.626]
 [0.68 ]
 [0.635]
 [0.639]
 [0.651]
 [0.656]
 [0.654]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.626]
 [0.68 ]
 [0.635]
 [0.639]
 [0.651]
 [0.656]
 [0.654]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.8431906
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.143 0.082 0.102 0.184 0.184 0.082 0.224]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.84273756
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.667]
 [0.715]
 [0.667]
 [0.687]
 [0.667]
 [0.667]
 [0.667]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.667]
 [0.715]
 [0.667]
 [0.687]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.8488979
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.84861326
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.152]
 [0.152]
 [0.152]
 [0.13 ]
 [0.152]
 [0.152]
 [0.152]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.152]
 [0.152]
 [0.152]
 [0.13 ]
 [0.152]
 [0.152]
 [0.152]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.154]
 [0.154]
 [0.154]
 [0.154]
 [0.154]
 [0.158]
 [0.154]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.154]
 [0.154]
 [0.154]
 [0.154]
 [0.154]
 [0.158]
 [0.154]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
Printing some Q and Qe and total Qs values:  [[0.061]
 [0.067]
 [0.073]
 [0.069]
 [0.068]
 [0.068]
 [0.07 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.061]
 [0.067]
 [0.073]
 [0.069]
 [0.068]
 [0.068]
 [0.07 ]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.143]
 [0.143]
 [0.143]
 [0.171]
 [0.143]
 [0.143]
 [0.143]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.143]
 [0.143]
 [0.143]
 [0.171]
 [0.143]
 [0.143]
 [0.143]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.124]
 [0.124]
 [0.124]
 [0.124]
 [0.124]
 [0.124]
 [0.124]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.124]
 [0.124]
 [0.124]
 [0.124]
 [0.124]
 [0.124]
 [0.124]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.84175473
Printing some Q and Qe and total Qs values:  [[0.168]
 [0.222]
 [0.184]
 [0.173]
 [0.192]
 [0.192]
 [0.197]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.168]
 [0.222]
 [0.184]
 [0.173]
 [0.192]
 [0.192]
 [0.197]]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
siam score:  -0.8370721
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.8346775
siam score:  -0.83771515
maxi score, test score, baseline:  -0.99244 -0.8695 -0.8695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  46 total reward:  0.02999999999999947  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
Printing some Q and Qe and total Qs values:  [[ 0.102]
 [ 0.13 ]
 [-0.009]
 [ 0.096]
 [ 0.09 ]
 [-0.002]
 [ 0.115]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.102]
 [ 0.13 ]
 [-0.009]
 [ 0.096]
 [ 0.09 ]
 [-0.002]
 [ 0.115]]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.8269974
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.8278943
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.154]
 [0.174]
 [0.144]
 [0.144]
 [0.143]
 [0.148]
 [0.151]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.154]
 [0.174]
 [0.144]
 [0.144]
 [0.143]
 [0.148]
 [0.151]]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
maxi score, test score, baseline:  -0.99038 -0.8695 -0.8695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.529]
 [0.403]
 [0.687]
 [0.431]
 [0.429]
 [0.429]
 [0.429]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.529]
 [0.403]
 [0.687]
 [0.431]
 [0.429]
 [0.429]
 [0.429]]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [0.856]
 [0.863]
 [0.866]
 [0.827]
 [0.827]
 [0.827]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.88 ]
 [0.856]
 [0.863]
 [0.866]
 [0.827]
 [0.827]
 [0.827]]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.15 ]
 [0.188]
 [0.15 ]
 [0.15 ]
 [0.15 ]
 [0.15 ]
 [0.15 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.15 ]
 [0.188]
 [0.15 ]
 [0.15 ]
 [0.15 ]
 [0.15 ]
 [0.15 ]]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.545]
 [0.58 ]
 [0.545]
 [0.579]
 [0.545]
 [0.545]
 [0.545]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.545]
 [0.58 ]
 [0.545]
 [0.579]
 [0.545]
 [0.545]
 [0.545]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
Printing some Q and Qe and total Qs values:  [[0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.9877199999999999 -0.8695 -0.8695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.98514 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.98514 -0.8695 -0.8695
maxi score, test score, baseline:  -0.98514 -0.8695 -0.8695
probs:  [1.0]
maxi score, test score, baseline:  -0.98514 -0.8695 -0.8695
probs:  [1.0]
siam score:  -0.84168077
siam score:  -0.8438451
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.499]
 [0.542]
 [0.518]
 [0.517]
 [0.525]
 [0.522]
 [0.507]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.499]
 [0.542]
 [0.518]
 [0.517]
 [0.525]
 [0.522]
 [0.507]]
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.105]
 [0.134]
 [0.104]
 [0.102]
 [0.102]
 [0.105]
 [0.103]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.105]
 [0.134]
 [0.104]
 [0.102]
 [0.102]
 [0.105]
 [0.103]]
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.8383266
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.129]
 [0.187]
 [0.169]
 [0.215]
 [0.085]
 [0.201]
 [0.188]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.129]
 [0.187]
 [0.169]
 [0.215]
 [0.085]
 [0.201]
 [0.188]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.98514 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.83945376
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.8352231
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.11 ]
 [0.126]
 [0.102]
 [0.1  ]
 [0.097]
 [0.099]
 [0.107]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.11 ]
 [0.126]
 [0.102]
 [0.1  ]
 [0.097]
 [0.099]
 [0.107]]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]]
siam score:  -0.84154165
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.282]
 [0.293]
 [0.29 ]
 [0.289]
 [0.29 ]
 [0.29 ]
 [0.29 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.282]
 [0.293]
 [0.29 ]
 [0.289]
 [0.29 ]
 [0.29 ]
 [0.29 ]]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
siam score:  -0.84163886
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.599]
 [0.627]
 [0.617]
 [0.608]
 [0.591]
 [0.591]
 [0.591]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.599]
 [0.627]
 [0.617]
 [0.608]
 [0.591]
 [0.591]
 [0.591]]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.392]
 [0.392]
 [0.392]
 [0.346]
 [0.392]
 [0.392]
 [0.392]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.392]
 [0.392]
 [0.392]
 [0.346]
 [0.392]
 [0.392]
 [0.392]]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.8356297
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]]
Printing some Q and Qe and total Qs values:  [[0.665]
 [0.683]
 [0.721]
 [0.653]
 [0.686]
 [0.71 ]
 [0.707]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.665]
 [0.683]
 [0.721]
 [0.653]
 [0.686]
 [0.71 ]
 [0.707]]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.8446663
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98738 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.8407452
maxi score, test score, baseline:  -0.9902000000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9902000000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9902000000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9902000000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.84242934
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.84180176
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.041]
 [0.027]
 [0.029]
 [0.029]
 [0.03 ]
 [0.031]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.031]
 [0.041]
 [0.027]
 [0.029]
 [0.029]
 [0.03 ]
 [0.031]]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9926 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.85089195
siam score:  -0.85029066
actor:  0 policy actor:  0  step number:  44 total reward:  0.12999999999999945  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.677]
 [0.664]
 [0.736]
 [0.633]
 [0.727]
 [0.736]
 [0.736]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.677]
 [0.664]
 [0.736]
 [0.633]
 [0.727]
 [0.736]
 [0.736]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.36 ]
 [0.369]
 [0.355]
 [0.351]
 [0.349]
 [0.345]
 [0.355]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.36 ]
 [0.369]
 [0.355]
 [0.351]
 [0.349]
 [0.345]
 [0.355]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.8324318
Printing some Q and Qe and total Qs values:  [[0.134]
 [0.166]
 [0.148]
 [0.131]
 [0.133]
 [0.132]
 [0.136]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.134]
 [0.166]
 [0.148]
 [0.131]
 [0.133]
 [0.132]
 [0.136]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.616]
 [0.559]
 [0.579]
 [0.567]
 [0.568]
 [0.548]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.571]
 [0.616]
 [0.559]
 [0.579]
 [0.567]
 [0.568]
 [0.548]]
siam score:  -0.8476648
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.339]
 [0.189]
 [0.355]
 [0.376]
 [0.348]
 [0.187]
 [0.263]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.339]
 [0.189]
 [0.355]
 [0.376]
 [0.348]
 [0.187]
 [0.263]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.432]
 [0.531]
 [0.451]
 [0.423]
 [0.472]
 [0.422]
 [0.419]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.432]
 [0.531]
 [0.451]
 [0.423]
 [0.472]
 [0.422]
 [0.419]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.84364074
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
Printing some Q and Qe and total Qs values:  [[0.222]
 [0.615]
 [0.24 ]
 [0.693]
 [0.24 ]
 [0.24 ]
 [0.24 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.222]
 [0.615]
 [0.24 ]
 [0.693]
 [0.24 ]
 [0.24 ]
 [0.24 ]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.523]
 [0.523]
 [0.523]
 [0.523]
 [0.523]
 [0.523]
 [0.523]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.523]
 [0.523]
 [0.523]
 [0.523]
 [0.523]
 [0.523]
 [0.523]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.434]
 [0.542]
 [0.438]
 [0.433]
 [0.514]
 [0.514]
 [0.427]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.434]
 [0.542]
 [0.438]
 [0.433]
 [0.514]
 [0.514]
 [0.427]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.116]
 [0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.116]
 [0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]]
Printing some Q and Qe and total Qs values:  [[0.816]
 [0.835]
 [0.806]
 [0.803]
 [0.847]
 [0.823]
 [0.823]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.816]
 [0.835]
 [0.806]
 [0.803]
 [0.847]
 [0.823]
 [0.823]]
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.538]
 [0.538]
 [0.538]
 [0.538]
 [0.538]
 [0.538]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.718]
 [0.538]
 [0.538]
 [0.538]
 [0.538]
 [0.538]
 [0.538]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.1  ]
 [0.117]
 [0.149]
 [0.152]
 [0.198]
 [0.144]
 [0.147]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.1  ]
 [0.117]
 [0.149]
 [0.152]
 [0.198]
 [0.144]
 [0.147]]
Printing some Q and Qe and total Qs values:  [[0.192]
 [0.192]
 [0.192]
 [0.088]
 [0.192]
 [0.192]
 [0.192]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.192]
 [0.192]
 [0.192]
 [0.088]
 [0.192]
 [0.192]
 [0.192]]
maxi score, test score, baseline:  -0.9903400000000001 -0.9355 -0.9355
actor:  0 policy actor:  0  step number:  66 total reward:  0.02999999999999936  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.267]
 [0.267]
 [0.267]
 [0.267]
 [0.267]
 [0.267]
 [0.267]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.267]
 [0.267]
 [0.267]
 [0.267]
 [0.267]
 [0.267]
 [0.267]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.83749664
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.8375253
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.84359497
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.574]
 [0.623]
 [0.58 ]
 [0.58 ]
 [0.58 ]
 [0.58 ]
 [0.58 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.574]
 [0.623]
 [0.58 ]
 [0.58 ]
 [0.58 ]
 [0.58 ]
 [0.58 ]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.185]
 [0.278]
 [0.185]
 [0.185]
 [0.185]
 [0.185]
 [0.185]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.185]
 [0.278]
 [0.185]
 [0.185]
 [0.185]
 [0.185]
 [0.185]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.845719
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.148]
 [0.155]
 [0.146]
 [0.143]
 [0.143]
 [0.144]
 [0.149]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.148]
 [0.155]
 [0.146]
 [0.143]
 [0.143]
 [0.144]
 [0.149]]
Printing some Q and Qe and total Qs values:  [[0.151]
 [0.162]
 [0.17 ]
 [0.119]
 [0.108]
 [0.113]
 [0.118]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.151]
 [0.162]
 [0.17 ]
 [0.119]
 [0.108]
 [0.113]
 [0.118]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.618]
 [0.673]
 [0.618]
 [0.618]
 [0.618]
 [0.618]
 [0.618]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.618]
 [0.673]
 [0.618]
 [0.618]
 [0.618]
 [0.618]
 [0.618]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.809]
 [0.47 ]
 [0.47 ]
 [0.787]
 [0.47 ]
 [0.47 ]
 [0.47 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.809]
 [0.47 ]
 [0.47 ]
 [0.787]
 [0.47 ]
 [0.47 ]
 [0.47 ]]
siam score:  -0.83777535
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.667]
 [0.747]
 [0.738]
 [0.712]
 [0.738]
 [0.738]
 [0.738]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.667]
 [0.747]
 [0.738]
 [0.712]
 [0.738]
 [0.738]
 [0.738]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.598]
 [0.702]
 [0.624]
 [0.659]
 [0.682]
 [0.682]
 [0.615]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.598]
 [0.702]
 [0.624]
 [0.659]
 [0.682]
 [0.682]
 [0.615]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.84030473
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.61 ]
 [0.626]
 [0.582]
 [0.583]
 [0.582]
 [0.582]
 [0.582]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.61 ]
 [0.626]
 [0.582]
 [0.583]
 [0.582]
 [0.582]
 [0.582]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.552]
 [0.599]
 [0.554]
 [0.55 ]
 [0.552]
 [0.552]
 [0.552]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.552]
 [0.599]
 [0.554]
 [0.55 ]
 [0.552]
 [0.552]
 [0.552]]
Printing some Q and Qe and total Qs values:  [[0.257]
 [0.255]
 [0.255]
 [0.259]
 [0.256]
 [0.255]
 [0.255]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.257]
 [0.255]
 [0.255]
 [0.259]
 [0.256]
 [0.255]
 [0.255]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
siam score:  -0.83337367
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.914]
 [0.773]
 [0.906]
 [0.9  ]
 [0.914]
 [0.907]
 [0.865]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.914]
 [0.773]
 [0.906]
 [0.9  ]
 [0.914]
 [0.907]
 [0.865]]
maxi score, test score, baseline:  -0.98828 -0.9355 -0.9355
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.469]
 [0.553]
 [0.48 ]
 [0.492]
 [0.458]
 [0.472]
 [0.47 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.469]
 [0.553]
 [0.48 ]
 [0.492]
 [0.458]
 [0.472]
 [0.47 ]]
siam score:  -0.83455217
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.8345964
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.8274206
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
siam score:  -0.830611
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
siam score:  -0.8331955
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.98596 -0.9355 -0.9355
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
siam score:  -0.8364512
Printing some Q and Qe and total Qs values:  [[0.3  ]
 [0.348]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.3  ]
 [0.348]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9859600000000001 -0.9355 -0.9355
probs:  [1.0]
actor:  0 policy actor:  0  step number:  48 total reward:  0.12999999999999945  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9837000000000001 -0.9355 -0.9355
maxi score, test score, baseline:  -0.9837000000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9837000000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.542]
 [0.623]
 [0.577]
 [0.558]
 [0.573]
 [0.564]
 [0.548]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.542]
 [0.623]
 [0.577]
 [0.558]
 [0.573]
 [0.564]
 [0.548]]
maxi score, test score, baseline:  -0.9837000000000001 -0.9355 -0.9355
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.9837000000000001 -0.9355 -0.9355
probs:  [1.0]
Starting evaluation
maxi score, test score, baseline:  -0.9837000000000001 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.099]
 [0.099]
 [0.099]
 [0.099]
 [0.099]
 [0.099]
 [0.099]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.099]
 [0.099]
 [0.099]
 [0.099]
 [0.099]
 [0.099]
 [0.099]]
maxi score, test score, baseline:  -0.9837000000000001 -0.9355 -0.9355
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9837 -0.9355 -0.9355
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.172]
 [0.177]
 [0.329]
 [0.264]
 [0.259]
 [0.251]
 [0.187]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.172]
 [0.177]
 [0.329]
 [0.264]
 [0.259]
 [0.251]
 [0.187]]
maxi score, test score, baseline:  -0.9837 -0.9355 -0.9355
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  40 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.872]
 [0.728]
 [0.759]
 [0.708]
 [0.662]
 [0.795]
 [0.68 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.872]
 [0.728]
 [0.759]
 [0.708]
 [0.662]
 [0.795]
 [0.68 ]]
maxi score, test score, baseline:  -0.9810800000000001 -0.9355 -0.9355
Printing some Q and Qe and total Qs values:  [[0.835]
 [0.75 ]
 [0.718]
 [0.643]
 [0.662]
 [0.803]
 [0.68 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.835]
 [0.75 ]
 [0.718]
 [0.643]
 [0.662]
 [0.803]
 [0.68 ]]
maxi score, test score, baseline:  -0.9810800000000001 -0.9355 -0.9355
probs:  [1.0]
maxi score, test score, baseline:  -0.9810800000000001 -0.9355 -0.9355
probs:  [1.0]
actor:  0 policy actor:  0  step number:  76 total reward:  0.08999999999999952  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.6116],
        [-0.7248],
        [-0.6812],
        [-0.7232],
        [-0.3707],
        [-0.5196],
        [-0.6288],
        [-0.6307],
        [-0.0000],
        [-0.0000]], dtype=torch.float64)
-0.048519850599000006 -0.6600966663410234
-0.048519850599000006 -0.7732957501497276
-0.048519850599000006 -0.7297581113076713
-0.048519850599000006 -0.7716824155298362
-0.145559551797 -0.5162737704886587
-0.145559551797 -0.665137360391336
-0.048519850599000006 -0.6773161269248483
-0.08675157179700001 -0.7174072038996254
-0.8811 -0.8811
-0.693 -0.693
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.43]
 [0.52]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.43]
 [0.52]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
Printing some Q and Qe and total Qs values:  [[0.576]
 [0.645]
 [0.583]
 [0.598]
 [0.583]
 [0.583]
 [0.583]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.576]
 [0.645]
 [0.583]
 [0.598]
 [0.583]
 [0.583]
 [0.583]]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.152]
 [0.182]
 [0.152]
 [0.149]
 [0.151]
 [0.151]
 [0.154]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.152]
 [0.182]
 [0.152]
 [0.149]
 [0.151]
 [0.151]
 [0.154]]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.188]
 [0.221]
 [0.183]
 [0.181]
 [0.191]
 [0.187]
 [0.186]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.188]
 [0.221]
 [0.183]
 [0.181]
 [0.191]
 [0.187]
 [0.186]]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[ 0.114]
 [ 0.169]
 [ 0.053]
 [ 0.172]
 [ 0.174]
 [-0.005]
 [ 0.173]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.114]
 [ 0.169]
 [ 0.053]
 [ 0.172]
 [ 0.174]
 [-0.005]
 [ 0.173]]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.8254946
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9789 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.821645
Printing some Q and Qe and total Qs values:  [[0.458]
 [0.524]
 [0.492]
 [0.482]
 [0.467]
 [0.475]
 [0.474]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.458]
 [0.524]
 [0.492]
 [0.482]
 [0.467]
 [0.475]
 [0.474]]
Printing some Q and Qe and total Qs values:  [[0.186]
 [0.186]
 [0.186]
 [0.186]
 [0.186]
 [0.186]
 [0.186]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.186]
 [0.186]
 [0.186]
 [0.186]
 [0.186]
 [0.186]
 [0.186]]
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.163]
 [0.196]
 [0.085]
 [0.153]
 [0.166]
 [0.07 ]
 [0.188]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.163]
 [0.196]
 [0.085]
 [0.153]
 [0.166]
 [0.07 ]
 [0.188]]
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.8203133
siam score:  -0.81922144
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9809599999999999 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.219]
 [0.223]
 [0.201]
 [0.207]
 [0.209]
 [0.201]
 [0.207]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.219]
 [0.223]
 [0.201]
 [0.207]
 [0.209]
 [0.201]
 [0.207]]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.8321417
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.408 0.143 0.102 0.143 0.082 0.061 0.061]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.208]
 [0.21 ]
 [0.21 ]
 [0.212]
 [0.211]
 [0.211]
 [0.21 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.208]
 [0.21 ]
 [0.21 ]
 [0.212]
 [0.211]
 [0.211]
 [0.21 ]]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.8422746
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
siam score:  -0.8448546
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98362 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.612]
 [0.645]
 [0.611]
 [0.612]
 [0.618]
 [0.613]
 [0.615]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.612]
 [0.645]
 [0.611]
 [0.612]
 [0.618]
 [0.613]
 [0.615]]
Printing some Q and Qe and total Qs values:  [[0.099]
 [0.161]
 [0.027]
 [0.148]
 [0.15 ]
 [0.009]
 [0.138]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.099]
 [0.161]
 [0.027]
 [0.148]
 [0.15 ]
 [0.009]
 [0.138]]
maxi score, test score, baseline:  -0.9862 -0.8800000000000001 -0.8800000000000001
actor:  0 policy actor:  0  step number:  48 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.8332515
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.743]
 [0.741]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.743]
 [0.741]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]]
Printing some Q and Qe and total Qs values:  [[0.38 ]
 [0.412]
 [0.391]
 [0.412]
 [0.408]
 [0.398]
 [0.388]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.38 ]
 [0.412]
 [0.391]
 [0.412]
 [0.408]
 [0.398]
 [0.388]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.8301585
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.584]
 [0.658]
 [0.577]
 [0.568]
 [0.569]
 [0.569]
 [0.564]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.584]
 [0.658]
 [0.577]
 [0.568]
 [0.569]
 [0.569]
 [0.564]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.097]
 [0.108]
 [0.1  ]
 [0.097]
 [0.096]
 [0.096]
 [0.096]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.097]
 [0.108]
 [0.1  ]
 [0.097]
 [0.096]
 [0.096]
 [0.096]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.383]
 [0.363]
 [0.415]
 [0.404]
 [0.406]
 [0.4  ]
 [0.396]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.383]
 [0.363]
 [0.415]
 [0.404]
 [0.406]
 [0.4  ]
 [0.396]]
Printing some Q and Qe and total Qs values:  [[0.999]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.999]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.585]
 [0.6  ]
 [0.595]
 [0.597]
 [0.596]
 [0.578]
 [0.586]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.585]
 [0.6  ]
 [0.595]
 [0.597]
 [0.596]
 [0.578]
 [0.586]]
siam score:  -0.8261838
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.83015144
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.182]
 [0.2  ]
 [0.182]
 [0.181]
 [0.18 ]
 [0.179]
 [0.181]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.182]
 [0.2  ]
 [0.182]
 [0.181]
 [0.18 ]
 [0.179]
 [0.181]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.25 ]
 [0.284]
 [0.284]
 [0.264]
 [0.284]
 [0.284]
 [0.284]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.25 ]
 [0.284]
 [0.284]
 [0.264]
 [0.284]
 [0.284]
 [0.284]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.83513236
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.586]
 [0.659]
 [0.604]
 [0.618]
 [0.63 ]
 [0.586]
 [0.586]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.586]
 [0.659]
 [0.604]
 [0.618]
 [0.63 ]
 [0.586]
 [0.586]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
Printing some Q and Qe and total Qs values:  [[0.773]
 [0.753]
 [0.757]
 [0.81 ]
 [0.678]
 [0.472]
 [0.472]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.773]
 [0.753]
 [0.757]
 [0.81 ]
 [0.678]
 [0.472]
 [0.472]]
Printing some Q and Qe and total Qs values:  [[0.595]
 [0.596]
 [0.597]
 [0.678]
 [0.593]
 [0.592]
 [0.592]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.595]
 [0.596]
 [0.597]
 [0.678]
 [0.593]
 [0.592]
 [0.592]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.626]
 [0.681]
 [0.657]
 [0.658]
 [0.636]
 [0.637]
 [0.631]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.626]
 [0.681]
 [0.657]
 [0.658]
 [0.636]
 [0.637]
 [0.631]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.201]
 [0.279]
 [0.212]
 [0.211]
 [0.21 ]
 [0.21 ]
 [0.206]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.201]
 [0.279]
 [0.212]
 [0.211]
 [0.21 ]
 [0.21 ]
 [0.206]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.134]
 [0.14 ]
 [0.129]
 [0.131]
 [0.122]
 [0.121]
 [0.132]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.134]
 [0.14 ]
 [0.129]
 [0.131]
 [0.122]
 [0.121]
 [0.132]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
Printing some Q and Qe and total Qs values:  [[0.139]
 [0.121]
 [0.121]
 [0.127]
 [0.121]
 [0.121]
 [0.121]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.139]
 [0.121]
 [0.121]
 [0.127]
 [0.121]
 [0.121]
 [0.121]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.8464163
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.84414995
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.538]
 [0.586]
 [0.581]
 [0.596]
 [0.569]
 [0.57 ]
 [0.572]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.538]
 [0.586]
 [0.581]
 [0.596]
 [0.569]
 [0.57 ]
 [0.572]]
siam score:  -0.83846194
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.645]
 [0.631]
 [0.631]
 [0.658]
 [0.631]
 [0.631]
 [0.631]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.645]
 [0.631]
 [0.631]
 [0.658]
 [0.631]
 [0.631]
 [0.631]]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.9835 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.8345121
Printing some Q and Qe and total Qs values:  [[0.148]
 [0.192]
 [0.219]
 [0.216]
 [0.212]
 [0.205]
 [0.208]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.148]
 [0.192]
 [0.219]
 [0.216]
 [0.212]
 [0.205]
 [0.208]]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.294]
 [0.297]
 [0.3  ]
 [0.296]
 [0.298]
 [0.305]
 [0.342]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.294]
 [0.297]
 [0.3  ]
 [0.296]
 [0.298]
 [0.305]
 [0.342]]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.544]
 [0.581]
 [0.547]
 [0.534]
 [0.517]
 [0.535]
 [0.555]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.544]
 [0.581]
 [0.547]
 [0.534]
 [0.517]
 [0.535]
 [0.555]]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.27 ]
 [0.344]
 [0.333]
 [0.294]
 [0.333]
 [0.333]
 [0.333]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.27 ]
 [0.344]
 [0.333]
 [0.294]
 [0.333]
 [0.333]
 [0.333]]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.611]
 [0.651]
 [0.625]
 [0.624]
 [0.608]
 [0.601]
 [0.607]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.611]
 [0.651]
 [0.625]
 [0.624]
 [0.608]
 [0.601]
 [0.607]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.641]
 [0.637]
 [0.646]
 [0.644]
 [0.644]
 [0.644]
 [0.644]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.641]
 [0.637]
 [0.646]
 [0.644]
 [0.644]
 [0.644]
 [0.644]]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.187]
 [0.333]
 [0.187]
 [0.187]
 [0.187]
 [0.187]
 [0.187]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.187]
 [0.333]
 [0.187]
 [0.187]
 [0.187]
 [0.187]
 [0.187]]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
Printing some Q and Qe and total Qs values:  [[0.639]
 [0.639]
 [0.566]
 [0.637]
 [0.633]
 [0.633]
 [0.64 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.639]
 [0.639]
 [0.566]
 [0.637]
 [0.633]
 [0.633]
 [0.64 ]]
siam score:  -0.8354351
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.83256537
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.517]
 [0.521]
 [0.513]
 [0.518]
 [0.508]
 [0.504]
 [0.523]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.517]
 [0.521]
 [0.513]
 [0.518]
 [0.508]
 [0.504]
 [0.523]]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98576 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.771]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.771]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]]
Printing some Q and Qe and total Qs values:  [[0.122]
 [0.125]
 [0.125]
 [0.121]
 [0.125]
 [0.125]
 [0.125]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.122]
 [0.125]
 [0.125]
 [0.121]
 [0.125]
 [0.125]
 [0.125]]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.247]
 [0.283]
 [0.252]
 [0.245]
 [0.248]
 [0.25 ]
 [0.304]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.247]
 [0.283]
 [0.252]
 [0.245]
 [0.248]
 [0.25 ]
 [0.304]]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.851]
 [0.877]
 [0.836]
 [0.867]
 [0.791]
 [0.792]
 [0.796]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.851]
 [0.877]
 [0.836]
 [0.867]
 [0.791]
 [0.792]
 [0.796]]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.216]
 [0.286]
 [0.216]
 [0.216]
 [0.216]
 [0.216]
 [0.216]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.216]
 [0.286]
 [0.216]
 [0.216]
 [0.216]
 [0.216]
 [0.216]]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]]
Printing some Q and Qe and total Qs values:  [[0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]]
Printing some Q and Qe and total Qs values:  [[0.131]
 [0.157]
 [0.124]
 [0.123]
 [0.122]
 [0.123]
 [0.129]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.131]
 [0.157]
 [0.124]
 [0.123]
 [0.122]
 [0.123]
 [0.129]]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.264]
 [0.279]
 [0.262]
 [0.263]
 [0.263]
 [0.258]
 [0.258]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.264]
 [0.279]
 [0.262]
 [0.263]
 [0.263]
 [0.258]
 [0.258]]
Printing some Q and Qe and total Qs values:  [[0.12]
 [0.12]
 [0.12]
 [0.12]
 [0.12]
 [0.12]
 [0.12]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.12]
 [0.12]
 [0.12]
 [0.12]
 [0.12]
 [0.12]
 [0.12]]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.82765
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.222]
 [0.271]
 [0.282]
 [0.259]
 [0.26 ]
 [0.254]
 [0.271]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.222]
 [0.271]
 [0.282]
 [0.259]
 [0.26 ]
 [0.254]
 [0.271]]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.635]
 [0.689]
 [0.654]
 [0.647]
 [0.648]
 [0.648]
 [0.648]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.635]
 [0.689]
 [0.654]
 [0.647]
 [0.648]
 [0.648]
 [0.648]]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.523]
 [0.567]
 [0.528]
 [0.521]
 [0.526]
 [0.507]
 [0.551]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.523]
 [0.567]
 [0.528]
 [0.521]
 [0.526]
 [0.507]
 [0.551]]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
siam score:  -0.8297297
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
siam score:  -0.82805115
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Starting evaluation
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.158]
 [0.142]
 [0.158]
 [0.157]
 [0.158]
 [0.158]
 [0.158]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.158]
 [0.142]
 [0.158]
 [0.157]
 [0.158]
 [0.158]
 [0.158]]
Printing some Q and Qe and total Qs values:  [[0.532]
 [0.584]
 [0.542]
 [0.554]
 [0.526]
 [0.522]
 [0.54 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.532]
 [0.584]
 [0.542]
 [0.554]
 [0.526]
 [0.522]
 [0.54 ]]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98782 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.178]
 [0.196]
 [0.179]
 [0.179]
 [0.177]
 [0.175]
 [0.177]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.178]
 [0.196]
 [0.179]
 [0.179]
 [0.177]
 [0.175]
 [0.177]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.98468 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
siam score:  -0.8292925
maxi score, test score, baseline:  -0.98468 -0.8800000000000001 -0.8800000000000001
siam score:  -0.82886267
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.707]
 [0.707]
 [0.674]
 [0.707]
 [0.707]
 [0.684]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.703]
 [0.707]
 [0.707]
 [0.674]
 [0.707]
 [0.707]
 [0.684]]
siam score:  -0.8306762
maxi score, test score, baseline:  -0.98468 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]]
maxi score, test score, baseline:  -0.98468 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.685]
 [0.704]
 [0.704]
 [0.704]
 [0.704]
 [0.704]
 [0.704]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.685]
 [0.704]
 [0.704]
 [0.704]
 [0.704]
 [0.704]
 [0.704]]
maxi score, test score, baseline:  -0.98468 -0.8800000000000001 -0.8800000000000001
maxi score, test score, baseline:  -0.98468 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]]
Printing some Q and Qe and total Qs values:  [[0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]]
maxi score, test score, baseline:  -0.98468 -0.8800000000000001 -0.8800000000000001
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.514]
 [0.487]
 [0.514]
 [0.538]
 [0.514]
 [0.514]
 [0.514]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.514]
 [0.487]
 [0.514]
 [0.538]
 [0.514]
 [0.514]
 [0.514]]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  45 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
siam score:  -0.825695
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
siam score:  -0.8272174
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.237]
 [0.237]
 [0.198]
 [0.237]
 [0.191]
 [0.237]
 [0.237]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.237]
 [0.237]
 [0.198]
 [0.237]
 [0.191]
 [0.237]
 [0.237]]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.204]
 [0.222]
 [0.198]
 [0.2  ]
 [0.196]
 [0.2  ]
 [0.199]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.204]
 [0.222]
 [0.198]
 [0.2  ]
 [0.196]
 [0.2  ]
 [0.199]]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.624]
 [0.579]
 [0.638]
 [0.627]
 [0.648]
 [0.613]
 [0.613]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.624]
 [0.579]
 [0.638]
 [0.627]
 [0.648]
 [0.613]
 [0.613]]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.126]
 [0.145]
 [0.129]
 [0.125]
 [0.127]
 [0.126]
 [0.127]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.126]
 [0.145]
 [0.129]
 [0.125]
 [0.127]
 [0.126]
 [0.127]]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98468 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  43 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.98224 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98224 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.8206239
Printing some Q and Qe and total Qs values:  [[0.645]
 [0.698]
 [0.601]
 [0.648]
 [0.601]
 [0.601]
 [0.601]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.645]
 [0.698]
 [0.601]
 [0.648]
 [0.601]
 [0.601]
 [0.601]]
maxi score, test score, baseline:  -0.98224 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98224 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98224 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  42 total reward:  0.02999999999999936  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.31 ]
 [0.383]
 [0.315]
 [0.315]
 [0.311]
 [0.31 ]
 [0.311]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.31 ]
 [0.383]
 [0.315]
 [0.315]
 [0.311]
 [0.31 ]
 [0.311]]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.8248529
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.52]
 [0.52]
 [0.52]
 [0.52]
 [0.52]
 [0.52]
 [0.52]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.52]
 [0.52]
 [0.52]
 [0.52]
 [0.52]
 [0.52]
 [0.52]]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.047]
 [0.112]
 [0.069]
 [0.139]
 [0.034]
 [0.035]
 [0.12 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.047]
 [0.112]
 [0.069]
 [0.139]
 [0.034]
 [0.035]
 [0.12 ]]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9801799999999999 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  61 total reward:  0.0799999999999994  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.97802 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.8204204
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.819516
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.448]
 [0.482]
 [0.439]
 [0.459]
 [0.432]
 [0.417]
 [0.401]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.448]
 [0.482]
 [0.439]
 [0.459]
 [0.432]
 [0.417]
 [0.401]]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]]
Printing some Q and Qe and total Qs values:  [[0.041]
 [0.061]
 [0.05 ]
 [0.042]
 [0.044]
 [0.042]
 [0.045]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.041]
 [0.061]
 [0.05 ]
 [0.042]
 [0.044]
 [0.042]
 [0.045]]
maxi score, test score, baseline:  -0.98028 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.81278145
maxi score, test score, baseline:  -0.9829 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9829 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9829 -0.9215 -0.9215
siam score:  -0.8102602
maxi score, test score, baseline:  -0.9829 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9829 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.064]
 [0.069]
 [0.06 ]
 [0.062]
 [0.061]
 [0.061]
 [0.061]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.064]
 [0.069]
 [0.06 ]
 [0.062]
 [0.061]
 [0.061]
 [0.061]]
maxi score, test score, baseline:  -0.9829 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.706]
 [0.69 ]
 [0.687]
 [0.693]
 [0.693]
 [0.693]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.682]
 [0.706]
 [0.69 ]
 [0.687]
 [0.693]
 [0.693]
 [0.693]]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.642]
 [0.645]
 [0.697]
 [0.648]
 [0.641]
 [0.648]
 [0.648]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.642]
 [0.645]
 [0.697]
 [0.648]
 [0.641]
 [0.648]
 [0.648]]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.63 ]
 [0.708]
 [0.656]
 [0.646]
 [0.646]
 [0.663]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.65 ]
 [0.63 ]
 [0.708]
 [0.656]
 [0.646]
 [0.646]
 [0.663]]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.8122122
Printing some Q and Qe and total Qs values:  [[0.127]
 [0.145]
 [0.156]
 [0.124]
 [0.127]
 [0.125]
 [0.126]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.127]
 [0.145]
 [0.156]
 [0.124]
 [0.127]
 [0.125]
 [0.126]]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.69 ]
 [0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.688]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.69 ]
 [0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.688]]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.8046016
Printing some Q and Qe and total Qs values:  [[0.19 ]
 [0.149]
 [0.128]
 [0.123]
 [0.117]
 [0.135]
 [0.134]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.19 ]
 [0.149]
 [0.128]
 [0.123]
 [0.117]
 [0.135]
 [0.134]]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.7626],
        [-0.6949],
        [-0.0000],
        [-0.6965],
        [-0.7626],
        [-0.7470],
        [-0.7445],
        [-0.3081],
        [-0.6856],
        [-0.3071]], dtype=torch.float64)
-0.048519850599000006 -0.8111190358654233
-0.145559551797 -0.8404660751324599
-0.45539999999999975 -0.45539999999999975
-0.125759551797 -0.8222492602501468
-0.048519850599000006 -0.8111190358654233
-0.048519850599000006 -0.7955297433000919
-0.048519850599000006 -0.7930180020910419
-0.145559551797 -0.4536253725896975
-0.048519850599000006 -0.7341606897600331
-0.145559551797 -0.45268261503849105
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.79283106
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.014]
 [0.028]
 [0.012]
 [0.012]
 [0.017]
 [0.017]
 [0.017]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.014]
 [0.028]
 [0.012]
 [0.012]
 [0.017]
 [0.017]
 [0.017]]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.7979702
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.7960138
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.786875
Printing some Q and Qe and total Qs values:  [[0.704]
 [0.723]
 [0.705]
 [0.721]
 [0.713]
 [0.702]
 [0.704]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.704]
 [0.723]
 [0.705]
 [0.721]
 [0.713]
 [0.702]
 [0.704]]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[-0.006]
 [-0.006]
 [-0.006]
 [-0.008]
 [-0.006]
 [-0.006]
 [-0.006]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.006]
 [-0.006]
 [-0.006]
 [-0.008]
 [-0.006]
 [-0.006]
 [-0.006]]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.069]
 [0.098]
 [0.069]
 [0.069]
 [0.069]
 [0.069]
 [0.069]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.069]
 [0.098]
 [0.069]
 [0.069]
 [0.069]
 [0.069]
 [0.069]]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9850800000000001 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  61 total reward:  0.0799999999999994  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.98292 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98292 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98292 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98292 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98292 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98292 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.076]
 [0.158]
 [0.205]
 [0.172]
 [0.115]
 [0.092]
 [0.096]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.076]
 [0.158]
 [0.205]
 [0.172]
 [0.115]
 [0.092]
 [0.096]]
Printing some Q and Qe and total Qs values:  [[0.502]
 [0.563]
 [0.501]
 [0.493]
 [0.484]
 [0.484]
 [0.484]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.502]
 [0.563]
 [0.501]
 [0.493]
 [0.484]
 [0.484]
 [0.484]]
maxi score, test score, baseline:  -0.98292 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98292 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98292 -0.9215 -0.9215
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.98292 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  47 total reward:  0.09999999999999942  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9807199999999999 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9807199999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9807199999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9807199999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9807199999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9807199999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9807199999999999 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9807199999999999 -0.9215 -0.9215
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.302]
 [0.298]
 [0.293]
 [0.271]
 [0.271]
 [0.293]
 [0.289]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.302]
 [0.298]
 [0.293]
 [0.271]
 [0.271]
 [0.293]
 [0.289]]
Printing some Q and Qe and total Qs values:  [[0.262]
 [0.256]
 [0.236]
 [0.224]
 [0.222]
 [0.222]
 [0.232]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.262]
 [0.256]
 [0.236]
 [0.224]
 [0.222]
 [0.222]
 [0.232]]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.77155447
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.553]
 [0.62 ]
 [0.542]
 [0.547]
 [0.542]
 [0.542]
 [0.542]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.553]
 [0.62 ]
 [0.542]
 [0.547]
 [0.542]
 [0.542]
 [0.542]]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.668]
 [0.688]
 [0.693]
 [0.687]
 [0.695]
 [0.674]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.693]
 [0.668]
 [0.688]
 [0.693]
 [0.687]
 [0.695]
 [0.674]]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.7658152
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.5096],
        [-0.3641],
        [-0.0000],
        [-0.0000],
        [-0.0000],
        [-0.7676],
        [-0.6006],
        [-0.0000],
        [-0.7676],
        [-0.7240]], dtype=torch.float64)
-0.145559551797 -0.6551409752477662
-0.145559551797 -0.5096115682612005
-0.039106979999999375 -0.039106979999999375
-0.08821196999999938 -0.08821196999999938
-0.5147999999999998 -0.5147999999999998
-0.048519850599000006 -0.8161040773300613
-0.106157551797 -0.7067603878363317
-0.0589049999999995 -0.0589049999999995
-0.048519850599000006 -0.8160922043872498
-0.048519850599000006 -0.7725416259210341
Printing some Q and Qe and total Qs values:  [[0.255]
 [0.255]
 [0.255]
 [0.163]
 [0.255]
 [0.255]
 [0.255]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.255]
 [0.255]
 [0.255]
 [0.163]
 [0.255]
 [0.255]
 [0.255]]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.077]
 [0.085]
 [0.077]
 [0.077]
 [0.077]
 [0.077]
 [0.077]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.077]
 [0.085]
 [0.077]
 [0.077]
 [0.077]
 [0.077]
 [0.077]]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.07 ]
 [0.073]
 [0.064]
 [0.066]
 [0.068]
 [0.065]
 [0.067]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.07 ]
 [0.073]
 [0.064]
 [0.066]
 [0.068]
 [0.065]
 [0.067]]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.15 ]
 [0.261]
 [0.15 ]
 [0.15 ]
 [0.15 ]
 [0.15 ]
 [0.15 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.15 ]
 [0.261]
 [0.15 ]
 [0.15 ]
 [0.15 ]
 [0.15 ]
 [0.15 ]]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.592]
 [0.599]
 [0.599]
 [0.598]
 [0.599]
 [0.599]
 [0.599]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.592]
 [0.599]
 [0.599]
 [0.598]
 [0.599]
 [0.599]
 [0.599]]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.98342 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.26 ]
 [0.346]
 [0.274]
 [0.272]
 [0.352]
 [0.352]
 [0.252]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.26 ]
 [0.346]
 [0.274]
 [0.272]
 [0.352]
 [0.352]
 [0.252]]
actor:  0 policy actor:  0  step number:  40 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.981 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.981 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.76241934
maxi score, test score, baseline:  -0.981 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.981 -0.9215 -0.9215
maxi score, test score, baseline:  -0.981 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  55 total reward:  0.05999999999999939  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.209]
 [0.136]
 [0.584]
 [0.42 ]
 [0.297]
 [0.246]
 [0.212]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.209]
 [0.136]
 [0.584]
 [0.42 ]
 [0.297]
 [0.246]
 [0.212]]
actor:  0 policy actor:  0  step number:  40 total reward:  0.10999999999999943  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]
 [0.383]]
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97666 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9739800000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9739800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97398 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97398 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97398 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.97398 -0.9215 -0.9215
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.9739800000000001 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.297]
 [0.319]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.274]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.297]
 [0.319]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.274]]
maxi score, test score, baseline:  -0.9739800000000001 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.532]
 [0.531]
 [0.545]
 [0.526]
 [0.431]
 [0.42 ]
 [0.497]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.532]
 [0.531]
 [0.545]
 [0.526]
 [0.431]
 [0.42 ]
 [0.497]]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[ 0.007]
 [-0.001]
 [ 0.007]
 [ 0.006]
 [ 0.007]
 [ 0.007]
 [ 0.007]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.007]
 [-0.001]
 [ 0.007]
 [ 0.006]
 [ 0.007]
 [ 0.007]
 [ 0.007]]
maxi score, test score, baseline:  -0.9739800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9739800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9739800000000001 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]]
maxi score, test score, baseline:  -0.9739800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9739800000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9739800000000001 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  46 total reward:  0.08999999999999941  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
siam score:  -0.7415411
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.034]
 [0.049]
 [0.02 ]
 [0.021]
 [0.049]
 [0.049]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.018]
 [0.034]
 [0.049]
 [0.02 ]
 [0.021]
 [0.049]
 [0.049]]
siam score:  -0.7399608
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9718000000000001 -0.9215 -0.9215
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9693400000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9693400000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9693400000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9693400000000001 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  42 total reward:  0.0699999999999994  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.19 ]
 [0.206]
 [0.053]
 [0.191]
 [0.202]
 [0.077]
 [0.208]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.19 ]
 [0.206]
 [0.053]
 [0.191]
 [0.202]
 [0.077]
 [0.208]]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.129]
 [0.137]
 [0.131]
 [0.132]
 [0.132]
 [0.131]
 [0.133]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.129]
 [0.137]
 [0.131]
 [0.132]
 [0.132]
 [0.131]
 [0.133]]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.024]
 [0.009]
 [0.012]
 [0.012]
 [0.008]
 [0.013]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.024]
 [0.009]
 [0.012]
 [0.012]
 [0.008]
 [0.013]]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.654]
 [0.714]
 [0.673]
 [0.682]
 [0.651]
 [0.648]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.682]
 [0.654]
 [0.714]
 [0.673]
 [0.682]
 [0.651]
 [0.648]]
Printing some Q and Qe and total Qs values:  [[0.234]
 [0.32 ]
 [0.234]
 [0.234]
 [0.234]
 [0.234]
 [0.234]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.234]
 [0.32 ]
 [0.234]
 [0.234]
 [0.234]
 [0.234]
 [0.234]]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.75943047
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.739]
 [0.623]
 [0.702]
 [0.745]
 [0.604]
 [0.66 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.693]
 [0.739]
 [0.623]
 [0.702]
 [0.745]
 [0.604]
 [0.66 ]]
Printing some Q and Qe and total Qs values:  [[0.366]
 [0.442]
 [0.366]
 [0.367]
 [0.366]
 [0.366]
 [0.366]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.366]
 [0.442]
 [0.366]
 [0.367]
 [0.366]
 [0.366]
 [0.366]]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.486]
 [0.557]
 [0.467]
 [0.506]
 [0.477]
 [0.477]
 [0.47 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.486]
 [0.557]
 [0.467]
 [0.506]
 [0.477]
 [0.477]
 [0.47 ]]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
siam score:  -0.7534514
siam score:  -0.75688463
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
Printing some Q and Qe and total Qs values:  [[0.182]
 [0.182]
 [0.182]
 [0.182]
 [0.182]
 [0.182]
 [0.182]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.182]
 [0.182]
 [0.182]
 [0.182]
 [0.182]
 [0.182]
 [0.182]]
Printing some Q and Qe and total Qs values:  [[0.213]
 [0.156]
 [0.199]
 [0.207]
 [0.213]
 [0.213]
 [0.503]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.213]
 [0.156]
 [0.199]
 [0.207]
 [0.213]
 [0.213]
 [0.503]]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.238]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.238]]
Printing some Q and Qe and total Qs values:  [[0.532]
 [0.58 ]
 [0.468]
 [0.522]
 [0.481]
 [0.47 ]
 [0.489]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.532]
 [0.58 ]
 [0.468]
 [0.522]
 [0.481]
 [0.47 ]
 [0.489]]
Printing some Q and Qe and total Qs values:  [[0.906]
 [0.797]
 [1.003]
 [0.965]
 [0.913]
 [0.913]
 [0.896]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.906]
 [0.797]
 [1.003]
 [0.965]
 [0.913]
 [0.913]
 [0.896]]
siam score:  -0.75725466
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9672 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.96406 -0.9215 -0.9215
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.95766 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  46 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.828]
 [0.928]
 [0.713]
 [0.749]
 [0.9  ]
 [0.9  ]
 [0.957]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.828]
 [0.928]
 [0.713]
 [0.749]
 [0.9  ]
 [0.9  ]
 [0.957]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.5499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
siam score:  -0.7575092
actor:  0 policy actor:  0  step number:  36 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.93726 -0.9215 -0.9215
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.668]
 [0.64 ]
 [0.7  ]
 [0.653]
 [0.65 ]
 [0.637]
 [0.642]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.668]
 [0.64 ]
 [0.7  ]
 [0.653]
 [0.65 ]
 [0.637]
 [0.642]]
actor:  0 policy actor:  0  step number:  41 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.93442 -0.9215 -0.9215
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9319000000000001 -0.9215 -0.9215
maxi score, test score, baseline:  -0.9319000000000001 -0.9215 -0.9215
probs:  [1.0]
maxi score, test score, baseline:  -0.9319000000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  53 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9295800000000001 -0.24200000000000008 -0.24200000000000008
Printing some Q and Qe and total Qs values:  [[0.262]
 [0.412]
 [0.265]
 [0.26 ]
 [0.254]
 [0.254]
 [0.257]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.262]
 [0.412]
 [0.265]
 [0.26 ]
 [0.254]
 [0.254]
 [0.257]]
maxi score, test score, baseline:  -0.9295800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9295800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9295800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9295800000000001 -0.24200000000000008 -0.24200000000000008
siam score:  -0.7570227
maxi score, test score, baseline:  -0.9295800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.109]
 [0.196]
 [0.002]
 [0.13 ]
 [0.116]
 [0.003]
 [0.161]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.109]
 [0.196]
 [0.002]
 [0.13 ]
 [0.116]
 [0.003]
 [0.161]]
maxi score, test score, baseline:  -0.9295800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9295800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.10999999999999943  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9273600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
siam score:  -0.75881225
maxi score, test score, baseline:  -0.9273600000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.9273600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9273600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9273600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9273600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9273600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9273600000000001 -0.24200000000000008 -0.24200000000000008
actor:  0 policy actor:  0  step number:  36 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.656]
 [0.643]
 [0.773]
 [0.656]
 [0.656]
 [0.625]
 [0.656]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.656]
 [0.643]
 [0.773]
 [0.656]
 [0.656]
 [0.625]
 [0.656]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
siam score:  -0.7576979
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.9245800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  43 total reward:  0.01999999999999935  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.92254 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.92254 -0.24200000000000008 -0.24200000000000008
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.92254 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.92254 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.92254 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.495]
 [0.495]
 [0.495]
 [0.495]
 [0.495]
 [0.495]
 [0.495]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.495]
 [0.495]
 [0.495]
 [0.495]
 [0.495]
 [0.495]
 [0.495]]
maxi score, test score, baseline:  -0.92254 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.92254 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.92254 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.92254 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.92254 -0.24200000000000008 -0.24200000000000008
actor:  0 policy actor:  0  step number:  58 total reward:  0.02999999999999936  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9204800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.164]
 [0.225]
 [0.154]
 [0.167]
 [0.156]
 [0.156]
 [0.157]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.164]
 [0.225]
 [0.154]
 [0.167]
 [0.156]
 [0.156]
 [0.157]]
maxi score, test score, baseline:  -0.9204800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.92048 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.92048 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.91764 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.91764 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.356]
 [0.365]
 [0.357]
 [0.351]
 [0.354]
 [0.347]
 [0.346]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.356]
 [0.365]
 [0.357]
 [0.351]
 [0.354]
 [0.347]
 [0.346]]
maxi score, test score, baseline:  -0.91764 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.91764 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.91764 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.046]
 [0.046]
 [0.046]
 [0.046]
 [0.046]
 [0.046]
 [0.046]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.046]
 [0.046]
 [0.046]
 [0.046]
 [0.046]
 [0.046]
 [0.046]]
maxi score, test score, baseline:  -0.91764 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.91764 -0.24200000000000008 -0.24200000000000008
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.91764 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.91764 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.91764 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  66 total reward:  0.0699999999999994  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9155000000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155000000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155000000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155000000000002 -0.24200000000000008 -0.24200000000000008
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.9155000000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155000000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.637]
 [0.63 ]
 [0.658]
 [0.639]
 [0.619]
 [0.634]
 [0.622]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.637]
 [0.63 ]
 [0.658]
 [0.639]
 [0.619]
 [0.634]
 [0.622]]
maxi score, test score, baseline:  -0.9155 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.9155 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9155 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.423]
 [0.563]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.423]
 [0.563]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]]
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.61 ]
 [0.583]
 [0.577]
 [0.571]
 [0.568]
 [0.576]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.566]
 [0.61 ]
 [0.583]
 [0.577]
 [0.571]
 [0.568]
 [0.576]]
actor:  0 policy actor:  0  step number:  41 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.91064 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.91064 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  42 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9082600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
siam score:  -0.75772375
maxi score, test score, baseline:  -0.9082600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9054599999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9054599999999999 -0.24200000000000008 -0.24200000000000008
Printing some Q and Qe and total Qs values:  [[0.165]
 [0.175]
 [0.175]
 [0.181]
 [0.111]
 [0.175]
 [0.175]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.165]
 [0.175]
 [0.175]
 [0.181]
 [0.111]
 [0.175]
 [0.175]]
maxi score, test score, baseline:  -0.9054599999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9054599999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90298 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.90612 -0.24200000000000008 -0.24200000000000008
Printing some Q and Qe and total Qs values:  [[0.178]
 [0.161]
 [0.331]
 [0.206]
 [0.206]
 [0.243]
 [0.251]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.178]
 [0.161]
 [0.331]
 [0.206]
 [0.206]
 [0.243]
 [0.251]]
maxi score, test score, baseline:  -0.90612 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.90612 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90612 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
siam score:  -0.77044165
maxi score, test score, baseline:  -0.90612 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.90612 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.90612 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.9031 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9031 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
siam score:  -0.7647091
maxi score, test score, baseline:  -0.9031 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9031 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.9031 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9031 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9031 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.9031 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
siam score:  -0.76264364
Printing some Q and Qe and total Qs values:  [[0.434]
 [0.512]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.434]
 [0.512]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]]
maxi score, test score, baseline:  -0.90072 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90072 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90072 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90072 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90072 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.737]
 [0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.737]
 [0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]]
maxi score, test score, baseline:  -0.90072 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.043]
 [0.075]
 [0.045]
 [0.045]
 [0.043]
 [0.042]
 [0.045]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.043]
 [0.075]
 [0.045]
 [0.045]
 [0.043]
 [0.042]
 [0.045]]
Printing some Q and Qe and total Qs values:  [[0.689]
 [0.902]
 [0.776]
 [0.782]
 [0.649]
 [0.738]
 [0.83 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.689]
 [0.902]
 [0.776]
 [0.782]
 [0.649]
 [0.738]
 [0.83 ]]
actor:  0 policy actor:  0  step number:  35 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.614]
 [0.609]
 [0.614]
 [0.555]
 [0.58 ]
 [0.552]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.581]
 [0.614]
 [0.609]
 [0.614]
 [0.555]
 [0.58 ]
 [0.552]]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.542]
 [0.603]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.542]
 [0.603]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.339]
 [0.464]
 [0.339]
 [0.339]
 [0.339]
 [0.339]
 [0.339]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.339]
 [0.464]
 [0.339]
 [0.339]
 [0.339]
 [0.339]
 [0.339]]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.356]
 [0.477]
 [0.335]
 [0.34 ]
 [0.451]
 [0.336]
 [0.334]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.356]
 [0.477]
 [0.335]
 [0.34 ]
 [0.451]
 [0.336]
 [0.334]]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89804 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.90036 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.89788 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.89788 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89788 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89788 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.065]
 [0.1  ]
 [0.068]
 [0.067]
 [0.071]
 [0.068]
 [0.07 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.065]
 [0.1  ]
 [0.068]
 [0.067]
 [0.071]
 [0.068]
 [0.07 ]]
maxi score, test score, baseline:  -0.89788 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89788 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.339]
 [0.713]
 [0.339]
 [0.339]
 [0.339]
 [0.339]
 [0.339]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.339]
 [0.713]
 [0.339]
 [0.339]
 [0.339]
 [0.339]
 [0.339]]
maxi score, test score, baseline:  -0.89788 -0.24200000000000008 -0.24200000000000008
siam score:  -0.75478554
Printing some Q and Qe and total Qs values:  [[0.606]
 [0.561]
 [0.557]
 [0.562]
 [0.557]
 [0.549]
 [0.56 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.606]
 [0.561]
 [0.557]
 [0.562]
 [0.557]
 [0.549]
 [0.56 ]]
maxi score, test score, baseline:  -0.89788 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  45 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.89552 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8955200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[ 0.067]
 [ 0.19 ]
 [ 0.17 ]
 [ 0.158]
 [ 0.134]
 [-0.009]
 [ 0.187]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.067]
 [ 0.19 ]
 [ 0.17 ]
 [ 0.158]
 [ 0.134]
 [-0.009]
 [ 0.187]]
maxi score, test score, baseline:  -0.8955200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8955200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.652]
 [0.72 ]
 [0.677]
 [0.684]
 [0.69 ]
 [0.687]
 [0.651]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.652]
 [0.72 ]
 [0.677]
 [0.684]
 [0.69 ]
 [0.687]
 [0.651]]
siam score:  -0.7572987
maxi score, test score, baseline:  -0.8955200000000001 -0.24200000000000008 -0.24200000000000008
Printing some Q and Qe and total Qs values:  [[0.898]
 [0.031]
 [0.031]
 [0.031]
 [0.031]
 [0.031]
 [0.031]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.898]
 [0.031]
 [0.031]
 [0.031]
 [0.031]
 [0.031]
 [0.031]]
maxi score, test score, baseline:  -0.89552 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.89552 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8955200000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8979600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8948600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8948600000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8948600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8948600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
siam score:  -0.7657051
UNIT TEST: sample policy line 217 mcts : [0.286 0.082 0.122 0.224 0.082 0.143 0.061]
actor:  0 policy actor:  0  step number:  40 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.89248 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89248 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89248 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89248 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8898600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8898600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8898600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.89192 -0.24200000000000008 -0.24200000000000008
Printing some Q and Qe and total Qs values:  [[0.493]
 [0.526]
 [0.498]
 [0.51 ]
 [0.493]
 [0.491]
 [0.493]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.493]
 [0.526]
 [0.498]
 [0.51 ]
 [0.493]
 [0.491]
 [0.493]]
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.75858605
maxi score, test score, baseline:  -0.89192 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.47 ]
 [0.476]
 [0.462]
 [0.454]
 [0.491]
 [0.489]
 [0.471]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.47 ]
 [0.476]
 [0.462]
 [0.454]
 [0.491]
 [0.489]
 [0.471]]
maxi score, test score, baseline:  -0.89192 -0.24200000000000008 -0.24200000000000008
actor:  0 policy actor:  0  step number:  43 total reward:  0.13999999999999946  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.88964 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.88964 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.88964 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.88964 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.88964 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.88964 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.079]
 [0.104]
 [0.078]
 [0.083]
 [0.079]
 [0.079]
 [0.082]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.079]
 [0.104]
 [0.078]
 [0.083]
 [0.079]
 [0.079]
 [0.082]]
maxi score, test score, baseline:  -0.88964 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.88964 -0.24200000000000008 -0.24200000000000008
Printing some Q and Qe and total Qs values:  [[0.193]
 [0.22 ]
 [0.234]
 [0.194]
 [0.234]
 [0.234]
 [0.234]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.193]
 [0.22 ]
 [0.234]
 [0.194]
 [0.234]
 [0.234]
 [0.234]]
siam score:  -0.75033927
maxi score, test score, baseline:  -0.8918000000000001 -0.24200000000000008 -0.24200000000000008
Printing some Q and Qe and total Qs values:  [[0.77 ]
 [0.771]
 [0.778]
 [0.887]
 [0.887]
 [0.887]
 [0.768]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.77 ]
 [0.771]
 [0.778]
 [0.887]
 [0.887]
 [0.887]
 [0.768]]
actor:  0 policy actor:  0  step number:  46 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8893 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8893 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.471]
 [0.605]
 [0.446]
 [0.473]
 [0.446]
 [0.446]
 [0.446]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.471]
 [0.605]
 [0.446]
 [0.473]
 [0.446]
 [0.446]
 [0.446]]
actor:  0 policy actor:  0  step number:  48 total reward:  0.02999999999999936  reward:  1.0 rdn_beta:  0.0
siam score:  -0.7484521
maxi score, test score, baseline:  -0.88724 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8872399999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.88724 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8872399999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8872399999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  45 total reward:  0.05999999999999939  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.88512 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.88512 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.88512 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8824 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.87898 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.87898 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
siam score:  -0.7556995
actor:  0 policy actor:  0  step number:  34 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8764799999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.87368 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.7661331
maxi score, test score, baseline:  -0.87368 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  43 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.087]
 [0.107]
 [0.127]
 [0.089]
 [0.127]
 [0.089]
 [0.087]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.087]
 [0.107]
 [0.127]
 [0.089]
 [0.127]
 [0.089]
 [0.087]]
maxi score, test score, baseline:  -0.8710000000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.86822 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8682200000000002 -0.24200000000000008 -0.24200000000000008
actor:  0 policy actor:  0  step number:  38 total reward:  0.2899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.86564 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
siam score:  -0.7662763
maxi score, test score, baseline:  -0.86564 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.575]
 [0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.424]
 [0.575]
 [0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8632 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8632000000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8632000000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  46 total reward:  0.02999999999999936  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.86114 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.86114 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.86114 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.86114 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.86114 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.86114 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  41 total reward:  0.13999999999999946  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.036]
 [0.012]
 [0.012]
 [0.009]
 [0.01 ]
 [0.01 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.013]
 [0.036]
 [0.012]
 [0.012]
 [0.009]
 [0.01 ]
 [0.01 ]]
maxi score, test score, baseline:  -0.8588600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
siam score:  -0.76554155
maxi score, test score, baseline:  -0.8588600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.85886 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8588600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.94 ]
 [0.942]
 [0.946]
 [0.948]
 [0.936]
 [0.936]
 [0.949]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.94 ]
 [0.942]
 [0.946]
 [0.948]
 [0.936]
 [0.936]
 [0.949]]
actor:  0 policy actor:  0  step number:  36 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
siam score:  -0.76549965
maxi score, test score, baseline:  -0.85616 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.85616 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.433]
 [0.433]
 [0.433]
 [0.468]
 [0.433]
 [0.433]
 [0.433]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.433]
 [0.433]
 [0.433]
 [0.468]
 [0.433]
 [0.433]
 [0.433]]
actor:  0 policy actor:  0  step number:  41 total reward:  0.1599999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.85384 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.85384 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.85384 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.225]
 [0.217]
 [0.217]
 [0.228]
 [0.217]
 [0.217]
 [0.217]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.225]
 [0.217]
 [0.217]
 [0.228]
 [0.217]
 [0.217]
 [0.217]]
maxi score, test score, baseline:  -0.85384 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.85384 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.85384 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.036]
 [0.016]
 [0.012]
 [0.01 ]
 [0.015]
 [0.012]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.013]
 [0.036]
 [0.016]
 [0.012]
 [0.01 ]
 [0.015]
 [0.012]]
maxi score, test score, baseline:  -0.85384 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.528]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.427]
 [0.528]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]]
maxi score, test score, baseline:  -0.85384 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  46 total reward:  0.02999999999999947  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.84616 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8461600000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8461600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.717]
 [0.601]
 [0.616]
 [0.715]
 [0.709]
 [0.52 ]
 [0.71 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.717]
 [0.601]
 [0.616]
 [0.715]
 [0.709]
 [0.52 ]
 [0.71 ]]
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8437 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8437 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.817]
 [0.508]
 [0.627]
 [0.459]
 [0.545]
 [0.654]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.751]
 [0.817]
 [0.508]
 [0.627]
 [0.459]
 [0.545]
 [0.654]]
maxi score, test score, baseline:  -0.8437 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8411200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8411200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8411200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.219]
 [0.278]
 [0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.219]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.219]
 [0.278]
 [0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.219]]
maxi score, test score, baseline:  -0.8411200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8411200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8411200000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8411200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.076]
 [0.098]
 [0.079]
 [0.08 ]
 [0.083]
 [0.082]
 [0.084]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.076]
 [0.098]
 [0.079]
 [0.08 ]
 [0.083]
 [0.082]
 [0.084]]
maxi score, test score, baseline:  -0.8411200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.8411200000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8411200000000001 -0.24200000000000008 -0.24200000000000008
actor:  0 policy actor:  0  step number:  46 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.83866 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8357199999999999 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8357199999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8357199999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8303600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8303600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8303600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8303600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8303600000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8303600000000001 -0.24200000000000008 -0.24200000000000008
Printing some Q and Qe and total Qs values:  [[0.086]
 [0.086]
 [0.086]
 [0.086]
 [0.086]
 [0.086]
 [0.086]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.086]
 [0.086]
 [0.086]
 [0.086]
 [0.086]
 [0.086]
 [0.086]]
maxi score, test score, baseline:  -0.8325200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8325200000000001 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8325200000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.375]
 [0.515]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.375]
 [0.515]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]]
maxi score, test score, baseline:  -0.8325200000000001 -0.24200000000000008 -0.24200000000000008
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.34999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.82694 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.82694 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.82694 -0.24200000000000008 -0.24200000000000008
actor:  0 policy actor:  0  step number:  51 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  40 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.82204 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.82204 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.82204 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.394]
 [0.423]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.394]
 [0.423]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]]
maxi score, test score, baseline:  -0.82204 -0.24200000000000008 -0.24200000000000008
siam score:  -0.7599809
actor:  0 policy actor:  0  step number:  42 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8195 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.561]
 [0.573]
 [0.567]
 [0.566]
 [0.565]
 [0.567]
 [0.567]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.561]
 [0.573]
 [0.567]
 [0.566]
 [0.565]
 [0.567]
 [0.567]]
maxi score, test score, baseline:  -0.8195 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8195 -0.24200000000000008 -0.24200000000000008
actor:  0 policy actor:  0  step number:  42 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8168000000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8168000000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
siam score:  -0.7705027
actor:  0 policy actor:  0  step number:  41 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.8144399999999999 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8144399999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8144399999999999 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.8144399999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8144399999999999 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.81422 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.81422 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.554]
 [0.421]
 [0.43 ]
 [0.569]
 [0.444]
 [0.443]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.424]
 [0.554]
 [0.421]
 [0.43 ]
 [0.569]
 [0.444]
 [0.443]]
maxi score, test score, baseline:  -0.81422 -0.24200000000000008 -0.24200000000000008
maxi score, test score, baseline:  -0.81422 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.81422 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.441]
 [0.562]
 [0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.441]
 [0.562]
 [0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]]
actor:  0 policy actor:  0  step number:  42 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.666]
 [0.7  ]
 [0.666]
 [0.666]
 [0.666]
 [0.666]
 [0.666]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.666]
 [0.7  ]
 [0.666]
 [0.666]
 [0.666]
 [0.666]
 [0.666]]
actor:  0 policy actor:  0  step number:  50 total reward:  0.02999999999999936  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.8097800000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Starting evaluation
maxi score, test score, baseline:  -0.8097800000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8097800000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.8097800000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
maxi score, test score, baseline:  -0.8097800000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.691]
 [0.828]
 [0.563]
 [0.708]
 [0.464]
 [0.459]
 [0.581]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.691]
 [0.828]
 [0.563]
 [0.708]
 [0.464]
 [0.459]
 [0.581]]
maxi score, test score, baseline:  -0.8097800000000002 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]]
actor:  0 policy actor:  0  step number:  34 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.904]
 [0.904]
 [0.904]
 [0.904]
 [0.904]
 [0.904]
 [0.904]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.904]
 [0.904]
 [0.904]
 [0.904]
 [0.904]
 [0.904]
 [0.904]]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7869800000000001 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.74464 -0.24200000000000008 -0.24200000000000008
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.73584 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.311]
 [0.37 ]
 [0.311]
 [0.311]
 [0.311]
 [0.311]
 [0.311]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.311]
 [0.37 ]
 [0.311]
 [0.311]
 [0.311]
 [0.311]
 [0.311]]
actor:  0 policy actor:  0  step number:  55 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7334000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7334000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7334000000000002 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.324]
 [0.398]
 [0.296]
 [0.294]
 [0.315]
 [0.314]
 [0.308]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.324]
 [0.398]
 [0.296]
 [0.294]
 [0.315]
 [0.314]
 [0.308]]
maxi score, test score, baseline:  -0.7334000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7334000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7334000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7334000000000002 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.584]
 [0.689]
 [0.607]
 [0.559]
 [0.676]
 [0.562]
 [0.582]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.584]
 [0.689]
 [0.607]
 [0.559]
 [0.676]
 [0.562]
 [0.582]]
siam score:  -0.78163147
maxi score, test score, baseline:  -0.7334000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7334000000000002 0.6445 0.6445
Printing some Q and Qe and total Qs values:  [[1.   ]
 [0.229]
 [0.229]
 [0.229]
 [0.229]
 [0.229]
 [0.229]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.   ]
 [0.229]
 [0.229]
 [0.229]
 [0.229]
 [0.229]
 [0.229]]
maxi score, test score, baseline:  -0.7334 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.47999999999999987  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7304400000000001 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.08 ]
 [0.106]
 [0.087]
 [0.081]
 [0.085]
 [0.082]
 [0.084]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.08 ]
 [0.106]
 [0.087]
 [0.081]
 [0.085]
 [0.082]
 [0.084]]
siam score:  -0.7880806
maxi score, test score, baseline:  -0.7304400000000001 0.6445 0.6445
maxi score, test score, baseline:  -0.7304400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.73044 0.6445 0.6445
maxi score, test score, baseline:  -0.73044 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.73044 0.6445 0.6445
maxi score, test score, baseline:  -0.73044 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.73044 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.73044 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.73044 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7279 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7279 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7279 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.04 ]
 [0.105]
 [0.043]
 [0.046]
 [0.045]
 [0.042]
 [0.04 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.04 ]
 [0.105]
 [0.043]
 [0.046]
 [0.045]
 [0.042]
 [0.04 ]]
maxi score, test score, baseline:  -0.7279 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7279 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7279 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.486]
 [0.573]
 [0.461]
 [0.513]
 [0.567]
 [0.456]
 [0.474]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.486]
 [0.573]
 [0.461]
 [0.513]
 [0.567]
 [0.456]
 [0.474]]
Printing some Q and Qe and total Qs values:  [[0.1  ]
 [0.172]
 [0.112]
 [0.1  ]
 [0.094]
 [0.102]
 [0.103]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.1  ]
 [0.172]
 [0.112]
 [0.1  ]
 [0.094]
 [0.102]
 [0.103]]
maxi score, test score, baseline:  -0.7279 0.6445 0.6445
maxi score, test score, baseline:  -0.7279 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7279 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7279 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7279000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7279000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7279000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7279000000000001 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.433]
 [0.51 ]
 [0.489]
 [0.503]
 [0.371]
 [0.36 ]
 [0.357]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.433]
 [0.51 ]
 [0.489]
 [0.503]
 [0.371]
 [0.36 ]
 [0.357]]
maxi score, test score, baseline:  -0.7303200000000001 0.6445 0.6445
actor:  0 policy actor:  0  step number:  38 total reward:  0.0699999999999994  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7281799999999999 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.72818 0.6445 0.6445
Printing some Q and Qe and total Qs values:  [[0.45 ]
 [0.508]
 [0.378]
 [0.401]
 [0.399]
 [0.383]
 [0.396]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.45 ]
 [0.508]
 [0.378]
 [0.401]
 [0.399]
 [0.383]
 [0.396]]
maxi score, test score, baseline:  -0.72818 0.6445 0.6445
probs:  [1.0]
siam score:  -0.7847588
maxi score, test score, baseline:  -0.72818 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.502]
 [0.515]
 [0.486]
 [0.521]
 [0.542]
 [0.503]
 [0.519]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.502]
 [0.515]
 [0.486]
 [0.521]
 [0.542]
 [0.503]
 [0.519]]
maxi score, test score, baseline:  -0.72818 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.72818 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7281799999999999 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7281799999999999 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7281799999999999 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7281799999999999 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  50 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7255600000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7255600000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.72524 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.72524 0.6445 0.6445
Printing some Q and Qe and total Qs values:  [[0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]]
actor:  0 policy actor:  0  step number:  37 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.72494 0.6445 0.6445
maxi score, test score, baseline:  -0.72494 0.6445 0.6445
maxi score, test score, baseline:  -0.72494 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.72494 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  43 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.72242 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.72242 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.72242 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.71708 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7197600000000002 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.775]
 [0.797]
 [0.727]
 [0.705]
 [0.748]
 [0.696]
 [0.73 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.775]
 [0.797]
 [0.727]
 [0.705]
 [0.748]
 [0.696]
 [0.73 ]]
actor:  0 policy actor:  0  step number:  43 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7172000000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
siam score:  -0.786929
actor:  0 policy actor:  0  step number:  38 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.71184 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.71184 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.462]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.462]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7091200000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7091200000000001 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.567]
 [0.567]
 [0.828]
 [0.567]
 [0.567]
 [0.567]
 [0.567]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.567]
 [0.567]
 [0.828]
 [0.567]
 [0.567]
 [0.567]
 [0.567]]
maxi score, test score, baseline:  -0.7091200000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7091200000000001 0.6445 0.6445
probs:  [1.0]
siam score:  -0.77842087
maxi score, test score, baseline:  -0.7091200000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7091200000000001 0.6445 0.6445
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.7091200000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7091200000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  61 total reward:  0.01999999999999935  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.70708 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.70708 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.337]
 [0.565]
 [0.372]
 [0.329]
 [0.336]
 [0.371]
 [0.328]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.337]
 [0.565]
 [0.372]
 [0.329]
 [0.336]
 [0.371]
 [0.328]]
maxi score, test score, baseline:  -0.70708 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.70708 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.215]
 [0.233]
 [0.223]
 [0.224]
 [0.222]
 [0.221]
 [0.216]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.215]
 [0.233]
 [0.223]
 [0.224]
 [0.222]
 [0.221]
 [0.216]]
Printing some Q and Qe and total Qs values:  [[0.191]
 [0.442]
 [0.209]
 [0.16 ]
 [0.191]
 [0.191]
 [0.532]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.191]
 [0.442]
 [0.209]
 [0.16 ]
 [0.191]
 [0.191]
 [0.532]]
maxi score, test score, baseline:  -0.7092600000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7066 0.6445 0.6445
maxi score, test score, baseline:  -0.7066 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7066 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7066 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7066 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7066 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7066 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.7066 0.6445 0.6445
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.397]
 [0.487]
 [0.636]
 [0.45 ]
 [0.404]
 [0.422]
 [0.478]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.397]
 [0.487]
 [0.636]
 [0.45 ]
 [0.404]
 [0.422]
 [0.478]]
Printing some Q and Qe and total Qs values:  [[0.394]
 [0.431]
 [0.622]
 [0.45 ]
 [0.404]
 [0.422]
 [0.432]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.394]
 [0.431]
 [0.622]
 [0.45 ]
 [0.404]
 [0.422]
 [0.432]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7035399999999999 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  46 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.70362 0.6445 0.6445
maxi score, test score, baseline:  -0.70362 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.70362 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  41 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.7004200000000002 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.529]
 [0.597]
 [0.506]
 [0.497]
 [0.523]
 [0.55 ]
 [0.476]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.529]
 [0.597]
 [0.506]
 [0.497]
 [0.523]
 [0.55 ]
 [0.476]]
Printing some Q and Qe and total Qs values:  [[0.76]
 [0.76]
 [0.76]
 [0.76]
 [0.76]
 [0.76]
 [0.76]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.76]
 [0.76]
 [0.76]
 [0.76]
 [0.76]
 [0.76]
 [0.76]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.69796 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.086]
 [0.101]
 [0.086]
 [0.086]
 [0.086]
 [0.086]
 [0.086]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.086]
 [0.101]
 [0.086]
 [0.086]
 [0.086]
 [0.086]
 [0.086]]
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
Printing some Q and Qe and total Qs values:  [[0.213]
 [0.226]
 [0.212]
 [0.215]
 [0.211]
 [0.211]
 [0.217]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.213]
 [0.226]
 [0.212]
 [0.215]
 [0.211]
 [0.211]
 [0.217]]
siam score:  -0.7725573
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
siam score:  -0.7780739
siam score:  -0.7761955
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.69488 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.35]
 [0.35]
 [0.35]
 [0.35]
 [0.35]
 [0.35]
 [0.35]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.35]
 [0.35]
 [0.35]
 [0.35]
 [0.35]
 [0.35]
 [0.35]]
actor:  0 policy actor:  0  step number:  42 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.881]
 [0.827]
 [0.819]
 [0.905]
 [0.761]
 [0.761]
 [0.761]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.881]
 [0.827]
 [0.819]
 [0.905]
 [0.761]
 [0.761]
 [0.761]]
actor:  0 policy actor:  0  step number:  45 total reward:  0.01999999999999935  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6905000000000001 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.799]
 [0.87 ]
 [0.799]
 [0.799]
 [0.799]
 [0.799]
 [0.799]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.799]
 [0.87 ]
 [0.799]
 [0.799]
 [0.799]
 [0.799]
 [0.799]]
maxi score, test score, baseline:  -0.6905000000000001 0.6445 0.6445
actor:  0 policy actor:  0  step number:  35 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6849800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6849800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6849800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6849800000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6796400000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  46 total reward:  0.12999999999999945  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.67738 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.192]
 [0.376]
 [0.192]
 [0.192]
 [0.192]
 [0.192]
 [0.192]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.192]
 [0.376]
 [0.192]
 [0.192]
 [0.192]
 [0.192]
 [0.192]]
siam score:  -0.7711527
maxi score, test score, baseline:  -0.67738 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.67738 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.67738 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.67738 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.67738 0.6445 0.6445
actor:  0 policy actor:  0  step number:  36 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  41 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.66988 0.6445 0.6445
maxi score, test score, baseline:  -0.66988 0.6445 0.6445
maxi score, test score, baseline:  -0.66988 0.6445 0.6445
maxi score, test score, baseline:  -0.66988 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.531]
 [0.807]
 [0.554]
 [0.554]
 [0.626]
 [0.626]
 [0.626]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.531]
 [0.807]
 [0.554]
 [0.554]
 [0.626]
 [0.626]
 [0.626]]
maxi score, test score, baseline:  -0.66988 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6762400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6762400000000001 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.022]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.022]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]]
maxi score, test score, baseline:  -0.6794200000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6794200000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.68188 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.043]
 [0.064]
 [0.037]
 [0.039]
 [0.04 ]
 [0.045]
 [0.041]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.043]
 [0.064]
 [0.037]
 [0.039]
 [0.04 ]
 [0.045]
 [0.041]]
maxi score, test score, baseline:  -0.68188 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.67904 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  43 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.7707542
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.08999999999999941  reward:  1.0 rdn_beta:  0.0
siam score:  -0.76911426
actor:  0 policy actor:  0  step number:  37 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6807000000000001 0.6445 0.6445
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.082 0.449 0.082 0.163 0.061 0.102 0.061]
Printing some Q and Qe and total Qs values:  [[0.038]
 [0.067]
 [0.042]
 [0.041]
 [0.039]
 [0.041]
 [0.043]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.038]
 [0.067]
 [0.042]
 [0.041]
 [0.039]
 [0.041]
 [0.043]]
maxi score, test score, baseline:  -0.6835400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6835400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6835400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6835400000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.68308 0.6445 0.6445
maxi score, test score, baseline:  -0.68308 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.15 ]
 [0.217]
 [0.152]
 [0.154]
 [0.153]
 [0.153]
 [0.149]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.15 ]
 [0.217]
 [0.152]
 [0.154]
 [0.153]
 [0.153]
 [0.149]]
maxi score, test score, baseline:  -0.68288 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.68288 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6800600000000001 0.6445 0.6445
probs:  [1.0]
siam score:  -0.7802182
Printing some Q and Qe and total Qs values:  [[ 0.005]
 [ 0.07 ]
 [ 0.009]
 [ 0.004]
 [-0.   ]
 [ 0.001]
 [-0.006]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.005]
 [ 0.07 ]
 [ 0.009]
 [ 0.004]
 [-0.   ]
 [ 0.001]
 [-0.006]]
maxi score, test score, baseline:  -0.6800600000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6800600000000001 0.6445 0.6445
maxi score, test score, baseline:  -0.6800600000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6800600000000001 0.6445 0.6445
maxi score, test score, baseline:  -0.6800600000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6800600000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6800600000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  44 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.67744 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  41 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6750000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6750000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6750000000000002 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.421]
 [0.736]
 [0.421]
 [0.422]
 [0.421]
 [0.421]
 [0.421]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.421]
 [0.736]
 [0.421]
 [0.422]
 [0.421]
 [0.421]
 [0.421]]
maxi score, test score, baseline:  -0.6750000000000002 0.6445 0.6445
siam score:  -0.7896612
actor:  0 policy actor:  0  step number:  35 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6747000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6747000000000001 0.6445 0.6445
maxi score, test score, baseline:  -0.6747000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6747000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6747000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6747000000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6719600000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6719600000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.67234 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.67234 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.253]
 [0.341]
 [0.196]
 [0.205]
 [0.208]
 [0.204]
 [0.203]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.253]
 [0.341]
 [0.196]
 [0.205]
 [0.208]
 [0.204]
 [0.203]]
Printing some Q and Qe and total Qs values:  [[0.488]
 [0.575]
 [0.488]
 [0.488]
 [0.488]
 [0.488]
 [0.488]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.488]
 [0.575]
 [0.488]
 [0.488]
 [0.488]
 [0.488]
 [0.488]]
maxi score, test score, baseline:  -0.67234 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.67234 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.67234 0.6445 0.6445
maxi score, test score, baseline:  -0.67234 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.67234 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.67234 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.67234 0.6445 0.6445
maxi score, test score, baseline:  -0.67234 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  49 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6671800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6671800000000001 0.6445 0.6445
actor:  0 policy actor:  0  step number:  39 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6646200000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.207]
 [0.292]
 [0.207]
 [0.207]
 [0.207]
 [0.207]
 [0.207]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.207]
 [0.292]
 [0.207]
 [0.207]
 [0.207]
 [0.207]
 [0.207]]
maxi score, test score, baseline:  -0.6621400000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6621400000000002 0.6445 0.6445
maxi score, test score, baseline:  -0.6621400000000002 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]]
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.142]
 [0.018]
 [0.042]
 [0.018]
 [0.018]
 [0.069]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.018]
 [0.142]
 [0.018]
 [0.042]
 [0.018]
 [0.018]
 [0.069]]
maxi score, test score, baseline:  -0.6621400000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  55 total reward:  0.11999999999999944  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.367]
 [0.353]
 [0.709]
 [0.394]
 [0.394]
 [0.413]
 [0.57 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.367]
 [0.353]
 [0.709]
 [0.394]
 [0.394]
 [0.413]
 [0.57 ]]
Printing some Q and Qe and total Qs values:  [[0.805]
 [0.944]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.805]
 [0.944]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6569400000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6569400000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6569400000000002 0.6445 0.6445
maxi score, test score, baseline:  -0.6569400000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6534600000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6534600000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6507800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6507800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6507800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6507800000000001 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.41 ]
 [0.369]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.41 ]
 [0.369]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]]
maxi score, test score, baseline:  -0.6507800000000001 0.6445 0.6445
maxi score, test score, baseline:  -0.6507800000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  43 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
siam score:  -0.7936265
siam score:  -0.79537386
maxi score, test score, baseline:  -0.6502400000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  44 total reward:  0.12999999999999945  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6479800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6479800000000001 0.6445 0.6445
actor:  0 policy actor:  0  step number:  33 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6483000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6483000000000001 0.6445 0.6445
actor:  0 policy actor:  0  step number:  38 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6458400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6458400000000001 0.6445 0.6445
maxi score, test score, baseline:  -0.6458400000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.64042 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.64042 0.6445 0.6445
probs:  [1.0]
siam score:  -0.79417807
maxi score, test score, baseline:  -0.64042 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6425600000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6425600000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6394000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6394000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6394000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6394000000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6368400000000001 0.6445 0.6445
maxi score, test score, baseline:  -0.6368400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6368400000000001 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]]
maxi score, test score, baseline:  -0.6368400000000001 0.6445 0.6445
probs:  [1.0]
siam score:  -0.7958028
siam score:  -0.79678786
actor:  0 policy actor:  0  step number:  36 total reward:  0.34999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6341400000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.05999999999999939  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6320200000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6296 0.6445 0.6445
probs:  [1.0]
siam score:  -0.79920167
Printing some Q and Qe and total Qs values:  [[0.778]
 [0.666]
 [0.365]
 [0.681]
 [0.615]
 [0.476]
 [0.481]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.778]
 [0.666]
 [0.365]
 [0.681]
 [0.615]
 [0.476]
 [0.481]]
maxi score, test score, baseline:  -0.6296 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6296 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6215400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6215400000000001 0.6445 0.6445
maxi score, test score, baseline:  -0.6215400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6215400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6215400000000001 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.819]
 [0.79 ]
 [0.801]
 [0.76 ]
 [0.903]
 [0.903]
 [0.797]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.819]
 [0.79 ]
 [0.801]
 [0.76 ]
 [0.903]
 [0.903]
 [0.797]]
siam score:  -0.80365235
maxi score, test score, baseline:  -0.6215400000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  46 total reward:  0.08999999999999952  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6242200000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6242200000000002 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.48 ]
 [0.811]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.48 ]
 [0.811]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]]
maxi score, test score, baseline:  -0.6242200000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6242200000000001 0.6445 0.6445
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6237000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6237000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6237000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6237000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6265000000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]]
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]]
maxi score, test score, baseline:  -0.6240600000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.62358 0.6445 0.6445
maxi score, test score, baseline:  -0.62358 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6235800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6235800000000001 0.6445 0.6445
actor:  0 policy actor:  0  step number:  43 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.363]
 [0.357]
 [0.363]
 [0.363]
 [0.363]
 [0.363]
 [0.363]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.363]
 [0.357]
 [0.363]
 [0.363]
 [0.363]
 [0.363]
 [0.363]]
maxi score, test score, baseline:  -0.62082 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.62082 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.62082 0.6445 0.6445
probs:  [1.0]
siam score:  -0.802569
maxi score, test score, baseline:  -0.62082 0.6445 0.6445
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.422]
 [0.263]
 [0.263]
 [0.263]
 [0.263]
 [0.263]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.422]
 [0.422]
 [0.263]
 [0.263]
 [0.263]
 [0.263]
 [0.263]]
maxi score, test score, baseline:  -0.62082 0.6445 0.6445
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.5907],
        [-0.7292],
        [ 0.2354],
        [-0.3015],
        [ 0.8602],
        [ 0.1344],
        [-0.4591],
        [-0.5921],
        [-0.7292],
        [ 0.3676]], dtype=torch.float64)
-0.106157551797 -0.6968436436592297
-0.048519850599000006 -0.7777391727617556
-0.107327830599 0.1280577161298756
-0.145559551797 -0.4470752737704933
-0.06831985059899999 0.7919261726112248
-0.048519850599000006 0.08585888722119063
-0.145559551797 -0.6046527607443479
-0.08675157179700001 -0.6788724982087616
-0.048519850599000006 -0.7777391727617556
-0.048519850599000006 0.31906936594973845
Printing some Q and Qe and total Qs values:  [[0.355]
 [0.471]
 [0.275]
 [0.251]
 [0.307]
 [0.369]
 [0.288]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.355]
 [0.471]
 [0.275]
 [0.251]
 [0.307]
 [0.369]
 [0.288]]
maxi score, test score, baseline:  -0.62082 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.62082 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6121800000000001 0.6445 0.6445
maxi score, test score, baseline:  -0.6121800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6121800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6121800000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
siam score:  -0.7998256
actor:  0 policy actor:  0  step number:  33 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6016800000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  45 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.6022600000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6022600000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6022600000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.6022600000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.59914 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5959200000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5953 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5953 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5953 0.6445 0.6445
maxi score, test score, baseline:  -0.5953 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.5499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8048246
maxi score, test score, baseline:  -0.5892400000000002 0.6445 0.6445
probs:  [1.0]
siam score:  -0.80703664
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5890200000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.08999999999999941  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5868400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5868400000000001 0.6445 0.6445
Printing some Q and Qe and total Qs values:  [[0.986]
 [0.707]
 [0.986]
 [0.986]
 [0.986]
 [0.986]
 [0.986]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.986]
 [0.707]
 [0.986]
 [0.986]
 [0.986]
 [0.986]
 [0.986]]
actor:  0 policy actor:  0  step number:  43 total reward:  0.03999999999999937  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5847600000000002 0.6445 0.6445
maxi score, test score, baseline:  -0.5847600000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5847600000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.078]
 [0.164]
 [0.078]
 [0.103]
 [0.078]
 [0.078]
 [0.106]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.078]
 [0.164]
 [0.078]
 [0.103]
 [0.078]
 [0.078]
 [0.106]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5758800000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5699400000000002 0.6445 0.6445
probs:  [1.0]
siam score:  -0.81394666
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5639600000000002 0.6445 0.6445
probs:  [1.0]
siam score:  -0.8108463
maxi score, test score, baseline:  -0.5639600000000002 0.6445 0.6445
probs:  [1.0]
siam score:  -0.8123662
actor:  0 policy actor:  0  step number:  35 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5583600000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5557000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5557000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5557000000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5557200000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5557200000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5553000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5553000000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5553000000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.20999999999999963  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5528800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5528800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5528800000000001 0.6445 0.6445
maxi score, test score, baseline:  -0.5528800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5528800000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5499000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5499000000000002 0.6445 0.6445
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5469000000000003 0.6445 0.6445
maxi score, test score, baseline:  -0.5469000000000003 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5469000000000003 0.6445 0.6445
maxi score, test score, baseline:  -0.5469000000000003 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5469000000000003 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5469000000000002 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.03 ]
 [0.099]
 [0.028]
 [0.029]
 [0.034]
 [0.018]
 [0.031]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.03 ]
 [0.099]
 [0.028]
 [0.029]
 [0.034]
 [0.018]
 [0.031]]
maxi score, test score, baseline:  -0.5469000000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5469000000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.11999999999999944  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5442800000000001 0.6445 0.6445
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.5442800000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5442800000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.475]
 [0.55 ]
 [0.318]
 [0.37 ]
 [0.283]
 [0.288]
 [0.284]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.475]
 [0.55 ]
 [0.318]
 [0.37 ]
 [0.283]
 [0.288]
 [0.284]]
siam score:  -0.8058197
siam score:  -0.8061855
maxi score, test score, baseline:  -0.5438000000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5434000000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5402400000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5344800000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5344800000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5367600000000001 0.6445 0.6445
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.061 0.592 0.041 0.245 0.02  0.02  0.02 ]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5341 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.412]
 [0.401]
 [0.411]
 [0.398]
 [0.388]
 [0.395]
 [0.4  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.412]
 [0.401]
 [0.411]
 [0.398]
 [0.388]
 [0.395]
 [0.4  ]]
maxi score, test score, baseline:  -0.5287800000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.81054044
maxi score, test score, baseline:  -0.5259000000000001 0.6445 0.6445
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5228600000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5228600000000002 0.6445 0.6445
maxi score, test score, baseline:  -0.5253600000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5253600000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5253600000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.52536 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5221400000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5242000000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5213800000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5213800000000002 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5129800000000002 0.6445 0.6445
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  43 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.5047200000000002 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5068400000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.5068400000000001 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  46 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.4983200000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.4983200000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.4983200000000001 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.4983200000000001 0.6445 0.6445
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.592 0.143 0.02  0.082 0.041 0.02  0.102]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Starting evaluation
siam score:  -0.80909055
maxi score, test score, baseline:  -0.49810000000000015 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.49872000000000016 0.6445 0.6445
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]]
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]]
maxi score, test score, baseline:  -0.49872000000000016 0.6445 0.6445
probs:  [1.0]
maxi score, test score, baseline:  -0.49872000000000005 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.44294000000000017 0.6445 0.6445
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.43914000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.43914000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.43914000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.43914000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.43914000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.43914000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.43608000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.43362000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.43362000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.4327400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.4327400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.426]
 [0.54 ]
 [0.461]
 [0.462]
 [0.438]
 [0.432]
 [0.442]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.426]
 [0.54 ]
 [0.461]
 [0.462]
 [0.438]
 [0.432]
 [0.442]]
Printing some Q and Qe and total Qs values:  [[0.415]
 [0.478]
 [0.43 ]
 [0.511]
 [0.599]
 [0.424]
 [0.468]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.415]
 [0.478]
 [0.43 ]
 [0.511]
 [0.599]
 [0.424]
 [0.468]]
Printing some Q and Qe and total Qs values:  [[0.415]
 [0.409]
 [0.41 ]
 [0.406]
 [0.412]
 [0.409]
 [0.404]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.415]
 [0.409]
 [0.41 ]
 [0.406]
 [0.412]
 [0.409]
 [0.404]]
siam score:  -0.82375824
maxi score, test score, baseline:  -0.4296800000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
siam score:  -0.8224898
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.4241400000000002 0.6759999999999999 0.6759999999999999
siam score:  -0.82294846
maxi score, test score, baseline:  -0.4241400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.4241400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.3099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.42422000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.407]
 [0.728]
 [0.407]
 [0.403]
 [0.407]
 [0.407]
 [0.407]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.407]
 [0.728]
 [0.407]
 [0.403]
 [0.407]
 [0.407]
 [0.407]]
maxi score, test score, baseline:  -0.4242200000000001 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  43 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.5399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.42090000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.057]
 [0.125]
 [0.054]
 [0.058]
 [0.053]
 [0.051]
 [0.058]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.057]
 [0.125]
 [0.054]
 [0.058]
 [0.053]
 [0.051]
 [0.058]]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.4119400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.4089200000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.767]
 [0.693]
 [0.693]
 [0.693]
 [0.693]
 [0.693]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.693]
 [0.767]
 [0.693]
 [0.693]
 [0.693]
 [0.693]
 [0.693]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.40910000000000013 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.41116000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.41074000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.373]
 [0.567]
 [0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.373]
 [0.567]
 [0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.142]
 [0.254]
 [0.142]
 [0.142]
 [0.142]
 [0.142]
 [0.142]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.142]
 [0.254]
 [0.142]
 [0.142]
 [0.142]
 [0.142]
 [0.142]]
maxi score, test score, baseline:  -0.4081800000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.4107600000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.4047000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.4047000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.4047000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.401]
 [0.367]
 [0.81 ]
 [0.436]
 [0.467]
 [0.467]
 [0.467]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.401]
 [0.367]
 [0.81 ]
 [0.436]
 [0.467]
 [0.467]
 [0.467]]
maxi score, test score, baseline:  -0.40168000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.374]
 [0.459]
 [0.374]
 [0.374]
 [0.374]
 [0.374]
 [0.374]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.374]
 [0.459]
 [0.374]
 [0.374]
 [0.374]
 [0.374]
 [0.374]]
Printing some Q and Qe and total Qs values:  [[0.484]
 [0.843]
 [0.508]
 [0.486]
 [0.387]
 [0.48 ]
 [0.601]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.484]
 [0.843]
 [0.508]
 [0.486]
 [0.387]
 [0.48 ]
 [0.601]]
maxi score, test score, baseline:  -0.39918000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.39918000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [0.924]
 [0.86 ]
 [0.86 ]
 [0.86 ]
 [0.86 ]
 [0.989]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.88 ]
 [0.924]
 [0.86 ]
 [0.86 ]
 [0.86 ]
 [0.86 ]
 [0.989]]
actor:  0 policy actor:  0  step number:  36 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3966000000000002 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.3966000000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3937200000000002 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.3937200000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3904400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3904400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.38738000000000017 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  30 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.405]
 [0.758]
 [0.423]
 [0.395]
 [0.396]
 [0.398]
 [0.44 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.405]
 [0.758]
 [0.423]
 [0.395]
 [0.396]
 [0.398]
 [0.44 ]]
maxi score, test score, baseline:  -0.38718000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38718000000000014 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.38968000000000014 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.38968000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38968000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3896800000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.38696000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38696000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38696000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38696000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38696000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38696000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3898400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.235]
 [0.248]
 [0.243]
 [0.233]
 [0.242]
 [0.242]
 [0.242]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.235]
 [0.248]
 [0.243]
 [0.233]
 [0.242]
 [0.242]
 [0.242]]
maxi score, test score, baseline:  -0.3894400000000001 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.3894400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3894400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3894400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3915400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3915400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3915400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3915400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3884800000000001 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.3884800000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.649]
 [0.637]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.649]
 [0.637]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.348]
 [0.741]
 [0.348]
 [0.348]
 [0.348]
 [0.348]
 [0.348]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.348]
 [0.741]
 [0.348]
 [0.348]
 [0.348]
 [0.348]
 [0.348]]
Printing some Q and Qe and total Qs values:  [[0.36 ]
 [0.867]
 [0.36 ]
 [0.36 ]
 [0.36 ]
 [0.36 ]
 [0.36 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.36 ]
 [0.867]
 [0.36 ]
 [0.36 ]
 [0.36 ]
 [0.36 ]
 [0.36 ]]
maxi score, test score, baseline:  -0.38806000000000007 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38806000000000007 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.245]
 [0.558]
 [0.245]
 [0.245]
 [0.245]
 [0.245]
 [0.245]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.245]
 [0.558]
 [0.245]
 [0.245]
 [0.245]
 [0.245]
 [0.245]]
maxi score, test score, baseline:  -0.38806000000000007 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3856600000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.38502000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38502000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.38744000000000006 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.38170000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.38314000000000015 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.38580000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3891600000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.39252000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.39928000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.39928000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.869]
 [0.869]
 [0.422]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.869]
 [0.869]
 [0.422]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.83334386
maxi score, test score, baseline:  -0.3999600000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.40034000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.40100000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.40100000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.40100000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.40100000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]]
actor:  0 policy actor:  0  step number:  45 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.051]
 [0.154]
 [0.08 ]
 [0.058]
 [0.06 ]
 [0.051]
 [0.072]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.051]
 [0.154]
 [0.08 ]
 [0.058]
 [0.06 ]
 [0.051]
 [0.072]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.4019200000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.41 ]
 [0.442]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.41 ]
 [0.442]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]]
maxi score, test score, baseline:  -0.4019200000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  16 total reward:  0.7699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.40490000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.40812000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.40812000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.843]
 [0.79 ]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.843]
 [0.79 ]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]]
maxi score, test score, baseline:  -0.40812000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8276528
maxi score, test score, baseline:  -0.40988000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.69 ]
 [0.527]
 [0.373]
 [0.364]
 [0.37 ]
 [0.366]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.368]
 [0.69 ]
 [0.527]
 [0.373]
 [0.364]
 [0.37 ]
 [0.366]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.4164800000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
siam score:  -0.8283783
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.4165400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.418]
 [0.504]
 [0.418]
 [0.418]
 [0.418]
 [0.418]
 [0.418]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.418]
 [0.504]
 [0.418]
 [0.418]
 [0.418]
 [0.418]
 [0.418]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.41612000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.363]
 [0.49 ]
 [0.366]
 [0.396]
 [0.358]
 [0.396]
 [0.442]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.363]
 [0.49 ]
 [0.366]
 [0.396]
 [0.358]
 [0.396]
 [0.442]]
siam score:  -0.8326754
maxi score, test score, baseline:  -0.41612000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.41612000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.41612000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.641]
 [0.641]
 [0.641]
 [0.641]
 [0.544]
 [0.641]
 [0.641]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.641]
 [0.641]
 [0.641]
 [0.641]
 [0.544]
 [0.641]
 [0.641]]
maxi score, test score, baseline:  -0.41612000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  42 total reward:  0.1699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.40762000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.4018200000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.40182000000000007 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.40182000000000007 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.234]
 [0.417]
 [0.236]
 [0.27 ]
 [0.211]
 [0.236]
 [0.296]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.234]
 [0.417]
 [0.236]
 [0.27 ]
 [0.211]
 [0.236]
 [0.296]]
maxi score, test score, baseline:  -0.3962800000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.348]
 [0.502]
 [0.348]
 [0.348]
 [0.348]
 [0.348]
 [0.348]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.348]
 [0.502]
 [0.348]
 [0.348]
 [0.348]
 [0.348]
 [0.348]]
siam score:  -0.8368869
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.84166837
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3867800000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3867800000000002 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.38652000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38652000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38652000000000014 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.38652000000000014 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.38652000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38652000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.38652000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
siam score:  -0.8448457
maxi score, test score, baseline:  -0.38652000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.184]
 [0.184]
 [0.184]
 [0.184]
 [0.184]
 [0.184]
 [0.184]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.184]
 [0.184]
 [0.184]
 [0.184]
 [0.184]
 [0.184]
 [0.184]]
actor:  0 policy actor:  0  step number:  34 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.37964000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.37964000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.297]
 [0.297]
 [0.297]
 [0.297]
 [0.297]
 [0.297]
 [0.297]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.297]
 [0.297]
 [0.297]
 [0.297]
 [0.297]
 [0.297]
 [0.297]]
Printing some Q and Qe and total Qs values:  [[0.303]
 [0.65 ]
 [0.295]
 [0.299]
 [0.309]
 [0.3  ]
 [0.574]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.303]
 [0.65 ]
 [0.295]
 [0.299]
 [0.309]
 [0.3  ]
 [0.574]]
actor:  0 policy actor:  0  step number:  19 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3702000000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3697800000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3670800000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.34999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.36382000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.164]
 [0.417]
 [0.018]
 [0.293]
 [0.189]
 [0.001]
 [0.37 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.164]
 [0.417]
 [0.018]
 [0.293]
 [0.189]
 [0.001]
 [0.37 ]]
Printing some Q and Qe and total Qs values:  [[0.555]
 [0.555]
 [0.555]
 [0.555]
 [0.555]
 [0.555]
 [0.555]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.555]
 [0.555]
 [0.555]
 [0.555]
 [0.555]
 [0.555]
 [0.555]]
maxi score, test score, baseline:  -0.3638200000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3662000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.3662000000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.413]
 [0.448]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.413]
 [0.448]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]]
maxi score, test score, baseline:  -0.3662000000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.184 0.041 0.143 0.102 0.102 0.265 0.163]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3633600000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.163]
 [0.413]
 [0.439]
 [0.317]
 [0.182]
 [0.407]
 [0.327]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.163]
 [0.413]
 [0.439]
 [0.317]
 [0.182]
 [0.407]
 [0.327]]
maxi score, test score, baseline:  -0.3630800000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[ 0.1770],
        [-0.2637],
        [ 0.2484],
        [ 0.2424],
        [-0.5675],
        [ 0.8458],
        [ 0.1538],
        [-0.0000],
        [ 0.1377],
        [-0.6818]], dtype=torch.float64)
-0.06831985059899999 0.10872481047160319
-0.145559551797 -0.40926087121836474
-0.048519850599000006 0.19985065409668873
-0.048519850599000006 0.1938633503899344
-0.048519850599000006 -0.6160064922822373
-0.048519850599000006 0.7972564569754839
-0.048519850599000006 0.10529653816971611
-0.009899999999999349 -0.009899999999999349
-0.087921850599 0.0497668284213144
-0.048519850599000006 -0.7302996378593309
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.36288000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.36288000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.786]
 [0.821]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.786]
 [0.821]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]]
maxi score, test score, baseline:  -0.36530000000000024 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.3653000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.952]
 [0.77 ]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.952]
 [0.77 ]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]]
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.35956000000000016 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.35956000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.163 0.204 0.367 0.041 0.02  0.041 0.163]
actor:  0 policy actor:  0  step number:  40 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3599400000000001 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.3599400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.35994000000000015 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3567200000000001 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  40 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.35434000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.35434000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.35434000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.748]
 [0.748]
 [0.748]
 [0.748]
 [0.748]
 [0.748]
 [0.748]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.748]
 [0.748]
 [0.748]
 [0.748]
 [0.748]
 [0.748]
 [0.748]]
actor:  0 policy actor:  0  step number:  37 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.34916000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.34916000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.34812000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.34812000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.34816000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.34816000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.542]
 [0.505]
 [0.503]
 [0.521]
 [0.529]
 [0.509]
 [0.515]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.542]
 [0.505]
 [0.503]
 [0.521]
 [0.529]
 [0.509]
 [0.515]]
siam score:  -0.8519622
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.34240000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.34240000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  51 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.33468000000000014 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.33468000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.33468000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.33400000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.5499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.017]
 [0.022]
 [0.021]
 [0.017]
 [0.017]
 [0.017]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.017]
 [0.017]
 [0.022]
 [0.021]
 [0.017]
 [0.017]
 [0.017]]
maxi score, test score, baseline:  -0.3330200000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3298400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.79 ]
 [0.733]
 [0.835]
 [0.801]
 [0.721]
 [0.806]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.707]
 [0.79 ]
 [0.733]
 [0.835]
 [0.801]
 [0.721]
 [0.806]]
maxi score, test score, baseline:  -0.3298400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
UNIT TEST: sample policy line 217 mcts : [0.082 0.265 0.082 0.204 0.143 0.143 0.082]
maxi score, test score, baseline:  -0.32604000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.32604000000000016 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
siam score:  -0.84585905
maxi score, test score, baseline:  -0.31748000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.31464000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.239]
 [0.241]
 [0.239]
 [0.239]
 [0.239]
 [0.239]
 [0.239]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.239]
 [0.241]
 [0.239]
 [0.239]
 [0.239]
 [0.239]
 [0.239]]
siam score:  -0.845399
Printing some Q and Qe and total Qs values:  [[0.205]
 [0.438]
 [0.076]
 [0.403]
 [0.246]
 [0.035]
 [0.408]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.205]
 [0.438]
 [0.076]
 [0.403]
 [0.246]
 [0.035]
 [0.408]]
Printing some Q and Qe and total Qs values:  [[0.569]
 [0.82 ]
 [0.569]
 [0.49 ]
 [0.569]
 [0.569]
 [0.569]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.569]
 [0.82 ]
 [0.569]
 [0.49 ]
 [0.569]
 [0.569]
 [0.569]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3114000000000001 0.6759999999999999 0.6759999999999999
Printing some Q and Qe and total Qs values:  [[0.33 ]
 [0.704]
 [0.329]
 [0.322]
 [0.329]
 [0.329]
 [0.329]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.33 ]
 [0.704]
 [0.329]
 [0.322]
 [0.329]
 [0.329]
 [0.329]]
Printing some Q and Qe and total Qs values:  [[0.432]
 [0.697]
 [0.426]
 [0.411]
 [0.436]
 [0.436]
 [0.469]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.432]
 [0.697]
 [0.426]
 [0.411]
 [0.436]
 [0.436]
 [0.469]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.5299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3106800000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.31272000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.31272000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3157200000000001 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.3157200000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.31258000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.31258000000000014 0.6759999999999999 0.6759999999999999
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.31258000000000014 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3151200000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.925]
 [0.891]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.925]
 [0.891]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3112800000000001 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.3112800000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  46 total reward:  0.0699999999999994  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.31150000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.31150000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.3081600000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2993000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.29624000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.29624000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.29624000000000017 0.6759999999999999 0.6759999999999999
siam score:  -0.84267867
maxi score, test score, baseline:  -0.29624000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.29696000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  30 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.29434000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.399]
 [0.399]
 [0.263]
 [0.263]
 [0.263]
 [0.263]
 [0.263]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.399]
 [0.399]
 [0.263]
 [0.263]
 [0.263]
 [0.263]
 [0.263]]
Printing some Q and Qe and total Qs values:  [[0.178]
 [0.178]
 [0.178]
 [0.178]
 [0.178]
 [0.178]
 [0.178]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.178]
 [0.178]
 [0.178]
 [0.178]
 [0.178]
 [0.178]
 [0.178]]
maxi score, test score, baseline:  -0.29434000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.29412000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.29412000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2935800000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.2935800000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.47999999999999987  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.29334000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.29634000000000016 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.29634000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.29634000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.2985200000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.089]
 [0.292]
 [0.089]
 [0.138]
 [0.089]
 [0.089]
 [0.186]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.089]
 [0.292]
 [0.089]
 [0.138]
 [0.089]
 [0.089]
 [0.186]]
maxi score, test score, baseline:  -0.3011200000000002 0.6759999999999999 0.6759999999999999
Printing some Q and Qe and total Qs values:  [[0.393]
 [0.554]
 [0.394]
 [0.401]
 [0.399]
 [0.397]
 [0.406]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.393]
 [0.554]
 [0.394]
 [0.401]
 [0.399]
 [0.397]
 [0.406]]
maxi score, test score, baseline:  -0.3011200000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.29646000000000017 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.29646000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.29646000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.29596000000000017 0.6759999999999999 0.6759999999999999
Printing some Q and Qe and total Qs values:  [[0.914]
 [0.029]
 [0.029]
 [0.029]
 [0.029]
 [0.029]
 [0.029]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.914]
 [0.029]
 [0.029]
 [0.029]
 [0.029]
 [0.029]
 [0.029]]
maxi score, test score, baseline:  -0.29596000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.29596000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2962000000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.2962000000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.938]
 [0.908]
 [0.856]
 [0.707]
 [0.856]
 [0.856]
 [0.856]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.938]
 [0.908]
 [0.856]
 [0.707]
 [0.856]
 [0.856]
 [0.856]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.6  ]
 [0.886]
 [0.6  ]
 [0.6  ]
 [0.6  ]
 [0.6  ]
 [0.6  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.6  ]
 [0.886]
 [0.6  ]
 [0.6  ]
 [0.6  ]
 [0.6  ]
 [0.6  ]]
Printing some Q and Qe and total Qs values:  [[0.913]
 [0.819]
 [0.375]
 [0.628]
 [0.627]
 [0.753]
 [0.632]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.913]
 [0.819]
 [0.375]
 [0.628]
 [0.627]
 [0.753]
 [0.632]]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.28044000000000013 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.28044000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.28044000000000013 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.28288000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.28288000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.28288000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.28288000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2797000000000001 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  37 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.27974000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.27974000000000016 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.27974000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.27974000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.404]
 [0.586]
 [0.405]
 [0.426]
 [0.402]
 [0.4  ]
 [0.601]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.404]
 [0.586]
 [0.405]
 [0.426]
 [0.402]
 [0.4  ]
 [0.601]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]]
maxi score, test score, baseline:  -0.2817000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.2817000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2787200000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.28144000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.28388000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.28388000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.86246157
UNIT TEST: sample policy line 217 mcts : [0.143 0.327 0.122 0.143 0.082 0.082 0.102]
siam score:  -0.86132246
actor:  0 policy actor:  0  step number:  38 total reward:  0.24999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.27724000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2737600000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.2737600000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  45 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.27150000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.27150000000000013 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.27150000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.27150000000000013 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  39 total reward:  0.0799999999999994  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.2693400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.26912000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.26912000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.26912000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.03999999999999937  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2670400000000001 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.2670400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
siam score:  -0.86195177
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
siam score:  -0.86432815
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2627200000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.634]
 [0.74 ]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.634]
 [0.74 ]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]]
maxi score, test score, baseline:  -0.2627200000000001 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.2627200000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[ 0.015]
 [ 0.118]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.015]
 [ 0.118]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]]
maxi score, test score, baseline:  -0.2652800000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.26814000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.26814000000000016 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2651000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  41 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2625000000000001 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.25636000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.898]
 [0.885]
 [0.732]
 [0.803]
 [0.803]
 [0.847]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.601]
 [0.898]
 [0.885]
 [0.732]
 [0.803]
 [0.803]
 [0.847]]
actor:  0 policy actor:  0  step number:  31 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2590000000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.605]
 [0.797]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.605]
 [0.797]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]]
actor:  0 policy actor:  0  step number:  45 total reward:  0.03999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.25962000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8515792
maxi score, test score, baseline:  -0.2592600000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.26182000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.768]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.617]
 [0.768]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]]
maxi score, test score, baseline:  -0.2646600000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.2646600000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2614400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.2614400000000002 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.2614400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.26062000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2581000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.2581000000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.25810000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
siam score:  -0.8667869
Printing some Q and Qe and total Qs values:  [[0.789]
 [0.843]
 [0.789]
 [0.789]
 [0.789]
 [0.789]
 [0.789]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.789]
 [0.843]
 [0.789]
 [0.789]
 [0.789]
 [0.789]
 [0.789]]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.25270000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.25270000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.25270000000000015 0.6759999999999999 0.6759999999999999
maxi score, test score, baseline:  -0.25270000000000015 0.6759999999999999 0.6759999999999999
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.8660176
maxi score, test score, baseline:  -0.24910000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.24910000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2433400000000001 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.24334000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.24334000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.24326000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.24326000000000014 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[ 0.018]
 [ 0.045]
 [ 0.046]
 [-0.009]
 [-0.006]
 [ 0.062]
 [ 0.098]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.018]
 [ 0.045]
 [ 0.046]
 [-0.009]
 [-0.006]
 [ 0.062]
 [ 0.098]]
maxi score, test score, baseline:  -0.24326000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.24326000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2406400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.2406400000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.0799999999999994  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.23782000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.23968000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.23968000000000017 0.6759999999999999 0.6759999999999999
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2334000000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.094]
 [0.351]
 [0.107]
 [0.192]
 [0.14 ]
 [0.107]
 [0.33 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.094]
 [0.351]
 [0.107]
 [0.192]
 [0.14 ]
 [0.107]
 [0.33 ]]
maxi score, test score, baseline:  -0.23312000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
siam score:  -0.85710984
actor:  0 policy actor:  0  step number:  34 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.698]
 [0.797]
 [0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.709]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.698]
 [0.797]
 [0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.709]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.2295800000000002 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  40 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.23048000000000016 0.6759999999999999 0.6759999999999999
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.23348000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
siam score:  -0.85889983
actor:  0 policy actor:  0  step number:  28 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.23042000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.23042000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.547]
 [0.727]
 [0.545]
 [0.537]
 [0.536]
 [0.55 ]
 [0.559]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.547]
 [0.727]
 [0.545]
 [0.537]
 [0.536]
 [0.55 ]
 [0.559]]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.23050000000000015 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.22528000000000017 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.85296065
maxi score, test score, baseline:  -0.22492000000000018 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Starting evaluation
maxi score, test score, baseline:  -0.22302000000000013 0.6759999999999999 0.6759999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.717]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.717]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]]
Printing some Q and Qe and total Qs values:  [[0.295]
 [0.306]
 [0.733]
 [0.381]
 [0.31 ]
 [0.324]
 [0.406]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.295]
 [0.306]
 [0.733]
 [0.381]
 [0.31 ]
 [0.324]
 [0.406]]
actor:  0 policy actor:  0  step number:  48 total reward:  0.12999999999999945  reward:  1.0 rdn_beta:  0.0
siam score:  -0.85248977
maxi score, test score, baseline:  -0.22674000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.22674000000000016 0.6759999999999999 0.6759999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18776000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18776000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18480000000000016 0.6769999999999999 0.6769999999999999
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.18480000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18828000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18828000000000011 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18712000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18712000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18712000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.477]
 [0.709]
 [0.491]
 [0.469]
 [0.742]
 [0.502]
 [0.472]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.477]
 [0.709]
 [0.491]
 [0.469]
 [0.742]
 [0.502]
 [0.472]]
maxi score, test score, baseline:  -0.18442000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18176000000000014 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18158000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8625434
maxi score, test score, baseline:  -0.18396000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
siam score:  -0.86264604
maxi score, test score, baseline:  -0.18396000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18396000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18396000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18074000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.1782800000000002 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17498000000000016 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.17498000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.17498000000000016 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.17498000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.17498000000000016 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.17498000000000016 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]]
actor:  0 policy actor:  0  step number:  38 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17564000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.17564000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17266000000000017 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.17824000000000015 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18932000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
siam score:  -0.8620274
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.0000],
        [-0.4909],
        [-0.5563],
        [ 0.6956],
        [-0.5241],
        [-0.2515],
        [-0.3617],
        [ 0.4676],
        [-0.0000],
        [-0.3048]], dtype=torch.float64)
-0.029403989999999366 -0.029403989999999366
-0.048519850599000006 -0.5394331956385707
-0.048519850599000006 -0.6047858823243247
-0.067539651597 0.6281007120380043
-0.048519850599000006 -0.5726167063979656
-0.145559551797 -0.39701374516239474
-0.145559551797 -0.5072501292059738
-0.087921850599 0.37964691592686073
0.91139202 0.91139202
-0.145559551797 -0.4503683019183289
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.325]
 [0.742]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.325]
 [0.742]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]]
maxi score, test score, baseline:  -0.18876000000000015 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.18876000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18876000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.139]
 [0.22 ]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.186]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.139]
 [0.22 ]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.186]]
maxi score, test score, baseline:  -0.19450000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19450000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19450000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
siam score:  -0.861266
maxi score, test score, baseline:  -0.19450000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.19488000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.072]
 [0.129]
 [0.08 ]
 [0.08 ]
 [0.078]
 [0.083]
 [0.083]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.072]
 [0.129]
 [0.08 ]
 [0.08 ]
 [0.078]
 [0.083]
 [0.083]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.19578000000000018 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.19578000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19578000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.19944000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19944000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]]
maxi score, test score, baseline:  -0.19954000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  -0.20290000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.808]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.566]
 [0.808]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]]
maxi score, test score, baseline:  -0.20290000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.20374000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
siam score:  -0.8671196
siam score:  -0.86819685
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.11999999999999944  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.20844000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.2187800000000001 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8699764
maxi score, test score, baseline:  -0.22226000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.22572000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.22572000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.22572000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.22572000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.22502000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.854]
 [0.735]
 [0.854]
 [0.854]
 [0.854]
 [0.854]
 [0.854]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.854]
 [0.735]
 [0.854]
 [0.854]
 [0.854]
 [0.854]
 [0.854]]
maxi score, test score, baseline:  -0.2252400000000002 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.22154000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.473]
 [0.562]
 [0.473]
 [0.473]
 [0.473]
 [0.473]
 [0.473]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.473]
 [0.562]
 [0.473]
 [0.473]
 [0.473]
 [0.473]
 [0.473]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.22434000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[ 0.109]
 [ 0.16 ]
 [ 0.109]
 [ 0.109]
 [-0.007]
 [ 0.109]
 [ 0.109]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.109]
 [ 0.16 ]
 [ 0.109]
 [ 0.109]
 [-0.007]
 [ 0.109]
 [ 0.109]]
maxi score, test score, baseline:  -0.22400000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8546141
siam score:  -0.85503936
maxi score, test score, baseline:  -0.22134000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8543935
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.59  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.21484000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.857]
 [0.615]
 [0.737]
 [0.718]
 [0.718]
 [0.718]
 [0.725]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.857]
 [0.615]
 [0.737]
 [0.718]
 [0.718]
 [0.718]
 [0.725]]
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.21066000000000018 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  30 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[ 0.013]
 [ 0.157]
 [-0.   ]
 [-0.002]
 [-0.006]
 [-0.003]
 [ 0.014]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.013]
 [ 0.157]
 [-0.   ]
 [-0.002]
 [-0.006]
 [-0.003]
 [ 0.014]]
maxi score, test score, baseline:  -0.20992000000000013 0.6769999999999999 0.6769999999999999
siam score:  -0.8562305
maxi score, test score, baseline:  -0.20992000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.936]
 [1.025]
 [0.936]
 [0.936]
 [0.936]
 [0.936]
 [0.936]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.936]
 [1.025]
 [0.936]
 [0.936]
 [0.936]
 [0.936]
 [0.936]]
maxi score, test score, baseline:  -0.20954000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.20962000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]]
siam score:  -0.8579055
maxi score, test score, baseline:  -0.21230000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.21198000000000014 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]]
maxi score, test score, baseline:  -0.21198000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.21486000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.353]
 [0.695]
 [0.352]
 [0.35 ]
 [0.437]
 [0.354]
 [0.382]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.353]
 [0.695]
 [0.352]
 [0.35 ]
 [0.437]
 [0.354]
 [0.382]]
Printing some Q and Qe and total Qs values:  [[0.169]
 [0.169]
 [0.169]
 [0.169]
 [0.169]
 [0.169]
 [0.169]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.169]
 [0.169]
 [0.169]
 [0.169]
 [0.169]
 [0.169]
 [0.169]]
Printing some Q and Qe and total Qs values:  [[0.628]
 [0.806]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.628]
 [0.806]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.21148000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]]
maxi score, test score, baseline:  -0.21178000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.826]
 [0.878]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.826]
 [0.878]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]]
maxi score, test score, baseline:  -0.21178000000000013 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  37 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.4099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.20942000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.20942000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.21192000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.20596000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.723]
 [0.781]
 [0.723]
 [0.723]
 [0.723]
 [0.723]
 [0.723]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.723]
 [0.781]
 [0.723]
 [0.723]
 [0.723]
 [0.723]
 [0.723]]
siam score:  -0.8630325
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.20574000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.784]
 [0.565]
 [0.543]
 [0.536]
 [0.645]
 [0.666]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.591]
 [0.784]
 [0.565]
 [0.543]
 [0.536]
 [0.645]
 [0.666]]
maxi score, test score, baseline:  -0.20308000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.20930000000000015 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  38 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.20974000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.20974000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.87309146
Printing some Q and Qe and total Qs values:  [[0.754]
 [0.797]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.754]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.754]
 [0.797]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.754]]
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.833]
 [0.734]
 [0.734]
 [0.734]
 [0.734]
 [0.734]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.734]
 [0.833]
 [0.734]
 [0.734]
 [0.734]
 [0.734]
 [0.734]]
maxi score, test score, baseline:  -0.20978000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.20392000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.911]
 [0.97 ]
 [0.911]
 [0.911]
 [0.911]
 [0.911]
 [0.911]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.911]
 [0.97 ]
 [0.911]
 [0.911]
 [0.911]
 [0.911]
 [0.911]]
actor:  0 policy actor:  0  step number:  37 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.87246895
siam score:  -0.8714125
maxi score, test score, baseline:  -0.20112000000000016 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.19852000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.575]
 [0.779]
 [0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.575]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.575]
 [0.779]
 [0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.575]]
actor:  0 policy actor:  0  step number:  35 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.33 ]
 [0.509]
 [0.319]
 [0.32 ]
 [0.332]
 [0.437]
 [0.32 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.33 ]
 [0.509]
 [0.319]
 [0.32 ]
 [0.332]
 [0.437]
 [0.32 ]]
maxi score, test score, baseline:  -0.18668000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18948000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18948000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.12999999999999945  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18722000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18778000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18778000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18774000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.97 ]
 [0.834]
 [0.88 ]
 [0.736]
 [0.88 ]
 [0.88 ]
 [0.88 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.97 ]
 [0.834]
 [0.88 ]
 [0.736]
 [0.88 ]
 [0.88 ]
 [0.88 ]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]]
actor:  0 policy actor:  0  step number:  43 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18778000000000017 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.18778000000000017 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.18778000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18778000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.462]
 [0.707]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.462]
 [0.707]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  40 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18202000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18218000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18218000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]
 [0.306]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18204000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18204000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18204000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18204000000000017 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.18534000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18236000000000016 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.18236000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18236000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.098]
 [0.174]
 [0.09 ]
 [0.096]
 [0.093]
 [0.096]
 [0.116]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.098]
 [0.174]
 [0.09 ]
 [0.096]
 [0.093]
 [0.096]
 [0.116]]
maxi score, test score, baseline:  -0.17928000000000016 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.17928000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [1.003]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.88 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.88 ]
 [1.003]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.88 ]]
maxi score, test score, baseline:  -0.17612000000000017 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.019]
 [0.019]
 [0.019]
 [0.019]
 [0.019]
 [0.019]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.019]
 [0.019]
 [0.019]
 [0.019]
 [0.019]
 [0.019]
 [0.019]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17962000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.17962000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17918000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17906000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
siam score:  -0.86666644
actor:  0 policy actor:  0  step number:  43 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17996000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.813]
 [0.815]
 [0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.813]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.813]
 [0.815]
 [0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.813]]
Printing some Q and Qe and total Qs values:  [[0.829]
 [0.895]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.829]
 [0.895]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]]
maxi score, test score, baseline:  -0.18242000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.356]
 [0.372]
 [0.348]
 [0.372]
 [0.372]
 [0.372]
 [0.372]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.356]
 [0.372]
 [0.348]
 [0.372]
 [0.372]
 [0.372]
 [0.372]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18140000000000014 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.18140000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18140000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18452000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18724000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.709]
 [0.709]
 [0.712]
 [0.672]
 [0.707]
 [0.708]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.707]
 [0.709]
 [0.709]
 [0.712]
 [0.672]
 [0.707]
 [0.708]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]]
maxi score, test score, baseline:  -0.18720000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8749652
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.464]
 [0.623]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.464]
 [0.623]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]]
Printing some Q and Qe and total Qs values:  [[0.3  ]
 [0.61 ]
 [0.299]
 [0.301]
 [0.302]
 [0.301]
 [0.304]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.3  ]
 [0.61 ]
 [0.299]
 [0.301]
 [0.302]
 [0.301]
 [0.304]]
maxi score, test score, baseline:  -0.18380000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.98 ]
 [0.981]
 [0.98 ]
 [0.982]
 [0.972]
 [0.904]
 [0.98 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.98 ]
 [0.981]
 [0.98 ]
 [0.982]
 [0.972]
 [0.904]
 [0.98 ]]
actor:  0 policy actor:  0  step number:  42 total reward:  0.14999999999999947  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.19324000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19636000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19636000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
siam score:  -0.86859185
maxi score, test score, baseline:  -0.19040000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19320000000000015 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.19320000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.19022000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19022000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18428000000000014 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.488]
 [0.63 ]
 [0.488]
 [0.488]
 [0.488]
 [0.488]
 [0.488]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.488]
 [0.63 ]
 [0.488]
 [0.488]
 [0.488]
 [0.488]
 [0.488]]
maxi score, test score, baseline:  -0.18428000000000014 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  32 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18154000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17880000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.703]
 [0.925]
 [0.703]
 [0.703]
 [0.703]
 [0.703]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.703]
 [0.703]
 [0.925]
 [0.703]
 [0.703]
 [0.703]
 [0.703]]
Printing some Q and Qe and total Qs values:  [[0.953]
 [0.814]
 [0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.865]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.953]
 [0.814]
 [0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.865]]
maxi score, test score, baseline:  -0.17880000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18444000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18444000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18782000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.339]
 [0.647]
 [0.335]
 [0.339]
 [0.341]
 [0.444]
 [0.444]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.339]
 [0.647]
 [0.335]
 [0.339]
 [0.341]
 [0.444]
 [0.444]]
maxi score, test score, baseline:  -0.18488000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.864732
maxi score, test score, baseline:  -0.18818000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18444000000000013 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.738]
 [0.738]
 [0.738]
 [0.738]
 [0.738]
 [0.738]
 [0.738]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.738]
 [0.738]
 [0.738]
 [0.738]
 [0.738]
 [0.738]
 [0.738]]
maxi score, test score, baseline:  -0.18444000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18440000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.86793363
maxi score, test score, baseline:  -0.18098000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.819]
 [0.88 ]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.819]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.819]
 [0.88 ]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.819]]
maxi score, test score, baseline:  -0.18380000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18346000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18346000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.259]
 [0.331]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.259]
 [0.331]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]]
maxi score, test score, baseline:  -0.18316000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18046000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18046000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.313]
 [0.561]
 [0.3  ]
 [0.346]
 [0.312]
 [0.305]
 [0.336]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.313]
 [0.561]
 [0.3  ]
 [0.346]
 [0.312]
 [0.305]
 [0.336]]
maxi score, test score, baseline:  -0.17470000000000013 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17646000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.17646000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.17646000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17340000000000017 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.532]
 [0.578]
 [0.532]
 [0.532]
 [0.532]
 [0.532]
 [0.532]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.532]
 [0.578]
 [0.532]
 [0.532]
 [0.532]
 [0.532]
 [0.532]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17594000000000015 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.439]
 [0.641]
 [0.42 ]
 [0.404]
 [0.416]
 [0.42 ]
 [0.42 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.439]
 [0.641]
 [0.42 ]
 [0.404]
 [0.416]
 [0.42 ]
 [0.42 ]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17502000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.17502000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.17232000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.17232000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.17232000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.572]
 [0.765]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.572]
 [0.765]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]]
maxi score, test score, baseline:  -0.17526000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.17808000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18044000000000018 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  44 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.519]
 [0.807]
 [0.519]
 [0.519]
 [0.519]
 [0.519]
 [0.519]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.519]
 [0.807]
 [0.519]
 [0.519]
 [0.519]
 [0.519]
 [0.519]]
maxi score, test score, baseline:  -0.18074000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18360000000000015 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.274]
 [0.723]
 [0.308]
 [0.268]
 [0.272]
 [0.273]
 [0.276]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.274]
 [0.723]
 [0.308]
 [0.268]
 [0.272]
 [0.273]
 [0.276]]
maxi score, test score, baseline:  -0.18360000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18720000000000014 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.18720000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18720000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18738000000000013 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.19054000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19054000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.19668000000000016 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8608422
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.19012000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.19038000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19038000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.225]
 [0.245]
 [0.229]
 [0.226]
 [0.228]
 [0.237]
 [0.226]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.225]
 [0.245]
 [0.229]
 [0.226]
 [0.228]
 [0.237]
 [0.226]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18764000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.19070000000000015 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.19070000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18756000000000014 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18684000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18998000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18998000000000015 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.18998000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18422000000000013 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.358]
 [0.709]
 [0.358]
 [0.358]
 [0.358]
 [0.358]
 [0.358]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.358]
 [0.709]
 [0.358]
 [0.358]
 [0.358]
 [0.358]
 [0.358]]
Printing some Q and Qe and total Qs values:  [[0.579]
 [0.691]
 [0.416]
 [0.424]
 [0.286]
 [0.303]
 [0.479]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.579]
 [0.691]
 [0.416]
 [0.424]
 [0.286]
 [0.303]
 [0.479]]
maxi score, test score, baseline:  -0.18422000000000013 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.18422000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18404000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18418000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  42 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18328000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18346000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18346000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.18356000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18644000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.18644000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[ 0.282]
 [ 0.524]
 [-0.018]
 [ 0.525]
 [ 0.35 ]
 [ 0.395]
 [ 0.586]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.282]
 [ 0.524]
 [-0.018]
 [ 0.525]
 [ 0.35 ]
 [ 0.395]
 [ 0.586]]
Printing some Q and Qe and total Qs values:  [[0.305]
 [0.378]
 [0.305]
 [0.305]
 [0.305]
 [0.305]
 [0.305]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.305]
 [0.378]
 [0.305]
 [0.305]
 [0.305]
 [0.305]
 [0.305]]
maxi score, test score, baseline:  -0.18056000000000014 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.345]
 [0.562]
 [0.35 ]
 [0.349]
 [0.355]
 [0.554]
 [0.347]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.345]
 [0.562]
 [0.35 ]
 [0.349]
 [0.355]
 [0.554]
 [0.347]]
maxi score, test score, baseline:  -0.18056000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.86628866
maxi score, test score, baseline:  -0.17148000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.385]
 [0.385]
 [0.385]
 [0.385]
 [0.385]
 [0.385]
 [0.385]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.385]
 [0.385]
 [0.385]
 [0.385]
 [0.385]
 [0.385]
 [0.385]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.16784000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8701949
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.16514000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.16514000000000012 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.453]
 [0.643]
 [0.425]
 [0.434]
 [0.45 ]
 [0.445]
 [0.605]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.453]
 [0.643]
 [0.425]
 [0.434]
 [0.45 ]
 [0.445]
 [0.605]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.16244000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.15948000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.15948000000000018 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.15948000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.15948000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.15856000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[ 0.021]
 [ 0.142]
 [ 0.018]
 [-0.005]
 [-0.001]
 [ 0.023]
 [ 0.01 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.021]
 [ 0.142]
 [ 0.018]
 [-0.005]
 [-0.001]
 [ 0.023]
 [ 0.01 ]]
Printing some Q and Qe and total Qs values:  [[0.83]
 [0.77]
 [0.77]
 [0.77]
 [0.77]
 [0.77]
 [0.77]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.83]
 [0.77]
 [0.77]
 [0.77]
 [0.77]
 [0.77]
 [0.77]]
maxi score, test score, baseline:  -0.15848000000000018 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.897]
 [0.925]
 [0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.961]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.897]
 [0.925]
 [0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.961]]
actor:  0 policy actor:  0  step number:  37 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.15478000000000014 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.15762000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.15716000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.15418000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.15418000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.15666000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.15358000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.15358000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.15408000000000016 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.15408000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.745]
 [0.788]
 [0.745]
 [0.745]
 [0.745]
 [0.745]
 [0.745]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.745]
 [0.788]
 [0.745]
 [0.745]
 [0.745]
 [0.745]
 [0.745]]
maxi score, test score, baseline:  -0.14826000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.1482600000000002 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.14510000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.14510000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.14510000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.14200000000000015 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.684]
 [0.876]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.684]
 [0.876]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]]
UNIT TEST: sample policy line 217 mcts : [0.041 0.408 0.122 0.061 0.163 0.122 0.082]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.13882000000000014 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.853]
 [0.883]
 [0.846]
 [0.832]
 [0.853]
 [0.853]
 [0.835]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.853]
 [0.883]
 [0.846]
 [0.832]
 [0.853]
 [0.853]
 [0.835]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.13586000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.517]
 [0.688]
 [0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.517]
 [0.688]
 [0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]]
actor:  0 policy actor:  0  step number:  38 total reward:  0.0699999999999994  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.13576000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.13576000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.13530000000000017 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.13398000000000015 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.13614000000000015 0.6769999999999999 0.6769999999999999
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.13614000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.641]
 [0.74 ]
 [0.454]
 [0.45 ]
 [0.443]
 [0.446]
 [0.501]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.641]
 [0.74 ]
 [0.454]
 [0.45 ]
 [0.443]
 [0.446]
 [0.501]]
maxi score, test score, baseline:  -0.13276000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.13254000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.12696000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.12572000000000016 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.12572000000000016 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.12612000000000015 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.12612000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.12296000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.11890000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.11584000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.11270000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.11270000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.0000],
        [-0.4316],
        [-0.0000],
        [ 0.8130],
        [-0.4533],
        [-0.2326],
        [-0.2243],
        [ 0.0052],
        [-0.5979],
        [-0.3491]], dtype=torch.float64)
-0.6600983399999999 -0.6600983399999999
-0.048519850599000006 -0.4801505357582324
0.8725780997999999 0.8725780997999999
-0.106157551797 0.7068346873676469
-0.06831985059899999 -0.5216335934000343
-0.145559551797 -0.37812133979325024
-0.145559551797 -0.3698369778294602
-0.126539750799 -0.1213557553228277
-0.048519850599000006 -0.6464105815415417
-0.08675157179700001 -0.43588280927206663
maxi score, test score, baseline:  -0.11270000000000013 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.11270000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.11218000000000014 0.6769999999999999 0.6769999999999999
siam score:  -0.8831184
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.10988000000000013 0.6769999999999999 0.6769999999999999
Printing some Q and Qe and total Qs values:  [[0.512]
 [0.743]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.512]
 [0.743]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.11010000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
siam score:  -0.8810267
maxi score, test score, baseline:  -0.11010000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.10648000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.10648000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.10510000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.908]
 [0.961]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.908]
 [0.961]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]]
actor:  0 policy actor:  0  step number:  34 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
siam score:  -0.87832034
maxi score, test score, baseline:  -0.10220000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.10220000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.661]
 [0.811]
 [0.598]
 [0.518]
 [0.598]
 [0.598]
 [0.598]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.661]
 [0.811]
 [0.598]
 [0.518]
 [0.598]
 [0.598]
 [0.598]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.10186000000000012 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.10186000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.10138000000000014 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.10438000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.10438000000000013 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.10438000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.71]
 [0.81]
 [0.71]
 [0.71]
 [0.71]
 [0.71]
 [0.71]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.71]
 [0.81]
 [0.71]
 [0.71]
 [0.71]
 [0.71]
 [0.71]]
maxi score, test score, baseline:  -0.10690000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.10360000000000012 0.6769999999999999 0.6769999999999999
actor:  0 policy actor:  0  step number:  29 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.10586000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.10604000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
siam score:  -0.87701505
maxi score, test score, baseline:  -0.10604000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.87656695
Printing some Q and Qe and total Qs values:  [[0.375]
 [0.66 ]
 [0.354]
 [0.356]
 [0.375]
 [0.375]
 [0.375]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.375]
 [0.66 ]
 [0.354]
 [0.356]
 [0.375]
 [0.375]
 [0.375]]
maxi score, test score, baseline:  -0.10576000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.10540000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Starting evaluation
maxi score, test score, baseline:  -0.10808000000000013 0.6769999999999999 0.6769999999999999
maxi score, test score, baseline:  -0.10808000000000013 0.6769999999999999 0.6769999999999999
probs:  [1.0]
siam score:  -0.8744697
maxi score, test score, baseline:  -0.10808000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
maxi score, test score, baseline:  -0.10808000000000015 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07328000000000012 0.6769999999999999 0.6769999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07240000000000014 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.07240000000000014 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.06928000000000013 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.909]
 [0.963]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.888]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.909]
 [0.963]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.888]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
siam score:  -0.87556946
maxi score, test score, baseline:  -0.06966000000000012 0.6805 0.6805
actor:  0 policy actor:  0  step number:  50 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07048000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07028000000000013 0.6805 0.6805
maxi score, test score, baseline:  -0.07028000000000013 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.787]
 [0.864]
 [0.805]
 [0.772]
 [0.74 ]
 [0.823]
 [0.834]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.787]
 [0.864]
 [0.805]
 [0.772]
 [0.74 ]
 [0.823]
 [0.834]]
maxi score, test score, baseline:  -0.07028000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.06724000000000015 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.06724000000000015 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.53 ]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.368]
 [0.53 ]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]]
maxi score, test score, baseline:  -0.07298000000000016 0.6805 0.6805
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07248000000000016 0.6805 0.6805
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.06972000000000013 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.06972000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.06350000000000013 0.6805 0.6805
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.06074000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.05732000000000013 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.05958000000000014 0.6805 0.6805
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.06016000000000013 0.6805 0.6805
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.06016000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.06464000000000011 0.6805 0.6805
probs:  [1.0]
siam score:  -0.8741901
maxi score, test score, baseline:  -0.06804000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.351]
 [0.629]
 [0.355]
 [0.354]
 [0.354]
 [0.355]
 [0.383]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.351]
 [0.629]
 [0.355]
 [0.354]
 [0.354]
 [0.355]
 [0.383]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07290000000000015 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07332000000000014 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.07332000000000014 0.6805 0.6805
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.358]
 [0.588]
 [0.327]
 [0.327]
 [0.327]
 [0.327]
 [0.327]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.358]
 [0.588]
 [0.327]
 [0.327]
 [0.327]
 [0.327]
 [0.327]]
maxi score, test score, baseline:  -0.08078000000000013 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.08406000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.08108000000000014 0.6805 0.6805
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.08076000000000014 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07748000000000013 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07422000000000013 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.549]
 [0.785]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.549]
 [0.785]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]]
maxi score, test score, baseline:  -0.07422000000000012 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07422000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07114000000000015 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.07122000000000013 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.701]
 [0.821]
 [0.76 ]
 [0.674]
 [0.798]
 [0.798]
 [0.921]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.701]
 [0.821]
 [0.76 ]
 [0.674]
 [0.798]
 [0.798]
 [0.921]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.979]
 [0.921]
 [0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.979]
 [0.921]
 [0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]]
maxi score, test score, baseline:  -0.06808000000000014 0.6805 0.6805
actor:  0 policy actor:  0  step number:  33 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.06540000000000012 0.6805 0.6805
maxi score, test score, baseline:  -0.06540000000000012 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.062240000000000135 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.845]
 [0.762]
 [0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.845]
 [0.762]
 [0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.061840000000000124 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.061840000000000124 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.062120000000000154 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.06190000000000014 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.39 ]
 [0.642]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.39 ]
 [0.642]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]]
maxi score, test score, baseline:  -0.06190000000000014 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.06190000000000014 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.05970000000000014 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.05970000000000013 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.05970000000000013 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.05970000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.059880000000000135 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.055920000000000136 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.866]
 [0.996]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.866]
 [0.996]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.05900000000000013 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.05900000000000013 0.6805 0.6805
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.056280000000000135 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.053020000000000116 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.05264000000000012 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.05264000000000012 0.6805 0.6805
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.052460000000000125 0.6805 0.6805
maxi score, test score, baseline:  -0.052460000000000125 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.429]
 [0.562]
 [0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.429]
 [0.562]
 [0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]]
maxi score, test score, baseline:  -0.049180000000000126 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.04638000000000013 0.6805 0.6805
maxi score, test score, baseline:  -0.04638000000000013 0.6805 0.6805
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.481]
 [0.669]
 [0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.481]
 [0.669]
 [0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]]
Printing some Q and Qe and total Qs values:  [[0.53 ]
 [0.649]
 [0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.575]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.53 ]
 [0.649]
 [0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.575]]
maxi score, test score, baseline:  -0.04046000000000013 0.6805 0.6805
maxi score, test score, baseline:  -0.04046000000000013 0.6805 0.6805
maxi score, test score, baseline:  -0.04046000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.040600000000000136 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.593]
 [0.48 ]
 [0.405]
 [0.607]
 [0.427]
 [0.462]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.537]
 [0.593]
 [0.48 ]
 [0.405]
 [0.607]
 [0.427]
 [0.462]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.03756000000000013 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.03756000000000013 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.03756000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.03456000000000014 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.03456000000000014 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.03458000000000013 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.317]
 [0.583]
 [0.323]
 [0.323]
 [0.442]
 [0.313]
 [0.442]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.317]
 [0.583]
 [0.323]
 [0.323]
 [0.442]
 [0.313]
 [0.442]]
maxi score, test score, baseline:  -0.03458000000000013 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.03458000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.028060000000000133 0.6805 0.6805
maxi score, test score, baseline:  -0.028060000000000133 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.028060000000000133 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.028060000000000133 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.028240000000000147 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.028240000000000147 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.028400000000000158 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
siam score:  -0.883185
Printing some Q and Qe and total Qs values:  [[0.213]
 [0.447]
 [0.224]
 [0.206]
 [0.205]
 [0.205]
 [0.205]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.213]
 [0.447]
 [0.224]
 [0.206]
 [0.205]
 [0.205]
 [0.205]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.37 ]
 [0.428]
 [0.37 ]
 [0.37 ]
 [0.37 ]
 [0.37 ]
 [0.37 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.37 ]
 [0.428]
 [0.37 ]
 [0.37 ]
 [0.37 ]
 [0.37 ]
 [0.37 ]]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.189]
 [0.003]
 [0.037]
 [0.003]
 [0.003]
 [0.067]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.189]
 [0.003]
 [0.037]
 [0.003]
 [0.003]
 [0.067]]
maxi score, test score, baseline:  -0.028940000000000143 0.6805 0.6805
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.024840000000000126 0.6805 0.6805
maxi score, test score, baseline:  -0.024840000000000126 0.6805 0.6805
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.024780000000000125 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.024780000000000125 0.6805 0.6805
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.02408000000000013 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.32 ]
 [0.685]
 [0.32 ]
 [0.306]
 [0.317]
 [0.305]
 [0.316]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.32 ]
 [0.685]
 [0.32 ]
 [0.306]
 [0.317]
 [0.305]
 [0.316]]
maxi score, test score, baseline:  -0.024080000000000157 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.02394000000000014 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.02394000000000014 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.352]
 [0.594]
 [0.352]
 [0.352]
 [0.352]
 [0.352]
 [0.352]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.352]
 [0.594]
 [0.352]
 [0.352]
 [0.352]
 [0.352]
 [0.352]]
maxi score, test score, baseline:  -0.02394000000000014 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.676]
 [0.862]
 [0.823]
 [0.696]
 [0.696]
 [0.696]
 [0.871]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.676]
 [0.862]
 [0.823]
 [0.696]
 [0.696]
 [0.696]
 [0.871]]
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.278]
 [0.435]
 [0.278]
 [0.278]
 [0.278]
 [0.278]
 [0.278]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.278]
 [0.435]
 [0.278]
 [0.278]
 [0.278]
 [0.278]
 [0.278]]
maxi score, test score, baseline:  -0.020120000000000148 0.6805 0.6805
maxi score, test score, baseline:  -0.020120000000000148 0.6805 0.6805
actor:  0 policy actor:  0  step number:  30 total reward:  0.5099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.02606000000000014 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.02606000000000014 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  51 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8669865
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.02336000000000015 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.02010000000000013 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.914]
 [0.72 ]
 [0.866]
 [0.596]
 [0.592]
 [0.882]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.644]
 [0.914]
 [0.72 ]
 [0.866]
 [0.596]
 [0.592]
 [0.882]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.01826000000000014 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.01826000000000014 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.01830000000000015 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.498]
 [0.602]
 [0.348]
 [0.348]
 [0.349]
 [0.347]
 [0.346]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.498]
 [0.602]
 [0.348]
 [0.348]
 [0.349]
 [0.347]
 [0.346]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  -0.01830000000000015 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.909]
 [0.734]
 [0.734]
 [0.734]
 [0.734]
 [0.734]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.734]
 [0.909]
 [0.734]
 [0.734]
 [0.734]
 [0.734]
 [0.734]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.01874000000000014 0.6805 0.6805
maxi score, test score, baseline:  -0.01874000000000014 0.6805 0.6805
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.018600000000000158 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.018600000000000158 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.018600000000000158 0.6805 0.6805
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.521]
 [0.725]
 [0.521]
 [0.521]
 [0.521]
 [0.521]
 [0.521]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.521]
 [0.725]
 [0.521]
 [0.521]
 [0.521]
 [0.521]
 [0.521]]
maxi score, test score, baseline:  -0.018480000000000156 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.647]
 [0.647]
 [0.647]
 [0.647]
 [0.647]
 [0.647]
 [0.647]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.647]
 [0.647]
 [0.647]
 [0.647]
 [0.647]
 [0.647]
 [0.647]]
maxi score, test score, baseline:  -0.018320000000000152 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.018320000000000152 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.018320000000000152 0.6805 0.6805
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.018220000000000135 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.14 ]
 [0.187]
 [0.125]
 [0.124]
 [0.111]
 [0.132]
 [0.131]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.14 ]
 [0.187]
 [0.125]
 [0.124]
 [0.111]
 [0.132]
 [0.131]]
siam score:  -0.8625098
actor:  0 policy actor:  0  step number:  29 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.01740000000000015 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.01946000000000015 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.01946000000000015 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.018540000000000143 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.736]
 [0.792]
 [0.736]
 [0.736]
 [0.736]
 [0.736]
 [0.736]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.736]
 [0.792]
 [0.736]
 [0.736]
 [0.736]
 [0.736]
 [0.736]]
maxi score, test score, baseline:  -0.018540000000000143 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.015600000000000145 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.01 ]
 [1.026]
 [1.01 ]
 [1.01 ]
 [1.01 ]
 [1.01 ]
 [1.01 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.01 ]
 [1.026]
 [1.01 ]
 [1.01 ]
 [1.01 ]
 [1.01 ]
 [1.01 ]]
maxi score, test score, baseline:  -0.012460000000000145 0.6805 0.6805
maxi score, test score, baseline:  -0.012460000000000145 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.015000000000000152 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.01476000000000015 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.01476000000000015 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.01476000000000015 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.012060000000000154 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.014860000000000144 0.6805 0.6805
maxi score, test score, baseline:  -0.014860000000000144 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.008120000000000148 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.004880000000000139 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.817]
 [0.839]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.817]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.817]
 [0.839]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.817]]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.592]
 [0.592]
 [0.905]
 [0.592]
 [0.592]
 [0.592]
 [0.592]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.592]
 [0.592]
 [0.905]
 [0.592]
 [0.592]
 [0.592]
 [0.592]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.007220000000000135 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.010160000000000141 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.177]
 [0.186]
 [0.177]
 [0.177]
 [0.177]
 [0.177]
 [0.177]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.177]
 [0.186]
 [0.177]
 [0.177]
 [0.177]
 [0.177]
 [0.177]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.007440000000000141 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.001420000000000145 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.001420000000000145 0.6805 0.6805
probs:  [1.0]
siam score:  -0.8823372
maxi score, test score, baseline:  -0.001420000000000145 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.834]
 [0.851]
 [0.9  ]
 [0.87 ]
 [0.931]
 [0.802]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.739]
 [0.834]
 [0.851]
 [0.9  ]
 [0.87 ]
 [0.931]
 [0.802]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.002399999999999862 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.779]
 [0.683]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.754]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.779]
 [0.683]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.754]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0030399999999998696 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.0030399999999998696 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[1.016]
 [1.015]
 [1.015]
 [1.016]
 [1.015]
 [1.015]
 [1.016]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.016]
 [1.015]
 [1.015]
 [1.016]
 [1.015]
 [1.015]
 [1.016]]
maxi score, test score, baseline:  0.0030399999999998696 0.6805 0.6805
maxi score, test score, baseline:  0.0030399999999998696 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.999]
 [1.011]
 [0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.999]
 [1.011]
 [0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]]
Printing some Q and Qe and total Qs values:  [[0.735]
 [0.849]
 [0.735]
 [0.735]
 [0.735]
 [0.735]
 [0.735]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.735]
 [0.849]
 [0.735]
 [0.735]
 [0.735]
 [0.735]
 [0.735]]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.0019600000000001305 0.6805 0.6805
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  -0.001620000000000134 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  -0.001620000000000134 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0017799999999998648 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]]
maxi score, test score, baseline:  0.0017799999999998648 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.0017799999999998648 0.6805 0.6805
actor:  0 policy actor:  0  step number:  31 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.0016399999999998714 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.0016399999999998714 0.6805 0.6805
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.004799999999999861 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.745]
 [0.759]
 [0.68 ]
 [0.745]
 [0.745]
 [0.745]
 [0.745]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.745]
 [0.759]
 [0.68 ]
 [0.745]
 [0.745]
 [0.745]
 [0.745]]
Printing some Q and Qe and total Qs values:  [[0.47 ]
 [0.672]
 [0.473]
 [0.473]
 [0.47 ]
 [0.473]
 [0.473]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.47 ]
 [0.672]
 [0.473]
 [0.473]
 [0.47 ]
 [0.473]
 [0.473]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.007719999999999862 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.007539999999999863 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8884703
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.010499999999999857 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
siam score:  -0.89006454
maxi score, test score, baseline:  0.01027999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.010119999999999846 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.733]
 [0.457]
 [0.522]
 [0.455]
 [0.448]
 [0.45 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.467]
 [0.733]
 [0.457]
 [0.522]
 [0.455]
 [0.448]
 [0.45 ]]
maxi score, test score, baseline:  0.010119999999999846 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.010119999999999846 0.6805 0.6805
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.875]
 [0.915]
 [0.885]
 [0.852]
 [0.873]
 [0.828]
 [0.898]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.875]
 [0.915]
 [0.885]
 [0.852]
 [0.873]
 [0.828]
 [0.898]]
maxi score, test score, baseline:  0.010719999999999862 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.01033999999999986 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.516]
 [0.741]
 [0.516]
 [0.516]
 [0.516]
 [0.516]
 [0.516]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.516]
 [0.741]
 [0.516]
 [0.516]
 [0.516]
 [0.516]
 [0.516]]
Printing some Q and Qe and total Qs values:  [[0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.874]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.874]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.010419999999999865 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.010739999999999857 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.01117999999999987 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.01117999999999987 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.014159999999999867 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.199]
 [0.359]
 [0.199]
 [0.204]
 [0.199]
 [0.199]
 [0.226]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.199]
 [0.359]
 [0.199]
 [0.204]
 [0.199]
 [0.199]
 [0.226]]
maxi score, test score, baseline:  0.010999999999999855 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.010999999999999855 0.6805 0.6805
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  42 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.021]
 [1.021]
 [1.015]
 [1.015]
 [1.015]
 [1.015]
 [1.015]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.021]
 [1.021]
 [1.015]
 [1.015]
 [1.015]
 [1.015]
 [1.015]]
maxi score, test score, baseline:  0.01383999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.017079999999999856 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.019719999999999842 0.6805 0.6805
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.922]
 [0.946]
 [0.919]
 [0.923]
 [0.933]
 [0.921]
 [0.934]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.922]
 [0.946]
 [0.919]
 [0.923]
 [0.933]
 [0.921]
 [0.934]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.017079999999999856 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.013979999999999857 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.013979999999999857 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.01709999999999986 0.6805 0.6805
actor:  0 policy actor:  0  step number:  33 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.39 ]
 [0.73 ]
 [0.453]
 [0.373]
 [0.384]
 [0.453]
 [0.453]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.39 ]
 [0.73 ]
 [0.453]
 [0.373]
 [0.384]
 [0.453]
 [0.453]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.019699999999999857 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.023259999999999857 0.6805 0.6805
maxi score, test score, baseline:  0.023259999999999857 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.838]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.838]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]]
maxi score, test score, baseline:  0.023099999999999864 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.023099999999999864 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.731]
 [0.731]
 [0.814]
 [0.458]
 [0.731]
 [0.731]
 [0.511]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.731]
 [0.731]
 [0.814]
 [0.458]
 [0.731]
 [0.731]
 [0.511]]
maxi score, test score, baseline:  0.020199999999999867 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.026419999999999857 0.6805 0.6805
probs:  [1.0]
siam score:  -0.8747382
maxi score, test score, baseline:  0.026419999999999857 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.87 ]
 [0.683]
 [0.738]
 [0.71 ]
 [0.668]
 [0.738]
 [0.824]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.87 ]
 [0.683]
 [0.738]
 [0.71 ]
 [0.668]
 [0.738]
 [0.824]]
maxi score, test score, baseline:  0.023619999999999856 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.023619999999999856 0.6805 0.6805
maxi score, test score, baseline:  0.023619999999999856 0.6805 0.6805
maxi score, test score, baseline:  0.02361999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.02619999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.02313999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.023239999999999858 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.687]
 [0.735]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.687]
 [0.735]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]]
maxi score, test score, baseline:  0.023239999999999858 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.026479999999999865 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.497]
 [0.629]
 [0.451]
 [0.423]
 [0.425]
 [0.417]
 [0.423]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.497]
 [0.629]
 [0.451]
 [0.423]
 [0.425]
 [0.417]
 [0.423]]
maxi score, test score, baseline:  0.026479999999999865 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.03217999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.03199999999999986 0.6805 0.6805
maxi score, test score, baseline:  0.03199999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.03199999999999986 0.6805 0.6805
probs:  [1.0]
siam score:  -0.8704088
maxi score, test score, baseline:  0.03199999999999986 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.519]
 [0.847]
 [0.519]
 [0.519]
 [0.519]
 [0.519]
 [0.519]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.519]
 [0.847]
 [0.519]
 [0.519]
 [0.519]
 [0.519]
 [0.519]]
Printing some Q and Qe and total Qs values:  [[0.818]
 [0.863]
 [0.864]
 [0.843]
 [0.848]
 [0.798]
 [0.856]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.818]
 [0.863]
 [0.864]
 [0.843]
 [0.848]
 [0.798]
 [0.856]]
maxi score, test score, baseline:  0.03199999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.03185999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.03183999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.03541999999999986 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.829]
 [0.925]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.816]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.829]
 [0.925]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.816]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.03819999999999985 0.6805 0.6805
Printing some Q and Qe and total Qs values:  [[0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.03803999999999985 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.03803999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.798]
 [0.92 ]
 [0.817]
 [0.815]
 [0.815]
 [0.815]
 [0.936]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.798]
 [0.92 ]
 [0.817]
 [0.815]
 [0.815]
 [0.815]
 [0.936]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.867462
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.076]
 [0.011]
 [0.007]
 [0.025]
 [0.031]
 [0.034]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.031]
 [0.076]
 [0.011]
 [0.007]
 [0.025]
 [0.031]
 [0.034]]
Printing some Q and Qe and total Qs values:  [[0.902]
 [0.963]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.902]
 [0.963]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.86967283
maxi score, test score, baseline:  0.04145999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.04175999999999987 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.03885999999999985 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.03885999999999987 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.03885999999999987 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.04145999999999986 0.6805 0.6805
maxi score, test score, baseline:  0.04145999999999986 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.388]
 [0.621]
 [0.388]
 [0.388]
 [0.388]
 [0.388]
 [0.388]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.388]
 [0.621]
 [0.388]
 [0.388]
 [0.388]
 [0.388]
 [0.388]]
Printing some Q and Qe and total Qs values:  [[0.517]
 [0.713]
 [0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.517]
 [0.713]
 [0.517]
 [0.517]
 [0.517]
 [0.517]
 [0.517]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.041459999999999844 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.041459999999999844 0.6805 0.6805
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.92 ]
 [0.871]
 [0.748]
 [0.736]
 [0.747]
 [0.367]
 [0.889]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.92 ]
 [0.871]
 [0.748]
 [0.736]
 [0.747]
 [0.367]
 [0.889]]
maxi score, test score, baseline:  0.041299999999999865 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.044139999999999846 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.972]
 [0.972]
 [0.972]
 [0.972]
 [0.972]
 [0.972]
 [0.972]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.972]
 [0.972]
 [0.972]
 [0.972]
 [0.972]
 [0.972]
 [0.972]]
maxi score, test score, baseline:  0.044139999999999846 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.047319999999999855 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.047319999999999855 0.6805 0.6805
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.05027999999999985 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.05027999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05615999999999986 0.6805 0.6805
maxi score, test score, baseline:  0.05345999999999985 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.05049999999999986 0.6805 0.6805
probs:  [1.0]
siam score:  -0.8822153
maxi score, test score, baseline:  0.05049999999999986 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.441]
 [0.779]
 [0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.441]
 [0.779]
 [0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05619999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.059379999999999857 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.059379999999999857 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.059379999999999857 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.059379999999999857 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06265999999999985 0.6805 0.6805
probs:  [1.0]
siam score:  -0.88196856
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.79 ]
 [0.832]
 [0.777]
 [0.765]
 [0.786]
 [0.783]
 [0.788]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.79 ]
 [0.832]
 [0.777]
 [0.765]
 [0.786]
 [0.783]
 [0.788]]
Printing some Q and Qe and total Qs values:  [[0.792]
 [0.385]
 [0.727]
 [0.792]
 [0.792]
 [0.792]
 [0.792]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.792]
 [0.385]
 [0.727]
 [0.792]
 [0.792]
 [0.792]
 [0.792]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.806]
 [0.807]
 [0.806]
 [0.799]
 [0.799]
 [0.799]
 [0.799]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.806]
 [0.807]
 [0.806]
 [0.799]
 [0.799]
 [0.799]
 [0.799]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06579999999999984 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06601999999999986 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.738]
 [0.541]
 [0.541]
 [0.541]
 [0.541]
 [0.541]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.541]
 [0.738]
 [0.541]
 [0.541]
 [0.541]
 [0.541]
 [0.541]]
maxi score, test score, baseline:  0.06601999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06601999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06895999999999985 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.676]
 [0.679]
 [0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.676]
 [0.679]
 [0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]]
Printing some Q and Qe and total Qs values:  [[0.887]
 [0.966]
 [0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.887]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.887]
 [0.966]
 [0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.887]]
maxi score, test score, baseline:  0.06895999999999984 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.635]
 [0.665]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.635]
 [0.665]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]]
Printing some Q and Qe and total Qs values:  [[0.532]
 [0.532]
 [0.67 ]
 [0.297]
 [0.532]
 [0.489]
 [0.403]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.532]
 [0.532]
 [0.67 ]
 [0.297]
 [0.532]
 [0.489]
 [0.403]]
maxi score, test score, baseline:  0.07497999999999985 0.6805 0.6805
siam score:  -0.88371485
maxi score, test score, baseline:  0.07497999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07805999999999985 0.6805 0.6805
Printing some Q and Qe and total Qs values:  [[0.859]
 [0.869]
 [0.865]
 [0.919]
 [0.919]
 [0.919]
 [0.827]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.859]
 [0.869]
 [0.865]
 [0.919]
 [0.919]
 [0.919]
 [0.827]]
Printing some Q and Qe and total Qs values:  [[0.671]
 [0.671]
 [0.671]
 [0.671]
 [0.671]
 [0.671]
 [0.671]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.671]
 [0.671]
 [0.671]
 [0.671]
 [0.671]
 [0.671]
 [0.671]]
maxi score, test score, baseline:  0.07805999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07783999999999987 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]
 [0.425]]
maxi score, test score, baseline:  0.07795999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.522]
 [0.555]
 [0.526]
 [0.522]
 [0.522]
 [0.508]
 [0.522]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.522]
 [0.555]
 [0.526]
 [0.522]
 [0.522]
 [0.508]
 [0.522]]
Printing some Q and Qe and total Qs values:  [[0.999]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.999]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]]
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.847]
 [0.831]
 [0.695]
 [0.831]
 [0.831]
 [0.589]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.81 ]
 [0.847]
 [0.831]
 [0.695]
 [0.831]
 [0.831]
 [0.589]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07463999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.416]
 [0.499]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.416]
 [0.499]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]]
Printing some Q and Qe and total Qs values:  [[0.464]
 [0.6  ]
 [0.469]
 [0.465]
 [0.464]
 [0.457]
 [0.459]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.464]
 [0.6  ]
 [0.469]
 [0.465]
 [0.464]
 [0.457]
 [0.459]]
Printing some Q and Qe and total Qs values:  [[0.475]
 [0.683]
 [0.475]
 [0.469]
 [0.475]
 [0.475]
 [0.475]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.475]
 [0.683]
 [0.475]
 [0.469]
 [0.475]
 [0.475]
 [0.475]]
maxi score, test score, baseline:  0.07477999999999983 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.851]
 [0.851]
 [0.915]
 [0.851]
 [0.851]
 [0.851]
 [0.851]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.851]
 [0.851]
 [0.915]
 [0.851]
 [0.851]
 [0.851]
 [0.851]]
Printing some Q and Qe and total Qs values:  [[0.938]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.93 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.938]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.93 ]]
maxi score, test score, baseline:  0.07477999999999983 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06905999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06905999999999986 0.6805 0.6805
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.261]
 [0.302]
 [0.867]
 [0.49 ]
 [0.746]
 [0.746]
 [0.735]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.261]
 [0.302]
 [0.867]
 [0.49 ]
 [0.746]
 [0.746]
 [0.735]]
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.752]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.467]
 [0.752]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06923999999999984 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.912]
 [0.686]
 [0.648]
 [0.686]
 [0.686]
 [0.686]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.739]
 [0.912]
 [0.686]
 [0.648]
 [0.686]
 [0.686]
 [0.686]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8836719
maxi score, test score, baseline:  0.07221999999999987 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.07221999999999987 0.6805 0.6805
maxi score, test score, baseline:  0.07221999999999987 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07243999999999987 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.885]
 [0.697]
 [0.822]
 [0.822]
 [0.822]
 [0.822]
 [0.812]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.885]
 [0.697]
 [0.822]
 [0.822]
 [0.822]
 [0.822]
 [0.812]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06977999999999987 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.653]
 [0.653]
 [0.83 ]
 [0.653]
 [0.653]
 [0.653]
 [0.653]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.653]
 [0.653]
 [0.83 ]
 [0.653]
 [0.653]
 [0.653]
 [0.653]]
Printing some Q and Qe and total Qs values:  [[0.577]
 [0.816]
 [0.547]
 [0.563]
 [0.577]
 [0.536]
 [0.575]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.577]
 [0.816]
 [0.547]
 [0.563]
 [0.577]
 [0.536]
 [0.575]]
Printing some Q and Qe and total Qs values:  [[0.93 ]
 [0.983]
 [0.951]
 [0.906]
 [0.929]
 [0.936]
 [0.957]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.93 ]
 [0.983]
 [0.951]
 [0.906]
 [0.929]
 [0.936]
 [0.957]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06669999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06669999999999986 0.6805 0.6805
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.11999999999999944  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06949999999999987 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06681999999999987 0.6805 0.6805
maxi score, test score, baseline:  0.06681999999999987 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06943999999999986 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.827]
 [0.823]
 [0.896]
 [0.825]
 [0.896]
 [0.896]
 [0.914]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.827]
 [0.823]
 [0.896]
 [0.825]
 [0.896]
 [0.896]
 [0.914]]
Printing some Q and Qe and total Qs values:  [[0.952]
 [0.952]
 [1.002]
 [0.952]
 [0.952]
 [0.952]
 [0.952]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.952]
 [0.952]
 [1.002]
 [0.952]
 [0.952]
 [0.952]
 [0.952]]
Printing some Q and Qe and total Qs values:  [[0.596]
 [0.774]
 [0.578]
 [0.562]
 [0.615]
 [0.615]
 [0.615]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.596]
 [0.774]
 [0.578]
 [0.562]
 [0.615]
 [0.615]
 [0.615]]
Printing some Q and Qe and total Qs values:  [[0.762]
 [0.762]
 [0.802]
 [0.352]
 [0.762]
 [0.268]
 [0.762]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.762]
 [0.762]
 [0.802]
 [0.352]
 [0.762]
 [0.268]
 [0.762]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06947999999999986 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06967999999999987 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06967999999999987 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06943999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06943999999999986 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.819]
 [0.819]
 [0.878]
 [0.819]
 [0.819]
 [0.819]
 [0.819]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.819]
 [0.819]
 [0.878]
 [0.819]
 [0.819]
 [0.819]
 [0.819]]
maxi score, test score, baseline:  0.06943999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06943999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.06639999999999988 0.6805 0.6805
maxi score, test score, baseline:  0.06639999999999988 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06307999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06307999999999986 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.301]
 [0.282]
 [0.291]
 [0.29 ]
 [0.285]
 [0.293]
 [0.278]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.301]
 [0.282]
 [0.291]
 [0.29 ]
 [0.285]
 [0.293]
 [0.278]]
maxi score, test score, baseline:  0.06307999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06307999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
siam score:  -0.87420255
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06589999999999988 0.6805 0.6805
maxi score, test score, baseline:  0.06589999999999988 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.06589999999999988 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.957]
 [1.008]
 [0.972]
 [0.957]
 [0.957]
 [0.957]
 [0.985]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.957]
 [1.008]
 [0.972]
 [0.957]
 [0.957]
 [0.957]
 [0.985]]
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06609999999999987 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.762]
 [0.825]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.762]
 [0.825]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]]
Printing some Q and Qe and total Qs values:  [[0.444]
 [0.707]
 [0.45 ]
 [0.454]
 [0.443]
 [0.441]
 [0.447]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.444]
 [0.707]
 [0.45 ]
 [0.454]
 [0.443]
 [0.441]
 [0.447]]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.87884814
maxi score, test score, baseline:  0.06865999999999985 0.6805 0.6805
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07165999999999985 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.831]
 [0.83 ]
 [0.859]
 [0.859]
 [0.859]
 [0.859]
 [0.859]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.831]
 [0.83 ]
 [0.859]
 [0.859]
 [0.859]
 [0.859]
 [0.859]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07473999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07773999999999985 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.07773999999999985 0.6805 0.6805
maxi score, test score, baseline:  0.07773999999999985 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]]
maxi score, test score, baseline:  0.07773999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.44 ]
 [0.584]
 [0.44 ]
 [0.44 ]
 [0.44 ]
 [0.44 ]
 [0.44 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.44 ]
 [0.584]
 [0.44 ]
 [0.44 ]
 [0.44 ]
 [0.44 ]
 [0.44 ]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.536]
 [0.803]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.536]
 [0.803]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]]
siam score:  -0.8845122
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.08337999999999984 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.08337999999999984 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08379999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08391999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.08075999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08085999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.03 ]
 [0.225]
 [0.03 ]
 [0.033]
 [0.03 ]
 [0.03 ]
 [0.109]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.03 ]
 [0.225]
 [0.03 ]
 [0.033]
 [0.03 ]
 [0.03 ]
 [0.109]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08063999999999985 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.08063999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07387999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.07387999999999986 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.07387999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07479999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07459999999999985 0.6805 0.6805
probs:  [1.0]
maxi score, test score, baseline:  0.07459999999999985 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.553]
 [0.803]
 [0.516]
 [0.626]
 [0.508]
 [0.494]
 [0.527]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.553]
 [0.803]
 [0.516]
 [0.626]
 [0.508]
 [0.494]
 [0.527]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07705999999999985 0.6805 0.6805
probs:  [1.0]
siam score:  -0.8849781
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07653999999999986 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07667999999999985 0.6805 0.6805
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.588]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.587]
 [0.588]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07637999999999985 0.6805 0.6805
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07949999999999983 0.6805 0.6805
probs:  [1.0]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.264]
 [0.424]
 [0.335]
 [0.335]
 [0.335]
 [0.335]
 [0.335]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.264]
 [0.424]
 [0.335]
 [0.335]
 [0.335]
 [0.335]
 [0.335]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.723]
 [0.543]
 [0.447]
 [0.543]
 [0.449]
 [0.508]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.451]
 [0.723]
 [0.543]
 [0.447]
 [0.543]
 [0.449]
 [0.508]]
maxi score, test score, baseline:  0.08257999999999985 0.6805 0.6805
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.842]
 [0.843]
 [0.84 ]
 [0.827]
 [0.827]
 [0.827]
 [0.827]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.842]
 [0.843]
 [0.84 ]
 [0.827]
 [0.827]
 [0.827]
 [0.827]]
actor:  0 policy actor:  0  step number:  37 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.876]
 [0.969]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.976]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.876]
 [0.969]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.976]]
Printing some Q and Qe and total Qs values:  [[0.94]
 [0.94]
 [0.94]
 [0.94]
 [0.94]
 [0.94]
 [0.94]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.94]
 [0.94]
 [0.94]
 [0.94]
 [0.94]
 [0.94]
 [0.94]]
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10059999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.433]
 [0.774]
 [0.433]
 [0.433]
 [0.433]
 [0.433]
 [0.433]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.433]
 [0.774]
 [0.433]
 [0.433]
 [0.433]
 [0.433]
 [0.433]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09685999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.09685999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.09685999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09633999999999987 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.483]
 [0.773]
 [0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.483]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.483]
 [0.773]
 [0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.483]]
Printing some Q and Qe and total Qs values:  [[0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]]
maxi score, test score, baseline:  0.09585999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09895999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.09895999999999984 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.913]
 [0.913]
 [0.913]
 [0.913]
 [0.913]
 [0.913]
 [0.913]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.913]
 [0.913]
 [0.913]
 [0.913]
 [0.913]
 [0.913]
 [0.913]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10503999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[-0.004]
 [ 0.21 ]
 [ 0.003]
 [ 0.002]
 [ 0.001]
 [ 0.001]
 [ 0.008]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.004]
 [ 0.21 ]
 [ 0.003]
 [ 0.002]
 [ 0.001]
 [ 0.001]
 [ 0.008]]
maxi score, test score, baseline:  0.10453999999999983 0.6645 0.6645
maxi score, test score, baseline:  0.10453999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.88181984
maxi score, test score, baseline:  0.10761999999999985 0.6645 0.6645
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.10761999999999985 0.6645 0.6645
maxi score, test score, baseline:  0.10761999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10433999999999984 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.851]
 [0.902]
 [0.865]
 [0.851]
 [0.851]
 [0.851]
 [0.879]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.851]
 [0.902]
 [0.865]
 [0.851]
 [0.851]
 [0.851]
 [0.879]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10671999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.10671999999999987 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10611999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10177999999999984 0.6645 0.6645
actor:  0 policy actor:  0  step number:  34 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.516]
 [0.528]
 [0.474]
 [0.516]
 [0.516]
 [0.516]
 [0.516]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.516]
 [0.528]
 [0.474]
 [0.516]
 [0.516]
 [0.516]
 [0.516]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09667999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.09327999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.09327999999999984 0.6645 0.6645
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.779]
 [0.514]
 [0.709]
 [0.521]
 [0.518]
 [0.523]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.513]
 [0.779]
 [0.514]
 [0.709]
 [0.521]
 [0.518]
 [0.523]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09307999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.09307999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.785]
 [0.785]
 [0.828]
 [0.785]
 [0.785]
 [0.785]
 [0.785]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.785]
 [0.785]
 [0.828]
 [0.785]
 [0.785]
 [0.785]
 [0.785]]
Printing some Q and Qe and total Qs values:  [[0.727]
 [0.727]
 [0.822]
 [0.727]
 [0.297]
 [0.727]
 [0.625]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.727]
 [0.727]
 [0.822]
 [0.727]
 [0.297]
 [0.727]
 [0.625]]
siam score:  -0.8825345
maxi score, test score, baseline:  0.08917999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08917999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08555999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08555999999999984 0.6645 0.6645
probs:  [1.0]
siam score:  -0.8876114
maxi score, test score, baseline:  0.08555999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08545999999999984 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.736]
 [0.918]
 [0.752]
 [0.787]
 [0.752]
 [0.752]
 [0.916]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.736]
 [0.918]
 [0.752]
 [0.787]
 [0.752]
 [0.752]
 [0.916]]
maxi score, test score, baseline:  0.08545999999999984 0.6645 0.6645
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08505999999999986 0.6645 0.6645
Printing some Q and Qe and total Qs values:  [[0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]]
maxi score, test score, baseline:  0.08211999999999985 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.991]
 [0.991]
 [0.991]
 [0.991]
 [0.991]
 [0.991]
 [0.991]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.991]
 [0.991]
 [0.991]
 [0.991]
 [0.991]
 [0.991]
 [0.991]]
Printing some Q and Qe and total Qs values:  [[0.569]
 [0.72 ]
 [0.569]
 [0.569]
 [0.569]
 [0.47 ]
 [0.519]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.569]
 [0.72 ]
 [0.569]
 [0.569]
 [0.569]
 [0.47 ]
 [0.519]]
Printing some Q and Qe and total Qs values:  [[0.599]
 [0.792]
 [0.599]
 [0.599]
 [0.599]
 [0.599]
 [0.599]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.599]
 [0.792]
 [0.599]
 [0.599]
 [0.599]
 [0.599]
 [0.599]]
maxi score, test score, baseline:  0.08211999999999986 0.6645 0.6645
maxi score, test score, baseline:  0.08211999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08191999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08191999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07915999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.09999999999999942  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07627999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07593999999999985 0.6645 0.6645
siam score:  -0.88840514
Printing some Q and Qe and total Qs values:  [[0.269]
 [0.275]
 [0.273]
 [0.264]
 [0.265]
 [0.257]
 [0.216]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.269]
 [0.275]
 [0.273]
 [0.264]
 [0.265]
 [0.257]
 [0.216]]
Printing some Q and Qe and total Qs values:  [[0.575]
 [0.768]
 [0.563]
 [0.553]
 [0.56 ]
 [0.569]
 [0.687]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.575]
 [0.768]
 [0.563]
 [0.553]
 [0.56 ]
 [0.569]
 [0.687]]
maxi score, test score, baseline:  0.07289999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.545]
 [0.569]
 [0.501]
 [0.545]
 [0.545]
 [0.496]
 [0.545]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.545]
 [0.569]
 [0.501]
 [0.545]
 [0.545]
 [0.496]
 [0.545]]
maxi score, test score, baseline:  0.07281999999999984 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.903]
 [0.984]
 [0.903]
 [0.903]
 [0.903]
 [0.903]
 [0.903]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.903]
 [0.984]
 [0.903]
 [0.903]
 [0.903]
 [0.903]
 [0.903]]
maxi score, test score, baseline:  0.07281999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07267999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07267999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07267999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8881811
maxi score, test score, baseline:  0.07263999999999984 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.502]
 [0.646]
 [0.501]
 [0.503]
 [0.505]
 [0.497]
 [0.495]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.502]
 [0.646]
 [0.501]
 [0.503]
 [0.505]
 [0.497]
 [0.495]]
maxi score, test score, baseline:  0.07263999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.073]
 [0.141]
 [0.088]
 [0.079]
 [0.069]
 [0.078]
 [0.12 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.073]
 [0.141]
 [0.088]
 [0.079]
 [0.069]
 [0.078]
 [0.12 ]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.895]
 [0.949]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.895]
 [0.949]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]]
Printing some Q and Qe and total Qs values:  [[0.413]
 [0.591]
 [0.424]
 [0.424]
 [0.428]
 [0.42 ]
 [0.411]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.413]
 [0.591]
 [0.424]
 [0.424]
 [0.428]
 [0.42 ]
 [0.411]]
Printing some Q and Qe and total Qs values:  [[0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]]
Printing some Q and Qe and total Qs values:  [[0.521]
 [0.743]
 [0.529]
 [0.519]
 [0.529]
 [0.529]
 [0.529]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.521]
 [0.743]
 [0.529]
 [0.519]
 [0.529]
 [0.529]
 [0.529]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07475999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07503999999999984 0.6645 0.6645
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]]
maxi score, test score, baseline:  0.07503999999999984 0.6645 0.6645
probs:  [1.0]
siam score:  -0.8899933
actor:  0 policy actor:  0  step number:  28 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07543999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07543999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07543999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07543999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07511999999999985 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[ 0.004]
 [ 0.193]
 [ 0.021]
 [ 0.017]
 [-0.001]
 [-0.004]
 [ 0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.004]
 [ 0.193]
 [ 0.021]
 [ 0.017]
 [-0.001]
 [-0.004]
 [ 0.004]]
maxi score, test score, baseline:  0.07221999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.101]
 [0.129]
 [0.101]
 [0.094]
 [0.101]
 [0.101]
 [0.118]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.101]
 [0.129]
 [0.101]
 [0.094]
 [0.101]
 [0.101]
 [0.118]]
maxi score, test score, baseline:  0.07171999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07157999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07161999999999984 0.6645 0.6645
maxi score, test score, baseline:  0.07161999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07175999999999982 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07197999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07197999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07511999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07529999999999985 0.6645 0.6645
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07785999999999985 0.6645 0.6645
maxi score, test score, baseline:  0.07459999999999985 0.6645 0.6645
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08077999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08065999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08065999999999983 0.6645 0.6645
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07775999999999984 0.6645 0.6645
probs:  [1.0]
siam score:  -0.8884583
maxi score, test score, baseline:  0.07775999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07765999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07849999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07519999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07211999999999985 0.6645 0.6645
Printing some Q and Qe and total Qs values:  [[0.873]
 [0.813]
 [0.873]
 [0.873]
 [0.873]
 [0.873]
 [0.873]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.873]
 [0.813]
 [0.873]
 [0.873]
 [0.873]
 [0.873]
 [0.873]]
maxi score, test score, baseline:  0.06911999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06911999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.34999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06909999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.015]
 [1.026]
 [1.015]
 [1.015]
 [1.015]
 [1.015]
 [1.015]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.015]
 [1.026]
 [1.015]
 [1.015]
 [1.015]
 [1.015]
 [1.015]]
maxi score, test score, baseline:  0.06953999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06779999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06779999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06779999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07075999999999985 0.6645 0.6645
maxi score, test score, baseline:  0.07075999999999985 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.536]
 [0.636]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.536]
 [0.636]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.061419999999999864 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06105999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06105999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06105999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.129]
 [0.325]
 [0.129]
 [0.154]
 [0.129]
 [0.129]
 [0.214]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.129]
 [0.325]
 [0.129]
 [0.154]
 [0.129]
 [0.129]
 [0.214]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.916]
 [0.984]
 [0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.916]
 [0.984]
 [0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06651999999999984 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.924]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.924]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]]
actor:  0 policy actor:  0  step number:  37 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06609999999999987 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06277999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06281999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06281999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06331999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06357999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06357999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06357999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06997999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07019999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07019999999999986 0.6645 0.6645
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.902]
 [0.926]
 [0.845]
 [0.89 ]
 [0.902]
 [0.848]
 [0.847]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.902]
 [0.926]
 [0.845]
 [0.89 ]
 [0.902]
 [0.848]
 [0.847]]
maxi score, test score, baseline:  0.07003999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06991999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06991999999999986 0.6645 0.6645
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.6  ]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.535]
 [0.6  ]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]]
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.754]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.535]
 [0.754]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]]
maxi score, test score, baseline:  0.07593999999999985 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.539]
 [0.524]
 [0.539]
 [0.539]
 [0.539]
 [0.539]
 [0.539]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.539]
 [0.524]
 [0.539]
 [0.539]
 [0.539]
 [0.539]
 [0.539]]
Printing some Q and Qe and total Qs values:  [[0.712]
 [0.763]
 [0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.712]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.712]
 [0.763]
 [0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.712]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.457]
 [0.745]
 [0.45 ]
 [0.459]
 [0.466]
 [0.449]
 [0.467]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.457]
 [0.745]
 [0.45 ]
 [0.459]
 [0.466]
 [0.449]
 [0.467]]
maxi score, test score, baseline:  0.07263999999999986 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.52 ]
 [0.68 ]
 [0.645]
 [0.645]
 [0.493]
 [0.645]
 [0.645]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.52 ]
 [0.68 ]
 [0.645]
 [0.645]
 [0.493]
 [0.645]
 [0.645]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07247999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07247999999999984 0.6645 0.6645
maxi score, test score, baseline:  0.07247999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07271999999999985 0.6645 0.6645
maxi score, test score, baseline:  0.07271999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06997999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.923]
 [0.954]
 [0.923]
 [0.923]
 [0.923]
 [0.923]
 [0.923]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.923]
 [0.954]
 [0.923]
 [0.923]
 [0.923]
 [0.923]
 [0.923]]
maxi score, test score, baseline:  0.07015999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07265999999999985 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.276]
 [0.276]
 [0.276]
 [0.276]
 [0.276]
 [0.276]
 [0.278]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.276]
 [0.276]
 [0.276]
 [0.276]
 [0.276]
 [0.276]
 [0.278]]
Printing some Q and Qe and total Qs values:  [[0.721]
 [0.769]
 [0.721]
 [0.721]
 [0.721]
 [0.721]
 [0.721]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.721]
 [0.769]
 [0.721]
 [0.721]
 [0.721]
 [0.721]
 [0.721]]
maxi score, test score, baseline:  0.06945999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06945999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06939999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07245999999999984 0.6645 0.6645
probs:  [1.0]
siam score:  -0.88214767
Printing some Q and Qe and total Qs values:  [[0.194]
 [0.271]
 [0.204]
 [0.217]
 [0.413]
 [0.413]
 [0.413]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.194]
 [0.271]
 [0.204]
 [0.217]
 [0.413]
 [0.413]
 [0.413]]
maxi score, test score, baseline:  0.07245999999999984 0.6645 0.6645
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.07245999999999984 0.6645 0.6645
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06879999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06879999999999985 0.6645 0.6645
maxi score, test score, baseline:  0.06879999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06539999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8809562
maxi score, test score, baseline:  0.06845999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07437999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07437999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07721999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07721999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07721999999999983 0.6645 0.6645
maxi score, test score, baseline:  0.07721999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.503]
 [0.585]
 [0.459]
 [0.452]
 [0.455]
 [0.445]
 [0.615]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.503]
 [0.585]
 [0.459]
 [0.452]
 [0.455]
 [0.445]
 [0.615]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.892]
 [0.924]
 [0.892]
 [0.892]
 [0.892]
 [0.892]
 [0.776]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.892]
 [0.924]
 [0.892]
 [0.892]
 [0.892]
 [0.892]
 [0.776]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07759999999999984 0.6645 0.6645
probs:  [1.0]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.0822],
        [-0.0000],
        [-0.1638],
        [-0.0822],
        [-0.0000],
        [ 0.7619],
        [ 0.0383],
        [-0.1923],
        [-0.2030],
        [ 0.1356]], dtype=torch.float64)
-0.145559551797 -0.22778605074680613
-0.6730033166999999 -0.6730033166999999
-0.125759551797 -0.2895522518389808
-0.145559551797 -0.22778605074680613
-0.8758811940119999 -0.8758811940119999
-0.067539651597 0.6943670582530974
-0.145559551797 -0.10725725191451467
-0.067539651597 -0.2598574613198396
-0.106157551797 -0.30915037635532594
-0.087921850599 0.047639320601625776
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.932]
 [0.985]
 [0.931]
 [0.932]
 [0.932]
 [0.932]
 [0.932]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.932]
 [0.985]
 [0.931]
 [0.932]
 [0.932]
 [0.932]
 [0.932]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07473999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07375999999999984 0.6645 0.6645
maxi score, test score, baseline:  0.07375999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07319999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06769999999999984 0.6645 0.6645
Printing some Q and Qe and total Qs values:  [[0.564]
 [0.817]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.564]
 [0.817]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]]
Printing some Q and Qe and total Qs values:  [[0.75 ]
 [0.75 ]
 [0.775]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.75 ]
 [0.75 ]
 [0.775]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]]
actor:  0 policy actor:  0  step number:  37 total reward:  0.11999999999999944  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.06381999999999985 0.6645 0.6645
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06363999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.574]
 [0.773]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.574]
 [0.773]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]]
maxi score, test score, baseline:  0.06439999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06439999999999985 0.6645 0.6645
probs:  [1.0]
siam score:  -0.8784171
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06487999999999985 0.6645 0.6645
maxi score, test score, baseline:  0.06487999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.06487999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06779999999999985 0.6645 0.6645
siam score:  -0.8785083
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  40 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07305999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07447999999999984 0.6645 0.6645
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07795999999999985 0.6645 0.6645
maxi score, test score, baseline:  0.07795999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.556]
 [0.793]
 [0.564]
 [0.583]
 [0.597]
 [0.512]
 [0.584]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.556]
 [0.793]
 [0.564]
 [0.583]
 [0.597]
 [0.512]
 [0.584]]
siam score:  -0.8872536
Printing some Q and Qe and total Qs values:  [[0.876]
 [0.939]
 [0.84 ]
 [0.876]
 [0.876]
 [0.876]
 [0.876]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.876]
 [0.939]
 [0.84 ]
 [0.876]
 [0.876]
 [0.876]
 [0.876]]
siam score:  -0.8872089
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08099999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08099999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  43 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08079999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08083999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08083999999999986 0.6645 0.6645
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08341999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08293999999999983 0.6645 0.6645
maxi score, test score, baseline:  0.07983999999999984 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.749]
 [0.774]
 [0.739]
 [0.731]
 [0.719]
 [0.716]
 [0.734]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.749]
 [0.774]
 [0.739]
 [0.731]
 [0.719]
 [0.716]
 [0.734]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.07983999999999984 0.6645 0.6645
maxi score, test score, baseline:  0.07983999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08265999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07933999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07933999999999984 0.6645 0.6645
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08281999999999987 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08603999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08631999999999986 0.6645 0.6645
probs:  [1.0]
siam score:  -0.9000604
maxi score, test score, baseline:  0.08313999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07753999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07753999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07753999999999983 0.6645 0.6645
actor:  0 policy actor:  0  step number:  36 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.89876664
maxi score, test score, baseline:  0.08001999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08001999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  43 total reward:  0.2999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07931999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08215999999999983 0.6645 0.6645
maxi score, test score, baseline:  0.08215999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08215999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  42 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08485999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07823999999999985 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.958]
 [0.917]
 [0.917]
 [0.917]
 [0.917]
 [0.917]
 [0.917]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.958]
 [0.917]
 [0.917]
 [0.917]
 [0.917]
 [0.917]
 [0.917]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.215]
 [0.215]
 [0.215]
 [0.215]
 [0.215]
 [0.215]
 [0.215]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.215]
 [0.215]
 [0.215]
 [0.215]
 [0.215]
 [0.215]
 [0.215]]
maxi score, test score, baseline:  0.08123999999999985 0.6645 0.6645
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.783]
 [0.838]
 [0.815]
 [0.779]
 [0.783]
 [0.784]
 [0.791]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.783]
 [0.838]
 [0.815]
 [0.779]
 [0.783]
 [0.784]
 [0.791]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07803999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07805999999999985 0.6645 0.6645
actor:  0 policy actor:  0  step number:  31 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07765999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07765999999999985 0.6645 0.6645
maxi score, test score, baseline:  0.07765999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07761999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07481999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07481999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07777999999999985 0.6645 0.6645
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.86 ]
 [0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.722]
 [0.86 ]
 [0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]]
maxi score, test score, baseline:  0.07777999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07773999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.83 ]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.83 ]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]]
maxi score, test score, baseline:  0.08391999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08385999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08093999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08093999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.694]
 [0.735]
 [0.694]
 [0.708]
 [0.694]
 [0.694]
 [0.728]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.694]
 [0.735]
 [0.694]
 [0.708]
 [0.694]
 [0.694]
 [0.728]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07725999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07725999999999986 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07725999999999986 0.6645 0.6645
maxi score, test score, baseline:  0.07433999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07397999999999985 0.6645 0.6645
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.02  0.918 0.02  0.02  0.    0.    0.02 ]
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07667999999999985 0.6645 0.6645
siam score:  -0.8981273
maxi score, test score, baseline:  0.07667999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.10999999999999943  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07537999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  42 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07567999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07845999999999984 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.662]
 [0.871]
 [0.662]
 [0.662]
 [0.662]
 [0.662]
 [0.662]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.662]
 [0.871]
 [0.662]
 [0.662]
 [0.662]
 [0.662]
 [0.662]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07851999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07807999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.929]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.929]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]]
siam score:  -0.8982914
actor:  0 policy actor:  0  step number:  31 total reward:  0.5399999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.854]
 [0.873]
 [0.872]
 [0.854]
 [0.854]
 [0.854]
 [0.854]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.854]
 [0.873]
 [0.872]
 [0.854]
 [0.854]
 [0.854]
 [0.854]]
maxi score, test score, baseline:  0.08117999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08153999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.225]
 [0.768]
 [0.845]
 [0.737]
 [0.274]
 [0.2  ]
 [0.733]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.225]
 [0.768]
 [0.845]
 [0.737]
 [0.274]
 [0.2  ]
 [0.733]]
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08473999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08229999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08223999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08223999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08287999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08611999999999985 0.6645 0.6645
probs:  [1.0]
siam score:  -0.8978119
maxi score, test score, baseline:  0.08611999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08611999999999985 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.913]
 [0.956]
 [0.897]
 [0.918]
 [0.918]
 [0.918]
 [0.896]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.913]
 [0.956]
 [0.897]
 [0.918]
 [0.918]
 [0.918]
 [0.896]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08863999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.08837999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08525999999999982 0.6645 0.6645
maxi score, test score, baseline:  0.08525999999999982 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08841999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08625999999999982 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08625999999999982 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08625999999999982 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08313999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08307999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08615999999999983 0.6645 0.6645
maxi score, test score, baseline:  0.08615999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08615999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08947999999999982 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08947999999999982 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08935999999999984 0.6645 0.6645
maxi score, test score, baseline:  0.08935999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08647999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08647999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08647999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.90182185
siam score:  -0.9011465
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]]
maxi score, test score, baseline:  0.08937999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08983999999999984 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.403]
 [0.5  ]
 [0.405]
 [0.403]
 [0.403]
 [0.403]
 [0.403]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.403]
 [0.5  ]
 [0.405]
 [0.403]
 [0.403]
 [0.403]
 [0.403]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09899999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09915999999999983 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.09915999999999983 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.848]
 [0.938]
 [0.848]
 [0.848]
 [0.848]
 [0.848]
 [0.848]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.848]
 [0.938]
 [0.848]
 [0.848]
 [0.848]
 [0.848]
 [0.848]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09015999999999984 0.6645 0.6645
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.489]
 [0.539]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.489]
 [0.539]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09085999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8873016
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.736]
 [0.723]
 [0.704]
 [0.709]
 [0.709]
 [0.754]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.81 ]
 [0.736]
 [0.723]
 [0.704]
 [0.709]
 [0.709]
 [0.754]]
Printing some Q and Qe and total Qs values:  [[0.706]
 [0.861]
 [0.779]
 [0.753]
 [0.759]
 [0.761]
 [0.882]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.706]
 [0.861]
 [0.779]
 [0.753]
 [0.759]
 [0.761]
 [0.882]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08723999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.184]
 [0.251]
 [0.184]
 [0.168]
 [0.184]
 [0.184]
 [0.224]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.184]
 [0.251]
 [0.184]
 [0.168]
 [0.184]
 [0.184]
 [0.224]]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8893313
maxi score, test score, baseline:  0.08387999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08387999999999984 0.6645 0.6645
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.08065999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08113999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  43 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08005999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8967736
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07669999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.07669999999999984 0.6645 0.6645
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08299999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08299999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08299999999999984 0.6645 0.6645
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08645999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.929]
 [0.913]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.929]
 [0.913]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.919]
 [0.919]
 [0.919]
 [0.919]
 [0.919]
 [0.919]
 [0.919]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.919]
 [0.919]
 [0.919]
 [0.919]
 [0.919]
 [0.919]
 [0.919]]
maxi score, test score, baseline:  0.09049999999999984 0.6645 0.6645
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09041999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.884]
 [0.943]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.947]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.884]
 [0.943]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.947]]
maxi score, test score, baseline:  0.09313999999999982 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.809]
 [0.807]
 [0.808]
 [0.806]
 [0.806]
 [0.809]
 [0.809]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.809]
 [0.807]
 [0.808]
 [0.806]
 [0.806]
 [0.809]
 [0.809]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09385999999999985 0.6645 0.6645
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.962]
 [1.004]
 [0.962]
 [0.962]
 [0.962]
 [0.962]
 [0.962]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.962]
 [1.004]
 [0.962]
 [0.962]
 [0.962]
 [0.962]
 [0.962]]
Printing some Q and Qe and total Qs values:  [[0.94 ]
 [0.991]
 [0.922]
 [0.952]
 [0.926]
 [0.926]
 [0.96 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.94 ]
 [0.991]
 [0.922]
 [0.952]
 [0.926]
 [0.926]
 [0.96 ]]
maxi score, test score, baseline:  0.09385999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.857]
 [0.693]
 [0.693]
 [0.693]
 [0.693]
 [0.693]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.693]
 [0.857]
 [0.693]
 [0.693]
 [0.693]
 [0.693]
 [0.693]]
maxi score, test score, baseline:  0.09451999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.301]
 [0.989]
 [0.904]
 [0.897]
 [0.897]
 [0.897]
 [0.827]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.301]
 [0.989]
 [0.904]
 [0.897]
 [0.897]
 [0.897]
 [0.827]]
maxi score, test score, baseline:  0.09757999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.215]
 [0.774]
 [0.844]
 [0.774]
 [0.238]
 [0.774]
 [0.636]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.215]
 [0.774]
 [0.844]
 [0.774]
 [0.238]
 [0.774]
 [0.636]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09777999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.691]
 [0.896]
 [0.762]
 [0.821]
 [0.864]
 [0.864]
 [0.903]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.691]
 [0.896]
 [0.762]
 [0.821]
 [0.864]
 [0.864]
 [0.903]]
maxi score, test score, baseline:  0.09151999999999987 0.6645 0.6645
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09457999999999984 0.6645 0.6645
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09139999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.579]
 [0.755]
 [0.584]
 [0.557]
 [0.557]
 [0.557]
 [0.558]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.579]
 [0.755]
 [0.584]
 [0.557]
 [0.557]
 [0.557]
 [0.558]]
maxi score, test score, baseline:  0.09203999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.09203999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.584]
 [0.656]
 [0.584]
 [0.584]
 [0.584]
 [0.584]
 [0.584]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.584]
 [0.656]
 [0.584]
 [0.584]
 [0.584]
 [0.584]
 [0.584]]
maxi score, test score, baseline:  0.09131999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08805999999999985 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08805999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.539]
 [0.649]
 [0.532]
 [0.633]
 [0.567]
 [0.524]
 [0.542]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.539]
 [0.649]
 [0.532]
 [0.633]
 [0.567]
 [0.524]
 [0.542]]
maxi score, test score, baseline:  0.08513999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08511999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8978441
maxi score, test score, baseline:  0.08791999999999986 0.6645 0.6645
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09111999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08801999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[ 1.179]
 [ 0.002]
 [-0.   ]
 [-0.002]
 [ 1.179]
 [ 0.   ]
 [ 1.179]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 1.179]
 [ 0.002]
 [-0.   ]
 [-0.002]
 [ 1.179]
 [ 0.   ]
 [ 1.179]]
maxi score, test score, baseline:  0.08841999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08571999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.14999999999999947  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8964932
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09135999999999986 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
siam score:  -0.8973206
maxi score, test score, baseline:  0.09159999999999985 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08845999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08527999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08527999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.917]
 [0.755]
 [0.755]
 [0.755]
 [0.755]
 [0.755]
 [0.755]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.917]
 [0.755]
 [0.755]
 [0.755]
 [0.755]
 [0.755]
 [0.755]]
maxi score, test score, baseline:  0.08457999999999985 0.6645 0.6645
maxi score, test score, baseline:  0.08457999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08427999999999984 0.6645 0.6645
probs:  [1.0]
maxi score, test score, baseline:  0.08427999999999984 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08481999999999983 0.6645 0.6645
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.891]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.891]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.08463999999999983 0.6645 0.6645
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.987]
 [0.988]
 [0.987]
 [0.935]
 [0.92 ]
 [0.87 ]
 [0.988]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.987]
 [0.988]
 [0.987]
 [0.935]
 [0.92 ]
 [0.87 ]
 [0.988]]
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
siam score:  -0.88946366
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10747999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.544]
 [0.83 ]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.544]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.544]
 [0.83 ]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.544]]
maxi score, test score, baseline:  0.10467999999999984 0.695 0.695
maxi score, test score, baseline:  0.10467999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.10467999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.10467999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.10159999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09815999999999984 0.695 0.695
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10127999999999987 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.10127999999999987 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.10127999999999987 0.695 0.695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.015]
 [1.003]
 [1.003]
 [1.003]
 [1.003]
 [1.003]
 [1.003]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.015]
 [1.003]
 [1.003]
 [1.003]
 [1.003]
 [1.003]
 [1.003]]
siam score:  -0.890776
maxi score, test score, baseline:  0.09583999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09909999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.09909999999999985 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.784]
 [0.915]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.905]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.784]
 [0.915]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.905]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.09875999999999986 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.09875999999999986 0.695 0.695
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
siam score:  -0.891107
Printing some Q and Qe and total Qs values:  [[0.3  ]
 [0.233]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.3  ]
 [0.233]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]]
maxi score, test score, baseline:  0.09289999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09287999999999984 0.695 0.695
maxi score, test score, baseline:  0.09287999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09323999999999985 0.695 0.695
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09617999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.09617999999999985 0.695 0.695
Printing some Q and Qe and total Qs values:  [[1.01]
 [0.95]
 [0.95]
 [0.95]
 [0.95]
 [0.95]
 [0.95]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.01]
 [0.95]
 [0.95]
 [0.95]
 [0.95]
 [0.95]
 [0.95]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09617999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.09617999999999985 0.695 0.695
actor:  0 policy actor:  0  step number:  35 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09571999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09561999999999987 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.09561999999999987 0.695 0.695
maxi score, test score, baseline:  0.09561999999999987 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.09561999999999987 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08993999999999987 0.695 0.695
probs:  [1.0]
siam score:  -0.85790557
maxi score, test score, baseline:  0.08993999999999987 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08969999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08679999999999985 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]]
maxi score, test score, baseline:  0.08679999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08651999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08651999999999985 0.695 0.695
maxi score, test score, baseline:  0.08651999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.333]
 [0.332]
 [0.34 ]
 [0.343]
 [0.335]
 [0.337]
 [0.34 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.333]
 [0.332]
 [0.34 ]
 [0.343]
 [0.335]
 [0.337]
 [0.34 ]]
maxi score, test score, baseline:  0.08657999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08657999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  51 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08369999999999984 0.695 0.695
maxi score, test score, baseline:  0.08369999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08303999999999986 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08303999999999986 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08303999999999986 0.695 0.695
maxi score, test score, baseline:  0.08303999999999986 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.352]
 [0.83 ]
 [0.352]
 [0.352]
 [0.352]
 [0.352]
 [0.435]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.352]
 [0.83 ]
 [0.352]
 [0.352]
 [0.352]
 [0.352]
 [0.435]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8632369
actor:  0 policy actor:  0  step number:  29 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07235999999999985 0.695 0.695
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.565]
 [0.58 ]
 [0.581]
 [0.582]
 [0.582]
 [0.582]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.582]
 [0.565]
 [0.58 ]
 [0.581]
 [0.582]
 [0.582]
 [0.582]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07135999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07069999999999986 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.947]
 [0.873]
 [0.863]
 [0.947]
 [0.947]
 [0.947]
 [0.947]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.947]
 [0.873]
 [0.863]
 [0.947]
 [0.947]
 [0.947]
 [0.947]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07033999999999985 0.695 0.695
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06671999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06671999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06671999999999985 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.26 ]
 [0.655]
 [0.251]
 [0.254]
 [0.252]
 [0.248]
 [0.244]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.26 ]
 [0.655]
 [0.251]
 [0.254]
 [0.252]
 [0.248]
 [0.244]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06663999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06309999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06309999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.060479999999999846 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06085999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06085999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06391999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06391999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.91 ]
 [0.917]
 [0.899]
 [0.905]
 [0.892]
 [0.899]
 [0.862]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.91 ]
 [0.917]
 [0.899]
 [0.905]
 [0.892]
 [0.899]
 [0.862]]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.061039999999999844 0.695 0.695
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06427999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8596475
maxi score, test score, baseline:  0.06145999999999985 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.865]
 [0.701]
 [0.777]
 [0.777]
 [0.777]
 [0.777]
 [0.654]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.865]
 [0.701]
 [0.777]
 [0.777]
 [0.777]
 [0.777]
 [0.654]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.468]
 [0.492]
 [0.468]
 [0.468]
 [0.468]
 [0.468]
 [0.468]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.468]
 [0.492]
 [0.468]
 [0.468]
 [0.468]
 [0.468]
 [0.468]]
Printing some Q and Qe and total Qs values:  [[0.072]
 [0.247]
 [0.072]
 [0.072]
 [0.072]
 [0.072]
 [0.05 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.072]
 [0.247]
 [0.072]
 [0.072]
 [0.072]
 [0.072]
 [0.05 ]]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05893999999999985 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.481]
 [0.523]
 [0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.481]
 [0.523]
 [0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.058919999999999854 0.695 0.695
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06141999999999986 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06141999999999986 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06141999999999986 0.695 0.695
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06189999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.418]
 [0.824]
 [0.84 ]
 [0.759]
 [0.789]
 [0.781]
 [0.832]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.418]
 [0.824]
 [0.84 ]
 [0.759]
 [0.789]
 [0.781]
 [0.832]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06505999999999984 0.695 0.695
maxi score, test score, baseline:  0.06505999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.429]
 [0.711]
 [0.447]
 [0.437]
 [0.443]
 [0.447]
 [0.447]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.429]
 [0.711]
 [0.447]
 [0.437]
 [0.443]
 [0.447]
 [0.447]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06535999999999985 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.758]
 [0.837]
 [0.758]
 [0.731]
 [0.758]
 [0.758]
 [0.758]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.758]
 [0.837]
 [0.758]
 [0.731]
 [0.758]
 [0.758]
 [0.758]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06217999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.976]
 [1.013]
 [0.976]
 [0.976]
 [0.976]
 [0.976]
 [0.976]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.976]
 [1.013]
 [0.976]
 [0.976]
 [0.976]
 [0.976]
 [0.976]]
maxi score, test score, baseline:  0.06179999999999984 0.695 0.695
Printing some Q and Qe and total Qs values:  [[0.686]
 [0.686]
 [0.888]
 [0.686]
 [0.686]
 [0.686]
 [0.686]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.686]
 [0.686]
 [0.888]
 [0.686]
 [0.686]
 [0.686]
 [0.686]]
UNIT TEST: sample policy line 217 mcts : [0.102 0.449 0.061 0.102 0.041 0.163 0.082]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06159999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06183999999999985 0.695 0.695
maxi score, test score, baseline:  0.058639999999999845 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05903999999999985 0.695 0.695
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.05611999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  50 total reward:  0.10999999999999943  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05535999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05819999999999985 0.695 0.695
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.061159999999999846 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.061159999999999846 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.05895999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.08999999999999941  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.058499999999999844 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.11999999999999944  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.886]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.832]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.886]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.832]]
maxi score, test score, baseline:  0.06385999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8831518
maxi score, test score, baseline:  0.06077999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.05205999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.608]
 [0.732]
 [0.608]
 [0.608]
 [0.608]
 [0.608]
 [0.608]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.608]
 [0.732]
 [0.608]
 [0.608]
 [0.608]
 [0.608]
 [0.608]]
siam score:  -0.8839183
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05203999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.04953999999999986 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.04953999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.052659999999999846 0.695 0.695
maxi score, test score, baseline:  0.052659999999999846 0.695 0.695
maxi score, test score, baseline:  0.052659999999999846 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.88705444
siam score:  -0.888697
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05233999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05529999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.055139999999999856 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05849999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05925999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06529999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06529999999999984 0.695 0.695
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.143]
 [0.186]
 [0.143]
 [0.143]
 [0.143]
 [0.143]
 [0.143]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.143]
 [0.186]
 [0.143]
 [0.143]
 [0.143]
 [0.143]
 [0.143]]
Printing some Q and Qe and total Qs values:  [[0.908]
 [0.789]
 [0.789]
 [0.789]
 [0.789]
 [0.789]
 [0.789]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.908]
 [0.789]
 [0.789]
 [0.789]
 [0.789]
 [0.789]
 [0.789]]
maxi score, test score, baseline:  0.06251999999999984 0.695 0.695
maxi score, test score, baseline:  0.06251999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.117]
 [0.139]
 [0.117]
 [0.021]
 [0.117]
 [0.117]
 [0.143]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.117]
 [0.139]
 [0.117]
 [0.021]
 [0.117]
 [0.117]
 [0.143]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06235999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[ 0.672]
 [ 0.703]
 [ 0.672]
 [ 0.643]
 [ 0.672]
 [-0.007]
 [ 0.68 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.672]
 [ 0.703]
 [ 0.672]
 [ 0.643]
 [ 0.672]
 [-0.007]
 [ 0.68 ]]
maxi score, test score, baseline:  0.06219999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06219999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06219999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06489999999999985 0.695 0.695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.042]
 [0.088]
 [0.036]
 [0.039]
 [0.047]
 [0.047]
 [0.059]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.042]
 [0.088]
 [0.036]
 [0.039]
 [0.047]
 [0.047]
 [0.059]]
maxi score, test score, baseline:  0.06477999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06477999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06787999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.73 ]
 [0.859]
 [0.783]
 [0.621]
 [0.783]
 [0.783]
 [0.215]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.73 ]
 [0.859]
 [0.783]
 [0.621]
 [0.783]
 [0.783]
 [0.215]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06765999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06765999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06765999999999985 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.956]
 [0.991]
 [0.967]
 [0.959]
 [0.96 ]
 [0.958]
 [0.967]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.956]
 [0.991]
 [0.967]
 [0.959]
 [0.96 ]
 [0.958]
 [0.967]]
actor:  0 policy actor:  0  step number:  37 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.723]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.616]
 [0.723]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]]
maxi score, test score, baseline:  0.06369999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06369999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.761]
 [0.9  ]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.761]
 [0.9  ]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.89450616
maxi score, test score, baseline:  0.06375999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06341999999999985 0.695 0.695
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06657999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06349999999999985 0.695 0.695
actor:  0 policy actor:  0  step number:  35 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.605]
 [0.605]
 [0.733]
 [0.605]
 [0.605]
 [0.605]
 [0.605]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.605]
 [0.605]
 [0.733]
 [0.605]
 [0.605]
 [0.605]
 [0.605]]
Printing some Q and Qe and total Qs values:  [[0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]
 [0.783]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.954]
 [0.965]
 [0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.954]
 [0.965]
 [0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]]
Printing some Q and Qe and total Qs values:  [[0.947]
 [1.015]
 [0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.947]
 [1.015]
 [0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]]
maxi score, test score, baseline:  0.06573999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.64 ]
 [0.785]
 [0.674]
 [0.674]
 [0.674]
 [0.635]
 [0.674]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.64 ]
 [0.785]
 [0.674]
 [0.674]
 [0.674]
 [0.635]
 [0.674]]
siam score:  -0.89949155
maxi score, test score, baseline:  0.06583999999999984 0.695 0.695
maxi score, test score, baseline:  0.06583999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.90107465
maxi score, test score, baseline:  0.06573999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06573999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06799999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07081999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.543]
 [0.697]
 [0.569]
 [0.545]
 [0.558]
 [0.554]
 [0.58 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.543]
 [0.697]
 [0.569]
 [0.545]
 [0.558]
 [0.554]
 [0.58 ]]
Printing some Q and Qe and total Qs values:  [[0.824]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.824]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]]
maxi score, test score, baseline:  0.07081999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07081999999999986 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06765999999999983 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.309]
 [0.931]
 [0.943]
 [0.831]
 [0.715]
 [0.778]
 [0.551]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.309]
 [0.931]
 [0.943]
 [0.831]
 [0.715]
 [0.778]
 [0.551]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07111999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06739999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06739999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07367999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07367999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07671999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07963999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07925999999999986 0.695 0.695
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07947999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07947999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08275999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08275999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08275999999999985 0.695 0.695
actor:  0 policy actor:  0  step number:  35 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.174]
 [0.232]
 [0.174]
 [0.174]
 [0.174]
 [0.174]
 [0.174]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.174]
 [0.232]
 [0.174]
 [0.174]
 [0.174]
 [0.174]
 [0.174]]
maxi score, test score, baseline:  0.07983999999999984 0.695 0.695
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.07717999999999985 0.695 0.695
maxi score, test score, baseline:  0.07717999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07697999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07729999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07753999999999983 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.355]
 [0.379]
 [0.355]
 [0.355]
 [0.355]
 [0.355]
 [0.355]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.355]
 [0.379]
 [0.355]
 [0.355]
 [0.355]
 [0.355]
 [0.355]]
actor:  0 policy actor:  0  step number:  38 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.989]
 [0.988]
 [0.993]
 [0.893]
 [0.964]
 [0.923]
 [0.983]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.989]
 [0.988]
 [0.993]
 [0.893]
 [0.964]
 [0.923]
 [0.983]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.897]
 [0.937]
 [0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.897]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.897]
 [0.937]
 [0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.897]]
maxi score, test score, baseline:  0.07691999999999985 0.695 0.695
maxi score, test score, baseline:  0.07691999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.5399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07699999999999983 0.695 0.695
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07679999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07321999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.894696
maxi score, test score, baseline:  0.07295999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.193]
 [0.198]
 [0.186]
 [0.181]
 [0.311]
 [0.178]
 [0.311]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.193]
 [0.198]
 [0.186]
 [0.181]
 [0.311]
 [0.178]
 [0.311]]
maxi score, test score, baseline:  0.07295999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06985999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06985999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.06985999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.995]
 [0.995]
 [0.995]
 [0.994]
 [0.994]
 [0.994]
 [0.995]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.995]
 [0.995]
 [0.995]
 [0.994]
 [0.994]
 [0.994]
 [0.995]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.06967999999999984 0.695 0.695
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06947999999999983 0.695 0.695
probs:  [1.0]
siam score:  -0.8966217
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06971999999999984 0.695 0.695
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07229999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07229999999999985 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.936]
 [0.937]
 [0.937]
 [0.937]
 [0.937]
 [0.937]
 [0.937]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.936]
 [0.937]
 [0.937]
 [0.937]
 [0.937]
 [0.937]
 [0.937]]
actor:  0 policy actor:  0  step number:  36 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07189999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07189999999999984 0.695 0.695
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
siam score:  -0.9033647
maxi score, test score, baseline:  0.07417999999999984 0.695 0.695
probs:  [1.0]
siam score:  -0.90253085
maxi score, test score, baseline:  0.07417999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.918]
 [0.987]
 [0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.918]
 [0.987]
 [0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07435999999999986 0.695 0.695
Printing some Q and Qe and total Qs values:  [[0.452]
 [0.7  ]
 [0.459]
 [0.528]
 [0.456]
 [0.454]
 [0.453]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.452]
 [0.7  ]
 [0.459]
 [0.528]
 [0.456]
 [0.454]
 [0.453]]
maxi score, test score, baseline:  0.07129999999999985 0.695 0.695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.07129999999999985 0.695 0.695
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.902]
 [0.817]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.891]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.902]
 [0.817]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.891]]
maxi score, test score, baseline:  0.07371999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07725999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.767]
 [0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.864]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.767]
 [0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.864]]
Printing some Q and Qe and total Qs values:  [[0.561]
 [0.684]
 [0.587]
 [0.585]
 [0.578]
 [0.672]
 [0.575]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.561]
 [0.684]
 [0.587]
 [0.585]
 [0.578]
 [0.672]
 [0.575]]
Printing some Q and Qe and total Qs values:  [[0.608]
 [0.608]
 [0.608]
 [0.608]
 [0.608]
 [0.608]
 [0.608]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.608]
 [0.608]
 [0.608]
 [0.608]
 [0.608]
 [0.608]
 [0.608]]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08237999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07957999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07957999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07663999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07663999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07687999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07413999999999984 0.695 0.695
maxi score, test score, baseline:  0.07413999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  44 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07723999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07723999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07723999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.9023432
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07541999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07541999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07553999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08123999999999985 0.695 0.695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.08123999999999985 0.695 0.695
Printing some Q and Qe and total Qs values:  [[0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]]
maxi score, test score, baseline:  0.08123999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08123999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08395999999999984 0.695 0.695
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08455999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.921]
 [0.99 ]
 [0.959]
 [0.934]
 [0.934]
 [0.926]
 [0.94 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.921]
 [0.99 ]
 [0.959]
 [0.934]
 [0.934]
 [0.926]
 [0.94 ]]
maxi score, test score, baseline:  0.08455999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.89904404
maxi score, test score, baseline:  0.08699999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
siam score:  -0.898089
Printing some Q and Qe and total Qs values:  [[0.74 ]
 [0.918]
 [0.752]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.764]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.74 ]
 [0.918]
 [0.752]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.764]]
maxi score, test score, baseline:  0.09037999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8982504
maxi score, test score, baseline:  0.08775999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08791999999999986 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08791999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08785999999999985 0.695 0.695
Printing some Q and Qe and total Qs values:  [[0.197]
 [0.226]
 [0.204]
 [0.202]
 [0.199]
 [0.199]
 [0.194]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.197]
 [0.226]
 [0.204]
 [0.202]
 [0.199]
 [0.199]
 [0.194]]
maxi score, test score, baseline:  0.08225999999999983 0.695 0.695
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08237999999999983 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[ 1.384]
 [-0.004]
 [ 1.384]
 [ 0.211]
 [ 1.384]
 [ 1.384]
 [ 1.384]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 1.384]
 [-0.004]
 [ 1.384]
 [ 0.211]
 [ 1.384]
 [ 1.384]
 [ 1.384]]
maxi score, test score, baseline:  0.07899999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07899999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07885999999999982 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07283999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.799]
 [0.762]
 [0.811]
 [0.68 ]
 [0.609]
 [0.811]
 [0.805]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.799]
 [0.762]
 [0.811]
 [0.68 ]
 [0.609]
 [0.811]
 [0.805]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07027999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.63 ]
 [0.729]
 [0.599]
 [0.591]
 [0.594]
 [0.628]
 [0.741]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.63 ]
 [0.729]
 [0.599]
 [0.591]
 [0.594]
 [0.628]
 [0.741]]
Printing some Q and Qe and total Qs values:  [[0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06749999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.89188254
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06277999999999985 0.695 0.695
maxi score, test score, baseline:  0.06277999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06603999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.894]
 [0.376]
 [0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.649]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.894]
 [0.376]
 [0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.649]]
maxi score, test score, baseline:  0.06973999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06997999999999983 0.695 0.695
actor:  0 policy actor:  0  step number:  39 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07017999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07017999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.74 ]
 [0.74 ]
 [0.869]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.771]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.74 ]
 [0.74 ]
 [0.869]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.771]]
actor:  0 policy actor:  0  step number:  38 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07033999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07033999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07033999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07599999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07599999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07599999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07669999999999984 0.695 0.695
maxi score, test score, baseline:  0.07669999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.881]
 [0.951]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.881]
 [0.951]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]]
maxi score, test score, baseline:  0.07639999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.94 ]
 [0.917]
 [0.861]
 [0.81 ]
 [0.819]
 [0.861]
 [0.909]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.94 ]
 [0.917]
 [0.861]
 [0.81 ]
 [0.819]
 [0.861]
 [0.909]]
maxi score, test score, baseline:  0.07669999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07669999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07417999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07417999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07469999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.865]
 [0.865]
 [0.865]
 [0.865]
 [0.865]
 [0.865]
 [0.865]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.865]
 [0.865]
 [0.865]
 [0.865]
 [0.865]
 [0.865]
 [0.865]]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07793999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07481999999999984 0.695 0.695
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07809999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08123999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08123999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08241999999999983 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]]
maxi score, test score, baseline:  0.08241999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.62 ]
 [0.854]
 [0.62 ]
 [0.62 ]
 [0.62 ]
 [0.62 ]
 [0.62 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.62 ]
 [0.854]
 [0.62 ]
 [0.62 ]
 [0.62 ]
 [0.62 ]
 [0.62 ]]
maxi score, test score, baseline:  0.08265999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08265999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08265999999999983 0.695 0.695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.564]
 [0.644]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.564]
 [0.644]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07993999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07993999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07993999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.83 ]
 [0.861]
 [0.814]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.83 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.83 ]
 [0.861]
 [0.814]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.83 ]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07783999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07783999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07825999999999984 0.695 0.695
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07867999999999985 0.695 0.695
probs:  [1.0]
siam score:  -0.8916708
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07557999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.136]
 [0.016]
 [0.034]
 [0.027]
 [0.011]
 [0.028]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.136]
 [0.016]
 [0.034]
 [0.027]
 [0.011]
 [0.028]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07861999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8850992
maxi score, test score, baseline:  0.07539999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07543999999999987 0.695 0.695
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.975]
 [0.988]
 [0.975]
 [0.975]
 [0.975]
 [0.975]
 [0.975]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.975]
 [0.988]
 [0.975]
 [0.975]
 [0.975]
 [0.975]
 [0.975]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.928]
 [0.928]
 [0.928]
 [0.928]
 [0.928]
 [0.928]
 [0.928]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.928]
 [0.928]
 [0.928]
 [0.928]
 [0.928]
 [0.928]
 [0.928]]
maxi score, test score, baseline:  0.07503999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.988]
 [0.988]
 [0.988]
 [0.988]
 [0.988]
 [0.988]
 [0.988]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.988]
 [0.988]
 [0.988]
 [0.988]
 [0.988]
 [0.988]
 [0.988]]
maxi score, test score, baseline:  0.07219999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.607]
 [0.624]
 [0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.607]
 [0.624]
 [0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]]
Printing some Q and Qe and total Qs values:  [[0.798]
 [0.959]
 [0.798]
 [0.798]
 [0.798]
 [0.798]
 [0.798]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.798]
 [0.959]
 [0.798]
 [0.798]
 [0.798]
 [0.798]
 [0.798]]
maxi score, test score, baseline:  0.07247999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.04999999999999938  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07761999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.963]
 [0.963]
 [0.963]
 [0.963]
 [0.963]
 [0.963]
 [0.963]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.963]
 [0.963]
 [0.963]
 [0.963]
 [0.963]
 [0.963]
 [0.963]]
Printing some Q and Qe and total Qs values:  [[0.646]
 [0.833]
 [0.646]
 [0.646]
 [0.646]
 [0.646]
 [0.646]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.646]
 [0.833]
 [0.646]
 [0.646]
 [0.646]
 [0.646]
 [0.646]]
maxi score, test score, baseline:  0.07761999999999984 0.695 0.695
maxi score, test score, baseline:  0.07761999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.844]
 [0.92 ]
 [0.811]
 [0.856]
 [0.818]
 [0.827]
 [0.876]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.844]
 [0.92 ]
 [0.811]
 [0.856]
 [0.818]
 [0.827]
 [0.876]]
maxi score, test score, baseline:  0.07445999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.677]
 [0.677]
 [0.834]
 [0.677]
 [0.677]
 [0.677]
 [0.677]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.677]
 [0.677]
 [0.834]
 [0.677]
 [0.677]
 [0.677]
 [0.677]]
maxi score, test score, baseline:  0.07459999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07459999999999985 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.671]
 [0.573]
 [0.508]
 [0.671]
 [0.671]
 [0.671]
 [0.671]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.671]
 [0.573]
 [0.508]
 [0.671]
 [0.671]
 [0.671]
 [0.671]]
maxi score, test score, baseline:  0.07459999999999985 0.695 0.695
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.69]
 [0.69]
 [0.82]
 [0.69]
 [0.69]
 [0.69]
 [0.69]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.69]
 [0.69]
 [0.82]
 [0.69]
 [0.69]
 [0.69]
 [0.69]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07477999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.655]
 [0.804]
 [0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.655]
 [0.804]
 [0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]]
maxi score, test score, baseline:  0.07427999999999983 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.953]
 [0.992]
 [0.925]
 [0.922]
 [0.922]
 [0.927]
 [0.943]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.953]
 [0.992]
 [0.925]
 [0.922]
 [0.922]
 [0.927]
 [0.943]]
maxi score, test score, baseline:  0.07427999999999983 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07427999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.165]
 [0.462]
 [0.169]
 [0.165]
 [0.165]
 [0.165]
 [0.165]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.165]
 [0.462]
 [0.169]
 [0.165]
 [0.165]
 [0.165]
 [0.165]]
maxi score, test score, baseline:  0.07389999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.07665999999999987 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07665999999999987 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07665999999999987 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07637999999999986 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07337999999999986 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07337999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07355999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8944095
siam score:  -0.89438874
maxi score, test score, baseline:  0.07397999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.953]
 [0.822]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.953]
 [0.822]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07741999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08333999999999986 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07955999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07955999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07955999999999984 0.695 0.695
maxi score, test score, baseline:  0.07955999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8826857
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07921999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08241999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08235999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08253999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08253999999999985 0.695 0.695
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08641999999999984 0.695 0.695
maxi score, test score, baseline:  0.08641999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.265]
 [0.41 ]
 [0.265]
 [0.265]
 [0.265]
 [0.265]
 [0.265]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.265]
 [0.41 ]
 [0.265]
 [0.265]
 [0.265]
 [0.265]
 [0.265]]
Printing some Q and Qe and total Qs values:  [[0.619]
 [0.883]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.754]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.619]
 [0.883]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.754]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09275999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09059999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09093999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.2799999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09051999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.09051999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08737999999999983 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08671999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08671999999999984 0.695 0.695
maxi score, test score, baseline:  0.08671999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.022]
 [0.164]
 [0.009]
 [0.007]
 [0.029]
 [0.012]
 [0.018]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.022]
 [0.164]
 [0.009]
 [0.007]
 [0.029]
 [0.012]
 [0.018]]
maxi score, test score, baseline:  0.08359999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08359999999999984 0.695 0.695
siam score:  -0.8795758
maxi score, test score, baseline:  0.08359999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08379999999999985 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08035999999999985 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.862]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.631]
 [0.862]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07711999999999984 0.695 0.695
maxi score, test score, baseline:  0.07711999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08099999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.08099999999999984 0.695 0.695
Printing some Q and Qe and total Qs values:  [[0.689]
 [0.823]
 [0.689]
 [0.655]
 [0.689]
 [0.689]
 [0.671]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.689]
 [0.823]
 [0.689]
 [0.655]
 [0.689]
 [0.689]
 [0.671]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07205999999999985 0.695 0.695
maxi score, test score, baseline:  0.07205999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06937999999999984 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06907999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.983]
 [1.011]
 [0.983]
 [0.983]
 [0.983]
 [0.983]
 [0.983]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.983]
 [1.011]
 [0.983]
 [0.983]
 [0.983]
 [0.983]
 [0.983]]
maxi score, test score, baseline:  0.07193999999999985 0.695 0.695
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]]
Starting evaluation
maxi score, test score, baseline:  0.07131999999999984 0.695 0.695
probs:  [1.0]
maxi score, test score, baseline:  0.07131999999999984 0.695 0.695
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.6  ]
 [0.6  ]
 [0.658]
 [0.388]
 [0.349]
 [0.513]
 [0.332]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.6  ]
 [0.6  ]
 [0.658]
 [0.388]
 [0.349]
 [0.513]
 [0.332]]
Printing some Q and Qe and total Qs values:  [[0.666]
 [0.864]
 [0.666]
 [0.666]
 [0.666]
 [0.666]
 [0.666]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.666]
 [0.864]
 [0.666]
 [0.666]
 [0.666]
 [0.666]
 [0.666]]
Printing some Q and Qe and total Qs values:  [[0.805]
 [0.805]
 [0.814]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.805]
 [0.805]
 [0.814]
 [0.805]
 [0.805]
 [0.805]
 [0.805]]
maxi score, test score, baseline:  0.06857999999999985 0.695 0.695
maxi score, test score, baseline:  0.06857999999999985 0.695 0.695
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.89163756
Printing some Q and Qe and total Qs values:  [[0.93 ]
 [0.987]
 [0.954]
 [0.927]
 [0.948]
 [0.955]
 [0.939]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.93 ]
 [0.987]
 [0.954]
 [0.927]
 [0.948]
 [0.955]
 [0.939]]
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.7699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10107999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10191999999999986 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.925]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.925]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10395999999999983 0.698 0.698
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10743999999999986 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10743999999999987 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.903]
 [0.887]
 [0.922]
 [0.941]
 [0.941]
 [0.941]
 [0.954]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.903]
 [0.887]
 [0.922]
 [0.941]
 [0.941]
 [0.941]
 [0.954]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10673999999999985 0.698 0.698
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10657999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.897]
 [0.925]
 [0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.949]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.897]
 [0.925]
 [0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.949]]
maxi score, test score, baseline:  0.10671999999999987 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10981999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11009999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  32 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10675999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.025]
 [0.126]
 [0.01 ]
 [0.013]
 [0.006]
 [0.056]
 [0.043]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.025]
 [0.126]
 [0.01 ]
 [0.013]
 [0.006]
 [0.056]
 [0.043]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11003999999999986 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]]
actor:  0 policy actor:  0  step number:  38 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]]
Printing some Q and Qe and total Qs values:  [[0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10877999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10877999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10839999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]]
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.727]
 [0.695]
 [0.6  ]
 [0.604]
 [0.62 ]
 [0.62 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.65 ]
 [0.727]
 [0.695]
 [0.6  ]
 [0.604]
 [0.62 ]
 [0.62 ]]
Printing some Q and Qe and total Qs values:  [[0.888]
 [0.776]
 [0.776]
 [0.776]
 [0.776]
 [0.776]
 [0.776]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.888]
 [0.776]
 [0.776]
 [0.776]
 [0.776]
 [0.776]
 [0.776]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10295999999999986 0.698 0.698
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10215999999999986 0.698 0.698
probs:  [1.0]
siam score:  -0.8865782
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09767999999999985 0.698 0.698
maxi score, test score, baseline:  0.09767999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.09767999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
UNIT TEST: sample policy line 217 mcts : [0.02  0.653 0.02  0.122 0.041 0.122 0.02 ]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08327999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.08327999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.08327999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08647999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08939999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.08939999999999984 0.698 0.698
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.725]
 [0.778]
 [0.757]
 [0.732]
 [0.724]
 [0.737]
 [0.758]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.725]
 [0.778]
 [0.757]
 [0.732]
 [0.724]
 [0.737]
 [0.758]]
maxi score, test score, baseline:  0.08939999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09273999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09613999999999985 0.698 0.698
maxi score, test score, baseline:  0.09613999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.09001999999999985 0.698 0.698
maxi score, test score, baseline:  0.09001999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.949]
 [0.949]
 [0.949]
 [0.949]
 [0.949]
 [0.949]
 [0.949]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.949]
 [0.949]
 [0.949]
 [0.949]
 [0.949]
 [0.949]
 [0.949]]
maxi score, test score, baseline:  0.08959999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08919999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08919999999999983 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.08919999999999982 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08951999999999984 0.698 0.698
maxi score, test score, baseline:  0.08951999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09281999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.09281999999999985 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.923]
 [0.952]
 [0.901]
 [0.86 ]
 [0.86 ]
 [0.886]
 [0.911]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.923]
 [0.952]
 [0.901]
 [0.86 ]
 [0.86 ]
 [0.886]
 [0.911]]
maxi score, test score, baseline:  0.09281999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09947999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09697999999999986 0.698 0.698
maxi score, test score, baseline:  0.09697999999999986 0.698 0.698
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.09697999999999986 0.698 0.698
maxi score, test score, baseline:  0.09697999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09761999999999985 0.698 0.698
maxi score, test score, baseline:  0.09761999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.09761999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10067999999999984 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.957]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.957]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]]
Printing some Q and Qe and total Qs values:  [[0.649]
 [0.846]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.649]
 [0.846]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]]
siam score:  -0.8762337
actor:  0 policy actor:  0  step number:  27 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.87871665
maxi score, test score, baseline:  0.10157999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10187999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10449999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10449999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10449999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10517999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10549999999999986 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10549999999999986 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10219999999999985 0.698 0.698
maxi score, test score, baseline:  0.10219999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10489999999999984 0.698 0.698
maxi score, test score, baseline:  0.10489999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10489999999999984 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]]
Printing some Q and Qe and total Qs values:  [[0.858]
 [0.925]
 [0.858]
 [0.858]
 [0.858]
 [0.858]
 [0.858]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.858]
 [0.925]
 [0.858]
 [0.858]
 [0.858]
 [0.858]
 [0.858]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10501999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10783999999999982 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11103999999999983 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10807999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10807999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10821999999999986 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.654]
 [0.727]
 [0.648]
 [0.639]
 [0.642]
 [0.656]
 [0.634]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.654]
 [0.727]
 [0.648]
 [0.639]
 [0.642]
 [0.656]
 [0.634]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10225999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.698]
 [0.63 ]
 [0.543]
 [0.559]
 [0.538]
 [0.551]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.541]
 [0.698]
 [0.63 ]
 [0.543]
 [0.559]
 [0.538]
 [0.551]]
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]]
maxi score, test score, baseline:  0.10213999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.704]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.587]
 [0.704]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]]
Printing some Q and Qe and total Qs values:  [[0.976]
 [0.887]
 [0.998]
 [1.005]
 [1.01 ]
 [0.998]
 [0.995]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.976]
 [0.887]
 [0.998]
 [1.005]
 [1.01 ]
 [0.998]
 [0.995]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10409999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10409999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10381999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.388]
 [0.45 ]
 [0.388]
 [0.388]
 [0.388]
 [0.388]
 [0.388]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.388]
 [0.45 ]
 [0.388]
 [0.388]
 [0.388]
 [0.388]
 [0.388]]
maxi score, test score, baseline:  0.10651999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10651999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.847]
 [0.89 ]
 [0.847]
 [0.847]
 [0.847]
 [0.847]
 [0.847]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.847]
 [0.89 ]
 [0.847]
 [0.847]
 [0.847]
 [0.847]
 [0.847]]
maxi score, test score, baseline:  0.10657999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  39 total reward:  0.13999999999999946  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10633999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10633999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10633999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10941999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10979999999999983 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10979999999999983 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10979999999999983 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10979999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8875899
maxi score, test score, baseline:  0.11259999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11245999999999985 0.698 0.698
maxi score, test score, baseline:  0.11245999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11197999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11219999999999984 0.698 0.698
Printing some Q and Qe and total Qs values:  [[0.604]
 [0.665]
 [0.285]
 [0.536]
 [0.143]
 [0.642]
 [0.335]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.604]
 [0.665]
 [0.285]
 [0.536]
 [0.143]
 [0.642]
 [0.335]]
Printing some Q and Qe and total Qs values:  [[0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.766]
 [0.766]
 [0.766]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.766]
 [0.766]
 [0.766]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10899999999999983 0.698 0.698
probs:  [1.0]
siam score:  -0.88367265
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10925999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10347999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10039999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.632]
 [0.678]
 [0.685]
 [0.685]
 [0.685]
 [0.685]
 [0.685]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.632]
 [0.678]
 [0.685]
 [0.685]
 [0.685]
 [0.685]
 [0.685]]
Printing some Q and Qe and total Qs values:  [[0.705]
 [0.705]
 [0.811]
 [0.705]
 [0.705]
 [0.705]
 [0.705]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.705]
 [0.705]
 [0.811]
 [0.705]
 [0.705]
 [0.705]
 [0.705]]
maxi score, test score, baseline:  0.09737999999999986 0.698 0.698
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10049999999999987 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.643]
 [0.763]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.643]
 [0.763]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]]
maxi score, test score, baseline:  0.10049999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10655999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10039999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10359999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10359999999999984 0.698 0.698
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10375999999999985 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.663]
 [0.716]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.663]
 [0.716]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]]
maxi score, test score, baseline:  0.10375999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10585999999999986 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10585999999999986 0.698 0.698
maxi score, test score, baseline:  0.10585999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10893999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11185999999999985 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.749]
 [0.744]
 [0.749]
 [0.739]
 [0.739]
 [0.739]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.722]
 [0.749]
 [0.744]
 [0.749]
 [0.739]
 [0.739]
 [0.739]]
maxi score, test score, baseline:  0.11185999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11011999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10959999999999986 0.698 0.698
maxi score, test score, baseline:  0.10959999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11035999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10767999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11059999999999985 0.698 0.698
actor:  0 policy actor:  0  step number:  19 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11667999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.11667999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.11667999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.11667999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.11607999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11629999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.89772993
maxi score, test score, baseline:  0.11623999999999984 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[1.012]
 [1.012]
 [1.012]
 [1.012]
 [1.012]
 [1.012]
 [1.012]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.012]
 [1.012]
 [1.012]
 [1.012]
 [1.012]
 [1.012]
 [1.012]]
maxi score, test score, baseline:  0.11623999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11023999999999985 0.698 0.698
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.11023999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.11023999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11033999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10959999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10959999999999984 0.698 0.698
maxi score, test score, baseline:  0.10959999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10593999999999984 0.698 0.698
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10549999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10249999999999984 0.698 0.698
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.10249999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.838]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.718]
 [0.838]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10589999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.922]
 [0.894]
 [0.152]
 [0.859]
 [0.815]
 [0.83 ]
 [0.881]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.922]
 [0.894]
 [0.152]
 [0.859]
 [0.815]
 [0.83 ]
 [0.881]]
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10599999999999984 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[-0.001]
 [ 0.1  ]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.001]
 [ 0.1  ]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]]
Printing some Q and Qe and total Qs values:  [[0.79 ]
 [0.861]
 [0.79 ]
 [0.79 ]
 [0.79 ]
 [0.79 ]
 [0.79 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.79 ]
 [0.861]
 [0.79 ]
 [0.79 ]
 [0.79 ]
 [0.79 ]
 [0.79 ]]
maxi score, test score, baseline:  0.10289999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10001999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10005999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.668]
 [0.742]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.668]
 [0.742]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10359999999999986 0.698 0.698
maxi score, test score, baseline:  0.10359999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10441999999999986 0.698 0.698
actor:  0 policy actor:  0  step number:  35 total reward:  0.13999999999999946  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.981]
 [1.007]
 [0.981]
 [0.981]
 [0.981]
 [0.981]
 [0.981]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.981]
 [1.007]
 [0.981]
 [0.981]
 [0.981]
 [0.981]
 [0.981]]
maxi score, test score, baseline:  0.10669999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.96 ]
 [1.004]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.96 ]
 [1.004]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]]
maxi score, test score, baseline:  0.10657999999999986 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.234]
 [0.359]
 [0.344]
 [0.229]
 [0.344]
 [0.344]
 [0.344]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.234]
 [0.359]
 [0.344]
 [0.229]
 [0.344]
 [0.344]
 [0.344]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8929918
Printing some Q and Qe and total Qs values:  [[0.426]
 [0.485]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.426]
 [0.485]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]]
maxi score, test score, baseline:  0.10657999999999986 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10341999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10659999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10675999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.738]
 [0.773]
 [0.738]
 [0.738]
 [0.738]
 [0.738]
 [0.738]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.738]
 [0.773]
 [0.738]
 [0.738]
 [0.738]
 [0.738]
 [0.738]]
maxi score, test score, baseline:  0.10409999999999986 0.698 0.698
maxi score, test score, baseline:  0.10409999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10475999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10513999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.91]
 [0.91]
 [0.91]
 [0.91]
 [0.91]
 [0.91]
 [0.91]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.91]
 [0.91]
 [0.91]
 [0.91]
 [0.91]
 [0.91]
 [0.91]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.866]
 [0.909]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.866]
 [0.909]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10177999999999984 0.698 0.698
Printing some Q and Qe and total Qs values:  [[0.79]
 [0.77]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.79]
 [0.77]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8988644
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10523999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.805]
 [0.84 ]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.805]
 [0.84 ]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]]
maxi score, test score, baseline:  0.10523999999999985 0.698 0.698
maxi score, test score, baseline:  0.10523999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10469999999999985 0.698 0.698
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.632]
 [0.792]
 [0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.632]
 [0.792]
 [0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10499999999999986 0.698 0.698
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10783999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.327]
 [0.377]
 [0.327]
 [0.327]
 [0.327]
 [0.327]
 [0.327]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.327]
 [0.377]
 [0.327]
 [0.327]
 [0.327]
 [0.327]
 [0.327]]
maxi score, test score, baseline:  0.11089999999999985 0.698 0.698
Printing some Q and Qe and total Qs values:  [[0.774]
 [0.781]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.774]
 [0.781]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
siam score:  -0.89286715
maxi score, test score, baseline:  0.11099999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10477999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.919]
 [0.967]
 [0.919]
 [0.921]
 [0.922]
 [0.919]
 [0.92 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.919]
 [0.967]
 [0.919]
 [0.921]
 [0.922]
 [0.919]
 [0.92 ]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10471999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10471999999999985 0.698 0.698
siam score:  -0.8885319
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]]
maxi score, test score, baseline:  0.10489999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10435999999999986 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10435999999999986 0.698 0.698
maxi score, test score, baseline:  0.10435999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10447999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.09857999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.87 ]
 [0.923]
 [0.917]
 [0.87 ]
 [0.87 ]
 [0.87 ]
 [0.87 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.87 ]
 [0.923]
 [0.917]
 [0.87 ]
 [0.87 ]
 [0.87 ]
 [0.87 ]]
actor:  0 policy actor:  0  step number:  35 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09873999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.09573999999999985 0.698 0.698
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09819999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8924369
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09261999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09547999999999983 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]]
maxi score, test score, baseline:  0.09547999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09595999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10189999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10189999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.09881999999999982 0.698 0.698
maxi score, test score, baseline:  0.09881999999999982 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09575999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.09575999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09585999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.45999999999999985  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09585999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09897999999999986 0.698 0.698
probs:  [1.0]
siam score:  -0.8901872
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.659]
 [0.685]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.634]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.659]
 [0.685]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.634]]
Printing some Q and Qe and total Qs values:  [[0.774]
 [0.871]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.774]
 [0.871]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]]
maxi score, test score, baseline:  0.09597999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]]
maxi score, test score, baseline:  0.09863999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09823999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.09823999999999984 0.698 0.698
maxi score, test score, baseline:  0.09823999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10139999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.369]
 [0.423]
 [0.369]
 [0.369]
 [0.369]
 [0.369]
 [0.369]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.369]
 [0.423]
 [0.369]
 [0.369]
 [0.369]
 [0.369]
 [0.369]]
maxi score, test score, baseline:  0.10119999999999986 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10119999999999986 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]]
maxi score, test score, baseline:  0.10119999999999986 0.698 0.698
maxi score, test score, baseline:  0.10119999999999986 0.698 0.698
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10159999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10207999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10207999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8952455
maxi score, test score, baseline:  0.10179999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10481999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10487999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10433999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.89656174
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10509999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.978]
 [0.977]
 [0.978]
 [0.978]
 [0.978]
 [0.978]
 [0.978]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.978]
 [0.977]
 [0.978]
 [0.978]
 [0.978]
 [0.978]
 [0.978]]
Printing some Q and Qe and total Qs values:  [[0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]]
actor:  0 policy actor:  0  step number:  36 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10509999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10509999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10509999999999985 0.698 0.698
probs:  [1.0]
siam score:  -0.89722884
actor:  0 policy actor:  0  step number:  26 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.602]
 [0.642]
 [0.603]
 [0.597]
 [0.597]
 [0.597]
 [0.597]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.602]
 [0.642]
 [0.603]
 [0.597]
 [0.597]
 [0.597]
 [0.597]]
maxi score, test score, baseline:  0.11125999999999986 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.781]
 [0.809]
 [0.716]
 [0.781]
 [0.641]
 [0.645]
 [0.656]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.781]
 [0.809]
 [0.716]
 [0.781]
 [0.641]
 [0.645]
 [0.656]]
maxi score, test score, baseline:  0.11125999999999986 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.765]
 [0.875]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.765]
 [0.875]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11101999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11405999999999984 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.832]
 [0.933]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.922]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.832]
 [0.933]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.922]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12017999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.12017999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.12017999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.12017999999999984 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.697]
 [0.897]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.697]
 [0.897]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]]
actor:  0 policy actor:  0  step number:  35 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.664]
 [0.859]
 [0.664]
 [0.664]
 [0.664]
 [0.664]
 [0.664]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.664]
 [0.859]
 [0.664]
 [0.664]
 [0.664]
 [0.664]
 [0.664]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11993999999999984 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.764]
 [0.753]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.764]
 [0.753]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.925]
 [0.887]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.925]
 [0.887]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.183]
 [0.251]
 [0.183]
 [0.164]
 [0.183]
 [0.183]
 [0.242]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.183]
 [0.251]
 [0.183]
 [0.164]
 [0.183]
 [0.183]
 [0.242]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12235999999999986 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.11949999999999984 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.871]
 [0.837]
 [0.873]
 [0.873]
 [0.873]
 [0.873]
 [0.827]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.871]
 [0.837]
 [0.873]
 [0.873]
 [0.873]
 [0.873]
 [0.827]]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12279999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.12279999999999987 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12243999999999984 0.698 0.698
maxi score, test score, baseline:  0.12243999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12297999999999985 0.698 0.698
maxi score, test score, baseline:  0.12297999999999985 0.698 0.698
probs:  [1.0]
siam score:  -0.88756853
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.678]
 [0.872]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.678]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.678]
 [0.872]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.678]]
actor:  0 policy actor:  0  step number:  36 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12527999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12541999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.12541999999999984 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.709]
 [0.777]
 [0.709]
 [0.715]
 [0.709]
 [0.711]
 [0.707]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.709]
 [0.777]
 [0.709]
 [0.715]
 [0.709]
 [0.711]
 [0.707]]
maxi score, test score, baseline:  0.11903999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.11903999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.236]
 [0.295]
 [0.236]
 [0.236]
 [0.236]
 [0.236]
 [0.236]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.236]
 [0.295]
 [0.236]
 [0.236]
 [0.236]
 [0.236]
 [0.236]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11957999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
siam score:  -0.88367593
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12281999999999985 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.634]
 [0.79 ]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.634]
 [0.79 ]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]]
maxi score, test score, baseline:  0.11963999999999986 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.928]
 [0.955]
 [0.932]
 [0.941]
 [0.912]
 [0.893]
 [0.912]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.928]
 [0.955]
 [0.932]
 [0.941]
 [0.912]
 [0.893]
 [0.912]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.851]
 [0.9  ]
 [0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.851]
 [0.9  ]
 [0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]]
siam score:  -0.88310266
maxi score, test score, baseline:  0.11983999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12007999999999985 0.698 0.698
maxi score, test score, baseline:  0.12007999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8802234
maxi score, test score, baseline:  0.11729999999999983 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.11729999999999983 0.698 0.698
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11741999999999983 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]]
maxi score, test score, baseline:  0.11741999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11717999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11335999999999982 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.11335999999999982 0.698 0.698
Printing some Q and Qe and total Qs values:  [[0.792]
 [0.868]
 [0.792]
 [0.792]
 [0.792]
 [0.683]
 [0.792]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.792]
 [0.868]
 [0.792]
 [0.792]
 [0.792]
 [0.683]
 [0.792]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11653999999999982 0.698 0.698
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.08999999999999941  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.823]
 [0.823]
 [0.823]
 [0.823]
 [0.823]
 [0.823]
 [0.823]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.823]
 [0.823]
 [0.823]
 [0.823]
 [0.823]
 [0.823]
 [0.823]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11455999999999984 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.926]
 [0.798]
 [0.751]
 [0.761]
 [0.764]
 [0.888]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.81 ]
 [0.926]
 [0.798]
 [0.751]
 [0.761]
 [0.764]
 [0.888]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11093999999999986 0.698 0.698
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.82 ]
 [0.733]
 [0.694]
 [0.694]
 [0.694]
 [0.694]
 [0.706]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.82 ]
 [0.733]
 [0.694]
 [0.694]
 [0.694]
 [0.694]
 [0.706]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10173999999999984 0.698 0.698
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.95 ]
 [0.866]
 [0.878]
 [0.878]
 [0.878]
 [0.865]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.878]
 [0.95 ]
 [0.866]
 [0.878]
 [0.878]
 [0.878]
 [0.865]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10101999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10409999999999985 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.668]
 [0.793]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.668]
 [0.793]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]]
Printing some Q and Qe and total Qs values:  [[0.799]
 [0.826]
 [0.788]
 [0.779]
 [0.759]
 [0.781]
 [0.756]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.799]
 [0.826]
 [0.788]
 [0.779]
 [0.759]
 [0.781]
 [0.756]]
maxi score, test score, baseline:  0.10101999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10091999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10399999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]]
maxi score, test score, baseline:  0.10127999999999986 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09789999999999986 0.698 0.698
Printing some Q and Qe and total Qs values:  [[0.864]
 [0.797]
 [0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.786]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.864]
 [0.797]
 [0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.786]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10087999999999984 0.698 0.698
maxi score, test score, baseline:  0.10087999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10087999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10063999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10063999999999985 0.698 0.698
maxi score, test score, baseline:  0.10063999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10025999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10335999999999984 0.698 0.698
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.831]
 [0.843]
 [0.837]
 [0.837]
 [0.837]
 [0.837]
 [0.789]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.831]
 [0.843]
 [0.837]
 [0.837]
 [0.837]
 [0.837]
 [0.789]]
maxi score, test score, baseline:  0.10335999999999984 0.698 0.698
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10339999999999983 0.698 0.698
maxi score, test score, baseline:  0.10339999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10571999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10571999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10821999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10799999999999983 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10799999999999983 0.698 0.698
maxi score, test score, baseline:  0.10799999999999983 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10845999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10511999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11187999999999983 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10877999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11005999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.11005999999999985 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.688]
 [0.718]
 [0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.688]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.688]
 [0.718]
 [0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.688]]
maxi score, test score, baseline:  0.10681999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10681999999999983 0.698 0.698
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.10681999999999983 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.853]
 [0.853]
 [0.853]
 [0.853]
 [0.853]
 [0.853]
 [0.853]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.853]
 [0.853]
 [0.853]
 [0.853]
 [0.853]
 [0.853]
 [0.853]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.76  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11235999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.981]
 [1.007]
 [0.981]
 [0.981]
 [0.981]
 [0.981]
 [0.981]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.981]
 [1.007]
 [0.981]
 [0.981]
 [0.981]
 [0.981]
 [0.981]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10779999999999985 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10779999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.75 ]
 [0.848]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.75 ]
 [0.848]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]]
maxi score, test score, baseline:  0.11011999999999983 0.698 0.698
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10643999999999984 0.698 0.698
maxi score, test score, baseline:  0.10643999999999984 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10963999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10093999999999984 0.698 0.698
probs:  [1.0]
maxi score, test score, baseline:  0.10093999999999984 0.698 0.698
Starting evaluation
Printing some Q and Qe and total Qs values:  [[ 0.767]
 [ 0.811]
 [ 0.08 ]
 [ 0.734]
 [ 0.748]
 [-0.008]
 [ 0.759]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.767]
 [ 0.811]
 [ 0.08 ]
 [ 0.734]
 [ 0.748]
 [-0.008]
 [ 0.759]]
maxi score, test score, baseline:  0.09775999999999985 0.698 0.698
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]]
maxi score, test score, baseline:  0.09775999999999985 0.698 0.698
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.817]
 [0.817]
 [0.878]
 [0.696]
 [0.817]
 [0.817]
 [0.788]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.817]
 [0.817]
 [0.878]
 [0.696]
 [0.817]
 [0.817]
 [0.788]]
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.772]
 [0.844]
 [0.799]
 [0.772]
 [0.772]
 [0.772]
 [0.772]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.772]
 [0.844]
 [0.799]
 [0.772]
 [0.772]
 [0.772]
 [0.772]]
maxi score, test score, baseline:  0.12691999999999984 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.12691999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.12691999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
siam score:  -0.88699985
maxi score, test score, baseline:  0.12691999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13339999999999982 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.13339999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13339999999999982 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.13339999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13339999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13339999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.839]
 [0.874]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.839]
 [0.874]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]]
Printing some Q and Qe and total Qs values:  [[0.89 ]
 [0.963]
 [0.89 ]
 [0.89 ]
 [0.89 ]
 [0.89 ]
 [0.89 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.89 ]
 [0.963]
 [0.89 ]
 [0.89 ]
 [0.89 ]
 [0.89 ]
 [0.89 ]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.2799999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13751999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13751999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13455999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13455999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.13717999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.672]
 [0.8  ]
 [0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.672]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.672]
 [0.8  ]
 [0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.672]]
maxi score, test score, baseline:  0.13407999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.839]
 [0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.644]
 [0.839]
 [0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]]
maxi score, test score, baseline:  0.14001999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13991999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.13991999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.095]
 [0.254]
 [0.095]
 [0.095]
 [0.095]
 [0.095]
 [0.095]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.095]
 [0.254]
 [0.095]
 [0.095]
 [0.095]
 [0.095]
 [0.095]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.5299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13755999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.209]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.209]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13731999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13369999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13369999999999985 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.13015999999999983 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.13015999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.88675445
maxi score, test score, baseline:  0.12241999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.12241999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12197999999999984 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.12197999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
siam score:  -0.8855282
maxi score, test score, baseline:  0.11517999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11499999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
siam score:  -0.88493484
maxi score, test score, baseline:  0.11499999999999984 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11429999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.11429999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.11429999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.10999999999999943  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11315999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11241999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.11241999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Sims:  50 1 epoch:  141117 pick best:  False frame count:  141117
maxi score, test score, baseline:  0.11149999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.027]
 [0.24 ]
 [0.027]
 [0.128]
 [0.027]
 [0.027]
 [0.132]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.027]
 [0.24 ]
 [0.027]
 [0.128]
 [0.027]
 [0.027]
 [0.132]]
Printing some Q and Qe and total Qs values:  [[0.891]
 [0.898]
 [0.896]
 [0.863]
 [0.863]
 [0.865]
 [0.9  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.891]
 [0.898]
 [0.896]
 [0.863]
 [0.863]
 [0.865]
 [0.9  ]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10457999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.10457999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10153999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.3]
 [0.3]
 [0.3]
 [0.3]
 [0.3]
 [0.3]
 [0.3]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.3]
 [0.3]
 [0.3]
 [0.3]
 [0.3]
 [0.3]
 [0.3]]
Printing some Q and Qe and total Qs values:  [[0.779]
 [0.779]
 [0.953]
 [0.779]
 [0.779]
 [0.779]
 [0.779]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.779]
 [0.779]
 [0.953]
 [0.779]
 [0.779]
 [0.779]
 [0.779]]
maxi score, test score, baseline:  0.10235999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09911999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.09627999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.09335999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09329999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09065999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.09065999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08667999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.609]
 [0.748]
 [0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.609]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.609]
 [0.748]
 [0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.609]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08713999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09107999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.09107999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.09107999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.09107999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09175999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09121999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08797999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08233999999999986 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.08233999999999986 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08521999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08521999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08521999999999984 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08537999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08827999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08835999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08811999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.752]
 [0.839]
 [0.752]
 [0.715]
 [0.752]
 [0.752]
 [0.768]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.752]
 [0.839]
 [0.752]
 [0.715]
 [0.752]
 [0.752]
 [0.768]]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08913999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.08621999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.052]
 [0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.035]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.006]
 [0.052]
 [0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.035]]
maxi score, test score, baseline:  0.08621999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08933999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08933999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.83 ]
 [0.83 ]
 [0.876]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.82 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.83 ]
 [0.83 ]
 [0.876]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.82 ]]
maxi score, test score, baseline:  0.09185999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09453999999999986 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09377999999999985 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.927]
 [0.928]
 [0.927]
 [0.927]
 [0.927]
 [0.927]
 [0.927]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.927]
 [0.928]
 [0.927]
 [0.927]
 [0.927]
 [0.927]
 [0.927]]
maxi score, test score, baseline:  0.09661999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.77]
 [0.77]
 [0.77]
 [0.77]
 [0.77]
 [0.77]
 [0.77]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.77]
 [0.77]
 [0.77]
 [0.77]
 [0.77]
 [0.77]
 [0.77]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.66 ]
 [0.711]
 [0.591]
 [0.699]
 [0.637]
 [0.614]
 [0.612]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.66 ]
 [0.711]
 [0.591]
 [0.699]
 [0.637]
 [0.614]
 [0.612]]
Printing some Q and Qe and total Qs values:  [[0.578]
 [0.924]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.879]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.578]
 [0.924]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.879]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10007999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.652]
 [0.69 ]
 [0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.652]
 [0.69 ]
 [0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.33 ]
 [0.393]
 [0.33 ]
 [0.324]
 [0.33 ]
 [0.33 ]
 [0.348]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.33 ]
 [0.393]
 [0.33 ]
 [0.324]
 [0.33 ]
 [0.33 ]
 [0.348]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09927999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10207999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.10207999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.585]
 [0.766]
 [0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.585]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.585]
 [0.766]
 [0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.585]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10123999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10483999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10469999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.867]
 [0.941]
 [0.867]
 [0.867]
 [0.867]
 [0.867]
 [0.867]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.867]
 [0.941]
 [0.867]
 [0.867]
 [0.867]
 [0.867]
 [0.867]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10779999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.711]
 [0.747]
 [0.686]
 [0.719]
 [0.729]
 [0.785]
 [0.796]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.711]
 [0.747]
 [0.686]
 [0.719]
 [0.729]
 [0.785]
 [0.796]]
siam score:  -0.8821945
maxi score, test score, baseline:  0.10779999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10727999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10709999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10659999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10905999999999984 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.10905999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.10905999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10605999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
siam score:  -0.88055086
maxi score, test score, baseline:  0.10605999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.10293999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]]
maxi score, test score, baseline:  0.10297999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.10297999999999984 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.10297999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.55 ]
 [0.686]
 [0.576]
 [0.592]
 [0.565]
 [0.568]
 [0.559]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.55 ]
 [0.686]
 [0.576]
 [0.592]
 [0.565]
 [0.568]
 [0.559]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10267999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
siam score:  -0.8816157
Printing some Q and Qe and total Qs values:  [[0.808]
 [0.846]
 [0.808]
 [0.724]
 [0.808]
 [0.808]
 [0.72 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.808]
 [0.846]
 [0.808]
 [0.724]
 [0.808]
 [0.808]
 [0.72 ]]
maxi score, test score, baseline:  0.10267999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.10267999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  40 total reward:  0.08999999999999941  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.352]
 [0.264]
 [0.325]
 [0.331]
 [0.318]
 [0.343]
 [0.388]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.352]
 [0.264]
 [0.325]
 [0.331]
 [0.318]
 [0.343]
 [0.388]]
Printing some Q and Qe and total Qs values:  [[0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10541999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.96 ]
 [0.987]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.96 ]
 [0.987]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]]
maxi score, test score, baseline:  0.10857999999999982 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.10571999999999984 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.07 ]
 [0.133]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.086]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.07 ]
 [0.133]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.086]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10921999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10945999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  42 total reward:  0.12999999999999945  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.09 ]
 [0.021]
 [0.001]
 [0.003]
 [0.046]
 [0.011]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.009]
 [0.09 ]
 [0.021]
 [0.001]
 [0.003]
 [0.046]
 [0.011]]
maxi score, test score, baseline:  0.10641999999999982 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  42 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10539999999999981 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.10235999999999984 0.6964999999999999 0.6964999999999999
Printing some Q and Qe and total Qs values:  [[0.661]
 [0.776]
 [0.657]
 [0.647]
 [0.669]
 [0.652]
 [0.65 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.661]
 [0.776]
 [0.657]
 [0.647]
 [0.669]
 [0.652]
 [0.65 ]]
maxi score, test score, baseline:  0.10235999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.10235999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]]
actor:  0 policy actor:  0  step number:  36 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10485999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10239999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.497]
 [0.43 ]
 [0.432]
 [0.473]
 [0.435]
 [0.46 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.424]
 [0.497]
 [0.43 ]
 [0.432]
 [0.473]
 [0.435]
 [0.46 ]]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.943]
 [0.966]
 [0.943]
 [0.943]
 [0.943]
 [0.943]
 [0.943]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.943]
 [0.966]
 [0.943]
 [0.943]
 [0.943]
 [0.943]
 [0.943]]
maxi score, test score, baseline:  0.10241999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.635]
 [0.709]
 [0.718]
 [0.682]
 [0.645]
 [0.678]
 [0.677]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.635]
 [0.709]
 [0.718]
 [0.682]
 [0.645]
 [0.678]
 [0.677]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.815]
 [0.833]
 [0.833]
 [0.588]
 [0.833]
 [0.664]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.587]
 [0.815]
 [0.833]
 [0.833]
 [0.588]
 [0.833]
 [0.664]]
maxi score, test score, baseline:  0.09305999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
UNIT TEST: sample policy line 217 mcts : [0.204 0.469 0.041 0.041 0.02  0.02  0.204]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09625999999999985 0.6964999999999999 0.6964999999999999
Printing some Q and Qe and total Qs values:  [[0.338]
 [0.338]
 [0.338]
 [0.338]
 [0.338]
 [0.338]
 [0.338]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.338]
 [0.338]
 [0.338]
 [0.338]
 [0.338]
 [0.338]
 [0.338]]
maxi score, test score, baseline:  0.09303999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.09303999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.09009999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.09009999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.934]
 [0.986]
 [0.932]
 [0.931]
 [0.931]
 [0.968]
 [0.938]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.934]
 [0.986]
 [0.932]
 [0.931]
 [0.931]
 [0.968]
 [0.938]]
actor:  0 policy actor:  0  step number:  31 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09037999999999984 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  27 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.842]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.65 ]
 [0.842]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]]
maxi score, test score, baseline:  0.08479999999999985 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.08479999999999985 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.08479999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08435999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08435999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08473999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08781999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08781999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09083999999999982 0.6964999999999999 0.6964999999999999
Printing some Q and Qe and total Qs values:  [[ 0.749]
 [ 0.796]
 [-0.003]
 [ 0.777]
 [ 0.758]
 [-0.008]
 [ 0.786]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.749]
 [ 0.796]
 [-0.003]
 [ 0.777]
 [ 0.758]
 [-0.008]
 [ 0.786]]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  41 total reward:  0.0799999999999994  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8801927
Printing some Q and Qe and total Qs values:  [[0.713]
 [0.713]
 [0.873]
 [0.713]
 [0.713]
 [0.713]
 [0.666]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.713]
 [0.713]
 [0.873]
 [0.713]
 [0.713]
 [0.713]
 [0.666]]
maxi score, test score, baseline:  0.08435999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08723999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09033999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.564]
 [0.606]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.564]
 [0.606]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]]
Printing some Q and Qe and total Qs values:  [[0.62 ]
 [0.733]
 [0.62 ]
 [0.62 ]
 [0.62 ]
 [0.62 ]
 [0.62 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.62 ]
 [0.733]
 [0.62 ]
 [0.62 ]
 [0.62 ]
 [0.62 ]
 [0.62 ]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.596]
 [0.689]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.596]
 [0.689]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]]
maxi score, test score, baseline:  0.09007999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.09007999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08975999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08903999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.226]
 [0.216]
 [0.221]
 [0.221]
 [0.223]
 [0.226]
 [0.227]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.226]
 [0.216]
 [0.221]
 [0.221]
 [0.223]
 [0.226]
 [0.227]]
maxi score, test score, baseline:  0.08903999999999984 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08915999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.8  ]
 [0.881]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.8  ]
 [0.881]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08661999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08643999999999984 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  36 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08685999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08685999999999985 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.08685999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.878]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.08699999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08699999999999984 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09009999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.731]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.616]
 [0.731]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]]
maxi score, test score, baseline:  0.08717999999999983 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08411999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08423999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.649]
 [0.846]
 [0.701]
 [0.62 ]
 [0.701]
 [0.511]
 [0.701]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.649]
 [0.846]
 [0.701]
 [0.62 ]
 [0.701]
 [0.511]
 [0.701]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.891]
 [0.883]
 [0.893]
 [0.826]
 [0.844]
 [0.871]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.878]
 [0.891]
 [0.883]
 [0.893]
 [0.826]
 [0.844]
 [0.871]]
actor:  0 policy actor:  0  step number:  35 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08669999999999985 0.6964999999999999 0.6964999999999999
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08667999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08669999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08669999999999983 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.08669999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08671999999999984 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.08387999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08387999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08387999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08387999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08055999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.847]
 [0.909]
 [0.836]
 [0.836]
 [0.836]
 [0.836]
 [0.836]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.847]
 [0.909]
 [0.836]
 [0.836]
 [0.836]
 [0.836]
 [0.836]]
maxi score, test score, baseline:  0.08053999999999983 0.6964999999999999 0.6964999999999999
UNIT TEST: sample policy line 217 mcts : [0.041 0.367 0.122 0.061 0.224 0.041 0.143]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08079999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
siam score:  -0.88515836
Printing some Q and Qe and total Qs values:  [[0.733]
 [0.837]
 [0.733]
 [0.753]
 [0.733]
 [0.733]
 [0.771]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.733]
 [0.837]
 [0.733]
 [0.753]
 [0.733]
 [0.733]
 [0.771]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08075999999999985 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08023999999999985 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.08023999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.036]
 [0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.007]
 [0.036]
 [0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]]
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.563]
 [0.741]
 [0.563]
 [0.563]
 [0.563]
 [0.563]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.563]
 [0.563]
 [0.741]
 [0.563]
 [0.563]
 [0.563]
 [0.563]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.07429999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
siam score:  -0.8879383
maxi score, test score, baseline:  0.06841999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06865999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07147999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
siam score:  -0.8880138
maxi score, test score, baseline:  0.07147999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.07147999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07407999999999984 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.07407999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07431999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.8861918
maxi score, test score, baseline:  0.07141999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07081999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.07081999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07163999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.996]
 [1.003]
 [1.004]
 [0.986]
 [0.986]
 [0.983]
 [1.   ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.996]
 [1.003]
 [1.004]
 [0.986]
 [0.986]
 [0.983]
 [1.   ]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
siam score:  -0.88854235
maxi score, test score, baseline:  0.07793999999999981 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.07793999999999981 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.894]
 [0.932]
 [0.853]
 [0.89 ]
 [0.89 ]
 [0.89 ]
 [0.904]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.894]
 [0.932]
 [0.853]
 [0.89 ]
 [0.89 ]
 [0.89 ]
 [0.904]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07783999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08053999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08375999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08631999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08663999999999984 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.08663999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[-0.001]
 [ 0.034]
 [ 0.005]
 [ 1.064]
 [ 0.006]
 [ 0.005]
 [ 1.064]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.001]
 [ 0.034]
 [ 0.005]
 [ 1.064]
 [ 0.006]
 [ 0.005]
 [ 1.064]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.14]
 [0.14]
 [0.14]
 [0.14]
 [0.14]
 [0.14]
 [0.14]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.14]
 [0.14]
 [0.14]
 [0.14]
 [0.14]
 [0.14]
 [0.14]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.157]
 [0.015]
 [0.087]
 [0.015]
 [0.014]
 [0.011]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.011]
 [0.157]
 [0.015]
 [0.087]
 [0.015]
 [0.014]
 [0.011]]
maxi score, test score, baseline:  0.08887999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.913]
 [0.904]
 [0.913]
 [0.913]
 [0.913]
 [0.913]
 [0.913]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.913]
 [0.904]
 [0.913]
 [0.913]
 [0.913]
 [0.913]
 [0.913]]
maxi score, test score, baseline:  0.08599999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.673]
 [0.799]
 [0.689]
 [0.665]
 [0.668]
 [0.666]
 [0.668]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.673]
 [0.799]
 [0.689]
 [0.665]
 [0.668]
 [0.666]
 [0.668]]
Printing some Q and Qe and total Qs values:  [[0.469]
 [0.47 ]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.469]
 [0.47 ]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.623]
 [0.762]
 [0.651]
 [0.623]
 [0.657]
 [0.623]
 [0.623]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.623]
 [0.762]
 [0.651]
 [0.623]
 [0.657]
 [0.623]
 [0.623]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.669]
 [0.781]
 [0.668]
 [0.662]
 [0.659]
 [0.655]
 [0.677]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.669]
 [0.781]
 [0.668]
 [0.662]
 [0.659]
 [0.655]
 [0.677]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08817999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08583999999999985 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.08583999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08633999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.908]
 [0.831]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.908]
 [0.831]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08623999999999984 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.846]
 [0.823]
 [0.84 ]
 [0.836]
 [0.837]
 [0.826]
 [0.856]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.846]
 [0.823]
 [0.84 ]
 [0.836]
 [0.837]
 [0.826]
 [0.856]]
maxi score, test score, baseline:  0.08327999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08299999999999984 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  20 total reward:  0.8099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08461999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08461999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.668]
 [0.786]
 [0.63 ]
 [0.646]
 [0.645]
 [0.642]
 [0.63 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.668]
 [0.786]
 [0.63 ]
 [0.646]
 [0.645]
 [0.642]
 [0.63 ]]
siam score:  -0.88417786
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.88392484
maxi score, test score, baseline:  0.09073999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.09073999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  41 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.754]
 [0.895]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.754]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.754]
 [0.895]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.754]]
maxi score, test score, baseline:  0.08725999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08185999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08185999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08173999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08173999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08173999999999984 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  34 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08117999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.07797999999999983 0.6964999999999999 0.6964999999999999
siam score:  -0.88370925
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8850357
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07855999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.57  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07857999999999983 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08825999999999982 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08825999999999982 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8849671
maxi score, test score, baseline:  0.08835999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.72 ]
 [0.815]
 [0.72 ]
 [0.765]
 [0.723]
 [0.72 ]
 [0.796]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.72 ]
 [0.815]
 [0.72 ]
 [0.765]
 [0.723]
 [0.72 ]
 [0.796]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09159999999999983 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.09523999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09235999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.468]
 [0.56 ]
 [0.481]
 [0.482]
 [0.468]
 [0.468]
 [0.482]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.468]
 [0.56 ]
 [0.481]
 [0.482]
 [0.468]
 [0.468]
 [0.482]]
maxi score, test score, baseline:  0.09235999999999983 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.09235999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.9  ]
 [0.884]
 [0.9  ]
 [0.9  ]
 [0.9  ]
 [0.9  ]
 [0.92 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.9  ]
 [0.884]
 [0.9  ]
 [0.9  ]
 [0.9  ]
 [0.9  ]
 [0.92 ]]
maxi score, test score, baseline:  0.08997999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.08703999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08637999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8808079
maxi score, test score, baseline:  0.07985999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08007999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.016]
 [0.661]
 [1.016]
 [1.016]
 [1.016]
 [1.016]
 [1.016]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.016]
 [0.661]
 [1.016]
 [1.016]
 [1.016]
 [1.016]
 [1.016]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08029999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.08265999999999983 0.6964999999999999 0.6964999999999999
Printing some Q and Qe and total Qs values:  [[0.74 ]
 [0.788]
 [0.65 ]
 [0.679]
 [0.709]
 [0.714]
 [0.692]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.74 ]
 [0.788]
 [0.65 ]
 [0.679]
 [0.709]
 [0.714]
 [0.692]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08271999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08239999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07937999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
siam score:  -0.87355334
actor:  0 policy actor:  0  step number:  27 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07965999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.572]
 [0.571]
 [0.593]
 [0.571]
 [0.571]
 [0.607]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.571]
 [0.572]
 [0.571]
 [0.593]
 [0.571]
 [0.571]
 [0.607]]
maxi score, test score, baseline:  0.07633999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.929]
 [0.751]
 [0.837]
 [0.929]
 [0.929]
 [0.929]
 [0.828]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.929]
 [0.751]
 [0.837]
 [0.929]
 [0.929]
 [0.929]
 [0.828]]
maxi score, test score, baseline:  0.07383999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.07383999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.081]
 [0.097]
 [0.081]
 [0.081]
 [0.081]
 [0.081]
 [0.081]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.081]
 [0.097]
 [0.081]
 [0.081]
 [0.081]
 [0.081]
 [0.081]]
maxi score, test score, baseline:  0.06811999999999985 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.06811999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06827999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06823999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06857999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.06857999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.06857999999999984 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.06857999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.929]
 [0.972]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.715]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.929]
 [0.972]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.715]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06613999999999985 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.06613999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[-0.001]
 [ 0.172]
 [ 0.118]
 [ 0.124]
 [ 0.068]
 [ 0.118]
 [ 0.111]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.001]
 [ 0.172]
 [ 0.118]
 [ 0.124]
 [ 0.068]
 [ 0.118]
 [ 0.111]]
maxi score, test score, baseline:  0.06363999999999985 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.05833999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.05833999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06155999999999986 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.06155999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.676]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.601]
 [0.676]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]]
Printing some Q and Qe and total Qs values:  [[0.771]
 [0.866]
 [0.771]
 [0.771]
 [0.771]
 [0.771]
 [0.771]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.771]
 [0.866]
 [0.771]
 [0.771]
 [0.771]
 [0.771]
 [0.771]]
UNIT TEST: sample policy line 217 mcts : [0.02  0.551 0.02  0.265 0.041 0.02  0.082]
Printing some Q and Qe and total Qs values:  [[0.943]
 [0.993]
 [0.943]
 [0.943]
 [0.943]
 [0.943]
 [0.943]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.943]
 [0.993]
 [0.943]
 [0.943]
 [0.943]
 [0.943]
 [0.943]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06475999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
siam score:  -0.8734813
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06431999999999985 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06691999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06679999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06677999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.9  ]
 [0.836]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.787]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.9  ]
 [0.836]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.787]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06687999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8696787
Printing some Q and Qe and total Qs values:  [[0.929]
 [0.873]
 [0.873]
 [0.815]
 [0.873]
 [0.173]
 [0.417]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.929]
 [0.873]
 [0.873]
 [0.815]
 [0.873]
 [0.173]
 [0.417]]
Printing some Q and Qe and total Qs values:  [[0.803]
 [0.883]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.803]
 [0.883]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]]
maxi score, test score, baseline:  0.06943999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.06655999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.86998457
maxi score, test score, baseline:  0.06669999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.794]
 [0.945]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.794]
 [0.945]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]]
maxi score, test score, baseline:  0.06629999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06611999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06359999999999985 0.6964999999999999 0.6964999999999999
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.835]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.699]
 [0.835]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]]
maxi score, test score, baseline:  0.06359999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06619999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
siam score:  -0.87266046
Printing some Q and Qe and total Qs values:  [[0.857]
 [0.871]
 [0.857]
 [0.857]
 [0.857]
 [0.857]
 [0.857]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.857]
 [0.871]
 [0.857]
 [0.857]
 [0.857]
 [0.857]
 [0.857]]
maxi score, test score, baseline:  0.06621999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06653999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.108]
 [0.295]
 [0.108]
 [0.112]
 [0.108]
 [0.108]
 [0.248]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.108]
 [0.295]
 [0.108]
 [0.112]
 [0.108]
 [0.108]
 [0.248]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06701999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.06701999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.135]
 [0.211]
 [0.164]
 [0.118]
 [0.24 ]
 [0.101]
 [0.125]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.135]
 [0.211]
 [0.164]
 [0.118]
 [0.24 ]
 [0.101]
 [0.125]]
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07051999999999983 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.06833999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.06803999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8722937
actor:  0 policy actor:  0  step number:  35 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07025999999999986 0.6964999999999999 0.6964999999999999
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07311999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.917]
 [0.934]
 [0.912]
 [0.907]
 [0.907]
 [0.907]
 [0.901]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.917]
 [0.934]
 [0.912]
 [0.907]
 [0.907]
 [0.907]
 [0.901]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07607999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.954]
 [1.003]
 [0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.954]
 [1.003]
 [0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.067]
 [0.158]
 [0.067]
 [0.067]
 [0.067]
 [0.067]
 [0.084]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.067]
 [0.158]
 [0.067]
 [0.067]
 [0.067]
 [0.067]
 [0.084]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07377999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.07377999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07695999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.921]
 [0.961]
 [0.921]
 [0.921]
 [0.921]
 [0.921]
 [0.921]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.921]
 [0.961]
 [0.921]
 [0.921]
 [0.921]
 [0.921]
 [0.921]]
maxi score, test score, baseline:  0.07695999999999985 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.07695999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07443999999999984 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07753999999999986 0.6964999999999999 0.6964999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07699999999999985 0.6964999999999999 0.6964999999999999
maxi score, test score, baseline:  0.07699999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Starting evaluation
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]]
Printing some Q and Qe and total Qs values:  [[0.638]
 [0.659]
 [0.638]
 [0.638]
 [0.638]
 [0.638]
 [0.638]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.638]
 [0.659]
 [0.638]
 [0.638]
 [0.638]
 [0.638]
 [0.638]]
Printing some Q and Qe and total Qs values:  [[0.757]
 [0.869]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.757]
 [0.869]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]]
siam score:  -0.8725763
maxi score, test score, baseline:  0.07999999999999985 0.6964999999999999 0.6964999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.997]
 [1.015]
 [0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.997]
 [1.015]
 [0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]]
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09353999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09625999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09273999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09273999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09313999999999983 0.6819999999999998 0.6819999999999998
Printing some Q and Qe and total Qs values:  [[ 0.021]
 [ 0.085]
 [ 0.048]
 [ 0.03 ]
 [-0.003]
 [-0.007]
 [ 0.073]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.021]
 [ 0.085]
 [ 0.048]
 [ 0.03 ]
 [-0.003]
 [-0.007]
 [ 0.073]]
maxi score, test score, baseline:  0.09055999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09069999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09069999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09079999999999985 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.09079999999999985 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Sims:  50 1 epoch:  150419 pick best:  False frame count:  150419
actor:  0 policy actor:  0  step number:  31 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09403999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09403999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09405999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.095]
 [0.013]
 [0.013]
 [0.013]
 [0.013]
 [0.032]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.013]
 [0.095]
 [0.013]
 [0.013]
 [0.013]
 [0.013]
 [0.032]]
maxi score, test score, baseline:  0.09381999999999985 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]
 [0.825]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.95 ]
 [0.951]
 [0.95 ]
 [0.95 ]
 [0.95 ]
 [0.95 ]
 [0.95 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.95 ]
 [0.951]
 [0.95 ]
 [0.95 ]
 [0.95 ]
 [0.95 ]
 [0.95 ]]
maxi score, test score, baseline:  0.09693999999999986 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.09693999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.681]
 [0.819]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.681]
 [0.819]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]]
maxi score, test score, baseline:  0.10011999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
siam score:  -0.87790704
maxi score, test score, baseline:  0.10011999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09947999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.62 ]
 [0.708]
 [0.254]
 [0.657]
 [0.67 ]
 [0.62 ]
 [0.685]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.62 ]
 [0.708]
 [0.254]
 [0.657]
 [0.67 ]
 [0.62 ]
 [0.685]]
Printing some Q and Qe and total Qs values:  [[0.583]
 [0.751]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.583]
 [0.751]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]]
maxi score, test score, baseline:  0.09601999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.09601999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09501999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.5199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09459999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09413999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.749]
 [0.749]
 [0.881]
 [0.749]
 [0.749]
 [0.749]
 [0.749]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.749]
 [0.749]
 [0.881]
 [0.749]
 [0.749]
 [0.749]
 [0.749]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.917]
 [0.938]
 [0.909]
 [0.905]
 [0.914]
 [0.914]
 [0.91 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.917]
 [0.938]
 [0.909]
 [0.905]
 [0.914]
 [0.914]
 [0.91 ]]
siam score:  -0.87338936
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09257999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.033]
 [0.092]
 [0.033]
 [0.06 ]
 [0.068]
 [0.04 ]
 [0.042]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.033]
 [0.092]
 [0.033]
 [0.06 ]
 [0.068]
 [0.04 ]
 [0.042]]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.564]
 [0.733]
 [0.569]
 [0.575]
 [0.57 ]
 [0.569]
 [0.569]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.564]
 [0.733]
 [0.569]
 [0.575]
 [0.57 ]
 [0.569]
 [0.569]]
maxi score, test score, baseline:  0.08861999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.835]
 [0.854]
 [0.855]
 [0.835]
 [0.835]
 [0.835]
 [0.856]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.835]
 [0.854]
 [0.855]
 [0.835]
 [0.835]
 [0.835]
 [0.856]]
actor:  0 policy actor:  0  step number:  34 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.599]
 [0.67 ]
 [0.596]
 [0.599]
 [0.599]
 [0.599]
 [0.588]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.599]
 [0.67 ]
 [0.596]
 [0.599]
 [0.599]
 [0.599]
 [0.588]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08223999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.698]
 [0.847]
 [0.698]
 [0.698]
 [0.698]
 [0.698]
 [0.698]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.698]
 [0.847]
 [0.698]
 [0.698]
 [0.698]
 [0.698]
 [0.698]]
maxi score, test score, baseline:  0.08179999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08179999999999985 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08087999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.07781999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.546]
 [0.698]
 [0.546]
 [0.413]
 [0.546]
 [0.413]
 [0.546]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.546]
 [0.698]
 [0.546]
 [0.413]
 [0.546]
 [0.413]
 [0.546]]
maxi score, test score, baseline:  0.07781999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07233999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07247999999999985 0.6819999999999998 0.6819999999999998
Printing some Q and Qe and total Qs values:  [[0.605]
 [0.605]
 [0.809]
 [0.605]
 [0.605]
 [0.605]
 [0.605]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.605]
 [0.605]
 [0.809]
 [0.605]
 [0.605]
 [0.605]
 [0.605]]
maxi score, test score, baseline:  0.07247999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07285999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07423999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.54 ]
 [0.841]
 [0.639]
 [0.555]
 [0.536]
 [0.715]
 [0.575]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.54 ]
 [0.841]
 [0.639]
 [0.555]
 [0.536]
 [0.715]
 [0.575]]
maxi score, test score, baseline:  0.07741999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.721]
 [0.806]
 [0.721]
 [0.609]
 [0.721]
 [0.721]
 [0.721]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.721]
 [0.806]
 [0.721]
 [0.609]
 [0.721]
 [0.721]
 [0.721]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.701]
 [0.876]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.701]
 [0.876]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]]
Printing some Q and Qe and total Qs values:  [[0.976]
 [1.024]
 [0.976]
 [0.976]
 [0.976]
 [0.976]
 [0.976]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.976]
 [1.024]
 [0.976]
 [0.976]
 [0.976]
 [0.976]
 [0.976]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07763999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.912]
 [0.963]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.912]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.912]
 [0.963]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.912]]
maxi score, test score, baseline:  0.07763999999999983 0.6819999999999998 0.6819999999999998
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.07763999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]]
maxi score, test score, baseline:  0.07803999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
siam score:  -0.8505908
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08381999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08381999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08597999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08597999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08597999999999986 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08883999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.794]
 [0.794]
 [0.86 ]
 [0.794]
 [0.794]
 [0.794]
 [0.794]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.794]
 [0.794]
 [0.86 ]
 [0.794]
 [0.794]
 [0.794]
 [0.794]]
siam score:  -0.843535
maxi score, test score, baseline:  0.08883999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09159999999999983 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09171999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09171999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09171999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.09171999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09171999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09765999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.09765999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09447999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09167999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09131999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.09131999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09191999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8609195
maxi score, test score, baseline:  0.08889999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08919999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.861]
 [0.904]
 [0.861]
 [0.861]
 [0.861]
 [0.861]
 [0.861]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.861]
 [0.904]
 [0.861]
 [0.861]
 [0.861]
 [0.861]
 [0.861]]
maxi score, test score, baseline:  0.08931999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.943]
 [0.947]
 [0.943]
 [0.943]
 [0.943]
 [0.943]
 [0.943]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.943]
 [0.947]
 [0.943]
 [0.943]
 [0.943]
 [0.943]
 [0.943]]
maxi score, test score, baseline:  0.08909999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08901999999999985 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  41 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8600759
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08855999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08855999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09107999999999986 0.6819999999999998 0.6819999999999998
Printing some Q and Qe and total Qs values:  [[0.781]
 [0.781]
 [0.866]
 [0.781]
 [0.781]
 [0.781]
 [0.781]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.781]
 [0.781]
 [0.866]
 [0.781]
 [0.781]
 [0.781]
 [0.781]]
maxi score, test score, baseline:  0.09107999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09411999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09411999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[1.015]
 [1.001]
 [1.015]
 [1.015]
 [1.015]
 [1.015]
 [0.708]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.015]
 [1.001]
 [1.015]
 [1.015]
 [1.015]
 [1.015]
 [0.708]]
maxi score, test score, baseline:  0.09411999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.92 ]
 [0.903]
 [0.891]
 [0.876]
 [0.764]
 [0.866]
 [0.965]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.92 ]
 [0.903]
 [0.891]
 [0.876]
 [0.764]
 [0.866]
 [0.965]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8653793
Printing some Q and Qe and total Qs values:  [[0.928]
 [0.965]
 [0.928]
 [0.894]
 [0.928]
 [0.928]
 [0.928]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.928]
 [0.965]
 [0.928]
 [0.894]
 [0.928]
 [0.928]
 [0.928]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
UNIT TEST: sample policy line 217 mcts : [0.041 0.531 0.02  0.041 0.041 0.02  0.306]
maxi score, test score, baseline:  0.09721999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09437999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.0699999999999994  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09341999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09643999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09643999999999983 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.09643999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09831999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.013]
 [0.973]
 [1.013]
 [1.013]
 [1.013]
 [1.013]
 [1.013]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.013]
 [0.973]
 [1.013]
 [1.013]
 [1.013]
 [1.013]
 [1.013]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.681]
 [0.681]
 [0.885]
 [0.681]
 [0.681]
 [0.681]
 [0.681]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.681]
 [0.681]
 [0.885]
 [0.681]
 [0.681]
 [0.681]
 [0.681]]
maxi score, test score, baseline:  0.09773999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.57  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09851999999999984 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  19 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09537999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.09537999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.897]
 [0.974]
 [0.95 ]
 [0.944]
 [0.937]
 [0.917]
 [0.975]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.897]
 [0.974]
 [0.95 ]
 [0.944]
 [0.937]
 [0.917]
 [0.975]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.911]
 [0.949]
 [0.911]
 [0.911]
 [0.895]
 [0.911]
 [0.911]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.911]
 [0.949]
 [0.911]
 [0.911]
 [0.895]
 [0.911]
 [0.911]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10207999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10151999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[1.014]
 [1.014]
 [1.014]
 [1.014]
 [1.014]
 [1.014]
 [1.014]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.014]
 [1.014]
 [1.014]
 [1.014]
 [1.014]
 [1.014]
 [1.014]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09837999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09909999999999983 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.499]
 [0.66 ]
 [0.499]
 [0.499]
 [0.499]
 [0.499]
 [0.499]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.499]
 [0.66 ]
 [0.499]
 [0.499]
 [0.499]
 [0.499]
 [0.499]]
maxi score, test score, baseline:  0.09727999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.475]
 [0.473]
 [0.475]
 [0.295]
 [0.3  ]
 [0.475]
 [0.475]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.475]
 [0.473]
 [0.475]
 [0.295]
 [0.3  ]
 [0.475]
 [0.475]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10359999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.10359999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.10359999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10089999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09799999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09837999999999983 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  38 total reward:  0.24999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09797999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.753]
 [0.806]
 [0.777]
 [0.707]
 [0.78 ]
 [0.711]
 [0.703]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.753]
 [0.806]
 [0.777]
 [0.707]
 [0.78 ]
 [0.711]
 [0.703]]
maxi score, test score, baseline:  0.09797999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09487999999999987 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09487999999999987 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09829999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09267999999999985 0.6819999999999998 0.6819999999999998
Printing some Q and Qe and total Qs values:  [[-0.004]
 [ 0.417]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.004]
 [ 0.417]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09297999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09297999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.09297999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09007999999999984 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.08685999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08685999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08685999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.784]
 [0.833]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.784]
 [0.833]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]]
Printing some Q and Qe and total Qs values:  [[0.799]
 [0.848]
 [0.791]
 [0.791]
 [0.792]
 [0.782]
 [0.788]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.799]
 [0.848]
 [0.791]
 [0.791]
 [0.792]
 [0.782]
 [0.788]]
maxi score, test score, baseline:  0.08087999999999983 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08131999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08081999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08081999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07735999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.07735999999999983 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07711999999999984 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07755999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.917]
 [0.958]
 [0.919]
 [0.884]
 [0.908]
 [0.907]
 [0.91 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.917]
 [0.958]
 [0.919]
 [0.884]
 [0.908]
 [0.907]
 [0.91 ]]
actor:  0 policy actor:  0  step number:  38 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07699999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.07699999999999983 0.6819999999999998 0.6819999999999998
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.867]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.81 ]
 [0.867]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07669999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.07669999999999984 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]]
maxi score, test score, baseline:  0.07735999999999983 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.07735999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.07675999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.992]
 [0.992]
 [0.992]
 [0.992]
 [0.992]
 [0.992]
 [0.992]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.992]
 [0.992]
 [0.992]
 [0.992]
 [0.992]
 [0.992]
 [0.992]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.684]
 [0.59 ]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.684]
 [0.59 ]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]]
Printing some Q and Qe and total Qs values:  [[0.869]
 [0.926]
 [0.869]
 [0.868]
 [0.869]
 [0.869]
 [0.967]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.869]
 [0.926]
 [0.869]
 [0.868]
 [0.869]
 [0.869]
 [0.967]]
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.673]
 [0.667]
 [0.685]
 [0.676]
 [0.696]
 [0.675]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.682]
 [0.673]
 [0.667]
 [0.685]
 [0.676]
 [0.696]
 [0.675]]
actor:  0 policy actor:  0  step number:  37 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08533999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.881]
 [0.772]
 [0.839]
 [0.858]
 [0.839]
 [0.839]
 [0.862]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.881]
 [0.772]
 [0.839]
 [0.858]
 [0.839]
 [0.839]
 [0.862]]
Printing some Q and Qe and total Qs values:  [[0.89 ]
 [0.896]
 [0.878]
 [0.883]
 [0.891]
 [0.87 ]
 [0.884]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.89 ]
 [0.896]
 [0.878]
 [0.883]
 [0.891]
 [0.87 ]
 [0.884]]
maxi score, test score, baseline:  0.08827999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08557999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08519999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08519999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08519999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08787999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.717]
 [0.765]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.717]
 [0.765]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]]
maxi score, test score, baseline:  0.08787999999999985 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.08787999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08787999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.016]
 [1.016]
 [1.016]
 [1.002]
 [1.002]
 [1.016]
 [1.016]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.016]
 [1.016]
 [1.016]
 [1.002]
 [1.002]
 [1.016]
 [1.016]]
maxi score, test score, baseline:  0.08455999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.08421999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08421999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.08421999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.08421999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.08421999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8574936
Printing some Q and Qe and total Qs values:  [[0.503]
 [0.682]
 [0.503]
 [0.503]
 [0.503]
 [0.503]
 [0.503]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.503]
 [0.682]
 [0.503]
 [0.503]
 [0.503]
 [0.503]
 [0.503]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.09607999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09917999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
siam score:  -0.8648856
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  41 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09889999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]]
Printing some Q and Qe and total Qs values:  [[0.635]
 [0.929]
 [0.899]
 [0.903]
 [0.899]
 [0.899]
 [0.944]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.635]
 [0.929]
 [0.899]
 [0.903]
 [0.899]
 [0.899]
 [0.944]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09877999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.075]
 [0.171]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.075]
 [0.171]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]]
maxi score, test score, baseline:  0.10173999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.10173999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09861999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.09861999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.09861999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10115999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.10115999999999985 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  32 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10343999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10389999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10357999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10589999999999983 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.10589999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.10589999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.393]
 [0.444]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.393]
 [0.444]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]]
maxi score, test score, baseline:  0.10917999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.851]
 [0.903]
 [0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.851]
 [0.903]
 [0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]]
maxi score, test score, baseline:  0.10867999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.10557999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.10557999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10521999999999984 0.6819999999999998 0.6819999999999998
Printing some Q and Qe and total Qs values:  [[0.738]
 [0.778]
 [0.744]
 [0.739]
 [0.727]
 [0.716]
 [0.771]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.738]
 [0.778]
 [0.744]
 [0.739]
 [0.727]
 [0.716]
 [0.771]]
actor:  0 policy actor:  0  step number:  34 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.69 ]
 [0.796]
 [0.69 ]
 [0.683]
 [0.69 ]
 [0.69 ]
 [0.717]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.69 ]
 [0.796]
 [0.69 ]
 [0.683]
 [0.69 ]
 [0.69 ]
 [0.717]]
maxi score, test score, baseline:  0.10459999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10815999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.10815999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.10815999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
siam score:  -0.8624622
maxi score, test score, baseline:  0.10527999999999985 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.10217999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.10217999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.10217999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.972]
 [0.961]
 [0.974]
 [0.965]
 [0.972]
 [0.955]
 [0.975]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.972]
 [0.961]
 [0.974]
 [0.965]
 [0.972]
 [0.955]
 [0.975]]
Printing some Q and Qe and total Qs values:  [[0.153]
 [0.163]
 [0.153]
 [0.155]
 [0.163]
 [0.163]
 [0.163]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.153]
 [0.163]
 [0.153]
 [0.155]
 [0.163]
 [0.163]
 [0.163]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09943999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.635]
 [0.65 ]
 [0.654]
 [0.628]
 [0.652]
 [0.635]
 [0.635]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.635]
 [0.65 ]
 [0.654]
 [0.628]
 [0.652]
 [0.635]
 [0.635]]
maxi score, test score, baseline:  0.09943999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09981999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.09981999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.09969999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
siam score:  -0.8644936
Printing some Q and Qe and total Qs values:  [[0.998]
 [0.999]
 [0.997]
 [0.972]
 [0.972]
 [0.973]
 [0.997]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.998]
 [0.999]
 [0.997]
 [0.972]
 [0.972]
 [0.973]
 [0.997]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10263999999999986 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10507999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.485]
 [0.485]
 [0.485]
 [0.485]
 [1.005]
 [1.005]
 [0.485]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.485]
 [0.485]
 [0.485]
 [0.485]
 [1.005]
 [1.005]
 [0.485]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10497999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.22]
 [0.22]
 [0.22]
 [0.22]
 [0.22]
 [0.22]
 [0.22]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.22]
 [0.22]
 [0.22]
 [0.22]
 [0.22]
 [0.22]
 [0.22]]
maxi score, test score, baseline:  0.10559999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10813999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.643]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.613]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.617]
 [0.643]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.613]]
Printing some Q and Qe and total Qs values:  [[0.755]
 [0.8  ]
 [0.755]
 [0.755]
 [0.755]
 [0.755]
 [0.755]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.755]
 [0.8  ]
 [0.755]
 [0.755]
 [0.755]
 [0.755]
 [0.755]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11131999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11185999999999982 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.11185999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11167999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.11167999999999985 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.11167999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.928]
 [0.922]
 [0.931]
 [0.931]
 [0.931]
 [0.931]
 [0.931]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.928]
 [0.922]
 [0.931]
 [0.931]
 [0.931]
 [0.931]
 [0.931]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11491999999999983 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11475999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
siam score:  -0.860262
Printing some Q and Qe and total Qs values:  [[0.881]
 [0.884]
 [0.857]
 [0.881]
 [0.868]
 [0.881]
 [0.881]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.881]
 [0.884]
 [0.857]
 [0.881]
 [0.868]
 [0.881]
 [0.881]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.925]
 [0.997]
 [0.9  ]
 [0.925]
 [0.925]
 [0.882]
 [0.999]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.925]
 [0.997]
 [0.9  ]
 [0.925]
 [0.925]
 [0.882]
 [0.999]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11827999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.11827999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11845999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11895999999999983 0.6819999999999998 0.6819999999999998
Printing some Q and Qe and total Qs values:  [[0.789]
 [0.827]
 [0.801]
 [0.796]
 [0.801]
 [0.801]
 [0.801]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.789]
 [0.827]
 [0.801]
 [0.796]
 [0.801]
 [0.801]
 [0.801]]
Printing some Q and Qe and total Qs values:  [[0.909]
 [0.948]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.909]
 [0.948]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11879999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.11563999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11573999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.11573999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11881999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12497999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.12497999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.936]
 [0.955]
 [0.955]
 [0.955]
 [0.955]
 [0.955]
 [0.955]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.936]
 [0.955]
 [0.955]
 [0.955]
 [0.955]
 [0.955]
 [0.955]]
maxi score, test score, baseline:  0.12843999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.12843999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.12843999999999983 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  45 total reward:  0.01999999999999935  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12741999999999984 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.808]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.878]
 [0.808]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]]
maxi score, test score, baseline:  0.13003999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.13003999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.13003999999999982 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12975999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1269199999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.1269199999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13033999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13301999999999983 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1364599999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8614102
maxi score, test score, baseline:  0.13065999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1306599999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.0799999999999994  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.86176944
maxi score, test score, baseline:  0.12657999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12645999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.12645999999999982 0.6819999999999998 0.6819999999999998
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12263999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.12263999999999982 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.12263999999999982 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.12263999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.11989999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11999999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11883999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
siam score:  -0.85591155
maxi score, test score, baseline:  0.11567999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.11567999999999982 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.11567999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.032]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.032]]
maxi score, test score, baseline:  0.11575999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11549999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.985]
 [1.015]
 [0.985]
 [0.985]
 [0.985]
 [0.985]
 [0.985]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.985]
 [1.015]
 [0.985]
 [0.985]
 [0.985]
 [0.985]
 [0.985]]
maxi score, test score, baseline:  0.11549999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.11549999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.675]
 [0.733]
 [0.678]
 [0.673]
 [0.681]
 [0.66 ]
 [0.692]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.675]
 [0.733]
 [0.678]
 [0.673]
 [0.681]
 [0.66 ]
 [0.692]]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.774]
 [0.882]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.774]
 [0.882]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]]
maxi score, test score, baseline:  0.11839999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.956]
 [0.956]
 [0.956]
 [0.956]
 [0.956]
 [0.956]
 [0.956]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.956]
 [0.956]
 [0.956]
 [0.956]
 [0.956]
 [0.956]
 [0.956]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12131999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.12131999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.064]
 [0.231]
 [0.064]
 [0.097]
 [0.064]
 [0.064]
 [0.124]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.064]
 [0.231]
 [0.064]
 [0.097]
 [0.064]
 [0.064]
 [0.124]]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.134]
 [0.006]
 [0.007]
 [0.031]
 [0.009]
 [0.01 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.007]
 [0.134]
 [0.006]
 [0.007]
 [0.031]
 [0.009]
 [0.01 ]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12109999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.12109999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.45999999999999985  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12441999999999985 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.81 ]
 [0.859]
 [0.81 ]
 [0.81 ]
 [0.261]
 [0.81 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.81 ]
 [0.81 ]
 [0.859]
 [0.81 ]
 [0.81 ]
 [0.261]
 [0.81 ]]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8535266
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12127999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.752]
 [0.8  ]
 [0.752]
 [0.752]
 [0.752]
 [0.752]
 [0.752]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.752]
 [0.8  ]
 [0.752]
 [0.752]
 [0.752]
 [0.752]
 [0.752]]
maxi score, test score, baseline:  0.12089999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  40 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8569451
actor:  0 policy actor:  0  step number:  33 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12611999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.12611999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.12611999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12349999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.10999999999999943  reward:  1.0 rdn_beta:  0.0
siam score:  -0.86342347
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.843]
 [0.908]
 [0.843]
 [0.843]
 [0.843]
 [0.843]
 [0.843]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.843]
 [0.908]
 [0.843]
 [0.843]
 [0.843]
 [0.843]
 [0.843]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12661999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.12661999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.993]
 [1.013]
 [0.993]
 [0.993]
 [0.993]
 [0.993]
 [0.993]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.993]
 [1.013]
 [0.993]
 [0.993]
 [0.993]
 [0.993]
 [0.993]]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12959999999999983 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13241999999999984 0.6819999999999998 0.6819999999999998
Printing some Q and Qe and total Qs values:  [[1.005]
 [1.006]
 [1.005]
 [0.993]
 [0.993]
 [1.006]
 [0.993]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.005]
 [1.006]
 [1.005]
 [0.993]
 [0.993]
 [1.006]
 [0.993]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1357999999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.1357999999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13635999999999981 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.004]
 [1.005]
 [1.005]
 [0.964]
 [0.989]
 [0.967]
 [1.005]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.004]
 [1.005]
 [1.005]
 [0.964]
 [0.989]
 [0.967]
 [1.005]]
Printing some Q and Qe and total Qs values:  [[0.839]
 [0.89 ]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.839]
 [0.89 ]
 [0.839]
 [0.839]
 [0.839]
 [0.839]
 [0.839]]
actor:  0 policy actor:  0  step number:  19 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1405199999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.1405199999999998 0.6819999999999998 0.6819999999999998
siam score:  -0.8626786
Printing some Q and Qe and total Qs values:  [[0.919]
 [0.948]
 [0.905]
 [0.913]
 [0.916]
 [0.916]
 [0.919]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.919]
 [0.948]
 [0.905]
 [0.913]
 [0.916]
 [0.916]
 [0.919]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.917]
 [0.934]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.959]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.917]
 [0.934]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.959]]
maxi score, test score, baseline:  0.1439799999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.958]
 [0.988]
 [0.944]
 [0.945]
 [0.945]
 [0.963]
 [0.947]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.958]
 [0.988]
 [0.944]
 [0.945]
 [0.945]
 [0.963]
 [0.947]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.891]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.891]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]]
maxi score, test score, baseline:  0.1439199999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.1439199999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.1439199999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14341999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14319999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.789]
 [0.831]
 [0.789]
 [0.789]
 [0.789]
 [0.789]
 [0.789]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.789]
 [0.831]
 [0.789]
 [0.789]
 [0.789]
 [0.789]
 [0.789]]
maxi score, test score, baseline:  0.14319999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.14319999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.821]
 [0.96 ]
 [0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.821]
 [0.96 ]
 [0.999]
 [0.999]
 [0.999]
 [0.999]
 [0.999]]
actor:  0 policy actor:  0  step number:  39 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13937999999999978 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.13937999999999978 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13889999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.13889999999999983 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.13889999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.13889999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.97 ]
 [0.778]
 [0.97 ]
 [0.97 ]
 [0.97 ]
 [0.97 ]
 [0.97 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.97 ]
 [0.778]
 [0.97 ]
 [0.97 ]
 [0.97 ]
 [0.97 ]
 [0.97 ]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.866]
 [0.964]
 [0.939]
 [0.941]
 [0.939]
 [0.939]
 [0.925]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.866]
 [0.964]
 [0.939]
 [0.941]
 [0.939]
 [0.939]
 [0.925]]
siam score:  -0.85779685
actor:  0 policy actor:  0  step number:  40 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[ 0.8370],
        [ 0.9361],
        [ 0.8370],
        [ 0.0000],
        [-0.4367],
        [ 0.3431],
        [ 0.1543],
        [ 0.3431],
        [ 0.2400],
        [ 0.3396]], dtype=torch.float64)
-0.106157551797 0.7308362717678305
-0.048519850599000006 0.8876052162793464
-0.08675157179700001 0.7502422517678305
0.99 0.99
-0.048519850599000006 -0.4851811651633781
-0.126539750799 0.2165441671707243
-0.107327830599 0.04700742135076552
-0.126539750799 0.2165441671707243
-0.145559551797 0.09443286681422591
-0.145559551797 0.19402042833772262
maxi score, test score, baseline:  0.14177999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.1387999999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1392399999999998 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.1392399999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.1392399999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.1392399999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1392399999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13873999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.703]
 [0.658]
 [0.659]
 [0.657]
 [0.657]
 [0.674]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.657]
 [0.703]
 [0.658]
 [0.659]
 [0.657]
 [0.657]
 [0.674]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13549999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13539999999999983 0.6819999999999998 0.6819999999999998
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13797999999999983 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.775]
 [0.884]
 [0.775]
 [0.775]
 [0.775]
 [0.775]
 [0.775]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.775]
 [0.884]
 [0.775]
 [0.775]
 [0.775]
 [0.775]
 [0.775]]
Printing some Q and Qe and total Qs values:  [[0.75]
 [0.75]
 [0.75]
 [0.75]
 [0.75]
 [0.75]
 [0.75]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.75]
 [0.75]
 [0.75]
 [0.75]
 [0.75]
 [0.75]
 [0.75]]
Printing some Q and Qe and total Qs values:  [[0.706]
 [0.738]
 [0.707]
 [0.706]
 [0.708]
 [0.705]
 [0.703]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.706]
 [0.738]
 [0.707]
 [0.706]
 [0.708]
 [0.705]
 [0.703]]
maxi score, test score, baseline:  0.13455999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.13455999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1346999999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13713999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14035999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.14035999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13821999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.674]
 [0.589]
 [0.587]
 [0.583]
 [0.631]
 [0.631]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.631]
 [0.674]
 [0.589]
 [0.587]
 [0.583]
 [0.631]
 [0.631]]
maxi score, test score, baseline:  0.14141999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.569]
 [0.664]
 [0.569]
 [0.569]
 [0.506]
 [0.569]
 [0.498]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.569]
 [0.664]
 [0.569]
 [0.569]
 [0.506]
 [0.569]
 [0.498]]
maxi score, test score, baseline:  0.14141999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.14141999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14101999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.14101999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.556]
 [0.56 ]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.556]
 [0.56 ]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]]
Printing some Q and Qe and total Qs values:  [[0.745]
 [0.882]
 [0.745]
 [0.745]
 [0.745]
 [0.745]
 [0.745]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.745]
 [0.882]
 [0.745]
 [0.745]
 [0.745]
 [0.745]
 [0.745]]
maxi score, test score, baseline:  0.13183999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.13183999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13219999999999982 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.13219999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13547999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.13547999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1319999999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.91 ]
 [0.945]
 [0.912]
 [0.902]
 [0.91 ]
 [0.883]
 [0.891]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.91 ]
 [0.945]
 [0.912]
 [0.902]
 [0.91 ]
 [0.883]
 [0.891]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13533999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.13533999999999982 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1413199999999998 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14417999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
Starting evaluation
maxi score, test score, baseline:  0.14417999999999984 0.6819999999999998 0.6819999999999998
maxi score, test score, baseline:  0.14417999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
maxi score, test score, baseline:  0.14417999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.735]
 [0.8  ]
 [0.796]
 [0.71 ]
 [0.733]
 [0.72 ]
 [0.752]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.735]
 [0.8  ]
 [0.796]
 [0.71 ]
 [0.733]
 [0.72 ]
 [0.752]]
maxi score, test score, baseline:  0.14417999999999984 0.6819999999999998 0.6819999999999998
Printing some Q and Qe and total Qs values:  [[0.925]
 [0.856]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.915]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.925]
 [0.856]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.915]]
maxi score, test score, baseline:  0.14417999999999984 0.6819999999999998 0.6819999999999998
probs:  [1.0]
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.4999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1775999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17763999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.828]
 [0.863]
 [0.828]
 [0.828]
 [0.828]
 [0.828]
 [0.828]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.828]
 [0.863]
 [0.828]
 [0.828]
 [0.828]
 [0.828]
 [0.828]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18109999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18109999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18109999999999982 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.17789999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1779599999999998 0.6874999999999999 0.6874999999999999
Printing some Q and Qe and total Qs values:  [[0.661]
 [0.741]
 [0.63 ]
 [0.643]
 [0.65 ]
 [0.649]
 [0.638]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.661]
 [0.741]
 [0.63 ]
 [0.643]
 [0.65 ]
 [0.649]
 [0.638]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17829999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17799999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
siam score:  -0.8485047
maxi score, test score, baseline:  0.17799999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17775999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17563999999999985 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17563999999999985 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17563999999999985 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17535999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.862]
 [0.882]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.862]
 [0.882]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]]
maxi score, test score, baseline:  0.1748399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.871]
 [0.888]
 [0.889]
 [0.871]
 [0.871]
 [0.871]
 [0.871]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.871]
 [0.888]
 [0.889]
 [0.871]
 [0.871]
 [0.871]
 [0.871]]
maxi score, test score, baseline:  0.1748399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1748399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1748399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.647]
 [0.817]
 [0.25 ]
 [0.639]
 [0.615]
 [0.182]
 [0.792]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.647]
 [0.817]
 [0.25 ]
 [0.639]
 [0.615]
 [0.182]
 [0.792]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17445999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.13999999999999946  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17629999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.669]
 [0.669]
 [0.678]
 [0.669]
 [0.669]
 [0.669]
 [0.669]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.669]
 [0.669]
 [0.678]
 [0.669]
 [0.669]
 [0.669]
 [0.669]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17663999999999985 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.083]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.083]]
maxi score, test score, baseline:  0.1772599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.   ]
 [0.913]
 [1.   ]
 [1.   ]
 [1.   ]
 [1.   ]
 [1.   ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.   ]
 [0.913]
 [1.   ]
 [1.   ]
 [1.   ]
 [1.   ]
 [1.   ]]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18001999999999985 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.629]
 [0.629]
 [0.803]
 [0.629]
 [0.629]
 [0.629]
 [0.629]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.629]
 [0.629]
 [0.803]
 [0.629]
 [0.629]
 [0.629]
 [0.629]]
maxi score, test score, baseline:  0.18001999999999985 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1795799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1795799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18237999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.335]
 [0.335]
 [0.311]
 [0.335]
 [0.335]
 [0.335]
 [0.335]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.335]
 [0.335]
 [0.311]
 [0.335]
 [0.335]
 [0.335]
 [0.335]]
actor:  0 policy actor:  0  step number:  40 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[ 0.001]
 [-0.   ]
 [ 0.018]
 [ 1.048]
 [ 0.016]
 [ 0.016]
 [ 1.048]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.001]
 [-0.   ]
 [ 0.018]
 [ 1.048]
 [ 0.016]
 [ 0.016]
 [ 1.048]]
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]]
maxi score, test score, baseline:  0.1806999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1806999999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18319999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18319999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18319999999999984 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18331999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18331999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.18627999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18627999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.859]
 [0.884]
 [0.859]
 [0.859]
 [0.859]
 [0.859]
 [0.859]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.859]
 [0.884]
 [0.859]
 [0.859]
 [0.859]
 [0.859]
 [0.859]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1861599999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1851799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18481999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18443999999999983 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18403999999999981 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18403999999999981 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.302]
 [0.302]
 [0.302]
 [0.302]
 [0.302]
 [0.302]
 [0.302]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.302]
 [0.302]
 [0.302]
 [0.302]
 [0.302]
 [0.302]
 [0.302]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.619]
 [0.742]
 [0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.619]
 [0.742]
 [0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1824399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18209999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18135999999999983 0.6874999999999999 0.6874999999999999
Printing some Q and Qe and total Qs values:  [[0.64 ]
 [0.64 ]
 [0.687]
 [0.64 ]
 [0.64 ]
 [0.64 ]
 [0.64 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.64 ]
 [0.64 ]
 [0.687]
 [0.64 ]
 [0.64 ]
 [0.64 ]
 [0.64 ]]
maxi score, test score, baseline:  0.1779199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.653]
 [0.732]
 [0.659]
 [0.654]
 [0.655]
 [0.656]
 [0.656]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.653]
 [0.732]
 [0.659]
 [0.654]
 [0.655]
 [0.656]
 [0.656]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1773799999999998 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.1773799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.74 ]
 [0.831]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.74 ]
 [0.831]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]]
Printing some Q and Qe and total Qs values:  [[0.13 ]
 [0.171]
 [0.13 ]
 [0.13 ]
 [0.13 ]
 [0.13 ]
 [0.13 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.13 ]
 [0.171]
 [0.13 ]
 [0.13 ]
 [0.13 ]
 [0.13 ]
 [0.13 ]]
maxi score, test score, baseline:  0.17375999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17375999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17375999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17719999999999977 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.14999999999999947  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1794999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1794999999999998 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.1794999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17951999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]]
maxi score, test score, baseline:  0.1756999999999998 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.1756999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.711]
 [0.809]
 [0.711]
 [0.703]
 [0.702]
 [0.711]
 [0.714]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.711]
 [0.809]
 [0.711]
 [0.703]
 [0.702]
 [0.711]
 [0.714]]
maxi score, test score, baseline:  0.1757399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17565999999999982 0.6874999999999999 0.6874999999999999
siam score:  -0.84222925
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.16997999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16997999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.775]
 [0.885]
 [0.78 ]
 [0.78 ]
 [0.78 ]
 [0.78 ]
 [0.78 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.775]
 [0.885]
 [0.78 ]
 [0.78 ]
 [0.78 ]
 [0.78 ]
 [0.78 ]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16693999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16693999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1663599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16343999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16343999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16303999999999982 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1658999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.102]
 [0.145]
 [0.102]
 [0.102]
 [0.102]
 [0.102]
 [0.102]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.102]
 [0.145]
 [0.102]
 [0.102]
 [0.102]
 [0.102]
 [0.102]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]]
actor:  0 policy actor:  0  step number:  16 total reward:  0.7699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1689999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.947]
 [0.983]
 [0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.947]
 [0.983]
 [0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.13999999999999946  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17171999999999982 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17171999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17171999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17177999999999982 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.17177999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17177999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
siam score:  -0.85637593
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.819]
 [0.819]
 [0.891]
 [0.78 ]
 [0.819]
 [0.819]
 [0.815]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.819]
 [0.819]
 [0.891]
 [0.78 ]
 [0.819]
 [0.819]
 [0.815]]
Printing some Q and Qe and total Qs values:  [[0.599]
 [0.617]
 [0.621]
 [0.605]
 [0.597]
 [0.612]
 [0.613]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.599]
 [0.617]
 [0.621]
 [0.605]
 [0.597]
 [0.612]
 [0.613]]
maxi score, test score, baseline:  0.1655199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16921999999999982 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.16921999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.925]
 [0.984]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.925]
 [0.984]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1695599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1700999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17003999999999977 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17007999999999981 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17007999999999981 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16459999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1642399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.593]
 [0.725]
 [0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.593]
 [0.725]
 [0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]]
maxi score, test score, baseline:  0.1586399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1586399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1586399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16115999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16115999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16409999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.759]
 [0.849]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.759]
 [0.849]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]]
maxi score, test score, baseline:  0.16409999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1638799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1638799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1638799999999998 0.6874999999999999 0.6874999999999999
Printing some Q and Qe and total Qs values:  [[0.575]
 [0.603]
 [0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.575]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.575]
 [0.603]
 [0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.575]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1566799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1566799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.231]
 [0.229]
 [0.228]
 [0.228]
 [0.234]
 [0.234]
 [0.234]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.231]
 [0.229]
 [0.228]
 [0.228]
 [0.234]
 [0.234]
 [0.234]]
maxi score, test score, baseline:  0.1568599999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15695999999999977 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.15695999999999977 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.896]
 [0.983]
 [0.896]
 [0.896]
 [0.896]
 [0.896]
 [0.896]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.896]
 [0.983]
 [0.896]
 [0.896]
 [0.896]
 [0.896]
 [0.896]]
siam score:  -0.8418497
Printing some Q and Qe and total Qs values:  [[0.915]
 [0.983]
 [0.915]
 [0.915]
 [0.915]
 [0.915]
 [0.915]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.915]
 [0.983]
 [0.915]
 [0.915]
 [0.915]
 [0.915]
 [0.915]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1567799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1567799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1569599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1569599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.816]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.682]
 [0.816]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]]
maxi score, test score, baseline:  0.1541799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1539199999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15389999999999981 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.963]
 [0.98 ]
 [0.98 ]
 [0.963]
 [0.963]
 [0.963]
 [0.982]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.963]
 [0.98 ]
 [0.98 ]
 [0.963]
 [0.963]
 [0.963]
 [0.982]]
maxi score, test score, baseline:  0.15389999999999981 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1541199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1541199999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1543599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1543599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1544999999999998 0.6874999999999999 0.6874999999999999
Printing some Q and Qe and total Qs values:  [[0.96 ]
 [1.026]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.96 ]
 [1.026]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15475999999999981 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.576]
 [0.694]
 [0.067]
 [0.649]
 [0.626]
 [0.609]
 [0.684]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.576]
 [0.694]
 [0.067]
 [0.649]
 [0.626]
 [0.609]
 [0.684]]
maxi score, test score, baseline:  0.1578999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1612199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16171999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.758]
 [0.805]
 [0.758]
 [0.758]
 [0.758]
 [0.739]
 [0.758]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.758]
 [0.805]
 [0.758]
 [0.758]
 [0.758]
 [0.739]
 [0.758]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8450656
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16741999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16741999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16741999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17089999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1764799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  42 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1764199999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17977999999999983 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18309999999999982 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.18309999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1862999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1862999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1862999999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  34 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1862999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1867399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1866999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1838799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.882]
 [0.942]
 [0.914]
 [0.908]
 [0.908]
 [0.918]
 [0.918]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.882]
 [0.942]
 [0.914]
 [0.908]
 [0.908]
 [0.918]
 [0.918]]
maxi score, test score, baseline:  0.1838799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18415999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.642]
 [0.817]
 [0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.642]
 [0.817]
 [0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]]
Printing some Q and Qe and total Qs values:  [[0.833]
 [0.884]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.833]
 [0.884]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]]
actor:  0 policy actor:  0  step number:  43 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1839399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1839399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.387]
 [0.387]
 [0.387]
 [0.387]
 [0.387]
 [0.387]
 [0.387]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.387]
 [0.387]
 [0.387]
 [0.387]
 [0.387]
 [0.387]
 [0.387]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1808199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1808199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18417999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18417999999999982 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  33 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.812]
 [0.888]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.812]
 [0.888]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1832399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1832399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1832399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.788]
 [0.788]
 [0.796]
 [0.815]
 [0.778]
 [0.774]
 [0.768]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.788]
 [0.788]
 [0.796]
 [0.815]
 [0.778]
 [0.774]
 [0.768]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1835599999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18385999999999977 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1839999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1839999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1832999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18377999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.753]
 [0.849]
 [0.753]
 [0.753]
 [0.753]
 [0.753]
 [0.753]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.753]
 [0.849]
 [0.753]
 [0.753]
 [0.753]
 [0.753]
 [0.753]]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.698]
 [0.705]
 [0.698]
 [0.698]
 [0.698]
 [0.656]
 [0.698]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.698]
 [0.705]
 [0.698]
 [0.698]
 [0.698]
 [0.656]
 [0.698]]
maxi score, test score, baseline:  0.1842599999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1845199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1845199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8509312
maxi score, test score, baseline:  0.1902999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1902999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1902999999999998 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.1902999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1901199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1901199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1901199999999998 0.6874999999999999 0.6874999999999999
siam score:  -0.8536538
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1843199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.842]
 [0.842]
 [0.842]
 [0.842]
 [0.842]
 [0.842]
 [0.842]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.842]
 [0.842]
 [0.842]
 [0.842]
 [0.842]
 [0.842]
 [0.842]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1835199999999998 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.1835199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1863999999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1865599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1865599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
siam score:  -0.8449571
maxi score, test score, baseline:  0.1865599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1868599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18651999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8473593
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1897199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1926999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1926999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.831]
 [0.858]
 [0.647]
 [0.647]
 [0.647]
 [0.647]
 [0.647]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.831]
 [0.858]
 [0.647]
 [0.647]
 [0.647]
 [0.647]
 [0.647]]
maxi score, test score, baseline:  0.1951799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.847715
Printing some Q and Qe and total Qs values:  [[0.967]
 [0.974]
 [0.982]
 [0.937]
 [0.949]
 [0.935]
 [0.975]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.967]
 [0.974]
 [0.982]
 [0.937]
 [0.949]
 [0.935]
 [0.975]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.692]
 [0.726]
 [0.692]
 [0.692]
 [0.692]
 [0.692]
 [0.718]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.692]
 [0.726]
 [0.692]
 [0.692]
 [0.692]
 [0.692]
 [0.718]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1988999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1988999999999998 0.6874999999999999 0.6874999999999999
Printing some Q and Qe and total Qs values:  [[0.928]
 [0.994]
 [0.928]
 [0.928]
 [0.928]
 [0.928]
 [0.928]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.928]
 [0.994]
 [0.928]
 [0.928]
 [0.928]
 [0.928]
 [0.928]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]]
maxi score, test score, baseline:  0.1940599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.711]
 [0.823]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.711]
 [0.823]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]]
maxi score, test score, baseline:  0.1913599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1913599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.962]
 [1.003]
 [0.966]
 [0.962]
 [0.962]
 [0.962]
 [1.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.962]
 [1.003]
 [0.966]
 [0.962]
 [0.962]
 [0.962]
 [1.002]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1942999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.884]
 [0.884]
 [0.884]
 [0.884]
 [0.884]
 [0.884]
 [0.884]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.884]
 [0.884]
 [0.884]
 [0.884]
 [0.884]
 [0.884]
 [0.884]]
actor:  0 policy actor:  0  step number:  39 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1935399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1935399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1935399999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1933599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1935399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.229]
 [0.229]
 [0.226]
 [0.229]
 [0.229]
 [0.229]
 [0.229]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.229]
 [0.229]
 [0.226]
 [0.229]
 [0.229]
 [0.229]
 [0.229]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1848799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1848799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1848799999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1852799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1851799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18533999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18533999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1855999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18815999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18815999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18827999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.18827999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.75  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.061]
 [0.14 ]
 [0.061]
 [0.082]
 [0.061]
 [0.061]
 [0.153]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.061]
 [0.14 ]
 [0.061]
 [0.082]
 [0.061]
 [0.061]
 [0.153]]
maxi score, test score, baseline:  0.1886199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1886199999999998 0.6874999999999999 0.6874999999999999
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1889399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.026]
 [0.142]
 [0.026]
 [0.04 ]
 [0.026]
 [0.026]
 [0.048]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.026]
 [0.142]
 [0.026]
 [0.04 ]
 [0.026]
 [0.026]
 [0.048]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.955]
 [0.943]
 [0.99 ]
 [0.99 ]
 [0.99 ]
 [0.99 ]
 [0.878]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.955]
 [0.943]
 [0.99 ]
 [0.99 ]
 [0.99 ]
 [0.99 ]
 [0.878]]
maxi score, test score, baseline:  0.1850399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1850399999999998 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.1850399999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18451999999999977 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1869999999999998 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.1869999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1869999999999998 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.1869999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.997]
 [1.014]
 [0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.997]
 [1.014]
 [0.997]
 [0.997]
 [0.997]
 [0.997]
 [0.997]]
maxi score, test score, baseline:  0.1869999999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1868799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1868799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.12999999999999945  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1859199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
siam score:  -0.8510307
Printing some Q and Qe and total Qs values:  [[0.982]
 [0.982]
 [0.982]
 [0.982]
 [0.982]
 [0.982]
 [0.982]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.982]
 [0.982]
 [0.982]
 [0.982]
 [0.982]
 [0.982]
 [0.982]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1867799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.774]
 [0.866]
 [0.769]
 [0.774]
 [0.774]
 [0.774]
 [0.774]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.774]
 [0.866]
 [0.769]
 [0.774]
 [0.774]
 [0.774]
 [0.774]]
maxi score, test score, baseline:  0.18353999999999981 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  35 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18609999999999982 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.18609999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18609999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  43 total reward:  0.03999999999999937  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18327999999999983 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.79 ]
 [0.866]
 [0.79 ]
 [0.79 ]
 [0.79 ]
 [0.79 ]
 [0.79 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.79 ]
 [0.866]
 [0.79 ]
 [0.79 ]
 [0.79 ]
 [0.79 ]
 [0.79 ]]
maxi score, test score, baseline:  0.1844399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
siam score:  -0.8400058
maxi score, test score, baseline:  0.18145999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.871]
 [0.955]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.871]
 [0.955]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18465999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1879399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.978]
 [0.023]
 [0.978]
 [0.978]
 [0.978]
 [0.002]
 [0.978]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.978]
 [0.023]
 [0.978]
 [0.978]
 [0.978]
 [0.002]
 [0.978]]
maxi score, test score, baseline:  0.1851399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18295999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18295999999999982 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1825599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.708]
 [0.777]
 [0.708]
 [0.708]
 [0.708]
 [0.708]
 [0.708]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.708]
 [0.777]
 [0.708]
 [0.708]
 [0.708]
 [0.708]
 [0.708]]
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.92 ]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.878]
 [0.92 ]
 [0.878]
 [0.878]
 [0.878]
 [0.878]
 [0.878]]
maxi score, test score, baseline:  0.1825599999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1819599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1819599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.17941999999999977 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  45 total reward:  0.0799999999999994  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1789799999999998 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.1789799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17863999999999977 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17595999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.874]
 [0.748]
 [0.874]
 [0.845]
 [0.781]
 [0.874]
 [0.861]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.874]
 [0.748]
 [0.874]
 [0.845]
 [0.781]
 [0.874]
 [0.861]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17593999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
siam score:  -0.8401816
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17607999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1756999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1724799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.727]
 [0.576]
 [0.77 ]
 [0.613]
 [0.727]
 [0.691]
 [0.572]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.727]
 [0.576]
 [0.77 ]
 [0.613]
 [0.727]
 [0.691]
 [0.572]]
UNIT TEST: sample policy line 217 mcts : [0.041 0.51  0.163 0.082 0.102 0.041 0.061]
maxi score, test score, baseline:  0.17585999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.1756199999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17031999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17057999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17057999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.837]
 [0.883]
 [0.837]
 [0.837]
 [0.837]
 [0.837]
 [0.837]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.837]
 [0.883]
 [0.837]
 [0.837]
 [0.837]
 [0.837]
 [0.837]]
maxi score, test score, baseline:  0.17057999999999984 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1705399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8505557
maxi score, test score, baseline:  0.1712999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]]
Printing some Q and Qe and total Qs values:  [[0.831]
 [0.904]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.831]
 [0.904]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.831]]
maxi score, test score, baseline:  0.17133999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17433999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.903]
 [0.975]
 [0.903]
 [0.903]
 [0.903]
 [0.903]
 [0.903]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.903]
 [0.975]
 [0.903]
 [0.903]
 [0.903]
 [0.903]
 [0.903]]
Printing some Q and Qe and total Qs values:  [[0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1744799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.941]
 [0.919]
 [0.856]
 [0.891]
 [0.856]
 [0.168]
 [0.913]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.941]
 [0.919]
 [0.856]
 [0.891]
 [0.856]
 [0.168]
 [0.913]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.732]
 [0.834]
 [0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.732]
 [0.834]
 [0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]]
maxi score, test score, baseline:  0.17693999999999985 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17693999999999985 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17425999999999978 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.17425999999999978 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.931]
 [0.989]
 [0.931]
 [0.931]
 [0.931]
 [0.931]
 [0.931]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.931]
 [0.989]
 [0.931]
 [0.931]
 [0.931]
 [0.931]
 [0.931]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17327999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17327999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1760799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[1.004]
 [1.005]
 [1.002]
 [0.999]
 [0.974]
 [1.005]
 [0.974]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.004]
 [1.005]
 [1.002]
 [0.999]
 [0.974]
 [1.005]
 [0.974]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8449573
Printing some Q and Qe and total Qs values:  [[0.824]
 [0.87 ]
 [0.824]
 [0.824]
 [0.824]
 [0.824]
 [0.824]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.824]
 [0.87 ]
 [0.824]
 [0.824]
 [0.824]
 [0.824]
 [0.824]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.705]
 [0.77 ]
 [0.714]
 [0.709]
 [0.705]
 [0.705]
 [0.712]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.705]
 [0.77 ]
 [0.714]
 [0.709]
 [0.705]
 [0.705]
 [0.712]]
maxi score, test score, baseline:  0.1799399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.1799399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.898]
 [0.889]
 [0.889]
 [0.889]
 [0.889]
 [0.889]
 [0.889]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.898]
 [0.889]
 [0.889]
 [0.889]
 [0.889]
 [0.889]
 [0.889]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18027999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18027999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18071999999999983 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18071999999999983 0.6874999999999999 0.6874999999999999
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.1780399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.747]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.707]
 [0.747]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]]
maxi score, test score, baseline:  0.18073999999999982 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.18073999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1834999999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18403999999999981 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18093999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1813799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18143999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.75 ]
 [0.797]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.75 ]
 [0.797]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]]
Printing some Q and Qe and total Qs values:  [[0.78]
 [0.78]
 [0.78]
 [0.78]
 [0.78]
 [0.78]
 [0.78]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.78]
 [0.78]
 [0.78]
 [0.78]
 [0.78]
 [0.78]
 [0.78]]
maxi score, test score, baseline:  0.18143999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18143999999999982 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1810399999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  34 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1784199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1784199999999998 0.6874999999999999 0.6874999999999999
maxi score, test score, baseline:  0.1784199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.642]
 [0.305]
 [0.549]
 [0.642]
 [0.642]
 [0.642]
 [0.642]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.642]
 [0.305]
 [0.549]
 [0.642]
 [0.642]
 [0.642]
 [0.642]]
maxi score, test score, baseline:  0.1726799999999998 0.6874999999999999 0.6874999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]]
maxi score, test score, baseline:  0.1701199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1700399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1671599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1671599999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16747999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1698399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
siam score:  -0.83947635
maxi score, test score, baseline:  0.1698399999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17235999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16891999999999982 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.75 ]
 [0.842]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.75 ]
 [0.842]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]]
maxi score, test score, baseline:  0.1723199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1723199999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1693799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Starting evaluation
maxi score, test score, baseline:  0.1693799999999998 0.6874999999999999 0.6874999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.812]
 [0.693]
 [0.693]
 [0.693]
 [0.724]
 [0.693]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.693]
 [0.812]
 [0.693]
 [0.693]
 [0.693]
 [0.724]
 [0.693]]
Printing some Q and Qe and total Qs values:  [[0.899]
 [0.894]
 [0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.809]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.899]
 [0.894]
 [0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.809]]
Printing some Q and Qe and total Qs values:  [[0.636]
 [0.78 ]
 [0.668]
 [0.706]
 [0.649]
 [0.646]
 [0.706]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.636]
 [0.78 ]
 [0.668]
 [0.706]
 [0.649]
 [0.646]
 [0.706]]
Printing some Q and Qe and total Qs values:  [[0.855]
 [0.899]
 [0.188]
 [0.855]
 [0.855]
 [0.855]
 [0.168]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.855]
 [0.899]
 [0.188]
 [0.855]
 [0.855]
 [0.855]
 [0.168]]
Printing some Q and Qe and total Qs values:  [[0.91 ]
 [0.952]
 [0.91 ]
 [0.901]
 [0.901]
 [0.901]
 [0.979]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.91 ]
 [0.952]
 [0.91 ]
 [0.901]
 [0.901]
 [0.901]
 [0.979]]
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1824799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1824799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.915]
 [0.996]
 [0.933]
 [0.915]
 [0.915]
 [0.915]
 [0.915]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.915]
 [0.996]
 [0.933]
 [0.915]
 [0.915]
 [0.915]
 [0.915]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18281999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18643999999999986 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18619999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18619999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.927]
 [0.816]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.875]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.927]
 [0.816]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.875]]
siam score:  -0.83668154
actor:  0 policy actor:  0  step number:  34 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1826399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1836199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.719]
 [0.774]
 [0.719]
 [0.719]
 [0.719]
 [0.719]
 [0.719]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.719]
 [0.774]
 [0.719]
 [0.719]
 [0.719]
 [0.719]
 [0.719]]
maxi score, test score, baseline:  0.18361999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.807]
 [0.91 ]
 [0.792]
 [0.792]
 [0.792]
 [0.792]
 [0.792]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.807]
 [0.91 ]
 [0.792]
 [0.792]
 [0.792]
 [0.792]
 [0.792]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1901999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.788]
 [0.788]
 [0.867]
 [0.7  ]
 [0.146]
 [0.788]
 [0.736]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.788]
 [0.788]
 [0.867]
 [0.7  ]
 [0.146]
 [0.788]
 [0.736]]
maxi score, test score, baseline:  0.18733999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18687999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.18687999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.815]
 [0.915]
 [0.846]
 [0.616]
 [0.846]
 [0.846]
 [0.172]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.815]
 [0.915]
 [0.846]
 [0.616]
 [0.846]
 [0.846]
 [0.172]]
maxi score, test score, baseline:  0.18687999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]]
maxi score, test score, baseline:  0.1869599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
siam score:  -0.8364748
maxi score, test score, baseline:  0.1869599999999998 0.6984999999999999 0.6984999999999999
Printing some Q and Qe and total Qs values:  [[0.761]
 [0.827]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.761]
 [0.827]
 [0.761]
 [0.761]
 [0.761]
 [0.761]
 [0.761]]
Printing some Q and Qe and total Qs values:  [[0.911]
 [0.821]
 [0.821]
 [0.821]
 [0.821]
 [0.821]
 [0.821]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.911]
 [0.821]
 [0.821]
 [0.821]
 [0.821]
 [0.821]
 [0.821]]
actor:  0 policy actor:  0  step number:  17 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1909199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1913799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1913799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1913799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1913799999999998 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.19713999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  42 total reward:  0.10999999999999943  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.19633999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.19301999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]]
maxi score, test score, baseline:  0.19301999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.953]
 [0.985]
 [0.953]
 [0.96 ]
 [0.929]
 [0.959]
 [0.953]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.953]
 [0.985]
 [0.953]
 [0.96 ]
 [0.929]
 [0.959]
 [0.953]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.19283999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.19607999999999984 0.6984999999999999 0.6984999999999999
Printing some Q and Qe and total Qs values:  [[0.801]
 [0.872]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.801]
 [0.872]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]]
maxi score, test score, baseline:  0.19607999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.19607999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.19597999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.19525999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.732]
 [0.72 ]
 [0.677]
 [0.732]
 [0.677]
 [0.676]
 [0.675]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.732]
 [0.72 ]
 [0.677]
 [0.732]
 [0.677]
 [0.676]
 [0.675]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.19537999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1943599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.757]
 [0.811]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.757]
 [0.811]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.19073999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.19073999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.881]
 [0.941]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.881]
 [0.941]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1871399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18321999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1798599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.215]
 [0.319]
 [0.249]
 [0.263]
 [0.249]
 [0.249]
 [0.246]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.215]
 [0.319]
 [0.249]
 [0.263]
 [0.249]
 [0.249]
 [0.246]]
maxi score, test score, baseline:  0.1798599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1764999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.991]
 [1.003]
 [1.005]
 [0.991]
 [0.991]
 [0.991]
 [0.991]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.991]
 [1.003]
 [1.005]
 [0.991]
 [0.991]
 [0.991]
 [0.991]]
maxi score, test score, baseline:  0.1764999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1753399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.552]
 [0.575]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.55 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.552]
 [0.575]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.55 ]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.693]
 [0.75 ]
 [0.693]
 [0.693]
 [0.693]
 [0.693]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.693]
 [0.693]
 [0.75 ]
 [0.693]
 [0.693]
 [0.693]
 [0.693]]
maxi score, test score, baseline:  0.17495999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17495999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17365999999999981 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.17365999999999981 0.6984999999999999 0.6984999999999999
probs:  [1.0]
siam score:  -0.82214963
maxi score, test score, baseline:  0.17365999999999981 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.17365999999999981 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.918]
 [0.979]
 [0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.918]
 [0.979]
 [0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]]
actor:  0 policy actor:  0  step number:  41 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.7  ]
 [0.529]
 [0.535]
 [0.531]
 [0.536]
 [0.589]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.541]
 [0.7  ]
 [0.529]
 [0.535]
 [0.531]
 [0.536]
 [0.589]]
Printing some Q and Qe and total Qs values:  [[0.719]
 [0.719]
 [0.92 ]
 [0.719]
 [0.719]
 [0.719]
 [0.719]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.719]
 [0.719]
 [0.92 ]
 [0.719]
 [0.719]
 [0.719]
 [0.719]]
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.781]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.601]
 [0.781]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]]
maxi score, test score, baseline:  0.1730599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1730599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1730599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.967]
 [0.991]
 [0.962]
 [0.971]
 [0.969]
 [0.974]
 [0.974]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.967]
 [0.991]
 [0.962]
 [0.971]
 [0.969]
 [0.974]
 [0.974]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17303999999999978 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  42 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.17249999999999982 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  26 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17279999999999981 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  41 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16941999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16941999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.988]
 [1.016]
 [0.988]
 [0.988]
 [0.988]
 [0.988]
 [1.01 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.988]
 [1.016]
 [0.988]
 [0.988]
 [0.988]
 [0.988]
 [1.01 ]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1727399999999998 0.6984999999999999 0.6984999999999999
siam score:  -0.82500273
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.833]
 [0.919]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.833]
 [0.919]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]]
maxi score, test score, baseline:  0.1695599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.636]
 [0.681]
 [0.636]
 [0.636]
 [0.636]
 [0.636]
 [0.636]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.636]
 [0.681]
 [0.636]
 [0.636]
 [0.636]
 [0.636]
 [0.636]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1666599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.82681364
actor:  0 policy actor:  0  step number:  33 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1672199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1676999999999998 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16437999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.915]
 [0.916]
 [0.889]
 [0.841]
 [0.905]
 [0.875]
 [0.929]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.915]
 [0.916]
 [0.889]
 [0.841]
 [0.905]
 [0.875]
 [0.929]]
siam score:  -0.82673407
maxi score, test score, baseline:  0.16401999999999983 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.16401999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.262]
 [0.304]
 [0.262]
 [0.262]
 [0.262]
 [0.262]
 [0.262]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.262]
 [0.304]
 [0.262]
 [0.262]
 [0.262]
 [0.262]
 [0.262]]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.292]
 [0.364]
 [0.292]
 [0.292]
 [0.292]
 [0.292]
 [0.292]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.292]
 [0.364]
 [0.292]
 [0.292]
 [0.292]
 [0.292]
 [0.292]]
maxi score, test score, baseline:  0.16463999999999981 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.675]
 [0.764]
 [0.687]
 [0.687]
 [0.686]
 [0.695]
 [0.687]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.675]
 [0.764]
 [0.687]
 [0.687]
 [0.686]
 [0.695]
 [0.687]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1645599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1645599999999998 0.6984999999999999 0.6984999999999999
Printing some Q and Qe and total Qs values:  [[0.828]
 [0.908]
 [0.823]
 [0.766]
 [0.642]
 [0.181]
 [0.264]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.828]
 [0.908]
 [0.823]
 [0.766]
 [0.642]
 [0.181]
 [0.264]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1654399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16293999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.994]
 [1.01 ]
 [1.009]
 [0.994]
 [0.994]
 [0.994]
 [0.994]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.994]
 [1.01 ]
 [1.009]
 [0.994]
 [0.994]
 [0.994]
 [0.994]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1656799999999998 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1662199999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1662199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1662199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.997]
 [1.   ]
 [0.999]
 [0.948]
 [0.948]
 [0.948]
 [1.   ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.997]
 [1.   ]
 [0.999]
 [0.948]
 [0.948]
 [0.948]
 [1.   ]]
Printing some Q and Qe and total Qs values:  [[0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]
 [0.81]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1661599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16333999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.16333999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16333999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16333999999999982 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.791]
 [0.867]
 [0.829]
 [0.634]
 [0.829]
 [0.829]
 [0.829]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.791]
 [0.867]
 [0.829]
 [0.634]
 [0.829]
 [0.829]
 [0.829]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16453999999999983 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.16453999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]]
actor:  0 policy actor:  0  step number:  36 total reward:  0.12999999999999945  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16391999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16397999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16397999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16397999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.16397999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
siam score:  -0.82757324
maxi score, test score, baseline:  0.16133999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16133999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.652]
 [0.737]
 [0.651]
 [0.658]
 [0.649]
 [0.665]
 [0.647]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.652]
 [0.737]
 [0.651]
 [0.658]
 [0.649]
 [0.665]
 [0.647]]
maxi score, test score, baseline:  0.16133999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15815999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1551799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.968]
 [1.024]
 [0.968]
 [0.968]
 [0.968]
 [0.968]
 [0.968]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.968]
 [1.024]
 [0.968]
 [0.968]
 [0.968]
 [0.968]
 [0.968]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15111999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1509999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14837999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.14837999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.14837999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.14837999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1485599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1485599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1450999999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1450999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.866]
 [0.866]
 [0.889]
 [0.866]
 [0.866]
 [0.866]
 [0.866]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.866]
 [0.866]
 [0.889]
 [0.866]
 [0.866]
 [0.866]
 [0.866]]
Printing some Q and Qe and total Qs values:  [[0.725]
 [0.831]
 [0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.725]
 [0.831]
 [0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1471799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1441799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1441799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1441799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14385999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  41 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14669999999999978 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1493599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14895999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1489199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1489199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1489199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1519799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1519799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.15177999999999983 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.15177999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1606399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1606399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16399999999999978 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.16399999999999978 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16399999999999978 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1638199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1638199999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1638199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1638199999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1609399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15855999999999978 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15855999999999978 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.15855999999999978 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15787999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.647]
 [0.793]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.647]
 [0.793]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15747999999999981 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1576199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
siam score:  -0.8239766
actor:  0 policy actor:  0  step number:  26 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.787]
 [0.828]
 [0.787]
 [0.787]
 [0.787]
 [0.787]
 [0.787]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.787]
 [0.828]
 [0.787]
 [0.787]
 [0.787]
 [0.787]
 [0.787]]
maxi score, test score, baseline:  0.15471999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15703999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15705999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
siam score:  -0.8202668
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.923]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.923]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8173389
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.802]
 [0.871]
 [0.802]
 [0.733]
 [0.802]
 [0.802]
 [0.802]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.802]
 [0.871]
 [0.802]
 [0.733]
 [0.802]
 [0.802]
 [0.802]]
maxi score, test score, baseline:  0.15625999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.15625999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1537599999999998 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1535199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1535199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.814]
 [0.875]
 [0.76 ]
 [0.755]
 [0.814]
 [0.814]
 [0.814]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.814]
 [0.875]
 [0.76 ]
 [0.755]
 [0.814]
 [0.814]
 [0.814]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.777]
 [0.83 ]
 [0.777]
 [0.797]
 [0.777]
 [0.777]
 [0.777]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.777]
 [0.83 ]
 [0.777]
 [0.797]
 [0.777]
 [0.777]
 [0.777]]
maxi score, test score, baseline:  0.15633999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8232144
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1535199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1502999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1502999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1563599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1600799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1631399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.041 0.51  0.041 0.061 0.061 0.224 0.061]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.79 ]
 [0.877]
 [0.79 ]
 [0.79 ]
 [0.764]
 [0.79 ]
 [0.79 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.79 ]
 [0.877]
 [0.79 ]
 [0.79 ]
 [0.764]
 [0.79 ]
 [0.79 ]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16319999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.988]
 [0.986]
 [0.988]
 [0.965]
 [0.96 ]
 [0.969]
 [0.987]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.988]
 [0.986]
 [0.988]
 [0.965]
 [0.96 ]
 [0.969]
 [0.987]]
maxi score, test score, baseline:  0.16319999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1625599999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1625599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1625599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15659999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.15659999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15997999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15997999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15969999999999984 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.15969999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1537999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.061 0.51  0.143 0.02  0.02  0.02  0.224]
actor:  0 policy actor:  0  step number:  35 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15311999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.072]
 [0.128]
 [0.072]
 [0.064]
 [0.072]
 [0.072]
 [0.099]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.072]
 [0.128]
 [0.072]
 [0.064]
 [0.072]
 [0.072]
 [0.099]]
maxi score, test score, baseline:  0.15251999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15251999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15251999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1496399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1496399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.785]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.785]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14623999999999981 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14669999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1435999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14063999999999985 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.866]
 [0.713]
 [0.758]
 [0.758]
 [0.758]
 [0.758]
 [0.758]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.866]
 [0.713]
 [0.758]
 [0.758]
 [0.758]
 [0.758]
 [0.758]]
maxi score, test score, baseline:  0.1400399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1431199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.827358
maxi score, test score, baseline:  0.14643999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.937]
 [0.931]
 [0.884]
 [0.909]
 [0.909]
 [0.909]
 [0.937]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.937]
 [0.931]
 [0.884]
 [0.909]
 [0.909]
 [0.909]
 [0.937]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
UNIT TEST: sample policy line 217 mcts : [0.02  0.    0.898 0.041 0.02  0.    0.02 ]
maxi score, test score, baseline:  0.14113999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1383799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.932]
 [0.898]
 [0.934]
 [0.854]
 [0.934]
 [0.934]
 [0.925]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.932]
 [0.898]
 [0.934]
 [0.854]
 [0.934]
 [0.934]
 [0.925]]
Printing some Q and Qe and total Qs values:  [[0.893]
 [0.931]
 [0.869]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.871]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.893]
 [0.931]
 [0.869]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.871]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.876]
 [0.876]
 [0.949]
 [0.876]
 [0.876]
 [0.876]
 [0.876]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.876]
 [0.876]
 [0.949]
 [0.876]
 [0.876]
 [0.876]
 [0.876]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.81586957
Printing some Q and Qe and total Qs values:  [[0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.801]
 [0.89 ]
 [0.832]
 [0.802]
 [0.832]
 [0.832]
 [0.832]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.801]
 [0.89 ]
 [0.832]
 [0.802]
 [0.832]
 [0.832]
 [0.832]]
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.087]
 [0.018]
 [0.018]
 [0.018]
 [0.018]
 [0.029]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.018]
 [0.087]
 [0.018]
 [0.018]
 [0.018]
 [0.018]
 [0.029]]
maxi score, test score, baseline:  0.1319999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.12925999999999982 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1292799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12601999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12371999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.555]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.427]
 [0.555]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [0.963]
 [0.892]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.881]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.88 ]
 [0.963]
 [0.892]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.881]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12731999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.747]
 [0.82 ]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.747]
 [0.82 ]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]]
maxi score, test score, baseline:  0.1272199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.744]
 [0.869]
 [0.744]
 [0.744]
 [0.744]
 [0.744]
 [0.739]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.744]
 [0.869]
 [0.744]
 [0.744]
 [0.744]
 [0.744]
 [0.739]]
maxi score, test score, baseline:  0.12711999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.832]
 [0.899]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.832]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.832]
 [0.899]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.832]]
maxi score, test score, baseline:  0.12711999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.12711999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.788]
 [0.921]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.896]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.788]
 [0.921]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [0.896]]
maxi score, test score, baseline:  0.12711999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12753999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1274199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1274199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1302999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1302999999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1302999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1302999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
siam score:  -0.8266754
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.132]
 [0.236]
 [0.132]
 [0.132]
 [0.132]
 [0.132]
 [0.132]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.132]
 [0.236]
 [0.132]
 [0.132]
 [0.132]
 [0.132]
 [0.132]]
Printing some Q and Qe and total Qs values:  [[0.747]
 [0.855]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.747]
 [0.855]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1307799999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1307799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13083999999999982 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  38 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13365999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.794]
 [0.794]
 [0.877]
 [0.794]
 [0.794]
 [0.794]
 [0.794]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.794]
 [0.794]
 [0.877]
 [0.794]
 [0.794]
 [0.794]
 [0.794]]
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1366799999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1366799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1366799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13969999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13983999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
siam score:  -0.821756
Printing some Q and Qe and total Qs values:  [[0.927]
 [0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.887]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.927]
 [0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.887]]
maxi score, test score, baseline:  0.14249999999999982 0.6984999999999999 0.6984999999999999
Printing some Q and Qe and total Qs values:  [[0.974]
 [0.979]
 [0.974]
 [0.974]
 [0.974]
 [0.974]
 [0.974]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.974]
 [0.979]
 [0.974]
 [0.974]
 [0.974]
 [0.974]
 [0.974]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14285999999999985 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14285999999999985 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14263999999999985 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1420199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1420199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  42 total reward:  0.08999999999999941  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14113999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.68]
 [0.68]
 [0.68]
 [0.68]
 [0.68]
 [0.68]
 [0.68]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.68]
 [0.68]
 [0.68]
 [0.68]
 [0.68]
 [0.68]
 [0.68]]
Printing some Q and Qe and total Qs values:  [[0.76 ]
 [0.812]
 [0.762]
 [0.787]
 [0.776]
 [0.751]
 [0.763]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.76 ]
 [0.812]
 [0.762]
 [0.787]
 [0.776]
 [0.751]
 [0.763]]
maxi score, test score, baseline:  0.14077999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14051999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14079999999999981 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14079999999999981 0.6984999999999999 0.6984999999999999
probs:  [1.0]
siam score:  -0.82567215
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14069999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14095999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14097999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1383799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1383799999999998 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.043]
 [0.088]
 [0.043]
 [0.043]
 [0.043]
 [0.043]
 [0.043]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.043]
 [0.088]
 [0.043]
 [0.043]
 [0.043]
 [0.043]
 [0.043]]
maxi score, test score, baseline:  0.13793999999999979 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1372399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.91 ]
 [0.907]
 [0.893]
 [0.893]
 [0.893]
 [0.893]
 [0.924]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.91 ]
 [0.907]
 [0.893]
 [0.893]
 [0.893]
 [0.893]
 [0.924]]
maxi score, test score, baseline:  0.13405999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.746]
 [0.828]
 [0.746]
 [0.746]
 [0.746]
 [0.746]
 [0.746]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.746]
 [0.828]
 [0.746]
 [0.746]
 [0.746]
 [0.746]
 [0.746]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13749999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1407199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.806]
 [0.802]
 [0.007]
 [0.754]
 [0.745]
 [0.772]
 [0.788]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.806]
 [0.802]
 [0.007]
 [0.754]
 [0.745]
 [0.772]
 [0.788]]
maxi score, test score, baseline:  0.14113999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14113999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14207999999999985 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14187999999999978 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.4875],
        [ 0.6697],
        [ 0.9306],
        [-0.0000],
        [ 0.6697],
        [ 0.8819],
        [ 0.8272],
        [ 0.8272],
        [ 0.8226],
        [ 0.5560]], dtype=torch.float64)
-0.048519850599000006 -0.5360453147688202
-0.087921850599 0.5818063471651945
-0.048519850599000006 0.8821235700515833
0.91139202 0.91139202
-0.068121850599 0.6016063471651946
-0.048519850599000006 0.8334300912135703
-0.08675157179700001 0.7404792848734874
-0.125759551797 0.7014713048734873
-0.048519850599000006 0.7740861010746807
-0.107327830599 0.44866599228673043
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.089]
 [0.089]
 [0.089]
 [0.089]
 [0.089]
 [0.089]
 [0.089]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.089]
 [0.089]
 [0.089]
 [0.089]
 [0.089]
 [0.089]
 [0.089]]
Printing some Q and Qe and total Qs values:  [[0.678]
 [0.754]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.678]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.678]
 [0.754]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.678]]
Printing some Q and Qe and total Qs values:  [[0.804]
 [0.878]
 [0.837]
 [0.837]
 [0.837]
 [0.837]
 [0.837]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.804]
 [0.878]
 [0.837]
 [0.837]
 [0.837]
 [0.837]
 [0.837]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1509799999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1509799999999998 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  34 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]]
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1514799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14815999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1455999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.807]
 [0.887]
 [0.805]
 [0.807]
 [0.807]
 [0.797]
 [0.807]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.807]
 [0.887]
 [0.805]
 [0.807]
 [0.807]
 [0.797]
 [0.807]]
maxi score, test score, baseline:  0.1455999999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1455999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1455999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
siam score:  -0.81787384
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14533999999999983 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.14533999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14533999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14533999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14457999999999985 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.974]
 [0.91 ]
 [0.91 ]
 [0.91 ]
 [0.91 ]
 [0.91 ]
 [0.91 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.974]
 [0.91 ]
 [0.91 ]
 [0.91 ]
 [0.91 ]
 [0.91 ]
 [0.91 ]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.1444199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1444199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1444199999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.952]
 [1.   ]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.952]
 [1.   ]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]]
maxi score, test score, baseline:  0.1469999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.922]
 [0.866]
 [0.843]
 [0.874]
 [0.843]
 [0.843]
 [0.871]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.922]
 [0.866]
 [0.843]
 [0.874]
 [0.843]
 [0.843]
 [0.871]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.694]
 [0.694]
 [0.694]
 [0.694]
 [0.694]
 [0.694]
 [0.694]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.694]
 [0.694]
 [0.694]
 [0.694]
 [0.694]
 [0.694]
 [0.694]]
Printing some Q and Qe and total Qs values:  [[0.685]
 [0.735]
 [0.685]
 [0.685]
 [0.685]
 [0.661]
 [0.661]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.685]
 [0.735]
 [0.685]
 [0.685]
 [0.685]
 [0.661]
 [0.661]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1396199999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.13961999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1400399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1400399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[1.007]
 [1.009]
 [0.844]
 [0.991]
 [0.991]
 [0.991]
 [1.01 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.007]
 [1.009]
 [0.844]
 [0.991]
 [0.991]
 [0.991]
 [1.01 ]]
actor:  0 policy actor:  0  step number:  38 total reward:  0.08999999999999941  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1397399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14277999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.864]
 [0.824]
 [0.863]
 [0.862]
 [0.871]
 [0.855]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.81 ]
 [0.864]
 [0.824]
 [0.863]
 [0.862]
 [0.871]
 [0.855]]
maxi score, test score, baseline:  0.14277999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.14277999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1399399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.052]
 [0.081]
 [0.044]
 [0.046]
 [0.057]
 [0.047]
 [0.057]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.052]
 [0.081]
 [0.044]
 [0.046]
 [0.057]
 [0.047]
 [0.057]]
maxi score, test score, baseline:  0.1370799999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1370799999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1370799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1370799999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13971999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.13971999999999982 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.81773776
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.732]
 [0.809]
 [0.747]
 [0.744]
 [0.746]
 [0.746]
 [0.743]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.732]
 [0.809]
 [0.747]
 [0.744]
 [0.746]
 [0.746]
 [0.743]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8173638
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14263999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.14263999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14263999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.14263999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14263999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1447399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1447399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.869]
 [0.896]
 [0.869]
 [0.869]
 [0.869]
 [0.869]
 [0.869]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.869]
 [0.896]
 [0.869]
 [0.869]
 [0.869]
 [0.869]
 [0.869]]
maxi score, test score, baseline:  0.1447399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1442599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14773999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.075]
 [0.087]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.089]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.075]
 [0.087]
 [0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.089]]
maxi score, test score, baseline:  0.14773999999999984 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.14807999999999982 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15095999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.82060397
maxi score, test score, baseline:  0.1510599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1510599999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15115999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1489999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.719]
 [0.827]
 [0.719]
 [0.719]
 [0.719]
 [0.719]
 [0.719]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.719]
 [0.827]
 [0.719]
 [0.719]
 [0.719]
 [0.719]
 [0.719]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1460399999999998 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1458999999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1458999999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.696]
 [0.791]
 [0.696]
 [0.696]
 [0.696]
 [0.696]
 [0.696]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.696]
 [0.791]
 [0.696]
 [0.696]
 [0.696]
 [0.696]
 [0.696]]
Printing some Q and Qe and total Qs values:  [[0.836]
 [0.861]
 [0.836]
 [0.816]
 [0.836]
 [0.836]
 [0.821]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.836]
 [0.861]
 [0.836]
 [0.816]
 [0.836]
 [0.836]
 [0.821]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14551999999999984 0.6984999999999999 0.6984999999999999
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14515999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.041]
 [0.024]
 [0.053]
 [0.053]
 [0.052]
 [0.045]
 [0.049]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.041]
 [0.024]
 [0.053]
 [0.053]
 [0.052]
 [0.045]
 [0.049]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]]
maxi score, test score, baseline:  0.1510399999999998 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.1510399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1448399999999998 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14473999999999984 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14777999999999983 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Starting evaluation
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.059]
 [0.097]
 [0.059]
 [0.059]
 [0.059]
 [0.059]
 [0.07 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.059]
 [0.097]
 [0.059]
 [0.059]
 [0.059]
 [0.059]
 [0.07 ]]
siam score:  -0.810912
Printing some Q and Qe and total Qs values:  [[0.998]
 [0.951]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.998]
 [0.951]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14723999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.14723999999999982 0.6984999999999999 0.6984999999999999
maxi score, test score, baseline:  0.14723999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.82 ]
 [0.887]
 [0.82 ]
 [0.77 ]
 [0.82 ]
 [0.264]
 [0.307]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.82 ]
 [0.887]
 [0.82 ]
 [0.77 ]
 [0.82 ]
 [0.264]
 [0.307]]
maxi score, test score, baseline:  0.14723999999999982 0.6984999999999999 0.6984999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  16 total reward:  0.75  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.7699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.7699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16655999999999982 0.7169999999999999 0.7169999999999999
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  31 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16647999999999982 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16597999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16885999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1685999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16297999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.042]
 [0.091]
 [0.042]
 [0.042]
 [0.042]
 [0.042]
 [0.042]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.042]
 [0.091]
 [0.042]
 [0.042]
 [0.042]
 [0.042]
 [0.042]]
maxi score, test score, baseline:  0.16297999999999982 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16249999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16247999999999982 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.16247999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1629399999999998 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  25 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1637199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  43 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16071999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.698]
 [0.862]
 [0.679]
 [0.681]
 [0.68 ]
 [0.678]
 [0.677]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.698]
 [0.862]
 [0.679]
 [0.681]
 [0.68 ]
 [0.678]
 [0.677]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17011999999999983 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.17011999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8146898
maxi score, test score, baseline:  0.17311999999999986 0.7169999999999999 0.7169999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.17311999999999986 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17583999999999983 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1754799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17249999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1722399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17283999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17607999999999985 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.701]
 [0.847]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.701]
 [0.847]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]]
maxi score, test score, baseline:  0.17651999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1730599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.669]
 [0.7  ]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.669]
 [0.7  ]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17169999999999985 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.745]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.631]
 [0.745]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1700599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16613999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.885]
 [0.897]
 [0.867]
 [0.867]
 [0.867]
 [0.867]
 [0.964]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.885]
 [0.897]
 [0.867]
 [0.867]
 [0.867]
 [0.867]
 [0.964]]
maxi score, test score, baseline:  0.16613999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.943]
 [0.965]
 [0.941]
 [0.95 ]
 [0.952]
 [0.942]
 [0.953]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.943]
 [0.965]
 [0.941]
 [0.95 ]
 [0.952]
 [0.942]
 [0.953]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1618399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1618399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1618399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1583999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15809999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1547399999999998 0.7169999999999999 0.7169999999999999
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.1547399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1547399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15475999999999981 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.15475999999999981 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.887]
 [0.954]
 [0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.897]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.887]
 [0.954]
 [0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.897]]
maxi score, test score, baseline:  0.15393999999999983 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15075999999999984 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1503999999999998 0.7169999999999999 0.7169999999999999
siam score:  -0.8182831
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15093999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15077999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.221]
 [0.397]
 [0.221]
 [0.221]
 [0.221]
 [0.221]
 [0.221]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.221]
 [0.397]
 [0.221]
 [0.221]
 [0.221]
 [0.221]
 [0.221]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15107999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15431999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8168219
maxi score, test score, baseline:  0.1514999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15027999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15027999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14417999999999984 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.14417999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.1899999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14389999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14083999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14083999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14419999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.3999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14355999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1466399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14571999999999982 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14537999999999981 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.14537999999999981 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14537999999999981 0.7169999999999999 0.7169999999999999
probs:  [1.0]
siam score:  -0.8176429
actor:  0 policy actor:  0  step number:  37 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.983]
 [1.002]
 [1.005]
 [0.983]
 [0.983]
 [0.983]
 [1.005]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.983]
 [1.002]
 [1.005]
 [0.983]
 [0.983]
 [0.983]
 [1.005]]
siam score:  -0.81720614
maxi score, test score, baseline:  0.14465999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14525999999999978 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14525999999999978 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.7  ]
 [0.792]
 [0.696]
 [0.667]
 [0.667]
 [0.697]
 [0.698]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.7  ]
 [0.792]
 [0.696]
 [0.667]
 [0.667]
 [0.697]
 [0.698]]
maxi score, test score, baseline:  0.1430399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1430399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14271999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14283999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14283999999999983 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.14283999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14279999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]]
maxi score, test score, baseline:  0.13991999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.833]
 [0.928]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.833]
 [0.928]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]]
maxi score, test score, baseline:  0.13991999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1366799999999998 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.1366799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13749999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13749999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.986]
 [0.965]
 [0.974]
 [0.974]
 [0.974]
 [0.974]
 [0.964]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.986]
 [0.965]
 [0.974]
 [0.974]
 [0.974]
 [0.974]
 [0.964]]
maxi score, test score, baseline:  0.13749999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1377999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.09999999999999942  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13417999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8104986
maxi score, test score, baseline:  0.13367999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13599999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13599999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13933999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13955999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1393199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13349999999999979 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13349999999999979 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13103999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13119999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13169999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1317399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.12859999999999983 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12865999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.726]
 [0.726]
 [0.717]
 [0.726]
 [0.726]
 [0.726]
 [0.726]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.726]
 [0.726]
 [0.717]
 [0.726]
 [0.726]
 [0.726]
 [0.726]]
maxi score, test score, baseline:  0.1289199999999998 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.1289199999999998 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.1289199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1320199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1323599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
siam score:  -0.81323624
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13243999999999978 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.918]
 [0.726]
 [0.922]
 [0.905]
 [0.918]
 [0.886]
 [0.944]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.918]
 [0.726]
 [0.922]
 [0.905]
 [0.918]
 [0.886]
 [0.944]]
maxi score, test score, baseline:  0.13243999999999978 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1350599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1350599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1315599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1315599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1315599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1315599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13403999999999983 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13375999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1369599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1372799999999998 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1403799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1403799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13727999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  39 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13991999999999982 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.13991999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13721999999999981 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.13721999999999981 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.13721999999999981 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13727999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]]
maxi score, test score, baseline:  0.14083999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14083999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14091999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.62 ]
 [0.675]
 [0.626]
 [0.628]
 [0.625]
 [0.625]
 [0.624]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.62 ]
 [0.675]
 [0.626]
 [0.628]
 [0.625]
 [0.625]
 [0.624]]
maxi score, test score, baseline:  0.14083999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.465]
 [0.581]
 [0.465]
 [0.472]
 [0.465]
 [0.465]
 [0.478]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.465]
 [0.581]
 [0.465]
 [0.472]
 [0.465]
 [0.465]
 [0.478]]
Printing some Q and Qe and total Qs values:  [[ 0.741]
 [ 0.182]
 [ 0.814]
 [ 0.741]
 [ 0.741]
 [-0.004]
 [ 0.606]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.741]
 [ 0.182]
 [ 0.814]
 [ 0.741]
 [ 0.741]
 [-0.004]
 [ 0.606]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1411599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1410999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.988]
 [0.99 ]
 [0.99 ]
 [0.989]
 [0.956]
 [0.965]
 [0.99 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.988]
 [0.99 ]
 [0.99 ]
 [0.989]
 [0.956]
 [0.965]
 [0.99 ]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14095999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14095999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.118]
 [0.249]
 [0.118]
 [0.118]
 [0.118]
 [0.118]
 [0.118]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.118]
 [0.249]
 [0.118]
 [0.118]
 [0.118]
 [0.118]
 [0.118]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14673999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14673999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1471399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1471399999999998 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.1471399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.886]
 [0.879]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.886]
 [0.879]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]]
maxi score, test score, baseline:  0.1471399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14751999999999985 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14749999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14749999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.848]
 [0.918]
 [0.864]
 [0.861]
 [0.856]
 [0.855]
 [0.896]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.848]
 [0.918]
 [0.864]
 [0.861]
 [0.856]
 [0.855]
 [0.896]]
maxi score, test score, baseline:  0.14749999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14743999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14783999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.14783999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
siam score:  -0.8140062
maxi score, test score, baseline:  0.14783999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.805]
 [0.805]
 [0.895]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.805]
 [0.805]
 [0.895]
 [0.805]
 [0.805]
 [0.805]
 [0.805]]
Printing some Q and Qe and total Qs values:  [[0.736]
 [0.78 ]
 [0.736]
 [0.736]
 [0.736]
 [0.736]
 [0.736]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.736]
 [0.78 ]
 [0.736]
 [0.736]
 [0.736]
 [0.736]
 [0.736]]
maxi score, test score, baseline:  0.14795999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1536799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.94 ]
 [1.   ]
 [0.94 ]
 [0.94 ]
 [0.973]
 [0.963]
 [0.94 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.94 ]
 [1.   ]
 [0.94 ]
 [0.94 ]
 [0.973]
 [0.963]
 [0.94 ]]
maxi score, test score, baseline:  0.15143999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
UNIT TEST: sample policy line 217 mcts : [0.    0.    0.571 0.102 0.02  0.286 0.02 ]
Printing some Q and Qe and total Qs values:  [[0.759]
 [0.759]
 [0.828]
 [0.759]
 [0.759]
 [0.759]
 [0.759]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.759]
 [0.759]
 [0.828]
 [0.759]
 [0.759]
 [0.759]
 [0.759]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15415999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15431999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.669]
 [0.666]
 [0.714]
 [0.71 ]
 [0.144]
 [0.71 ]
 [0.71 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.669]
 [0.666]
 [0.714]
 [0.71 ]
 [0.144]
 [0.71 ]
 [0.71 ]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15675999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
siam score:  -0.81588876
actor:  0 policy actor:  0  step number:  21 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15745999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16075999999999985 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16075999999999985 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.16075999999999985 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15801999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.706]
 [0.905]
 [0.706]
 [0.706]
 [0.706]
 [0.706]
 [0.706]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.706]
 [0.905]
 [0.706]
 [0.706]
 [0.706]
 [0.706]
 [0.706]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.673]
 [0.762]
 [0.704]
 [0.69 ]
 [0.755]
 [0.755]
 [0.689]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.673]
 [0.762]
 [0.704]
 [0.69 ]
 [0.755]
 [0.755]
 [0.689]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15999999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16279999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16279999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15995999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15905999999999978 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15905999999999978 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1587999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15925999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.842]
 [0.886]
 [0.842]
 [0.814]
 [0.842]
 [0.842]
 [0.842]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.842]
 [0.886]
 [0.842]
 [0.814]
 [0.842]
 [0.842]
 [0.842]]
actor:  0 policy actor:  0  step number:  37 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15613999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15613999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1567399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15387999999999985 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  36 total reward:  0.14999999999999947  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.821]
 [0.906]
 [0.821]
 [0.821]
 [0.821]
 [0.821]
 [0.821]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.821]
 [0.906]
 [0.821]
 [0.821]
 [0.821]
 [0.821]
 [0.821]]
maxi score, test score, baseline:  0.1561799999999998 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1592999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15903999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.243]
 [0.359]
 [0.243]
 [0.243]
 [0.243]
 [0.243]
 [0.243]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.243]
 [0.359]
 [0.243]
 [0.243]
 [0.243]
 [0.243]
 [0.243]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16203999999999982 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  21 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1625799999999998 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.1625799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.75  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16253999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.004]
 [0.489]
 [1.004]
 [1.004]
 [1.004]
 [1.004]
 [1.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.004]
 [0.489]
 [1.004]
 [1.004]
 [1.004]
 [1.004]
 [1.004]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.676]]
maxi score, test score, baseline:  0.1632999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1632999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16349999999999978 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16357999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16357999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16357999999999984 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.16357999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16357999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16453999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1613999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1613999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16437999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16437999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16437999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.632]
 [0.767]
 [0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.632]
 [0.767]
 [0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.789]
 [0.789]
 [0.86 ]
 [0.789]
 [0.789]
 [0.789]
 [0.789]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.789]
 [0.789]
 [0.86 ]
 [0.789]
 [0.789]
 [0.789]
 [0.789]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17063999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.84 ]
 [0.725]
 [0.727]
 [0.728]
 [0.727]
 [0.725]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.722]
 [0.84 ]
 [0.725]
 [0.727]
 [0.728]
 [0.727]
 [0.725]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1714999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.678]
 [0.623]
 [0.621]
 [0.621]
 [0.62 ]
 [0.62 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.616]
 [0.678]
 [0.623]
 [0.621]
 [0.621]
 [0.62 ]
 [0.62 ]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17479999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.005]
 [1.005]
 [1.005]
 [0.973]
 [0.973]
 [1.005]
 [1.005]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.005]
 [1.005]
 [1.005]
 [0.973]
 [0.973]
 [1.005]
 [1.005]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1772599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1772599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1772599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1772599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17435999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1775399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1804399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.17465999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17465999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17489999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.916]
 [0.957]
 [0.934]
 [0.914]
 [0.926]
 [0.922]
 [0.938]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.916]
 [0.957]
 [0.934]
 [0.914]
 [0.926]
 [0.922]
 [0.938]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  40 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1742399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]]
maxi score, test score, baseline:  0.1742399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1741599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1686199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1686199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1689999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.845]
 [0.924]
 [0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.845]
 [0.924]
 [0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]]
siam score:  -0.80149376
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1690999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.1690999999999998 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.1690999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.817]
 [0.817]
 [0.903]
 [0.817]
 [0.817]
 [0.817]
 [0.817]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.817]
 [0.817]
 [0.903]
 [0.817]
 [0.817]
 [0.817]
 [0.817]]
maxi score, test score, baseline:  0.1693799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.17013999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1759199999999998 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.1759199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17563999999999985 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  29 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17577999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17577999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.962]
 [0.989]
 [0.96 ]
 [0.952]
 [0.959]
 [0.964]
 [0.951]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.962]
 [0.989]
 [0.96 ]
 [0.952]
 [0.959]
 [0.964]
 [0.951]]
maxi score, test score, baseline:  0.17577999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  43 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1777599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8156662
maxi score, test score, baseline:  0.17413999999999985 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17155999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.857]
 [0.987]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.934]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.857]
 [0.987]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.934]]
maxi score, test score, baseline:  0.1715999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.76]
 [0.76]
 [0.88]
 [0.76]
 [0.76]
 [0.76]
 [0.76]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.76]
 [0.76]
 [0.88]
 [0.76]
 [0.76]
 [0.76]
 [0.76]]
maxi score, test score, baseline:  0.16831999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16793999999999978 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.844]
 [0.876]
 [0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.844]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.844]
 [0.876]
 [0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.844]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.653]
 [0.793]
 [0.657]
 [0.742]
 [0.657]
 [0.661]
 [0.657]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.653]
 [0.793]
 [0.657]
 [0.742]
 [0.657]
 [0.661]
 [0.657]]
Printing some Q and Qe and total Qs values:  [[0.833]
 [0.751]
 [0.735]
 [0.732]
 [0.735]
 [0.735]
 [0.714]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.833]
 [0.751]
 [0.735]
 [0.732]
 [0.735]
 [0.735]
 [0.714]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16831999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16827999999999982 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.16827999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16827999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.916]
 [0.937]
 [0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.96 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.916]
 [0.937]
 [0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.96 ]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.17071999999999982 0.7169999999999999 0.7169999999999999
Printing some Q and Qe and total Qs values:  [[0.875]
 [0.875]
 [0.954]
 [0.875]
 [0.875]
 [0.875]
 [0.875]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.875]
 [0.875]
 [0.954]
 [0.875]
 [0.875]
 [0.875]
 [0.875]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17665999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3899999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1701799999999998 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  32 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]]
maxi score, test score, baseline:  0.1677199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17089999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.17089999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.907]
 [0.976]
 [0.912]
 [0.854]
 [0.907]
 [0.863]
 [0.93 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.907]
 [0.976]
 [0.912]
 [0.854]
 [0.907]
 [0.863]
 [0.93 ]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
siam score:  -0.80659926
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1743999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.61 ]
 [0.61 ]
 [0.778]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.61 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.61 ]
 [0.61 ]
 [0.778]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.61 ]]
maxi score, test score, baseline:  0.1775399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1775399999999998 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.1775399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1769199999999998 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  24 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1769199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[-0.001]
 [ 0.187]
 [ 0.093]
 [ 0.081]
 [ 0.093]
 [ 0.093]
 [ 0.128]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.001]
 [ 0.187]
 [ 0.093]
 [ 0.081]
 [ 0.093]
 [ 0.093]
 [ 0.128]]
maxi score, test score, baseline:  0.1769199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1769199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1736999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1740599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.547]
 [0.613]
 [0.185]
 [0.597]
 [0.548]
 [0.554]
 [0.595]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.547]
 [0.613]
 [0.185]
 [0.597]
 [0.548]
 [0.554]
 [0.595]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16791999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.16215999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16187999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.626]
 [0.759]
 [0.642]
 [0.577]
 [0.585]
 [0.593]
 [0.61 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.626]
 [0.759]
 [0.642]
 [0.577]
 [0.585]
 [0.593]
 [0.61 ]]
maxi score, test score, baseline:  0.16169999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
UNIT TEST: sample policy line 217 mcts : [0.776 0.02  0.02  0.02  0.02  0.    0.143]
maxi score, test score, baseline:  0.1617799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1617799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8025319
Printing some Q and Qe and total Qs values:  [[0.908]
 [0.881]
 [0.876]
 [0.827]
 [0.794]
 [0.876]
 [0.807]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.908]
 [0.881]
 [0.876]
 [0.827]
 [0.794]
 [0.876]
 [0.807]]
actor:  0 policy actor:  0  step number:  35 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.224]
 [0.248]
 [0.224]
 [0.259]
 [0.224]
 [0.224]
 [0.256]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.224]
 [0.248]
 [0.224]
 [0.259]
 [0.224]
 [0.224]
 [0.256]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.447]
 [0.469]
 [0.447]
 [0.447]
 [0.447]
 [0.447]
 [0.447]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.447]
 [0.469]
 [0.447]
 [0.447]
 [0.447]
 [0.447]
 [0.447]]
maxi score, test score, baseline:  0.16203999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
siam score:  -0.8000639
actor:  0 policy actor:  0  step number:  19 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1627199999999998 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1658599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1660799999999998 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.894]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.894]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16617999999999983 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.16617999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16663999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16663999999999984 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.16663999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.884]
 [0.843]
 [0.843]
 [0.843]
 [0.843]
 [0.843]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.703]
 [0.884]
 [0.843]
 [0.843]
 [0.843]
 [0.843]
 [0.843]]
Printing some Q and Qe and total Qs values:  [[0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1668199999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16497999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16497999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16527999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16527999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16527999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16517999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16469999999999985 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16469999999999985 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.16469999999999985 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1683999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1683999999999998 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.1683999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.061 0.388 0.245 0.061 0.143 0.041 0.061]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1658599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1689799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.122]
 [0.225]
 [0.122]
 [0.122]
 [0.122]
 [0.122]
 [0.122]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.122]
 [0.225]
 [0.122]
 [0.122]
 [0.122]
 [0.122]
 [0.122]]
maxi score, test score, baseline:  0.15919999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.1559999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1564999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1564999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15425999999999981 0.7169999999999999 0.7169999999999999
siam score:  -0.8031982
maxi score, test score, baseline:  0.15425999999999981 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.80696577
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15409999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15063999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1537999999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1512599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1510399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1510399999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15109999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15403999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.497]
 [0.497]
 [0.165]
 [0.165]
 [0.165]
 [0.165]
 [0.165]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.497]
 [0.497]
 [0.165]
 [0.165]
 [0.165]
 [0.165]
 [0.165]]
Printing some Q and Qe and total Qs values:  [[0.744]
 [0.891]
 [0.744]
 [0.744]
 [0.744]
 [0.744]
 [0.744]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.744]
 [0.891]
 [0.744]
 [0.744]
 [0.744]
 [0.744]
 [0.744]]
Printing some Q and Qe and total Qs values:  [[0.702]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.702]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]]
maxi score, test score, baseline:  0.15111999999999984 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15465999999999983 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.15465999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15495999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15495999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15477999999999983 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.15477999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15501999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.15501999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15453999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1605799999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15759999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15759999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1578599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.1578599999999998 0.7169999999999999 0.7169999999999999
probs:  [1.0]
siam score:  -0.8050523
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15745999999999982 0.7169999999999999 0.7169999999999999
probs:  [1.0]
maxi score, test score, baseline:  0.15745999999999982 0.7169999999999999 0.7169999999999999
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15779999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Starting evaluation
maxi score, test score, baseline:  0.15779999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.15779999999999983 0.7169999999999999 0.7169999999999999
maxi score, test score, baseline:  0.15779999999999983 0.7169999999999999 0.7169999999999999
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.923]
 [0.92 ]
 [0.894]
 [0.888]
 [0.894]
 [0.407]
 [0.891]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.923]
 [0.92 ]
 [0.894]
 [0.888]
 [0.894]
 [0.407]
 [0.891]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1875799999999998 0.6815 0.6815
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.18779999999999983 0.6815 0.6815
maxi score, test score, baseline:  0.18779999999999983 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.18779999999999983 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.18779999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18201999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.17909999999999981 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.664]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.617]
 [0.664]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]]
maxi score, test score, baseline:  0.1759799999999998 0.6815 0.6815
maxi score, test score, baseline:  0.1759799999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1759799999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1759799999999998 0.6815 0.6815
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17613999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18163999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.18453999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17789999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.17789999999999984 0.6815 0.6815
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1750399999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17543999999999985 0.6815 0.6815
actor:  0 policy actor:  0  step number:  18 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17885999999999982 0.6815 0.6815
maxi score, test score, baseline:  0.17885999999999982 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.79 ]
 [0.895]
 [0.821]
 [0.702]
 [0.821]
 [0.821]
 [0.198]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.79 ]
 [0.895]
 [0.821]
 [0.702]
 [0.821]
 [0.821]
 [0.198]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.774]
 [0.774]
 [0.875]
 [0.774]
 [0.774]
 [0.774]
 [0.774]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.774]
 [0.774]
 [0.875]
 [0.774]
 [0.774]
 [0.774]
 [0.774]]
maxi score, test score, baseline:  0.17959999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.17959999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17961999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.17961999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.045]
 [0.194]
 [0.039]
 [0.023]
 [0.022]
 [0.039]
 [0.066]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.045]
 [0.194]
 [0.039]
 [0.023]
 [0.022]
 [0.039]
 [0.066]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.17507999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.3099999999999997  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16705999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16319999999999985 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.898]
 [0.907]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.96 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.898]
 [0.907]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.96 ]]
actor:  0 policy actor:  0  step number:  30 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15953999999999982 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.694]
 [0.73 ]
 [0.663]
 [0.688]
 [0.686]
 [0.684]
 [0.689]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.694]
 [0.73 ]
 [0.663]
 [0.688]
 [0.686]
 [0.684]
 [0.689]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15189999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15189999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8113336
Printing some Q and Qe and total Qs values:  [[0.904]
 [0.951]
 [0.897]
 [0.904]
 [0.904]
 [0.904]
 [0.908]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.904]
 [0.951]
 [0.897]
 [0.904]
 [0.904]
 [0.904]
 [0.908]]
Printing some Q and Qe and total Qs values:  [[0.994]
 [0.994]
 [0.994]
 [0.994]
 [0.994]
 [0.994]
 [0.994]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.994]
 [0.994]
 [0.994]
 [0.994]
 [0.994]
 [0.994]
 [0.994]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14931999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14955999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  41 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1517599999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1517599999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1517599999999998 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.914]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.914]]
maxi score, test score, baseline:  0.1517599999999998 0.6815 0.6815
probs:  [1.0]
siam score:  -0.8067456
maxi score, test score, baseline:  0.1517599999999998 0.6815 0.6815
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15487999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15487999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15793999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16113999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.16113999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16095999999999983 0.6815 0.6815
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.731]
 [0.831]
 [0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.731]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.731]
 [0.831]
 [0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.731]]
maxi score, test score, baseline:  0.15457999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.069]
 [0.006]
 [0.004]
 [0.005]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.   ]
 [0.069]
 [0.006]
 [0.004]
 [0.005]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  0.1520199999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.968]
 [1.001]
 [0.968]
 [0.968]
 [0.968]
 [0.968]
 [0.968]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.968]
 [1.001]
 [0.968]
 [0.968]
 [0.968]
 [0.968]
 [0.968]]
maxi score, test score, baseline:  0.1524199999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1524199999999998 0.6815 0.6815
actor:  0 policy actor:  0  step number:  27 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14881999999999984 0.6815 0.6815
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.634]
 [0.659]
 [0.644]
 [0.644]
 [0.644]
 [0.651]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.644]
 [0.634]
 [0.659]
 [0.644]
 [0.644]
 [0.644]
 [0.651]]
Printing some Q and Qe and total Qs values:  [[-0.004]
 [ 0.057]
 [ 0.865]
 [ 0.808]
 [ 0.808]
 [ 0.808]
 [ 0.68 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[-0.004]
 [ 0.057]
 [ 0.865]
 [ 0.808]
 [ 0.808]
 [ 0.808]
 [ 0.68 ]]
maxi score, test score, baseline:  0.14881999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14907999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.691]
 [0.808]
 [0.691]
 [0.691]
 [0.691]
 [0.691]
 [0.691]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.691]
 [0.808]
 [0.691]
 [0.691]
 [0.691]
 [0.691]
 [0.691]]
maxi score, test score, baseline:  0.14957999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15295999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.922]
 [0.841]
 [0.841]
 [0.841]
 [0.721]
 [0.841]
 [0.841]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.922]
 [0.841]
 [0.841]
 [0.841]
 [0.721]
 [0.841]
 [0.841]]
maxi score, test score, baseline:  0.14921999999999983 0.6815 0.6815
maxi score, test score, baseline:  0.14921999999999983 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.745]
 [0.613]
 [0.615]
 [0.639]
 [0.614]
 [0.613]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.617]
 [0.745]
 [0.613]
 [0.615]
 [0.639]
 [0.614]
 [0.613]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14677999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1469199999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1469199999999998 0.6815 0.6815
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14649999999999985 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.13993999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.13993999999999984 0.6815 0.6815
actor:  0 policy actor:  0  step number:  27 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14317999999999984 0.6815 0.6815
probs:  [1.0]
UNIT TEST: sample policy line 217 mcts : [0.02  0.49  0.02  0.02  0.041 0.041 0.367]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14057999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1408199999999998 0.6815 0.6815
maxi score, test score, baseline:  0.1408199999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13807999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14137999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.76 ]
 [0.722]
 [0.713]
 [0.722]
 [0.722]
 [0.722]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.722]
 [0.76 ]
 [0.722]
 [0.713]
 [0.722]
 [0.722]
 [0.722]]
maxi score, test score, baseline:  0.14185999999999985 0.6815 0.6815
Printing some Q and Qe and total Qs values:  [[0.715]
 [0.804]
 [0.701]
 [0.714]
 [0.715]
 [0.709]
 [0.716]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.715]
 [0.804]
 [0.701]
 [0.714]
 [0.715]
 [0.709]
 [0.716]]
siam score:  -0.81002426
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8093614
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14151999999999984 0.6815 0.6815
Printing some Q and Qe and total Qs values:  [[0.768]
 [0.839]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.768]
 [0.839]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]]
maxi score, test score, baseline:  0.14151999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13867999999999983 0.6815 0.6815
maxi score, test score, baseline:  0.13573999999999983 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.13573999999999983 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.13573999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13853999999999986 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.776]
 [0.824]
 [0.776]
 [0.776]
 [0.776]
 [0.776]
 [0.776]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.776]
 [0.824]
 [0.776]
 [0.776]
 [0.776]
 [0.776]
 [0.776]]
maxi score, test score, baseline:  0.13847999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13805999999999982 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.797]
 [0.797]
 [0.863]
 [0.797]
 [0.797]
 [0.797]
 [0.797]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.797]
 [0.797]
 [0.863]
 [0.797]
 [0.797]
 [0.797]
 [0.797]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[0.6776],
        [0.3972],
        [0.0000],
        [0.0000],
        [0.6625],
        [0.0000],
        [0.0000],
        [0.6625],
        [0.7749],
        [0.3972]], dtype=torch.float64)
-0.048519850599000006 0.6291237099070524
-0.145559551797 0.2516445113423921
-0.77653422 -0.77653422
-0.9306 -0.9306
-0.087921850599 0.5746130062186445
-0.7306390773 -0.7306390773
0.91139202 0.91139202
-0.087921850599 0.5746130062186445
-0.048519850599000006 0.7263587501632105
-0.145559551797 0.2516445113423921
Printing some Q and Qe and total Qs values:  [[0.556]
 [0.616]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.556]
 [0.616]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]]
maxi score, test score, baseline:  0.1352199999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13783999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.13783999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.13783999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.912]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.912]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13707999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1398799999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.334]
 [0.337]
 [0.305]
 [0.339]
 [0.307]
 [0.305]
 [0.372]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.334]
 [0.337]
 [0.305]
 [0.339]
 [0.307]
 [0.305]
 [0.372]]
maxi score, test score, baseline:  0.13977999999999982 0.6815 0.6815
probs:  [1.0]
siam score:  -0.8088635
actor:  0 policy actor:  0  step number:  30 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13989999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14063999999999982 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.398]
 [0.431]
 [0.419]
 [0.421]
 [0.418]
 [0.416]
 [0.418]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.398]
 [0.431]
 [0.419]
 [0.421]
 [0.418]
 [0.416]
 [0.418]]
maxi score, test score, baseline:  0.14063999999999982 0.6815 0.6815
maxi score, test score, baseline:  0.14063999999999982 0.6815 0.6815
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14057999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14351999999999984 0.6815 0.6815
maxi score, test score, baseline:  0.1402599999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.127]
 [0.131]
 [0.127]
 [0.127]
 [0.127]
 [0.127]
 [0.127]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.127]
 [0.131]
 [0.127]
 [0.127]
 [0.127]
 [0.127]
 [0.127]]
maxi score, test score, baseline:  0.1403799999999998 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.774]
 [0.796]
 [0.79 ]
 [0.79 ]
 [0.774]
 [0.777]
 [0.865]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.774]
 [0.796]
 [0.79 ]
 [0.79 ]
 [0.774]
 [0.777]
 [0.865]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14355999999999983 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.701]
 [0.731]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.701]
 [0.731]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1434799999999998 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.747]
 [0.619]
 [0.619]
 [0.625]
 [0.719]
 [0.619]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.631]
 [0.747]
 [0.619]
 [0.619]
 [0.625]
 [0.719]
 [0.619]]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1489799999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14877999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.036]
 [0.036]
 [0.036]
 [0.036]
 [0.036]
 [0.036]
 [0.036]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.036]
 [0.036]
 [0.036]
 [0.036]
 [0.036]
 [0.036]
 [0.036]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.933]
 [0.978]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.933]
 [0.978]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15115999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14835999999999983 0.6815 0.6815
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.747]
 [0.822]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.747]
 [0.822]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]]
maxi score, test score, baseline:  0.14855999999999983 0.6815 0.6815
maxi score, test score, baseline:  0.14855999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14909999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14909999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.868]
 [0.883]
 [0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.868]
 [0.883]
 [0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14699999999999985 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14699999999999985 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14699999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14675999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14675999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14957999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14913999999999983 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.659]
 [0.739]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.659]
 [0.739]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.898]
 [0.895]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.898]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.898]
 [0.895]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.898]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.396]
 [0.722]
 [0.65 ]
 [0.589]
 [0.674]
 [0.65 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.65 ]
 [0.396]
 [0.722]
 [0.65 ]
 [0.589]
 [0.674]
 [0.65 ]]
maxi score, test score, baseline:  0.15215999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15215999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15509999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15509999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15437999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15765999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15771999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15813999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15501999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.985]
 [1.012]
 [0.979]
 [0.985]
 [0.985]
 [0.985]
 [1.015]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.985]
 [1.012]
 [0.979]
 [0.985]
 [0.985]
 [0.985]
 [1.015]]
Printing some Q and Qe and total Qs values:  [[ 0.403]
 [ 0.297]
 [ 0.325]
 [ 0.156]
 [ 0.325]
 [ 0.325]
 [-0.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.403]
 [ 0.297]
 [ 0.325]
 [ 0.156]
 [ 0.325]
 [ 0.325]
 [-0.002]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1517399999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1546199999999998 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.193]
 [0.246]
 [0.839]
 [0.627]
 [0.807]
 [0.193]
 [0.616]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.193]
 [0.246]
 [0.839]
 [0.627]
 [0.807]
 [0.193]
 [0.616]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15445999999999982 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.696]
 [0.768]
 [0.696]
 [0.696]
 [0.696]
 [0.696]
 [0.696]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.696]
 [0.768]
 [0.696]
 [0.696]
 [0.696]
 [0.696]
 [0.696]]
maxi score, test score, baseline:  0.15445999999999982 0.6815 0.6815
probs:  [1.0]
siam score:  -0.81147647
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1576399999999998 0.6815 0.6815
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.1576399999999998 0.6815 0.6815
maxi score, test score, baseline:  0.1576399999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15739999999999982 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.838]
 [0.87 ]
 [0.838]
 [0.838]
 [0.838]
 [0.838]
 [0.838]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.838]
 [0.87 ]
 [0.838]
 [0.838]
 [0.838]
 [0.838]
 [0.838]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  55 total reward:  0.09999999999999953  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1598599999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1598599999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1598599999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15351999999999982 0.6815 0.6815
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.995]
 [0.999]
 [0.999]
 [0.959]
 [0.982]
 [0.959]
 [0.992]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.995]
 [0.999]
 [0.999]
 [0.959]
 [0.982]
 [0.959]
 [0.992]]
maxi score, test score, baseline:  0.15283999999999984 0.6815 0.6815
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.15277999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14931999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.882]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.882]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]]
maxi score, test score, baseline:  0.14887999999999985 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.942]
 [0.978]
 [0.944]
 [0.944]
 [0.944]
 [0.944]
 [0.9  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.942]
 [0.978]
 [0.944]
 [0.944]
 [0.944]
 [0.944]
 [0.9  ]]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.671]
 [0.736]
 [0.706]
 [0.698]
 [0.688]
 [0.733]
 [0.697]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.671]
 [0.736]
 [0.706]
 [0.698]
 [0.688]
 [0.733]
 [0.697]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8128174
maxi score, test score, baseline:  0.15611999999999984 0.6815 0.6815
maxi score, test score, baseline:  0.15611999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15611999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15575999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15575999999999982 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.838]
 [0.923]
 [0.872]
 [0.843]
 [0.872]
 [0.887]
 [0.872]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.838]
 [0.923]
 [0.872]
 [0.843]
 [0.872]
 [0.887]
 [0.872]]
maxi score, test score, baseline:  0.15575999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15539999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15539999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15183999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1541799999999998 0.6815 0.6815
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1540599999999998 0.6815 0.6815
maxi score, test score, baseline:  0.1540599999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15427999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.46999999999999986  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1572399999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1572399999999998 0.6815 0.6815
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15699999999999983 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15381999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15381999999999982 0.6815 0.6815
maxi score, test score, baseline:  0.15381999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.15381999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.15671999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15663999999999983 0.6815 0.6815
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.911]
 [0.986]
 [0.911]
 [0.911]
 [0.911]
 [0.911]
 [0.911]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.911]
 [0.986]
 [0.911]
 [0.911]
 [0.911]
 [0.911]
 [0.911]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.15415999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15117999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14887999999999985 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14887999999999985 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14591999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14565999999999982 0.6815 0.6815
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14535999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14535999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14251999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14577999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1454799999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1428799999999998 0.6815 0.6815
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.1428799999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1428799999999998 0.6815 0.6815
actor:  0 policy actor:  0  step number:  25 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.134]
 [0.067]
 [0.067]
 [0.067]
 [0.067]
 [0.073]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.   ]
 [0.134]
 [0.067]
 [0.067]
 [0.067]
 [0.067]
 [0.073]]
maxi score, test score, baseline:  0.1429799999999998 0.6815 0.6815
maxi score, test score, baseline:  0.1429799999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1429799999999998 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]]
actor:  0 policy actor:  0  step number:  39 total reward:  0.13999999999999946  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14441999999999983 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14441999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.7899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14529999999999985 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.993]
 [0.986]
 [0.993]
 [0.993]
 [0.993]
 [0.993]
 [0.993]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.993]
 [0.986]
 [0.993]
 [0.993]
 [0.993]
 [0.993]
 [0.993]]
maxi score, test score, baseline:  0.14529999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.432]
 [0.283]
 [0.392]
 [0.485]
 [0.48 ]
 [0.457]
 [0.424]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.432]
 [0.283]
 [0.392]
 [0.485]
 [0.48 ]
 [0.457]
 [0.424]]
Printing some Q and Qe and total Qs values:  [[0.894]
 [0.938]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.978]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.894]
 [0.938]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.978]]
Printing some Q and Qe and total Qs values:  [[0.666]
 [0.777]
 [0.666]
 [0.666]
 [0.666]
 [0.666]
 [0.666]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.666]
 [0.777]
 [0.666]
 [0.666]
 [0.666]
 [0.666]
 [0.666]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[ 0.023]
 [ 0.066]
 [ 0.023]
 [ 0.027]
 [ 0.028]
 [-0.   ]
 [ 0.009]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.023]
 [ 0.066]
 [ 0.023]
 [ 0.027]
 [ 0.028]
 [-0.   ]
 [ 0.009]]
maxi score, test score, baseline:  0.1427599999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1400399999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1400399999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.13667999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.2699999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1366799999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13941999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13607999999999984 0.6815 0.6815
maxi score, test score, baseline:  0.13607999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13649999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.776]
 [0.739]
 [0.739]
 [0.739]
 [0.739]
 [0.739]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.739]
 [0.776]
 [0.739]
 [0.739]
 [0.739]
 [0.739]
 [0.739]]
Printing some Q and Qe and total Qs values:  [[0.861]
 [0.909]
 [0.861]
 [0.861]
 [0.861]
 [0.861]
 [0.861]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.861]
 [0.909]
 [0.861]
 [0.861]
 [0.861]
 [0.861]
 [0.861]]
maxi score, test score, baseline:  0.13381999999999986 0.6815 0.6815
UNIT TEST: sample policy line 217 mcts : [0.02  0.694 0.041 0.02  0.041 0.061 0.122]
actor:  0 policy actor:  0  step number:  31 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13403999999999983 0.6815 0.6815
probs:  [1.0]
siam score:  -0.81470215
maxi score, test score, baseline:  0.13403999999999983 0.6815 0.6815
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  37 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.711]
 [0.801]
 [0.718]
 [0.711]
 [0.711]
 [0.711]
 [0.712]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.711]
 [0.801]
 [0.718]
 [0.711]
 [0.711]
 [0.711]
 [0.712]]
maxi score, test score, baseline:  0.13047999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.12761999999999984 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]]
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.10999999999999943  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.028]
 [0.107]
 [0.042]
 [0.032]
 [0.027]
 [0.   ]
 [0.044]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.028]
 [0.107]
 [0.042]
 [0.032]
 [0.027]
 [0.   ]
 [0.044]]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1297999999999998 0.6815 0.6815
maxi score, test score, baseline:  0.1297999999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.12669999999999984 0.6815 0.6815
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12655999999999984 0.6815 0.6815
maxi score, test score, baseline:  0.12655999999999984 0.6815 0.6815
maxi score, test score, baseline:  0.12655999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12705999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12725999999999985 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.683]
 [0.69 ]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.683]
 [0.69 ]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]]
maxi score, test score, baseline:  0.12725999999999985 0.6815 0.6815
probs:  [1.0]
siam score:  -0.8114322
maxi score, test score, baseline:  0.12725999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12733999999999984 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.602]
 [0.719]
 [0.617]
 [0.567]
 [0.602]
 [0.602]
 [0.615]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.602]
 [0.719]
 [0.617]
 [0.567]
 [0.602]
 [0.602]
 [0.615]]
maxi score, test score, baseline:  0.12733999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.12733999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.7  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.432]
 [0.383]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.432]
 [0.383]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]]
maxi score, test score, baseline:  0.12255999999999985 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.12255999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12219999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12469999999999984 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.782]
 [0.923]
 [0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.782]
 [0.923]
 [0.782]
 [0.782]
 [0.782]
 [0.782]
 [0.782]]
maxi score, test score, baseline:  0.12469999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11515999999999983 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.11515999999999983 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.11515999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11213999999999985 0.6815 0.6815
actor:  0 policy actor:  0  step number:  20 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.955]
 [0.896]
 [0.896]
 [0.896]
 [0.896]
 [0.896]
 [0.896]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.955]
 [0.896]
 [0.896]
 [0.896]
 [0.896]
 [0.896]
 [0.896]]
maxi score, test score, baseline:  0.10195999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.10195999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  34 total reward:  0.3299999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  40 total reward:  0.24999999999999956  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10403999999999984 0.6815 0.6815
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10427999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.81762624
actor:  0 policy actor:  0  step number:  28 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
siam score:  -0.81816345
Printing some Q and Qe and total Qs values:  [[0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]]
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10349999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10327999999999984 0.6815 0.6815
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10599999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.688]
 [0.757]
 [0.707]
 [0.708]
 [0.671]
 [0.657]
 [0.721]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.688]
 [0.757]
 [0.707]
 [0.708]
 [0.671]
 [0.657]
 [0.721]]
maxi score, test score, baseline:  0.10873999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.808]
 [0.899]
 [0.195]
 [0.82 ]
 [0.236]
 [0.831]
 [0.171]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.808]
 [0.899]
 [0.195]
 [0.82 ]
 [0.236]
 [0.831]
 [0.171]]
Printing some Q and Qe and total Qs values:  [[0.926]
 [0.993]
 [0.955]
 [0.926]
 [0.926]
 [0.926]
 [0.926]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.926]
 [0.993]
 [0.955]
 [0.926]
 [0.926]
 [0.926]
 [0.926]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.10955999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  41 total reward:  0.09999999999999942  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11137999999999984 0.6815 0.6815
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11109999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11113999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11309999999999983 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.11309999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8070164
maxi score, test score, baseline:  0.11637999999999983 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.11637999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.11939999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12211999999999984 0.6815 0.6815
maxi score, test score, baseline:  0.12211999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12505999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.12505999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.767]
 [0.803]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.767]
 [0.803]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]]
actor:  0 policy actor:  0  step number:  36 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.859]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.81 ]
 [0.859]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]]
Printing some Q and Qe and total Qs values:  [[0.911]
 [0.816]
 [0.838]
 [0.838]
 [0.838]
 [0.838]
 [0.825]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.911]
 [0.816]
 [0.838]
 [0.838]
 [0.838]
 [0.838]
 [0.825]]
maxi score, test score, baseline:  0.12517999999999982 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.844]
 [0.931]
 [0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.844]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.844]
 [0.931]
 [0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.844]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12525999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12509999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12511999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.12511999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.12511999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.12199999999999984 0.6815 0.6815
probs:  [1.0]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[ 0.1285],
        [ 0.2190],
        [ 0.0000],
        [ 0.0930],
        [ 0.8422],
        [ 0.0000],
        [ 0.9427],
        [-0.5315],
        [ 0.0000],
        [ 0.6054]], dtype=torch.float64)
-0.145559551797 -0.017104120962968705
-0.106157551797 0.1128217539158554
-0.8363046384 -0.8363046384
-0.125759551797 -0.03278182781575438
-0.145559551797 0.6965973278591224
0.91139202 0.91139202
-0.08752783059899999 0.8551699305683786
-0.087921850599 -0.6194645691236154
0.950598 0.950598
-0.107327830599 0.49804678985605033
actor:  0 policy actor:  0  step number:  30 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12281999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12283999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.776]
 [0.776]
 [0.89 ]
 [0.776]
 [0.776]
 [0.776]
 [0.706]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.776]
 [0.776]
 [0.89 ]
 [0.776]
 [0.776]
 [0.776]
 [0.706]]
Printing some Q and Qe and total Qs values:  [[0.72 ]
 [0.846]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.72 ]
 [0.846]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]]
maxi score, test score, baseline:  0.12605999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12933999999999982 0.6815 0.6815
probs:  [1.0]
siam score:  -0.8076265
actor:  0 policy actor:  0  step number:  36 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13167999999999982 0.6815 0.6815
probs:  [1.0]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  24 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.538]
 [0.582]
 [0.582]
 [0.582]
 [0.582]
 [0.582]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.582]
 [0.538]
 [0.582]
 [0.582]
 [0.582]
 [0.582]
 [0.582]]
maxi score, test score, baseline:  0.13227999999999981 0.6815 0.6815
probs:  [1.0]
siam score:  -0.81564516
maxi score, test score, baseline:  0.12945999999999983 0.6815 0.6815
maxi score, test score, baseline:  0.12945999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1292799999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1292799999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  31 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12897999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12669999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.12669999999999984 0.6815 0.6815
siam score:  -0.8213593
siam score:  -0.8225528
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12683999999999981 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8195612
maxi score, test score, baseline:  0.12739999999999982 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.12739999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1307799999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13091999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6499999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.807]
 [0.807]
 [0.893]
 [0.807]
 [0.807]
 [0.807]
 [0.807]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.807]
 [0.807]
 [0.893]
 [0.807]
 [0.807]
 [0.807]
 [0.807]]
maxi score, test score, baseline:  0.1309999999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13745999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
siam score:  -0.81518877
actor:  0 policy actor:  0  step number:  19 total reward:  0.6599999999999999  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
maxi score, test score, baseline:  0.13701999999999984 0.6815 0.6815
maxi score, test score, baseline:  0.13701999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.13701999999999984 0.6815 0.6815
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14001999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14067999999999983 0.6815 0.6815
siam score:  -0.8094389
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1408799999999998 0.6815 0.6815
actor:  0 policy actor:  0  step number:  28 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1409599999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1409599999999998 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.1409599999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13737999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13751999999999984 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.951]
 [0.99 ]
 [0.959]
 [0.951]
 [0.951]
 [0.951]
 [0.951]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.951]
 [0.99 ]
 [0.959]
 [0.951]
 [0.951]
 [0.951]
 [0.951]]
maxi score, test score, baseline:  0.13751999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.869]
 [0.907]
 [0.889]
 [0.871]
 [0.908]
 [0.871]
 [0.897]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.869]
 [0.907]
 [0.889]
 [0.871]
 [0.908]
 [0.871]
 [0.897]]
maxi score, test score, baseline:  0.14049999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14045999999999983 0.6815 0.6815
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13741999999999985 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.763]
 [0.682]
 [0.63 ]
 [0.675]
 [0.682]
 [0.682]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.682]
 [0.763]
 [0.682]
 [0.63 ]
 [0.675]
 [0.682]
 [0.682]]
maxi score, test score, baseline:  0.13741999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14023999999999984 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.656]
 [0.8  ]
 [0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.656]
 [0.8  ]
 [0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]]
maxi score, test score, baseline:  0.14023999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.14023999999999984 0.6815 0.6815
probs:  [1.0]
maxi score, test score, baseline:  0.13717999999999983 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.404]
 [0.439]
 [0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.404]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.404]
 [0.439]
 [0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.404]]
maxi score, test score, baseline:  0.13733999999999982 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [0.918]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.964]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.88 ]
 [0.918]
 [0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.964]]
maxi score, test score, baseline:  0.13733999999999982 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13447999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13429999999999984 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  36 total reward:  0.22999999999999954  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13675999999999985 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.936]
 [0.833]
 [0.843]
 [0.843]
 [0.843]
 [0.16 ]
 [0.868]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.936]
 [0.833]
 [0.843]
 [0.843]
 [0.843]
 [0.16 ]
 [0.868]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13301999999999983 0.6815 0.6815
Printing some Q and Qe and total Qs values:  [[0.826]
 [0.929]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.826]
 [0.929]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]]
maxi score, test score, baseline:  0.13301999999999983 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.98]
 [0.98]
 [0.98]
 [0.98]
 [0.98]
 [0.98]
 [0.98]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.98]
 [0.98]
 [0.98]
 [0.98]
 [0.98]
 [0.98]
 [0.98]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.13301999999999983 0.6815 0.6815
actor:  0 policy actor:  0  step number:  28 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  39 total reward:  0.13999999999999946  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.855]
 [0.853]
 [0.855]
 [0.855]
 [0.855]
 [0.855]
 [0.855]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.855]
 [0.853]
 [0.855]
 [0.855]
 [0.855]
 [0.855]
 [0.855]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1318599999999998 0.6815 0.6815
maxi score, test score, baseline:  0.1318599999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  18 total reward:  0.6699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.1356599999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.035]
 [0.144]
 [0.072]
 [0.108]
 [0.072]
 [0.072]
 [0.111]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.035]
 [0.144]
 [0.072]
 [0.108]
 [0.072]
 [0.072]
 [0.111]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]
 [0.979]]
maxi score, test score, baseline:  0.1362999999999998 0.6815 0.6815
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.832]
 [0.832]
 [0.847]
 [0.832]
 [0.832]
 [0.832]
 [0.807]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.832]
 [0.832]
 [0.847]
 [0.832]
 [0.832]
 [0.832]
 [0.807]]
Printing some Q and Qe and total Qs values:  [[0.832]
 [0.955]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.832]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.832]
 [0.955]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.832]]
maxi score, test score, baseline:  0.1362999999999998 0.6815 0.6815
actor:  0 policy actor:  0  step number:  32 total reward:  0.2899999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.47999999999999976  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1388799999999998 0.6815 0.6815
probs:  [1.0]
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.7699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.7699999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  16 total reward:  0.73  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  17 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16527999999999982 0.7255 0.7255
actor:  0 policy actor:  0  step number:  35 total reward:  0.23999999999999955  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1612799999999998 0.7255 0.7255
probs:  [1.0]
siam score:  -0.8132564
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16125999999999982 0.7255 0.7255
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16131999999999985 0.7255 0.7255
maxi score, test score, baseline:  0.16131999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15515999999999983 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.678]
 [0.837]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.669]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.678]
 [0.837]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.669]]
maxi score, test score, baseline:  0.15515999999999983 0.7255 0.7255
maxi score, test score, baseline:  0.15515999999999983 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15515999999999983 0.7255 0.7255
actor:  0 policy actor:  0  step number:  30 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[1.007]
 [1.007]
 [1.007]
 [1.007]
 [1.007]
 [1.007]
 [1.007]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.007]
 [1.007]
 [1.007]
 [1.007]
 [1.007]
 [1.007]
 [1.007]]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15773999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.742]
 [0.852]
 [0.742]
 [0.742]
 [0.742]
 [0.742]
 [0.742]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.742]
 [0.852]
 [0.742]
 [0.742]
 [0.742]
 [0.742]
 [0.742]]
siam score:  -0.80899286
maxi score, test score, baseline:  0.15767999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15767999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15767999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15767999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15767999999999985 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15753999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15781999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1606799999999998 0.7255 0.7255
probs:  [1.0]
siam score:  -0.805949
maxi score, test score, baseline:  0.1606799999999998 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.1606799999999998 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.908]
 [0.994]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.908]
 [0.994]
 [0.908]
 [0.908]
 [0.908]
 [0.908]
 [0.908]]
maxi score, test score, baseline:  0.1606799999999998 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.2799999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15665999999999985 0.7255 0.7255
Printing some Q and Qe and total Qs values:  [[0.875]
 [0.875]
 [0.892]
 [0.875]
 [0.875]
 [0.875]
 [0.875]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.875]
 [0.875]
 [0.892]
 [0.875]
 [0.875]
 [0.875]
 [0.875]]
maxi score, test score, baseline:  0.15665999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15369999999999984 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15369999999999984 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.44999999999999973  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15085999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.34999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.372]
 [0.277]
 [0.272]
 [0.204]
 [0.389]
 [0.365]
 [0.372]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.372]
 [0.277]
 [0.272]
 [0.204]
 [0.389]
 [0.365]
 [0.372]]
maxi score, test score, baseline:  0.15637999999999985 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15643999999999983 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15643999999999983 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15625999999999984 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[ 0.532]
 [ 0.62 ]
 [ 0.657]
 [ 0.641]
 [ 0.645]
 [-0.007]
 [ 0.627]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.532]
 [ 0.62 ]
 [ 0.657]
 [ 0.641]
 [ 0.645]
 [-0.007]
 [ 0.627]]
maxi score, test score, baseline:  0.15013999999999983 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15013999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]]
maxi score, test score, baseline:  0.1499199999999998 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14993999999999985 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.817]
 [0.816]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.817]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.817]
 [0.816]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.817]]
maxi score, test score, baseline:  0.14941999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  38 total reward:  0.10999999999999943  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.227]
 [0.602]
 [0.227]
 [0.227]
 [0.227]
 [0.227]
 [0.227]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.227]
 [0.602]
 [0.227]
 [0.227]
 [0.227]
 [0.227]
 [0.227]]
maxi score, test score, baseline:  0.14491999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.045]
 [0.051]
 [0.045]
 [0.045]
 [0.045]
 [0.045]
 [0.045]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.045]
 [0.051]
 [0.045]
 [0.045]
 [0.045]
 [0.045]
 [0.045]]
maxi score, test score, baseline:  0.14467999999999984 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.14467999999999984 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14347999999999983 0.7255 0.7255
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14307999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.14307999999999985 0.7255 0.7255
maxi score, test score, baseline:  0.14307999999999985 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.874]
 [0.902]
 [0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.897]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.874]
 [0.902]
 [0.874]
 [0.874]
 [0.874]
 [0.874]
 [0.897]]
maxi score, test score, baseline:  0.13955999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  37 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
actor:  0 policy actor:  0  step number:  39 total reward:  0.33999999999999975  reward:  1.0 rdn_beta:  0.0
siam score:  -0.8006046
siam score:  -0.80117905
maxi score, test score, baseline:  0.1344399999999998 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.12799999999999984 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.811]
 [0.911]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.811]
 [0.911]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]]
maxi score, test score, baseline:  0.12483999999999983 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.12483999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12481999999999986 0.7255 0.7255
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.724]
 [0.799]
 [0.695]
 [0.711]
 [0.677]
 [0.744]
 [0.671]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.724]
 [0.799]
 [0.695]
 [0.711]
 [0.677]
 [0.744]
 [0.671]]
maxi score, test score, baseline:  0.12197999999999982 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.12197999999999982 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.708]
 [0.75 ]
 [0.672]
 [0.667]
 [0.664]
 [0.66 ]
 [0.695]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.708]
 [0.75 ]
 [0.672]
 [0.667]
 [0.664]
 [0.66 ]
 [0.695]]
maxi score, test score, baseline:  0.12501999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.15999999999999948  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12471999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.72  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12563999999999984 0.7255 0.7255
maxi score, test score, baseline:  0.12563999999999984 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.12563999999999984 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.74  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13211999999999982 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.13211999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  28 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13233999999999982 0.7255 0.7255
Printing some Q and Qe and total Qs values:  [[0.942]
 [0.996]
 [0.947]
 [0.941]
 [0.941]
 [0.941]
 [0.945]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.942]
 [0.996]
 [0.947]
 [0.941]
 [0.941]
 [0.941]
 [0.945]]
Printing some Q and Qe and total Qs values:  [[0.691]
 [0.8  ]
 [0.732]
 [0.687]
 [0.689]
 [0.732]
 [0.655]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.691]
 [0.8  ]
 [0.732]
 [0.687]
 [0.689]
 [0.732]
 [0.655]]
maxi score, test score, baseline:  0.13233999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  44 total reward:  0.20999999999999963  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13159999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  40 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.13017999999999982 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.13017999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.12995999999999983 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.998]
 [1.024]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.998]
 [1.024]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]]
maxi score, test score, baseline:  0.12995999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13317999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.25999999999999956  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13855999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13801999999999984 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13447999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.13447999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.13447999999999985 0.7255 0.7255
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.084]
 [0.091]
 [0.084]
 [0.084]
 [0.084]
 [0.084]
 [0.084]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.084]
 [0.091]
 [0.084]
 [0.084]
 [0.084]
 [0.084]
 [0.084]]
maxi score, test score, baseline:  0.13511999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.13511999999999985 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13789999999999983 0.7255 0.7255
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1380999999999998 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.13809999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.933]
 [0.965]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.933]
 [0.965]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13895999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13917999999999983 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.709]
 [0.766]
 [0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.709]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.709]
 [0.766]
 [0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.709]]
maxi score, test score, baseline:  0.13917999999999983 0.7255 0.7255
maxi score, test score, baseline:  0.13917999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14239999999999983 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.13951999999999984 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.209]
 [0.307]
 [0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.209]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.209]
 [0.307]
 [0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.209]]
maxi score, test score, baseline:  0.13951999999999984 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.13951999999999984 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.13951999999999984 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3199999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14215999999999981 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.14215999999999981 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14227999999999982 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.14227999999999982 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.14227999999999982 0.7255 0.7255
Printing some Q and Qe and total Qs values:  [[0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]]
maxi score, test score, baseline:  0.14227999999999982 0.7255 0.7255
maxi score, test score, baseline:  0.14227999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.06 ]
 [0.031]
 [0.027]
 [0.027]
 [0.025]
 [0.034]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.031]
 [0.06 ]
 [0.031]
 [0.027]
 [0.027]
 [0.025]
 [0.034]]
siam score:  -0.8111717
maxi score, test score, baseline:  0.1381599999999998 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.561]
 [0.561]
 [0.868]
 [0.561]
 [0.561]
 [0.619]
 [0.561]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.561]
 [0.561]
 [0.868]
 [0.561]
 [0.561]
 [0.619]
 [0.561]]
Printing some Q and Qe and total Qs values:  [[0.909]
 [0.972]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.909]
 [0.972]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]]
maxi score, test score, baseline:  0.1381599999999998 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.71  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14157999999999984 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.45999999999999974  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.6099999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14241999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.3899999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  19 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.6799999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.13963999999999985 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.74 ]
 [0.809]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.74 ]
 [0.809]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]]
maxi score, test score, baseline:  0.13963999999999985 0.7255 0.7255
maxi score, test score, baseline:  0.13963999999999985 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.917]
 [0.774]
 [0.842]
 [0.842]
 [0.842]
 [0.842]
 [0.802]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.917]
 [0.774]
 [0.842]
 [0.842]
 [0.842]
 [0.842]
 [0.802]]
siam score:  -0.8121739
maxi score, test score, baseline:  0.13963999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.13963999999999985 0.7255 0.7255
maxi score, test score, baseline:  0.13963999999999985 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.14055999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.14361999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15013999999999983 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15013999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15007999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15631999999999982 0.7255 0.7255
maxi score, test score, baseline:  0.15309999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6199999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15325999999999984 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  36 total reward:  0.16999999999999948  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.857]
 [0.857]
 [0.913]
 [0.857]
 [0.857]
 [0.857]
 [0.857]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.857]
 [0.857]
 [0.913]
 [0.857]
 [0.857]
 [0.857]
 [0.857]]
Printing some Q and Qe and total Qs values:  [[0.653]
 [0.792]
 [0.649]
 [0.653]
 [0.651]
 [0.652]
 [0.649]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.653]
 [0.792]
 [0.649]
 [0.653]
 [0.651]
 [0.652]
 [0.649]]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15587999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  18 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.36999999999999966  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.287]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.287]]
maxi score, test score, baseline:  0.15589999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  25 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1557399999999998 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5399999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  32 total reward:  0.3099999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15537999999999982 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15537999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  31 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15507999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5299999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.919]
 [0.927]
 [0.9  ]
 [0.842]
 [0.88 ]
 [0.887]
 [0.972]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.919]
 [0.927]
 [0.9  ]
 [0.842]
 [0.88 ]
 [0.887]
 [0.972]]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15815999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  35 total reward:  0.1799999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.37999999999999967  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15775999999999982 0.7255 0.7255
maxi score, test score, baseline:  0.15775999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  21 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  30 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1577399999999998 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]
 [0.866]]
siam score:  -0.8095658
maxi score, test score, baseline:  0.1577399999999998 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1578399999999998 0.7255 0.7255
actor:  0 policy actor:  0  step number:  33 total reward:  0.2999999999999996  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1576799999999998 0.7255 0.7255
maxi score, test score, baseline:  0.1576799999999998 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.1576799999999998 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.1576799999999998 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  22 total reward:  0.5499999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  23 total reward:  0.5999999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1578599999999998 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.1578599999999998 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.908]
 [0.898]
 [0.908]
 [0.898]
 [0.898]
 [0.908]
 [0.898]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.908]
 [0.898]
 [0.908]
 [0.898]
 [0.898]
 [0.908]
 [0.898]]
actor:  0 policy actor:  0  step number:  29 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  21 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16057999999999983 0.7255 0.7255
probs:  [1.0]
Printing some Q and Qe and total Qs values:  [[0.797]
 [0.903]
 [0.797]
 [0.797]
 [0.797]
 [0.797]
 [0.797]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.797]
 [0.903]
 [0.797]
 [0.797]
 [0.797]
 [0.797]
 [0.797]]
maxi score, test score, baseline:  0.16057999999999983 0.7255 0.7255
maxi score, test score, baseline:  0.16057999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.6299999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16063999999999984 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16037999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  34 total reward:  0.4099999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16319999999999985 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.16033999999999982 0.7255 0.7255
maxi score, test score, baseline:  0.16033999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15651999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.1999999999999995  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15885999999999983 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15885999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  29 total reward:  0.3999999999999997  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16165999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  27 total reward:  0.4199999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  50 total reward:  0.20999999999999952  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1607999999999998 0.7255 0.7255
Printing some Q and Qe and total Qs values:  [[0.742]
 [0.86 ]
 [0.761]
 [0.762]
 [0.763]
 [0.757]
 [0.775]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.742]
 [0.86 ]
 [0.761]
 [0.762]
 [0.763]
 [0.757]
 [0.775]]
maxi score, test score, baseline:  0.1607999999999998 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  20 total reward:  0.69  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  29 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  35 total reward:  0.4399999999999997  reward:  1.0 rdn_beta:  0.0
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.912]
 [0.972]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.903]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.912]
 [0.972]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.903]]
maxi score, test score, baseline:  0.16123999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  32 total reward:  0.48999999999999977  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  25 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.35999999999999965  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1613599999999998 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  11176
Printing some Q and Qe and total Qs values:  [[ 0.628]
 [ 0.772]
 [-0.006]
 [ 0.663]
 [ 0.652]
 [ 0.707]
 [ 0.719]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.628]
 [ 0.772]
 [-0.006]
 [ 0.663]
 [ 0.652]
 [ 0.707]
 [ 0.719]]
actor:  0 policy actor:  0  step number:  25 total reward:  0.6399999999999999  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.16245999999999983 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.16245999999999983 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  33 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.1561199999999998 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.1561199999999998 0.7255 0.7255
actor:  0 policy actor:  0  step number:  25 total reward:  0.4999999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  28 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15613999999999983 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15613999999999983 0.7255 0.7255
probs:  [1.0]
line 256 mcts: sample exp_bonus 0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  22 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  27 total reward:  0.5199999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.709]
 [0.819]
 [0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.709]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.709]
 [0.819]
 [0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.709]]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5799999999999998  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  24 total reward:  0.5899999999999999  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5099999999999998  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]
 [0.79]]
actor:  0 policy actor:  0  step number:  26 total reward:  0.4299999999999997  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  38 total reward:  0.14999999999999947  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  26 total reward:  0.5699999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15709999999999982 0.7255 0.7255
probs:  [1.0]
maxi score, test score, baseline:  0.15709999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  23 total reward:  0.5599999999999998  reward:  1.0 rdn_beta:  0.0
maxi score, test score, baseline:  0.15745999999999982 0.7255 0.7255
probs:  [1.0]
actor:  0 policy actor:  0  step number:  24 total reward:  0.46999999999999975  reward:  1.0 rdn_beta:  0.0
Printing some Q and Qe and total Qs values:  [[0.919]
 [0.956]
 [0.904]
 [0.888]
 [0.908]
 [0.918]
 [0.925]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.919]
 [0.956]
 [0.904]
 [0.888]
 [0.908]
 [0.918]
 [0.925]]
actor:  0 policy actor:  0  step number:  43 total reward:  0.33999999999999964  reward:  1.0 rdn_beta:  0.0
actor:  0 policy actor:  0  step number:  33 total reward:  0.21999999999999953  reward:  1.0 rdn_beta:  0.0
