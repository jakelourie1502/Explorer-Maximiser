dirichlet_alpha:0.3
noise:0.3
dirichlet_alpha:0.5
noise:0.5
sims:{-1: 6, 6000: 25}
c1:1
c2:19652
temperature_init:1
temperature_changes:{-1: 1, 3000000.0: 0.5}
manual_over_ride_play_limit:None
exponent_node_n:1
ucb_denom_k:1
use_policy:True
model_expV_on_dones:True
norm_Qs_OnMaxi:True
norm_Qs_OnAll:True
norm_each_turn:False
state_channels:64
res_block_kernel_size:3
res_block_channels:[32, 32, 64, 64, 64]
res_block_ds:[False, True, False, False, False]
conv1:{'channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1}
conv2:{'channels': 64, 'kernel_size': 3, 'stride': 2, 'padding': 1}
reward_support:[-1, 1, 51]
conv1:{'kernel_size': 3, 'stride': 1, 'padding': 1}
res_blocks:[64]
reward_conv_channels:32
reward_hidden_dim:128
terminal_conv_channels:32
terminal_hidden_dim:64
value_support:[-1, 1, 51]
res_block:[64]
value_conv_channels:32
value_hidden_dim:128
policy_conv_channels:32
policy_hidden_dim:128
expV_conv_channels:32
expV_hidden_dim:128
expV_support:[-10, 10, 51]
proj_l1:256
proj_out:128
pred_hid:256
replay_buffer_size:50000
replay_buffer_size_exploration:200000
all_time_buffer_size:200000
batch_size:128
play_workers:2
min_workers:1
max_workers:6
lr:0.001
lr_warmup:1000
lr_decay:1
lr_decay_step:100000
optimizer:<class 'torch.optim.rmsprop.RMSprop'>
momentum:0.9
l2:0.0001
rho:0.99
k:5
value:0.25
dones:2.0
siam:2
rdn:0.5
expV:0.5
train_start_batch_multiple:2
prioritised_replay:True
ep_to_batch_ratio:[15, 16]
main_to_rdn_ratio:2
train_to_RS_ratio:4
on_policy_expV:False
rgb_im:True
channels:3
state_size:[6, 6]
timesteps_in_obs:2
store_prev_actions:True
env:<class 'game_play.frozen_lakeGym_Image.gridWorld'>
same_env_each_time:True
env_size:[8, 8]
observable_size:[8, 8]
game_modes:1
env_map:[['S' 'F' 'H' 'F' 'F' 'F' 'F' 'F']
 ['F' 'H' 'F' 'F' 'F' 'F' 'F' 'H']
 ['F' 'H' 'F' 'F' 'H' 'F' 'F' 'H']
 ['F' 'F' 'F' 'F' 'H' 'F' 'H' 'H']
 ['F' 'F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'H' 'F' 'F' 'H' 'F' 'F']
 ['F' 'F' 'H' 'F' 'F' 'H' 'H' 'F']
 ['F' 'F' 'F' 'F' 'F' 'H' 'H' 'G']]
max_steps:100
actions_size:5
optimal_score:1
total_frames:255000
exp_gamma:0.95
atari_env:False
reward_clipping:False
memory_size:100
image_size:[48, 48]
deque_length:3
PRESET_CONFIG:7
VK:True
use_two_heads:True
follow_better_policy:0.5
use_siam:True
exploration_type:episodic
rdn_beta:[1, 3, 5]
explorer_percentage:0.8
reward_exploration:False
train_dones:True
contrast_vector:True
norm_state_vecs:False
RND_output_vector:256
RND_loss:cosine
prediction_bias:True
distance_measure:False
update_play_model:16
gamma:0.99
calc_n_step_rewards_after_frames:10000
N_steps_reward:5
start_frame_count:0
load_in_model:False
log_states:True
log_metrics:False
exploration_logger_dims:(1, 64)
device_train:cpu
device_selfplay:cpu
eval_x_frames:10000
eval_count:20
detach_expV_calc:True
use_new_episode_expV:False
start_training_expV_min:10000
start_training_expV_max:20000
start_training_expV_siam_override:0.8
value_only:False
[['S' 'F' 'H' 'F' 'F' 'F' 'F' 'F']
 ['F' 'H' 'F' 'F' 'F' 'F' 'F' 'H']
 ['F' 'H' 'F' 'F' 'H' 'F' 'F' 'H']
 ['F' 'F' 'F' 'F' 'H' 'F' 'H' 'H']
 ['F' 'F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'H' 'F' 'F' 'H' 'F' 'F']
 ['F' 'F' 'H' 'F' 'F' 'H' 'H' 'F']
 ['F' 'F' 'F' 'F' 'F' 'H' 'H' 'G']]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
UNIT TEST: sample policy line 217 mcts : [0. 0. 0. 0. 1.]
from probs:  [0.2, 0.2, 0.2, 0.2, 0.2]
from probs:  [0.2, 0.2, 0.2, 0.2, 0.2]
Printing some Q and Qe and total Qs values:  [[-0.   ]
 [-0.   ]
 [-0.   ]
 [ 0.001]
 [-0.   ]] [[5.659]
 [5.659]
 [5.659]
 [9.109]
 [5.659]] [[1.398]
 [1.398]
 [1.398]
 [2.501]
 [1.398]]
from probs:  [0.2, 0.2, 0.2, 0.2, 0.2]
from probs:  [0.2, 0.2, 0.2, 0.2, 0.2]
printing an ep nov before normalisation:  2.722405791282654
from probs:  [0.2, 0.2, 0.2, 0.2, 0.2]
from probs:  [0.2, 0.2, 0.2, 0.2, 0.2]
from probs:  [0.2, 0.2, 0.2, 0.2, 0.2]
Starting evaluation
printing an ep nov before normalisation:  2.7068542109595404
siam score:  -0.0006175948920744387
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
deleting a thread, now have 2 threads
Frames:  1222 train batches done:  22 episodes:  121
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
deleting a thread, now have 1 threads
Frames:  1222 train batches done:  56 episodes:  121
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([0.4787, 0.0178, 0.0133, 0.3023, 0.1879], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0588, 0.6504, 0.1564, 0.0208, 0.1136], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0765, 0.0161, 0.4466, 0.2603, 0.2005], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.2882, 0.0434, 0.1777, 0.2949, 0.1959], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.3103, 0.0160, 0.2220, 0.2619, 0.1898], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.39468864
actions average: 
K:  1  action  0 :  tensor([0.4041, 0.0095, 0.0075, 0.3266, 0.2522], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0688, 0.7067, 0.0844, 0.0114, 0.1287], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0487, 0.0669, 0.5846, 0.1561, 0.1436], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.2688, 0.0148, 0.1541, 0.3150, 0.2474], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2157, 0.1386, 0.1613, 0.1762, 0.3081], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.44186142
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.48367032
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.48741218
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([0.4512, 0.0081, 0.0131, 0.2953, 0.2323], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.1121, 0.7561, 0.0187, 0.0023, 0.1108], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0196, 0.1062, 0.6507, 0.1088, 0.1147], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.2783, 0.0057, 0.0886, 0.4185, 0.2089], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2633, 0.0116, 0.1162, 0.3084, 0.3006], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5190037
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.51392835
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.714208734721595
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5257591
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5533409
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.  0.  0.  0.2 0.8]
UNIT TEST: sample policy line 217 mcts : [0.  0.8 0.  0.2 0. ]
actions average: 
K:  3  action  0 :  tensor([0.5202, 0.0015, 0.0088, 0.2679, 0.2015], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0127, 0.9225, 0.0176, 0.0033, 0.0439], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0045, 0.0034, 0.8364, 0.0751, 0.0807], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.3133, 0.0068, 0.0574, 0.3878, 0.2347], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2135, 0.1428, 0.1624, 0.2730, 0.2083], grad_fn=<DivBackward0>)
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.56632555
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  8.420696262360252
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([0.5390, 0.0017, 0.0009, 0.2332, 0.2251], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0264,     0.9285,     0.0072,     0.0007,     0.0373],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0117, 0.0106, 0.8372, 0.0864, 0.0541], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.1653,     0.0005,     0.0258,     0.5170,     0.2913],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.2653, 0.0026, 0.0252, 0.3596, 0.3473], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  67.90568828582764
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  77.35854148864746
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.55382186
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  55.51720926641585
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5605186
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5680768
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[81.395]
 [84.16 ]
 [77.761]
 [71.223]
 [82.318]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  47.4525260925293
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  90.17567222910658
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  107.20144251682056
siam score:  -0.5791449
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  95.81197444611135
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.973]
 [90.332]
 [86.973]
 [86.973]
 [86.973]] [[1.683]
 [1.785]
 [1.683]
 [1.683]
 [1.683]]
printing an ep nov before normalisation:  66.98398720898093
printing an ep nov before normalisation:  95.50547377524117
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  35.75904568040157
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  95.38563105962965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5474161
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 72.5179386138916
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  83.27857408483304
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  75.93663132782571
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  108.64972322733325
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5064453
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([0.5592, 0.0041, 0.0006, 0.2095, 0.2266], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0525, 0.8874, 0.0318, 0.0091, 0.0192], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0009,     0.9491,     0.0266,     0.0231],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.1896, 0.0184, 0.0414, 0.5980, 0.1525], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2542, 0.0486, 0.0394, 0.1731, 0.4848], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  83.59201500121429
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  68.46704596982498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  55.09956032670701
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  7.256126147488828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5682724
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([0.4723, 0.0347, 0.0165, 0.2164, 0.2602], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0774, 0.8137, 0.0267, 0.0035, 0.0787], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0137, 0.0180, 0.9178, 0.0265, 0.0240], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1754, 0.0101, 0.0421, 0.5245, 0.2478], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2748, 0.0045, 0.1005, 0.2546, 0.3657], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  50.91718661719885
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  118.13980593311182
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([0.4873, 0.0017, 0.0005, 0.2372, 0.2732], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0206, 0.9269, 0.0211, 0.0056, 0.0258], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0004,     0.0014,     0.9383,     0.0354,     0.0245],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.2003, 0.0007, 0.0118, 0.5569, 0.2302], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.3026, 0.0064, 0.0273, 0.2793, 0.3844], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
line 256 mcts: sample exp_bonus 50.96216678619385
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  1.8951263107008272
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.52247125
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.709]
 [32.832]
 [22.278]
 [21.521]
 [20.903]] [[0.734]
 [0.765]
 [0.473]
 [0.452]
 [0.435]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[114.628]
 [103.278]
 [107.144]
 [107.144]
 [107.144]] [[2.895]
 [2.516]
 [2.645]
 [2.645]
 [2.645]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.875]
 [36.875]
 [36.875]
 [36.875]
 [36.875]] [[1.789]
 [1.789]
 [1.789]
 [1.789]
 [1.789]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[96.37 ]
 [74.514]
 [74.514]
 [74.514]
 [83.732]] [[2.166]
 [1.376]
 [1.376]
 [1.376]
 [1.709]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [83.159]
 [ 0.   ]] [[-0.725]
 [-0.725]
 [-0.725]
 [ 1.655]
 [-0.725]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  114.12982425866227
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([0.5930, 0.0117, 0.0018, 0.1791, 0.2144], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0011,     0.9970,     0.0003,     0.0000,     0.0016],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0123, 0.0019, 0.9483, 0.0193, 0.0182], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.2481, 0.0012, 0.0041, 0.4422, 0.3043], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2807, 0.0011, 0.0166, 0.2476, 0.4540], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 63.983]
 [135.026]
 [ 63.983]
 [ 73.407]
 [ 73.052]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.56821096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5570663
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 73.447]
 [109.892]
 [ 97.875]
 [ 73.447]
 [ 73.447]] [[0.432]
 [0.84 ]
 [0.705]
 [0.432]
 [0.432]]
printing an ep nov before normalisation:  120.0698808124499
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  132.9517407394203
printing an ep nov before normalisation:  53.0791301198178
printing an ep nov before normalisation:  69.56627618145596
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([0.5665, 0.0236, 0.0037, 0.1747, 0.2316], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0020,     0.9897,     0.0042,     0.0008,     0.0032],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0014, 0.0013, 0.9673, 0.0076, 0.0224], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.1337,     0.0002,     0.0118,     0.6362,     0.2181],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2505, 0.0568, 0.0382, 0.2348, 0.4198], grad_fn=<DivBackward0>)
siam score:  -0.5439669
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.6363,     0.0046,     0.0005,     0.1466,     0.2121],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0061, 0.9520, 0.0263, 0.0063, 0.0093], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0004,     0.0002,     0.9811,     0.0097,     0.0085],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.1376,     0.0003,     0.0209,     0.5020,     0.3392],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2206, 0.0015, 0.0697, 0.3250, 0.3832], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 61.912]
 [115.044]
 [ 75.201]
 [ 75.201]
 [ 75.201]] [[0.408]
 [1.074]
 [0.574]
 [0.574]
 [0.574]]
using explorer policy with actor:  1
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  47.646630603850966
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.50398475
siam score:  -0.5094457
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([0.5597, 0.0104, 0.0007, 0.1957, 0.2335], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0113, 0.9442, 0.0213, 0.0026, 0.0206], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0279, 0.0012, 0.9114, 0.0266, 0.0329], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.2330, 0.0013, 0.0112, 0.4506, 0.3039], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.3612, 0.0005, 0.0007, 0.2146, 0.4230], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  80.46826521555583
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[108.98 ]
 [ 98.26 ]
 [ 97.002]
 [108.98 ]
 [108.98 ]] [[2.374]
 [1.982]
 [1.936]
 [2.374]
 [2.374]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  84.8169938896514
printing an ep nov before normalisation:  112.15146056779899
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([0.4851, 0.0114, 0.0036, 0.1830, 0.3169], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0017,     0.9945,     0.0005,     0.0003,     0.0030],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0174,     0.0001,     0.8968,     0.0588,     0.0268],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.1472,     0.0005,     0.0042,     0.6395,     0.2086],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.1299,     0.0004,     0.0099,     0.3585,     0.5013],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.57337385
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([0.5817, 0.0013, 0.0014, 0.1746, 0.2409], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0159, 0.9147, 0.0283, 0.0055, 0.0356], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0117, 0.0086, 0.8864, 0.0528, 0.0405], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.2344, 0.0013, 0.0328, 0.4364, 0.2951], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.3034, 0.0010, 0.0141, 0.2827, 0.3989], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  54.55780506134033
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 52.44819471650595
printing an ep nov before normalisation:  131.06656820413986
printing an ep nov before normalisation:  70.90593558455271
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5905569
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.6785,     0.0002,     0.0006,     0.1581,     0.1625],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0131, 0.9140, 0.0195, 0.0219, 0.0315], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0531, 0.0280, 0.8065, 0.0635, 0.0488], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.2173,     0.0001,     0.0007,     0.6242,     0.1578],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2951, 0.0081, 0.0086, 0.3201, 0.3681], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  36.435539203569284
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5677016
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.188]
 [88.453]
 [84.958]
 [94.913]
 [59.08 ]] [[1.114]
 [1.611]
 [1.548]
 [1.729]
 [1.076]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  13.433817498701437
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  62.291056613767644
printing an ep nov before normalisation:  58.921570777893066
siam score:  -0.5645232
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 58.463]
 [ 91.47 ]
 [113.23 ]
 [112.29 ]
 [110.723]] [[0.2  ]
 [1.16 ]
 [1.793]
 [1.766]
 [1.72 ]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  84.98866558074951
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.56435376
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[117.295]
 [128.073]
 [ 93.15 ]
 [ 66.431]
 [115.855]] [[1.517]
 [1.708]
 [1.09 ]
 [0.617]
 [1.491]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  101.36448834855277
printing an ep nov before normalisation:  102.57576344481384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  84.44844174616719
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5772285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.55234987
siam score:  -0.54993796
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  43.01480054855347
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.52991682624324
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  5.01715635870994
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 34.58201231308856
printing an ep nov before normalisation:  86.90251853752906
printing an ep nov before normalisation:  85.42805671691895
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([0.6217, 0.0540, 0.0052, 0.0855, 0.2337], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0228, 0.9275, 0.0181, 0.0069, 0.0247], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0548,     0.9436,     0.0007,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.1338, 0.0006, 0.0112, 0.5400, 0.3143], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2508, 0.0424, 0.0174, 0.2969, 0.3926], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.51245713
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  97.38969802856445
printing an ep nov before normalisation:  90.82185429079144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  109.50706005096437
using explorer policy with actor:  1
printing an ep nov before normalisation:  92.28864908218384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([0.5779, 0.0316, 0.0027, 0.1721, 0.2157], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0055,     0.9732,     0.0174,     0.0002,     0.0038],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0664,     0.9057,     0.0144,     0.0131],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0813,     0.0003,     0.0083,     0.6744,     0.2356],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2514, 0.0536, 0.0260, 0.1454, 0.5236], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.60050946
actions average: 
K:  2  action  0 :  tensor([0.3649, 0.0022, 0.0221, 0.1990, 0.4119], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0165, 0.9390, 0.0033, 0.0162, 0.0250], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0062, 0.0238, 0.9126, 0.0246, 0.0328], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.1127, 0.0022, 0.0655, 0.5473, 0.2724], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2549, 0.0490, 0.0472, 0.2825, 0.3664], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  17.21683547153134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  59.248641552255776
printing an ep nov before normalisation:  120.1587026211287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[128.623]
 [126.183]
 [126.183]
 [126.183]
 [126.183]] [[2.932]
 [2.825]
 [2.825]
 [2.825]
 [2.825]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.61418843
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([0.4931, 0.0074, 0.0404, 0.2206, 0.2385], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0278,     0.9144,     0.0274,     0.0007,     0.0297],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0010,     0.9976,     0.0008,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0520,     0.0005,     0.0762,     0.6832,     0.1881],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2758, 0.0050, 0.0051, 0.2945, 0.4196], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.905]
 [17.392]
 [51.965]
 [25.513]
 [67.659]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.001]
 [30.601]
 [25.593]
 [34.668]
 [34.164]] [[0.653]
 [0.512]
 [0.427]
 [0.58 ]
 [0.572]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[102.476]
 [104.541]
 [102.476]
 [102.476]
 [102.476]] [[2.454]
 [2.512]
 [2.454]
 [2.454]
 [2.454]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([0.5200, 0.0427, 0.0208, 0.1534, 0.2630], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0207, 0.9421, 0.0196, 0.0018, 0.0158], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0028, 0.0287, 0.8841, 0.0467, 0.0377], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.1726,     0.0005,     0.0892,     0.5276,     0.2102],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2867, 0.1282, 0.0692, 0.2254, 0.2906], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([0.6138, 0.0032, 0.0017, 0.1971, 0.1842], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0159, 0.9630, 0.0058, 0.0011, 0.0142], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0021, 0.0229, 0.8710, 0.0435, 0.0605], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.1756, 0.0032, 0.0195, 0.5408, 0.2609], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.3883, 0.0291, 0.0035, 0.1887, 0.3904], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([    0.5446,     0.0095,     0.0005,     0.1441,     0.3013],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0089,     0.9589,     0.0267,     0.0002,     0.0053],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0009,     0.0009,     0.9098,     0.0528,     0.0357],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0992,     0.0002,     0.0006,     0.6467,     0.2533],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2746, 0.0282, 0.0204, 0.1953, 0.4814], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  65.62819181919437
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.435]
 [73.992]
 [56.926]
 [68.821]
 [52.733]] [[0.626]
 [1.586]
 [0.891]
 [1.375]
 [0.72 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  54.508864958321055
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  17.990816831588745
printing an ep nov before normalisation:  21.354510403123186
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([0.5378, 0.0091, 0.0041, 0.1877, 0.2613], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0366, 0.8731, 0.0618, 0.0012, 0.0272], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0011, 0.0018, 0.9448, 0.0271, 0.0252], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.2346, 0.0015, 0.0050, 0.4389, 0.3200], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.2781, 0.0074, 0.0098, 0.2697, 0.4350], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.833]
 [44.777]
 [44.777]
 [44.777]
 [44.777]] [[2.613]
 [2.441]
 [2.441]
 [2.441]
 [2.441]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5932415
using explorer policy with actor:  1
printing an ep nov before normalisation:  71.93262747849029
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  8.96291732788086
siam score:  -0.5958581
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  87.93047703209103
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
siam score:  -0.61537635
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  91.20981824505812
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.51 ]
 [52.28 ]
 [52.28 ]
 [52.28 ]
 [56.208]] [[1.482]
 [1.469]
 [1.469]
 [1.469]
 [1.686]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.333]
 [61.333]
 [76.199]
 [55.925]
 [72.994]] [[0.791]
 [0.791]
 [1.365]
 [0.583]
 [1.241]]
actions average: 
K:  1  action  0 :  tensor([0.5791, 0.0090, 0.0009, 0.1109, 0.3001], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0135,     0.9134,     0.0656,     0.0005,     0.0070],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0018,     0.0000,     0.9337,     0.0360,     0.0284],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.1366,     0.0001,     0.0457,     0.5532,     0.2644],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2405, 0.0228, 0.1573, 0.1766, 0.4027], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([0.5970, 0.0155, 0.0017, 0.1086, 0.2771], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0010,     0.9960,     0.0012,     0.0002,     0.0015],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0102, 0.0029, 0.9318, 0.0353, 0.0198], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.1873, 0.0041, 0.0007, 0.4840, 0.3238], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2170, 0.0301, 0.0023, 0.3062, 0.4444], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5641209
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  22.313219818360608
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([0.5150, 0.0007, 0.0011, 0.0587, 0.4245], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0207,     0.9108,     0.0190,     0.0006,     0.0489],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0012,     0.0003,     0.9759,     0.0068,     0.0158],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.1140,     0.0002,     0.1630,     0.5032,     0.2195],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2822, 0.0174, 0.0120, 0.2635, 0.4249], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6108928
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.60393685
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([0.4895, 0.0046, 0.0013, 0.2159, 0.2886], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0183, 0.9493, 0.0031, 0.0050, 0.0243], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0141, 0.0153, 0.9437, 0.0049, 0.0220], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1047, 0.0006, 0.0078, 0.5583, 0.3287], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.1644, 0.0783, 0.0159, 0.2815, 0.4599], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  85.79817803717762
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
siam score:  -0.6029892
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.292 0.375 0.208 0.042 0.083]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  48.78143787384033
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[107.286]
 [107.286]
 [107.286]
 [107.286]
 [107.286]] [[1.63]
 [1.63]
 [1.63]
 [1.63]
 [1.63]]
siam score:  -0.63079876
printing an ep nov before normalisation:  0.3386629004429172
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.086]
 [82.695]
 [77.871]
 [72.226]
 [52.849]] [[0.795]
 [1.513]
 [1.383]
 [1.23 ]
 [0.707]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  17.63809718524091
siam score:  -0.64066106
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  59.85081380688205
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.631457
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  134.09864664750117
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  96.772319171734
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([0.5213, 0.0015, 0.0220, 0.2244, 0.2307], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0042,     0.9891,     0.0010,     0.0002,     0.0055],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0007,     0.0001,     0.9859,     0.0082,     0.0052],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0867, 0.0229, 0.0911, 0.5754, 0.2240], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2356, 0.0203, 0.0069, 0.2522, 0.4850], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
siam score:  -0.6312545
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  119.8413576873893
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  101.37112617492676
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6376881
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.6267,     0.0005,     0.0003,     0.0968,     0.2756],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0258,     0.9116,     0.0169,     0.0006,     0.0450],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0007,     0.0002,     0.9920,     0.0029,     0.0043],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0765, 0.0013, 0.0894, 0.4985, 0.3344], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2764, 0.0021, 0.0052, 0.1574, 0.5589], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  10.200786919261157
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6328425
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  107.38331930977958
using explorer policy with actor:  1
printing an ep nov before normalisation:  88.7117862701416
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
STARTED EXPV TRAINING ON FRAME NO.  20015
Starting evaluation
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  82.5390629193283
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6113268
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.   0.   0.25 0.75 0.  ]
actions average: 
K:  1  action  0 :  tensor([    0.5375,     0.0002,     0.0002,     0.1637,     0.2983],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0082, 0.9536, 0.0078, 0.0050, 0.0255], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0004,     0.9981,     0.0009,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1648, 0.0007, 0.0021, 0.4519, 0.3805], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.3125, 0.0206, 0.0119, 0.1220, 0.5330], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.6934,     0.0144,     0.0002,     0.0705,     0.2214],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0091, 0.9540, 0.0126, 0.0025, 0.0218], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9988,     0.0007,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.1096, 0.0126, 0.0128, 0.6090, 0.2560], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2666, 0.0109, 0.0087, 0.3549, 0.3590], grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.7284,     0.0018,     0.0003,     0.1131,     0.1564],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0182,     0.9763,     0.0002,     0.0001,     0.0051],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0012, 0.0262, 0.8680, 0.0585, 0.0460], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.1501, 0.0074, 0.0414, 0.6365, 0.1645], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2832, 0.0603, 0.0066, 0.2639, 0.3860], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.679]
 [74.679]
 [74.679]
 [74.679]
 [74.679]] [[1.392]
 [1.392]
 [1.392]
 [1.392]
 [1.392]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  13.627022351054547
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  86.71727710300021
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  82.54330198214468
actions average: 
K:  0  action  0 :  tensor([0.5158, 0.0005, 0.0028, 0.2062, 0.2748], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0015,     0.9848,     0.0005,     0.0007,     0.0125],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0003,     0.0400,     0.9467,     0.0031,     0.0099],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.2581, 0.0006, 0.0421, 0.3423, 0.3569], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.3277, 0.0326, 0.0100, 0.2383, 0.3914], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5938135
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  20015
siam score:  -0.6132392
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.444]
 [25.193]
 [33.596]
 [19.24 ]
 [33.596]] [[0.523]
 [1.276]
 [2.   ]
 [0.764]
 [2.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.10025702030121
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  76.71408562650632
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 78.297]
 [104.294]
 [115.179]
 [ 72.364]
 [ 85.227]] [[0.435]
 [0.733]
 [0.858]
 [0.367]
 [0.514]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  98.75383076786815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.417 0.25  0.208 0.042 0.083]
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  39.27101532513806
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.6845,     0.0336,     0.0002,     0.0952,     0.1865],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0012, 0.9935, 0.0018, 0.0011, 0.0023], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.9813,     0.0103,     0.0083],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.1937,     0.0001,     0.0442,     0.3767,     0.3853],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2874, 0.0146, 0.0039, 0.2083, 0.4858], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 49.026190466409595
printing an ep nov before normalisation:  78.50536618913924
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([0.5224, 0.0259, 0.0057, 0.1150, 0.3311], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.1026, 0.7414, 0.0881, 0.0084, 0.0595], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0120,     0.9832,     0.0011,     0.0036],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.1636, 0.0059, 0.1045, 0.4824, 0.2435], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2924, 0.0222, 0.0450, 0.2187, 0.4217], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  77.34697020954664
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6235524
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.167 0.208 0.333 0.208 0.083]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.6260433
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  97.7157751719157
printing an ep nov before normalisation:  84.12574696197262
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.61932313
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.61575663
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.62496102424791
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.6303348
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.7606,     0.0072,     0.0006,     0.0480,     0.1837],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0031,     0.9453,     0.0190,     0.0004,     0.0322],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0003,     0.0002,     0.9793,     0.0065,     0.0137],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.1714, 0.0036, 0.0224, 0.4913, 0.3113], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.1536, 0.0767, 0.0065, 0.2917, 0.4715], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  81.99593164660838
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.42106833871014
printing an ep nov before normalisation:  4.33379234110248
siam score:  -0.57180744
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  69.88186247377897
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6022259
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([0.6220, 0.0043, 0.0013, 0.1212, 0.2512], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0017,     0.9828,     0.0003,     0.0001,     0.0150],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0004,     0.0153,     0.9512,     0.0077,     0.0254],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.1572,     0.0005,     0.0157,     0.5364,     0.2903],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.3115, 0.1030, 0.0023, 0.1794, 0.4038], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [1.]
 [1.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [1.]
 [1.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  117.5105346324888
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  113.73168093532021
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  90.33196650310043
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6362732
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.6351714
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([0.5642, 0.0049, 0.0008, 0.1380, 0.2922], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0149, 0.9618, 0.0053, 0.0014, 0.0165], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0479,     0.9102,     0.0273,     0.0144],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.1684,     0.0005,     0.0450,     0.5268,     0.2593],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2785, 0.0351, 0.0912, 0.2621, 0.3331], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  69.60836317202882
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  83.67165984552014
siam score:  -0.6249283
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.7042,     0.0006,     0.0004,     0.0850,     0.2098],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0050, 0.9315, 0.0162, 0.0038, 0.0435], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0004,     0.0004,     0.9688,     0.0120,     0.0184],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.1257,     0.0004,     0.0007,     0.6559,     0.2173],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.3031, 0.0010, 0.0012, 0.3082, 0.3865], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 83.98 ]
 [ 83.98 ]
 [ 83.98 ]
 [ 95.786]
 [113.559]] [[0.419]
 [0.419]
 [0.419]
 [0.572]
 [0.803]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  75.04193445682743
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  125.26028098831961
printing an ep nov before normalisation:  0.04204664755889098
actions average: 
K:  1  action  0 :  tensor([0.5749, 0.0016, 0.0010, 0.1446, 0.2779], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9994,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0019, 0.0425, 0.9410, 0.0060, 0.0087], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1090, 0.0040, 0.0019, 0.6420, 0.2431], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.3293, 0.0042, 0.0018, 0.2339, 0.4308], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.6678,     0.0054,     0.0005,     0.0820,     0.2443],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0007,     0.9940,     0.0005,     0.0001,     0.0047],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0006,     0.0023,     0.9572,     0.0118,     0.0282],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.3557, 0.0009, 0.0006, 0.4264, 0.2164], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2083, 0.0012, 0.0006, 0.3121, 0.4779], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.243976354598999
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  74.3536400030946
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.615]
 [92.681]
 [84.615]
 [84.615]
 [84.615]] [[2.503]
 [3.   ]
 [2.503]
 [2.503]
 [2.503]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  100.77109336853027
printing an ep nov before normalisation:  63.53143459288191
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.125 0.167 0.125 0.375 0.208]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.5204,     0.0005,     0.0025,     0.1744,     0.3023],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0052,     0.9749,     0.0111,     0.0009,     0.0080],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0035,     0.9690,     0.0149,     0.0125],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1741, 0.0024, 0.0050, 0.5141, 0.3045], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.3540, 0.0009, 0.0030, 0.2188, 0.4233], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  53.63248825073242
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.919]
 [88.862]
 [99.564]
 [91.043]
 [96.825]] [[0.5  ]
 [0.617]
 [0.87 ]
 [0.668]
 [0.805]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.806]
 [27.042]
 [25.363]
 [26.012]
 [30.609]] [[0.925]
 [0.718]
 [0.592]
 [0.641]
 [0.985]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  0.659069110511723
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.63258266
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  71.67490469345952
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  63.65133471331801
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 99.236]
 [102.795]
 [ 86.388]
 [ 84.14 ]
 [103.242]] [[0.572]
 [0.623]
 [0.388]
 [0.356]
 [0.629]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.64060104
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  99.10776292347727
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  147.1317729230734
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 13.722592897534888
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.214]
 [88.682]
 [70.13 ]
 [69.283]
 [71.73 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  48.40063167271831
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
actions average: 
K:  4  action  0 :  tensor([    0.6687,     0.0031,     0.0002,     0.0642,     0.2638],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0654,     0.9302,     0.0007,     0.0002,     0.0036],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0009,     0.0114,     0.9639,     0.0184,     0.0054],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.1656, 0.0006, 0.0017, 0.5554, 0.2767], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2924, 0.0774, 0.0369, 0.1839, 0.4093], grad_fn=<DivBackward0>)
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 2.8438583181719257e-11
0.0 0.0
0.0 2.1484623033094317e-10
0.0 7.004471462846891e-10
0.0 0.0
0.0 0.0
0.0 0.0
0.0 4.133627632456866e-10
0.0 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  52.13523864746094
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6239167
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  144.3962083289048
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.645747
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  38.5608434677124
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.64657044
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  126.22445424397786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  2  action  0 :  tensor([0.6711, 0.0030, 0.0010, 0.1005, 0.2243], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0014,     0.9891,     0.0078,     0.0003,     0.0014],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0025,     0.0003,     0.9878,     0.0057,     0.0037],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.1835,     0.0005,     0.0008,     0.6165,     0.1988],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2694, 0.0674, 0.0034, 0.2694, 0.3904], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  89.14634431783578
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6386483
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  69.38108265316684
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.64479417
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  74.1353662795569
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.791]
 [71.511]
 [65.994]
 [49.921]
 [60.706]] [[1.562]
 [1.637]
 [1.395]
 [0.691]
 [1.164]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.753]
 [66.124]
 [60.093]
 [46.859]
 [60.093]] [[1.805]
 [1.775]
 [1.487]
 [0.854]
 [1.487]]
printing an ep nov before normalisation:  20.58593511581421
printing an ep nov before normalisation:  11.957290172576904
siam score:  -0.64189285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6442162
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  107.12948329799181
actions average: 
K:  0  action  0 :  tensor([0.5285, 0.0007, 0.0011, 0.1304, 0.3393], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0152, 0.9266, 0.0214, 0.0096, 0.0272], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0018,     0.9661,     0.0202,     0.0117],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1795, 0.0006, 0.0081, 0.4859, 0.3258], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.3039, 0.0351, 0.0058, 0.2490, 0.4062], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  37.20345735549927
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  63.652389051343654
printing an ep nov before normalisation:  69.80909310198209
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  74.00533910279748
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  76.79083110048833
siam score:  -0.594246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [   -0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 0.0
0.0 0.0
0.0 0.0
0.0 0.0
0.0 0.0
0.0 0.0
0.0 1.9374217194543677e-12
0.0 0.0
0.0 0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 8.477]
 [12.582]
 [ 8.753]
 [ 7.391]
 [ 8.363]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  6.587613239847849
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 6.189]
 [11.799]
 [ 6.189]
 [ 6.189]
 [ 6.189]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  86.42712640822872
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([0.6373, 0.0578, 0.0020, 0.0815, 0.2214], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0022, 0.9638, 0.0207, 0.0020, 0.0113], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0004,     0.9976,     0.0011,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1030, 0.0011, 0.0384, 0.5970, 0.2606], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.1862, 0.0600, 0.0253, 0.2545, 0.4740], grad_fn=<DivBackward0>)
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 1.010227041204798e-11
0.0 1.0569327430638306e-11
0.0 0.0
0.0 1.327652831068636e-12
0.0 0.0
0.0 1.5291792876339378e-11
0.0 1.7211916198012937e-11
0.0 1.1295860580468194e-11
0.0 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  65.90182627666356
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  39.69090938568115
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Sims:  25 1 epoch:  31538 pick best:  False frame count:  31538
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 69.536]
 [ 88.515]
 [103.533]
 [ 88.515]
 [ 94.903]] [[1.389]
 [2.111]
 [2.682]
 [2.111]
 [2.354]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.842]
 [29.842]
 [29.842]
 [29.842]
 [29.842]] [[2.002]
 [2.002]
 [2.002]
 [2.002]
 [2.002]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  76.21529296692972
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([0.6927, 0.0188, 0.0022, 0.0419, 0.2444], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0007,     0.9631,     0.0018,     0.0006,     0.0338],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0080,     0.9867,     0.0021,     0.0030],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.1383,     0.0001,     0.0036,     0.5288,     0.3292],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.1836, 0.0036, 0.0316, 0.2461, 0.5351], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  96.81200336421973
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.6171,     0.0004,     0.0003,     0.1204,     0.2617],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0019,     0.9685,     0.0012,     0.0001,     0.0284],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0036,     0.9705,     0.0130,     0.0127],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.1037,     0.0006,     0.0097,     0.6023,     0.2838],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2021, 0.0009, 0.0038, 0.3481, 0.4452], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  83.29957261024957
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  119.46162232861694
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.343]
 [79.343]
 [79.343]
 [79.343]
 [79.343]] [[0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.898]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.6170,     0.0008,     0.0006,     0.1356,     0.2460],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0348, 0.9420, 0.0020, 0.0020, 0.0192], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0009,     0.9852,     0.0033,     0.0106],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1948, 0.0039, 0.0411, 0.4446, 0.3156], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2364, 0.0191, 0.0351, 0.2190, 0.4904], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  113.79470010719366
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.538]
 [30.954]
 [29.847]
 [25.021]
 [26.502]] [[1.678]
 [1.647]
 [1.588]
 [1.329]
 [1.409]]
printing an ep nov before normalisation:  77.49046357521472
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
printing an ep nov before normalisation:  75.47712828550672
printing an ep nov before normalisation:  67.62127894980293
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  68.83280199328097
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6459062
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6375029
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.6267682
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  109.7839245354981
printing an ep nov before normalisation:  113.38816370700741
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[146.945]
 [144.06 ]
 [144.06 ]
 [144.06 ]
 [144.06 ]] [[3.  ]
 [2.89]
 [2.89]
 [2.89]
 [2.89]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([0.6699, 0.0008, 0.0007, 0.1167, 0.2119], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0022,     0.9819,     0.0040,     0.0002,     0.0118],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0006,     0.0182,     0.9251,     0.0264,     0.0297],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.1017,     0.0002,     0.0366,     0.5853,     0.2762],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.3100,     0.0003,     0.0759,     0.2270,     0.3868],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.6932,     0.0007,     0.0003,     0.1098,     0.1961],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0040,     0.9662,     0.0059,     0.0003,     0.0237],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0011, 0.0049, 0.9750, 0.0064, 0.0127], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.1963,     0.0004,     0.0034,     0.4984,     0.3015],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.1975, 0.0011, 0.0153, 0.3291, 0.4570], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  11.074426118284464
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  84.22531196878936
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [27.259]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[-0.002]
 [ 0.711]
 [-0.002]
 [-0.002]
 [-0.002]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.6961,     0.0104,     0.0004,     0.1277,     0.1654],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0149,     0.9629,     0.0015,     0.0002,     0.0204],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0006,     0.0068,     0.9737,     0.0063,     0.0126],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.1620, 0.0218, 0.0198, 0.5659, 0.2305], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.3538, 0.0023, 0.0465, 0.1922, 0.4051], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6412004
actions average: 
K:  3  action  0 :  tensor([    0.5421,     0.0003,     0.0005,     0.1202,     0.3368],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0029,     0.9942,     0.0010,     0.0002,     0.0017],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0006,     0.0250,     0.9167,     0.0483,     0.0093],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.2303,     0.0004,     0.0021,     0.4721,     0.2951],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2963, 0.0005, 0.0065, 0.3324, 0.3643], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [1. 0. 0. 0. 0.]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  108.2389884872697
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  126.44881248474121
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6461142
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  87.52718774261727
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  96.53087795579407
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  123.42755849487352
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  131.64274729258773
printing an ep nov before normalisation:  95.72764211222278
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  65.1102916557852
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  1.856741968893516
printing an ep nov before normalisation:  1.9915004325919687
actions average: 
K:  3  action  0 :  tensor([0.5878, 0.0014, 0.0010, 0.1199, 0.2899], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0005,     0.9968,     0.0015,     0.0001,     0.0012],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0006,     0.0047,     0.9742,     0.0017,     0.0188],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.1374,     0.0003,     0.0045,     0.5711,     0.2866],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1868, 0.0097, 0.0182, 0.2150, 0.5704], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.914]
 [35.788]
 [40.466]
 [26.914]
 [25.656]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  96.96289300918579
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([    0.6220,     0.0019,     0.0004,     0.0902,     0.2855],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0031,     0.9948,     0.0003,     0.0002,     0.0016],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0006,     0.0024,     0.9837,     0.0070,     0.0063],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.1486,     0.0006,     0.0015,     0.6565,     0.1928],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.3018, 0.0375, 0.0704, 0.2204, 0.3698], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[123.506]
 [123.506]
 [123.506]
 [123.506]
 [123.506]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.125 0.375 0.125 0.208 0.167]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  87.28452072163294
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  97.11049700584952
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  78.61911296844482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.6348533
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6348374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  5.034255288247873
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 33.8588140643256
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  133.25213502401812
printing an ep nov before normalisation:  126.97064291730226
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  122.17790084004811
printing an ep nov before normalisation:  103.2593187248364
printing an ep nov before normalisation:  86.83733301712894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 94.383]
 [114.278]
 [ 84.174]
 [ 79.772]
 [ 83.989]] [[0.561]
 [0.785]
 [0.447]
 [0.397]
 [0.445]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  89.62253732328682
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.6410583
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  2.9510225418783875
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.7416,     0.0020,     0.0003,     0.1106,     0.1455],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0005,     0.9870,     0.0014,     0.0048,     0.0062],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9968,     0.0020,     0.0012],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0073,     0.0000,     0.0102,     0.7496,     0.2329],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.1353, 0.0630, 0.0636, 0.2012, 0.5369], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([0.5787, 0.0017, 0.0010, 0.1857, 0.2329], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0019,     0.9813,     0.0010,     0.0004,     0.0153],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0000,     0.9506,     0.0343,     0.0147],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0470,     0.0003,     0.0036,     0.7088,     0.2402],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.1828, 0.0007, 0.0536, 0.3149, 0.4481], grad_fn=<DivBackward0>)
actions average: 
K:  0  action  0 :  tensor([0.5947, 0.0013, 0.0011, 0.1494, 0.2536], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0009,     0.9812,     0.0049,     0.0005,     0.0125],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0000,     0.9613,     0.0285,     0.0101],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1977, 0.0006, 0.0043, 0.5142, 0.2831], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.3196, 0.0012, 0.0039, 0.2721, 0.4032], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  90.65378038989954
actions average: 
K:  3  action  0 :  tensor([    0.7089,     0.0004,     0.0012,     0.1093,     0.1802],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0439, 0.8874, 0.0036, 0.0092, 0.0559], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0002,     0.8820,     0.0886,     0.0292],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0068, 0.0008, 0.0518, 0.7264, 0.2141], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.3082, 0.0038, 0.0079, 0.1707, 0.5094], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
rdn beta is 0 so we're just using the maxi policy
UNIT TEST: sample policy line 217 mcts : [0.083 0.167 0.125 0.458 0.167]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  96.33910759879912
siam score:  -0.641237
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.64093107
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 97.34914110160298
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  113.83262361798968
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.6372934
printing an ep nov before normalisation:  121.0391013093963
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
printing an ep nov before normalisation:  11.141315161356147
printing an ep nov before normalisation:  84.26946231297084
printing an ep nov before normalisation:  109.68134995915804
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.167 0.125 0.25  0.083 0.375]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  0.5327293611507855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [94.774]
 [ 0.   ]
 [ 0.   ]] [[-1.678]
 [-1.678]
 [ 1.498]
 [-1.678]
 [-1.678]]
printing an ep nov before normalisation:  97.46657904470872
printing an ep nov before normalisation:  23.38777302175277
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.645]
 [47.821]
 [39.22 ]
 [64.645]
 [64.645]] [[3.   ]
 [1.934]
 [1.389]
 [3.   ]
 [3.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6148763
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  80.15545436314174
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.125 0.125 0.333 0.292 0.125]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[105.423]
 [106.611]
 [105.423]
 [105.423]
 [105.423]] [[2.275]
 [2.323]
 [2.275]
 [2.275]
 [2.275]]
printing an ep nov before normalisation:  44.236512786570756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.61683005
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  57.31459140777588
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  96.84935490764776
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  106.7920095788379
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  5.599744109590574
actions average: 
K:  0  action  0 :  tensor([    0.6059,     0.0003,     0.0008,     0.1352,     0.2579],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0019,     0.9781,     0.0003,     0.0009,     0.0188],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0002,     0.9971,     0.0015,     0.0012],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1150, 0.0009, 0.0081, 0.5233, 0.3527], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.1684, 0.0023, 0.0107, 0.2397, 0.5789], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  91.73099604434034
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  57.13378874177622
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.64219457
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.6692,     0.0017,     0.0006,     0.1488,     0.1796],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0033,     0.9888,     0.0030,     0.0006,     0.0043],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0033,     0.9862,     0.0041,     0.0062],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1652, 0.0007, 0.0320, 0.5300, 0.2722], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.1578, 0.0014, 0.0426, 0.3068, 0.4914], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
siam score:  -0.64283615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6428106
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.23 ]
 [90.243]
 [84.23 ]
 [61.783]
 [73.594]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6242278
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  43.351492419381245
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 89.691]
 [104.057]
 [ 89.691]
 [ 84.243]
 [ 88.553]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  8.722172379493713
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.6672,     0.0003,     0.0003,     0.1171,     0.2151],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0079,     0.9897,     0.0001,     0.0008,     0.0014],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0026, 0.0147, 0.9102, 0.0587, 0.0138], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.1898,     0.0005,     0.0003,     0.5356,     0.2738],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.3270,     0.0105,     0.0004,     0.2578,     0.4044],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 99.025]
 [120.79 ]
 [ 99.025]
 [ 99.025]
 [ 99.025]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  107.91199528052431
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  126.58785985366121
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.7682,     0.0013,     0.0003,     0.0581,     0.1721],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0059, 0.9743, 0.0061, 0.0023, 0.0114], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0059,     0.0003,     0.8937,     0.0469,     0.0533],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.1771,     0.0004,     0.0018,     0.5949,     0.2258],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.3217,     0.0004,     0.0078,     0.2280,     0.4421],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[125.473]
 [125.473]
 [ 79.831]
 [125.473]
 [125.473]] [[1.884]
 [1.884]
 [0.663]
 [1.884]
 [1.884]]
printing an ep nov before normalisation:  130.17213821411133
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([    0.5968,     0.0102,     0.0006,     0.1321,     0.2603],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0016,     0.9883,     0.0035,     0.0003,     0.0062],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0007,     0.0056,     0.9074,     0.0385,     0.0477],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.1646, 0.0095, 0.0007, 0.5641, 0.2610], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2617, 0.0014, 0.0015, 0.3293, 0.4062], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.6253,     0.0678,     0.0002,     0.0546,     0.2521],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0014,     0.9937,     0.0005,     0.0002,     0.0041],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0399, 0.0462, 0.8757, 0.0104, 0.0278], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.1353, 0.1149, 0.0955, 0.4666, 0.1877], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2933, 0.0022, 0.0016, 0.2642, 0.4387], grad_fn=<DivBackward0>)
siam score:  -0.6558631
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  90.05173634611909
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  2.046700745421788
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  101.4348030090332
printing an ep nov before normalisation:  91.70000265872437
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.875]
 [26.795]
 [31.249]
 [32.875]
 [20.688]] [[1.485]
 [1.094]
 [1.381]
 [1.485]
 [0.7  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.63476145
printing an ep nov before normalisation:  111.97642333695795
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 94.627]
 [106.06 ]
 [101.054]
 [101.054]
 [ 95.359]] [[1.748]
 [2.176]
 [1.989]
 [1.989]
 [1.775]]
printing an ep nov before normalisation:  35.23397828313885
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.63592523
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  100.56696604470571
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.1119671673582919
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 83.121]
 [103.087]
 [103.84 ]
 [113.801]
 [114.303]] [[1.499]
 [2.274]
 [2.304]
 [2.69 ]
 [2.71 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  79.47306102921347
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 80.267]
 [130.744]
 [ 80.267]
 [ 80.267]
 [ 80.267]] [[0.835]
 [1.835]
 [0.835]
 [0.835]
 [0.835]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.   ]
 [81.047]
 [77.396]
 [74.073]
 [80.33 ]] [[1.777]
 [1.495]
 [1.347]
 [1.213]
 [1.466]]
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  103.11059092592079
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.64557475
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6437607
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  100.60264849767965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.64051634
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6304683
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([0.5949, 0.0182, 0.0009, 0.1433, 0.2428], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9852,     0.0086,     0.0034,     0.0025],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.9631,     0.0283,     0.0085],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1462, 0.0018, 0.0170, 0.5641, 0.2708], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.1680, 0.0053, 0.0097, 0.3287, 0.4882], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  88.97695541381836
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6126799
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  115.2027139146904
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.62409616
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.634739
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6310265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.6490,     0.0061,     0.0004,     0.1093,     0.2351],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0063,     0.9863,     0.0006,     0.0003,     0.0065],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0008,     0.9965,     0.0013,     0.0014],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1785, 0.0021, 0.0191, 0.4663, 0.3340], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.3120, 0.0031, 0.0020, 0.1300, 0.5529], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
actions average: 
K:  3  action  0 :  tensor([0.5436, 0.0010, 0.0012, 0.1217, 0.3325], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0030,     0.9937,     0.0016,     0.0002,     0.0016],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0115,     0.9602,     0.0232,     0.0050],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0580,     0.0002,     0.0068,     0.7209,     0.2140],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1894, 0.0338, 0.0270, 0.3527, 0.3971], grad_fn=<DivBackward0>)
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  0.14927681192678696
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.63996273
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  83.10549326166611
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  104.8401327308552
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 84.17502219437173
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.6252129
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.543]
 [51.608]
 [43.732]
 [46.064]
 [49.336]] [[0.698]
 [0.674]
 [0.469]
 [0.53 ]
 [0.615]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.137]
 [80.714]
 [82.63 ]
 [75.802]
 [80.738]] [[1.545]
 [1.985]
 [2.033]
 [1.862]
 [1.986]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  111.407918007454
printing an ep nov before normalisation:  114.91982845141415
printing an ep nov before normalisation:  122.66511553142641
actions average: 
K:  3  action  0 :  tensor([    0.6830,     0.0107,     0.0006,     0.1252,     0.1805],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0316, 0.8975, 0.0264, 0.0057, 0.0387], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0004,     0.0577,     0.8228,     0.0139,     0.1052],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0582,     0.0004,     0.0985,     0.6216,     0.2213],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.4297, 0.0216, 0.0017, 0.0708, 0.4762], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  136.55176811312023
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  82.44993720813697
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  84.45392322871723
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([0.6561, 0.0342, 0.0008, 0.1121, 0.1968], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0018,     0.9956,     0.0003,     0.0001,     0.0021],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0030,     0.9347,     0.0425,     0.0196],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.1001,     0.0001,     0.0011,     0.6434,     0.2552],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2505, 0.0346, 0.0022, 0.2596, 0.4530], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  90.7184681417639
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  131.3558096266126
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  95.7920494514107
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  86.24765859855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  132.39481074439107
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  94.80527877807617
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  94.73209506447091
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.33957969596713
printing an ep nov before normalisation:  34.02672052383423
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  9.313803240556808
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  1.1170601030798366
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  16.965177059173584
printing an ep nov before normalisation:  98.16179099738821
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.8796,     0.0085,     0.0005,     0.0032,     0.1082],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0047, 0.9746, 0.0062, 0.0043, 0.0102], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0074,     0.9877,     0.0012,     0.0035],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0691, 0.0029, 0.1073, 0.6318, 0.1889], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.3295, 0.0556, 0.0022, 0.1764, 0.4363], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  128.73879270315507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6359241
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  7.911029124994684
printing an ep nov before normalisation:  59.064595957037696
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6062188
printing an ep nov before normalisation:  1.227394204990162
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  71.61884976865221
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  0.05051031274803108
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.517]
 [39.553]
 [37.884]
 [37.978]
 [37.931]] [[1.543]
 [1.642]
 [1.483]
 [1.492]
 [1.488]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.24631404876709
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6276604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.63186926
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  110.39981230595902
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  80.61498199055013
using explorer policy with actor:  1
siam score:  -0.6494579
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.64801985
printing an ep nov before normalisation:  4.054293253093988
siam score:  -0.6533089
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  103.87685639517649
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  61.68877220333187
siam score:  -0.6556007
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  87.5281499455964
UNIT TEST: sample policy line 217 mcts : [0.25  0.417 0.125 0.083 0.125]
printing an ep nov before normalisation:  99.55985589783258
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 0.00452060110929627
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  95.4771900177002
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  29.44512091588308
printing an ep nov before normalisation:  12.732343673706055
printing an ep nov before normalisation:  0.6721667013563604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 41.89790755639274
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
UNIT TEST: sample policy line 217 mcts : [1. 0. 0. 0. 0.]
printing an ep nov before normalisation:  32.61979037803446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  69.4687631395128
actions average: 
K:  4  action  0 :  tensor([0.7438, 0.0042, 0.0012, 0.0675, 0.1834], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0005,     0.9981,     0.0007,     0.0000,     0.0006],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0404,     0.9570,     0.0007,     0.0018],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.1368, 0.0061, 0.0024, 0.4559, 0.3989], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2656, 0.0167, 0.0028, 0.2458, 0.4691], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  101.72764838988267
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  72.27284466339103
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  60.62435917619843
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  83.38806000302756
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.065]
 [84.8  ]
 [82.34 ]
 [78.964]
 [82.095]] [[1.137]
 [1.061]
 [1.004]
 [0.926]
 [0.998]]
siam score:  -0.6474928
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Starting evaluation
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.8219,     0.0224,     0.0003,     0.0301,     0.1253],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0006,     0.9895,     0.0043,     0.0008,     0.0049],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0015, 0.0103, 0.9399, 0.0024, 0.0459], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.1497,     0.0002,     0.0005,     0.5813,     0.2682],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2599, 0.0850, 0.0537, 0.1248, 0.4766], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  99.1792866361938
printing an ep nov before normalisation:  65.49299509186098
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.6022,     0.0008,     0.0004,     0.1423,     0.2543],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0061,     0.9870,     0.0003,     0.0017,     0.0049],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0003,     0.0322,     0.8765,     0.0166,     0.0743],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0700,     0.0001,     0.0057,     0.6843,     0.2398],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2642, 0.0100, 0.1364, 0.2154, 0.3740], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.6481347
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  21.460518836975098
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([0.5016, 0.0008, 0.0005, 0.1487, 0.3484], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0006,     0.9947,     0.0035,     0.0000,     0.0013],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0003,     0.9746,     0.0199,     0.0051],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0798, 0.0007, 0.0049, 0.5941, 0.3206], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2527, 0.0016, 0.0033, 0.2257, 0.5167], grad_fn=<DivBackward0>)
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6127995
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.60556734
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 90.463]
 [111.132]
 [ 72.457]
 [ 78.146]
 [ 82.672]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  105.00219266126275
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.417 0.333 0.083 0.125 0.042]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[141.046]
 [141.046]
 [141.046]
 [141.046]
 [141.046]] [[0.96]
 [0.96]
 [0.96]
 [0.96]
 [0.96]]
printing an ep nov before normalisation:  2.592332034282663
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.64820325
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[123.629]
 [102.1  ]
 [112.659]
 [ 92.004]
 [125.722]] [[2.366]
 [1.76 ]
 [2.057]
 [1.476]
 [2.425]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  42.946105003356934
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6412723
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  104.20951843261719
actions average: 
K:  2  action  0 :  tensor([    0.8697,     0.0002,     0.0002,     0.0531,     0.0767],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0271,     0.9710,     0.0001,     0.0001,     0.0017],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9266,     0.0332,     0.0401],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.1564, 0.0006, 0.0015, 0.5509, 0.2906], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.3146, 0.0729, 0.0054, 0.2421, 0.3651], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  0.06789840054807428
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.65071213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[129.407]
 [129.407]
 [129.407]
 [129.407]
 [129.407]] [[1.5]
 [1.5]
 [1.5]
 [1.5]
 [1.5]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[81.67 ]
 [86.387]
 [97.481]
 [99.908]
 [90.184]] [[0.748]
 [0.879]
 [1.189]
 [1.257]
 [0.985]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  1.56199660122752
printing an ep nov before normalisation:  84.02595520019531
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.296]
 [21.814]
 [26.254]
 [21.816]
 [22.883]] [[0.293]
 [0.301]
 [0.364]
 [0.301]
 [0.316]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [12.123]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[-0.005]
 [ 0.376]
 [-0.005]
 [-0.005]
 [-0.005]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.8229,     0.0005,     0.0001,     0.0012,     0.1753],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0005,     0.9802,     0.0145,     0.0002,     0.0046],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0022, 0.0063, 0.9816, 0.0017, 0.0083], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1102, 0.0009, 0.0204, 0.6465, 0.2220], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2452, 0.0011, 0.0277, 0.2290, 0.4970], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.6515045
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  126.76797409298051
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  92.10737894323387
printing an ep nov before normalisation:  100.20429066249304
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.65342003
printing an ep nov before normalisation:  79.64788802414131
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  114.21459927684651
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  2.833892853587372
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6491664
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  127.05007142428069
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.625539
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6270138
printing an ep nov before normalisation:  81.4537271081034
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.407]
 [79.407]
 [79.407]
 [79.407]
 [79.407]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6347481
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6454685
printing an ep nov before normalisation:  109.94599448161782
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 0.0
0.0 0.0
0.0 -4.181890188714567e-12
0.0 -2.0455367738320923e-11
0.0 -2.270416082243189e-12
0.0 -1.17629175972461e-11
0.0 0.0
0.0 0.0
0.0 -1.1494792273963052e-11
0.0 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  0  action  0 :  tensor([0.6333, 0.0064, 0.0007, 0.1317, 0.2279], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0080,     0.9683,     0.0167,     0.0009,     0.0062],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0061,     0.0004,     0.9199,     0.0646,     0.0090],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1624, 0.0005, 0.0166, 0.4667, 0.3539], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.3052, 0.0006, 0.0022, 0.2513, 0.4407], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  118.47994608795887
printing an ep nov before normalisation:  117.91753847815119
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  81.21252059936523
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[103.021]
 [109.915]
 [100.381]
 [ 95.166]
 [ 95.166]] [[0.96 ]
 [1.087]
 [0.911]
 [0.815]
 [0.815]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.7757,     0.0008,     0.0003,     0.0688,     0.1544],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0007,     0.9922,     0.0004,     0.0051,     0.0016],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0338,     0.9587,     0.0005,     0.0069],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0480, 0.0041, 0.0247, 0.6960, 0.2272], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2957, 0.0266, 0.0124, 0.1761, 0.4891], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  84.50563882584565
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  3.095109344305911
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6523743
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 98.666]
 [131.91 ]
 [ 98.666]
 [ 98.666]
 [101.991]] [[1.721]
 [2.874]
 [1.721]
 [1.721]
 [1.836]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[125.933]
 [126.941]
 [112.073]
 [124.441]
 [124.472]] [[1.451]
 [1.466]
 [1.244]
 [1.429]
 [1.43 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  62.97321319580078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.65050447
printing an ep nov before normalisation:  36.649726799585096
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.6743,     0.0018,     0.0006,     0.0647,     0.2586],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0003,     0.9711,     0.0203,     0.0014,     0.0069],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0011, 0.0158, 0.8598, 0.0825, 0.0408], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.1521, 0.0031, 0.1320, 0.5970, 0.1158], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1550, 0.0008, 0.0213, 0.3575, 0.4655], grad_fn=<DivBackward0>)
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.6880,     0.0010,     0.0004,     0.0998,     0.2108],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0152, 0.9306, 0.0082, 0.0029, 0.0431], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0005,     0.0159,     0.9692,     0.0058,     0.0085],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0910, 0.0039, 0.0148, 0.6323, 0.2580], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2927, 0.0283, 0.0476, 0.2227, 0.4088], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  135.85474033934813
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[129.543]
 [129.543]
 [115.348]
 [129.543]
 [129.543]] [[3.   ]
 [3.   ]
 [2.589]
 [3.   ]
 [3.   ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.65]
 [79.84]
 [79.65]
 [79.65]
 [79.65]] [[1.161]
 [1.164]
 [1.161]
 [1.161]
 [1.161]]
printing an ep nov before normalisation:  73.52478698387507
siam score:  -0.64396906
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.6431387
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.648273
printing an ep nov before normalisation:  106.41611653305047
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  28.080757648909184
printing an ep nov before normalisation:  90.28376623364707
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.311]
 [94.701]
 [83.311]
 [83.311]
 [69.238]] [[1.205]
 [1.477]
 [1.205]
 [1.205]
 [0.869]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 95.291]
 [111.685]
 [ 95.291]
 [ 95.291]
 [ 95.291]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 88.947]
 [110.013]
 [ 88.947]
 [ 88.947]
 [ 88.947]] [[1.49 ]
 [2.377]
 [1.49 ]
 [1.49 ]
 [1.49 ]]
printing an ep nov before normalisation:  91.78933777357409
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.7039,     0.0010,     0.0005,     0.0546,     0.2399],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0042,     0.9916,     0.0002,     0.0001,     0.0039],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0007,     0.0011,     0.9631,     0.0288,     0.0063],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0543,     0.0008,     0.0007,     0.6981,     0.2460],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2655, 0.0017, 0.0018, 0.2347, 0.4964], grad_fn=<DivBackward0>)
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 95.059]
 [ 95.059]
 [ 95.059]
 [113.34 ]
 [108.41 ]] [[0.559]
 [0.559]
 [0.559]
 [0.819]
 [0.749]]
printing an ep nov before normalisation:  107.47968673706055
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  100.46693137750235
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([0.6591, 0.0042, 0.0013, 0.0818, 0.2537], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0011,     0.9942,     0.0027,     0.0002,     0.0018],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9667,     0.0142,     0.0190],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0159, 0.0081, 0.0686, 0.5644, 0.3430], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.3273, 0.0060, 0.0017, 0.0557, 0.6093], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.7851,     0.0017,     0.0006,     0.0381,     0.1746],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0015, 0.9806, 0.0088, 0.0014, 0.0076], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0012, 0.0373, 0.9546, 0.0031, 0.0039], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1556, 0.0007, 0.0020, 0.5700, 0.2717], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.1757, 0.0092, 0.0021, 0.2665, 0.5467], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  22.899995349506952
printing an ep nov before normalisation:  4.065197059781411
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  102.83734301094556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  72.91137920367079
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[95.02 ]
 [93.524]
 [98.76 ]
 [87.849]
 [87.849]] [[0.958]
 [0.93 ]
 [1.029]
 [0.822]
 [0.822]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  2.4089814154194755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.63995785
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.8131,     0.0009,     0.0003,     0.0874,     0.0983],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0016,     0.9954,     0.0004,     0.0000,     0.0026],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9950,     0.0006,     0.0042],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0609,     0.0001,     0.0009,     0.7003,     0.2378],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2539, 0.0036, 0.0036, 0.1977, 0.5411], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  122.58828530252197
printing an ep nov before normalisation:  80.07967825614348
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  84.10320811801486
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[96.502]
 [93.187]
 [93.187]
 [93.187]
 [93.187]] [[0.944]
 [0.884]
 [0.884]
 [0.884]
 [0.884]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  75.67216555626908
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.66255736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.193]
 [87.438]
 [89.075]
 [86.325]
 [90.377]] [[2.295]
 [2.261]
 [2.334]
 [2.211]
 [2.393]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  3.30323562177
siam score:  -0.6618231
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6585094
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  101.36481524276239
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  111.97105858520808
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6558833
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[121.517]
 [121.517]
 [108.714]
 [117.384]
 [118.402]] [[1.5  ]
 [1.5  ]
 [1.257]
 [1.421]
 [1.441]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[105.727]
 [105.49 ]
 [109.257]
 [ 82.177]
 [103.851]] [[0.616]
 [0.614]
 [0.652]
 [0.38 ]
 [0.598]]
printing an ep nov before normalisation:  77.6047134399414
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.7417,     0.0006,     0.0003,     0.0746,     0.1828],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0172,     0.9654,     0.0065,     0.0001,     0.0108],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9999,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.1025,     0.0002,     0.0265,     0.6682,     0.2026],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2518, 0.0011, 0.0011, 0.2555, 0.4905], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  80.27677600585221
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.416]
 [93.371]
 [85.416]
 [85.416]
 [85.416]] [[2.251]
 [2.682]
 [2.251]
 [2.251]
 [2.251]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.6737,     0.0058,     0.0005,     0.0990,     0.2209],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0045,     0.9911,     0.0010,     0.0001,     0.0034],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0003,     0.0009,     0.9777,     0.0056,     0.0154],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1554, 0.0010, 0.0016, 0.5772, 0.2648], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.3234, 0.0216, 0.0448, 0.2495, 0.3607], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  74.82198238372803
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.65243894
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.65403944
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.64103556
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  20.76769369427227
printing an ep nov before normalisation:  0.0027778076264439733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  35.059100622323776
printing an ep nov before normalisation:  120.41170597076416
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  2.4125821035261197
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([0.6198, 0.0011, 0.0013, 0.1059, 0.2720], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9872,     0.0031,     0.0011,     0.0083],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0009,     0.9734,     0.0200,     0.0055],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0973, 0.0013, 0.0013, 0.6590, 0.2410], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.1947, 0.0029, 0.0568, 0.3410, 0.4046], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  77.53321783883231
printing an ep nov before normalisation:  92.88010671495054
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  105.74446979964826
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  82.55451707154367
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  83.9885406346455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  81.48445780737279
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.083 0.292 0.125 0.333 0.167]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  7.212425213809581
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  115.48211369603105
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
siam score:  -0.65878433
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  81.13219261169434
printing an ep nov before normalisation:  84.98557322981472
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  39.149556159973145
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  1.564407345285872
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[98.409]
 [98.409]
 [98.409]
 [98.409]
 [98.409]] [[1.351]
 [1.351]
 [1.351]
 [1.351]
 [1.351]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  102.11772918701172
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  82.33166020965675
siam score:  -0.66823167
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 78.04339993828285
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  83.88552648857518
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6705037
printing an ep nov before normalisation:  86.8675439884158
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[109.692]
 [109.692]
 [109.692]
 [109.692]
 [109.692]] [[2.421]
 [2.421]
 [2.421]
 [2.421]
 [2.421]]
siam score:  -0.66800904
siam score:  -0.6694217
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.51 ]
 [96.366]
 [95.005]
 [76.325]
 [95.698]] [[2.362]
 [2.5  ]
 [2.434]
 [1.531]
 [2.468]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  106.40389755791129
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6524078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
siam score:  -0.64061034
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.63696367
siam score:  -0.63600993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.415]
 [51.415]
 [51.415]
 [51.415]
 [51.415]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.65218335
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  95.96821951136697
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  55.13171146203993
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  121.6976321371332
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6574225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[134.746]
 [134.746]
 [134.746]
 [134.746]
 [134.746]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 94.989]
 [108.462]
 [ 94.989]
 [ 94.989]
 [ 94.989]] [[2.181]
 [2.713]
 [2.181]
 [2.181]
 [2.181]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  109.473446811346
actions average: 
K:  2  action  0 :  tensor([    0.6881,     0.0069,     0.0005,     0.1093,     0.1952],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0050,     0.9802,     0.0041,     0.0004,     0.0104],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0021, 0.0013, 0.9318, 0.0357, 0.0292], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0584,     0.0004,     0.0717,     0.6483,     0.2212],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2194, 0.0030, 0.0006, 0.2814, 0.4956], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.6490,     0.0004,     0.0007,     0.1315,     0.2184],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0005,     0.9925,     0.0051,     0.0003,     0.0016],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0000,     0.9945,     0.0040,     0.0014],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.1574,     0.0003,     0.0014,     0.6016,     0.2393],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.2113, 0.0020, 0.0654, 0.2834, 0.4379], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  47.46819294310591
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  104.28775117959484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.7078,     0.0486,     0.0006,     0.0596,     0.1834],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9187,     0.0685,     0.0005,     0.0121],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0002,     0.9966,     0.0013,     0.0018],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0473, 0.0038, 0.0023, 0.7500, 0.1965], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.1431, 0.0192, 0.0121, 0.2171, 0.6084], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  110.95555364361965
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  57.02888284410749
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  141.53598747378646
UNIT TEST: sample policy line 217 mcts : [0.125 0.167 0.25  0.167 0.292]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[108.58 ]
 [108.715]
 [ 98.255]
 [ 99.89 ]
 [105.076]] [[2.042]
 [2.047]
 [1.689]
 [1.745]
 [1.922]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.0800691147686747
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  77.01088587443033
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6466463
siam score:  -0.6485972
rdn beta is 0 so we're just using the maxi policy
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.65908265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  107.16909011057028
printing an ep nov before normalisation:  99.75936608019572
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  38.31962585449219
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  79.20239148649551
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[103.242]
 [100.698]
 [ 90.98 ]
 [ 90.98 ]
 [ 90.98 ]] [[2.169]
 [2.086]
 [1.767]
 [1.767]
 [1.767]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([    0.7324,     0.0043,     0.0005,     0.0793,     0.1835],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0005,     0.9969,     0.0001,     0.0003,     0.0022],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9983,     0.0011,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0636,     0.0001,     0.0047,     0.6741,     0.2575],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2773, 0.0007, 0.0027, 0.1853, 0.5340], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  69.76338431426483
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  95.25965690612793
actions average: 
K:  4  action  0 :  tensor([    0.7940,     0.0001,     0.0000,     0.0682,     0.1376],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0153, 0.9318, 0.0135, 0.0126, 0.0268], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0025,     0.0007,     0.9514,     0.0361,     0.0094],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0147,     0.0002,     0.0326,     0.6725,     0.2801],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.3383, 0.0019, 0.0006, 0.2543, 0.4049], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  92.30839000642491
printing an ep nov before normalisation:  88.73270352681479
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  4.2073341333122025
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  123.95217996298697
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  126.86360733062415
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 95.3008844185218
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.355]
 [43.073]
 [32.362]
 [30.607]
 [24.597]] [[0.324]
 [0.504]
 [0.305]
 [0.273]
 [0.161]]
printing an ep nov before normalisation:  0.7458051829360102
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6566093
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6510247
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.65651566
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
siam score:  -0.65793455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.375 0.083 0.5   0.    0.042]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.7815,     0.0042,     0.0005,     0.0314,     0.1824],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9970,     0.0008,     0.0000,     0.0018],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9990,     0.0007,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1427, 0.0014, 0.0011, 0.5881, 0.2667], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.1974, 0.0045, 0.0013, 0.3436, 0.4531], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  3.005857298517185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.035]
 [15.184]
 [14.831]
 [12.896]
 [15.649]] [[0.365]
 [0.509]
 [0.497]
 [0.43 ]
 [0.525]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.666262025270598
siam score:  -0.65428114
printing an ep nov before normalisation:  4.759317656854429
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([    0.6688,     0.0219,     0.0004,     0.0833,     0.2257],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0070,     0.9846,     0.0002,     0.0025,     0.0057],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0136,     0.9321,     0.0516,     0.0026],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.1196,     0.0004,     0.0297,     0.6567,     0.1937],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.4243,     0.0002,     0.0006,     0.2235,     0.3514],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.64342654
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  0.004272039293735159
printing an ep nov before normalisation:  97.36477071938278
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.64271677
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 81.343]
 [101.839]
 [ 82.937]
 [ 85.188]
 [ 80.511]] [[2.027]
 [3.   ]
 [2.103]
 [2.21 ]
 [1.988]]
printing an ep nov before normalisation:  109.77072927565156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  106.29408349693637
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[106.294]
 [106.354]
 [117.769]
 [116.471]
 [114.442]] [[2.121]
 [2.124]
 [2.558]
 [2.508]
 [2.431]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.625 0.167 0.083 0.042 0.083]
printing an ep nov before normalisation:  103.68417739868164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[123.011]
 [123.011]
 [123.011]
 [123.011]
 [123.011]] [[2.5]
 [2.5]
 [2.5]
 [2.5]
 [2.5]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.47892961665956
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  85.60605279032988
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.6340,     0.0003,     0.0005,     0.0959,     0.2693],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0046,     0.9597,     0.0001,     0.0003,     0.0353],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0187,     0.9536,     0.0087,     0.0189],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0733,     0.0001,     0.0012,     0.7248,     0.2007],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.4456,     0.0001,     0.0006,     0.1404,     0.4133],
       grad_fn=<DivBackward0>)
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.67123145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  115.52162204405055
printing an ep nov before normalisation:  101.840739297369
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  132.08723870406445
printing an ep nov before normalisation:  100.94331743589794
printing an ep nov before normalisation:  48.95331723687197
printing an ep nov before normalisation:  1.1116467493991424
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  127.59436091386823
siam score:  -0.66613275
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.40205303562408
printing an ep nov before normalisation:  128.41358184814453
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.7326,     0.0123,     0.0003,     0.0705,     0.1842],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0067,     0.9768,     0.0082,     0.0001,     0.0082],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0002,     0.9973,     0.0004,     0.0021],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0858,     0.0001,     0.0006,     0.7026,     0.2109],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.2214,     0.0002,     0.0010,     0.3635,     0.4138],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 89.322]
 [101.898]
 [ 83.946]
 [ 89.322]
 [ 91.852]] [[1.082]
 [1.358]
 [0.965]
 [1.082]
 [1.138]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  0.02882513231838857
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6599342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  13.03614616394043
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  120.76656341552734
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6600693
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  31.726207034583904
printing an ep nov before normalisation:  84.03717068752907
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  106.2062250798105
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  109.118212358353
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6584863
siam score:  -0.65493655
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  116.85346510427422
printing an ep nov before normalisation:  81.59286499023438
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  110.18441759455156
siam score:  -0.66388756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6614615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  109.46120722309983
printing an ep nov before normalisation:  117.13956095189887
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  100.6478922707694
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  7.799278257795096
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  81.82324559848128
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.66064715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  121.27799034118652
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  98.4682019644464
printing an ep nov before normalisation:  76.2435868981006
printing an ep nov before normalisation:  77.30856003189295
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 5.596]
 [ 5.342]
 [ 6.635]
 [ 6.642]
 [49.439]] [[0.004]
 [0.   ]
 [0.022]
 [0.022]
 [0.763]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.6544026
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.108]
 [52.665]
 [61.542]
 [64.928]
 [65.383]] [[1.146]
 [1.133]
 [1.376]
 [1.468]
 [1.481]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 88.51589174955008
printing an ep nov before normalisation:  98.43355090991959
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  126.90768458600574
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  101.33194923400879
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.65909
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  107.01302289962769
printing an ep nov before normalisation:  73.61442745266295
siam score:  -0.6591423
siam score:  -0.6596853
printing an ep nov before normalisation:  56.11636070113552
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  88.322098051938
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.66567343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[114.572]
 [114.572]
 [110.408]
 [114.572]
 [114.572]] [[1.399]
 [1.399]
 [1.348]
 [1.399]
 [1.399]]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
siam score:  -0.6707866
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  33.36780690720626
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.5804,     0.0155,     0.0006,     0.1075,     0.2961],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0084,     0.9876,     0.0006,     0.0008,     0.0027],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0014, 0.0250, 0.9323, 0.0089, 0.0324], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1679, 0.0079, 0.0021, 0.4733, 0.3488], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.2282, 0.0145, 0.0210, 0.2810, 0.4553], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.083 0.125 0.125 0.542 0.125]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  93.77263289355841
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6665265
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.333 0.333 0.125 0.042 0.167]
printing an ep nov before normalisation:  122.03229395495536
actions average: 
K:  1  action  0 :  tensor([0.6581, 0.0008, 0.0008, 0.1256, 0.2147], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0016,     0.9963,     0.0001,     0.0001,     0.0019],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9986,     0.0005,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0646,     0.0002,     0.0104,     0.6134,     0.3114],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2169, 0.0036, 0.0019, 0.2327, 0.5448], grad_fn=<DivBackward0>)
siam score:  -0.66203886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.6875,     0.0003,     0.0006,     0.0528,     0.2587],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0060,     0.9893,     0.0010,     0.0000,     0.0037],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.9950,     0.0027,     0.0022],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1582, 0.0012, 0.0345, 0.5076, 0.2984], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2835, 0.0231, 0.0025, 0.2421, 0.4488], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6582053
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.659496
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[110.745]
 [121.134]
 [111.908]
 [110.745]
 [110.745]] [[0.78 ]
 [0.919]
 [0.795]
 [0.78 ]
 [0.78 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.6609846
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  115.0974697236838
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 53.3417975115185
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.539]
 [86.995]
 [69.651]
 [69.651]
 [69.651]] [[1.4  ]
 [1.362]
 [0.941]
 [0.941]
 [0.941]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  116.75940363503966
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  113.26606187397324
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.093]
 [86.297]
 [86.297]
 [86.297]
 [92.285]] [[1.492]
 [1.297]
 [1.297]
 [1.297]
 [1.469]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 92.75 ]
 [ 86.297]
 [102.515]
 [ 86.297]
 [ 92.285]] [[1.248]
 [1.092]
 [1.484]
 [1.092]
 [1.237]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  51.579989504620016
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.8639,     0.0011,     0.0001,     0.0809,     0.0540],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0131,     0.8836,     0.0837,     0.0002,     0.0195],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0097, 0.0463, 0.8715, 0.0045, 0.0681], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.1027, 0.0034, 0.0036, 0.5812, 0.3091], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2393, 0.0038, 0.0363, 0.1896, 0.5310], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  103.97961754259663
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.66348755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  99.50714160953775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.8790,     0.0185,     0.0002,     0.0042,     0.0982],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0007,     0.9829,     0.0012,     0.0054,     0.0098],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0003,     0.0028,     0.9924,     0.0007,     0.0038],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.1142,     0.0022,     0.0004,     0.6724,     0.2108],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2494, 0.0076, 0.0036, 0.2969, 0.4425], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  90.79863548278809
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([    0.7229,     0.0123,     0.0002,     0.0570,     0.2077],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0018,     0.9115,     0.0396,     0.0001,     0.0469],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0015, 0.0040, 0.9647, 0.0075, 0.0223], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0506,     0.0002,     0.0072,     0.6304,     0.3116],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.2049,     0.0002,     0.0017,     0.2347,     0.5584],
       grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.7498,     0.0008,     0.0002,     0.0611,     0.1881],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0043,     0.9810,     0.0002,     0.0006,     0.0139],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0008,     0.0686,     0.9233,     0.0027,     0.0046],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.1529,     0.0002,     0.0034,     0.5774,     0.2661],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.3281, 0.0163, 0.0005, 0.2529, 0.4021], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.66755754
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  78.18706644338408
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 1.5058264370769745e-11
0.0 0.0
0.0 1.4457144685704775e-11
0.0 5.24660721893565e-11
0.0 0.0
0.0 0.0
0.0 0.0
0.0 2.0515912173044923e-11
0.0 4.265787471458146e-11
0.0 5.074920517925065e-12
siam score:  -0.6557623
printing an ep nov before normalisation:  122.57915496826172
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  49.426331520080566
printing an ep nov before normalisation:  47.601898656146545
printing an ep nov before normalisation:  67.79630934718475
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.6591748
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.65739805
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  87.37434296254818
siam score:  -0.6582639
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  9.055754542350769
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  116.84627902438466
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  20015
line 256 mcts: sample exp_bonus 58.65983252983885
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  73.35837364196777
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  119.80281890706677
printing an ep nov before normalisation:  97.45991909078067
printing an ep nov before normalisation:  45.5403498122465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
siam score:  -0.65945596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  133.52225350906377
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
actor:  1 policy actor:  1  step number:  42 total reward:  1.0  reward:  1.0 rdn_beta:  1.5
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  92.47096832000682
printing an ep nov before normalisation:  135.84202200303412
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  14.748109586136323
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  114.3949232968719
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  119.15263071556748
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
UNIT TEST: sample policy line 217 mcts : [0.    0.708 0.    0.    0.292]
printing an ep nov before normalisation:  101.6633281866822
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  114.27196897703416
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  67.83150672912598
printing an ep nov before normalisation:  46.37404918670654
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  0.598343351271069
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
using explorer policy with actor:  1
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  84.31854465481769
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
siam score:  -0.6420683
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  90.65449281731665
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  84.67223167419434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
siam score:  -0.668451
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  120.04615045621793
printing an ep nov before normalisation:  71.75747978349501
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
actions average: 
K:  3  action  0 :  tensor([    0.6600,     0.0061,     0.0004,     0.0733,     0.2603],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0007,     0.9974,     0.0004,     0.0006,     0.0009],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0017,     0.9929,     0.0037,     0.0016],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0499, 0.0012, 0.0789, 0.5337, 0.3364], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1759, 0.1694, 0.0112, 0.1807, 0.4627], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.67359525
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
actions average: 
K:  3  action  0 :  tensor([    0.7203,     0.0013,     0.0002,     0.0300,     0.2482],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0004,     0.9986,     0.0000,     0.0000,     0.0009],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0022, 0.0444, 0.8750, 0.0573, 0.0211], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0508,     0.0005,     0.0011,     0.5608,     0.3868],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2337, 0.0019, 0.0017, 0.2867, 0.4760], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  47.325834053078715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
using explorer policy with actor:  1
printing an ep nov before normalisation:  84.61187362670898
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 98.485]
 [107.005]
 [103.534]
 [103.534]
 [103.534]] [[1.279]
 [1.5  ]
 [1.41 ]
 [1.41 ]
 [1.41 ]]
printing an ep nov before normalisation:  68.14782063652811
printing an ep nov before normalisation:  118.05843625749861
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
siam score:  -0.69103515
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
using explorer policy with actor:  1
printing an ep nov before normalisation:  4.465190669901062
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
actions average: 
K:  0  action  0 :  tensor([    0.7516,     0.0237,     0.0002,     0.0967,     0.1278],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0007,     0.9949,     0.0015,     0.0001,     0.0028],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0010,     0.0006,     0.9846,     0.0063,     0.0074],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1379, 0.0007, 0.0048, 0.5611, 0.2955], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.2019, 0.0175, 0.0042, 0.3283, 0.4482], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
actions average: 
K:  4  action  0 :  tensor([0.7157, 0.0109, 0.0017, 0.1115, 0.1603], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0290,     0.9293,     0.0048,     0.0006,     0.0364],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0002,     0.9899,     0.0004,     0.0096],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0630,     0.0002,     0.0025,     0.6885,     0.2458],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.2181, 0.0058, 0.0028, 0.2941, 0.4791], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.5367245741553006
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
siam score:  -0.7068838
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  91.24380735476188
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  9.603410080401176
actions average: 
K:  2  action  0 :  tensor([    0.7464,     0.0089,     0.0004,     0.0357,     0.2086],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0004,     0.9969,     0.0008,     0.0002,     0.0017],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0062,     0.9793,     0.0023,     0.0120],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.1313,     0.0004,     0.0008,     0.6700,     0.1976],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2877, 0.0290, 0.0042, 0.1739, 0.5052], grad_fn=<DivBackward0>)
siam score:  -0.72420347
siam score:  -0.72312427
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
Starting evaluation
using explorer policy with actor:  0
printing an ep nov before normalisation:  113.624450138637
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
using explorer policy with actor:  1
rdn probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
printing an ep nov before normalisation:  133.0696892660482
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[72.07 ]
 [70.6  ]
 [47.996]
 [71.987]
 [69.391]] [[1.049]
 [1.006]
 [0.34 ]
 [1.047]
 [0.97 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
siam score:  -0.69630784
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
using another actor
from probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[134.103]
 [134.103]
 [134.103]
 [134.103]
 [134.103]] [[2.501]
 [2.501]
 [2.501]
 [2.501]
 [2.501]]
printing an ep nov before normalisation:  76.28441712802505
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06673330268105993, 0.7330667892757602, 0.06673330268105993, 0.06673330268105993, 0.06673330268105993]
