append_mcts_svs:False
dirichlet_alpha:0.3
noise:0.3
dirichlet_alpha:0.5
noise:0.5
sims:{-1: 6, 6000: 40}
c1:1
c2:19652
temperature_init:1
temperature_changes:{-1: 1, 3000000.0: 0.5}
manual_over_ride_play_limit:None
exponent_node_n:1
ucb_denom_k:1
use_policy:True
model_expV_on_dones:True
norm_Qs_OnMaxi:True
norm_Qs_OnAll:True
norm_each_turn:False
state_channels:64
res_block_kernel_size:3
res_block_channels:[32, 32, 64, 64, 64]
res_block_ds:[False, True, False, False, False]
conv1:{'channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1}
conv2:{'channels': 64, 'kernel_size': 3, 'stride': 2, 'padding': 1}
reward_support:[-1, 1, 51]
conv1:{'kernel_size': 3, 'stride': 1, 'padding': 1}
res_blocks:[64]
reward_conv_channels:32
reward_hidden_dim:128
terminal_conv_channels:32
terminal_hidden_dim:64
value_support:[-1, 1, 51]
res_block:[64]
value_conv_channels:32
value_hidden_dim:128
policy_conv_channels:32
policy_hidden_dim:128
expV_conv_channels:32
expV_hidden_dim:128
expV_support:[-10, 10, 51]
proj_l1:256
proj_out:128
pred_hid:256
replay_buffer_size:50000
replay_buffer_size_exploration:200000
all_time_buffer_size:200000
batch_size:128
play_workers:2
min_workers:1
max_workers:6
lr:0.001
lr_warmup:1000
lr_decay:1
lr_decay_step:100000
optimizer:<class 'torch.optim.rmsprop.RMSprop'>
momentum:0.9
l2:0.0001
rho:0.99
k:5
value:0.25
dones:2.0
siam:2
rdn:0.5
expV:0.5
train_start_batch_multiple:2
prioritised_replay:True
ep_to_batch_ratio:[15, 16]
main_to_rdn_ratio:2
train_to_RS_ratio:4
on_policy_expV:False
rgb_im:True
channels:3
state_size:[6, 6]
timesteps_in_obs:2
store_prev_actions:True
env:<class 'game_play.frozen_lake_KEY.gridWorld'>
same_env_each_time:True
env_size:[7, 7]
observable_size:[7, 7]
game_modes:2
env_map:[['H' 'H' 'H' 'H' 'H' 'F' 'G']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F']
 ['S' 'F' 'H' 'H' 'H' 'H' 'H']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'K' 'F']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']]
max_steps:120
actions_size:5
optimal_score:1
total_frames:305000
exp_gamma:0.95
atari_env:False
memory_size:30
reward_clipping:False
image_size:[48, 48]
deque_length:3
PRESET_CONFIG:7
VK:True
use_two_heads:True
follow_better_policy:0.5
use_siam:True
exploration_type:episodic
rdn_beta:[0.3333333333333333, 2, 6]
explorer_percentage:0.8
reward_exploration:False
train_dones:True
contrast_vector:True
norm_state_vecs:False
RND_output_vector:256
RND_loss:cosine
prediction_bias:True
distance_measure:False
update_play_model:16
gamma:0.99
calc_n_step_rewards_after_frames:10000
N_steps_reward:5
start_frame_count:0
load_in_model:False
log_states:True
log_metrics:False
exploration_logger_dims:(2, 49)
device_train:cpu
device_selfplay:cpu
eval_x_frames:10000
eval_count:20
detach_expV_calc:True
use_new_episode_expV:False
start_training_expV_min:10000
start_training_expV_max:20000
start_training_expV_siam_override:0.8
value_only:False
[['H' 'H' 'H' 'H' 'H' 'F' 'G']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F']
 ['S' 'F' 'H' 'H' 'H' 'H' 'H']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'K' 'F']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
printing an ep nov before normalisation:  13.374204635620117
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  13.039851188659668
UNIT TEST: sample policy line 217 mcts : [0. 0. 1. 0. 0.]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
printing an ep nov before normalisation:  8.251773412850534
printing an ep nov before normalisation:  10.397732257843018
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
UNIT TEST: sample policy line 217 mcts : [0.  0.  0.6 0.4 0. ]
printing an ep nov before normalisation:  9.818487577368558
printing an ep nov before normalisation:  8.439472980192875
printing an ep nov before normalisation:  9.711940754844761
Starting evaluation
printing an ep nov before normalisation:  13.828778266906738
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.0018412424410185354
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  9.98374219364365
siam score:  -0.005611898617084639
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.017020262062863407
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([0.3057, 0.2249, 0.1599, 0.1340, 0.1754], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.1647, 0.4923, 0.1837, 0.0341, 0.1252], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.1359, 0.1605, 0.3413, 0.1899, 0.1722], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.1888, 0.0779, 0.2886, 0.2998, 0.1449], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.2105, 0.1954, 0.2228, 0.1728, 0.1985], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
deleting a thread, now have 2 threads
Frames:  1549 train batches done:  36 episodes:  110
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([0.5738, 0.0463, 0.1028, 0.1795, 0.0976], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0882, 0.5801, 0.1260, 0.0384, 0.1673], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.1429, 0.1727, 0.2904, 0.1985, 0.1955], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.1937, 0.0272, 0.2563, 0.3295, 0.1934], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2088, 0.2211, 0.1702, 0.1697, 0.2302], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([0.4927, 0.1162, 0.0922, 0.1145, 0.1845], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.1088, 0.5019, 0.1864, 0.0347, 0.1682], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0812, 0.1843, 0.3963, 0.1765, 0.1617], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.2373, 0.0116, 0.2030, 0.3479, 0.2003], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2070, 0.1256, 0.2533, 0.1964, 0.2176], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.50020754
actions average: 
K:  1  action  0 :  tensor([0.5336, 0.2025, 0.0470, 0.0831, 0.1338], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0713, 0.6027, 0.1554, 0.0212, 0.1494], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0583, 0.1058, 0.5315, 0.1275, 0.1769], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1799, 0.0621, 0.1741, 0.3519, 0.2320], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.2614, 0.1260, 0.1544, 0.2101, 0.2481], grad_fn=<DivBackward0>)
deleting a thread, now have 1 threads
Frames:  1549 train batches done:  97 episodes:  110
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.5382755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([0.7099, 0.0231, 0.0421, 0.1100, 0.1149], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0305, 0.7479, 0.0373, 0.0030, 0.1812], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0150, 0.2251, 0.3957, 0.1673, 0.1970], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0533, 0.0186, 0.3316, 0.3429, 0.2535], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.1287, 0.1583, 0.1008, 0.1751, 0.4371], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([0.4818, 0.1809, 0.0612, 0.1051, 0.1711], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0955, 0.5815, 0.1405, 0.0366, 0.1459], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0378, 0.1883, 0.4791, 0.1303, 0.1646], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.1718, 0.0116, 0.1726, 0.4063, 0.2378], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1128, 0.2023, 0.1947, 0.2055, 0.2846], grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.55100733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.369049608634185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.55525398254395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.8508,     0.0421,     0.0002,     0.0363,     0.0706],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0049, 0.8762, 0.0297, 0.0028, 0.0864], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0030, 0.0035, 0.8590, 0.0647, 0.0698], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0375, 0.0069, 0.1046, 0.5709, 0.2801], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0521, 0.0482, 0.1614, 0.3257, 0.4127], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.63022065162659
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.64152765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  15.38554072380066
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.70021987
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.8588,     0.0360,     0.0004,     0.0303,     0.0745],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0029, 0.8288, 0.0318, 0.0108, 0.1257], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0014, 0.0420, 0.8800, 0.0307, 0.0459], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0225, 0.0028, 0.1839, 0.4779, 0.3127], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0199, 0.0571, 0.1551, 0.2376, 0.5303], grad_fn=<DivBackward0>)
siam score:  -0.70304406
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.68033385
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.66025376
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9592,     0.0011,     0.0000,     0.0135,     0.0261],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0260, 0.8577, 0.0215, 0.0032, 0.0915], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0018,     0.8952,     0.0572,     0.0457],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0016,     0.0000,     0.0386,     0.8159,     0.1438],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0267, 0.0526, 0.2060, 0.2261, 0.4886], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.62195105739174
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
siam score:  -0.7098427
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.11174207203694
printing an ep nov before normalisation:  62.77115478123874
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7185132
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.7074593
line 256 mcts: sample exp_bonus 37.96756960385994
printing an ep nov before normalisation:  33.71847559876916
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.503]
 [31.688]
 [34.962]
 [34.204]
 [32.287]] [[1.092]
 [1.18 ]
 [1.423]
 [1.367]
 [1.224]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.833]
 [32.833]
 [32.833]
 [32.833]
 [32.833]] [[1.464]
 [1.464]
 [1.464]
 [1.464]
 [1.464]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.13126564025879
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.15073413066569888
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.65535873
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 90.704]
 [ 97.355]
 [101.185]
 [ 98.518]
 [101.24 ]] [[1.128]
 [1.302]
 [1.402]
 [1.332]
 [1.403]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.880177144074544
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.55136636163991
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.75 ]
 [49.417]
 [36.43 ]
 [38.165]
 [36.278]] [[0.159]
 [0.157]
 [0.092]
 [0.101]
 [0.091]]
printing an ep nov before normalisation:  31.11138063804543
actions average: 
K:  2  action  0 :  tensor([    0.9275,     0.0312,     0.0002,     0.0083,     0.0328],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0008,     0.9727,     0.0101,     0.0001,     0.0163],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0022,     0.9400,     0.0305,     0.0273],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0022,     0.0003,     0.0474,     0.7173,     0.2328],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0046, 0.0872, 0.1251, 0.2931, 0.4900], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.72597855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  26.99023933406492
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9138,     0.0161,     0.0000,     0.0200,     0.0501],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0006,     0.8837,     0.0146,     0.0026,     0.0985],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0154,     0.8932,     0.0413,     0.0500],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0054, 0.0049, 0.0619, 0.6691, 0.2586], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0046, 0.0330, 0.0926, 0.3709, 0.4989], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  51.01973309207635
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.25 ]
 [57.225]
 [48.713]
 [48.67 ]
 [50.222]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
main train batch thing paused
add a thread
Adding thread: now have 2 threads
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.962]
 [31.778]
 [46.535]
 [44.802]
 [41.001]] [[0.278]
 [0.23 ]
 [0.454]
 [0.427]
 [0.37 ]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.80900906055048
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.04494389453346
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.2531637270567444
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.93]
 [55.93]
 [55.93]
 [55.93]
 [55.93]] [[18.625]
 [18.625]
 [18.625]
 [18.625]
 [18.625]]
printing an ep nov before normalisation:  84.65343151941305
line 256 mcts: sample exp_bonus 46.57607984542847
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 54.599]
 [ 91.82 ]
 [115.51 ]
 [ 96.551]
 [ 91.914]] [[0.07 ]
 [0.2  ]
 [0.282]
 [0.216]
 [0.2  ]]
printing an ep nov before normalisation:  89.39134951393527
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.728]
 [39.411]
 [42.633]
 [44.322]
 [42.733]] [[0.553]
 [0.182]
 [0.224]
 [0.246]
 [0.225]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  81.9780316541218
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.62735807075405
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.8507,     0.0011,     0.0001,     0.0921,     0.0560],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0053, 0.8655, 0.0403, 0.0196, 0.0693], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0273,     0.8879,     0.0363,     0.0484],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0004,     0.0030,     0.1260,     0.6951,     0.1755],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0028, 0.0159, 0.1437, 0.3890, 0.4486], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7158115
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.65661334991455
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.567]
 [52.567]
 [74.317]
 [52.567]
 [52.567]] [[0.272]
 [0.272]
 [0.493]
 [0.272]
 [0.272]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.8643,     0.0010,     0.0001,     0.0278,     0.1067],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0023,     0.9282,     0.0039,     0.0009,     0.0647],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0359,     0.7837,     0.1214,     0.0590],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0963, 0.0016, 0.1222, 0.5896, 0.1903], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0480, 0.1516, 0.0411, 0.3830, 0.3763], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.806]
 [40.382]
 [30.025]
 [22.587]
 [22.781]] [[0.556]
 [1.042]
 [0.771]
 [0.577]
 [0.582]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
printing an ep nov before normalisation:  4.265508910512494
siam score:  -0.7115805
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.453]
 [49.493]
 [65.767]
 [47.932]
 [47.871]] [[0.704]
 [0.828]
 [1.328]
 [0.781]
 [0.779]]
printing an ep nov before normalisation:  69.65954303741455
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  101.1197281193048
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.23380622703825793
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.33796261522794
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.53 ]
 [83.53 ]
 [84.417]
 [79.656]
 [83.53 ]] [[0.903]
 [0.903]
 [0.921]
 [0.823]
 [0.903]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.643]
 [36.678]
 [29.643]
 [29.643]
 [29.643]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.60013650932805
printing an ep nov before normalisation:  65.58947809578677
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.544]
 [46.097]
 [62.275]
 [69.805]
 [56.429]] [[1.126]
 [0.625]
 [1.15 ]
 [1.394]
 [0.96 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[ 0.]
 [-0.]
 [ 0.]
 [ 0.]
 [ 0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.]
 [-0.]
 [ 0.]
 [ 0.]
 [ 0.]]
printing an ep nov before normalisation:  69.74790573120117
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.83469163738647
printing an ep nov before normalisation:  54.312262979483236
printing an ep nov before normalisation:  66.96163700834862
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.12687403974733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.48917447893086
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[95.651]
 [71.176]
 [49.624]
 [73.262]
 [68.916]] [[0.735]
 [0.491]
 [0.276]
 [0.512]
 [0.468]]
printing an ep nov before normalisation:  68.48253104037941
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.091114917437714
printing an ep nov before normalisation:  77.93658478246516
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.00649917832823
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.217859653358445
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.39530655296457
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.841]
 [62.744]
 [47.841]
 [47.841]
 [47.841]] [[0.617]
 [1.158]
 [0.617]
 [0.617]
 [0.617]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.10973642117666
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9106,     0.0004,     0.0001,     0.0365,     0.0525],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0177, 0.8905, 0.0257, 0.0044, 0.0617], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0004,     0.0106,     0.8223,     0.0921,     0.0746],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0015, 0.0260, 0.0801, 0.5503, 0.3421], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0484, 0.0260, 0.0518, 0.3434, 0.5305], grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
printing an ep nov before normalisation:  51.321152096659546
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 49.371785930239255
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.816]
 [57.816]
 [57.816]
 [57.816]
 [57.816]] [[1.651]
 [1.651]
 [1.651]
 [1.651]
 [1.651]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.227]
 [32.987]
 [34.454]
 [29.159]
 [27.775]] [[0.378]
 [0.539]
 [0.58 ]
 [0.432]
 [0.393]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.12120946248372
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.6690559387207
deleting a thread, now have 1 threads
Frames:  9522 train batches done:  1114 episodes:  603
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.63025522232056
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([0.8882, 0.0216, 0.0112, 0.0403, 0.0386], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9420,     0.0129,     0.0012,     0.0437],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0034,     0.9098,     0.0167,     0.0701],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0175, 0.0086, 0.0584, 0.5679, 0.3476], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0069, 0.0355, 0.0452, 0.3612, 0.5512], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.44922410873717
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.871]
 [62.295]
 [66.654]
 [62.295]
 [62.295]] [[0.909]
 [1.133]
 [1.249]
 [1.133]
 [1.133]]
printing an ep nov before normalisation:  32.06885483379041
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.19002151489258
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.52151669187765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.00371170043945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.73352003
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.59524917602539
printing an ep nov before normalisation:  62.92273534537891
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  14.876311278480046
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[7.114]
 [7.114]
 [7.114]
 [7.114]
 [7.114]] [[0.053]
 [0.053]
 [0.053]
 [0.053]
 [0.053]]
printing an ep nov before normalisation:  61.21675968170166
actions average: 
K:  2  action  0 :  tensor([    0.9347,     0.0010,     0.0000,     0.0298,     0.0344],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0004,     0.9785,     0.0010,     0.0013,     0.0188],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0024,     0.9686,     0.0064,     0.0225],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0045,     0.1199,     0.5041,     0.3713],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0493, 0.0504, 0.0770, 0.3045, 0.5188], grad_fn=<DivBackward0>)
siam score:  -0.7528079
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.996613849033196
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.841560758408775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.699]
 [54.699]
 [52.055]
 [63.01 ]
 [54.699]] [[0.89 ]
 [0.89 ]
 [0.811]
 [1.139]
 [0.89 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
main train batch thing paused
add a thread
Adding thread: now have 2 threads
printing an ep nov before normalisation:  75.2057982857177
printing an ep nov before normalisation:  47.661322215615634
printing an ep nov before normalisation:  77.4556267345303
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  40.31046780921765
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.682]
 [65.682]
 [77.631]
 [75.419]
 [69.027]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  37.75618108040334
printing an ep nov before normalisation:  60.698132300776436
printing an ep nov before normalisation:  53.886472198121666
printing an ep nov before normalisation:  42.10451515715211
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  54.55526686907133
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.68885632563031
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.06393204983422
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.651907222648866
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.7616751
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  107.63476591184212
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  80.15157670781461
printing an ep nov before normalisation:  61.95024667185438
printing an ep nov before normalisation:  65.20047167311436
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.00455371126192
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7717893
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.38895243550501
main train batch thing paused
add a thread
Adding thread: now have 3 threads
printing an ep nov before normalisation:  62.14748537772902
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.52384199222273
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.401]
 [54.57 ]
 [50.825]
 [47.878]
 [49.473]] [[0.197]
 [0.237]
 [0.208]
 [0.186]
 [0.198]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.49919353685397
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.443123070592435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.58740237583172
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
printing an ep nov before normalisation:  71.79845395701513
printing an ep nov before normalisation:  55.948592719537245
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.237]
 [61.56 ]
 [72.15 ]
 [71.237]
 [71.237]] [[1.633]
 [1.271]
 [1.667]
 [1.633]
 [1.633]]
printing an ep nov before normalisation:  37.638916969299316
printing an ep nov before normalisation:  73.55952829321231
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.7626991
printing an ep nov before normalisation:  72.2708880622578
siam score:  -0.76210785
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.724662101602604
siam score:  -0.76350653
printing an ep nov before normalisation:  51.278053806742115
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7695218
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.388]
 [36.916]
 [66.226]
 [38.547]
 [38.7  ]] [[0.42 ]
 [0.456]
 [1.149]
 [0.494]
 [0.498]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  98.52481627768807
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.76611817
printing an ep nov before normalisation:  82.03315364119365
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.819]
 [36.869]
 [44.594]
 [37.944]
 [35.951]] [[0.575]
 [0.784]
 [1.183]
 [0.84 ]
 [0.737]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.73 ]
 [44.843]
 [42.278]
 [42.278]
 [42.278]] [[1.37 ]
 [1.271]
 [1.137]
 [1.137]
 [1.137]]
siam score:  -0.7670511
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  36.16746525125786
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.571]
 [50.571]
 [50.571]
 [50.571]
 [50.571]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
printing an ep nov before normalisation:  75.67820030123386
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.49137568473816
printing an ep nov before normalisation:  40.870351791381836
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.42109261451307
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  130.2095275143775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  63.767243741569764
printing an ep nov before normalisation:  59.704263326662534
printing an ep nov before normalisation:  58.55944344110637
printing an ep nov before normalisation:  31.182782649993896
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.37981945776838
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.11986953669666
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.73968167153477
printing an ep nov before normalisation:  58.29611429341444
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.7848078606408
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.778]
 [56.074]
 [60.852]
 [60.77 ]
 [56.671]] [[1.306]
 [1.41 ]
 [1.627]
 [1.623]
 [1.437]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.350335121154785
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.32974187533844
printing an ep nov before normalisation:  60.245307496368966
printing an ep nov before normalisation:  81.3056533286946
siam score:  -0.7886908
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.736421247490846
printing an ep nov before normalisation:  74.59257660142504
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.05525541305542
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.14 ]
 [59.849]
 [45.989]
 [59.849]
 [59.849]] [[1.966]
 [1.73 ]
 [1.112]
 [1.73 ]
 [1.73 ]]
printing an ep nov before normalisation:  37.87161772397276
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  64.78533451186497
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  57.17692039224472
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.98713998103147
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.35173797607422
actions average: 
K:  1  action  0 :  tensor([    0.9911,     0.0021,     0.0000,     0.0019,     0.0048],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0007,     0.9958,     0.0003,     0.0001,     0.0032],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9899,     0.0007,     0.0093],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0003,     0.0309,     0.7712,     0.1969],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0093, 0.0127, 0.0384, 0.3475, 0.5921], grad_fn=<DivBackward0>)
siam score:  -0.78096354
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.108]
 [45.108]
 [45.108]
 [59.729]
 [45.108]] [[0.493]
 [0.493]
 [0.493]
 [0.653]
 [0.493]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.56 ]
 [45.878]
 [42.284]
 [45.652]
 [42.284]] [[1.229]
 [0.717]
 [0.619]
 [0.711]
 [0.619]]
printing an ep nov before normalisation:  59.96158431623055
deleting a thread, now have 2 threads
Frames:  13500 train batches done:  1571 episodes:  755
UNIT TEST: sample policy line 217 mcts : [0.051 0.436 0.231 0.154 0.128]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  92.5394640307023
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.3355981773938
printing an ep nov before normalisation:  65.43294081414716
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.33603699597206
actions average: 
K:  3  action  0 :  tensor([    0.9943,     0.0002,     0.0000,     0.0007,     0.0047],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0010, 0.9571, 0.0031, 0.0122, 0.0266], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0044,     0.9422,     0.0280,     0.0252],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0127, 0.0033, 0.0334, 0.6521, 0.2985], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0258, 0.0623, 0.0125, 0.3528, 0.5465], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.19195016146259
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.893]
 [41.893]
 [47.314]
 [41.893]
 [41.893]] [[0.123]
 [0.123]
 [0.157]
 [0.123]
 [0.123]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7793855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 89.97911417990726
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.56472056380306
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.269471945913644
printing an ep nov before normalisation:  44.862475605990745
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.78594923
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.356]
 [36.982]
 [44.883]
 [44.044]
 [37.879]] [[0.856]
 [0.62 ]
 [0.873]
 [0.846]
 [0.649]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  64.03153714899429
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  107.29464142450445
printing an ep nov before normalisation:  75.31175780793586
using explorer policy with actor:  1
printing an ep nov before normalisation:  63.71062279337089
printing an ep nov before normalisation:  65.35721263780322
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.326862335205078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.40537612250015
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.469084129501724
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  74.36970389539437
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.38562794545405
printing an ep nov before normalisation:  42.482366563164724
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  103.3286787319555
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.78880786895752
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.70249907392343
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  100.42425979283931
printing an ep nov before normalisation:  74.80850730690761
siam score:  -0.76874346
actions average: 
K:  1  action  0 :  tensor([    0.9709,     0.0003,     0.0000,     0.0206,     0.0082],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0033, 0.9116, 0.0124, 0.0010, 0.0718], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0004,     0.9359,     0.0318,     0.0318],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0021,     0.1261,     0.6588,     0.2128],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0033, 0.0435, 0.0582, 0.4840, 0.4109], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.58693058052503
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.7552301496504
printing an ep nov before normalisation:  55.41557853111645
printing an ep nov before normalisation:  76.87413179848016
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.7611833
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  100.29554691968698
siam score:  -0.7589485
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.146]
 [46.675]
 [52.914]
 [50.428]
 [33.517]] [[0.827]
 [1.136]
 [1.391]
 [1.29 ]
 [0.596]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.569]
 [58.56 ]
 [65.923]
 [69.659]
 [58.966]] [[0.755]
 [0.723]
 [0.955]
 [1.073]
 [0.736]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.81734023697741
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7624144
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.674]
 [55.23 ]
 [48.877]
 [43.313]
 [46.035]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  103.47995264667543
printing an ep nov before normalisation:  46.508326758678926
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.045]
 [54.045]
 [54.045]
 [54.045]
 [54.045]] [[0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]]
printing an ep nov before normalisation:  77.72390625422209
printing an ep nov before normalisation:  83.7378985960139
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9659,     0.0003,     0.0000,     0.0116,     0.0222],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0020, 0.9265, 0.0163, 0.0073, 0.0479], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0005,     0.0019,     0.9446,     0.0258,     0.0272],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0029,     0.0631,     0.6627,     0.2712],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0325, 0.0161, 0.0427, 0.4138, 0.4949], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  47.94410705566406
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.499]
 [64.333]
 [44.902]
 [47.376]
 [64.333]] [[1.626]
 [3.302]
 [1.81 ]
 [2.   ]
 [3.302]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.58983225411875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7898189
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.048]
 [35.465]
 [58.637]
 [46.569]
 [44.28 ]] [[0.734]
 [0.451]
 [1.135]
 [0.779]
 [0.711]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.061]
 [53.912]
 [55.221]
 [56.368]
 [53.912]] [[1.241]
 [0.738]
 [0.77 ]
 [0.799]
 [0.738]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.518]
 [76.518]
 [87.195]
 [76.518]
 [76.518]] [[1.274]
 [1.274]
 [1.574]
 [1.274]
 [1.274]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.30828944468271
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.63352492094161
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.133]
 [60.853]
 [62.751]
 [63.683]
 [61.451]] [[0.895]
 [0.887]
 [0.941]
 [0.968]
 [0.904]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  128.20273848067347
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.295877780614845
printing an ep nov before normalisation:  33.14342871931563
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.80864821866852
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.042]
 [29.044]
 [35.104]
 [34.616]
 [33.081]] [[0.154]
 [0.052]
 [0.081]
 [0.079]
 [0.072]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.75823617
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.7687489
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  113.25225541766643
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.502]
 [59.593]
 [59.593]
 [59.593]
 [59.593]] [[1.107]
 [0.768]
 [0.768]
 [0.768]
 [0.768]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.42864550606827
actions average: 
K:  1  action  0 :  tensor([    0.9885,     0.0045,     0.0000,     0.0013,     0.0057],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9906,     0.0000,     0.0000,     0.0092],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0003,     0.9322,     0.0247,     0.0427],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0008, 0.0010, 0.1176, 0.5997, 0.2809], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0021, 0.0084, 0.0258, 0.3390, 0.6247], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  14.643423557281494
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  76.72440864363729
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.35064035009633
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.7956444
printing an ep nov before normalisation:  94.26291828991224
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.7963777
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.12]
 [ 0.  ]
 [71.67]
 [ 0.  ]
 [ 0.  ]] [[ 0.638]
 [-0.487]
 [ 0.751]
 [-0.487]
 [-0.487]]
printing an ep nov before normalisation:  62.482099673347925
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
STARTED EXPV TRAINING ON FRAME NO.  16198
printing an ep nov before normalisation:  56.36276636035646
siam score:  -0.8013714
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9906,     0.0002,     0.0000,     0.0040,     0.0052],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9807,     0.0030,     0.0001,     0.0159],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0010, 0.0044, 0.8665, 0.0502, 0.0779], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0000,     0.0003,     0.0459,     0.6371,     0.3167],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0004,     0.0079,     0.0371,     0.2302,     0.7243],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  78.58847626367026
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.150394100285645
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.543]
 [26.667]
 [29.771]
 [29.137]
 [41.182]] [[0.545]
 [0.423]
 [0.521]
 [0.501]
 [0.88 ]]
printing an ep nov before normalisation:  86.93170463643278
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[105.803]
 [100.732]
 [100.732]
 [123.201]
 [100.732]] [[1.495]
 [1.398]
 [1.398]
 [1.826]
 [1.398]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.462 0.179 0.205 0.077 0.077]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  62.169311046406726
using explorer policy with actor:  1
siam score:  -0.8009143
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.797165
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  83.84297033427563
printing an ep nov before normalisation:  51.999441041232544
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.742]
 [40.189]
 [46.865]
 [39.933]
 [40.082]] [[1.033]
 [0.59 ]
 [0.826]
 [0.581]
 [0.586]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.202]
 [26.981]
 [31.016]
 [27.187]
 [30.406]] [[0.805]
 [0.328]
 [0.446]
 [0.334]
 [0.428]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  120.237961280813
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.395]
 [21.34 ]
 [19.873]
 [19.618]
 [19.618]] [[0.538]
 [0.202]
 [0.177]
 [0.173]
 [0.173]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.621857406019096
printing an ep nov before normalisation:  35.5871476642084
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.323]
 [35.732]
 [35.152]
 [59.985]
 [32.816]] [[0.226]
 [0.175]
 [0.17 ]
 [0.364]
 [0.152]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.2496161329569
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.71609117439594
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.10816212884492
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.845858655024706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.644]
 [47.292]
 [47.292]
 [47.292]
 [47.292]] [[0.569]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.14624264710337
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7924864
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0010,     0.9776,     0.0037,     0.0007,     0.0171],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9725,     0.0157,     0.0118],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0100,     0.0001,     0.0690,     0.6566,     0.2643],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0090,     0.0002,     0.1004,     0.3222,     0.5682],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.14074458883944
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.693]
 [74.693]
 [74.693]
 [74.693]
 [74.693]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.003]
 [29.452]
 [43.183]
 [27.189]
 [25.177]] [[0.437]
 [0.45 ]
 [0.874]
 [0.381]
 [0.319]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.3465771282404262
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.565]
 [50.396]
 [63.04 ]
 [61.338]
 [56.307]] [[0.828]
 [1.082]
 [1.354]
 [1.318]
 [1.209]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.9032735824585
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 2.144788985978419e-08
0.0 1.0434923125078863e-08
0.0 0.0
0.0 1.2919510798491852e-08
0.0 0.0
0.0 1.07293420332675e-08
0.0 1.1418882533184992e-08
0.0 0.0
0.0 1.6340240755034558e-08
0.0 1.2557104821336328e-08
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.23796704935148
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8062508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.0744276046753
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.003985076990624
siam score:  -0.8015808
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.672]
 [29.389]
 [50.755]
 [28.425]
 [29.06 ]] [[0.247]
 [0.221]
 [0.645]
 [0.202]
 [0.215]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 68.852]
 [ 85.877]
 [103.137]
 [100.518]
 [ 92.617]] [[0.485]
 [0.764]
 [1.046]
 [1.003]
 [0.874]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 90.051]
 [ 90.051]
 [110.771]
 [ 90.051]
 [ 90.051]] [[0.521]
 [0.521]
 [0.667]
 [0.521]
 [0.521]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.545]
 [34.158]
 [51.546]
 [34.983]
 [31.198]] [[0.254]
 [0.457]
 [0.869]
 [0.477]
 [0.387]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9958,     0.0015,     0.0000,     0.0009,     0.0018],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9778,     0.0001,     0.0002,     0.0218],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0020, 0.0018, 0.8878, 0.0630, 0.0455], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0009, 0.0011, 0.0228, 0.7049, 0.2703], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0112, 0.0068, 0.0171, 0.3559, 0.6090], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 0.0
0.0 -1.4864868165756913e-09
0.0 -1.557444887149585e-09
0.0 -1.5377938953972237e-09
0.0 -1.6033202658080047e-09
0.0 0.0
0.0 -1.663691710549049e-09
0.0 -1.5306669512052213e-09
0.0 0.0
0.0 -1.2848219733372316e-09
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.362007125485135
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  87.88850172055014
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  91.50287947637439
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.73750644556905
actions average: 
K:  0  action  0 :  tensor([    0.9742,     0.0017,     0.0006,     0.0031,     0.0204],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0120,     0.9487,     0.0195,     0.0001,     0.0196],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9746,     0.0143,     0.0110],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0007,     0.0003,     0.0221,     0.7223,     0.2546],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0023,     0.0005,     0.0435,     0.3145,     0.6393],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.925]
 [55.164]
 [56.144]
 [54.059]
 [50.989]] [[0.14 ]
 [0.265]
 [0.273]
 [0.255]
 [0.228]]
printing an ep nov before normalisation:  60.643972638253736
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.026 0.026 0.897 0.026 0.026]
printing an ep nov before normalisation:  56.57443907324
actions average: 
K:  3  action  0 :  tensor([    0.9960,     0.0005,     0.0000,     0.0006,     0.0029],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0009,     0.9975,     0.0001,     0.0000,     0.0015],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0012, 0.0281, 0.8575, 0.0492, 0.0640], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0006,     0.0003,     0.0692,     0.7407,     0.1891],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0061,     0.0005,     0.0347,     0.3607,     0.5980],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.252]
 [31.915]
 [56.099]
 [47.241]
 [50.481]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  44.0498933899242
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  11.031521967818492
printing an ep nov before normalisation:  34.256205558776855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.79 ]
 [73.79 ]
 [94.046]
 [96.898]
 [73.79 ]] [[0.909]
 [0.909]
 [1.305]
 [1.36 ]
 [0.909]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.457]
 [46.786]
 [46.786]
 [46.786]
 [46.786]] [[1.208]
 [0.649]
 [0.649]
 [0.649]
 [0.649]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.497031283058625
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
siam score:  -0.7979541
printing an ep nov before normalisation:  36.04243131457183
printing an ep nov before normalisation:  25.682762792646095
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.774]
 [83.804]
 [99.051]
 [91.019]
 [72.077]] [[0.132]
 [0.235]
 [0.296]
 [0.264]
 [0.189]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.298]
 [56.186]
 [49.877]
 [75.472]
 [64.568]] [[0.922]
 [0.623]
 [0.49 ]
 [1.031]
 [0.8  ]]
printing an ep nov before normalisation:  40.44077557420357
printing an ep nov before normalisation:  98.0540783827178
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.43836822567842
printing an ep nov before normalisation:  80.01612670431498
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.678]
 [46.231]
 [69.77 ]
 [46.231]
 [46.231]] [[0.857]
 [0.704]
 [1.26 ]
 [0.704]
 [0.704]]
printing an ep nov before normalisation:  27.449778793982368
printing an ep nov before normalisation:  63.39790659668332
actions average: 
K:  1  action  0 :  tensor([    0.9980,     0.0000,     0.0000,     0.0004,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0290,     0.9621,     0.0031,     0.0000,     0.0058],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0009,     0.9396,     0.0348,     0.0247],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0049,     0.0001,     0.0442,     0.7258,     0.2250],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0157, 0.0077, 0.0161, 0.2989, 0.6616], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.422]
 [50.911]
 [54.614]
 [57.423]
 [51.335]] [[1.177]
 [1.305]
 [1.495]
 [1.64 ]
 [1.327]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.47975254058838
printing an ep nov before normalisation:  61.86577354966383
printing an ep nov before normalisation:  52.49827284067409
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.679]
 [44.679]
 [44.679]
 [44.679]
 [66.055]] [[0.692]
 [0.692]
 [0.692]
 [0.692]
 [1.731]]
printing an ep nov before normalisation:  57.02036097960811
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.04415102025447
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.016]
 [63.016]
 [73.013]
 [63.016]
 [63.016]] [[1.647]
 [1.647]
 [2.   ]
 [1.647]
 [1.647]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.542]
 [39.542]
 [46.339]
 [39.542]
 [39.542]] [[0.626]
 [0.626]
 [0.814]
 [0.626]
 [0.626]]
printing an ep nov before normalisation:  97.05642564422853
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.30981628846139
printing an ep nov before normalisation:  61.12749090430972
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.079935196626444
siam score:  -0.80478364
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.132]
 [67.248]
 [72.248]
 [58.066]
 [61.027]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  48.000240899785844
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.154]
 [0.182]
 [0.267]
 [0.174]
 [0.176]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  29.57491738020383
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [99.382]
 [ 0.   ]
 [ 0.   ]] [[-0.576]
 [-0.576]
 [ 1.217]
 [-0.576]
 [-0.576]]
line 256 mcts: sample exp_bonus 130.1620724166476
printing an ep nov before normalisation:  74.00801265525672
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.325]
 [88.325]
 [88.325]
 [88.325]
 [88.325]] [[0.56]
 [0.56]
 [0.56]
 [0.56]
 [0.56]]
printing an ep nov before normalisation:  70.26250338855448
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9640,     0.0008,     0.0000,     0.0192,     0.0160],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0017,     0.9950,     0.0001,     0.0001,     0.0031],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0004,     0.9838,     0.0025,     0.0133],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0107, 0.0021, 0.0599, 0.6549, 0.2724], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0012, 0.0093, 0.0855, 0.2504, 0.6536], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.85203097727163
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.09772688270432
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.3223522999362
siam score:  -0.80383074
printing an ep nov before normalisation:  64.9061676269029
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.494]
 [37.494]
 [54.275]
 [37.494]
 [37.494]] [[1.04 ]
 [1.04 ]
 [1.505]
 [1.04 ]
 [1.04 ]]
printing an ep nov before normalisation:  73.18243502071967
printing an ep nov before normalisation:  59.32054560475563
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.80095464
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.518]
 [35.027]
 [41.081]
 [37.498]
 [37.276]] [[0.224]
 [0.217]
 [0.302]
 [0.252]
 [0.249]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9498,     0.0006,     0.0028,     0.0249,     0.0218],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0006,     0.9588,     0.0158,     0.0096,     0.0152],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0004,     0.0037,     0.9335,     0.0110,     0.0514],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0004,     0.1307,     0.5607,     0.3079],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0007, 0.0009, 0.0739, 0.2594, 0.6652], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  72.91945842934362
siam score:  -0.79608417
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  12.980462312698364
siam score:  -0.7940454
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  1  action  0 :  tensor([    0.9944,     0.0006,     0.0000,     0.0030,     0.0020],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9982,     0.0003,     0.0000,     0.0014],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0035,     0.9613,     0.0180,     0.0172],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0014,     0.0917,     0.7172,     0.1893],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0017, 0.0102, 0.0361, 0.3573, 0.5946], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.79637444
printing an ep nov before normalisation:  85.68721778642876
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.580898898546614
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.985]
 [81.518]
 [85.501]
 [87.371]
 [81.518]] [[0.882]
 [0.853]
 [0.932]
 [0.97 ]
 [0.853]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.908]
 [47.835]
 [47.593]
 [52.955]
 [44.817]] [[0.899]
 [0.57 ]
 [0.564]
 [0.699]
 [0.495]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.07082728607459
actions average: 
K:  1  action  0 :  tensor([    0.9617,     0.0036,     0.0000,     0.0112,     0.0235],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0835,     0.8222,     0.0165,     0.0008,     0.0770],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0207,     0.6918,     0.1501,     0.1373],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0805,     0.0002,     0.0381,     0.6701,     0.2111],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.1588, 0.0186, 0.1398, 0.4053, 0.2775], grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.52014636993408
printing an ep nov before normalisation:  36.256614327430725
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.35 ]
 [54.839]
 [54.839]
 [54.839]
 [54.839]] [[1.116]
 [0.557]
 [0.557]
 [0.557]
 [0.557]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7919386
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  109.45605615813143
printing an ep nov before normalisation:  106.46324733348693
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.405]
 [66.85 ]
 [76.64 ]
 [76.757]
 [70.438]] [[1.159]
 [1.316]
 [1.663]
 [1.667]
 [1.443]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  50.41145614838028
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.80337006
printing an ep nov before normalisation:  31.48935511417601
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.59837256461388
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.406]
 [40.606]
 [57.461]
 [57.227]
 [40.606]] [[0.455]
 [0.459]
 [0.822]
 [0.817]
 [0.459]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.64165776604597
UNIT TEST: sample policy line 217 mcts : [0.615 0.077 0.179 0.051 0.077]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.315]
 [58.315]
 [58.315]
 [58.315]
 [58.315]] [[0.992]
 [0.992]
 [0.992]
 [0.992]
 [0.992]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.932]
 [74.916]
 [45.502]
 [59.172]
 [45.446]] [[1.022]
 [1.082]
 [0.485]
 [0.763]
 [0.484]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.785]
 [68.107]
 [88.871]
 [78.28 ]
 [72.222]] [[0.479]
 [0.581]
 [0.98 ]
 [0.777]
 [0.66 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.00790909894772
siam score:  -0.8110273
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.75726725771965
printing an ep nov before normalisation:  63.537689736070796
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  88.61285799591826
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.44052752153823
printing an ep nov before normalisation:  0.4951372996271175
printing an ep nov before normalisation:  41.27306071599183
siam score:  -0.8034824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.71643746557334
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  100.50513161623601
printing an ep nov before normalisation:  49.66292248992078
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.36305703125593
printing an ep nov before normalisation:  34.24612998962402
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.717]
 [38.717]
 [47.811]
 [38.717]
 [38.717]] [[0.568]
 [0.568]
 [0.841]
 [0.568]
 [0.568]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.31580649087668
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.81467223
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.854]
 [51.854]
 [71.553]
 [51.854]
 [51.854]] [[1.004]
 [1.004]
 [1.655]
 [1.004]
 [1.004]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.586]
 [34.247]
 [35.284]
 [34.874]
 [27.872]] [[0.288]
 [0.316]
 [0.333]
 [0.326]
 [0.208]]
printing an ep nov before normalisation:  21.74487096691914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9981,     0.0001,     0.0000,     0.0006,     0.0013],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9565,     0.0004,     0.0000,     0.0431],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9234,     0.0508,     0.0257],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0117,     0.0006,     0.0510,     0.6934,     0.2434],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0206, 0.0193, 0.0315, 0.4142, 0.5144], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.329673372185155
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.612]
 [20.919]
 [20.919]
 [20.919]
 [20.919]] [[0.415]
 [0.129]
 [0.129]
 [0.129]
 [0.129]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.67958985838334
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.879]
 [49.602]
 [41.894]
 [42.899]
 [41.608]] [[0.264]
 [0.323]
 [0.243]
 [0.254]
 [0.24 ]]
printing an ep nov before normalisation:  65.83356857299805
printing an ep nov before normalisation:  71.05712888672676
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.8810982874298
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.986]
 [41.986]
 [44.042]
 [41.986]
 [41.986]] [[0.542]
 [0.542]
 [0.587]
 [0.542]
 [0.542]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.201365230947125
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.346]
 [76.346]
 [76.346]
 [76.346]
 [76.346]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.27717312977619
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 57.423650614295795
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.81392097473145
printing an ep nov before normalisation:  80.79568401784869
printing an ep nov before normalisation:  5.834117012736897
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  104.63377202853906
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  114.93158634959785
siam score:  -0.8283607
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.767]
 [46.617]
 [42.767]
 [42.767]
 [42.767]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.03633514675509
printing an ep nov before normalisation:  61.41677133191777
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.513]
 [73.513]
 [79.69 ]
 [76.438]
 [73.513]] [[1.489]
 [1.489]
 [1.655]
 [1.568]
 [1.489]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  101.74374016147675
printing an ep nov before normalisation:  70.20136358185262
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.74930918914916
line 256 mcts: sample exp_bonus 76.66848349517667
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 96.125]
 [ 96.125]
 [124.352]
 [ 96.125]
 [ 96.125]] [[0.794]
 [0.794]
 [1.177]
 [0.794]
 [0.794]]
printing an ep nov before normalisation:  35.046084347914075
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.037]
 [59.048]
 [87.429]
 [59.113]
 [56.304]] [[0.554]
 [0.619]
 [1.073]
 [0.62 ]
 [0.575]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8105104
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.256 0.026 0.667 0.026 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.7675739026205
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.034]
 [31.308]
 [45.346]
 [52.108]
 [43.638]] [[0.634]
 [0.566]
 [0.82 ]
 [0.943]
 [0.79 ]]
printing an ep nov before normalisation:  64.67573034826133
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.783]
 [67.783]
 [67.783]
 [67.783]
 [67.783]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.114]
 [38.704]
 [32.119]
 [34.937]
 [36.248]] [[0.836]
 [0.422]
 [0.244]
 [0.32 ]
 [0.355]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([    0.9951,     0.0011,     0.0000,     0.0011,     0.0026],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0042,     0.9806,     0.0012,     0.0001,     0.0138],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0070,     0.8547,     0.0582,     0.0800],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0196,     0.0003,     0.0331,     0.6590,     0.2880],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0264, 0.0204, 0.1031, 0.3977, 0.4524], grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.9978,     0.0002,     0.0000,     0.0008,     0.0013],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0041,     0.9879,     0.0001,     0.0001,     0.0078],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0191,     0.8398,     0.0658,     0.0750],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0009, 0.0070, 0.0241, 0.7817, 0.1862], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0416, 0.1040, 0.0007, 0.3988, 0.4549], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([0.9181, 0.0439, 0.0084, 0.0037, 0.0259], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0017,     0.9699,     0.0159,     0.0002,     0.0123],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0009,     0.8864,     0.0575,     0.0550],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0006,     0.0001,     0.0313,     0.7041,     0.2638],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0052, 0.0250, 0.0906, 0.2225, 0.6567], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  37.71618146272066
printing an ep nov before normalisation:  70.60920263922604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.98102924937356
siam score:  -0.81431407
printing an ep nov before normalisation:  27.84496247768402
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
line 256 mcts: sample exp_bonus 32.523338512904715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.81238943
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  69.42357063293457
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 42.503573574993986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.315]
 [65.941]
 [62.907]
 [68.99 ]
 [67.84 ]] [[0.666]
 [0.571]
 [0.525]
 [0.616]
 [0.599]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.44326972961426
printing an ep nov before normalisation:  55.54039760614012
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.103 0.231 0.179 0.308 0.179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.95675973210287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.820064
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.32439214074235
printing an ep nov before normalisation:  2.2206043966872357
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.9216480301938
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.82463926
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.7893279680134
actions average: 
K:  3  action  0 :  tensor([    0.9895,     0.0002,     0.0000,     0.0018,     0.0085],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0024,     0.9654,     0.0003,     0.0000,     0.0320],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.8652,     0.1108,     0.0239],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0018,     0.0006,     0.0269,     0.6592,     0.3115],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0002,     0.0003,     0.1917,     0.4378,     0.3699],
       grad_fn=<DivBackward0>)
siam score:  -0.82230294
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  100.26494807912916
printing an ep nov before normalisation:  31.342574701982848
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 72.98879343116612
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  90.89277502538437
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.49278605765791
printing an ep nov before normalisation:  64.35194223312752
actions average: 
K:  1  action  0 :  tensor([    0.9988,     0.0004,     0.0000,     0.0002,     0.0006],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0123, 0.9526, 0.0112, 0.0035, 0.0204], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9985,     0.0003,     0.0012],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0006,     0.0004,     0.0357,     0.6957,     0.2676],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0017, 0.0068, 0.0047, 0.3271, 0.6597], grad_fn=<DivBackward0>)
siam score:  -0.82788557
printing an ep nov before normalisation:  98.74293814869093
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.765]
 [38.765]
 [38.765]
 [38.765]
 [38.765]] [[0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]]
printing an ep nov before normalisation:  78.14993953438749
printing an ep nov before normalisation:  40.31781168000022
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.73505971461563
actions average: 
K:  0  action  0 :  tensor([    0.9978,     0.0017,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0009,     0.9915,     0.0001,     0.0001,     0.0074],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0004,     0.9255,     0.0302,     0.0439],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0001,     0.0182,     0.7437,     0.2377],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0127, 0.0069, 0.0429, 0.3502, 0.5873], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.60264833065911
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.89026403427124
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.813537302663335
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9993,     0.0000,     0.0000,     0.0004,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0032, 0.9483, 0.0225, 0.0074, 0.0186], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0040,     0.9310,     0.0230,     0.0418],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0082,     0.0006,     0.0226,     0.7177,     0.2509],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0572, 0.0146, 0.0405, 0.3605, 0.5271], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  72.15893609183176
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.345020336352626
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.674]
 [59.782]
 [53.993]
 [62.472]
 [58.409]] [[0.722]
 [0.666]
 [0.555]
 [0.718]
 [0.64 ]]
printing an ep nov before normalisation:  48.62346817160479
printing an ep nov before normalisation:  62.74430729188128
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.91567017598101
printing an ep nov before normalisation:  81.78234657218319
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.548]
 [44.497]
 [69.388]
 [38.25 ]
 [37.674]] [[0.522]
 [0.286]
 [0.54 ]
 [0.223]
 [0.217]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  1.2150711709460893
printing an ep nov before normalisation:  76.95824121704855
printing an ep nov before normalisation:  40.21436287858504
printing an ep nov before normalisation:  42.42640143518116
printing an ep nov before normalisation:  25.277318954467773
printing an ep nov before normalisation:  18.60895872116089
printing an ep nov before normalisation:  0.01771186090024912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.81231177
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.84887595513645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.561187744140625
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.657]
 [70.657]
 [70.657]
 [94.403]
 [70.657]] [[0.572]
 [0.572]
 [0.572]
 [0.892]
 [0.572]]
printing an ep nov before normalisation:  64.59306391096008
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.82549256
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.06513069322224
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.44131658579346
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.53087529272603
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  55.75237223189136
printing an ep nov before normalisation:  40.964698791503906
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.79756918223545
printing an ep nov before normalisation:  40.450462207205476
printing an ep nov before normalisation:  63.851340536573275
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.094]
 [53.094]
 [79.701]
 [53.094]
 [53.094]] [[0.874]
 [0.874]
 [1.709]
 [0.874]
 [0.874]]
printing an ep nov before normalisation:  68.24918286402787
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.91907823213969
printing an ep nov before normalisation:  32.17833448741449
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.5797870110113
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.276]
 [55.276]
 [55.276]
 [55.276]
 [55.276]] [[55.276]
 [55.276]
 [55.276]
 [55.276]
 [55.276]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.443]
 [18.443]
 [42.966]
 [18.443]
 [18.443]] [[0.305]
 [0.305]
 [1.077]
 [0.305]
 [0.305]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.490010261535645
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[78.259]
 [36.919]
 [36.919]
 [36.919]
 [36.919]] [[0.686]
 [0.219]
 [0.219]
 [0.219]
 [0.219]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.83346575
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.328105926513672
printing an ep nov before normalisation:  72.21191831748766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
siam score:  -0.83431524
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.256]
 [0.256]
 [0.322]
 [0.256]
 [0.256]] [[0.002]
 [0.002]
 [0.003]
 [0.002]
 [0.002]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.224]
 [34.219]
 [36.688]
 [30.093]
 [39.166]] [[0.336]
 [0.551]
 [0.61 ]
 [0.452]
 [0.669]]
line 256 mcts: sample exp_bonus 86.18653398651834
printing an ep nov before normalisation:  82.45466144074787
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  98.7875157540742
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.118]
 [ 0.104]
 [25.834]
 [ 0.148]
 [ 0.115]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.3306104756265
printing an ep nov before normalisation:  78.41294724628662
printing an ep nov before normalisation:  65.88412284851074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  63.69022755033492
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.6426822508138
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.051 0.077 0.026 0.205 0.641]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  109.30446939584145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.425]
 [60.582]
 [31.296]
 [51.812]
 [31.296]] [[0.736]
 [0.648]
 [0.112]
 [0.487]
 [0.112]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[95.725]
 [95.725]
 [95.725]
 [95.725]
 [95.725]] [[0.704]
 [0.704]
 [0.704]
 [0.704]
 [0.704]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 92.081]
 [ 94.009]
 [ 94.009]
 [101.593]
 [ 94.009]] [[0.894]
 [0.913]
 [0.913]
 [0.987]
 [0.913]]
siam score:  -0.81725264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  111.24160733704889
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  79.5929408248091
printing an ep nov before normalisation:  73.65147990438425
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.438]
 [76.466]
 [49.752]
 [42.547]
 [43.016]] [[0.31 ]
 [0.614]
 [0.302]
 [0.218]
 [0.224]]
printing an ep nov before normalisation:  59.889494086945405
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 32.23223725219542
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.15455375017666
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.38 ]
 [14.38 ]
 [34.477]
 [14.38 ]
 [14.38 ]] [[0.339]
 [0.339]
 [1.242]
 [0.339]
 [0.339]]
printing an ep nov before normalisation:  53.16954059271584
printing an ep nov before normalisation:  10.770337581634521
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.1493733594876
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.91893371079473
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.045]
 [22.045]
 [42.838]
 [22.045]
 [22.045]] [[0.662]
 [0.662]
 [1.492]
 [0.662]
 [0.662]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.66070328747619
printing an ep nov before normalisation:  36.19524663569122
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.78616081393731
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.227092312711584
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.23273345099984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.039427757263184
printing an ep nov before normalisation:  47.68005675281119
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.745]
 [16.473]
 [32.062]
 [13.202]
 [11.87 ]] [[0.326]
 [0.36 ]
 [1.082]
 [0.208]
 [0.147]]
printing an ep nov before normalisation:  46.78685993758505
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  0.5454283452157446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.48654840254688
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.155]
 [50.155]
 [50.155]
 [50.155]
 [50.155]] [[0.509]
 [0.509]
 [0.509]
 [0.509]
 [0.509]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.896]
 [64.896]
 [64.896]
 [64.896]
 [64.896]] [[1.461]
 [1.461]
 [1.461]
 [1.461]
 [1.461]]
printing an ep nov before normalisation:  49.33480819162413
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 43.022]
 [ 42.428]
 [103.646]
 [ 42.02 ]
 [ 43.022]] [[0.246]
 [0.239]
 [0.906]
 [0.235]
 [0.246]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.189]
 [45.331]
 [52.479]
 [47.903]
 [51.54 ]] [[0.495]
 [0.707]
 [0.894]
 [0.775]
 [0.87 ]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.91922029826977
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.72982883453369
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  97.78486288797842
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.25855442606654
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.09456750016227
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9425,     0.0003,     0.0000,     0.0316,     0.0256],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9573,     0.0342,     0.0000,     0.0082],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0132,     0.8577,     0.0472,     0.0818],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0336, 0.0028, 0.0163, 0.6140, 0.3334], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0119, 0.0331, 0.0641, 0.2293, 0.6615], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  93.74969495066013
printing an ep nov before normalisation:  25.263371467590332
printing an ep nov before normalisation:  32.199995356755416
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  117.64210224187363
line 256 mcts: sample exp_bonus 125.68999164552905
printing an ep nov before normalisation:  52.665320323028574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  84.28983488119513
printing an ep nov before normalisation:  55.08237805887304
line 256 mcts: sample exp_bonus 62.11832865527978
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.186922753296415
printing an ep nov before normalisation:  56.32800878968767
printing an ep nov before normalisation:  71.03814133801149
printing an ep nov before normalisation:  34.19207874948347
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  101.51907190151594
printing an ep nov before normalisation:  35.71126937866211
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.223941802978516
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.83959415344771
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  102.43069477619105
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.821575
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.15584754186878
printing an ep nov before normalisation:  63.715362133259866
using explorer policy with actor:  1
printing an ep nov before normalisation:  86.22197044384534
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.928]
 [39.928]
 [39.928]
 [44.018]
 [39.928]] [[0.571]
 [0.571]
 [0.571]
 [0.667]
 [0.571]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.662]
 [31.662]
 [36.158]
 [31.662]
 [31.662]] [[1.621]
 [1.621]
 [2.   ]
 [1.621]
 [1.621]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.3  ]
 [49.981]
 [86.046]
 [38.89 ]
 [36.419]] [[0.17 ]
 [0.235]
 [0.404]
 [0.182]
 [0.171]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.82573473
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.60457330243074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[102.078]
 [102.078]
 [102.078]
 [102.078]
 [102.078]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8275547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.29757198692758
printing an ep nov before normalisation:  75.18597322705695
printing an ep nov before normalisation:  95.33734674595513
printing an ep nov before normalisation:  79.58158305733889
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  95.521338649941
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.13059490261895
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.018780585702608
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.156]
 [28.567]
 [40.248]
 [33.745]
 [32.185]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.24393702109846
printing an ep nov before normalisation:  43.93991587135544
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.6693359343918
line 256 mcts: sample exp_bonus 23.554968829231555
printing an ep nov before normalisation:  60.00640168756288
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.7980916457051
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.829906
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.46039519121755
printing an ep nov before normalisation:  54.741557712196204
printing an ep nov before normalisation:  37.39433765411377
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.14137427110033
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 35.45467338823798
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.83018393502928
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.094556316460476
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.45982110528099
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.51222014372818
printing an ep nov before normalisation:  20.35425586972255
printing an ep nov before normalisation:  25.152402623708543
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.85618838211123
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  89.9260416013157
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.073]
 [23.073]
 [34.212]
 [23.073]
 [23.073]] [[0.348]
 [0.348]
 [0.668]
 [0.348]
 [0.348]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  57.425387822310846
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.2667550747593
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.86488964847894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.955]
 [49.955]
 [49.955]
 [49.955]
 [49.955]] [[1.251]
 [1.251]
 [1.251]
 [1.251]
 [1.251]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.049]
 [31.049]
 [46.326]
 [31.049]
 [31.049]] [[0.941]
 [0.941]
 [1.432]
 [0.941]
 [0.941]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.534156807550453
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.178590615835247
printing an ep nov before normalisation:  0.0048302738468919415
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.86358498560604
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.69698149719913
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.0158378927027
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.83580416577347
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.562]
 [86.586]
 [87.127]
 [76.562]
 [76.562]] [[1.347]
 [1.629]
 [1.644]
 [1.347]
 [1.347]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.292]
 [31.663]
 [57.672]
 [27.942]
 [31.663]] [[0.338]
 [0.216]
 [0.695]
 [0.147]
 [0.216]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.571]
 [51.862]
 [43.409]
 [33.072]
 [60.968]] [[0.652]
 [0.362]
 [0.259]
 [0.133]
 [0.474]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.07327175048678
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.62504005432129
printing an ep nov before normalisation:  29.28966999053955
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.83446276
printing an ep nov before normalisation:  45.20322647855285
printing an ep nov before normalisation:  42.08707809448242
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.82 ]
 [73.366]
 [75.084]
 [79.96 ]
 [73.366]] [[1.747]
 [1.505]
 [1.569]
 [1.752]
 [1.505]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.10317374466763
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.93643398810822
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.974]
 [42.974]
 [42.974]
 [42.974]
 [42.974]] [[1.249]
 [1.249]
 [1.249]
 [1.249]
 [1.249]]
printing an ep nov before normalisation:  38.515513043807886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.977288246154785
siam score:  -0.83541834
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.41979965120798
printing an ep nov before normalisation:  94.61543906581717
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
deleting a thread, now have 1 threads
Frames:  32967 train batches done:  3858 episodes:  1383
printing an ep nov before normalisation:  24.975016117095947
printing an ep nov before normalisation:  47.80531920197607
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.4392027785347
line 256 mcts: sample exp_bonus 57.852430998932405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.07801569958458
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.531517539786766
printing an ep nov before normalisation:  58.443200913792914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0112,     0.9667,     0.0023,     0.0001,     0.0197],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9378,     0.0376,     0.0245],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0003,     0.0349,     0.7104,     0.2538],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0033,     0.0004,     0.0445,     0.4612,     0.4906],
       grad_fn=<DivBackward0>)
actions average: 
K:  3  action  0 :  tensor([    0.9744,     0.0004,     0.0002,     0.0168,     0.0083],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0063,     0.9492,     0.0086,     0.0008,     0.0351],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0012,     0.8375,     0.0661,     0.0950],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0001,     0.0409,     0.7652,     0.1936],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0046, 0.0362, 0.1709, 0.3784, 0.4099], grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.9974,     0.0008,     0.0000,     0.0006,     0.0013],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0075,     0.9713,     0.0003,     0.0016,     0.0193],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0008,     0.9483,     0.0292,     0.0215],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0004,     0.0790,     0.6901,     0.2301],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0054, 0.0496, 0.0441, 0.3648, 0.5361], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  97.80245762987532
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.446]
 [38.446]
 [47.655]
 [38.446]
 [38.446]] [[0.81 ]
 [0.81 ]
 [1.093]
 [0.81 ]
 [0.81 ]]
siam score:  -0.830728
printing an ep nov before normalisation:  57.949158761069754
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.620927810668945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.098375148706296
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.631]
 [39.962]
 [49.974]
 [44.498]
 [42.195]] [[0.574]
 [0.536]
 [0.762]
 [0.638]
 [0.586]]
siam score:  -0.8266798
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8271127
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.85681898212052
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.82160705
printing an ep nov before normalisation:  85.67029807698326
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8304455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.52276732451223
printing an ep nov before normalisation:  76.5189998888377
printing an ep nov before normalisation:  32.93645325886426
printing an ep nov before normalisation:  47.122090800958745
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.83169496
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8324168
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.674]
 [61.674]
 [89.23 ]
 [61.674]
 [61.674]] [[0.33 ]
 [0.33 ]
 [0.478]
 [0.33 ]
 [0.33 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9991,     0.0002,     0.0000,     0.0004,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0135,     0.9770,     0.0018,     0.0001,     0.0075],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0008,     0.0001,     0.9639,     0.0161,     0.0190],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0008,     0.0006,     0.0369,     0.6863,     0.2753],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0104, 0.0187, 0.0562, 0.2010, 0.7137], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.05383463179271075
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.778]
 [47.778]
 [73.777]
 [47.778]
 [47.778]] [[0.164]
 [0.164]
 [0.333]
 [0.164]
 [0.164]]
printing an ep nov before normalisation:  60.39886432860886
printing an ep nov before normalisation:  59.875690474178896
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.949]
 [43.721]
 [51.913]
 [34.521]
 [36.57 ]] [[1.257]
 [1.222]
 [1.46 ]
 [0.954]
 [1.014]]
printing an ep nov before normalisation:  37.46394084995238
printing an ep nov before normalisation:  52.819515662404115
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.733]
 [24.595]
 [43.04 ]
 [24.421]
 [23.979]] [[0.389]
 [0.525]
 [1.171]
 [0.519]
 [0.503]]
printing an ep nov before normalisation:  18.386105843374786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.59178635485024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.532]
 [68.532]
 [65.25 ]
 [68.532]
 [68.532]] [[1.615]
 [1.615]
 [1.468]
 [1.615]
 [1.615]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.602453446050895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.56417740938392
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.70578546432414
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.577]
 [31.577]
 [47.477]
 [31.577]
 [31.577]] [[0.344]
 [0.344]
 [0.52 ]
 [0.344]
 [0.344]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.74]
 [74.74]
 [74.74]
 [74.74]
 [74.74]] [[1.2]
 [1.2]
 [1.2]
 [1.2]
 [1.2]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  113.29799707735872
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 72.82574931615697
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.982]
 [56.657]
 [56.657]
 [56.657]
 [56.657]] [[1.269]
 [1.05 ]
 [1.05 ]
 [1.05 ]
 [1.05 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[10.404]
 [10.404]
 [10.404]
 [10.404]
 [10.404]] [[0.075]
 [0.075]
 [0.075]
 [0.075]
 [0.075]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.80536800341406
actions average: 
K:  3  action  0 :  tensor([    0.9765,     0.0001,     0.0000,     0.0090,     0.0144],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0053, 0.9297, 0.0021, 0.0216, 0.0414], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0009,     0.8684,     0.0658,     0.0648],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0000,     0.0001,     0.0287,     0.8409,     0.1302],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0002,     0.0013,     0.1411,     0.3457,     0.5116],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8357489
actions average: 
K:  1  action  0 :  tensor([    0.9990,     0.0001,     0.0000,     0.0004,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0019, 0.9749, 0.0013, 0.0057, 0.0162], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0056,     0.9452,     0.0108,     0.0384],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0027,     0.0715,     0.6116,     0.3140],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0003,     0.0086,     0.0578,     0.2241,     0.7092],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.032460386321986334
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.00972032375788
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.031898928612208
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  78.17665067247316
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.64734639835378
siam score:  -0.84093034
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9973,     0.0001,     0.0000,     0.0014,     0.0013],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0020,     0.9747,     0.0030,     0.0001,     0.0202],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0001,     0.9561,     0.0019,     0.0418],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0012,     0.0002,     0.0682,     0.7407,     0.1897],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0688, 0.0180, 0.0663, 0.2780, 0.5689], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9982,     0.0000,     0.0000,     0.0001,     0.0018],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0010,     0.9775,     0.0077,     0.0000,     0.0138],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0005,     0.9049,     0.0538,     0.0407],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0020, 0.0031, 0.0699, 0.6656, 0.2595], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0021, 0.0006, 0.1250, 0.4434, 0.4288], grad_fn=<DivBackward0>)
siam score:  -0.8371866
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  93.47294286058305
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.74320461861606
printing an ep nov before normalisation:  60.51155481774719
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.12759214322188
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  142.34362582345668
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.00014780230799260607
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  52.49101951160661
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[78.581]
 [78.581]
 [84.891]
 [78.581]
 [78.581]] [[1.628]
 [1.628]
 [1.816]
 [1.628]
 [1.628]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.093]
 [47.093]
 [47.093]
 [47.093]
 [47.093]] [[0.802]
 [0.802]
 [0.802]
 [0.802]
 [0.802]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0002,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9998,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9646,     0.0215,     0.0138],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0037,     0.0006,     0.0602,     0.6309,     0.3046],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0058, 0.0010, 0.1103, 0.3456, 0.5374], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.009]
 [62.587]
 [53.398]
 [47.215]
 [50.127]] [[0.859]
 [1.218]
 [0.906]
 [0.696]
 [0.795]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.134]
 [67.134]
 [67.134]
 [67.134]
 [67.134]] [[1.529]
 [1.529]
 [1.529]
 [1.529]
 [1.529]]
printing an ep nov before normalisation:  48.19627285003662
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8333711
printing an ep nov before normalisation:  49.867383257087624
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  25.370702743530273
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  109.94813757383032
printing an ep nov before normalisation:  40.16176843508352
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.546]
 [84.546]
 [84.546]
 [86.39 ]
 [84.546]] [[0.824]
 [0.824]
 [0.824]
 [0.849]
 [0.824]]
printing an ep nov before normalisation:  47.993798949801274
siam score:  -0.8276967
actions average: 
K:  3  action  0 :  tensor([    0.9980,     0.0006,     0.0000,     0.0003,     0.0011],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0077,     0.9841,     0.0015,     0.0000,     0.0067],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0008,     0.9675,     0.0189,     0.0128],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0043,     0.0004,     0.0403,     0.7553,     0.1997],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0193, 0.0246, 0.1021, 0.3544, 0.4996], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.972]
 [24.669]
 [18.441]
 [17.429]
 [17.519]] [[0.615]
 [0.794]
 [0.492]
 [0.443]
 [0.448]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.2188295985361
line 256 mcts: sample exp_bonus 25.806410670280457
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.588]
 [61.588]
 [61.588]
 [61.588]
 [61.588]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.731]
 [59.731]
 [59.27 ]
 [59.731]
 [59.731]] [[1.781]
 [1.781]
 [1.765]
 [1.781]
 [1.781]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9857,     0.0008,     0.0001,     0.0070,     0.0064],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9907,     0.0026,     0.0000,     0.0066],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9994,     0.0002,     0.0004],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0004,     0.0796,     0.6309,     0.2889],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0028, 0.0020, 0.0700, 0.4294, 0.4958], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0002,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0001,     0.8985,     0.0546,     0.0466],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0009, 0.0010, 0.0165, 0.7814, 0.2001], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0511, 0.0083, 0.0243, 0.3509, 0.5654], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.56351874471136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 30.278000950561278
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9965,     0.0003,     0.0000,     0.0016,     0.0016],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9941,     0.0005,     0.0000,     0.0054],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0026,     0.9405,     0.0339,     0.0230],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0022, 0.0008, 0.0933, 0.6051, 0.2987], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0006,     0.0116,     0.0672,     0.2279,     0.6927],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.361]
 [20.658]
 [15.143]
 [21.916]
 [37.142]] [[0.278]
 [0.26 ]
 [0.12 ]
 [0.292]
 [0.679]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [   -0.0000]], dtype=torch.float64)
0.0 1.4530662920073355e-12
0.0 5.812265171251421e-12
0.0 1.7471392347175316e-12
0.0 3.307455657568574e-11
0.0 2.0066153498869714e-11
0.0 2.2833898881305442e-12
0.0 0.0
0.0 3.161284104028302e-12
0.0 2.1588413508869666e-11
0.0 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9996,     0.0001,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9966,     0.0002,     0.0000,     0.0032],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0429,     0.8337,     0.0433,     0.0800],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0106,     0.0007,     0.0438,     0.7308,     0.2141],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0132, 0.0341, 0.0935, 0.3338, 0.5253], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.33277215664192
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8441365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.3643848813173
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.88054216182796
printing an ep nov before normalisation:  39.36738464050747
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
main train batch thing paused
add a thread
Adding thread: now have 2 threads
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.638]
 [53.638]
 [53.638]
 [53.638]
 [69.837]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  78.60056576064157
using explorer policy with actor:  1
printing an ep nov before normalisation:  68.62687406927444
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.004]
 [69.638]
 [31.252]
 [32.408]
 [69.638]] [[1.301]
 [4.25 ]
 [1.242]
 [1.333]
 [4.25 ]]
printing an ep nov before normalisation:  46.78323770176837
printing an ep nov before normalisation:  46.65115021073113
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[103.264]
 [103.264]
 [103.264]
 [103.264]
 [103.264]] [[0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.72595882169541
printing an ep nov before normalisation:  84.2416774493836
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.812987327575684
printing an ep nov before normalisation:  55.10834439835433
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.465624484546254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9985,     0.0005,     0.0000,     0.0006,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0022,     0.9924,     0.0003,     0.0005,     0.0045],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0004,     0.0001,     0.9313,     0.0364,     0.0318],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0017, 0.0007, 0.0729, 0.6734, 0.2512], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0025, 0.0455, 0.0813, 0.2863, 0.5845], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.05448238116869675
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.034]
 [37.989]
 [36.986]
 [31.005]
 [33.666]] [[0.442]
 [0.709]
 [0.676]
 [0.475]
 [0.564]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.08565533526894
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  77.99869176640988
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.608]
 [53.608]
 [53.608]
 [53.608]
 [53.608]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  66.51285423459991
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [63.767]
 [ 0.   ]
 [ 0.   ]] [[-0.157]
 [-0.157]
 [ 0.68 ]
 [-0.157]
 [-0.157]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  9.497340144312147
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.25668534049719
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.318]
 [58.318]
 [58.318]
 [58.318]
 [58.318]] [[1.773]
 [1.773]
 [1.773]
 [1.773]
 [1.773]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.80686664581299
printing an ep nov before normalisation:  56.19422578984556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.9806991735645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.93726007199786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.053]
 [80.435]
 [78.735]
 [82.021]
 [78.269]] [[1.612]
 [1.709]
 [1.66 ]
 [1.754]
 [1.647]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.71 ]
 [40.71 ]
 [50.516]
 [40.71 ]
 [40.71 ]] [[1.062]
 [1.062]
 [1.465]
 [1.062]
 [1.062]]
printing an ep nov before normalisation:  28.317459002736573
printing an ep nov before normalisation:  54.36989190355976
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  15.261411666870117
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  41.314883144529986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.00076569824189
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.15523870037416
printing an ep nov before normalisation:  62.15522871427251
printing an ep nov before normalisation:  29.37584958332596
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.077 0.256 0.231 0.359 0.077]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  144.4001061361735
printing an ep nov before normalisation:  69.25562620345707
printing an ep nov before normalisation:  62.75959088712219
printing an ep nov before normalisation:  74.89724689301775
actions average: 
K:  3  action  0 :  tensor([    0.9887,     0.0017,     0.0000,     0.0028,     0.0068],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9827,     0.0141,     0.0000,     0.0030],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.8647,     0.0604,     0.0747],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0002,     0.1033,     0.6854,     0.2107],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0280, 0.0197, 0.0070, 0.4215, 0.5238], grad_fn=<DivBackward0>)
siam score:  -0.8380829
printing an ep nov before normalisation:  29.659569263458252
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.09143068323605
actions average: 
K:  0  action  0 :  tensor([    0.9720,     0.0152,     0.0000,     0.0016,     0.0112],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9942,     0.0005,     0.0000,     0.0051],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0007,     0.9211,     0.0358,     0.0424],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0000,     0.0002,     0.7115,     0.2882],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0004,     0.0068,     0.1226,     0.3710,     0.4991],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.7740368970913
printing an ep nov before normalisation:  54.87182771626492
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.38951377773947
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.060718498371365
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9997,     0.0001,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0026,     0.9689,     0.0021,     0.0003,     0.0262],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0010,     0.8919,     0.0753,     0.0318],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0024,     0.0002,     0.0207,     0.7771,     0.1995],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0045, 0.0535, 0.1555, 0.1451, 0.6414], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8322517
printing an ep nov before normalisation:  0.17019827673081525
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.19445336662597
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  74.31062908125736
using explorer policy with actor:  1
printing an ep nov before normalisation:  56.07106066271421
printing an ep nov before normalisation:  51.06132900285459
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
siam score:  -0.8327767
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.226]
 [51.226]
 [55.524]
 [51.226]
 [51.226]] [[0.571]
 [0.571]
 [0.647]
 [0.571]
 [0.571]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.432318794582336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.70310501487124
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.199]
 [37.199]
 [50.013]
 [37.199]
 [37.199]] [[0.637]
 [0.637]
 [0.955]
 [0.637]
 [0.637]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[111.748]
 [111.748]
 [118.015]
 [111.748]
 [111.748]] [[1.839]
 [1.839]
 [2.   ]
 [1.839]
 [1.839]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  100.68289310392869
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  101.77688490589345
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9854,     0.0000,     0.0000,     0.0056,     0.0090],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9990,     0.0002,     0.0000,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0009, 0.0082, 0.8635, 0.0532, 0.0742], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0005,     0.0001,     0.0375,     0.6505,     0.3113],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0021, 0.0022, 0.1294, 0.1765, 0.6898], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  85.48096536727152
line 256 mcts: sample exp_bonus 32.78509950769838
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.063029289245605
using explorer policy with actor:  1
printing an ep nov before normalisation:  70.98664174396113
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.20104502125439
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  73.23162623482716
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.48207611227465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8456645
printing an ep nov before normalisation:  18.5908014789009
printing an ep nov before normalisation:  66.70803534376392
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  104.1199093182209
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.81394129086361
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.39444153062387
printing an ep nov before normalisation:  37.34364861064561
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.09829425811768
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.781025479931245
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  45.701840043471265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.957840737264604
siam score:  -0.84563553
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.077 0.179 0.538 0.128 0.077]
siam score:  -0.847641
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.664340496063232
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.924829284514498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.297]
 [40.297]
 [43.521]
 [40.297]
 [40.297]] [[1.178]
 [1.178]
 [1.333]
 [1.178]
 [1.178]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.858]
 [35.223]
 [36.895]
 [33.407]
 [38.714]] [[0.458]
 [0.37 ]
 [0.402]
 [0.336]
 [0.437]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  48.811992018306945
printing an ep nov before normalisation:  40.49899843407039
printing an ep nov before normalisation:  81.6537885717319
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  20.608463287353516
printing an ep nov before normalisation:  22.987494011239583
printing an ep nov before normalisation:  68.76624674005487
printing an ep nov before normalisation:  29.62452352260695
printing an ep nov before normalisation:  40.00288802225156
printing an ep nov before normalisation:  34.01980330082873
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.519]
 [26.96 ]
 [26.96 ]
 [26.96 ]
 [26.96 ]] [[0.461]
 [0.293]
 [0.293]
 [0.293]
 [0.293]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  94.0175666957066
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.032]
 [36.391]
 [55.158]
 [43.032]
 [43.032]] [[0.512]
 [0.38 ]
 [0.753]
 [0.512]
 [0.512]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.99960318031525
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [     0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [     0.0000],
        [    -0.0000],
        [     0.0000],
        [     0.0000]], dtype=torch.float64)
0.0 -1.1174771717464347e-11
0.0 5.673877903619847e-12
0.0 -4.610025794475946e-12
0.0 -2.594761419127006e-14
0.0 0.0
0.0 0.0
0.0 2.857697039779756e-11
0.0 -3.0012738275913685e-11
0.0 3.3974073793541935e-11
0.0 1.1292400896642777e-10
actions average: 
K:  2  action  0 :  tensor([    0.9962,     0.0008,     0.0000,     0.0006,     0.0024],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0049,     0.9861,     0.0003,     0.0004,     0.0083],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0004,     0.8788,     0.0559,     0.0648],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0018,     0.0004,     0.0422,     0.7064,     0.2492],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0173,     0.0003,     0.0297,     0.4142,     0.5385],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.092763681873485
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.679]
 [31.679]
 [31.679]
 [31.679]
 [31.679]] [[1.118]
 [1.118]
 [1.118]
 [1.118]
 [1.118]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.683]
 [37.414]
 [44.863]
 [36.113]
 [34.459]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.61919768275386
printing an ep nov before normalisation:  29.212641716003418
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.7129236155082
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.9624462034972
printing an ep nov before normalisation:  83.21574284595088
siam score:  -0.84264505
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.850412
printing an ep nov before normalisation:  88.38124448082765
siam score:  -0.85087276
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.62035818683216
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.96436312667434
printing an ep nov before normalisation:  33.23919057846069
printing an ep nov before normalisation:  50.550756630554474
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.720379184748225
printing an ep nov before normalisation:  104.01240116142445
siam score:  -0.8491487
line 256 mcts: sample exp_bonus 42.17634201049805
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8523766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.697]
 [26.471]
 [23.09 ]
 [23.09 ]
 [23.09 ]] [[0.437]
 [0.197]
 [0.158]
 [0.158]
 [0.158]]
printing an ep nov before normalisation:  46.53580491770922
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8471367
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.256319999694824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.87194226963251
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.16716303194274
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.7403563198157
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.03526894944452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.517048835754395
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.84595156
printing an ep nov before normalisation:  70.67298678059876
actions average: 
K:  4  action  0 :  tensor([    0.8775,     0.0007,     0.0000,     0.0163,     0.1055],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0011,     0.9883,     0.0009,     0.0002,     0.0096],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0015,     0.9811,     0.0029,     0.0144],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0012,     0.0005,     0.0640,     0.6715,     0.2629],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0017,     0.1671,     0.2200,     0.6109],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.850781032938436
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.41663586695994
printing an ep nov before normalisation:  45.260723942244425
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.900877952575684
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  121.46818225762198
printing an ep nov before normalisation:  50.31065109457085
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.957]
 [42.281]
 [53.367]
 [59.967]
 [39.007]] [[0.246]
 [0.38 ]
 [0.585]
 [0.706]
 [0.32 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.133]
 [44.133]
 [57.123]
 [54.281]
 [44.133]] [[0.673]
 [0.673]
 [0.913]
 [0.86 ]
 [0.673]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.807]
 [23.579]
 [54.287]
 [52.786]
 [28.596]] [[0.049]
 [0.075]
 [0.287]
 [0.277]
 [0.11 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  88.90176231166348
siam score:  -0.84079516
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.904]
 [58.904]
 [58.904]
 [58.904]
 [58.904]] [[1.251]
 [1.251]
 [1.251]
 [1.251]
 [1.251]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.9064675346591
printing an ep nov before normalisation:  76.35970578480702
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.11 ]
 [39.11 ]
 [46.346]
 [39.11 ]
 [39.11 ]] [[0.91 ]
 [0.91 ]
 [1.176]
 [0.91 ]
 [0.91 ]]
printing an ep nov before normalisation:  56.68262934358436
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.99993866429957
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  78.40995980992984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.08826304584808
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.562413629624057
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 47.11209520947043
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  104.8919177320184
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([0.9576, 0.0060, 0.0033, 0.0086, 0.0244], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9920,     0.0010,     0.0001,     0.0069],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0029,     0.8814,     0.0529,     0.0626],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0004,     0.0292,     0.8407,     0.1293],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0006, 0.0054, 0.0346, 0.4089, 0.5505], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.726]
 [48.172]
 [50.104]
 [51.168]
 [47.097]] [[1.129]
 [1.093]
 [1.137]
 [1.162]
 [1.069]]
printing an ep nov before normalisation:  53.95164102449986
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.78 ]
 [37.4  ]
 [45.389]
 [43.743]
 [42.996]] [[0.223]
 [0.176]
 [0.246]
 [0.231]
 [0.225]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 51.62087506607728
printing an ep nov before normalisation:  70.73634551613365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.69199562072754
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.5396032333374
printing an ep nov before normalisation:  16.247069835662842
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0009,     0.9805,     0.0001,     0.0000,     0.0186],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0010, 0.0023, 0.8399, 0.0601, 0.0968], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0302,     0.0005,     0.0463,     0.7262,     0.1969],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0181, 0.0146, 0.0576, 0.3239, 0.5858], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  72.86527453904483
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.055652618408203
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.708948510273547
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.514]
 [27.262]
 [41.261]
 [29.184]
 [27.514]] [[0.406]
 [0.399]
 [0.792]
 [0.453]
 [0.406]]
printing an ep nov before normalisation:  39.525566502384955
printing an ep nov before normalisation:  47.42585674869289
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.034452512741986
line 256 mcts: sample exp_bonus 54.13000264872483
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8428508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.54652562033775
printing an ep nov before normalisation:  71.64203763186788
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.228]
 [36.228]
 [36.228]
 [39.278]
 [38.543]] [[0.568]
 [0.568]
 [0.568]
 [0.667]
 [0.643]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.556338274920584
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.88275757992493
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.963271617889404
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.45723674910843
printing an ep nov before normalisation:  47.69626172350114
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.25676311961513
printing an ep nov before normalisation:  50.05137072223013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.295470237731934
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 50.99840069259723
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8459694
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.58042754297241
printing an ep nov before normalisation:  54.85173319168563
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  64.82507083881599
UNIT TEST: sample policy line 217 mcts : [0.154 0.051 0.205 0.103 0.487]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.867]
 [43.347]
 [28.377]
 [31.85 ]
 [30.742]] [[0.222]
 [0.203]
 [0.09 ]
 [0.116]
 [0.108]]
printing an ep nov before normalisation:  39.13089008829834
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.98877755019807
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 27.971328931944942
printing an ep nov before normalisation:  28.94677520138589
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.18428707122803
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.036]
 [50.036]
 [50.036]
 [50.036]
 [50.036]] [[1.868]
 [1.868]
 [1.868]
 [1.868]
 [1.868]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.17392349243164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.15530894462623
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.10715502404175
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.386]
 [69.152]
 [45.246]
 [63.991]
 [54.272]] [[0.836]
 [1.22 ]
 [0.798]
 [1.129]
 [0.957]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9932,     0.0004,     0.0000,     0.0003,     0.0061],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0047,     0.9908,     0.0012,     0.0000,     0.0032],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0007,     0.9306,     0.0286,     0.0401],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0002,     0.0543,     0.6394,     0.3058],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0001,     0.0029,     0.0629,     0.3696,     0.5645],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.696]
 [28.696]
 [40.156]
 [28.696]
 [28.696]] [[0.546]
 [0.546]
 [0.946]
 [0.546]
 [0.546]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.09617799753126
printing an ep nov before normalisation:  39.46776348313761
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.38761473371618
printing an ep nov before normalisation:  52.30083899454139
printing an ep nov before normalisation:  64.97310161590576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.40532535009452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  5.494414949680504e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.902]
 [47.637]
 [34.902]
 [39.311]
 [34.902]] [[0.966]
 [1.361]
 [0.966]
 [1.103]
 [0.966]]
printing an ep nov before normalisation:  55.584836352506166
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.07 ]
 [26.151]
 [36.665]
 [31.058]
 [33.868]] [[0.366]
 [0.369]
 [0.716]
 [0.531]
 [0.624]]
printing an ep nov before normalisation:  23.11989150948876
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.67809772491455
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.973]
 [38.407]
 [39.319]
 [27.28 ]
 [40.267]] [[0.534]
 [0.662]
 [0.677]
 [0.47 ]
 [0.694]]
printing an ep nov before normalisation:  30.338690114425123
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.99640631805855
using explorer policy with actor:  1
siam score:  -0.8499606
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8500942
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.84509695
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  64.0253304073742
printing an ep nov before normalisation:  34.34609205961388
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.63644646907187
printing an ep nov before normalisation:  36.56246564402356
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.25570395890213
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.75 ]
 [18.817]
 [17.16 ]
 [16.262]
 [16.504]] [[0.503]
 [0.556]
 [0.474]
 [0.429]
 [0.441]]
siam score:  -0.85230833
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.86714206363965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  30.56935718550227
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.84899086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  47.88156344456799
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9981,     0.0000,     0.0000,     0.0010,     0.0009],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0027,     0.9702,     0.0079,     0.0004,     0.0188],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0003,     0.8957,     0.0444,     0.0596],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0031,     0.0001,     0.0004,     0.7296,     0.2667],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0110, 0.0225, 0.1322, 0.1271, 0.7072], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.50241470336914
printing an ep nov before normalisation:  23.33918571472168
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9697,     0.0277,     0.0000,     0.0001,     0.0025],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9967,     0.0000,     0.0000,     0.0029],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0014,     0.8427,     0.0785,     0.0773],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0013,     0.0002,     0.1108,     0.6596,     0.2281],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0021, 0.0514, 0.0829, 0.2746, 0.5890], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.39]
 [46.39]
 [46.39]
 [46.39]
 [46.39]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.492643250371557
printing an ep nov before normalisation:  58.19377131790526
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.65249351570307
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9997,     0.0001,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9867,     0.0023,     0.0000,     0.0108],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0002,     0.9240,     0.0303,     0.0455],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0065,     0.0006,     0.0365,     0.6864,     0.2699],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0033, 0.0073, 0.1304, 0.2961, 0.5628], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.806]
 [28.806]
 [28.806]
 [28.806]
 [43.36 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.959]
 [41.937]
 [52.372]
 [41.937]
 [45.251]] [[0.448]
 [0.782]
 [1.132]
 [0.782]
 [0.893]]
printing an ep nov before normalisation:  94.17785023248351
line 256 mcts: sample exp_bonus 65.84141735501674
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.47439002990723
printing an ep nov before normalisation:  38.651059738022504
printing an ep nov before normalisation:  30.23672079778321
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.486449786013136
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 8.448]
 [12.598]
 [18.786]
 [11.018]
 [ 6.497]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([0.9492, 0.0215, 0.0039, 0.0066, 0.0187], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0012,     0.9953,     0.0008,     0.0000,     0.0027],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0122,     0.9231,     0.0221,     0.0425],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0075,     0.0003,     0.0772,     0.6342,     0.2808],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0030, 0.0018, 0.0675, 0.2296, 0.6981], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.91897201538086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9921,     0.0001,     0.0000,     0.0042,     0.0036],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9903,     0.0018,     0.0001,     0.0076],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0043,     0.7806,     0.1071,     0.1079],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0002,     0.0708,     0.6223,     0.3065],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0014,     0.0004,     0.1096,     0.2911,     0.5975],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.295906353119484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.950054182396165
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.90691809209856
actions average: 
K:  2  action  0 :  tensor([    0.9253,     0.0015,     0.0001,     0.0584,     0.0148],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0005,     0.9755,     0.0101,     0.0001,     0.0139],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0019,     0.9153,     0.0456,     0.0370],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0030,     0.0003,     0.0560,     0.7382,     0.2025],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0064, 0.0156, 0.1425, 0.2166, 0.6190], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9919,     0.0020,     0.0000,     0.0008,     0.0053],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.151]
 [45.55 ]
 [45.946]
 [45.205]
 [44.619]] [[0.193]
 [0.32 ]
 [0.325]
 [0.316]
 [0.309]]
tensor([    0.0001,     0.9752,     0.0153,     0.0000,     0.0094],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0041,     0.8389,     0.0602,     0.0967],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0006,     0.0850,     0.6395,     0.2748],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0007, 0.0217, 0.1095, 0.3015, 0.5666], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.253]
 [52.05 ]
 [52.942]
 [48.766]
 [52.942]] [[0.42 ]
 [0.236]
 [0.244]
 [0.208]
 [0.244]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.043506155564756455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.84376174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 44.599531680826914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.77696995080214
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.663]
 [21.695]
 [21.695]
 [21.695]
 [21.695]] [[0.768]
 [0.503]
 [0.503]
 [0.503]
 [0.503]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.64491778084543
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.34227580983273
printing an ep nov before normalisation:  52.743428772522336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.01002247380922
printing an ep nov before normalisation:  56.746973313428555
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.273]
 [44.111]
 [32.239]
 [32.365]
 [32.239]] [[0.734]
 [1.087]
 [0.662]
 [0.666]
 [0.662]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  23.468806192315007
printing an ep nov before normalisation:  0.011585555376996126
siam score:  -0.846565
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.526]
 [47.567]
 [57.441]
 [56.583]
 [57.755]] [[0.559]
 [0.845]
 [1.079]
 [1.059]
 [1.087]]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [     0.0000],
        [     0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 -2.5947612298298285e-12
0.0 -2.715850090417116e-12
0.0 -2.1795994390179033e-12
0.0 -2.361232724662955e-12
0.0 0.0
0.0 -2.4131279506289354e-12
0.0 1.94607093143447e-12
0.0 2.1536518280487127e-12
0.0 0.0
0.0 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.40879370954702
printing an ep nov before normalisation:  34.201983985613936
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.59187412261963
siam score:  -0.8416829
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8424672
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  13.985264301300049
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8395787
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.56341505050659
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  42.72233247756958
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 48.577476501464844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.61717469574185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.733]
 [59.537]
 [51.382]
 [55.995]
 [55.447]] [[1.688]
 [1.639]
 [1.304]
 [1.493]
 [1.471]]
printing an ep nov before normalisation:  42.62346851044367
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.271181450822915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.53069882014574
printing an ep nov before normalisation:  66.02264239493759
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.013]
 [34.013]
 [31.698]
 [34.013]
 [34.013]] [[1.305]
 [1.305]
 [1.144]
 [1.305]
 [1.305]]
printing an ep nov before normalisation:  28.31728180294093
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0002,     0.0009],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0014,     0.9934,     0.0004,     0.0001,     0.0048],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0005,     0.0005,     0.9172,     0.0356,     0.0463],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0482,     0.0001,     0.0365,     0.7516,     0.1636],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0284, 0.0015, 0.0417, 0.3302, 0.5982], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0005,     0.9978,     0.0005,     0.0000,     0.0012],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0004,     0.9715,     0.0032,     0.0248],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0002,     0.0521,     0.6723,     0.2749],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0252, 0.0406, 0.0741, 0.3312, 0.5288], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  55.49755932689182
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.94941669040256
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0018710721832349009
printing an ep nov before normalisation:  53.95156466102682
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.74286702254102
line 256 mcts: sample exp_bonus 48.304426974302686
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.277120716232005
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.7148181906865
siam score:  -0.85124826
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  55.7277182476124
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.84358615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.256668618659035
using explorer policy with actor:  1
printing an ep nov before normalisation:  52.23953484346958
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  94.00696951627765
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  30.969967980696225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.055846691131592
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.105]
 [26.917]
 [32.844]
 [45.298]
 [29.604]] [[0.452]
 [0.341]
 [0.498]
 [0.828]
 [0.412]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.453017354011536
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.367]
 [53.367]
 [53.367]
 [77.2  ]
 [53.367]] [[0.412]
 [0.412]
 [0.412]
 [0.711]
 [0.412]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.89]
 [24.89]
 [24.89]
 [24.89]
 [24.89]] [[0.086]
 [0.086]
 [0.086]
 [0.086]
 [0.086]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  65.30705600540098
printing an ep nov before normalisation:  29.12238107824323
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.84070176
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.482811572944364
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.06872918233511
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9984,     0.0001,     0.0000,     0.0002,     0.0012],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0012,     0.9641,     0.0049,     0.0008,     0.0291],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0131,     0.8704,     0.0392,     0.0772],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0070, 0.0009, 0.0014, 0.7148, 0.2759], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0060, 0.0459, 0.0340, 0.2575, 0.6565], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8452803
siam score:  -0.84575164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.95023820123522
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.00524190763245
printing an ep nov before normalisation:  35.182126390966864
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.315948827073406
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8411552
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8425408
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.727273773772566
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.16485277157141
printing an ep nov before normalisation:  81.43337449233005
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.223321313248896
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.359]
 [30.077]
 [45.371]
 [43.554]
 [25.056]] [[0.427]
 [0.575]
 [1.057]
 [1.   ]
 [0.417]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.02022842854585
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  2.1914516829773288e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.12782441428008
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.278]
 [44.278]
 [49.83 ]
 [44.278]
 [44.278]] [[1.307]
 [1.307]
 [1.569]
 [1.307]
 [1.307]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.329972388953216
printing an ep nov before normalisation:  66.94740410019149
printing an ep nov before normalisation:  37.26802714110914
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.930740564533316
printing an ep nov before normalisation:  31.244999937774896
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.42804322389306
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  17.440158803839545
Sims:  40 1 epoch:  49945 pick best:  False frame count:  49945
actions average: 
K:  3  action  0 :  tensor([    0.9827,     0.0129,     0.0000,     0.0003,     0.0042],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0004,     0.9954,     0.0001,     0.0012,     0.0028],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0162, 0.0009, 0.9159, 0.0237, 0.0433], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0010,     0.0005,     0.0950,     0.7526,     0.1509],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0014, 0.0017, 0.0876, 0.3175, 0.5917], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.20077259545009
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.161]
 [26.217]
 [28.224]
 [26.217]
 [26.217]] [[0.465]
 [0.36 ]
 [0.414]
 [0.36 ]
 [0.36 ]]
printing an ep nov before normalisation:  34.93750333786011
printing an ep nov before normalisation:  22.84110983212789
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 30.145347165150483
printing an ep nov before normalisation:  55.187097043796356
printing an ep nov before normalisation:  35.08007482454994
siam score:  -0.8533854
printing an ep nov before normalisation:  44.81273128541752
printing an ep nov before normalisation:  29.50056911886045
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.37 ]
 [29.166]
 [24.311]
 [23.345]
 [25.23 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.118548114525854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8607704
printing an ep nov before normalisation:  37.21788221852853
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9860,     0.0007,     0.0000,     0.0016,     0.0116],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0009,     0.9818,     0.0003,     0.0007,     0.0163],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0079,     0.9238,     0.0312,     0.0371],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0128,     0.0004,     0.0875,     0.7567,     0.1426],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0012, 0.0023, 0.1531, 0.3655, 0.4779], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  40.371946373319396
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.851857788320785
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.86533594
printing an ep nov before normalisation:  84.77379893613889
siam score:  -0.8626063
printing an ep nov before normalisation:  65.02131394232319
printing an ep nov before normalisation:  29.99476432800293
printing an ep nov before normalisation:  46.0456657409668
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.463]
 [42.463]
 [53.844]
 [42.463]
 [42.463]] [[0.562]
 [0.562]
 [0.882]
 [0.562]
 [0.562]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.94118224974507
printing an ep nov before normalisation:  44.95655328474178
actions average: 
K:  1  action  0 :  tensor([    0.9978,     0.0000,     0.0000,     0.0002,     0.0019],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0027,     0.9734,     0.0163,     0.0000,     0.0076],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.9235,     0.0349,     0.0414],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0006,     0.0002,     0.0484,     0.6432,     0.3076],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0015, 0.0327, 0.1000, 0.2183, 0.6474], grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.1974458694458
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.94238597760287
printing an ep nov before normalisation:  49.038703030847
printing an ep nov before normalisation:  43.58266728510523
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.00515875808696
printing an ep nov before normalisation:  50.50600338378781
UNIT TEST: sample policy line 217 mcts : [0.128 0.154 0.205 0.205 0.308]
printing an ep nov before normalisation:  30.05878448486328
printing an ep nov before normalisation:  54.581484421059436
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.76839923892733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.67013825939362
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8760861
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.68527218469681
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.409]
 [49.409]
 [52.323]
 [49.409]
 [49.409]] [[1.624]
 [1.624]
 [1.769]
 [1.624]
 [1.624]]
siam score:  -0.875519
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0020436425359093846
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0016389291681662144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  18.23253511754794
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.00038026537481528067
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.840091563684446
printing an ep nov before normalisation:  76.69845916942676
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9993,     0.0000,     0.0001,     0.0003,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9804,     0.0002,     0.0000,     0.0193],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.9169,     0.0466,     0.0365],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0002,     0.0499,     0.7516,     0.1981],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0021, 0.0042, 0.1486, 0.2387, 0.6064], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.468]
 [20.684]
 [23.457]
 [23.99 ]
 [21.273]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.531]
 [22.848]
 [25.531]
 [26.582]
 [25.844]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.099]
 [36.099]
 [36.239]
 [36.099]
 [36.099]] [[1.676]
 [1.676]
 [1.687]
 [1.676]
 [1.676]]
siam score:  -0.8720366
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9606,     0.0006,     0.0000,     0.0206,     0.0182],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0034,     0.9329,     0.0321,     0.0005,     0.0311],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0064,     0.8435,     0.0216,     0.1285],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0000,     0.0001,     0.0659,     0.7668,     0.1672],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0011, 0.0017, 0.0592, 0.3967, 0.5413], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.03517246246338
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.16825297694504
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.37447452545166
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.75604321268874
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.541]
 [31.875]
 [31.875]
 [46.692]
 [47.348]] [[0.615]
 [0.18 ]
 [0.18 ]
 [0.464]
 [0.477]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.15080568971313
siam score:  -0.8752157
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.06929301907654
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.938]
 [79.528]
 [79.528]
 [79.528]
 [79.528]] [[2.  ]
 [1.86]
 [1.86]
 [1.86]
 [1.86]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.17330825017592
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.87128276
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.318]
 [21.414]
 [29.095]
 [25.145]
 [22.959]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
UNIT TEST: sample policy line 217 mcts : [0.179 0.103 0.103 0.538 0.077]
printing an ep nov before normalisation:  19.274035692214966
printing an ep nov before normalisation:  27.844772245099385
printing an ep nov before normalisation:  27.252772654717806
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.99 ]
 [46.857]
 [42.497]
 [50.53 ]
 [45.202]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 8.794]
 [10.168]
 [10.622]
 [12.456]
 [10.7  ]] [[0.144]
 [0.167]
 [0.174]
 [0.204]
 [0.175]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9979,     0.0006,     0.0000,     0.0014],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0003,     0.9312,     0.0263,     0.0421],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0012,     0.0615,     0.7404,     0.1963],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0027, 0.0629, 0.0507, 0.4498, 0.4339], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  78.95934402798153
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.35516357421875
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.600201946466385
siam score:  -0.8785983
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.58236676545837
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0009,     0.9943,     0.0011,     0.0001,     0.0035],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0032,     0.9149,     0.0164,     0.0654],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0030,     0.0004,     0.1491,     0.5432,     0.3043],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0174, 0.0457, 0.0413, 0.3355, 0.5602], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.113]
 [79.113]
 [89.896]
 [79.113]
 [79.113]] [[1.157]
 [1.157]
 [1.333]
 [1.157]
 [1.157]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.301]
 [28.664]
 [38.409]
 [28.065]
 [29.45 ]] [[0.402]
 [0.485]
 [0.828]
 [0.464]
 [0.513]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.901380077609545
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.86912775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.86935866
printing an ep nov before normalisation:  48.765655966435695
printing an ep nov before normalisation:  50.15350202100846
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.214]
 [39.214]
 [39.214]
 [39.214]
 [39.214]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.89360240379508
actions average: 
K:  2  action  0 :  tensor([    0.9986,     0.0000,     0.0000,     0.0007,     0.0007],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0016,     0.9961,     0.0000,     0.0000,     0.0022],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0014,     0.9349,     0.0340,     0.0295],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0015,     0.0004,     0.0311,     0.7750,     0.1920],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0521, 0.0092, 0.1389, 0.2660, 0.5339], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 39.96469538563071
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.14774867596234
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9896,     0.0006,     0.0000,     0.0018,     0.0079],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0004,     0.9771,     0.0171,     0.0003,     0.0050],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0029,     0.0004,     0.9120,     0.0512,     0.0334],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0024, 0.0012, 0.0489, 0.7523, 0.1952], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0032, 0.0040, 0.0367, 0.3503, 0.6057], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  90.70428205388198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9970,     0.0010,     0.0000,     0.0001,     0.0019],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9993,     0.0003,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0059,     0.8699,     0.0396,     0.0846],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0020, 0.0007, 0.1238, 0.6398, 0.2337], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0100, 0.0013, 0.2135, 0.2523, 0.5229], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  59.93305671250715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.279]
 [31.554]
 [57.413]
 [53.54 ]
 [31.554]] [[0.526]
 [0.163]
 [0.595]
 [0.53 ]
 [0.163]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.1597286867243
printing an ep nov before normalisation:  26.327853202819824
printing an ep nov before normalisation:  52.55602854842441
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.982]
 [52.488]
 [44.887]
 [44.887]
 [44.887]] [[1.34 ]
 [1.514]
 [1.138]
 [1.138]
 [1.138]]
printing an ep nov before normalisation:  41.02242469787598
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.312]
 [63.528]
 [58.626]
 [63.131]
 [59.028]] [[1.705]
 [1.64 ]
 [1.46 ]
 [1.625]
 [1.475]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.15240716934204
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.23004452180916
printing an ep nov before normalisation:  51.33786979667322
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.16088858960361
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.522]
 [34.145]
 [53.171]
 [47.294]
 [54.47 ]] [[0.189]
 [0.173]
 [0.391]
 [0.324]
 [0.406]]
printing an ep nov before normalisation:  0.01972305114691153
printing an ep nov before normalisation:  61.7778973916498
printing an ep nov before normalisation:  53.31213108341335
printing an ep nov before normalisation:  49.19627060030598
printing an ep nov before normalisation:  31.0837459564209
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8790433
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.79170322418213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.233]
 [20.355]
 [20.355]
 [20.355]
 [20.355]] [[1.182]
 [0.515]
 [0.515]
 [0.515]
 [0.515]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8825044
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9763,     0.0173,     0.0008,     0.0009,     0.0047],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9988,     0.0002,     0.0000,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0004,     0.0004,     0.8672,     0.0587,     0.0734],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0016, 0.0019, 0.1524, 0.6225, 0.2215], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0021, 0.0369, 0.2656, 0.1503, 0.5451], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.305]
 [36.305]
 [36.305]
 [36.305]
 [36.305]] [[0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]]
printing an ep nov before normalisation:  45.7084353531011
printing an ep nov before normalisation:  20.414390563964844
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.339]
 [57.339]
 [65.136]
 [57.339]
 [57.339]] [[0.809]
 [0.809]
 [1.   ]
 [0.809]
 [0.809]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.803750299912906
printing an ep nov before normalisation:  61.15916469705338
printing an ep nov before normalisation:  31.43412170589147
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.006]
 [68.868]
 [91.248]
 [77.332]
 [68.868]] [[0.519]
 [0.842]
 [1.225]
 [0.987]
 [0.842]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.976514679177072
line 256 mcts: sample exp_bonus 47.284652609726976
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0006,     0.9664,     0.0096,     0.0001,     0.0233],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0028,     0.9154,     0.0415,     0.0401],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0034,     0.0004,     0.0643,     0.6541,     0.2777],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0018, 0.0166, 0.1900, 0.2377, 0.5539], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.028915291288065
printing an ep nov before normalisation:  39.54949962632902
siam score:  -0.8820552
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.28704252193068
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.402]
 [58.402]
 [61.573]
 [58.402]
 [58.402]] [[1.291]
 [1.291]
 [1.409]
 [1.291]
 [1.291]]
printing an ep nov before normalisation:  56.117420012391
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.733]
 [27.733]
 [44.987]
 [27.733]
 [27.733]] [[0.364]
 [0.364]
 [0.749]
 [0.364]
 [0.364]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.637]
 [84.637]
 [84.637]
 [84.637]
 [84.637]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.85969087371701
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.5037899017334
printing an ep nov before normalisation:  62.427681222275716
printing an ep nov before normalisation:  39.23276901245117
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.31393647084363
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.6696875613071
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.88001496
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.458]
 [21.458]
 [21.458]
 [21.458]
 [21.458]] [[0.396]
 [0.396]
 [0.396]
 [0.396]
 [0.396]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.26723973198959
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.633]
 [50.633]
 [63.905]
 [50.633]
 [50.633]] [[0.636]
 [0.636]
 [0.875]
 [0.636]
 [0.636]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.651735305786133
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88243264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9992,     0.0002,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0003,     0.9933,     0.0034,     0.0004,     0.0026],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0005,     0.0001,     0.8343,     0.0965,     0.0686],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0006,     0.0002,     0.0849,     0.7480,     0.1662],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0025, 0.0177, 0.0984, 0.3269, 0.5544], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  68.25929245705802
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.859651844929875
printing an ep nov before normalisation:  23.0629304525903
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.87370473
printing an ep nov before normalisation:  38.77122035487249
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.052]
 [41.052]
 [41.052]
 [41.052]
 [41.052]] [[0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.485]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.03630125571233
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  54.911932945251465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9952,     0.0000,     0.0000,     0.0018,     0.0030],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0028,     0.9197,     0.0523,     0.0003,     0.0250],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0007,     0.8454,     0.0473,     0.1065],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0002,     0.1089,     0.6045,     0.2863],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0018, 0.0026, 0.0294, 0.3400, 0.6261], grad_fn=<DivBackward0>)
siam score:  -0.875381
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.188395414228516
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.630923982947735
printing an ep nov before normalisation:  32.80645020988127
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  52.28978613198129
printing an ep nov before normalisation:  31.473855284234133
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.82021846870261
printing an ep nov before normalisation:  0.0036503229637219192
printing an ep nov before normalisation:  45.95223885557409
printing an ep nov before normalisation:  29.596795108932152
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0004,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0006,     0.9978,     0.0007,     0.0001,     0.0008],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0043, 0.0064, 0.9158, 0.0376, 0.0359], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0002,     0.0348,     0.6059,     0.3590],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0086, 0.0007, 0.0375, 0.3183, 0.6349], grad_fn=<DivBackward0>)
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  33.761757701192735
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.163]
 [30.063]
 [31.648]
 [33.163]
 [33.163]] [[1.052]
 [0.865]
 [0.961]
 [1.052]
 [1.052]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.332345747593656
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.57080828719787
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.87714094
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.114]
 [25.661]
 [24.77 ]
 [23.114]
 [23.519]] [[0.75 ]
 [0.91 ]
 [0.854]
 [0.75 ]
 [0.776]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.404]
 [43.404]
 [61.088]
 [43.404]
 [43.404]] [[0.538]
 [0.538]
 [1.113]
 [0.538]
 [0.538]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.88103193
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.789524776942834
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.27306365966797
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 41.66694362667034
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.957]
 [28.459]
 [23.704]
 [20.865]
 [22.994]] [[0.347]
 [0.247]
 [0.183]
 [0.145]
 [0.174]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.92438793182373
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.945089328066295
printing an ep nov before normalisation:  46.719536901779776
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.995384343599774
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.657]
 [37.822]
 [45.536]
 [42.158]
 [41.251]] [[0.549]
 [0.388]
 [0.57 ]
 [0.49 ]
 [0.469]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.79965591430664
printing an ep nov before normalisation:  40.21987367635229
printing an ep nov before normalisation:  0.09725423704765035
printing an ep nov before normalisation:  41.777557619125304
printing an ep nov before normalisation:  29.950790405273438
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.40415214563107
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.8778886
printing an ep nov before normalisation:  67.34292436085774
actions average: 
K:  3  action  0 :  tensor([    0.9953,     0.0001,     0.0000,     0.0023,     0.0024],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0006,     0.9788,     0.0036,     0.0001,     0.0169],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0010, 0.0038, 0.8038, 0.1096, 0.0818], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0003,     0.0919,     0.7081,     0.1995],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0008, 0.0008, 0.1367, 0.2906, 0.5710], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  23.234485085667465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8796751
printing an ep nov before normalisation:  55.57662445710054
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.016]
 [0.016]
 [0.016]
 [0.016]
 [0.016]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.61685382000206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.61685988096033
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.48788070678711
printing an ep nov before normalisation:  51.50698026021321
printing an ep nov before normalisation:  61.50701639954731
printing an ep nov before normalisation:  0.038588643121784116
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9979,     0.0001,     0.0000,     0.0009,     0.0012],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0004,     0.9883,     0.0010,     0.0002,     0.0102],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0005,     0.0003,     0.8266,     0.0854,     0.0873],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0008, 0.0127, 0.1396, 0.5778, 0.2691], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0049, 0.0026, 0.0432, 0.2046, 0.7447], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.11179237513275
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.379]
 [15.258]
 [17.077]
 [13.022]
 [13.74 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.863238033476925
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.205]
 [55.554]
 [52.205]
 [55.791]
 [59.07 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8964261
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9988,     0.0000,     0.0000,     0.0006,     0.0006],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9975,     0.0011,     0.0000,     0.0014],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0008,     0.9700,     0.0114,     0.0178],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0001,     0.0311,     0.8439,     0.1247],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0024, 0.0005, 0.0727, 0.4032, 0.5211], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  45.08242959085282
printing an ep nov before normalisation:  48.22674109843961
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.394136030121786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.735620498657227
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  50.19356369176995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.94938898086548
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.99179935455322
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.363]
 [41.363]
 [41.363]
 [41.363]
 [41.363]] [[1.092]
 [1.092]
 [1.092]
 [1.092]
 [1.092]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.368]
 [43.938]
 [43.938]
 [49.513]
 [48.534]] [[0.299]
 [0.229]
 [0.229]
 [0.258]
 [0.253]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  56.27502070838393
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.251]
 [32.881]
 [32.881]
 [32.881]
 [32.881]] [[1.108]
 [0.373]
 [0.373]
 [0.373]
 [0.373]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8829477
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.028417296037105
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9990,     0.0001,     0.0000,     0.0000,     0.0009],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0008,     0.9413,     0.0003,     0.0001,     0.0574],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0093,     0.8274,     0.0835,     0.0796],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0016, 0.0007, 0.0767, 0.5758, 0.3452], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0033, 0.0011, 0.0832, 0.4383, 0.4741], grad_fn=<DivBackward0>)
siam score:  -0.8842452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.57102705065835
printing an ep nov before normalisation:  42.84653356573696
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.952]
 [46.815]
 [48.739]
 [34.719]
 [27.795]] [[0.13 ]
 [0.246]
 [0.26 ]
 [0.157]
 [0.107]]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 -2.913916867224876e-11
0.0 0.0
0.0 -4.4750982104684087e-11
0.0 -2.7435275459169545e-11
0.0 0.0
0.0 0.0
0.0 0.0
0.0 0.0
0.0 0.0
0.0 -2.6319528132719005e-11
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  34.36608076095581
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87701255
printing an ep nov before normalisation:  61.913987687018334
printing an ep nov before normalisation:  31.062905301970247
actions average: 
K:  3  action  0 :  tensor([    0.7017,     0.0004,     0.0000,     0.1324,     0.1654],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0051,     0.9396,     0.0003,     0.0289,     0.0261],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0005,     0.0040,     0.8684,     0.0569,     0.0701],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0002,     0.0561,     0.7726,     0.1710],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0001,     0.0573,     0.2141,     0.2778,     0.4507],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.25431936984505
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.835]
 [32.638]
 [29.527]
 [33.321]
 [33.416]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.64667600388484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  30.553051583369015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.353]
 [24.806]
 [27.6  ]
 [28.067]
 [23.351]] [[0.653]
 [0.584]
 [0.708]
 [0.729]
 [0.519]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.216]
 [33.216]
 [71.314]
 [33.216]
 [33.216]] [[0.283]
 [0.283]
 [0.902]
 [0.283]
 [0.283]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 67.99728086775369
using explorer policy with actor:  1
printing an ep nov before normalisation:  60.61832762099868
printing an ep nov before normalisation:  56.84357593656081
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.595]
 [43.595]
 [43.595]
 [43.595]
 [43.595]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
printing an ep nov before normalisation:  39.71355199813843
siam score:  -0.8869284
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.906]
 [40.906]
 [40.906]
 [40.906]
 [40.906]] [[0.18]
 [0.18]
 [0.18]
 [0.18]
 [0.18]]
printing an ep nov before normalisation:  43.88438700393111
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.067]
 [24.315]
 [33.133]
 [24.681]
 [28.564]] [[0.222]
 [0.182]
 [0.308]
 [0.188]
 [0.243]]
printing an ep nov before normalisation:  32.39635944366455
printing an ep nov before normalisation:  33.78081341349674
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.567]
 [22.62 ]
 [19.567]
 [21.685]
 [22.344]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.884173
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.03999197076702
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.838227131223704
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  82.76857218973129
printing an ep nov before normalisation:  40.70803580312093
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.413]
 [30.413]
 [40.746]
 [38.83 ]
 [30.413]] [[0.501]
 [0.501]
 [0.823]
 [0.763]
 [0.501]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.981]
 [37.981]
 [40.213]
 [37.981]
 [38.471]] [[0.938]
 [0.938]
 [1.011]
 [0.938]
 [0.954]]
printing an ep nov before normalisation:  36.62661075592041
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.708296159078397
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.89073163
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.4891559706957
printing an ep nov before normalisation:  38.45269186141339
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.2159562289571
printing an ep nov before normalisation:  45.31485419061184
using explorer policy with actor:  1
siam score:  -0.8895833
printing an ep nov before normalisation:  54.05327698565736
printing an ep nov before normalisation:  66.98670030579687
siam score:  -0.89036334
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.779]
 [12.291]
 [11.86 ]
 [ 9.64 ]
 [ 5.933]] [[0.163]
 [0.156]
 [0.151]
 [0.123]
 [0.075]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.671589962256977
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9984,     0.0003,     0.0000,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0002,     0.9307,     0.0359,     0.0331],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0012,     0.0001,     0.0657,     0.7267,     0.2062],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0106, 0.0606, 0.0280, 0.3500, 0.5508], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.85459518432617
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.747307193326492
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.042]
 [41.042]
 [48.517]
 [41.042]
 [41.042]] [[0.843]
 [0.843]
 [1.085]
 [0.843]
 [0.843]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.784]
 [37.784]
 [37.784]
 [42.258]
 [37.784]] [[0.975]
 [0.975]
 [0.975]
 [1.169]
 [0.975]]
siam score:  -0.8925745
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8915458
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.172964819997887
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.30440228595126
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88179797
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.609]
 [32.192]
 [32.804]
 [32.192]
 [32.192]] [[1.534]
 [1.412]
 [1.464]
 [1.412]
 [1.412]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.806]
 [40.806]
 [40.806]
 [40.806]
 [40.806]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
printing an ep nov before normalisation:  52.05226489265615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8738575
siam score:  -0.87412
siam score:  -0.873346
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.310355481982995
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.746]
 [39.404]
 [39.998]
 [45.881]
 [44.709]] [[0.456]
 [0.313]
 [0.326]
 [0.459]
 [0.433]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.289586864050676
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.23159105357043
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.8888997
printing an ep nov before normalisation:  34.47579383850098
printing an ep nov before normalisation:  34.09015484297262
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.25337911981515
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.07916314220903
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.19324799491396
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9983,     0.0001,     0.0000,     0.0003,     0.0013],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0013,     0.9259,     0.0345,     0.0001,     0.0382],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0006,     0.0001,     0.9041,     0.0498,     0.0454],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0002,     0.0557,     0.7005,     0.2434],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0017, 0.0024, 0.2096, 0.3068, 0.4796], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  55.76049418606508
printing an ep nov before normalisation:  69.57136512994396
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0023792364977452962
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.374085426330566
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.74889072833794
siam score:  -0.88441545
printing an ep nov before normalisation:  66.45415771268715
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.997]
 [46.67 ]
 [41.549]
 [53.827]
 [48.047]] [[0.836]
 [0.6  ]
 [0.435]
 [0.831]
 [0.645]]
printing an ep nov before normalisation:  27.736146841931877
printing an ep nov before normalisation:  31.718939337127562
printing an ep nov before normalisation:  51.8986497231063
actions average: 
K:  1  action  0 :  tensor([    0.9946,     0.0001,     0.0000,     0.0026,     0.0027],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9989,     0.0000,     0.0001,     0.0009],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0051,     0.9442,     0.0258,     0.0249],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0001,     0.0416,     0.7974,     0.1607],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0016, 0.0028, 0.1614, 0.1554, 0.6789], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.17 ]
 [55.514]
 [55.514]
 [55.514]
 [55.514]] [[1.287]
 [1.1  ]
 [1.1  ]
 [1.1  ]
 [1.1  ]]
actions average: 
K:  4  action  0 :  tensor([    0.9967,     0.0003,     0.0000,     0.0005,     0.0024],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0004,     0.8805,     0.0263,     0.0927],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0017, 0.0131, 0.1117, 0.6146, 0.2590], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0579, 0.0057, 0.2048, 0.2282, 0.5033], grad_fn=<DivBackward0>)
siam score:  -0.8874304
printing an ep nov before normalisation:  38.45320224761963
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.342]
 [37.257]
 [37.257]
 [37.75 ]
 [37.257]] [[0.87 ]
 [0.508]
 [0.508]
 [0.519]
 [0.508]]
UNIT TEST: sample policy line 217 mcts : [0.026 0.051 0.667 0.205 0.051]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9986,     0.0000,     0.0000,     0.0005,     0.0009],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0030,     0.9633,     0.0000,     0.0017,     0.0320],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0007,     0.0004,     0.8952,     0.0426,     0.0611],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0005,     0.0261,     0.7715,     0.2015],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0016, 0.0032, 0.1571, 0.2667, 0.5715], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.982211808651726
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9999,     0.0001,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0145,     0.8924,     0.0393,     0.0538],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0021,     0.0004,     0.0679,     0.6861,     0.2436],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0564, 0.0202, 0.0617, 0.2647, 0.5971], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  43.0108672221724
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9968,     0.0007,     0.0000,     0.0024],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.8722,     0.0466,     0.0811],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0014,     0.0002,     0.0841,     0.6643,     0.2500],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0013,     0.0003,     0.0845,     0.3822,     0.5317],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.38039086250272
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.63938708830037
printing an ep nov before normalisation:  54.09669961082683
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.401]
 [37.401]
 [37.401]
 [37.401]
 [37.401]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  49.30280024896374
printing an ep nov before normalisation:  48.327187389407
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.247]
 [10.978]
 [ 8.892]
 [ 9.4  ]
 [13.383]] [[0.4  ]
 [0.391]
 [0.316]
 [0.334]
 [0.476]]
printing an ep nov before normalisation:  45.04763603210449
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.057733710173444
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.160856655784304
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88620985
printing an ep nov before normalisation:  44.26998447293099
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.861]
 [39.945]
 [45.032]
 [36.825]
 [43.975]] [[0.305]
 [0.207]
 [0.263]
 [0.173]
 [0.251]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.63047919378532
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0005,     0.9784,     0.0003,     0.0000,     0.0207],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0069,     0.8656,     0.0465,     0.0810],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0006,     0.1303,     0.6871,     0.1813],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0089, 0.0029, 0.1224, 0.2553, 0.6105], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.34509822954598
printing an ep nov before normalisation:  37.511931870203064
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  63.86927406973788
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.998]
 [53.998]
 [53.998]
 [53.998]
 [53.998]] [[1.159]
 [1.159]
 [1.159]
 [1.159]
 [1.159]]
siam score:  -0.889395
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.282]
 [27.661]
 [34.352]
 [27.765]
 [27.964]] [[0.623]
 [0.596]
 [0.884]
 [0.601]
 [0.609]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.6207591455703
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.727159227480655
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.24953770838521
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.444]
 [54.622]
 [53.444]
 [53.444]
 [53.444]] [[1.392]
 [1.448]
 [1.392]
 [1.392]
 [1.392]]
printing an ep nov before normalisation:  59.57556490997408
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.90308953098312
printing an ep nov before normalisation:  34.736928939819336
printing an ep nov before normalisation:  28.096271627400192
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  47.21546828820496
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.5436917202768
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.729]
 [35.807]
 [34.217]
 [36.909]
 [37.369]] [[0.789]
 [0.747]
 [0.673]
 [0.798]
 [0.819]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.705911543061475
printing an ep nov before normalisation:  68.70751154916881
printing an ep nov before normalisation:  74.09102712047944
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.196887531279145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8836663
printing an ep nov before normalisation:  63.836908647716044
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.672058869062454
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.874522
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.68 ]
 [31.663]
 [31.322]
 [28.213]
 [28.363]] [[1.01 ]
 [1.075]
 [1.052]
 [0.847]
 [0.857]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.841]
 [28.841]
 [58.39 ]
 [28.841]
 [28.841]] [[0.408]
 [0.408]
 [1.036]
 [0.408]
 [0.408]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.08677494198329
printing an ep nov before normalisation:  44.94602070141131
printing an ep nov before normalisation:  41.27855147967291
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8824246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.105725288391113
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.76457140696533
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.5242500384716
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9988,     0.0002,     0.0000,     0.0002,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0066,     0.9585,     0.0011,     0.0000,     0.0337],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.7824,     0.1090,     0.1084],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0077,     0.0660,     0.7223,     0.2037],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0006,     0.0221,     0.0649,     0.3405,     0.5720],
       grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.58651638031006
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.21705263421746
printing an ep nov before normalisation:  22.822203465636278
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.52707500943172
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.765]
 [26.765]
 [39.388]
 [26.765]
 [26.765]] [[0.107]
 [0.107]
 [0.196]
 [0.107]
 [0.107]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.7724823835734
printing an ep nov before normalisation:  66.87356445558379
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  4.581541475090489e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [53.217]] [[-0.446]
 [-0.446]
 [-0.446]
 [-0.446]
 [ 0.689]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8922195
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.116743221053575
printing an ep nov before normalisation:  62.12568738243253
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.60355640797425
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.062422918500175
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  44.23697471618652
printing an ep nov before normalisation:  24.19520854949951
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.59628144170513
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9712,     0.0155,     0.0000,     0.0061,     0.0073],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9958,     0.0001,     0.0002,     0.0038],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0285,     0.8378,     0.0601,     0.0734],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0000,     0.0002,     0.0935,     0.7853,     0.1210],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0004,     0.0356,     0.0796,     0.2909,     0.5936],
       grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  102.021619941134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  90.09091421272008
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.523]
 [53.523]
 [53.523]
 [57.669]
 [53.523]] [[1.795]
 [1.795]
 [1.795]
 [1.963]
 [1.795]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.931]
 [46.931]
 [46.255]
 [46.931]
 [46.931]] [[1.961]
 [1.961]
 [1.922]
 [1.961]
 [1.961]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.94903072717335
actions average: 
K:  3  action  0 :  tensor([    0.9997,     0.0001,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0003,     0.9976,     0.0001,     0.0000,     0.0020],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0073,     0.8677,     0.0504,     0.0746],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0004,     0.0736,     0.7200,     0.2057],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0199, 0.0498, 0.1124, 0.2373, 0.5807], grad_fn=<DivBackward0>)
siam score:  -0.8789447
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 45.648667097091675
printing an ep nov before normalisation:  31.34969302586147
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.51 ]
 [33.076]
 [47.226]
 [35.874]
 [33.51 ]] [[0.73 ]
 [0.715]
 [1.191]
 [0.81 ]
 [0.73 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.77807644855704
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.53282990034642
line 256 mcts: sample exp_bonus 45.906685722889286
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.55747533220469
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.814]
 [34.756]
 [23.733]
 [34.597]
 [34.905]] [[0.929]
 [0.861]
 [0.497]
 [0.855]
 [0.866]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.801102833196474
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.23371965161283
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.31098943565513
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.204]
 [39.619]
 [42.491]
 [39.619]
 [39.619]] [[0.543]
 [0.553]
 [0.626]
 [0.553]
 [0.553]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.974]
 [41.077]
 [41.077]
 [41.077]
 [39.528]] [[0.667]
 [0.568]
 [0.568]
 [0.568]
 [0.528]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88855195
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0005,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0006,     0.9965,     0.0001,     0.0004,     0.0024],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0005,     0.0018,     0.8822,     0.0528,     0.0628],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0002,     0.1841,     0.5707,     0.2446],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0045,     0.0014,     0.0004,     0.3410,     0.6527],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88751554
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.86494643513197
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.30336638282331
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.266518469445984
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8884297
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.49072460405144
printing an ep nov before normalisation:  43.891280558208635
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.27693194831599
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.930000167646256
siam score:  -0.88442457
printing an ep nov before normalisation:  0.0009129301542998292
printing an ep nov before normalisation:  30.925118377107477
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  105.39848248401462
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.09952029300888
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.63843749799712
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.46517639474748
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.779]
 [41.055]
 [36.273]
 [35.104]
 [36.493]] [[0.532]
 [0.657]
 [0.517]
 [0.482]
 [0.523]]
printing an ep nov before normalisation:  39.99093532562256
actions average: 
K:  4  action  0 :  tensor([    0.9964,     0.0002,     0.0000,     0.0013,     0.0021],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0011, 0.9583, 0.0024, 0.0217, 0.0165], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.8746,     0.0558,     0.0693],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0005,     0.0549,     0.6453,     0.2988],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0026, 0.0032, 0.1552, 0.2392, 0.5997], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.504891999251953
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.004]
 [25.004]
 [25.004]
 [25.004]
 [25.004]] [[0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]]
printing an ep nov before normalisation:  50.55467689336703
printing an ep nov before normalisation:  31.195406353335127
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.376815960947305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.19682569701542
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.491388242650345
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.477922474188567
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.49076153646573
printing an ep nov before normalisation:  32.598951370725224
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.74867508825209
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9946,     0.0002,     0.0005,     0.0017,     0.0029],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0004,     0.9356,     0.0042,     0.0119,     0.0479],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9128,     0.0373,     0.0499],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0009,     0.0913,     0.6958,     0.2117],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0011, 0.0012, 0.0464, 0.2495, 0.7019], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.60600497625509
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.065366987776464
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.54555101583685
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.341094702457877
printing an ep nov before normalisation:  47.1501319566317
printing an ep nov before normalisation:  74.20261914935651
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.1078795013048
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.894]
 [29.4  ]
 [29.4  ]
 [29.4  ]
 [29.4  ]] [[0.48 ]
 [0.247]
 [0.247]
 [0.247]
 [0.247]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 38.74690217391726
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  46.23667172023229
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.089]
 [69.089]
 [69.089]
 [69.089]
 [69.089]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  64.74721499613679
printing an ep nov before normalisation:  49.075798234663715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.962]
 [32.962]
 [31.126]
 [32.445]
 [33.358]] [[0.747]
 [0.747]
 [0.671]
 [0.726]
 [0.764]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.486370146845616
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  22.507138415611543
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87273246
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.8852034989467
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0309, 0.0093, 0.8089, 0.0553, 0.0956], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0062,     0.0585,     0.7418,     0.1932],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0086, 0.0388, 0.1180, 0.3249, 0.5098], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.013]
 [48.22 ]
 [32.013]
 [32.013]
 [32.013]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.244]
 [39.148]
 [37.625]
 [35.238]
 [35.545]] [[0.249]
 [0.259]
 [0.243]
 [0.216]
 [0.22 ]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.753493221312468
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.62246036529541
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.1152085122148
printing an ep nov before normalisation:  51.45618269874047
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.00455209349448
printing an ep nov before normalisation:  0.016282940191558737
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.72689247131348
line 256 mcts: sample exp_bonus 33.86778085240669
printing an ep nov before normalisation:  25.13514475615727
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88790536
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.069214432970696
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.403514468462426
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.78272247314453
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.79713987313264
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.61269850470481
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.723]
 [44.356]
 [48.869]
 [44.848]
 [44.155]] [[0.401]
 [0.681]
 [0.8  ]
 [0.694]
 [0.676]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.29768319688196
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.9  ]
 [28.418]
 [28.283]
 [28.35 ]
 [27.791]] [[0.188]
 [0.226]
 [0.224]
 [0.225]
 [0.216]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.47977638244629
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.2150925378786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.02682706217762
printing an ep nov before normalisation:  66.48276194062669
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.946538649785374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8872476
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.661]
 [26.661]
 [30.806]
 [25.099]
 [26.661]] [[0.488]
 [0.488]
 [0.633]
 [0.434]
 [0.488]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.097344808133577
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.64673137664795
printing an ep nov before normalisation:  21.35472812777033
printing an ep nov before normalisation:  39.119403985387386
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.887]
 [23.887]
 [23.887]
 [23.887]
 [23.887]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  35.527294151989224
printing an ep nov before normalisation:  21.374501469346477
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 22.499991797386947
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.655730043873298
printing an ep nov before normalisation:  32.03109633085162
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.365]
 [29.365]
 [29.365]
 [33.625]
 [29.365]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  22.235300540924072
printing an ep nov before normalisation:  69.05523179732708
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  40.979891410921084
using explorer policy with actor:  1
siam score:  -0.8837265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88424253
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.508]
 [49.255]
 [49.255]
 [49.255]
 [49.255]] [[1.362]
 [1.35 ]
 [1.35 ]
 [1.35 ]
 [1.35 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.977]
 [34.977]
 [34.977]
 [34.977]
 [34.977]] [[0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]]
printing an ep nov before normalisation:  22.578503051933758
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  45.65477198945727
printing an ep nov before normalisation:  36.31809180128666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  39.7813127642907
printing an ep nov before normalisation:  49.28300040303899
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.114]
 [39.496]
 [39.193]
 [39.193]
 [39.193]] [[0.569]
 [0.767]
 [0.756]
 [0.756]
 [0.756]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.732850403280338
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.324]
 [36.324]
 [36.324]
 [36.324]
 [36.324]] [[1.829]
 [1.829]
 [1.829]
 [1.829]
 [1.829]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.36367100988381
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.836]
 [36.286]
 [36.747]
 [36.893]
 [36.143]] [[0.499]
 [0.54 ]
 [0.553]
 [0.557]
 [0.536]]
printing an ep nov before normalisation:  62.069057945886435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.814]
 [61.077]
 [60.464]
 [64.622]
 [63.833]] [[2.   ]
 [1.73 ]
 [1.701]
 [1.897]
 [1.859]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.005]
 [42.07 ]
 [44.753]
 [44.508]
 [44.801]] [[0.913]
 [1.319]
 [1.498]
 [1.482]
 [1.501]]
printing an ep nov before normalisation:  67.21827110140208
printing an ep nov before normalisation:  56.9534661237639
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9985,     0.0001,     0.0007,     0.0005],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0002,     0.8837,     0.0495,     0.0665],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0012, 0.0019, 0.1427, 0.6259, 0.2283], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0018, 0.0575, 0.0020, 0.2643, 0.6744], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  25.631657433400324
line 256 mcts: sample exp_bonus 59.63636283848012
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.004971398703901286
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  78.62755642909156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.36412110694756
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.161]
 [47.161]
 [51.836]
 [47.161]
 [47.161]] [[1.316]
 [1.316]
 [1.503]
 [1.316]
 [1.316]]
printing an ep nov before normalisation:  24.284286499023438
printing an ep nov before normalisation:  46.57460072565671
printing an ep nov before normalisation:  38.884531317494925
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.623]
 [46.536]
 [50.71 ]
 [46.053]
 [45.592]] [[0.423]
 [0.471]
 [0.54 ]
 [0.463]
 [0.455]]
printing an ep nov before normalisation:  48.275037424105086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9950,     0.0005,     0.0000,     0.0017,     0.0028],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0016,     0.9919,     0.0001,     0.0002,     0.0063],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0003,     0.0009,     0.8748,     0.0403,     0.0837],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0006,     0.0007,     0.1416,     0.6885,     0.1686],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0118, 0.0075, 0.1488, 0.1490, 0.6830], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.10772488229297
siam score:  -0.88197756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.63659501054199
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.596907897574
printing an ep nov before normalisation:  103.96747362613858
printing an ep nov before normalisation:  26.728868929298116
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.8804591
printing an ep nov before normalisation:  41.25070329448937
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88341975
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.86263354709588
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.026]
 [31.026]
 [35.98 ]
 [31.026]
 [31.026]] [[1.039]
 [1.039]
 [1.399]
 [1.039]
 [1.039]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.814707259768674
printing an ep nov before normalisation:  52.13008808441796
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.258002281188965
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 36.77011749129902
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.52665901184082
printing an ep nov before normalisation:  32.53732299859578
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.9274626832286
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0024607697810097307
printing an ep nov before normalisation:  38.77570210279528
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  38.13636528152594
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.677]
 [30.677]
 [32.855]
 [30.677]
 [30.677]] [[1.717]
 [1.717]
 [1.839]
 [1.717]
 [1.717]]
line 256 mcts: sample exp_bonus 59.977309766794036
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.16246977382746
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  51.276808636943045
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.154 0.41  0.179 0.128 0.128]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8843199
using explorer policy with actor:  1
printing an ep nov before normalisation:  59.602919946035215
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  47.41866943789642
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.71595419900693
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.564]
 [47.68 ]
 [34.51 ]
 [32.663]
 [34.247]] [[0.409]
 [0.351]
 [0.194]
 [0.173]
 [0.191]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.68597819354398
printing an ep nov before normalisation:  51.98723757573012
printing an ep nov before normalisation:  36.258076529857455
printing an ep nov before normalisation:  57.62746432342114
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.949]
 [36.949]
 [36.949]
 [36.949]
 [36.949]] [[0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.085]
 [31.464]
 [30.576]
 [20.085]
 [25.771]] [[0.072]
 [0.213]
 [0.202]
 [0.072]
 [0.142]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.84063148498535
printing an ep nov before normalisation:  26.56093762401066
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.04251172998735
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.047]
 [42.502]
 [48.471]
 [42.601]
 [46.829]] [[0.828]
 [0.695]
 [0.838]
 [0.698]
 [0.799]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
siam score:  -0.88066506
using explorer policy with actor:  1
printing an ep nov before normalisation:  58.11458730543692
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  33.276346747705944
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.57475576241866
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.41917305551041
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 43.384288749710436
printing an ep nov before normalisation:  70.71866551159393
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.298]
 [32.36 ]
 [33.954]
 [31.507]
 [32.771]] [[0.718]
 [1.032]
 [1.13 ]
 [0.979]
 [1.057]]
printing an ep nov before normalisation:  55.73454511792678
printing an ep nov before normalisation:  47.161862657687955
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.17282107740515
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.450494040831916
printing an ep nov before normalisation:  0.0011931551733823653
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.21313771552574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.57842457883402
printing an ep nov before normalisation:  45.61838626861572
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0002192261808886542
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 48.16379465858735
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.114]
 [54.114]
 [57.649]
 [57.967]
 [54.699]] [[1.058]
 [1.058]
 [1.167]
 [1.177]
 [1.076]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9995,     0.0001,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9995,     0.0002,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0019,     0.8778,     0.0493,     0.0709],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0004,     0.1236,     0.7218,     0.1538],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0022, 0.0050, 0.1420, 0.1804, 0.6704], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.802699313275646
siam score:  -0.88319117
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.89722696995985
printing an ep nov before normalisation:  36.9202140023359
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  29.829603213955252
actions average: 
K:  1  action  0 :  tensor([    0.9669,     0.0134,     0.0010,     0.0020,     0.0167],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9987,     0.0004,     0.0001,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0044,     0.0007,     0.8668,     0.0702,     0.0579],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0058,     0.0002,     0.0211,     0.8399,     0.1330],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0328, 0.0019, 0.0470, 0.2923, 0.6260], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  37.56643530500097
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9947,     0.0005,     0.0000,     0.0018,     0.0030],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9976,     0.0001,     0.0004,     0.0019],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.8667,     0.0709,     0.0621],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0002,     0.0904,     0.6871,     0.2222],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0007, 0.0677, 0.1284, 0.1902, 0.6130], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.921181678771973
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.756]
 [60.756]
 [67.429]
 [60.756]
 [60.756]] [[1.121]
 [1.121]
 [1.333]
 [1.121]
 [1.121]]
printing an ep nov before normalisation:  47.55237378912124
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.625]
 [23.053]
 [23.053]
 [23.053]
 [23.053]] [[1.001]
 [0.047]
 [0.047]
 [0.047]
 [0.047]]
printing an ep nov before normalisation:  23.61175775527954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
UNIT TEST: sample policy line 217 mcts : [0.077 0.154 0.385 0.077 0.308]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.3876576224757
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.671]
 [38.671]
 [59.987]
 [38.671]
 [38.671]] [[0.611]
 [0.611]
 [1.165]
 [0.611]
 [0.611]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.230487102103844
printing an ep nov before normalisation:  40.684163340864615
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.549]
 [37.549]
 [60.767]
 [40.723]
 [37.549]] [[0.415]
 [0.415]
 [0.824]
 [0.471]
 [0.415]]
printing an ep nov before normalisation:  79.29164053957803
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.81124397582615
actions average: 
K:  4  action  0 :  tensor([    0.9966,     0.0010,     0.0001,     0.0006,     0.0016],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9960,     0.0009,     0.0003,     0.0027],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.8762,     0.0531,     0.0706],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0001,     0.1346,     0.6768,     0.1884],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0055, 0.0031, 0.2484, 0.2145, 0.5285], grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.609]
 [45.669]
 [59.973]
 [51.882]
 [53.916]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.53808575765919
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.271341296629004
line 256 mcts: sample exp_bonus 50.995663651697576
printing an ep nov before normalisation:  27.34396123186357
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.706]
 [31.706]
 [63.737]
 [31.706]
 [31.706]] [[0.272]
 [0.272]
 [0.977]
 [0.272]
 [0.272]]
line 256 mcts: sample exp_bonus 56.901092523861436
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.17357629290696
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.283]
 [55.283]
 [53.456]
 [55.133]
 [55.283]] [[1.162]
 [1.162]
 [1.105]
 [1.158]
 [1.162]]
printing an ep nov before normalisation:  44.41071033477783
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.179]
 [39.726]
 [41.31 ]
 [46.763]
 [44.803]] [[1.438]
 [0.921]
 [0.987]
 [1.213]
 [1.132]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 58.10570837015089
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.54063604263674
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.841]
 [64.841]
 [64.841]
 [64.841]
 [64.841]] [[1.609]
 [1.609]
 [1.609]
 [1.609]
 [1.609]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.9335297214971
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.09519672393799
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.567]
 [54.327]
 [57.966]
 [56.367]
 [57.308]] [[1.058]
 [1.189]
 [1.317]
 [1.261]
 [1.294]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.98 ]
 [44.75 ]
 [46.126]
 [38.489]
 [46.213]] [[1.541]
 [1.375]
 [1.446]
 [1.054]
 [1.45 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.158]
 [22.194]
 [16.433]
 [16.726]
 [15.889]] [[0.969]
 [1.067]
 [0.79 ]
 [0.804]
 [0.764]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.115]
 [70.115]
 [77.63 ]
 [72.312]
 [70.115]] [[1.273]
 [1.273]
 [1.441]
 [1.322]
 [1.273]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.659693857234245
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.278]
 [40.278]
 [40.278]
 [40.278]
 [40.278]] [[0.586]
 [0.586]
 [0.586]
 [0.586]
 [0.586]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.011846922511996
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  18.482862253187264
printing an ep nov before normalisation:  36.70902072989562
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.659]
 [42.077]
 [46.68 ]
 [46.214]
 [50.121]] [[1.441]
 [1.157]
 [1.443]
 [1.414]
 [1.656]]
printing an ep nov before normalisation:  88.80870320497175
line 256 mcts: sample exp_bonus 48.843424707450446
printing an ep nov before normalisation:  56.37117681332356
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  45.874911509860446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.0464226035665
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.888109314100376
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.874]
 [33.914]
 [32.318]
 [43.876]
 [32.318]] [[0.867]
 [0.537]
 [0.494]
 [0.812]
 [0.494]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8797902
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.28 ]
 [29.178]
 [29.478]
 [29.437]
 [29.707]] [[0.986]
 [0.633]
 [0.646]
 [0.644]
 [0.656]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  60.70231504706485
printing an ep nov before normalisation:  0.007259393107119649
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.667 0.    0.    0.179 0.154]
printing an ep nov before normalisation:  43.64382041982774
printing an ep nov before normalisation:  40.8035122684722
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.48875814628371
printing an ep nov before normalisation:  44.171754068160666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.92396971748287
using explorer policy with actor:  1
printing an ep nov before normalisation:  49.35511112213135
printing an ep nov before normalisation:  49.263078987597105
printing an ep nov before normalisation:  27.5508713722229
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.02088354557315597
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.80258540069948
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.87454176
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.02446436938214447
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [41.248]
 [ 0.   ]
 [ 0.   ]] [[-0.597]
 [-0.597]
 [ 1.166]
 [-0.597]
 [-0.597]]
using explorer policy with actor:  1
siam score:  -0.87557447
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.93248294545928
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.89996918396653
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.664]
 [35.664]
 [35.664]
 [35.664]
 [35.664]] [[1.065]
 [1.065]
 [1.065]
 [1.065]
 [1.065]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.477074279493735
printing an ep nov before normalisation:  85.94878105676979
actions average: 
K:  3  action  0 :  tensor([    0.9976,     0.0001,     0.0000,     0.0016,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9984,     0.0008,     0.0004,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0002,     0.8661,     0.0788,     0.0548],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0005,     0.0004,     0.0869,     0.6869,     0.2254],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0137, 0.0017, 0.0441, 0.3592, 0.5813], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.682]
 [43.682]
 [64.25 ]
 [43.682]
 [43.682]] [[0.866]
 [0.866]
 [1.455]
 [0.866]
 [0.866]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.511296851380614
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8767794
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 24.013461300243634
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.014]
 [60.014]
 [74.232]
 [60.014]
 [60.014]] [[0.94 ]
 [0.94 ]
 [1.224]
 [0.94 ]
 [0.94 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.068842887878418
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.55401664611373
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.322174547732345
printing an ep nov before normalisation:  48.467629226510844
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.7400221824646
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.435271128502354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.928]
 [32.048]
 [31.259]
 [36.488]
 [31.756]] [[0.183]
 [0.166]
 [0.159]
 [0.206]
 [0.164]]
UNIT TEST: sample policy line 217 mcts : [0.128 0.41  0.205 0.103 0.154]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.173]
 [32.496]
 [34.696]
 [33.976]
 [32.656]] [[1.091]
 [1.182]
 [1.332]
 [1.283]
 [1.193]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.342]
 [30.735]
 [30.433]
 [37.433]
 [35.342]] [[0.152]
 [0.119]
 [0.117]
 [0.168]
 [0.152]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.99732565439422
siam score:  -0.88209337
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9846,     0.0002,     0.0011,     0.0073,     0.0068],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0004,     0.9600,     0.0031,     0.0273,     0.0092],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0004,     0.0004,     0.9341,     0.0248,     0.0404],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0252,     0.1075,     0.6662,     0.2010],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0208, 0.0739, 0.0712, 0.3033, 0.5309], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.733]
 [39.733]
 [39.733]
 [39.733]
 [39.733]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
printing an ep nov before normalisation:  40.03297847401709
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.783005100206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.80835826688913
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.51914636861305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.647798775507056
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.596775394862426
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.195]
 [30.836]
 [32.618]
 [26.289]
 [27.208]] [[0.845]
 [0.598]
 [0.667]
 [0.421]
 [0.457]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 50.67026282791762
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.79 ]
 [36.489]
 [39.898]
 [41.656]
 [41.857]] [[0.581]
 [0.436]
 [0.529]
 [0.578]
 [0.583]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.633]
 [29.046]
 [31.521]
 [29.889]
 [29.981]] [[0.568]
 [0.379]
 [0.44 ]
 [0.4  ]
 [0.402]]
printing an ep nov before normalisation:  33.967809134798706
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  30.008362175165736
printing an ep nov before normalisation:  27.866513832117324
printing an ep nov before normalisation:  55.87295055389404
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 27.46461092982165
printing an ep nov before normalisation:  59.600499857216
printing an ep nov before normalisation:  39.04239366582834
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.61892032623291
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.64481360617324
actions average: 
K:  4  action  0 :  tensor([    0.9612,     0.0009,     0.0010,     0.0107,     0.0262],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0013, 0.9634, 0.0163, 0.0027, 0.0164], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0003,     0.0218,     0.8392,     0.0505,     0.0882],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0005,     0.0001,     0.8378,     0.1615],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0023, 0.0099, 0.0725, 0.2286, 0.6867], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  29.78602087084351
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.056]
 [26.059]
 [26.225]
 [21.858]
 [21.93 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  27.337490707175206
printing an ep nov before normalisation:  85.05366367270216
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.121]
 [55.121]
 [75.47 ]
 [58.206]
 [60.532]] [[0.782]
 [0.782]
 [1.193]
 [0.844]
 [0.891]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.35653609988529
printing an ep nov before normalisation:  26.46522588154351
actions average: 
K:  2  action  0 :  tensor([    0.9998,     0.0001,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0007,     0.9626,     0.0274,     0.0002,     0.0091],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0055,     0.8612,     0.0575,     0.0758],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0014, 0.0061, 0.0568, 0.6905, 0.2452], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0008, 0.0010, 0.1434, 0.3605, 0.4944], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  45.16775925386411
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.067]
 [36.067]
 [36.94 ]
 [37.37 ]
 [36.067]] [[1.38 ]
 [1.38 ]
 [1.439]
 [1.469]
 [1.38 ]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  14.725374034126142
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.70722455730837
printing an ep nov before normalisation:  59.87536969529228
printing an ep nov before normalisation:  41.06203397010794
printing an ep nov before normalisation:  43.963197479833354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.40331301960501
using explorer policy with actor:  1
printing an ep nov before normalisation:  46.503166889562884
printing an ep nov before normalisation:  52.75437008404852
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.869]
 [49.801]
 [58.949]
 [61.846]
 [62.869]] [[1.667]
 [1.149]
 [1.512]
 [1.626]
 [1.667]]
printing an ep nov before normalisation:  61.287986812129354
printing an ep nov before normalisation:  44.805985216228265
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  51.57331378007568
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.679]
 [26.566]
 [27.249]
 [21.523]
 [21.448]] [[0.922]
 [1.144]
 [1.196]
 [0.757]
 [0.751]]
printing an ep nov before normalisation:  51.76613093634603
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.474805162641125
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.946339095761054
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.68098909789298
printing an ep nov before normalisation:  41.58205615715716
printing an ep nov before normalisation:  32.6497483253479
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.70958955522349
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.81636912560603
printing an ep nov before normalisation:  46.842721903686304
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.502]
 [37.502]
 [37.502]
 [47.483]
 [37.502]] [[0.94 ]
 [0.94 ]
 [0.94 ]
 [1.333]
 [0.94 ]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.89431245391028
printing an ep nov before normalisation:  28.044414260017945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.83130693435669
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.86053497041236
printing an ep nov before normalisation:  48.21190024781943
printing an ep nov before normalisation:  46.75926572192347
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.027]
 [27.336]
 [30.993]
 [29.633]
 [28.994]] [[0.719]
 [0.867]
 [1.103]
 [1.015]
 [0.974]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.344]
 [38.344]
 [44.079]
 [38.344]
 [38.344]] [[1.341]
 [1.341]
 [1.667]
 [1.341]
 [1.341]]
siam score:  -0.87067825
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.15653624994188
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.93229614813972
printing an ep nov before normalisation:  60.369504142640004
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 33.97647996825403
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.084895133972168
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9917,     0.0001,     0.0000,     0.0049,     0.0033],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0005,     0.9520,     0.0092,     0.0016,     0.0367],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0046,     0.8284,     0.0842,     0.0827],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0038,     0.0425,     0.7537,     0.1998],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0003,     0.0022,     0.2283,     0.2653,     0.5039],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.52194280061636
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  55.98829358586853
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.66778398613501
printing an ep nov before normalisation:  48.0991524804665
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.8494815826416
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.197]
 [26.78 ]
 [25.12 ]
 [27.144]
 [27.179]] [[0.22 ]
 [0.179]
 [0.158]
 [0.183]
 [0.183]]
printing an ep nov before normalisation:  58.2539160021888
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.98939186207698
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.293]
 [54.293]
 [54.293]
 [61.307]
 [54.293]] [[1.13 ]
 [1.13 ]
 [1.13 ]
 [1.333]
 [1.13 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.007124842343368225
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.849776915836266
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.956]
 [52.277]
 [62.35 ]
 [55.499]
 [56.711]] [[0.514]
 [0.688]
 [0.898]
 [0.755]
 [0.78 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.729779668074244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.11440372467041
printing an ep nov before normalisation:  33.10192346572876
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.060466883495494
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.638]
 [58.707]
 [67.876]
 [61.473]
 [61.61 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.07370646248658
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9905,     0.0006,     0.0003,     0.0027,     0.0059],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9986,     0.0002,     0.0000,     0.0010],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9347,     0.0344,     0.0309],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0005,     0.0003,     0.0252,     0.7131,     0.2610],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0008, 0.0385, 0.2777, 0.2089, 0.4741], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  28.31783724775646
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.84220946140914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.09866905212402
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.41308678652846
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.566553115844727
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.60915241420205
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.74150554340392
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0001639419045318391
printing an ep nov before normalisation:  61.034932136535645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.457077503204346
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.448]
 [41.673]
 [41.673]
 [41.673]
 [41.673]] [[1.683]
 [1.414]
 [1.414]
 [1.414]
 [1.414]]
printing an ep nov before normalisation:  44.03316740457769
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.036]
 [41.036]
 [43.932]
 [41.036]
 [41.036]] [[1.598]
 [1.598]
 [1.805]
 [1.598]
 [1.598]]
printing an ep nov before normalisation:  60.29232527900786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88498574
printing an ep nov before normalisation:  57.06241961340846
printing an ep nov before normalisation:  43.59230915354749
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.76 ]
 [53.76 ]
 [57.679]
 [53.76 ]
 [53.76 ]] [[1.336]
 [1.336]
 [1.464]
 [1.336]
 [1.336]]
printing an ep nov before normalisation:  31.115047931671143
printing an ep nov before normalisation:  56.777464854883895
using explorer policy with actor:  1
printing an ep nov before normalisation:  46.524540530185625
siam score:  -0.8878685
printing an ep nov before normalisation:  43.01008497681173
printing an ep nov before normalisation:  37.65467323541079
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.558]
 [46.565]
 [51.28 ]
 [52.851]
 [53.351]] [[0.42 ]
 [0.522]
 [0.642]
 [0.682]
 [0.695]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.228317157024673
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.01339697615037494
using explorer policy with actor:  1
printing an ep nov before normalisation:  49.0592823738262
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.961]
 [37.552]
 [38.214]
 [39.052]
 [38.792]] [[1.232]
 [1.147]
 [1.187]
 [1.238]
 [1.222]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.09980795241531
siam score:  -0.8875552
printing an ep nov before normalisation:  28.485877513885498
printing an ep nov before normalisation:  46.11545939306885
printing an ep nov before normalisation:  51.437693605289034
using explorer policy with actor:  1
printing an ep nov before normalisation:  66.94931394698986
printing an ep nov before normalisation:  32.37068190498735
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.5126661209865
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.96139606027336
printing an ep nov before normalisation:  35.139930987248825
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9760,     0.0019,     0.0000,     0.0014,     0.0207],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0012,     0.9516,     0.0049,     0.0001,     0.0422],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0005,     0.0044,     0.8434,     0.0543,     0.0974],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0017,     0.0005,     0.1052,     0.6792,     0.2134],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0012, 0.0021, 0.1571, 0.2465, 0.5931], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  30.410408973693848
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0036,     0.9853,     0.0005,     0.0018,     0.0089],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9445,     0.0264,     0.0291],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0034,     0.0002,     0.1176,     0.5921,     0.2867],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0051, 0.0211, 0.2149, 0.1818, 0.5771], grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 45.15919238058193
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9889,     0.0005,     0.0009,     0.0050,     0.0047],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9990,     0.0002,     0.0004,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.8601,     0.0603,     0.0795],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0012,     0.0003,     0.0016,     0.8264,     0.1704],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0007, 0.0269, 0.0705, 0.3524, 0.5496], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  52.735605093897405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.948376116758254
printing an ep nov before normalisation:  33.878628901692196
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.371069159665836
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.42479801516181
printing an ep nov before normalisation:  65.10295485350237
printing an ep nov before normalisation:  27.43422960207365
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.400604918930803
deleting a thread, now have 1 threads
Frames:  83750 train batches done:  9802 episodes:  3162
printing an ep nov before normalisation:  52.61083315040621
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88408583
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8863378
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 31.333815650173545
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.0868098021605
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.205179763299746
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.53424191797238
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.941331869813283
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9522,     0.0006,     0.0002,     0.0287,     0.0183],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9940,     0.0004,     0.0001,     0.0054],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0021, 0.0086, 0.9371, 0.0200, 0.0321], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0003,     0.0535,     0.7180,     0.2279],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0206,     0.2317,     0.1674,     0.5800],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.797]
 [24.124]
 [29.956]
 [21.587]
 [22.208]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.13537633695356
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  74.03852114884428
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.436 0.    0.256 0.282 0.026]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 9.801970043164326e-10
0.0 1.2952702119540028e-09
0.0 1.2717789735558777e-09
0.0 0.0
0.0 0.0
0.0 2.5375381010060304e-09
0.0 2.177177660691318e-09
0.0 0.0
0.0 0.0
0.0 2.035192325876688e-09
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87854433
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.478]
 [29.121]
 [50.977]
 [50.408]
 [46.618]] [[0.266]
 [0.279]
 [0.701]
 [0.69 ]
 [0.617]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.63415874027843
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9947,     0.0001,     0.0005,     0.0006,     0.0041],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0024,     0.9562,     0.0009,     0.0356,     0.0049],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0003,     0.0014,     0.8878,     0.0508,     0.0598],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0001,     0.0205,     0.7732,     0.2059],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0009, 0.0010, 0.0352, 0.3013, 0.6616], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.82415817042874
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.072868948564796
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.683839750199425
printing an ep nov before normalisation:  58.465130410568115
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.7  ]
 [22.455]
 [20.7  ]
 [22.049]
 [21.315]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.729]
 [45.729]
 [55.938]
 [45.729]
 [45.729]] [[0.206]
 [0.206]
 [0.284]
 [0.206]
 [0.206]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.14946791730881
line 256 mcts: sample exp_bonus 30.05548430626151
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.04003785296521
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.33715870331013
siam score:  -0.8953688
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.084]
 [27.47 ]
 [37.455]
 [42.227]
 [41.673]] [[0.307]
 [0.236]
 [0.389]
 [0.462]
 [0.454]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.679294399984936
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0010, 0.9739, 0.0013, 0.0026, 0.0212], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9100,     0.0446,     0.0453],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0012,     0.0002,     0.0208,     0.7676,     0.2102],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0033, 0.0377, 0.0561, 0.3732, 0.5297], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  42.39813804626465
maxi score, test score, baseline:  0.0001 0.0 0.0001
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 1.5817664492292185e-10
0.0 1.4731324454514298e-10
0.0 3.9855532578471143e-10
0.0 4.079656598741078e-10
0.0 4.079656598741078e-10
0.0 9.140478914695476e-11
0.0 1.289769318409202e-10
0.0 3.675565782251104e-10
0.0 9.495096281899573e-11
0.0 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8839255
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.91695355322432
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  55.55906238420265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.75186797235981
printing an ep nov before normalisation:  83.81311012145953
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88298035
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.37004108986476
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.71926021575928
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88781846
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00038525388958987605
siam score:  -0.88851666
printing an ep nov before normalisation:  49.49670958687362
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.495]
 [39.495]
 [50.48 ]
 [39.495]
 [39.495]] [[0.599]
 [0.599]
 [0.856]
 [0.599]
 [0.599]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.858]
 [63.71 ]
 [69.704]
 [63.71 ]
 [63.71 ]] [[0.827]
 [1.325]
 [1.483]
 [1.325]
 [1.325]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.396]
 [36.396]
 [48.243]
 [36.396]
 [36.396]] [[0.869]
 [0.869]
 [1.408]
 [0.869]
 [0.869]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.76142524326373
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.224]
 [34.081]
 [34.089]
 [36.654]
 [34.144]] [[0.961]
 [0.849]
 [0.849]
 [0.983]
 [0.852]]
printing an ep nov before normalisation:  51.64174072244818
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8818296
printing an ep nov before normalisation:  35.54699462623642
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0006,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9973,     0.0001,     0.0015,     0.0010],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0002,     0.8422,     0.0822,     0.0754],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0001,     0.0805,     0.7548,     0.1644],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0224, 0.0024, 0.1024, 0.3375, 0.5352], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9956,     0.0000,     0.0003,     0.0041],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0004,     0.0064,     0.9018,     0.0281,     0.0631],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0031, 0.0008, 0.0461, 0.7422, 0.2078], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0020, 0.0024, 0.1071, 0.3100, 0.5785], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  56.813308622511926
printing an ep nov before normalisation:  30.588660268123206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9990,     0.0000,     0.0000,     0.0005,     0.0004],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9996,     0.0001,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0077,     0.0006,     0.9123,     0.0341,     0.0452],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0004,     0.1265,     0.6425,     0.2302],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0043, 0.0014, 0.0295, 0.3630, 0.6018], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  34.241676609322454
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.963]
 [31.239]
 [38.799]
 [25.013]
 [34.734]] [[0.228]
 [0.488]
 [0.679]
 [0.331]
 [0.577]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.64707768605961
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.97495268038442
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.746828715006515
using explorer policy with actor:  1
printing an ep nov before normalisation:  58.02928510348597
printing an ep nov before normalisation:  40.95019270538013
siam score:  -0.8856279
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.886669158935547
siam score:  -0.8879501
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.25532312613746
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.541]
 [27.515]
 [25.541]
 [36.365]
 [25.541]] [[0.641]
 [0.736]
 [0.641]
 [1.159]
 [0.641]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.502]
 [33.502]
 [45.16 ]
 [33.502]
 [33.502]] [[0.81 ]
 [0.81 ]
 [1.358]
 [0.81 ]
 [0.81 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.689204488481796
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.30529032152814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.902679856696125
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.30440258391087
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9996,     0.0001,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0072,     0.9615,     0.0004,     0.0052,     0.0258],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0002,     0.9502,     0.0178,     0.0317],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0057,     0.0004,     0.0746,     0.7139,     0.2055],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0071, 0.0009, 0.0736, 0.2777, 0.6407], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.79854462006674
siam score:  -0.88770247
printing an ep nov before normalisation:  40.301477472731044
printing an ep nov before normalisation:  38.13442768552999
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88635653
printing an ep nov before normalisation:  82.82677520628748
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.135593485123735
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.548047040182254
printing an ep nov before normalisation:  42.05464568667752
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.222]
 [16.03 ]
 [15.853]
 [21.997]
 [15.026]] [[0.402]
 [0.386]
 [0.37 ]
 [0.897]
 [0.3  ]]
printing an ep nov before normalisation:  30.5053973197937
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.351]
 [22.054]
 [19.633]
 [18.434]
 [18.647]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.6785958528438
printing an ep nov before normalisation:  41.9418559045547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.63249588012695
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.094]
 [40.094]
 [41.797]
 [40.094]
 [40.094]] [[1.549]
 [1.549]
 [1.667]
 [1.549]
 [1.549]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.880950789889305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.672706957354244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.453]
 [34.357]
 [34.357]
 [34.357]
 [54.633]] [[1.316]
 [0.243]
 [0.243]
 [0.243]
 [1.146]]
printing an ep nov before normalisation:  44.38000906956082
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.784]
 [56.784]
 [56.784]
 [56.784]
 [56.784]] [[1.965]
 [1.965]
 [1.965]
 [1.965]
 [1.965]]
printing an ep nov before normalisation:  50.66937574622659
siam score:  -0.8789643
actions average: 
K:  4  action  0 :  tensor([    0.9873,     0.0005,     0.0000,     0.0044,     0.0077],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9920,     0.0000,     0.0034,     0.0044],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0170,     0.8927,     0.0507,     0.0394],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0007,     0.0821,     0.6651,     0.2518],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0004,     0.0007,     0.1047,     0.2278,     0.6665],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.90783261752739
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.094]
 [29.094]
 [29.094]
 [41.439]
 [29.094]] [[0.453]
 [0.453]
 [0.453]
 [0.82 ]
 [0.453]]
siam score:  -0.8834007
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.825881958007812
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9912,     0.0011,     0.0073,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0109,     0.9785,     0.0004,     0.0006,     0.0096],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0007,     0.0001,     0.9143,     0.0471,     0.0377],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0015,     0.0005,     0.0750,     0.7470,     0.1760],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0217, 0.0028, 0.0411, 0.2361, 0.6983], grad_fn=<DivBackward0>)
siam score:  -0.8864467
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.06737652899418
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.635088659927064
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.116]
 [49.116]
 [49.116]
 [49.116]
 [49.116]] [[1.393]
 [1.393]
 [1.393]
 [1.393]
 [1.393]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.359026701643295
printing an ep nov before normalisation:  37.029108018560045
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8745883
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.34776784186972
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.017964836542887497
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.31857085598767
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8894699
printing an ep nov before normalisation:  50.588388442993164
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.78354415805461
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.000870414375716185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.002009961942803784
printing an ep nov before normalisation:  0.001179884164533481
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.967]
 [35.967]
 [51.434]
 [35.967]
 [42.253]] [[0.356]
 [0.356]
 [0.834]
 [0.356]
 [0.55 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.36502849861631
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 35.77482800303027
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8910804
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.513725085375643
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.90035461102389
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.82739135776724
actions average: 
K:  3  action  0 :  tensor([    0.9994,     0.0002,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0007,     0.9732,     0.0085,     0.0000,     0.0175],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0006,     0.0031,     0.8531,     0.0638,     0.0794],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0005,     0.0003,     0.0843,     0.6024,     0.3124],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0011, 0.0008, 0.1710, 0.1916, 0.6355], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.75678972417032
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.23773384094238
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88354844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.507265090942383
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.886]
 [50.833]
 [60.923]
 [43.886]
 [43.886]] [[0.847]
 [1.093]
 [1.452]
 [0.847]
 [0.847]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.614]
 [54.614]
 [38.921]
 [33.959]
 [34.255]] [[3.536]
 [3.536]
 [2.   ]
 [1.514]
 [1.543]]
printing an ep nov before normalisation:  46.90564625445294
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.73384318651412
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.753]
 [61.751]
 [49.118]
 [68.08 ]
 [67.023]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8887808
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.174619446335676
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.04893944831084
printing an ep nov before normalisation:  63.52436132783504
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.01218829459394
siam score:  -0.8853387
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8868242
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9990,     0.0001,     0.0001,     0.0002,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9975,     0.0003,     0.0002,     0.0019],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0003,     0.0002,     0.9383,     0.0295,     0.0317],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0002,     0.0468,     0.7589,     0.1936],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0018, 0.0007, 0.1966, 0.2236, 0.5773], grad_fn=<DivBackward0>)
actions average: 
K:  3  action  0 :  tensor([    0.9484,     0.0032,     0.0000,     0.0029,     0.0455],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9942,     0.0001,     0.0035,     0.0021],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0003,     0.8703,     0.0639,     0.0653],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0001,     0.0382,     0.7656,     0.1958],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0008, 0.0022, 0.2112, 0.1609, 0.6248], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.71248615835413
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8841811
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.8836557
actions average: 
K:  0  action  0 :  tensor([    0.9986,     0.0000,     0.0000,     0.0001,     0.0013],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9604,     0.0002,     0.0001,     0.0391],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0001,     0.8755,     0.0614,     0.0628],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0022,     0.0005,     0.0449,     0.6972,     0.2551],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0007, 0.0457, 0.1465, 0.2029, 0.6042], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.56332923413386
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.723881228189626
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.436293264143547
printing an ep nov before normalisation:  86.19791704402793
printing an ep nov before normalisation:  37.43853419173924
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.827]
 [53.827]
 [53.827]
 [53.827]
 [53.827]] [[1.835]
 [1.835]
 [1.835]
 [1.835]
 [1.835]]
printing an ep nov before normalisation:  42.37817023649376
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0080,     0.9728,     0.0002,     0.0004,     0.0187],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0062,     0.8807,     0.0391,     0.0739],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0020,     0.0006,     0.0513,     0.6420,     0.3042],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0056, 0.0009, 0.1535, 0.3187, 0.5213], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
siam score:  -0.89171976
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.973878155739925
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.90004843014856
actions average: 
K:  3  action  0 :  tensor([0.9070, 0.0117, 0.0012, 0.0400, 0.0400], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9993,     0.0001,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0009,     0.8701,     0.0614,     0.0676],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0190,     0.1252,     0.6838,     0.1719],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0003,     0.0027,     0.0997,     0.3273,     0.5699],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.730414648898844
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.265]
 [35.587]
 [34.19 ]
 [32.704]
 [32.873]] [[1.072]
 [1.162]
 [1.067]
 [0.966]
 [0.978]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9980,     0.0001,     0.0000,     0.0000,     0.0018],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9966,     0.0000,     0.0002,     0.0031],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0009,     0.0001,     0.8612,     0.0681,     0.0696],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0021, 0.0008, 0.1500, 0.6789, 0.1682], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0007, 0.0025, 0.2122, 0.2154, 0.5691], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.216304779048436
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 23.906336662615644
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.82524871826172
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.375]
 [37.421]
 [36.082]
 [35.052]
 [34.36 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  47.17812671530746
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  26.304760521007022
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.54672893748128
siam score:  -0.88599485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.9995,     0.0001,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0015,     0.9972,     0.0001,     0.0005,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0006,     0.0002,     0.8634,     0.0582,     0.0777],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0006,     0.0025,     0.1280,     0.6734,     0.1954],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0043, 0.0326, 0.0685, 0.2417, 0.6529], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9989,     0.0002,     0.0001,     0.0004,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9887,     0.0000,     0.0011,     0.0101],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0012, 0.0070, 0.8593, 0.0651, 0.0674], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0011,     0.0002,     0.0194,     0.7447,     0.2346],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0426, 0.0011, 0.1165, 0.2340, 0.6057], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.17975619238451
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.308]
 [34.453]
 [30.998]
 [33.124]
 [30.998]] [[1.27 ]
 [1.729]
 [1.556]
 [1.663]
 [1.556]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.888]
 [35.888]
 [35.888]
 [36.179]
 [35.888]] [[1.605]
 [1.605]
 [1.605]
 [1.618]
 [1.605]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.956]
 [30.077]
 [42.071]
 [49.031]
 [38.662]] [[1.486]
 [0.952]
 [1.332]
 [1.552]
 [1.224]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.042302905040685346
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.82457679499931
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.7331081176233
printing an ep nov before normalisation:  43.5681655465784
printing an ep nov before normalisation:  31.02930784225464
printing an ep nov before normalisation:  46.115291858454675
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.6782670711318
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.851]
 [31.851]
 [31.851]
 [31.851]
 [31.851]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
printing an ep nov before normalisation:  39.93277802906603
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.45661350536875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8835016
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  71.8980969546688
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  45.69453517317238
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 57.06676386268836
printing an ep nov before normalisation:  41.18861056237183
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.44647702322469
siam score:  -0.88032776
siam score:  -0.88057435
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8798284
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8776104
printing an ep nov before normalisation:  37.509549245628186
printing an ep nov before normalisation:  47.528052038976874
siam score:  -0.8782631
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9965,     0.0003,     0.0002,     0.0014,     0.0016],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9885,     0.0002,     0.0007,     0.0104],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0019,     0.0002,     0.9143,     0.0441,     0.0394],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0002,     0.0800,     0.7611,     0.1585],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0017, 0.0070, 0.0868, 0.1871, 0.7174], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  33.16218218399528
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.11929086480901
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.66596971768854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.70244138316081
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.253710746942446
siam score:  -0.8841135
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88662857
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [51.426]
 [43.872]
 [ 0.   ]] [[-0.128]
 [-0.128]
 [ 0.383]
 [ 0.308]
 [-0.128]]
siam score:  -0.88630074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.93706269541617
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 32.01432163482974
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.2376163980401
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.175]
 [28.175]
 [35.921]
 [28.175]
 [28.175]] [[0.77 ]
 [0.77 ]
 [1.173]
 [0.77 ]
 [0.77 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.32432179670359
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.932]
 [56.271]
 [55.144]
 [57.499]
 [59.313]] [[1.5  ]
 [1.517]
 [1.46 ]
 [1.579]
 [1.67 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.05587212986331
printing an ep nov before normalisation:  43.13598309274228
siam score:  -0.8851745
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 48.163163376886814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.206]
 [34.206]
 [50.384]
 [34.206]
 [34.206]] [[0.872]
 [0.872]
 [1.506]
 [0.872]
 [0.872]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
main train batch thing paused
add a thread
Adding thread: now have 2 threads
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.711]
 [41.596]
 [41.596]
 [42.513]
 [41.596]] [[1.809]
 [1.577]
 [1.577]
 [1.629]
 [1.577]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.781]
 [38.   ]
 [38.   ]
 [38.374]
 [38.   ]] [[1.663]
 [1.296]
 [1.296]
 [1.308]
 [1.296]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.2676376092665
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.291114180665616
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  46.176783913189325
printing an ep nov before normalisation:  55.0017261194013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.958999238786138
printing an ep nov before normalisation:  30.47443577398987
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.077 0.333 0.205 0.205 0.179]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.896]
 [62.896]
 [62.896]
 [62.896]
 [62.896]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.229]
 [43.077]
 [46.126]
 [45.358]
 [45.723]] [[1.012]
 [1.108]
 [1.267]
 [1.227]
 [1.246]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.96170679213178
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.76216710078765
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  47.6362121035634
UNIT TEST: sample policy line 217 mcts : [0.026 0.128 0.538 0.282 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.481967894888705
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.389259815216064
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.96486635757095
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  1.3145898947186652e-05
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.535]
 [33.737]
 [47.597]
 [52.722]
 [36.12 ]] [[0.454]
 [0.494]
 [0.958]
 [1.13 ]
 [0.574]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 40.94400997824911
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.40473911640609
line 256 mcts: sample exp_bonus 33.84560856805344
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8844445
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.750452995300293
printing an ep nov before normalisation:  30.36747455596924
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.812]
 [48.738]
 [39.899]
 [47.323]
 [47.529]] [[1.039]
 [1.497]
 [1.226]
 [1.454]
 [1.46 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.89]
 [58.89]
 [58.89]
 [58.89]
 [58.89]] [[1.609]
 [1.609]
 [1.609]
 [1.609]
 [1.609]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  2.6698008923631278e-05
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.692]
 [87.692]
 [87.692]
 [87.692]
 [87.692]] [[0.88]
 [0.88]
 [0.88]
 [0.88]
 [0.88]]
printing an ep nov before normalisation:  32.66389025408793
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.56745522597097
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.489]
 [43.489]
 [46.112]
 [43.489]
 [43.489]] [[1.203]
 [1.203]
 [1.335]
 [1.203]
 [1.203]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.32956391264622
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.040610073162476
printing an ep nov before normalisation:  50.43683698396637
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.82 ]
 [31.008]
 [31.008]
 [31.008]
 [31.008]] [[1.181]
 [0.746]
 [0.746]
 [0.746]
 [0.746]]
printing an ep nov before normalisation:  41.01295812883109
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.22446741592327
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.369136522873106
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.948]
 [32.508]
 [34.346]
 [32.358]
 [34.356]] [[0.8  ]
 [0.766]
 [0.81 ]
 [0.763]
 [0.81 ]]
printing an ep nov before normalisation:  0.00039630311079008607
siam score:  -0.8878468
printing an ep nov before normalisation:  60.706764587640734
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.06920314164142
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.96754819389978
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.668]
 [61.668]
 [61.668]
 [61.668]
 [61.668]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
printing an ep nov before normalisation:  56.41942330133296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.486]
 [49.717]
 [56.035]
 [53.848]
 [53.716]] [[0.219]
 [0.248]
 [0.304]
 [0.285]
 [0.284]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.278401374816895
printing an ep nov before normalisation:  53.998790549790506
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.836]
 [53.953]
 [56.102]
 [51.42 ]
 [54.836]] [[0.323]
 [0.316]
 [0.333]
 [0.295]
 [0.323]]
printing an ep nov before normalisation:  39.92410322609657
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.853]
 [28.841]
 [46.649]
 [34.207]
 [30.546]] [[0.372]
 [0.232]
 [0.508]
 [0.315]
 [0.258]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.0037972597240809596
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.233]
 [52.837]
 [58.261]
 [57.934]
 [56.178]] [[0.965]
 [1.383]
 [1.562]
 [1.552]
 [1.493]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.772754399828326
printing an ep nov before normalisation:  0.22853860651480318
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  17.016439491831168
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  1  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0010,     0.9978,     0.0009,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0001,     0.9193,     0.0563,     0.0241],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0004,     0.0504,     0.7165,     0.2321],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0066, 0.0095, 0.1781, 0.2127, 0.5930], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.203481057105336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.957917214285686
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87442726
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.273]
 [58.273]
 [58.273]
 [58.273]
 [58.273]] [[0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]]
printing an ep nov before normalisation:  45.04408838350362
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.62896888684345
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.686768269979
printing an ep nov before normalisation:  55.96572582568717
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.23782484433842
printing an ep nov before normalisation:  58.931410017009895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.37668434058258
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  47.7769262001594
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.96406077716094
printing an ep nov before normalisation:  51.0836124420166
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
UNIT TEST: sample policy line 217 mcts : [0.41  0.41  0.    0.179 0.   ]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.164]
 [45.164]
 [53.207]
 [51.006]
 [45.164]] [[1.517]
 [1.517]
 [1.788]
 [1.714]
 [1.517]]
printing an ep nov before normalisation:  61.607945943706696
printing an ep nov before normalisation:  33.113718032836914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.92222452163696
printing an ep nov before normalisation:  38.61628930315627
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.69795740310993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.67414098858706
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  42.99102168988065
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9996,     0.0001,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0208,     0.8573,     0.0393,     0.0825],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0035,     0.0357,     0.6824,     0.2778],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0008, 0.0069, 0.0936, 0.3743, 0.5243], grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8878172
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.606]
 [31.223]
 [28.262]
 [30.103]
 [30.298]] [[1.461]
 [1.425]
 [1.145]
 [1.319]
 [1.337]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.87348627465939
printing an ep nov before normalisation:  57.913834496009926
printing an ep nov before normalisation:  37.73047577681217
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.873]
 [30.873]
 [37.535]
 [30.873]
 [30.873]] [[1.076]
 [1.076]
 [1.459]
 [1.076]
 [1.076]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9850,     0.0035,     0.0054,     0.0007,     0.0053],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0008,     0.9836,     0.0073,     0.0012,     0.0070],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0008,     0.8951,     0.0446,     0.0594],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0001,     0.1387,     0.6342,     0.2269],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0012, 0.0051, 0.2940, 0.2422, 0.4575], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.267072190239986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9960,     0.0011,     0.0001,     0.0014,     0.0014],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9992,     0.0000,     0.0002,     0.0006],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0003,     0.0278,     0.9334,     0.0211,     0.0173],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0003,     0.0003,     0.6504,     0.3486],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0014, 0.0142, 0.0438, 0.2570, 0.6835], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.14796750833583
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.81 ]
 [12.219]
 [19.486]
 [11.516]
 [17.169]] [[0.457]
 [0.314]
 [0.5  ]
 [0.295]
 [0.441]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.702083587646484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.74124285873303
printing an ep nov before normalisation:  40.14751956114284
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.602]
 [38.049]
 [39.791]
 [40.171]
 [37.118]] [[0.758]
 [1.048]
 [1.141]
 [1.161]
 [0.998]]
printing an ep nov before normalisation:  47.67291528482612
actions average: 
K:  1  action  0 :  tensor([    0.9957,     0.0011,     0.0008,     0.0009,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9941,     0.0000,     0.0001,     0.0058],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.8745,     0.0369,     0.0885],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0002,     0.1416,     0.6599,     0.1982],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0005,     0.0009,     0.0687,     0.2863,     0.6436],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.538]
 [29.538]
 [29.538]
 [43.638]
 [29.538]] [[0.18 ]
 [0.18 ]
 [0.18 ]
 [0.312]
 [0.18 ]]
printing an ep nov before normalisation:  31.626300827456337
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.421359555665006
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.83092173999687
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.5078067779541
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.362]
 [58.895]
 [67.362]
 [61.143]
 [60.475]] [[1.667]
 [1.457]
 [1.667]
 [1.513]
 [1.497]]
line 256 mcts: sample exp_bonus 55.43210696647566
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.530567548854368
line 256 mcts: sample exp_bonus 34.814881791990224
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.87 ]
 [30.87 ]
 [41.339]
 [32.883]
 [30.87 ]] [[0.755]
 [0.755]
 [1.239]
 [0.848]
 [0.755]]
printing an ep nov before normalisation:  36.6139373156512
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.361]
 [42.361]
 [42.361]
 [42.361]
 [42.361]] [[1.291]
 [1.291]
 [1.291]
 [1.291]
 [1.291]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.951]
 [40.189]
 [37.651]
 [42.951]
 [40.698]] [[1.647]
 [1.449]
 [1.268]
 [1.647]
 [1.486]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.961]
 [40.229]
 [40.487]
 [40.229]
 [40.229]] [[1.593]
 [1.381]
 [1.396]
 [1.381]
 [1.381]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.925429839784336
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.601]
 [51.363]
 [53.96 ]
 [51.94 ]
 [49.655]] [[0.257]
 [0.254]
 [0.28 ]
 [0.26 ]
 [0.237]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.37906315092946
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.42912087602474
printing an ep nov before normalisation:  23.559485563305095
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.883703
printing an ep nov before normalisation:  69.44616201170189
siam score:  -0.88702667
printing an ep nov before normalisation:  36.47824766986716
printing an ep nov before normalisation:  54.20389864287412
printing an ep nov before normalisation:  38.15754337726901
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.384358087633586
printing an ep nov before normalisation:  31.790963198144702
line 256 mcts: sample exp_bonus 87.46345598263402
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 54.952641252927705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.97099575183655
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.82259527583226
printing an ep nov before normalisation:  39.64523923653065
printing an ep nov before normalisation:  56.61454462561899
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.475752076257535
printing an ep nov before normalisation:  19.998738225162704
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.745]
 [35.745]
 [35.745]
 [35.745]
 [35.745]] [[0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.287]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.673]
 [42.673]
 [57.481]
 [42.104]
 [42.673]] [[0.731]
 [0.731]
 [1.213]
 [0.712]
 [0.731]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.2048080559524
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.489]
 [42.195]
 [46.984]
 [42.489]
 [42.489]] [[1.461]
 [1.445]
 [1.707]
 [1.461]
 [1.461]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
line 256 mcts: sample exp_bonus 32.497529834890884
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.652916169946046
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.18 ]
 [31.152]
 [32.261]
 [40.917]
 [33.749]] [[0.631]
 [0.59 ]
 [0.634]
 [0.974]
 [0.693]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.853]
 [17.877]
 [38.91 ]
 [17.364]
 [18.863]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.03]
 [23.03]
 [23.03]
 [23.03]
 [23.03]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.69951595652007
printing an ep nov before normalisation:  33.1910288347422
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  33.72129832384458
printing an ep nov before normalisation:  34.90524372895979
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.750152233154736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.04780251775997
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.828116416931152
printing an ep nov before normalisation:  43.41319727251886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.004352198816377495
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.77014881306094
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.47576577024785
printing an ep nov before normalisation:  40.45286338850454
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.711]
 [34.713]
 [36.558]
 [35.711]
 [35.711]] [[1.737]
 [1.644]
 [1.815]
 [1.737]
 [1.737]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.880934715270996
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  54.91563999937972
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.0559196472168
printing an ep nov before normalisation:  49.0693998336792
printing an ep nov before normalisation:  42.04936264756713
printing an ep nov before normalisation:  44.86646568210912
printing an ep nov before normalisation:  33.743392405878446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.50907689713733
printing an ep nov before normalisation:  44.32347774505615
printing an ep nov before normalisation:  5.101311910663071
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.431258505336686
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.35]
 [51.35]
 [51.35]
 [51.35]
 [51.35]] [[1.747]
 [1.747]
 [1.747]
 [1.747]
 [1.747]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.546]
 [25.546]
 [25.546]
 [25.546]
 [25.546]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  0.0016489255085616605
printing an ep nov before normalisation:  38.252153723647204
printing an ep nov before normalisation:  51.696038246154785
printing an ep nov before normalisation:  1.2185712421342032e-05
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.076]
 [46.767]
 [52.931]
 [53.028]
 [44.988]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.95596750592202
printing an ep nov before normalisation:  55.63741357272404
printing an ep nov before normalisation:  33.26222896575928
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.477632687723904
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.50121700957657
printing an ep nov before normalisation:  55.170877313478314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.06334447315799
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.429]
 [51.53 ]
 [49.439]
 [52.256]
 [49.757]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.52356658185177
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.112]
 [43.112]
 [43.112]
 [43.112]
 [43.112]] [[0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.07442056707449
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.102258619225815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.345190384913984
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.53159438800345
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  28.061752621320103
siam score:  -0.88218874
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8825713
printing an ep nov before normalisation:  57.0014235812843
printing an ep nov before normalisation:  50.55010742170894
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.47862604722357
printing an ep nov before normalisation:  39.71139412790366
UNIT TEST: sample policy line 217 mcts : [0.154 0.077 0.179 0.487 0.103]
printing an ep nov before normalisation:  49.346226685145524
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.382780441474694
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.416]
 [62.333]
 [64.416]
 [59.558]
 [64.151]] [[1.926]
 [1.841]
 [1.926]
 [1.728]
 [1.915]]
printing an ep nov before normalisation:  55.06435143185246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.49126765428409
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.113]
 [52.113]
 [52.113]
 [52.113]
 [52.113]] [[1.141]
 [1.141]
 [1.141]
 [1.141]
 [1.141]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.819294452667236
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.65029644883152
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.7129229325956
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.83869439321806
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.64623703826926
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.623]
 [55.087]
 [42.623]
 [42.623]
 [42.623]] [[0.828]
 [1.29 ]
 [0.828]
 [0.828]
 [0.828]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.55642821930006
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.72679935535926
printing an ep nov before normalisation:  30.734289106036027
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.457]
 [33.199]
 [30.529]
 [28.242]
 [28.794]] [[0.703]
 [0.544]
 [0.464]
 [0.395]
 [0.411]]
siam score:  -0.88493806
printing an ep nov before normalisation:  47.96733204366892
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.957]
 [38.322]
 [32.945]
 [40.551]
 [39.516]] [[0.555]
 [0.436]
 [0.298]
 [0.493]
 [0.466]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.09641613941398
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.541907555835046
printing an ep nov before normalisation:  61.866612862039936
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.34206327831612
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  70.18004648957081
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  0  action  0 :  tensor([    0.9986,     0.0002,     0.0006,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.8579,     0.0382,     0.1038],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0013,     0.0006,     0.0434,     0.7051,     0.2496],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0015, 0.0011, 0.1448, 0.4034, 0.4491], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  39.31356176929188
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.378]
 [50.378]
 [50.378]
 [50.378]
 [50.378]] [[1.244]
 [1.244]
 [1.244]
 [1.244]
 [1.244]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.663]
 [41.464]
 [36.663]
 [36.663]
 [39.687]] [[1.104]
 [1.376]
 [1.104]
 [1.104]
 [1.275]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 33.58177376097073
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.769]
 [25.769]
 [25.769]
 [25.769]
 [25.769]] [[0.239]
 [0.239]
 [0.239]
 [0.239]
 [0.239]]
printing an ep nov before normalisation:  39.31631911936579
printing an ep nov before normalisation:  35.64016312935068
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9914,     0.0003,     0.0002,     0.0021,     0.0060],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0012, 0.8725, 0.0520, 0.0040, 0.0702], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.8643,     0.0689,     0.0667],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0000,     0.0007,     0.0430,     0.8308,     0.1255],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0003,     0.0013,     0.1400,     0.1997,     0.6586],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.79225435717365
actions average: 
K:  0  action  0 :  tensor([    0.9988,     0.0000,     0.0000,     0.0003,     0.0009],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9984,     0.0000,     0.0008,     0.0008],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0003,     0.0035,     0.8717,     0.0538,     0.0706],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0015,     0.0786,     0.7880,     0.1315],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0003,     0.0061,     0.0032,     0.3848,     0.6055],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  83.26070532657378
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.479]
 [45.258]
 [45.258]
 [45.258]
 [45.258]] [[0.554]
 [0.527]
 [0.527]
 [0.527]
 [0.527]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.058]
 [34.058]
 [34.058]
 [40.511]
 [34.504]] [[0.821]
 [0.821]
 [0.821]
 [0.976]
 [0.831]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  16.880152714014
printing an ep nov before normalisation:  80.21741970561133
printing an ep nov before normalisation:  39.327829993466075
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.13332170377276
siam score:  -0.88096315
printing an ep nov before normalisation:  49.26630814817762
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.025192909950775
printing an ep nov before normalisation:  44.495215889105964
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.485]
 [48.387]
 [48.387]
 [48.387]
 [48.387]] [[1.64 ]
 [1.263]
 [1.263]
 [1.263]
 [1.263]]
printing an ep nov before normalisation:  45.2703263348936
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.0019945598580761725
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.932]
 [30.932]
 [30.932]
 [30.932]
 [30.932]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.38429924536702
printing an ep nov before normalisation:  41.23774606261251
line 256 mcts: sample exp_bonus 33.9969769423307
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.11997760728961
printing an ep nov before normalisation:  53.040697378250854
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.368632316589355
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.12847524711629
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  40.8566487265519
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.7925202658335
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.63819414026282
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.139846373085135
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 56.047257586327774
printing an ep nov before normalisation:  0.004954607885565565
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
printing an ep nov before normalisation:  63.042082954884016
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.163432152906
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.1383148198647
printing an ep nov before normalisation:  27.00833797454834
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.426]
 [34.535]
 [39.167]
 [34.535]
 [27.008]] [[0.688]
 [1.004]
 [1.243]
 [1.004]
 [0.615]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.51328706741333
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.649]
 [37.984]
 [37.984]
 [43.917]
 [37.984]] [[1.161]
 [0.715]
 [0.715]
 [0.941]
 [0.715]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.57 ]
 [37.57 ]
 [37.229]
 [36.166]
 [36.638]] [[1.229]
 [1.229]
 [1.21 ]
 [1.151]
 [1.177]]
printing an ep nov before normalisation:  54.21881982493426
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.06081043380609
printing an ep nov before normalisation:  52.21771421716453
printing an ep nov before normalisation:  54.48252956053623
printing an ep nov before normalisation:  50.09181130735302
UNIT TEST: sample policy line 217 mcts : [0.359 0.128 0.282 0.103 0.128]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.627]
 [40.718]
 [35.817]
 [35.817]
 [36.408]] [[0.492]
 [0.42 ]
 [0.33 ]
 [0.33 ]
 [0.341]]
printing an ep nov before normalisation:  49.91163646538327
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.54285678403013
printing an ep nov before normalisation:  67.1981327618944
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.607543813523186
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.236]
 [32.057]
 [34.458]
 [25.088]
 [25.122]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  62.597865379706114
printing an ep nov before normalisation:  42.562696303164216
printing an ep nov before normalisation:  70.51788000827086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.74317899083842
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8839481
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.25248505906026
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.193101697389157
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8809349
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.24 ]
 [41.255]
 [42.108]
 [38.409]
 [38.98 ]] [[1.117]
 [1.284]
 [1.332]
 [1.126]
 [1.158]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  30.342940755928012
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.09913543262959
siam score:  -0.88447386
actions average: 
K:  3  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0004,     0.0004],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9958,     0.0003,     0.0004,     0.0034],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0003,     0.9152,     0.0116,     0.0728],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0074,     0.0014,     0.8382,     0.1528],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0003,     0.0018,     0.2454,     0.1976,     0.5549],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.533772468566895
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 57.851494594602016
printing an ep nov before normalisation:  53.97909868619894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.01091909408569
printing an ep nov before normalisation:  29.824622472127277
printing an ep nov before normalisation:  50.22949660405923
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.8643145122541
printing an ep nov before normalisation:  49.35102559691553
printing an ep nov before normalisation:  0.03357144897904618
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.54298850280435
printing an ep nov before normalisation:  53.895114153535246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.90111153822143
using explorer policy with actor:  1
printing an ep nov before normalisation:  58.507055419790674
printing an ep nov before normalisation:  56.95807350438295
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.663118297655597
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.386]
 [33.692]
 [38.207]
 [37.535]
 [37.386]] [[1.382]
 [1.17 ]
 [1.429]
 [1.39 ]
 [1.382]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.026 0.282 0.41  0.051 0.231]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.855]
 [40.986]
 [47.715]
 [45.364]
 [46.801]] [[0.402]
 [0.387]
 [0.498]
 [0.459]
 [0.483]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.92635283533077
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.25932963502004
printing an ep nov before normalisation:  45.870361328125
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8770863
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.58087550383836
line 256 mcts: sample exp_bonus 53.08600723584049
printing an ep nov before normalisation:  31.323772328093337
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.98422447535783
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.18608351968524
printing an ep nov before normalisation:  43.03857234754466
using explorer policy with actor:  1
siam score:  -0.85931396
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.6294086513092
line 256 mcts: sample exp_bonus 55.371268105901464
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.080861207013612
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.793755492518464
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.708]
 [38.62 ]
 [41.858]
 [41.408]
 [39.562]] [[0.804]
 [0.845]
 [0.991]
 [0.971]
 [0.888]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  65.1610445573276
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8669249
printing an ep nov before normalisation:  54.13906278643373
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.92305494521379
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.739934663771265
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.17 ]
 [32.496]
 [32.545]
 [24.142]
 [24.554]] [[0.862]
 [1.074]
 [1.077]
 [0.664]
 [0.684]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.184126523223405
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.26769340775731
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87608755
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0005,     0.9619,     0.0205,     0.0002,     0.0169],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0003,     0.0060,     0.7967,     0.0905,     0.1065],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0041, 0.0007, 0.1068, 0.6064, 0.2820], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0012, 0.0010, 0.1260, 0.3035, 0.5682], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9950,     0.0001,     0.0000,     0.0031,     0.0018],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0011,     0.9670,     0.0013,     0.0003,     0.0302],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0005,     0.8837,     0.0475,     0.0682],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0006,     0.0004,     0.0634,     0.7352,     0.2004],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0193, 0.0093, 0.1156, 0.2390, 0.6168], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.842]
 [21.231]
 [22.52 ]
 [20.778]
 [20.778]] [[0.221]
 [0.228]
 [0.254]
 [0.219]
 [0.219]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.472]
 [54.472]
 [54.472]
 [54.472]
 [54.472]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
printing an ep nov before normalisation:  35.16152998518512
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.115]
 [54.115]
 [92.084]
 [54.115]
 [54.115]] [[0.572]
 [0.572]
 [1.337]
 [0.572]
 [0.572]]
printing an ep nov before normalisation:  65.86612965778814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.82884534692547
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.96710061396388
printing an ep nov before normalisation:  35.75204458199878
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 54.159319713038315
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.146980407873755
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  0.13597737245731878
actions average: 
K:  4  action  0 :  tensor([    0.9971,     0.0012,     0.0002,     0.0004,     0.0012],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0006,     0.9907,     0.0018,     0.0008,     0.0060],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0008,     0.8438,     0.0685,     0.0867],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0002,     0.0880,     0.6763,     0.2352],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0037,     0.0006,     0.0810,     0.2571,     0.6575],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.57702561182189
actions average: 
K:  3  action  0 :  tensor([    0.9990,     0.0001,     0.0000,     0.0001,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0003,     0.9711,     0.0043,     0.0008,     0.0235],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0002,     0.9105,     0.0379,     0.0514],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0005,     0.0477,     0.7474,     0.2041],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0021, 0.0050, 0.0553, 0.2766, 0.6610], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  82.86359380062393
actions average: 
K:  2  action  0 :  tensor([    0.9994,     0.0002,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9996,     0.0000,     0.0001,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0006,     0.0225,     0.8505,     0.0482,     0.0783],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0009,     0.0004,     0.0871,     0.7001,     0.2115],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0034, 0.0164, 0.0679, 0.2717, 0.6406], grad_fn=<DivBackward0>)
siam score:  -0.88105375
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.582767830870484
printing an ep nov before normalisation:  36.46825075149536
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.522]
 [30.827]
 [26.945]
 [24.   ]
 [23.745]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  83.3586631136736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.0891227722168
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.606]
 [44.606]
 [47.523]
 [46.265]
 [44.606]] [[0.798]
 [0.798]
 [0.891]
 [0.851]
 [0.798]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.85540991834226
printing an ep nov before normalisation:  34.11674310990209
printing an ep nov before normalisation:  33.30019950866699
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.41268644418532
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.576297336757136
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.749583473173338
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.002035541735949664
printing an ep nov before normalisation:  55.32211358978718
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.515647089953134
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.019577668033576856
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.0122023005493
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.35750486582665
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.531091647194565
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.077121323274092
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.295]
 [41.295]
 [41.295]
 [48.168]
 [41.295]] [[1.173]
 [1.173]
 [1.173]
 [1.432]
 [1.173]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.215132808068233
printing an ep nov before normalisation:  28.513007033115848
printing an ep nov before normalisation:  36.35512760707311
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.99319354043036
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.0396085192856
printing an ep nov before normalisation:  54.46077291577769
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.351]
 [18.566]
 [27.349]
 [17.57 ]
 [19.793]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  38.69064807891846
printing an ep nov before normalisation:  27.292286462650218
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.991213808994097
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.141]
 [42.141]
 [42.141]
 [42.141]
 [42.141]] [[0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.795]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.428957618296714
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 32.0677873670979
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9899,     0.0006,     0.0006,     0.0008,     0.0081],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9971,     0.0007,     0.0017,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0004,     0.0057,     0.8990,     0.0239,     0.0710],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0001,     0.0928,     0.6594,     0.2476],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0002,     0.0006,     0.1599,     0.2300,     0.6094],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.58975541552762
line 256 mcts: sample exp_bonus 45.305530993963366
actions average: 
K:  2  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0008,     0.9970,     0.0000,     0.0009,     0.0013],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0094, 0.0187, 0.9324, 0.0103, 0.0292], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0026,     0.0388,     0.7849,     0.1736],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0012, 0.0434, 0.0752, 0.1935, 0.6868], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [19.652]
 [ 0.   ]] [[-0.696]
 [-0.696]
 [-0.696]
 [ 1.   ]
 [-0.696]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.627151012420654
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.12209662236011
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  37.63833045959473
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.18263012772454
printing an ep nov before normalisation:  46.305316170800076
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.335784912109375
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.65025946204256
printing an ep nov before normalisation:  30.81005190465369
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9952,     0.0002,     0.0006,     0.0038],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0002,     0.9294,     0.0311,     0.0393],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0009,     0.0002,     0.0188,     0.8063,     0.1738],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0009, 0.0041, 0.0366, 0.2408, 0.7177], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  35.603163404470564
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.771]
 [54.8  ]
 [54.301]
 [55.992]
 [57.761]] [[1.561]
 [1.71 ]
 [1.686]
 [1.769]
 [1.856]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
printing an ep nov before normalisation:  27.052402496337894
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.523]
 [49.489]
 [41.523]
 [44.71 ]
 [44.109]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.89390165
printing an ep nov before normalisation:  40.82788403785042
actions average: 
K:  1  action  0 :  tensor([    0.9996,     0.0000,     0.0001,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9971,     0.0027,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0002,     0.8420,     0.0642,     0.0935],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0044, 0.0008, 0.0458, 0.7497, 0.1993], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0075, 0.0188, 0.1092, 0.2763, 0.5882], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.736]
 [ 3.458]
 [10.462]
 [ 7.671]
 [ 8.   ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  41.859056109833155
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8916388
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  0.11768083867139012
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.837]
 [41.837]
 [46.542]
 [41.837]
 [41.837]] [[0.852]
 [0.852]
 [1.   ]
 [0.852]
 [0.852]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.32843208312988
printing an ep nov before normalisation:  44.87719478040381
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.00177250114854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.72325563430786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.37082278594068
printing an ep nov before normalisation:  33.90981305533327
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  43.60167155707114
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.61661223612824
printing an ep nov before normalisation:  21.188723855799086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.967]
 [40.55 ]
 [40.55 ]
 [47.563]
 [40.55 ]] [[1.614]
 [1.052]
 [1.052]
 [1.43 ]
 [1.052]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.28282574599863
printing an ep nov before normalisation:  52.985565658672144
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 42.00959667921119
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.32 ]
 [38.528]
 [37.752]
 [36.32 ]
 [36.32 ]] [[1.802]
 [2.   ]
 [1.931]
 [1.802]
 [1.802]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.37316679274056
printing an ep nov before normalisation:  27.327228629260794
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.68223019967381
printing an ep nov before normalisation:  42.49249408085879
printing an ep nov before normalisation:  32.686325214970736
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
UNIT TEST: sample policy line 217 mcts : [0.026 0.077 0.462 0.051 0.385]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.685750133033565
actions average: 
K:  3  action  0 :  tensor([0.9384, 0.0290, 0.0014, 0.0109, 0.0203], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9969,     0.0004,     0.0005,     0.0022],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0003,     0.0003,     0.8795,     0.0601,     0.0599],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0039,     0.0507,     0.7452,     0.1997],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0014, 0.0041, 0.1166, 0.1863, 0.6915], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  58.12585710747974
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.47 ]
 [46.47 ]
 [54.331]
 [52.35 ]
 [54.374]] [[0.727]
 [0.727]
 [0.921]
 [0.872]
 [0.922]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.0290907125358
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.30091335994807
printing an ep nov before normalisation:  27.17341661453247
printing an ep nov before normalisation:  47.890621031982064
printing an ep nov before normalisation:  49.7880220413208
siam score:  -0.88921046
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.68865297869203
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.963]
 [36.322]
 [42.867]
 [35.736]
 [39.225]] [[0.499]
 [0.453]
 [0.535]
 [0.446]
 [0.49 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.334]
 [14.633]
 [ 5.5  ]
 [12.011]
 [15.919]] [[0.186]
 [0.204]
 [0.077]
 [0.168]
 [0.222]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.29150462257724
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.25549047254934
printing an ep nov before normalisation:  86.65842098951148
printing an ep nov before normalisation:  41.73037917238372
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.327335357666016
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 44.503030326946615
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.718]
 [47.718]
 [55.072]
 [54.785]
 [53.906]] [[1.176]
 [1.176]
 [1.521]
 [1.507]
 [1.466]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.103655148793447
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
deleting a thread, now have 1 threads
Frames:  111913 train batches done:  13111 episodes:  4153
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8789409
printing an ep nov before normalisation:  43.782215274943376
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8798574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8836491
actions average: 
K:  2  action  0 :  tensor([    0.9993,     0.0000,     0.0001,     0.0002,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9679,     0.0127,     0.0005,     0.0186],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0006,     0.9561,     0.0125,     0.0308],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0005,     0.0384,     0.7580,     0.2026],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0032, 0.0345, 0.0976, 0.1876, 0.6771], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.029937744140625
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9992,     0.0001,     0.0001,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0011, 0.9567, 0.0047, 0.0017, 0.0357], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0001,     0.9365,     0.0242,     0.0388],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0006,     0.0001,     0.0221,     0.8558,     0.1214],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0024, 0.0015, 0.1332, 0.1615, 0.7014], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.54537151730446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9960,     0.0003,     0.0002,     0.0020,     0.0014],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0029,     0.9922,     0.0004,     0.0006,     0.0039],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0002,     0.8515,     0.0640,     0.0843],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0007,     0.0004,     0.0407,     0.8059,     0.1524],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0018, 0.0059, 0.1771, 0.2271, 0.5882], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.89404184
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.62053389427842
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.921]
 [21.776]
 [21.224]
 [24.039]
 [18.289]] [[0.167]
 [0.114]
 [0.108]
 [0.137]
 [0.078]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.58924197187488
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.88951564
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9976,     0.0002,     0.0000,     0.0007,     0.0015],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0011, 0.9667, 0.0076, 0.0032, 0.0214], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0002,     0.8565,     0.0608,     0.0823],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0005,     0.0017,     0.6426,     0.3546],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0008, 0.0021, 0.1919, 0.2801, 0.5251], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.596]
 [34.596]
 [34.596]
 [34.596]
 [34.596]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.7127752590163
printing an ep nov before normalisation:  52.00173377990723
printing an ep nov before normalisation:  81.20232465938929
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.05918059623786
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.31635027437555
printing an ep nov before normalisation:  48.05492431064213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.3930721282959
siam score:  -0.88886935
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.71022955658702
printing an ep nov before normalisation:  41.62781238555908
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.043]
 [36.043]
 [36.043]
 [40.903]
 [36.043]] [[1.447]
 [1.447]
 [1.447]
 [1.83 ]
 [1.447]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.22065177860638
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.034]
 [45.582]
 [34.034]
 [34.034]
 [34.034]] [[0.685]
 [1.128]
 [0.685]
 [0.685]
 [0.685]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.33982686564492
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.56848434031518
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.45915699782919
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.79808229523622
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.486]
 [37.314]
 [38.66 ]
 [37.034]
 [35.317]] [[0.69 ]
 [0.718]
 [0.764]
 [0.708]
 [0.65 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.15847465501242
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.566972287399757
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.051 0.103 0.205 0.385 0.256]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.893]
 [37.72 ]
 [55.602]
 [34.882]
 [35.837]] [[0.143]
 [0.161]
 [0.273]
 [0.143]
 [0.149]]
printing an ep nov before normalisation:  35.8904309327559
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.814866065979004
printing an ep nov before normalisation:  38.98971004581138
siam score:  -0.88639045
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.3122818438005
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.889]
 [37.312]
 [37.32 ]
 [35.159]
 [37.312]] [[0.844]
 [0.718]
 [0.718]
 [0.676]
 [0.718]]
actions average: 
K:  4  action  0 :  tensor([    0.9938,     0.0002,     0.0003,     0.0022,     0.0036],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9944,     0.0018,     0.0002,     0.0036],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0044,     0.0004,     0.9404,     0.0280,     0.0268],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0013,     0.0594,     0.7141,     0.2248],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0008, 0.0415, 0.1816, 0.2435, 0.5326], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.2343652825442
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.002]
 [57.108]
 [57.631]
 [56.747]
 [56.583]] [[0.59 ]
 [0.861]
 [0.877]
 [0.85 ]
 [0.845]]
siam score:  -0.8892705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.991067315097574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.81870974429647
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.77742813309561
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.095058328258325
siam score:  -0.8874361
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([0.9888, 0.0011, 0.0076, 0.0015, 0.0010], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0005,     0.9373,     0.0003,     0.0004,     0.0616],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0032,     0.9000,     0.0359,     0.0609],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0009,     0.0006,     0.0557,     0.7753,     0.1675],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0073, 0.0112, 0.0525, 0.4145, 0.5145], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  16.296963635350384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.15745950319049
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.453]
 [40.77 ]
 [33.131]
 [33.131]
 [28.407]] [[0.778]
 [1.293]
 [0.871]
 [0.871]
 [0.61 ]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.366]
 [36.706]
 [30.447]
 [33.908]
 [32.363]] [[1.047]
 [1.015]
 [0.707]
 [0.877]
 [0.801]]
actions average: 
K:  1  action  0 :  tensor([    0.9312,     0.0000,     0.0000,     0.0375,     0.0313],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0001,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.8865,     0.0575,     0.0559],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0003,     0.0551,     0.7314,     0.2131],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0002,     0.0019,     0.0937,     0.3172,     0.5870],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.094220407421695
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  59.58460228995237
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.422]
 [34.422]
 [34.422]
 [34.422]
 [34.422]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9972,     0.0001,     0.0000,     0.0012,     0.0015],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9988,     0.0000,     0.0001,     0.0011],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0124,     0.8570,     0.0451,     0.0854],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0005,     0.0007,     0.0814,     0.6809,     0.2365],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0021, 0.0181, 0.0365, 0.3575, 0.5858], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.077 0.513 0.154 0.026 0.231]
siam score:  -0.8877529
actions average: 
K:  0  action  0 :  tensor([    0.9996,     0.0001,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9996,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0003,     0.9307,     0.0293,     0.0395],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0003,     0.0454,     0.6852,     0.2686],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0010, 0.0146, 0.1172, 0.2102, 0.6570], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88577104
siam score:  -0.8869221
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.639]
 [32.431]
 [34.912]
 [46.567]
 [32.431]] [[0.912]
 [0.501]
 [0.585]
 [0.977]
 [0.501]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.745964487943894
printing an ep nov before normalisation:  84.64868222954426
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.45871891611472
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.55997858931776
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.14502037332785
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.937740966785064
actions average: 
K:  1  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9990,     0.0005,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0005,     0.8636,     0.0506,     0.0851],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0010, 0.0020, 0.0658, 0.7092, 0.2220], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0023, 0.0048, 0.0387, 0.3901, 0.5641], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.02506351470947
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.2927601889177
line 256 mcts: sample exp_bonus 49.21033311091922
printing an ep nov before normalisation:  39.99798604151498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.631955846649625
printing an ep nov before normalisation:  40.92517175268941
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88420343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.626]
 [37.137]
 [39.385]
 [45.518]
 [41.649]] [[0.268]
 [0.323]
 [0.372]
 [0.507]
 [0.422]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.63514335488066
siam score:  -0.86895144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.52922608181081
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.14291572570801
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.06182116184508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.717]
 [53.284]
 [41.742]
 [53.284]
 [53.284]] [[0.567]
 [0.529]
 [0.347]
 [0.529]
 [0.529]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.67905503428963
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.179 0.205 0.282 0.179 0.154]
printing an ep nov before normalisation:  36.73047669367042
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87732816
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.81518667783678
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.48764753341675
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.569]
 [37.497]
 [38.182]
 [40.218]
 [38.358]] [[1.53 ]
 [1.209]
 [1.252]
 [1.381]
 [1.263]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.911]
 [46.179]
 [49.144]
 [49.532]
 [49.525]] [[1.885]
 [1.73 ]
 [1.898]
 [1.92 ]
 [1.92 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.239]
 [33.164]
 [33.164]
 [33.164]
 [33.164]] [[1.503]
 [1.072]
 [1.072]
 [1.072]
 [1.072]]
printing an ep nov before normalisation:  52.613343294247045
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.00393659335121
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.76710163707273
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.010555425061604
siam score:  -0.8827248
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9894,     0.0032,     0.0024,     0.0005,     0.0045],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9988,     0.0001,     0.0004,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0040,     0.8925,     0.0414,     0.0621],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0003,     0.1241,     0.6618,     0.2137],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0016, 0.0176, 0.1425, 0.2596, 0.5787], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8845312
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.37811186393097
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.32256031036377
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8851139
actions average: 
K:  0  action  0 :  tensor([    0.9630,     0.0060,     0.0001,     0.0305,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9989,     0.0000,     0.0010,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0000,     0.9681,     0.0158,     0.0160],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0010,     0.0004,     0.0382,     0.7277,     0.2327],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0010, 0.0011, 0.0553, 0.2572, 0.6854], grad_fn=<DivBackward0>)
siam score:  -0.88387877
printing an ep nov before normalisation:  34.96186713534647
printing an ep nov before normalisation:  31.010916233062744
printing an ep nov before normalisation:  49.32323873259094
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 -1.4885280285021994e-11
0.0 -1.6424838614264566e-11
0.0 -1.2377011091420502e-11
0.0 -1.0232008468303593e-11
0.0 -1.802494138145322e-11
0.0 0.0
0.0 0.0
0.0 -1.774816684941215e-11
0.0 -1.6641068718831313e-11
0.0 -1.489392949055794e-11
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.468]
 [30.468]
 [31.903]
 [30.468]
 [30.468]] [[0.82 ]
 [0.82 ]
 [0.897]
 [0.82 ]
 [0.82 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.69752108604836
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9999,     0.0001,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9971,     0.0016,     0.0004,     0.0008],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0031,     0.9231,     0.0290,     0.0447],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0014,     0.0568,     0.6638,     0.2775],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0011, 0.0027, 0.0639, 0.1991, 0.7332], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8809549
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.8976556096352
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88624954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  28.15784535093637
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.576]
 [17.736]
 [21.638]
 [24.819]
 [20.76 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.027445793151855
printing an ep nov before normalisation:  56.3186865253378
printing an ep nov before normalisation:  34.19212287851373
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.93105433784468
printing an ep nov before normalisation:  44.781079732458814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  60.678450430081895
printing an ep nov before normalisation:  33.31328180558349
printing an ep nov before normalisation:  45.70630620628007
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.43603193174417
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.0505464850901
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.97747899385318
actions average: 
K:  3  action  0 :  tensor([    0.9961,     0.0002,     0.0000,     0.0004,     0.0032],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9928,     0.0001,     0.0062,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0000,     0.9623,     0.0128,     0.0248],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0018,     0.0003,     0.0743,     0.6732,     0.2504],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0073, 0.0118, 0.0338, 0.2863, 0.6608], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  49.97583511467213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.89651322364807
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.625680923461914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.95927380023263
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.041]
 [18.139]
 [18.139]
 [22.909]
 [18.139]] [[0.69 ]
 [0.24 ]
 [0.24 ]
 [0.353]
 [0.24 ]]
printing an ep nov before normalisation:  32.59502882242007
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9888,     0.0093,     0.0001,     0.0003,     0.0014],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9996,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0004,     0.9129,     0.0287,     0.0579],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0032,     0.0830,     0.6703,     0.2431],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0014, 0.0019, 0.1129, 0.3833, 0.5004], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.773343086242676
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.2759841000846
printing an ep nov before normalisation:  48.71647780176698
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.948262886581723
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.033149384496724
printing an ep nov before normalisation:  38.76991358600754
printing an ep nov before normalisation:  37.777060748767866
actions average: 
K:  4  action  0 :  tensor([    0.8899,     0.0034,     0.0007,     0.0323,     0.0738],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9967,     0.0013,     0.0005,     0.0014],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0058, 0.0010, 0.8677, 0.0659, 0.0597], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0000,     0.0066,     0.1100,     0.7547,     0.1286],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0002,     0.0014,     0.0726,     0.2754,     0.6504],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  41.89248672809601
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.89738114167518
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.827215018462354
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  8.195633057539453e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.11315440284257
printing an ep nov before normalisation:  46.85093972887062
printing an ep nov before normalisation:  44.10697884029812
printing an ep nov before normalisation:  49.248064328941055
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.69904804229736
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  53.03417395986297
siam score:  -0.8797037
siam score:  -0.87742543
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.094850213727405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.98417485971915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.519876837730408
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  49.64639210891607
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.733288670948305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.8538956235163
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.934112497491974
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.536]
 [17.959]
 [22.538]
 [15.403]
 [16.446]] [[0.208]
 [0.145]
 [0.225]
 [0.1  ]
 [0.118]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.672948286873496
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  41.49359703063965
siam score:  -0.8794618
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.15413284301758
printing an ep nov before normalisation:  0.0003761189725537406
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.41763704717852
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.8471155166626
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0011, 0.9865, 0.0017, 0.0032, 0.0075], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0000,     0.9137,     0.0367,     0.0495],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0003,     0.0010,     0.7985,     0.2001],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0009, 0.0011, 0.0886, 0.1818, 0.7277], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  45.60755540544024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.51771147661343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.273183260996554
printing an ep nov before normalisation:  53.98687438334381
printing an ep nov before normalisation:  42.13433265686035
siam score:  -0.86963534
printing an ep nov before normalisation:  41.145593095199644
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  19.602214801845175
printing an ep nov before normalisation:  23.498717308105025
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  3.684453702135215e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9986,     0.0001,     0.0001,     0.0007,     0.0005],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9948,     0.0018,     0.0012,     0.0018],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.8604,     0.0607,     0.0788],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0015,     0.0004,     0.0723,     0.7320,     0.1939],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0087, 0.0029, 0.0894, 0.2515, 0.6475], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  74.8862829813479
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.31103801727295
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.699393676205936
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.524050760863716
printing an ep nov before normalisation:  37.080252607798364
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8723518
printing an ep nov before normalisation:  38.24887898243297
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  29.001264962011184
siam score:  -0.87136686
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.909]
 [31.253]
 [40.012]
 [37.122]
 [31.253]] [[0.785]
 [0.752]
 [1.187]
 [1.044]
 [0.752]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.162211441271495
printing an ep nov before normalisation:  46.00267660463649
printing an ep nov before normalisation:  28.646148157777958
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8725755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.88239708635598
actions average: 
K:  4  action  0 :  tensor([    0.9811,     0.0012,     0.0001,     0.0007,     0.0169],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9919,     0.0006,     0.0006,     0.0069],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0015, 0.0016, 0.8971, 0.0372, 0.0627], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0011,     0.1325,     0.6233,     0.2426],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0063, 0.0080, 0.1307, 0.2549, 0.6001], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  51.92024821979431
printing an ep nov before normalisation:  45.78318548990444
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[78.952]
 [78.952]
 [78.952]
 [78.952]
 [78.952]] [[1.666]
 [1.666]
 [1.666]
 [1.666]
 [1.666]]
printing an ep nov before normalisation:  53.651443700474616
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.596903075946376
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.18502492532649
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.885885
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  55.058052154358265
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.566]
 [63.566]
 [63.566]
 [63.566]
 [63.566]] [[1.976]
 [1.976]
 [1.976]
 [1.976]
 [1.976]]
printing an ep nov before normalisation:  33.656439781188965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9637,     0.0160,     0.0008,     0.0194],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0026, 0.0008, 0.7609, 0.1240, 0.1117], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0026, 0.0017, 0.0653, 0.7724, 0.1582], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0179, 0.0019, 0.0894, 0.3202, 0.5706], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.706]
 [36.706]
 [37.934]
 [36.706]
 [36.706]] [[1.258]
 [1.258]
 [1.333]
 [1.258]
 [1.258]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88423723
printing an ep nov before normalisation:  48.65359640989726
actions average: 
K:  3  action  0 :  tensor([    0.9910,     0.0009,     0.0001,     0.0032,     0.0048],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9986,     0.0006,     0.0005,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9311,     0.0389,     0.0300],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0002,     0.0230,     0.8078,     0.1689],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0004,     0.0032,     0.0160,     0.1562,     0.8242],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.488419874273262
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.262431006471274
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.80653085079124
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.826]
 [33.449]
 [38.737]
 [36.534]
 [32.678]] [[1.056]
 [1.035]
 [1.335]
 [1.21 ]
 [0.991]]
printing an ep nov before normalisation:  30.221681594848633
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.884]
 [52.884]
 [52.423]
 [52.884]
 [54.032]] [[1.933]
 [1.933]
 [1.906]
 [1.933]
 [2.   ]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.42505800378949
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.884215615779958
maxi score, test score, baseline:  0.0001 0.0 0.0001
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.41943073272705
printing an ep nov before normalisation:  33.88872571418977
printing an ep nov before normalisation:  30.93228816986084
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  29.477980734946367
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.00465718395027
printing an ep nov before normalisation:  33.93321752548218
printing an ep nov before normalisation:  48.4374887599478
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  62.94019732832815
siam score:  -0.8727832
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.243]
 [42.243]
 [42.243]
 [50.822]
 [42.243]] [[1.054]
 [1.054]
 [1.054]
 [1.354]
 [1.054]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.107]
 [20.349]
 [42.393]
 [43.644]
 [19.719]] [[0.174]
 [0.06 ]
 [0.273]
 [0.285]
 [0.054]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.48858109063499
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.3430231457718
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.32289614250832
printing an ep nov before normalisation:  45.133142521587736
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  39.47126865386963
printing an ep nov before normalisation:  27.079158819492687
printing an ep nov before normalisation:  35.91265403908839
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.31280149990361
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.72785323019896
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.806]
 [31.353]
 [28.881]
 [31.353]
 [31.353]] [[1.301]
 [0.665]
 [0.575]
 [0.665]
 [0.665]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 36.541314125061035
printing an ep nov before normalisation:  37.78342247009277
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88060087
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8794836
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.942166857886356
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.05757713317871
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.28450478967612
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.407]
 [42.407]
 [50.358]
 [42.407]
 [42.407]] [[0.824]
 [0.824]
 [1.119]
 [0.824]
 [0.824]]
printing an ep nov before normalisation:  59.01772459191139
printing an ep nov before normalisation:  43.110063071499084
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.399309828152965
printing an ep nov before normalisation:  68.99408240614723
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.59189528552987
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.328419220129305
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.8807904
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.21097479484352
printing an ep nov before normalisation:  43.938775062561035
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.756]
 [39.05 ]
 [36.306]
 [39.532]
 [40.571]] [[1.459]
 [1.041]
 [0.892]
 [1.067]
 [1.124]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9975,     0.0000,     0.0000,     0.0008,     0.0017],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0007,     0.9967,     0.0009,     0.0011,     0.0006],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0001,     0.8852,     0.0564,     0.0582],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0002,     0.0630,     0.6695,     0.2670],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0017, 0.0113, 0.1224, 0.2779, 0.5868], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  44.120138577844465
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9987,     0.0001,     0.0000,     0.0004,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9992,     0.0000,     0.0008,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0006,     0.8966,     0.0450,     0.0577],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0004,     0.0006,     0.1643,     0.5448,     0.2899],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0013, 0.0019, 0.0925, 0.2676, 0.6368], grad_fn=<DivBackward0>)
siam score:  -0.8859064
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.013]
 [28.242]
 [34.022]
 [30.819]
 [31.982]] [[0.193]
 [0.196]
 [0.283]
 [0.235]
 [0.252]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.67060329998856
printing an ep nov before normalisation:  30.38776112009661
printing an ep nov before normalisation:  45.32823807549757
printing an ep nov before normalisation:  38.58416795730591
siam score:  -0.8877725
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  75.61814044722482
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.93469476699829
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.011]
 [77.011]
 [77.011]
 [77.011]
 [77.011]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.64787075855539
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.460162397171615
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.23926486715762
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.34885011867142
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.400878747212342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.74430502105155
printing an ep nov before normalisation:  58.99495506624296
using explorer policy with actor:  1
siam score:  -0.8900223
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.667467835676646
printing an ep nov before normalisation:  58.15326569852286
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.268]
 [33.176]
 [32.376]
 [30.931]
 [28.136]] [[1.048]
 [1.494]
 [1.433]
 [1.324]
 [1.114]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.47830700749965
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0161,     0.9803,     0.0001,     0.0005,     0.0030],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0143,     0.9261,     0.0176,     0.0418],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0085, 0.0023, 0.0366, 0.7777, 0.1749], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0329, 0.0424, 0.0385, 0.3563, 0.5299], grad_fn=<DivBackward0>)
siam score:  -0.8831714
printing an ep nov before normalisation:  49.26835333866977
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.54260699854957
printing an ep nov before normalisation:  66.27774713093733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.5251903001035
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.009]
 [38.009]
 [38.009]
 [38.009]
 [38.009]] [[1.194]
 [1.194]
 [1.194]
 [1.194]
 [1.194]]
printing an ep nov before normalisation:  48.31338949412398
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.713041097864185
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.31580608964388
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.472583583149124
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.31946563720703
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.76680620369522
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8807205
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0021,     0.9869,     0.0001,     0.0008,     0.0101],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9189,     0.0340,     0.0468],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0054,     0.0002,     0.0365,     0.7355,     0.2224],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0057, 0.0013, 0.0753, 0.2519, 0.6659], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.17546190214957
siam score:  -0.88534427
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.11766496854342
printing an ep nov before normalisation:  49.2031192779541
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.22844290008044
printing an ep nov before normalisation:  50.46556940249987
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.096]
 [37.096]
 [37.096]
 [37.096]
 [37.096]] [[1.013]
 [1.013]
 [1.013]
 [1.013]
 [1.013]]
printing an ep nov before normalisation:  50.63322796283312
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.681727873692445
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.096]
 [26.059]
 [29.317]
 [25.097]
 [28.096]] [[0.564]
 [0.493]
 [0.607]
 [0.46 ]
 [0.564]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.25717491347558
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.9982,     0.0000,     0.0000,     0.0010,     0.0007],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9978,     0.0002,     0.0007,     0.0013],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0062, 0.0015, 0.9056, 0.0262, 0.0605], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0073, 0.0047, 0.0283, 0.7803, 0.1794], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0136, 0.0019, 0.0221, 0.2655, 0.6968], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.81688373507785
siam score:  -0.8811278
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8794634
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.029]
 [46.029]
 [47.818]
 [46.029]
 [46.771]] [[1.513]
 [1.513]
 [1.572]
 [1.513]
 [1.538]]
printing an ep nov before normalisation:  60.73638268653027
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.52154953340073
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.994]
 [71.994]
 [69.282]
 [71.994]
 [68.816]] [[1.   ]
 [1.   ]
 [0.951]
 [1.   ]
 [0.943]]
siam score:  -0.8829659
actions average: 
K:  3  action  0 :  tensor([    0.9964,     0.0001,     0.0000,     0.0010,     0.0026],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0068,     0.8979,     0.0424,     0.0528],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0009,     0.0003,     0.0004,     0.7880,     0.2104],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0016, 0.0031, 0.0396, 0.3592, 0.5966], grad_fn=<DivBackward0>)
siam score:  -0.88018435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.42701408431932
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.80738600401107
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.337]
 [44.27 ]
 [26.266]
 [26.762]
 [35.118]] [[0.26 ]
 [0.26 ]
 [0.093]
 [0.098]
 [0.175]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.08998423761885
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.411]
 [42.411]
 [42.411]
 [42.411]
 [42.411]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
siam score:  -0.88183576
printing an ep nov before normalisation:  31.73868179321289
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9996,     0.0000,     0.0001,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9961,     0.0010,     0.0019,     0.0010],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.8109,     0.0792,     0.1098],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0008,     0.0382,     0.7019,     0.2589],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0010, 0.0016, 0.0814, 0.3114, 0.6046], grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  44.771815616726
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.552749783418825
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.723340376193015
printing an ep nov before normalisation:  45.78470564088917
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.462 0.154 0.282 0.051 0.051]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.196]
 [26.81 ]
 [24.245]
 [36.019]
 [26.914]] [[0.457]
 [0.307]
 [0.22 ]
 [0.622]
 [0.311]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.97938585281372
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.75196351333436
printing an ep nov before normalisation:  23.190167951241023
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.165]
 [39.165]
 [39.165]
 [39.165]
 [39.165]] [[1.76]
 [1.76]
 [1.76]
 [1.76]
 [1.76]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.407]
 [38.827]
 [36.97 ]
 [36.642]
 [30.084]] [[1.208]
 [1.117]
 [1.009]
 [0.99 ]
 [0.61 ]]
printing an ep nov before normalisation:  53.371242360691696
printing an ep nov before normalisation:  35.37707976479523
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.493]
 [35.194]
 [43.327]
 [38.539]
 [38.77 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.72431775868128
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.8813676
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.155228821678875
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.384883665256964
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.899]
 [35.465]
 [30.122]
 [35.926]
 [35.777]] [[0.976]
 [0.818]
 [0.627]
 [0.834]
 [0.829]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.715]
 [42.715]
 [43.275]
 [42.715]
 [42.715]] [[1.302]
 [1.302]
 [1.333]
 [1.302]
 [1.302]]
printing an ep nov before normalisation:  50.095622401030994
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.748055271578735
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  73.322448691154
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.7760987034903
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  0.0
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.659]
 [37.264]
 [37.861]
 [37.861]
 [37.861]] [[1.667]
 [1.485]
 [1.53 ]
 [1.53 ]
 [1.53 ]]
printing an ep nov before normalisation:  37.54685828573139
printing an ep nov before normalisation:  38.650109833331356
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.4365394782079
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.911718141207295
printing an ep nov before normalisation:  38.44224712498751
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.374854942644106
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 39.42033370006534
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.081]
 [48.754]
 [50.904]
 [46.45 ]
 [28.227]] [[0.425]
 [1.169]
 [1.239]
 [1.093]
 [0.495]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.57 ]
 [37.57 ]
 [37.57 ]
 [49.453]
 [37.57 ]] [[0.842]
 [0.842]
 [0.842]
 [1.233]
 [0.842]]
actions average: 
K:  2  action  0 :  tensor([    0.9988,     0.0004,     0.0000,     0.0002,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0001,     0.9087,     0.0391,     0.0520],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0026, 0.0025, 0.0431, 0.7056, 0.2461], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0053, 0.0016, 0.1025, 0.2755, 0.6151], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.425630779599786
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.06113564910183
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  44.24963520589525
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.89080710303642
printing an ep nov before normalisation:  37.46092831931371
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.25]
 [40.25]
 [40.25]
 [40.25]
 [40.25]] [[1.346]
 [1.346]
 [1.346]
 [1.346]
 [1.346]]
printing an ep nov before normalisation:  43.967772605045695
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88260406
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.784]
 [48.387]
 [29.554]
 [19.207]
 [24.59 ]] [[0.181]
 [0.466]
 [0.229]
 [0.098]
 [0.166]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.65301411370928
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.951]
 [43.788]
 [37.951]
 [37.951]
 [49.465]] [[0.465]
 [0.683]
 [0.465]
 [0.465]
 [0.895]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.965]
 [46.359]
 [46.359]
 [46.753]
 [46.359]] [[0.854]
 [0.901]
 [0.901]
 [0.915]
 [0.901]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.53496512081815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.01863698458402
printing an ep nov before normalisation:  55.836182787552026
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.667]
 [27.309]
 [41.144]
 [28.484]
 [29.29 ]] [[0.368]
 [0.428]
 [0.927]
 [0.47 ]
 [0.499]]
siam score:  -0.88356185
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.659]
 [27.97 ]
 [22.847]
 [27.545]
 [28.669]] [[0.853]
 [0.874]
 [0.526]
 [0.846]
 [0.922]]
siam score:  -0.8847026
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.098]
 [35.177]
 [43.712]
 [36.065]
 [43.199]] [[0.284]
 [0.376]
 [0.532]
 [0.392]
 [0.522]]
printing an ep nov before normalisation:  79.46029794239529
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  9.489488661529322e-06
actions average: 
K:  1  action  0 :  tensor([    0.9960,     0.0004,     0.0018,     0.0011,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0011,     0.9939,     0.0036,     0.0004,     0.0009],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0010,     0.8809,     0.0311,     0.0870],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0008, 0.0021, 0.0154, 0.7465, 0.2352], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0036, 0.0014, 0.1114, 0.2613, 0.6222], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.88651365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.64556085335864
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88552415
maxi score, test score, baseline:  0.0001 0.0 0.0001
rdn beta is 0 so we're just using the maxi policy
actions average: 
K:  0  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0007,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9976,     0.0006,     0.0007,     0.0010],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9074,     0.0365,     0.0560],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0004,     0.0850,     0.7327,     0.1817],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0006,     0.0006,     0.0856,     0.2642,     0.6490],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9991,     0.0002,     0.0000,     0.0001,     0.0007],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9988,     0.0004,     0.0001,     0.0007],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.8828,     0.0461,     0.0710],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0024, 0.0011, 0.0760, 0.7930, 0.1275], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0013, 0.0197, 0.1171, 0.2743, 0.5876], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88737184
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.50624451295686
line 256 mcts: sample exp_bonus 0.00023853294607079079
printing an ep nov before normalisation:  63.0458412394498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.40679745613161
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.67243774684844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.57800742640147
printing an ep nov before normalisation:  36.64953964571412
printing an ep nov before normalisation:  0.00045434088463025546
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8644183
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.184749603271484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.184671915005126
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.376]
 [30.174]
 [32.604]
 [27.682]
 [27.947]] [[0.958]
 [0.491]
 [0.571]
 [0.409]
 [0.418]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 54.9021957394268
siam score:  -0.86924666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.56477548678223
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.35652197299505
line 256 mcts: sample exp_bonus 36.74342955880384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.54495048522949
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.482080671666736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.969913959503174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8834648
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.36536791854947
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.92]
 [60.92]
 [60.92]
 [60.92]
 [60.92]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.507]
 [38.507]
 [30.51 ]
 [38.507]
 [24.452]] [[1.897]
 [1.897]
 [1.333]
 [1.897]
 [0.906]]
printing an ep nov before normalisation:  63.30792454279181
printing an ep nov before normalisation:  74.93754099002672
printing an ep nov before normalisation:  58.23958764038654
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.43188674824177
printing an ep nov before normalisation:  66.53219407921287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.276]
 [48.276]
 [48.276]
 [48.276]
 [48.276]] [[0.96]
 [0.96]
 [0.96]
 [0.96]
 [0.96]]
siam score:  -0.88469696
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.02086742361068
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.67676278348115
printing an ep nov before normalisation:  61.16701660339834
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.890472193110405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  71.47848474610895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.40401537453775
printing an ep nov before normalisation:  38.12431024057868
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.61 ]
 [41.861]
 [33.835]
 [41.861]
 [41.861]] [[0.855]
 [0.589]
 [0.408]
 [0.589]
 [0.589]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.405]
 [42.405]
 [43.682]
 [41.463]
 [42.405]] [[1.36 ]
 [1.36 ]
 [1.438]
 [1.303]
 [1.36 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.450030500210545
printing an ep nov before normalisation:  37.670183181762695
printing an ep nov before normalisation:  30.380196571350098
printing an ep nov before normalisation:  54.483256329346624
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88361096
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.879]
 [23.942]
 [39.098]
 [16.038]
 [18.253]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  48.83896001157863
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.58 ]
 [28.58 ]
 [28.58 ]
 [41.949]
 [28.58 ]] [[0.262]
 [0.262]
 [0.262]
 [0.667]
 [0.262]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  60.0864063315034
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.05 ]
 [23.505]
 [23.755]
 [28.574]
 [24.706]] [[0.192]
 [0.25 ]
 [0.256]
 [0.37 ]
 [0.278]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.715575961638315
printing an ep nov before normalisation:  36.90049849519941
printing an ep nov before normalisation:  0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.94367924070104
siam score:  -0.8869092
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.00896702674497
printing an ep nov before normalisation:  32.8183931797379
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.43135738372803
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.799]
 [27.799]
 [27.799]
 [27.799]
 [27.799]] [[9.257]
 [9.257]
 [9.257]
 [9.257]
 [9.257]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.37117024130869
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.415]
 [24.415]
 [24.415]
 [24.415]
 [24.415]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.11387576087512
printing an ep nov before normalisation:  24.082992307217417
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.76979550153036
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.341721745259974
printing an ep nov before normalisation:  51.21530736692706
printing an ep nov before normalisation:  34.168808449478554
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0001,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9897,     0.0002,     0.0006,     0.0092],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9109,     0.0403,     0.0487],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0001,     0.0334,     0.7100,     0.2561],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0010, 0.0009, 0.0577, 0.2898, 0.6506], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.541]
 [34.541]
 [31.174]
 [41.674]
 [36.563]] [[0.505]
 [0.505]
 [0.349]
 [0.836]
 [0.599]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.181]
 [45.181]
 [50.357]
 [45.181]
 [45.181]] [[1.107]
 [1.107]
 [1.333]
 [1.107]
 [1.107]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.53312699780052
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.61543722625946
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.898690092166337
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.005]
 [37.861]
 [42.928]
 [37.861]
 [37.861]] [[0.465]
 [0.317]
 [0.422]
 [0.317]
 [0.317]]
printing an ep nov before normalisation:  31.392767429351807
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.21540487841319
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.80004537410072
Starting evaluation
printing an ep nov before normalisation:  47.826335404718115
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.8867438
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.853011403765
printing an ep nov before normalisation:  0.0005345937594825045
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.13511201999045
printing an ep nov before normalisation:  40.665720747873465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0018,     0.9310,     0.0024,     0.0002,     0.0646],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0022, 0.0269, 0.8805, 0.0266, 0.0637], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0060, 0.0008, 0.0400, 0.6356, 0.3176], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0118, 0.0446, 0.1057, 0.2462, 0.5918], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  27.733696230060318
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.560808051664964
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.2270380614145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.884901
using explorer policy with actor:  1
siam score:  -0.88496095
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.401597413574834
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.733483914001
printing an ep nov before normalisation:  0.00033660014167935515
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.64666564604794
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.37 ]
 [42.913]
 [42.913]
 [42.913]
 [42.913]] [[0.862]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
UNIT TEST: sample policy line 217 mcts : [0.026 0.564 0.205 0.128 0.077]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.830478227169756
printing an ep nov before normalisation:  24.55993329355721
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.73276075047408
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8849059
printing an ep nov before normalisation:  45.04329924861235
using explorer policy with actor:  1
printing an ep nov before normalisation:  56.61535502636364
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
line 256 mcts: sample exp_bonus 42.8921730741232
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.62408787097913
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  44.71636791271801
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.13 ]
 [47.348]
 [47.348]
 [42.805]
 [47.348]] [[1.576]
 [1.587]
 [1.587]
 [1.347]
 [1.587]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 33.64364976440735
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9953,     0.0003,     0.0023,     0.0005,     0.0016],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9951,     0.0002,     0.0040,     0.0006],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0005,     0.9087,     0.0239,     0.0668],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0002,     0.0607,     0.6476,     0.2914],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0002,     0.0005,     0.0858,     0.2950,     0.6185],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88882303
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.165]
 [34.307]
 [37.513]
 [36.827]
 [36.751]] [[0.889]
 [1.042]
 [1.27 ]
 [1.221]
 [1.215]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.16 ]
 [33.16 ]
 [46.093]
 [33.16 ]
 [33.16 ]] [[0.603]
 [0.603]
 [1.427]
 [0.603]
 [0.603]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.235]
 [41.235]
 [41.235]
 [41.235]
 [41.235]] [[1.308]
 [1.308]
 [1.308]
 [1.308]
 [1.308]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.1138565569652
printing an ep nov before normalisation:  55.239227216284064
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.03421769823347
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.7341046333313
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.76757049560547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0001,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0013,     0.9623,     0.0014,     0.0001,     0.0349],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0003,     0.0009,     0.8167,     0.0789,     0.1033],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0004,     0.0605,     0.7395,     0.1992],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0275, 0.0184, 0.1052, 0.3138, 0.5351], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.772366137417556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.77 ]
 [45.335]
 [44.845]
 [43.631]
 [43.343]] [[1.229]
 [1.536]
 [1.503]
 [1.421]
 [1.402]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.693]
 [43.945]
 [44.694]
 [46.46 ]
 [46.46 ]] [[0.578]
 [0.364]
 [0.375]
 [0.4  ]
 [0.4  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.67410620280069
printing an ep nov before normalisation:  21.199081785263537
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8857027
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.403781414031982
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.44336123088393
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  0.0003450763093345207
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.663]
 [37.663]
 [37.663]
 [37.663]
 [37.663]] [[75.326]
 [75.326]
 [75.326]
 [75.326]
 [75.326]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8752553
printing an ep nov before normalisation:  47.34075738507542
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.80535551760501
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.046]
 [41.046]
 [41.046]
 [41.046]
 [41.046]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.182]
 [40.175]
 [40.175]
 [42.617]
 [40.175]] [[1.783]
 [1.498]
 [1.498]
 [1.672]
 [1.498]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.03214224461618
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.39553753599933
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.82372802401678
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.13959552710395
printing an ep nov before normalisation:  41.11888885498047
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 54.5435876218044
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.17 ]
 [38.318]
 [46.558]
 [47.882]
 [41.141]] [[1.103]
 [1.057]
 [1.502]
 [1.573]
 [1.21 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 27.087183748103907
printing an ep nov before normalisation:  36.53099253134863
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.013]
 [40.931]
 [40.931]
 [41.424]
 [40.931]] [[1.904]
 [1.758]
 [1.758]
 [1.792]
 [1.758]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.239]
 [26.239]
 [26.239]
 [26.239]
 [26.066]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.534]
 [43.152]
 [35.534]
 [35.534]
 [35.534]] [[1.367]
 [1.899]
 [1.367]
 [1.367]
 [1.367]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.01677418561082
actions average: 
K:  1  action  0 :  tensor([    0.9986,     0.0001,     0.0000,     0.0004,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9976,     0.0005,     0.0014,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0002,     0.8616,     0.0379,     0.1002],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0003,     0.0223,     0.7835,     0.1938],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0010, 0.0015, 0.0740, 0.3387, 0.5847], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  43.91914284761682
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.772]
 [41.772]
 [41.772]
 [41.772]
 [41.772]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
printing an ep nov before normalisation:  34.94546439926065
printing an ep nov before normalisation:  36.600512372600775
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.59951244371661
siam score:  -0.88058627
printing an ep nov before normalisation:  31.373242755194607
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.80297660827637
printing an ep nov before normalisation:  40.33013469531348
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.436332048354025
printing an ep nov before normalisation:  52.60159990607228
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  61.21110374542102
printing an ep nov before normalisation:  41.03412968434291
printing an ep nov before normalisation:  39.21170198593917
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9980,     0.0001,     0.0000,     0.0001,     0.0018],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9951,     0.0001,     0.0001,     0.0046],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9205,     0.0420,     0.0374],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0007, 0.0011, 0.1087, 0.6298, 0.2598], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0013, 0.0009, 0.0689, 0.2736, 0.6553], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.184]
 [41.184]
 [43.174]
 [42.807]
 [44.273]] [[0.585]
 [0.585]
 [0.63 ]
 [0.622]
 [0.656]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9824,     0.0021,     0.0038,     0.0008,     0.0109],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9985,     0.0002,     0.0003,     0.0009],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.8983,     0.0428,     0.0589],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0009,     0.0004,     0.0219,     0.7740,     0.2028],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0011, 0.0044, 0.1004, 0.2383, 0.6559], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.332667118778026
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8814899
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.007651508958304021
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.671]
 [47.081]
 [47.081]
 [47.081]
 [47.081]] [[1.777]
 [1.4  ]
 [1.4  ]
 [1.4  ]
 [1.4  ]]
printing an ep nov before normalisation:  45.55357478050104
printing an ep nov before normalisation:  54.68054547610688
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.766]
 [40.892]
 [36.566]
 [40.391]
 [41.705]] [[1.305]
 [1.375]
 [1.105]
 [1.344]
 [1.426]]
printing an ep nov before normalisation:  37.44363784790039
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  4  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0011,     0.9980,     0.0002,     0.0001,     0.0006],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0003,     0.8187,     0.0896,     0.0912],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0002,     0.0777,     0.7553,     0.1663],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0479, 0.0018, 0.1286, 0.3439, 0.4779], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.506551853795386
siam score:  -0.88156646
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.274]
 [36.377]
 [36.601]
 [32.734]
 [34.924]] [[1.497]
 [1.729]
 [1.746]
 [1.457]
 [1.621]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  37.145777050595
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.969]
 [21.969]
 [23.901]
 [21.969]
 [22.873]] [[1.276]
 [1.276]
 [1.514]
 [1.276]
 [1.388]]
printing an ep nov before normalisation:  37.37260913209784
printing an ep nov before normalisation:  59.141697146740796
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.40211971728588
printing an ep nov before normalisation:  37.57435679544055
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.95099776312961
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.278]
 [39.903]
 [31.485]
 [30.18 ]
 [33.494]] [[1.2  ]
 [1.132]
 [0.719]
 [0.655]
 [0.817]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.274]
 [23.2  ]
 [28.514]
 [37.762]
 [30.205]] [[0.571]
 [0.617]
 [0.876]
 [1.328]
 [0.959]]
printing an ep nov before normalisation:  40.77505388034057
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.41369742427043
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.901]
 [32.901]
 [ 0.192]
 [ 0.169]
 [ 0.186]] [[0.745]
 [0.745]
 [0.004]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8764986
printing an ep nov before normalisation:  68.48685544631054
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9989,     0.0001,     0.0000,     0.0003,     0.0007],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0015,     0.9689,     0.0140,     0.0008,     0.0149],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0002,     0.9147,     0.0135,     0.0715],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0009,     0.0005,     0.1287,     0.5799,     0.2898],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0034, 0.0280, 0.1620, 0.2015, 0.6051], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.265]
 [53.265]
 [53.265]
 [53.265]
 [53.265]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0009948867773346137
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.39902615667717
UNIT TEST: sample policy line 217 mcts : [0.026 0.179 0.308 0.256 0.231]
printing an ep nov before normalisation:  48.96929740905762
printing an ep nov before normalisation:  69.16089942141593
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.1  ]
 [40.1  ]
 [64.073]
 [40.1  ]
 [40.1  ]] [[0.371]
 [0.371]
 [0.667]
 [0.371]
 [0.371]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.268313801109635
printing an ep nov before normalisation:  24.194817543029785
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.64566206103562
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.76448901871091
printing an ep nov before normalisation:  33.49488386606857
printing an ep nov before normalisation:  43.78033433740254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88115466
printing an ep nov before normalisation:  26.133935202584762
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.88875737593837
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.03896513316891
printing an ep nov before normalisation:  49.80051500335063
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.79618073077264
printing an ep nov before normalisation:  45.723692295832144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.718]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[ 0.471]
 [-0.253]
 [-0.253]
 [-0.253]
 [-0.253]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.005]
 [50.005]
 [47.742]
 [46.863]
 [50.005]] [[1.667]
 [1.667]
 [1.54 ]
 [1.49 ]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.869043535527666
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.740678758933676
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.55747985839844
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.41405506422372
printing an ep nov before normalisation:  76.76760555374977
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.261]
 [45.261]
 [64.977]
 [45.261]
 [45.261]] [[0.311]
 [0.311]
 [0.529]
 [0.311]
 [0.311]]
actions average: 
K:  2  action  0 :  tensor([    0.9897,     0.0002,     0.0000,     0.0050,     0.0051],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0037, 0.9468, 0.0112, 0.0022, 0.0361], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0002,     0.8696,     0.0692,     0.0610],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0068, 0.0019, 0.0304, 0.8177, 0.1432], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0170, 0.0106, 0.1070, 0.2816, 0.5839], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.818852278528155
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.79179382324219
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.5045175276174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.033066071725592
printing an ep nov before normalisation:  18.811926809708343
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.187]
 [30.187]
 [30.187]
 [30.187]
 [30.187]] [[0.308]
 [0.308]
 [0.308]
 [0.308]
 [0.308]]
printing an ep nov before normalisation:  50.506882667541504
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 -6.703133187800656e-12
0.0 -2.6812532718981825e-12
0.0 -1.1719671574802263e-11
0.0 0.0
0.0 0.0
0.0 -5.232768489353173e-12
0.0 -6.089039696848332e-12
0.0 -1.982397584052569e-11
0.0 -1.9676939372594053e-11
0.0 -6.53879831423439e-12
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.908864700512357
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.62280874231602
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.09160872374671
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.291]
 [22.109]
 [22.951]
 [34.239]
 [23.606]] [[0.383]
 [0.338]
 [0.37 ]
 [0.8  ]
 [0.395]]
siam score:  -0.8813191
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.35410465937853
printing an ep nov before normalisation:  33.13640827161611
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0014030020247446373
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.133]
 [25.133]
 [25.133]
 [25.133]
 [25.133]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.27412613637992
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.646524906158447
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.72501374315996
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.325340573851964
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.834]
 [39.037]
 [32.479]
 [37.899]
 [35.439]] [[0.393]
 [0.329]
 [0.217]
 [0.309]
 [0.267]]
printing an ep nov before normalisation:  42.0223041826903
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.688]
 [25.896]
 [30.314]
 [35.521]
 [31.265]] [[0.295]
 [0.254]
 [0.354]
 [0.471]
 [0.375]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.03076934814453
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.98408972388151
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.616]
 [45.616]
 [45.616]
 [45.616]
 [45.616]] [[1.246]
 [1.246]
 [1.246]
 [1.246]
 [1.246]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.037]
 [28.322]
 [28.322]
 [28.322]
 [28.322]] [[1.134]
 [0.654]
 [0.654]
 [0.654]
 [0.654]]
siam score:  -0.88211524
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.46193147269877
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.12022227758176
printing an ep nov before normalisation:  27.829132473764595
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  46.31806449614427
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.285]
 [38.508]
 [38.508]
 [38.508]
 [38.508]] [[1.466]
 [1.274]
 [1.274]
 [1.274]
 [1.274]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0006718787346926547
printing an ep nov before normalisation:  40.75280598231725
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.062]
 [35.508]
 [38.183]
 [38.435]
 [39.428]] [[0.236]
 [0.229]
 [0.264]
 [0.267]
 [0.28 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.335]
 [24.844]
 [22.946]
 [23.355]
 [22.853]] [[0.119]
 [0.071]
 [0.061]
 [0.063]
 [0.06 ]]
printing an ep nov before normalisation:  92.3378612209964
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.0460952387352
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.08260128229554
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.07062943630002
printing an ep nov before normalisation:  38.54907512664795
printing an ep nov before normalisation:  24.46395049351316
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.033998963401736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9965,     0.0004,     0.0007,     0.0012,     0.0012],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9996,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9207,     0.0289,     0.0503],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0008,     0.0005,     0.0690,     0.6816,     0.2480],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0046, 0.0382, 0.0843, 0.2841, 0.5887], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.773460839386384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.19607721383158
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.223]
 [40.223]
 [40.223]
 [40.223]
 [40.223]] [[1.083]
 [1.083]
 [1.083]
 [1.083]
 [1.083]]
printing an ep nov before normalisation:  92.25500159053678
printing an ep nov before normalisation:  50.287551876831444
actions average: 
K:  0  action  0 :  tensor([    0.9986,     0.0001,     0.0009,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0010,     0.9856,     0.0000,     0.0001,     0.0132],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0015,     0.0004,     0.8810,     0.0519,     0.0652],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0007,     0.0002,     0.0947,     0.6424,     0.2620],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0017, 0.0084, 0.0507, 0.2837, 0.6554], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.115]
 [31.202]
 [34.023]
 [24.65 ]
 [20.342]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  30.861123058424777
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8774437
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.44318094230215
printing an ep nov before normalisation:  31.645452044622626
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88232666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.195856668632814
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  36.44028370330412
siam score:  -0.88323885
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.6407721794285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8836258
siam score:  -0.88384265
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.6383943117797
printing an ep nov before normalisation:  38.8898369846413
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.75196028440223
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.54]
 [38.54]
 [38.54]
 [38.54]
 [38.54]] [[1.199]
 [1.199]
 [1.199]
 [1.199]
 [1.199]]
siam score:  -0.8823465
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  22.482283022256787
printing an ep nov before normalisation:  41.3341415508598
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.282 0.128 0.282 0.154 0.154]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.471]
 [39.639]
 [43.915]
 [34.139]
 [37.451]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.93515224806915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.168829235742034
printing an ep nov before normalisation:  27.658847155795467
siam score:  -0.87811416
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  47.21212296857433
siam score:  -0.87844765
siam score:  -0.8780582
printing an ep nov before normalisation:  32.07671880722046
printing an ep nov before normalisation:  59.05003428281034
printing an ep nov before normalisation:  49.101664561545014
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.56922654004299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.80855452039483
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 27.67471857474422
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.35478190717607
siam score:  -0.8751961
actions average: 
K:  3  action  0 :  tensor([0.9780, 0.0040, 0.0010, 0.0031, 0.0138], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9983,     0.0001,     0.0006,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0006,     0.0109,     0.8652,     0.0460,     0.0773],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0015,     0.0821,     0.7404,     0.1759],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0017, 0.0060, 0.0776, 0.1993, 0.7155], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.870714955681244
actions average: 
K:  4  action  0 :  tensor([    0.9990,     0.0002,     0.0000,     0.0002,     0.0007],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9981,     0.0010,     0.0001,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0002,     0.9042,     0.0458,     0.0497],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0008,     0.0825,     0.6681,     0.2482],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0016, 0.0040, 0.0538, 0.2299, 0.7107], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  34.36114460450216
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.77960909379033
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.697429263778076
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.592]
 [33.101]
 [42.453]
 [35.1  ]
 [37.702]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.107794626828923
printing an ep nov before normalisation:  27.21989002218907
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.35596442222595
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.568106515066965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.715]
 [40.313]
 [31.715]
 [34.321]
 [35.768]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.13922378968356
printing an ep nov before normalisation:  43.56957816033017
printing an ep nov before normalisation:  0.0024429775271528342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.60988472942473
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.867]
 [52.867]
 [62.885]
 [52.867]
 [52.867]] [[0.771]
 [0.771]
 [1.   ]
 [0.771]
 [0.771]]
printing an ep nov before normalisation:  46.985821913832716
printing an ep nov before normalisation:  46.09069358300252
printing an ep nov before normalisation:  47.672032181287946
printing an ep nov before normalisation:  40.546784642385454
printing an ep nov before normalisation:  37.179942901524946
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.026 0.154 0.359 0.231 0.231]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.647]
 [36.647]
 [36.647]
 [36.647]
 [36.647]] [[0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.897]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.54096256799575
printing an ep nov before normalisation:  48.80167371513075
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.15277671813965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  57.160307016130034
printing an ep nov before normalisation:  39.23876026319304
printing an ep nov before normalisation:  44.33282334064332
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.1268025616314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  58.36244923021607
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.032]
 [51.032]
 [60.367]
 [51.032]
 [51.032]] [[1.045]
 [1.045]
 [1.369]
 [1.045]
 [1.045]]
siam score:  -0.88319886
printing an ep nov before normalisation:  32.32234001159668
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.565]
 [28.538]
 [32.948]
 [32.454]
 [32.864]] [[1.265]
 [1.178]
 [1.549]
 [1.507]
 [1.542]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.041725158691406
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.465341343486465
printing an ep nov before normalisation:  47.33862107972185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.56472635269166
printing an ep nov before normalisation:  49.257461290416195
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.077040672302246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.330952809336985
Starting evaluation
printing an ep nov before normalisation:  28.988116979599003
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  43.927679749834134
printing an ep nov before normalisation:  39.04361204645393
printing an ep nov before normalisation:  26.880333423614502
siam score:  -0.88922304
printing an ep nov before normalisation:  4.952471840624639e-05
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.747]
 [26.747]
 [26.747]
 [26.747]
 [26.747]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  20.393469699383783
printing an ep nov before normalisation:  46.451950612116924
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.3208974132337
printing an ep nov before normalisation:  47.09747411780475
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.72177708032027
printing an ep nov before normalisation:  52.81902102683876
printing an ep nov before normalisation:  61.20628078643133
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.69961288769663
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.08611702624489
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.246]
 [36.51 ]
 [40.401]
 [34.655]
 [33.455]] [[0.305]
 [0.372]
 [0.451]
 [0.334]
 [0.309]]
printing an ep nov before normalisation:  38.04107666015625
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.621]
 [29.621]
 [29.621]
 [30.936]
 [28.743]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.129150685535
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.13529580262286
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.982]
 [38.047]
 [37.914]
 [34.81 ]
 [35.48 ]] [[1.001]
 [1.242]
 [1.234]
 [1.05 ]
 [1.09 ]]
printing an ep nov before normalisation:  30.0736403465271
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.07606441283662946
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8784349
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.138]
 [58.138]
 [55.808]
 [55.317]
 [58.138]] [[1.922]
 [1.922]
 [1.815]
 [1.792]
 [1.922]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.854881540873635
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.77965616437334
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 41.5512924686943
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.02397204574377
printing an ep nov before normalisation:  31.485938924129083
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  18.604361466859082
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.577]
 [60.644]
 [55.474]
 [60.613]
 [59.799]] [[1.238]
 [1.834]
 [1.654]
 [1.833]
 [1.805]]
line 256 mcts: sample exp_bonus 36.9388330899615
printing an ep nov before normalisation:  43.933845287373344
printing an ep nov before normalisation:  28.281614518789517
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.52834497201435
printing an ep nov before normalisation:  53.92429667788306
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.834523352072964
printing an ep nov before normalisation:  47.2352104632932
printing an ep nov before normalisation:  41.18842309110385
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.851]
 [42.851]
 [57.427]
 [42.851]
 [42.851]] [[0.156]
 [0.156]
 [0.264]
 [0.156]
 [0.156]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.233]
 [31.81 ]
 [34.571]
 [34.913]
 [34.473]] [[1.322]
 [1.362]
 [1.553]
 [1.576]
 [1.546]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.542]
 [27.054]
 [36.396]
 [40.832]
 [37.06 ]] [[0.734]
 [0.483]
 [0.911]
 [1.114]
 [0.941]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.353]
 [42.353]
 [42.353]
 [42.353]
 [40.926]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 51.54825060594023
actions average: 
K:  2  action  0 :  tensor([    0.9971,     0.0005,     0.0000,     0.0001,     0.0022],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0013,     0.9661,     0.0002,     0.0048,     0.0275],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0005,     0.0010,     0.8679,     0.0587,     0.0718],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0019,     0.0002,     0.0577,     0.7522,     0.1880],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0046, 0.0066, 0.1558, 0.2543, 0.5787], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  45.08262634277344
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.947]
 [39.477]
 [38.256]
 [36.498]
 [36.384]] [[0.18 ]
 [0.257]
 [0.243]
 [0.222]
 [0.221]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.657]
 [47.657]
 [47.657]
 [55.97 ]
 [47.657]] [[0.605]
 [0.605]
 [0.605]
 [0.786]
 [0.605]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.30987615190753
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.48919995036745
printing an ep nov before normalisation:  41.7057101350009
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.567]
 [58.567]
 [58.567]
 [58.567]
 [58.567]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.556212826607705
printing an ep nov before normalisation:  51.77460281453472
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.818056432285275
printing an ep nov before normalisation:  38.39121316010507
siam score:  -0.87852967
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.801]
 [31.808]
 [34.618]
 [36.063]
 [36.883]] [[0.87 ]
 [0.722]
 [0.861]
 [0.932]
 [0.972]]
printing an ep nov before normalisation:  38.57061106363209
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9990,     0.0006,     0.0001,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9996,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0000,     0.9459,     0.0168,     0.0371],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0002,     0.0572,     0.6751,     0.2670],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0013, 0.0011, 0.1164, 0.2786, 0.6027], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  30.268841693115494
printing an ep nov before normalisation:  31.406760215759277
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.337041610173365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.009890909580275
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.77205600744636
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.016344831211313
printing an ep nov before normalisation:  51.18861275194653
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.975]
 [46.975]
 [46.975]
 [46.975]
 [46.975]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  43.76178323972
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.49666951775878
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.22555019700397
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88677245
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.7  ]
 [27.102]
 [22.7  ]
 [20.897]
 [23.406]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  1  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0003,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9930,     0.0000,     0.0063,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0005,     0.0277,     0.9150,     0.0265,     0.0302],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0041,     0.0006,     0.0779,     0.6986,     0.2189],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0035, 0.0027, 0.1533, 0.1970, 0.6435], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  56.581809436813316
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.18513523706044
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.817]
 [40.648]
 [35.724]
 [42.663]
 [40.488]] [[1.371]
 [1.202]
 [0.941]
 [1.309]
 [1.194]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9398,     0.0122,     0.0001,     0.0012,     0.0467],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9956,     0.0001,     0.0010,     0.0031],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0003,     0.8605,     0.0570,     0.0820],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0005,     0.0003,     0.0352,     0.7661,     0.1978],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0012, 0.0010, 0.0465, 0.3215, 0.6299], grad_fn=<DivBackward0>)
siam score:  -0.87964475
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.11495304107666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.08357797881261
printing an ep nov before normalisation:  0.0002907009621821999
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87730026
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.710392075660636
actions average: 
K:  3  action  0 :  tensor([    0.9851,     0.0087,     0.0000,     0.0011,     0.0050],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0019, 0.9562, 0.0014, 0.0011, 0.0393], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9171,     0.0426,     0.0402],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0015,     0.0509,     0.7341,     0.2133],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0114, 0.0020, 0.1497, 0.2248, 0.6121], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.56072807312012
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.81544494628906
printing an ep nov before normalisation:  34.379049224342424
printing an ep nov before normalisation:  46.42822341649096
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8820195
printing an ep nov before normalisation:  48.62856509636118
printing an ep nov before normalisation:  88.38608748033597
printing an ep nov before normalisation:  52.64657455147234
line 256 mcts: sample exp_bonus 34.884467611371946
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.531]
 [39.797]
 [35.531]
 [35.531]
 [34.77 ]] [[0.879]
 [1.066]
 [0.879]
 [0.879]
 [0.846]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8830931
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.623]
 [29.385]
 [29.385]
 [29.385]
 [29.385]] [[0.752]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]]
actions average: 
K:  3  action  0 :  tensor([    0.9880,     0.0001,     0.0000,     0.0005,     0.0114],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0004,     0.9943,     0.0004,     0.0009,     0.0040],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0022,     0.0001,     0.9119,     0.0444,     0.0414],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0216,     0.0626,     0.7488,     0.1668],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0017, 0.0045, 0.2065, 0.2152, 0.5721], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.041233428369424
printing an ep nov before normalisation:  35.68109375632448
printing an ep nov before normalisation:  37.38925749257678
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.488]
 [47.488]
 [47.488]
 [47.488]
 [47.488]] [[1.548]
 [1.548]
 [1.548]
 [1.548]
 [1.548]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.01145514434734
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.929]
 [41.483]
 [39.032]
 [40.259]
 [40.3  ]] [[1.398]
 [1.37 ]
 [1.218]
 [1.294]
 [1.297]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.20289889709664
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.    0.41  0.564 0.026 0.   ]
printing an ep nov before normalisation:  32.132124110247375
printing an ep nov before normalisation:  46.88139767338051
UNIT TEST: sample policy line 217 mcts : [0.051 0.103 0.359 0.154 0.333]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8867787
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  40.91540477448882
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.19656357066313
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.701]
 [32.788]
 [35.032]
 [26.155]
 [33.394]] [[0.421]
 [0.602]
 [0.669]
 [0.404]
 [0.62 ]]
siam score:  -0.8766256
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.712]
 [43.686]
 [43.525]
 [43.686]
 [43.686]] [[1.375]
 [1.085]
 [1.077]
 [1.085]
 [1.085]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.27457709720265
actions average: 
K:  2  action  0 :  tensor([    0.9583,     0.0047,     0.0004,     0.0210,     0.0156],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9883,     0.0002,     0.0005,     0.0108],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0002,     0.9395,     0.0227,     0.0376],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0005,     0.0027,     0.0884,     0.6460,     0.2625],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0007, 0.0014, 0.1116, 0.2384, 0.6479], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.853803343924035
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87708545
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.1205054419108
printing an ep nov before normalisation:  49.070405941585854
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.586649417877197
siam score:  -0.87783384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 35.353618091042506
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  48.033699040766614
printing an ep nov before normalisation:  32.84252643585205
printing an ep nov before normalisation:  62.16427943894119
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.131797634239547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88104784
printing an ep nov before normalisation:  48.07052512462816
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.8153704359602
printing an ep nov before normalisation:  33.692163364057464
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.644557550712065
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.434]
 [33.434]
 [56.217]
 [37.053]
 [34.904]] [[0.238]
 [0.238]
 [0.492]
 [0.278]
 [0.254]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.569]
 [25.973]
 [25.973]
 [26.618]
 [25.263]] [[0.353]
 [0.147]
 [0.147]
 [0.154]
 [0.138]]
printing an ep nov before normalisation:  69.1178662484852
printing an ep nov before normalisation:  43.84445762291243
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.17 ]
 [51.17 ]
 [50.379]
 [52.397]
 [51.17 ]] [[1.605]
 [1.605]
 [1.566]
 [1.666]
 [1.605]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00015755396987060524
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.07057940994247
using explorer policy with actor:  1
siam score:  -0.8832292
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.50828837985408
printing an ep nov before normalisation:  76.24754372134474
printing an ep nov before normalisation:  26.860824839602454
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.746]
 [61.133]
 [61.133]
 [61.133]
 [61.133]] [[0.899]
 [0.627]
 [0.627]
 [0.627]
 [0.627]]
printing an ep nov before normalisation:  42.706469633298845
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.885695771900515
printing an ep nov before normalisation:  43.25928333497231
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 29.608436944870185
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.427]
 [27.427]
 [53.648]
 [27.427]
 [27.427]] [[0.297]
 [0.297]
 [0.839]
 [0.297]
 [0.297]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9936,     0.0000,     0.0000,     0.0031,     0.0033],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0004,     0.9977,     0.0001,     0.0015,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0002,     0.8347,     0.0757,     0.0894],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0014,     0.0973,     0.6690,     0.2321],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0061, 0.0257, 0.1838, 0.2285, 0.5559], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.708]
 [42.568]
 [42.068]
 [37.595]
 [37.715]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  48.419288558541936
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.038]
 [48.832]
 [48.832]
 [48.832]
 [48.832]] [[1.889]
 [1.651]
 [1.651]
 [1.651]
 [1.651]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.816]
 [31.292]
 [31.292]
 [31.292]
 [31.292]] [[1.413]
 [0.622]
 [0.622]
 [0.622]
 [0.622]]
printing an ep nov before normalisation:  39.45293188095093
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.66082870622844
siam score:  -0.8841884
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.10210653917877
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.03342075045051
printing an ep nov before normalisation:  47.70975931296529
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  95.08242288438899
printing an ep nov before normalisation:  7.338391583289194e-06
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.18527546088202
siam score:  -0.8695389
printing an ep nov before normalisation:  23.125713212149485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.473617553710938
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.184245109558105
line 256 mcts: sample exp_bonus 50.064590812127946
printing an ep nov before normalisation:  31.84943553172471
siam score:  -0.8715989
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.88 ]
 [37.396]
 [30.241]
 [29.322]
 [31.634]] [[0.346]
 [0.271]
 [0.188]
 [0.177]
 [0.204]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.792]
 [48.135]
 [49.647]
 [52.755]
 [50.071]] [[0.972]
 [1.088]
 [1.14 ]
 [1.248]
 [1.155]]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.87207353
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.525]
 [39.525]
 [ 0.   ]
 [39.525]
 [39.525]] [[0.923]
 [0.923]
 [0.   ]
 [0.923]
 [0.923]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 55.34597993168685
printing an ep nov before normalisation:  60.846820576749
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.189800199524825
printing an ep nov before normalisation:  33.694851280882716
printing an ep nov before normalisation:  42.68769308569041
printing an ep nov before normalisation:  25.930468515249547
printing an ep nov before normalisation:  52.600649057552076
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.05477102696972
printing an ep nov before normalisation:  31.531636714935303
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 26.925726044530492
printing an ep nov before normalisation:  46.91177191268794
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.219]
 [31.544]
 [21.692]
 [31.544]
 [31.544]] [[0.584]
 [0.313]
 [0.118]
 [0.313]
 [0.313]]
printing an ep nov before normalisation:  40.12330783520005
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.16753399635229
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.09821796172427
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.05613747544093
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.75 ]
 [79.75 ]
 [81.813]
 [81.453]
 [84.025]] [[1.23 ]
 [1.23 ]
 [1.266]
 [1.26 ]
 [1.305]]
printing an ep nov before normalisation:  46.852559127090736
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.52]
 [58.52]
 [58.52]
 [58.52]
 [58.52]] [[1.269]
 [1.269]
 [1.269]
 [1.269]
 [1.269]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.90842286321683
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.397]
 [30.906]
 [37.19 ]
 [32.03 ]
 [35.049]] [[0.65 ]
 [0.672]
 [0.938]
 [0.719]
 [0.847]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.125]
 [25.053]
 [30.532]
 [28.61 ]
 [29.543]] [[0.788]
 [0.555]
 [0.869]
 [0.759]
 [0.812]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.732083164874396
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.08462865592758
printing an ep nov before normalisation:  42.030278071966784
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9993,     0.0000,     0.0001,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0005,     0.9620,     0.0006,     0.0009,     0.0360],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0028,     0.0001,     0.9128,     0.0382,     0.0462],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0003,     0.1679,     0.6128,     0.2188],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0006,     0.0002,     0.2217,     0.3336,     0.4439],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  43.33334895774491
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.005597561970915876
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.66955996081384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 34.970004365802126
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.22798442840576
printing an ep nov before normalisation:  44.852944863984575
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.45741223458339
siam score:  -0.8793321
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  49.172306060791016
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.07435583931913
printing an ep nov before normalisation:  65.2849976383284
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.491]
 [29.617]
 [29.617]
 [29.617]
 [29.617]] [[1.667]
 [1.398]
 [1.398]
 [1.398]
 [1.398]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.888]
 [38.888]
 [44.161]
 [38.888]
 [38.888]] [[1.152]
 [1.152]
 [1.473]
 [1.152]
 [1.152]]
printing an ep nov before normalisation:  55.90335352161962
Printing some Q and Qe and total Qs values:  [[1.5]
 [0. ]
 [1.5]
 [1.5]
 [1.5]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[1.5]
 [0. ]
 [1.5]
 [1.5]
 [1.5]]
siam score:  -0.8748088
printing an ep nov before normalisation:  40.74078678403425
line 256 mcts: sample exp_bonus 37.34467570215048
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.903]
 [38.491]
 [38.491]
 [40.854]
 [38.491]] [[1.519]
 [1.406]
 [1.406]
 [1.596]
 [1.406]]
UNIT TEST: sample policy line 217 mcts : [0.282 0.103 0.051 0.538 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9988,     0.0000,     0.0000,     0.0005,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0007,     0.9721,     0.0012,     0.0012,     0.0248],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9383,     0.0357,     0.0259],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0023,     0.0003,     0.0782,     0.6927,     0.2265],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0040, 0.0024, 0.0941, 0.1821, 0.7174], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.883]
 [44.159]
 [44.676]
 [46.883]
 [46.883]] [[1.95 ]
 [1.736]
 [1.776]
 [1.95 ]
 [1.95 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.434]
 [35.434]
 [35.434]
 [35.434]
 [35.434]] [[70.869]
 [70.869]
 [70.869]
 [70.869]
 [70.869]]
printing an ep nov before normalisation:  40.34071445465088
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.7  ]
 [44.394]
 [46.749]
 [46.685]
 [47.803]] [[1.261]
 [1.38 ]
 [1.544]
 [1.54 ]
 [1.618]]
printing an ep nov before normalisation:  59.14574944260799
siam score:  -0.8794929
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.167]
 [35.65 ]
 [41.425]
 [35.165]
 [33.895]] [[0.608]
 [0.74 ]
 [0.958]
 [0.721]
 [0.673]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.666]
 [34.666]
 [33.755]
 [34.666]
 [34.666]] [[1.551]
 [1.551]
 [1.483]
 [1.551]
 [1.551]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([    0.9963,     0.0006,     0.0002,     0.0007,     0.0022],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9976,     0.0007,     0.0009,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0002,     0.8415,     0.0548,     0.1033],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0004,     0.0219,     0.6722,     0.3051],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0005,     0.0021,     0.1002,     0.2759,     0.6214],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  38.09620374896265
printing an ep nov before normalisation:  39.28791246490738
printing an ep nov before normalisation:  35.366694409037414
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 55.75926363345536
printing an ep nov before normalisation:  37.86963422185684
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.22048105155127
printing an ep nov before normalisation:  33.75573396682739
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.14164025379127
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8879678
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  44.64040279388428
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.647]
 [40.647]
 [49.849]
 [40.647]
 [40.647]] [[0.693]
 [0.693]
 [1.013]
 [0.693]
 [0.693]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.95857630182229
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.804]
 [39.567]
 [35.79 ]
 [38.955]
 [40.876]] [[0.72 ]
 [0.654]
 [0.543]
 [0.636]
 [0.693]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.83176715883678
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.5517725717506
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.488128755762716
printing an ep nov before normalisation:  48.271033293032225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87945724
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  105.3963635875458
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  1  action  0 :  tensor([    0.9898,     0.0000,     0.0007,     0.0054,     0.0040],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0007,     0.9634,     0.0033,     0.0182,     0.0145],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0017,     0.0002,     0.9050,     0.0474,     0.0456],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0012,     0.0006,     0.0494,     0.7578,     0.1910],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0129, 0.0055, 0.0383, 0.2838, 0.6596], grad_fn=<DivBackward0>)
Starting evaluation
printing an ep nov before normalisation:  22.393831978915895
printing an ep nov before normalisation:  19.200067860739573
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  17.307986220736577
siam score:  -0.8779648
UNIT TEST: sample policy line 217 mcts : [0.026 0.026 0.897 0.026 0.026]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.797]
 [41.797]
 [53.042]
 [41.797]
 [41.797]] [[0.709]
 [0.709]
 [1.   ]
 [0.709]
 [0.709]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.205]
 [30.7  ]
 [30.7  ]
 [30.7  ]
 [30.7  ]] [[0.667]
 [0.646]
 [0.646]
 [0.646]
 [0.646]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.012105189912745
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.44291543960571
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.97457739833367
printing an ep nov before normalisation:  38.97084732527559
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8823607
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.7791953086853
printing an ep nov before normalisation:  35.32438975132236
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.58000423769433
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.293922127420444
printing an ep nov before normalisation:  33.79112736514584
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.42 ]
 [30.42 ]
 [31.976]
 [31.281]
 [33.041]] [[1.441]
 [1.441]
 [1.582]
 [1.519]
 [1.678]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 1.3154401559531357e-09
0.0 2.3048399134454346e-09
0.0 1.3662628793452073e-09
0.0 1.1130487796107608e-09
0.0 1.533988245586492e-09
0.0 3.5458969139801963e-09
0.0 1.6505449202932086e-09
0.0 1.0327841653559047e-09
0.0 1.3662628793452073e-09
0.0 3.3561679724754785e-09
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.699]
 [39.611]
 [39.611]
 [39.611]
 [39.611]] [[0.993]
 [0.917]
 [0.917]
 [0.917]
 [0.917]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.691216269580146
printing an ep nov before normalisation:  32.74858280793658
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.172330364829826
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.151]
 [30.151]
 [30.151]
 [30.151]
 [30.151]] [[0.166]
 [0.166]
 [0.166]
 [0.166]
 [0.166]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.22326472313815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.63784299068395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.904327733411225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.54373265845308
printing an ep nov before normalisation:  46.176349020166974
printing an ep nov before normalisation:  46.37713460034278
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.002]
 [42.002]
 [38.595]
 [42.002]
 [45.02 ]] [[1.771]
 [1.771]
 [1.511]
 [1.771]
 [2.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.807]
 [37.22 ]
 [37.22 ]
 [40.081]
 [37.22 ]] [[1.733]
 [1.472]
 [1.472]
 [1.585]
 [1.472]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8783812
printing an ep nov before normalisation:  31.220228135704318
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.406]
 [45.406]
 [45.406]
 [45.406]
 [45.406]] [[0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]]
printing an ep nov before normalisation:  23.42641177451261
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  4.417478010054765e-06
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.738]
 [30.091]
 [29.314]
 [30.091]
 [30.091]] [[0.99 ]
 [0.703]
 [0.663]
 [0.703]
 [0.703]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.95598071886556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.028902053833008
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.22026824951172
printing an ep nov before normalisation:  32.27466344833374
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.2272555304892
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.94164952835112
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.045]
 [34.106]
 [27.011]
 [26.989]
 [26.989]] [[0.915]
 [0.712]
 [0.469]
 [0.468]
 [0.468]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.30981731414795
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.008452574404671509
printing an ep nov before normalisation:  55.04174144082274
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.584750712387148
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.734]
 [23.734]
 [23.734]
 [23.734]
 [23.734]] [[0.918]
 [0.918]
 [0.918]
 [0.918]
 [0.918]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.82123080374198
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00012170283298473805
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  3  action  0 :  tensor([    0.9971,     0.0009,     0.0003,     0.0003,     0.0014],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9994,     0.0001,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0003,     0.0001,     0.9374,     0.0124,     0.0499],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0006,     0.0370,     0.7966,     0.1655],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0017, 0.0009, 0.0036, 0.3338, 0.6600], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.8885881573565
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.72475725681416
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00015513446271597786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.589833577188067
printing an ep nov before normalisation:  28.288285732269287
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.735]
 [24.727]
 [35.347]
 [31.419]
 [33.902]] [[0.38 ]
 [0.135]
 [0.423]
 [0.317]
 [0.384]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.348]
 [32.69 ]
 [36.363]
 [35.939]
 [35.443]] [[0.548]
 [0.496]
 [0.611]
 [0.598]
 [0.582]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.91510260567404
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.521329371383935
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.532]
 [37.532]
 [ 0.   ]
 [ 0.   ]
 [37.532]] [[1.455]
 [1.455]
 [0.   ]
 [0.   ]
 [1.455]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.98076343536377
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.2346872602482
printing an ep nov before normalisation:  34.57799089271921
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.466389698655995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.566155132298455
printing an ep nov before normalisation:  49.27312680242405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.18675098552926
printing an ep nov before normalisation:  65.7589664151199
printing an ep nov before normalisation:  36.28777265548706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.364668119485565
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.517]
 [62.517]
 [62.517]
 [62.517]
 [62.517]] [[1.226]
 [1.226]
 [1.226]
 [1.226]
 [1.226]]
printing an ep nov before normalisation:  55.131256621567424
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.52747648691415
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.3513422741249
printing an ep nov before normalisation:  21.960507006259554
siam score:  -0.8824179
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  38.987239273739995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 52.17293739965878
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8820397
printing an ep nov before normalisation:  75.18063766525208
printing an ep nov before normalisation:  55.01485285374972
printing an ep nov before normalisation:  46.25741549676437
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.312]
 [52.298]
 [47.645]
 [47.645]
 [44.001]] [[1.643]
 [1.559]
 [1.365]
 [1.365]
 [1.213]]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9977,     0.0001,     0.0020,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9249,     0.0359,     0.0392],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0024, 0.0062, 0.0256, 0.7241, 0.2416], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0026, 0.0028, 0.0237, 0.2934, 0.6775], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.395]
 [39.221]
 [39.221]
 [39.221]
 [39.221]] [[1.647]
 [1.436]
 [1.436]
 [1.436]
 [1.436]]
printing an ep nov before normalisation:  36.46158218383789
siam score:  -0.87920415
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.089]
 [38.089]
 [38.089]
 [38.089]
 [38.089]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
siam score:  -0.88027745
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.364]
 [34.63 ]
 [41.499]
 [44.018]
 [35.389]] [[0.814]
 [0.55 ]
 [0.758]
 [0.834]
 [0.573]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.429]
 [39.61 ]
 [51.745]
 [43.442]
 [43.062]] [[0.661]
 [0.636]
 [1.008]
 [0.754]
 [0.742]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.982406257773725
printing an ep nov before normalisation:  47.280266195581724
printing an ep nov before normalisation:  39.8892264466138
printing an ep nov before normalisation:  32.13809602050076
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.23352726350127
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9955,     0.0007,     0.0001,     0.0017,     0.0021],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9977,     0.0006,     0.0001,     0.0014],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9457,     0.0247,     0.0295],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0008,     0.0004,     0.0320,     0.6890,     0.2778],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0007, 0.0006, 0.1208, 0.3156, 0.5624], grad_fn=<DivBackward0>)
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  0.031149904611993406
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.47184089436267
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.88032836
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.278]
 [46.278]
 [44.489]
 [45.429]
 [45.816]] [[1.667]
 [1.667]
 [1.571]
 [1.622]
 [1.642]]
siam score:  -0.8800452
printing an ep nov before normalisation:  36.16136249768974
printing an ep nov before normalisation:  39.49887350802969
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.379]
 [42.575]
 [42.987]
 [43.124]
 [41.81 ]] [[0.536]
 [0.768]
 [0.783]
 [0.788]
 [0.739]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.878]
 [42.878]
 [41.752]
 [42.878]
 [42.878]] [[0.893]
 [0.893]
 [0.851]
 [0.893]
 [0.893]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.57075322225243
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.652]
 [26.869]
 [32.652]
 [24.754]
 [26.682]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.697885434419675
printing an ep nov before normalisation:  37.222787312098916
printing an ep nov before normalisation:  38.808573597200194
line 256 mcts: sample exp_bonus 30.384494956460085
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.581221048443446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.06487884536986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.40416431427002
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.078]
 [32.347]
 [24.539]
 [23.729]
 [26.451]] [[0.558]
 [0.946]
 [0.718]
 [0.694]
 [0.774]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.61646181181319
line 256 mcts: sample exp_bonus 29.54428398923383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.000983988966254401
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.374159454892094
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00015294303068458248
UNIT TEST: sample policy line 217 mcts : [0.179 0.154 0.128 0.385 0.154]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 7.518]
 [15.555]
 [29.156]
 [14.382]
 [13.504]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.20748389813376
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88259614
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  7.929867251732503e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.195426704414842
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.508]
 [31.011]
 [27.198]
 [26.988]
 [27.924]] [[0.911]
 [0.671]
 [0.53 ]
 [0.522]
 [0.556]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.65578175644936
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.6909384727478
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.983563276950626
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.02 ]
 [39.847]
 [40.382]
 [42.197]
 [41.739]] [[1.798]
 [1.561]
 [1.601]
 [1.737]
 [1.702]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.892]
 [33.308]
 [38.348]
 [32.849]
 [33.357]] [[0.521]
 [0.599]
 [0.761]
 [0.584]
 [0.601]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.22762163491361
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.43225030072445
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  35.12828802697179
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.455244461169713
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.903]
 [33.566]
 [35.243]
 [35.045]
 [35.796]] [[1.461]
 [1.246]
 [1.354]
 [1.341]
 [1.39 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.35029836780396
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  75.70791728856837
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.007]
 [36.284]
 [34.181]
 [36.969]
 [34.579]] [[1.685]
 [1.628]
 [1.462]
 [1.682]
 [1.494]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.118]
 [34.118]
 [ 0.001]
 [ 0.   ]
 [34.118]] [[0.664]
 [0.664]
 [0.   ]
 [0.   ]
 [0.664]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8830127
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.777370636151762
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.800390697479905
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.90313398083035
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8823986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.73041095212218
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.50621803251858
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.86038158319777
printing an ep nov before normalisation:  64.7391853590483
printing an ep nov before normalisation:  52.0395528832197
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.78876490628836
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.865205764770508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.76547101001799
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.31011966578079
siam score:  -0.8813338
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.07314917846417
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.82718146484608
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.55263342661145
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9988,     0.0001,     0.0000,     0.0001,     0.0010],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9990,     0.0000,     0.0004,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0019, 0.0033, 0.9238, 0.0355, 0.0356], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0007,     0.0032,     0.0411,     0.7163,     0.2387],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0013, 0.0024, 0.1257, 0.2469, 0.6238], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.87598807
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.63544096822972
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.6175911348695
printing an ep nov before normalisation:  45.76470402261569
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.301599979400635
printing an ep nov before normalisation:  42.2515171931962
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.753]
 [30.972]
 [25.026]
 [30.972]
 [30.972]] [[0.995]
 [0.677]
 [0.462]
 [0.677]
 [0.677]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  3.7159921362217574e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.68514597342498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.19188795704425
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.550052642822266
printing an ep nov before normalisation:  52.78471970295027
printing an ep nov before normalisation:  49.54882592396519
printing an ep nov before normalisation:  41.22844457380058
siam score:  -0.87951016
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.266882540776173
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.39514595442859
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.6172772248358
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.01329030282497
printing an ep nov before normalisation:  41.65734557894001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.80490255355835
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.833974400035856
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.615]
 [29.367]
 [24.615]
 [24.615]
 [24.615]] [[0.849]
 [1.161]
 [0.849]
 [0.849]
 [0.849]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.797]
 [33.797]
 [33.797]
 [51.153]
 [33.797]] [[0.595]
 [0.595]
 [0.595]
 [1.192]
 [0.595]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.274]
 [39.937]
 [50.644]
 [50.847]
 [50.886]] [[1.194]
 [0.988]
 [1.4  ]
 [1.408]
 [1.41 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.81 ]
 [47.81 ]
 [47.81 ]
 [48.045]
 [47.81 ]] [[1.362]
 [1.362]
 [1.362]
 [1.374]
 [1.362]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.17402982711792
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.13906764984131
printing an ep nov before normalisation:  60.86150528213875
printing an ep nov before normalisation:  53.884010314941406
printing an ep nov before normalisation:  35.18853635279728
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.10163308916219
printing an ep nov before normalisation:  31.699691562674538
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.83119103459711
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88220996
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.877]
 [26.391]
 [41.107]
 [37.258]
 [28.176]] [[0.126]
 [0.172]
 [0.364]
 [0.313]
 [0.195]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.895846943995103
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9987,     0.0001,     0.0000,     0.0004,     0.0008],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9984,     0.0002,     0.0006,     0.0006],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0010,     0.8366,     0.0554,     0.1067],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0003,     0.0237,     0.7934,     0.1825],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0220, 0.0331, 0.1489, 0.2511, 0.5449], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.54611722861985
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.162]
 [24.459]
 [24.078]
 [24.946]
 [25.028]] [[0.238]
 [0.265]
 [0.257]
 [0.275]
 [0.277]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.418523744629006
printing an ep nov before normalisation:  29.30393913680387
printing an ep nov before normalisation:  37.69655887699295
printing an ep nov before normalisation:  29.34360688673015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.597734539104415
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.128 0.359 0.128 0.154 0.231]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.36720119644729
siam score:  -0.87961406
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.53580207205878
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.213]
 [38.213]
 [37.217]
 [37.601]
 [37.467]] [[0.936]
 [0.936]
 [0.89 ]
 [0.908]
 [0.902]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.71256900295846
actions average: 
K:  0  action  0 :  tensor([    0.9084,     0.0025,     0.0001,     0.0448,     0.0442],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0006,     0.9990,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0018, 0.0146, 0.8111, 0.0619, 0.1106], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0016,     0.0007,     0.0387,     0.7481,     0.2109],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0937, 0.0043, 0.0759, 0.2294, 0.5966], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  60.15221542982115
printing an ep nov before normalisation:  64.01193940547172
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.367]
 [30.875]
 [31.307]
 [35.37 ]
 [27.944]] [[0.439]
 [0.452]
 [0.463]
 [0.569]
 [0.376]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.8787172
printing an ep nov before normalisation:  33.18686759128286
printing an ep nov before normalisation:  35.02967834472656
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.88867668918636
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  42.39688279710922
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.19174773902596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.479]
 [35.336]
 [35.29 ]
 [33.968]
 [33.917]] [[0.933]
 [0.979]
 [0.976]
 [0.905]
 [0.902]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8860958
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.29217068360921
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.01111667918005
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.390320088716564
printing an ep nov before normalisation:  35.162758978983135
printing an ep nov before normalisation:  49.684197745499276
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.289]
 [33.844]
 [34.649]
 [36.876]
 [36.579]] [[0.779]
 [0.863]
 [0.906]
 [1.026]
 [1.01 ]]
printing an ep nov before normalisation:  31.382806788918742
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 27.060231116114103
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.05561994008462
printing an ep nov before normalisation:  57.62403970072904
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.98080923756156
printing an ep nov before normalisation:  47.19990033027416
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.77117078310147
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8711149
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.727760481027985
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0033298720649099778
printing an ep nov before normalisation:  57.47543770033442
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  0.04996425849128628
printing an ep nov before normalisation:  0.0003187609529220481
printing an ep nov before normalisation:  31.361549225583328
printing an ep nov before normalisation:  45.809621810913086
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.134]
 [22.674]
 [27.565]
 [28.299]
 [28.274]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  31.689884849609065
printing an ep nov before normalisation:  21.299854195763665
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.05074835809039
printing an ep nov before normalisation:  25.545480251312256
printing an ep nov before normalisation:  0.00016180834450096881
printing an ep nov before normalisation:  25.679009542265128
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.202165603637695
printing an ep nov before normalisation:  3.583704142329225e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.984]
 [38.984]
 [41.093]
 [38.984]
 [38.984]] [[1.453]
 [1.453]
 [1.603]
 [1.453]
 [1.453]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.026 0.128 0.308 0.308 0.231]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9962,     0.0004,     0.0001,     0.0016,     0.0017],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0007,     0.9685,     0.0101,     0.0001,     0.0206],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0000,     0.9245,     0.0345,     0.0410],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0008, 0.0017, 0.0243, 0.6144, 0.3589], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0014, 0.0242, 0.0687, 0.3762, 0.5295], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  29.107425212860107
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.794]
 [30.663]
 [29.797]
 [49.317]
 [30.699]] [[0.625]
 [0.285]
 [0.27 ]
 [0.616]
 [0.286]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.73534870147705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.997019962897305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([0.9641, 0.0026, 0.0017, 0.0128, 0.0187], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9996,     0.0001,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9997,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0002,     0.0644,     0.7317,     0.2036],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0001,     0.0006,     0.1563,     0.2622,     0.5808],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88021636
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.43045194386595
printing an ep nov before normalisation:  47.12161610392556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.33881459917341
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.87716174
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.449]
 [42.67 ]
 [47.102]
 [46.757]
 [47.745]] [[1.087]
 [0.883]
 [1.072]
 [1.058]
 [1.1  ]]
printing an ep nov before normalisation:  55.373396523702716
printing an ep nov before normalisation:  53.339106025325556
siam score:  -0.8810468
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  51.33186362727419
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.70630758164559
printing an ep nov before normalisation:  14.138878385225933
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  60.83523873598784
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.521]
 [44.521]
 [44.521]
 [44.521]
 [44.521]] [[1.623]
 [1.623]
 [1.623]
 [1.623]
 [1.623]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.133]
 [36.607]
 [30.023]
 [38.579]
 [36.466]] [[1.165]
 [1.066]
 [0.636]
 [1.195]
 [1.057]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.59059235361178
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9965,     0.0003,     0.0002,     0.0017,     0.0013],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9992,     0.0000,     0.0004,     0.0004],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0005,     0.8997,     0.0151,     0.0847],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0049,     0.0650,     0.7052,     0.2247],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0121,     0.0359,     0.3128,     0.6389],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.892]
 [42.178]
 [27.896]
 [26.918]
 [37.99 ]] [[0.241]
 [0.397]
 [0.2  ]
 [0.186]
 [0.339]]
printing an ep nov before normalisation:  61.496649117040214
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.88412523
printing an ep nov before normalisation:  44.100688235451166
siam score:  -0.88372743
UNIT TEST: sample policy line 217 mcts : [0.051 0.385 0.179 0.026 0.359]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.88286537
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.041]
 [36.038]
 [36.923]
 [42.937]
 [36.923]] [[0.588]
 [0.519]
 [0.549]
 [0.755]
 [0.549]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.62476402486316
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.16417289465852
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.848963123311115
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.714]
 [42.07 ]
 [47.343]
 [37.714]
 [49.008]] [[1.036]
 [1.313]
 [1.647]
 [1.036]
 [1.753]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.78626346588135
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.80919541323447
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.05263174390014
actions average: 
K:  0  action  0 :  tensor([0.9628, 0.0061, 0.0014, 0.0069, 0.0228], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0108, 0.9193, 0.0117, 0.0308, 0.0274], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.9191,     0.0355,     0.0452],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0012,     0.0005,     0.0392,     0.6644,     0.2947],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0178, 0.0157, 0.0410, 0.3490, 0.5764], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  37.13921920980095
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.19951677785414
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9677,     0.0074,     0.0002,     0.0160,     0.0086],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0022, 0.9624, 0.0043, 0.0031, 0.0280], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.8734,     0.0486,     0.0778],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0485,     0.0007,     0.0166,     0.7718,     0.1623],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0516, 0.0220, 0.0551, 0.2035, 0.6678], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.79326868057251
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 40.92028916763741
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 41.48718813807116
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.904255810476876
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0030, 0.9919, 0.0018, 0.0010, 0.0023], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0007,     0.0050,     0.8784,     0.0462,     0.0697],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0026,     0.0005,     0.0633,     0.7615,     0.1721],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0021, 0.0007, 0.0714, 0.3289, 0.5968], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.933]
 [31.598]
 [23.513]
 [25.271]
 [25.379]] [[0.386]
 [0.249]
 [0.142]
 [0.165]
 [0.167]]
printing an ep nov before normalisation:  35.227041827588636
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.59883434057218
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.730079650878906
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9989,     0.0000,     0.0005,     0.0004,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9784,     0.0007,     0.0006,     0.0199],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.8840,     0.0498,     0.0661],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0002,     0.0912,     0.7209,     0.1876],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0043, 0.0112, 0.0794, 0.2551, 0.6499], grad_fn=<DivBackward0>)
actions average: 
K:  2  action  0 :  tensor([    0.9509,     0.0085,     0.0004,     0.0045,     0.0358],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9968,     0.0003,     0.0003,     0.0026],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0012,     0.0001,     0.8731,     0.0543,     0.0714],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0006,     0.0689,     0.6925,     0.2379],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0004,     0.0016,     0.1008,     0.2772,     0.6200],
       grad_fn=<DivBackward0>)
siam score:  -0.8829123
printing an ep nov before normalisation:  43.294326101116006
line 256 mcts: sample exp_bonus 48.69416330756607
printing an ep nov before normalisation:  34.6112873308111
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.71543376827993
printing an ep nov before normalisation:  40.95236718916191
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.94548886638373
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.08745848992549
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.35 ]
 [26.771]
 [28.339]
 [25.86 ]
 [26.534]] [[0.897]
 [0.802]
 [0.896]
 [0.748]
 [0.788]]
printing an ep nov before normalisation:  51.17391440161984
printing an ep nov before normalisation:  29.147300720214844
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.883531806199905
printing an ep nov before normalisation:  25.012013912200928
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.954]
 [40.386]
 [38.479]
 [38.534]
 [38.559]] [[0.659]
 [0.569]
 [0.521]
 [0.522]
 [0.523]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.676]
 [31.577]
 [32.662]
 [32.268]
 [31.019]] [[0.537]
 [0.504]
 [0.536]
 [0.524]
 [0.487]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.052140022003844
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.894]
 [30.742]
 [23.178]
 [20.083]
 [21.009]] [[0.281]
 [0.558]
 [0.365]
 [0.286]
 [0.31 ]]
printing an ep nov before normalisation:  72.20580957987792
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.395438114362015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.684775180114357
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.65570824134323
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.924]
 [54.924]
 [60.407]
 [54.924]
 [54.924]] [[0.991]
 [0.991]
 [1.172]
 [0.991]
 [0.991]]
actions average: 
K:  4  action  0 :  tensor([    0.9914,     0.0002,     0.0000,     0.0023,     0.0062],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0008,     0.9896,     0.0013,     0.0037,     0.0047],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9511,     0.0235,     0.0253],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0003,     0.0624,     0.6815,     0.2553],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0005,     0.0009,     0.1404,     0.1497,     0.7086],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  52.86755909128599
printing an ep nov before normalisation:  47.286440005999324
printing an ep nov before normalisation:  47.665742313908204
printing an ep nov before normalisation:  49.78773593902588
printing an ep nov before normalisation:  42.533091779296996
printing an ep nov before normalisation:  31.92521333694458
printing an ep nov before normalisation:  43.77165145889843
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.218]
 [42.272]
 [35.053]
 [42.059]
 [42.69 ]] [[0.973]
 [0.891]
 [0.585]
 [0.882]
 [0.908]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 57.67027283866248
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.005097909729556704
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.83323949487994
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.779357643689536
siam score:  -0.8767544
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.587]
 [28.398]
 [28.398]
 [28.398]
 [39.868]] [[0.491]
 [0.259]
 [0.259]
 [0.259]
 [0.69 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.010061253053472
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9929,     0.0011,     0.0021,     0.0036],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0003,     0.9546,     0.0210,     0.0240],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0009, 0.0010, 0.0221, 0.7580, 0.2180], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0030, 0.0237, 0.1063, 0.3175, 0.5495], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87823087
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.82014626362369
printing an ep nov before normalisation:  36.00801686269628
printing an ep nov before normalisation:  40.835954326597786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.956]
 [33.53 ]
 [33.53 ]
 [33.53 ]
 [33.53 ]] [[0.397]
 [0.171]
 [0.171]
 [0.171]
 [0.171]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 61.085716270461354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.80108735370326
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.206]
 [34.176]
 [23.922]
 [26.838]
 [27.174]] [[0.75 ]
 [0.647]
 [0.297]
 [0.397]
 [0.408]]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  84.73018552783687
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.8775954
printing an ep nov before normalisation:  53.08580419481639
printing an ep nov before normalisation:  33.93898248672485
printing an ep nov before normalisation:  35.53485460101005
printing an ep nov before normalisation:  45.13286576677153
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.69753980636597
printing an ep nov before normalisation:  37.849976926609955
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.97723627090454
printing an ep nov before normalisation:  37.766193719564576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.81036328460648
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  4  action  0 :  tensor([0.9292, 0.0215, 0.0013, 0.0193, 0.0288], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9994,     0.0002,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9236,     0.0326,     0.0437],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0015, 0.0012, 0.0623, 0.6938, 0.2411], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0017, 0.0104, 0.0982, 0.2438, 0.6459], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.387]
 [ 0.001]
 [ 0.   ]
 [33.387]
 [33.387]] [[0.222]
 [0.   ]
 [0.   ]
 [0.222]
 [0.222]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.26684782851023
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.39217281341553
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.917]
 [40.212]
 [27.917]
 [27.917]
 [27.917]] [[0.63 ]
 [1.158]
 [0.63 ]
 [0.63 ]
 [0.63 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8672862
printing an ep nov before normalisation:  54.197401069684595
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.965]
 [34.346]
 [36.328]
 [34.965]
 [34.965]] [[0.532]
 [0.515]
 [0.572]
 [0.532]
 [0.532]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  74.8681607908662
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.4376416165999
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.75870075795652
printing an ep nov before normalisation:  42.3197707189116
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.101]
 [44.729]
 [46.555]
 [46.99 ]
 [46.58 ]] [[1.63 ]
 [1.546]
 [1.658]
 [1.684]
 [1.659]]
printing an ep nov before normalisation:  44.289546706291134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0015138682307735962
printing an ep nov before normalisation:  66.10955826319535
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.74272627033486
printing an ep nov before normalisation:  43.044302178550204
printing an ep nov before normalisation:  0.0008813218855152627
printing an ep nov before normalisation:  103.47695637935502
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.905]
 [42.708]
 [33.905]
 [44.59 ]
 [33.905]] [[0.497]
 [0.884]
 [0.497]
 [0.967]
 [0.497]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.934376396048304
printing an ep nov before normalisation:  0.002480902173829236
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.86439681708138
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  45.94850685297831
printing an ep nov before normalisation:  36.59588004895227
printing an ep nov before normalisation:  36.85065461539076
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88239396
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8836894
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.581]
 [31.349]
 [36.256]
 [30.128]
 [33.572]] [[0.527]
 [0.791]
 [1.016]
 [0.735]
 [0.893]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.841843952149084
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.014]
 [32.073]
 [46.211]
 [44.329]
 [34.172]] [[0.869]
 [0.338]
 [0.68 ]
 [0.635]
 [0.389]]
printing an ep nov before normalisation:  70.78248513813263
printing an ep nov before normalisation:  28.73356580734253
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.85959339957232
printing an ep nov before normalisation:  0.0011794744381177225
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.137]
 [33.421]
 [40.407]
 [37.939]
 [36.587]] [[0.581]
 [0.342]
 [0.497]
 [0.442]
 [0.412]]
printing an ep nov before normalisation:  40.101526445427204
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.712351161180237
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.17844259087374
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.628]
 [34.06 ]
 [31.142]
 [27.435]
 [34.849]] [[0.598]
 [0.788]
 [0.663]
 [0.504]
 [0.822]]
printing an ep nov before normalisation:  31.93628936455745
printing an ep nov before normalisation:  27.003635820155512
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.48951139615217
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8814725
line 256 mcts: sample exp_bonus 43.06188968200096
printing an ep nov before normalisation:  43.95330893798221
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.90549721700013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.166]
 [28.166]
 [31.316]
 [28.166]
 [28.166]] [[1.155]
 [1.155]
 [1.424]
 [1.155]
 [1.155]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.444128546006844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.75937655824994
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.296283952872304
printing an ep nov before normalisation:  29.8002405052758
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  60.870987897962976
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.879]
 [41.016]
 [29.431]
 [23.201]
 [26.741]] [[0.406]
 [0.961]
 [0.586]
 [0.384]
 [0.499]]
printing an ep nov before normalisation:  40.15004054264667
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0026076712420793533
printing an ep nov before normalisation:  43.08774239213428
siam score:  -0.88315254
printing an ep nov before normalisation:  44.73293015303339
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.526]
 [25.526]
 [41.071]
 [25.526]
 [25.526]] [[0.576]
 [0.576]
 [1.244]
 [0.576]
 [0.576]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.13731421960505
printing an ep nov before normalisation:  41.590559196153535
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9756,     0.0001,     0.0014,     0.0003,     0.0227],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9728,     0.0000,     0.0000,     0.0270],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0018,     0.9109,     0.0387,     0.0486],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0010, 0.0024, 0.0367, 0.7525, 0.2073], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0030, 0.0153, 0.0374, 0.2949, 0.6493], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  49.47480856934555
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 72.74637835105433
using explorer policy with actor:  1
printing an ep nov before normalisation:  55.318931835228675
actions average: 
K:  1  action  0 :  tensor([    0.9969,     0.0004,     0.0000,     0.0017,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9999,     0.0001,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0002,     0.9641,     0.0099,     0.0258],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0009, 0.0087, 0.0678, 0.7286, 0.1939], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0025, 0.0432, 0.0215, 0.3265, 0.6063], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.04077937311648
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.27760456029776
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.537]
 [32.138]
 [41.905]
 [40.063]
 [42.77 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.32116222381592
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.66347340352597
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.45105244963962
printing an ep nov before normalisation:  36.27084044469197
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.721407890319824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.74876708423719
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.32074440515143
printing an ep nov before normalisation:  28.952205125881505
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.327]
 [35.551]
 [51.079]
 [48.941]
 [43.967]] [[0.354]
 [0.3  ]
 [0.601]
 [0.559]
 [0.463]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9563,     0.0110,     0.0002,     0.0005,     0.0321],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9305,     0.0002,     0.0006,     0.0686],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0005,     0.8643,     0.0479,     0.0872],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0027,     0.0433,     0.6927,     0.2611],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0006,     0.0028,     0.1155,     0.2122,     0.6690],
       grad_fn=<DivBackward0>)
siam score:  -0.8789058
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.14797592163086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.52688064979617
actions average: 
K:  3  action  0 :  tensor([    0.9928,     0.0010,     0.0000,     0.0026,     0.0037],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9756,     0.0202,     0.0018,     0.0024],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.7578,     0.1188,     0.1233],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0028, 0.0078, 0.0288, 0.8469, 0.1138], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0021, 0.0016, 0.1247, 0.3955, 0.4761], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.89064096269428
siam score:  -0.87980103
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9730,     0.0045,     0.0002,     0.0072,     0.0151],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0006,     0.9297,     0.0009,     0.0006,     0.0681],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0000,     0.9375,     0.0266,     0.0358],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0003,     0.0304,     0.6706,     0.2985],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0012, 0.0070, 0.0745, 0.2187, 0.6986], grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.318]
 [29.89 ]
 [46.538]
 [29.091]
 [29.966]] [[0.164]
 [0.16 ]
 [0.329]
 [0.152]
 [0.161]]
printing an ep nov before normalisation:  37.87146176187671
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 -2.7962876913692155e-11
0.0 -3.3563236577707546e-11
0.0 -6.560421323563336e-11
0.0 0.0
0.0 -5.615928233456498e-11
0.0 -3.9916077004133047e-11
0.0 -8.789321224872637e-11
0.0 -5.940273388051161e-11
0.0 -8.344752133063601e-11
0.0 -4.956858880121153e-11
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.09993792722866601
printing an ep nov before normalisation:  54.462229750854576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.362]
 [54.315]
 [53.362]
 [53.362]
 [53.362]] [[1.945]
 [1.997]
 [1.945]
 [1.945]
 [1.945]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.541442797083107
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.19208305395294
printing an ep nov before normalisation:  54.68137933219441
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.223]
 [34.348]
 [36.764]
 [33.421]
 [40.55 ]] [[0.256]
 [0.273]
 [0.31 ]
 [0.259]
 [0.368]]
printing an ep nov before normalisation:  54.054230117843495
printing an ep nov before normalisation:  33.281103053102804
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9970,     0.0008,     0.0001,     0.0005,     0.0016],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0014,     0.9616,     0.0008,     0.0003,     0.0358],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.9016,     0.0478,     0.0503],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0012,     0.0415,     0.7620,     0.1948],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0045, 0.0077, 0.0460, 0.3632, 0.5786], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.301]
 [55.301]
 [55.301]
 [55.301]
 [57.495]] [[1.224]
 [1.224]
 [1.224]
 [1.224]
 [1.302]]
actions average: 
K:  4  action  0 :  tensor([    0.9661,     0.0001,     0.0000,     0.0223,     0.0115],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0028, 0.9234, 0.0034, 0.0011, 0.0693], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0022, 0.0026, 0.8048, 0.0759, 0.1146], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0007,     0.0708,     0.5564,     0.3716],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0007, 0.0009, 0.0493, 0.2961, 0.6530], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.355]
 [38.02 ]
 [44.078]
 [40.636]
 [40.321]] [[0.669]
 [0.732]
 [0.962]
 [0.832]
 [0.82 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8892481
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.545]
 [31.545]
 [31.545]
 [31.545]
 [31.545]] [[0.17]
 [0.17]
 [0.17]
 [0.17]
 [0.17]]
actions average: 
K:  2  action  0 :  tensor([    0.9908,     0.0005,     0.0001,     0.0035,     0.0051],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9515,     0.0307,     0.0013,     0.0165],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0002,     0.9126,     0.0253,     0.0619],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0003,     0.0484,     0.7274,     0.2236],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0008, 0.0010, 0.0549, 0.2420, 0.7013], grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  8.853147700652439e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9667,     0.0003,     0.0000,     0.0175,     0.0155],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9950,     0.0041,     0.0003,     0.0005],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.8821,     0.0453,     0.0725],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0007,     0.0295,     0.8139,     0.1555],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0032, 0.0038, 0.0703, 0.2643, 0.6583], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9950,     0.0008,     0.0023,     0.0002,     0.0017],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0025,     0.9932,     0.0023,     0.0007,     0.0013],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0003,     0.7454,     0.0965,     0.1578],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0126, 0.0045, 0.0472, 0.6951, 0.2407], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0324, 0.0033, 0.1334, 0.2186, 0.6124], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8876604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8849028
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.528]
 [36.308]
 [41.093]
 [41.093]
 [41.093]] [[1.512]
 [1.003]
 [1.241]
 [1.241]
 [1.241]]
printing an ep nov before normalisation:  36.54241177945637
printing an ep nov before normalisation:  38.02657127380371
printing an ep nov before normalisation:  55.45796840829134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.678]
 [44.098]
 [41.981]
 [35.695]
 [39.724]] [[0.368]
 [0.537]
 [0.495]
 [0.368]
 [0.449]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0011004342520948285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.040390240373032
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.238]
 [35.624]
 [30.159]
 [31.001]
 [30.406]] [[1.266]
 [0.998]
 [0.737]
 [0.777]
 [0.749]]
printing an ep nov before normalisation:  42.92585681102782
printing an ep nov before normalisation:  31.84379333736771
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.12714318398127
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 41.270023584365845
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88518846
printing an ep nov before normalisation:  55.38280683414885
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.80787799399113
siam score:  -0.8837068
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  30.706354580162852
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.851]
 [26.322]
 [34.379]
 [29.6  ]
 [29.351]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  28.511372642149563
printing an ep nov before normalisation:  46.481539231839015
actions average: 
K:  0  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0093,     0.9881,     0.0001,     0.0007,     0.0018],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0020, 0.0017, 0.9117, 0.0376, 0.0470], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0008,     0.0440,     0.8008,     0.1539],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0027, 0.0152, 0.0402, 0.4148, 0.5271], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  41.67769711315415
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88388824
printing an ep nov before normalisation:  42.55613418374863
printing an ep nov before normalisation:  38.779444665701824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.798208236694336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 30.006754398345947
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 37.43185355161979
printing an ep nov before normalisation:  25.802629266200814
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.763]
 [45.763]
 [43.584]
 [45.763]
 [43.617]] [[1.591]
 [1.591]
 [1.481]
 [1.591]
 [1.483]]
printing an ep nov before normalisation:  51.68811865649219
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8896871
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  4.431380489222647e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88756704
printing an ep nov before normalisation:  31.547465565516553
printing an ep nov before normalisation:  34.58983245013112
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.297]
 [37.297]
 [81.882]
 [37.297]
 [37.297]] [[0.408]
 [0.408]
 [1.336]
 [0.408]
 [0.408]]
printing an ep nov before normalisation:  33.526343632360565
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.14363230081602
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
siam score:  -0.87937355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.557]
 [37.557]
 [37.919]
 [37.557]
 [37.557]] [[1.211]
 [1.211]
 [1.231]
 [1.211]
 [1.211]]
actions average: 
K:  3  action  0 :  tensor([    0.9965,     0.0000,     0.0000,     0.0017,     0.0018],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0049,     0.9909,     0.0012,     0.0005,     0.0025],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.8942,     0.0415,     0.0642],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0082,     0.0735,     0.7632,     0.1551],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0015, 0.0009, 0.0315, 0.2814, 0.6847], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  38.16749878723814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8803456
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.085832595825195
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.748345377017934
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.224]
 [40.224]
 [40.224]
 [40.224]
 [33.651]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  42.54851527503022
printing an ep nov before normalisation:  36.66578961653885
printing an ep nov before normalisation:  25.97915475158633
printing an ep nov before normalisation:  28.002747444976606
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.34740976796791
printing an ep nov before normalisation:  46.61406472337766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.83921366922753
printing an ep nov before normalisation:  34.47079462196458
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.112]
 [23.696]
 [30.512]
 [26.205]
 [26.452]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  27.436126103307938
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.631]
 [0.629]
 [0.462]
 [0.545]
 [0.541]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  53.87194441258993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.176688417810958
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.887426
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.21920394897461
printing an ep nov before normalisation:  27.62855939128463
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.74424475139284
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.360838189300324
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.84387177734623
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.84556770324707
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.20296912130309
printing an ep nov before normalisation:  54.3177891211119
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.711546897935705
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.92781267697513
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.66501808166504
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.296]
 [31.55 ]
 [18.265]
 [16.758]
 [17.753]] [[0.361]
 [0.93 ]
 [0.399]
 [0.339]
 [0.379]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.005806610308809468
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([    0.9808,     0.0125,     0.0001,     0.0019,     0.0047],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9882,     0.0000,     0.0058,     0.0059],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0002,     0.9152,     0.0365,     0.0479],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0040, 0.0054, 0.0621, 0.6945, 0.2340], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0068, 0.0418, 0.1114, 0.2665, 0.5735], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.78178770714682
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.72524789696677
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.209]
 [45.481]
 [34.225]
 [29.209]
 [39.497]] [[0.068]
 [0.248]
 [0.123]
 [0.068]
 [0.182]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.09803406230333
printing an ep nov before normalisation:  73.42085524617028
printing an ep nov before normalisation:  41.26034221693302
siam score:  -0.88325286
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88316137
printing an ep nov before normalisation:  53.14622296937703
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.36355792155096
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9996,     0.0001,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0018, 0.9477, 0.0122, 0.0014, 0.0370], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0018, 0.0124, 0.8659, 0.0369, 0.0829], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0414, 0.0029, 0.0397, 0.7597, 0.1564], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0006,     0.0045,     0.0754,     0.1907,     0.7288],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9993,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9472,     0.0111,     0.0416],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0005,     0.0003,     0.0200,     0.8524,     0.1268],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0015, 0.0029, 0.1222, 0.3501, 0.5234], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.166310340330625
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.98252765761108
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.87820185782068
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.762621927318204
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
actions average: 
K:  4  action  0 :  tensor([    0.9802,     0.0029,     0.0000,     0.0073,     0.0096],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9742,     0.0017,     0.0026,     0.0213],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0032,     0.0002,     0.9833,     0.0045,     0.0089],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0041, 0.0013, 0.0195, 0.7190, 0.2561], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0118, 0.0211, 0.1005, 0.1862, 0.6804], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  23.969979286193848
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.144]
 [33.667]
 [28.164]
 [34.77 ]
 [30.386]] [[0.363]
 [0.219]
 [0.149]
 [0.232]
 [0.177]]
printing an ep nov before normalisation:  64.98343216090072
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.385]
 [37.385]
 [37.385]
 [37.385]
 [37.385]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
printing an ep nov before normalisation:  32.84790007490761
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9996,     0.0000,     0.0001,     0.0003,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9669,     0.0001,     0.0005,     0.0324],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0000,     0.9595,     0.0182,     0.0222],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0033, 0.0008, 0.0374, 0.6855, 0.2730], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0199, 0.0018, 0.1155, 0.2616, 0.6012], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  34.0098769863043
printing an ep nov before normalisation:  43.443054399817065
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.529]
 [35.529]
 [35.529]
 [37.297]
 [35.529]] [[0.798]
 [0.798]
 [0.798]
 [0.882]
 [0.798]]
printing an ep nov before normalisation:  34.093252798156854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.156]
 [52.597]
 [25.044]
 [31.981]
 [32.23 ]] [[0.768]
 [0.644]
 [0.027]
 [0.182]
 [0.188]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.987749099731445
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.33376025130895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.81 ]
 [48.81 ]
 [68.061]
 [48.81 ]
 [48.81 ]] [[0.695]
 [0.695]
 [1.094]
 [0.695]
 [0.695]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.42 ]
 [57.42 ]
 [58.845]
 [56.752]
 [58.331]] [[1.896]
 [1.896]
 [1.97 ]
 [1.861]
 [1.943]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.155]
 [34.155]
 [40.159]
 [34.155]
 [34.155]] [[1.465]
 [1.465]
 [1.909]
 [1.465]
 [1.465]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
siam score:  -0.86640245
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.760854886009213
actions average: 
K:  1  action  0 :  tensor([    0.9976,     0.0013,     0.0000,     0.0003,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0357,     0.9583,     0.0000,     0.0041,     0.0019],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0007,     0.8952,     0.0486,     0.0553],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0100, 0.0023, 0.1043, 0.6048, 0.2786], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0431, 0.0007, 0.1103, 0.2855, 0.5604], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.17628310202955
printing an ep nov before normalisation:  33.07800018011571
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.58356561492318
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
actions average: 
K:  4  action  0 :  tensor([    0.9976,     0.0005,     0.0001,     0.0003,     0.0015],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0051, 0.9599, 0.0146, 0.0073, 0.0131], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0003,     0.9205,     0.0167,     0.0623],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0009, 0.0010, 0.0188, 0.7084, 0.2708], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0018, 0.0218, 0.1602, 0.2121, 0.6041], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  39.06780881776323
printing an ep nov before normalisation:  31.236002051921087
printing an ep nov before normalisation:  0.0
actions average: 
K:  0  action  0 :  tensor([    0.9989,     0.0000,     0.0002,     0.0003,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9736,     0.0020,     0.0078,     0.0163],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9584,     0.0151,     0.0265],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0002,     0.0392,     0.7638,     0.1966],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0012,     0.0004,     0.1329,     0.2598,     0.6057],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.8727238126977
printing an ep nov before normalisation:  25.242857933044434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.4249070829473
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.896]
 [55.974]
 [55.974]
 [55.974]
 [55.974]] [[1.193]
 [0.873]
 [0.873]
 [0.873]
 [0.873]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.0413936013271
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.00311255455017
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.877505294173194
actions average: 
K:  4  action  0 :  tensor([    0.9986,     0.0003,     0.0000,     0.0001,     0.0010],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0004,     0.9955,     0.0002,     0.0004,     0.0035],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0067, 0.0172, 0.9272, 0.0093, 0.0397], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0038, 0.0035, 0.0120, 0.7697, 0.2111], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0016, 0.0045, 0.1156, 0.2660, 0.6123], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.80090141296387
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.505066421476336
siam score:  -0.88311994
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8833348
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  0.03242247001556583
printing an ep nov before normalisation:  51.52439665112493
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.713]
 [47.713]
 [51.985]
 [46.146]
 [45.673]] [[1.424]
 [1.424]
 [1.667]
 [1.335]
 [1.308]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.115]
 [36.115]
 [36.115]
 [36.115]
 [36.115]] [[0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]]
actions average: 
K:  3  action  0 :  tensor([    0.9865,     0.0001,     0.0019,     0.0008,     0.0108],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0005,     0.9555,     0.0001,     0.0000,     0.0438],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0001,     0.8588,     0.0623,     0.0787],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0004,     0.0015,     0.7580,     0.2398],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0011, 0.0010, 0.0853, 0.4320, 0.4806], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.17972390461486
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.8773357
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9991,     0.0001,     0.0000,     0.0002,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9996,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0003,     0.0001,     0.9405,     0.0272,     0.0319],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0012,     0.0006,     0.0624,     0.7187,     0.2170],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0015, 0.0013, 0.0350, 0.3227, 0.6395], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9642,     0.0007,     0.0002,     0.0197,     0.0152],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9973,     0.0000,     0.0018,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.8952,     0.0497,     0.0549],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0000,     0.0002,     0.0018,     0.8205,     0.1775],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0012, 0.0038, 0.1203, 0.3037, 0.5710], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.69676791313244
actions average: 
K:  3  action  0 :  tensor([    0.9969,     0.0003,     0.0000,     0.0005,     0.0023],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0014,     0.8889,     0.0418,     0.0679],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0007, 0.0472, 0.0522, 0.6696, 0.2303], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0068, 0.0633, 0.1160, 0.2438, 0.5701], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.26327268121318
printing an ep nov before normalisation:  34.91620063781738
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.28030941608561
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.483]
 [35.483]
 [35.483]
 [35.483]
 [35.483]] [[1.179]
 [1.179]
 [1.179]
 [1.179]
 [1.179]]
printing an ep nov before normalisation:  33.337272616367194
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.199819564819336
printing an ep nov before normalisation:  21.10311508178711
printing an ep nov before normalisation:  23.96057874092625
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.245]
 [29.112]
 [29.508]
 [29.482]
 [28.847]] [[1.451]
 [1.342]
 [1.381]
 [1.378]
 [1.317]]
printing an ep nov before normalisation:  36.28349521173576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8812499
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.95715273285878
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.118735626286956
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.884957063508594
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.69122694677299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.130578037427895
printing an ep nov before normalisation:  49.33891941133342
printing an ep nov before normalisation:  25.176497307826253
siam score:  -0.8827089
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.78582988641936
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  49.96411692660181
printing an ep nov before normalisation:  35.11386423883162
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.303556514697
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.315089087036945
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.81 ]
 [35.093]
 [36.054]
 [31.16 ]
 [33.037]] [[1.278]
 [1.127]
 [1.18 ]
 [0.909]
 [1.013]]
actions average: 
K:  4  action  0 :  tensor([    0.9985,     0.0001,     0.0003,     0.0004,     0.0007],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9988,     0.0000,     0.0003,     0.0009],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9384,     0.0320,     0.0296],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0009,     0.0002,     0.0238,     0.7818,     0.1933],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0014, 0.0019, 0.1849, 0.2615, 0.5503], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.21786349765182
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.52064284477729
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88703966
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88494825
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.677397998023153
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.45180041964461
printing an ep nov before normalisation:  32.68781396990413
printing an ep nov before normalisation:  51.62618145297747
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.7006254196167
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.99323727762346
printing an ep nov before normalisation:  42.6089136348076
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.001]
 [26.699]
 [26.86 ]
 [29.339]
 [25.872]] [[1.137]
 [0.973]
 [0.985]
 [1.161]
 [0.914]]
printing an ep nov before normalisation:  25.188311111277635
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  63.348600549226
printing an ep nov before normalisation:  60.546574627115014
siam score:  -0.8864659
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.322]
 [34.32 ]
 [27.107]
 [26.973]
 [25.459]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.31159448623657
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.475000941056216
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.65007495880127
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.61503531045531
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.36969697428148
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8830447
printing an ep nov before normalisation:  75.7129858108406
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.40745395280109
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.71152076984188
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.15086327950961
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.9  ]
 [47.9  ]
 [50.188]
 [47.9  ]
 [47.9  ]] [[1.177]
 [1.177]
 [1.261]
 [1.177]
 [1.177]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.02672845257805
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  49.54858821586659
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.524]
 [34.451]
 [37.263]
 [37.263]
 [37.263]] [[0.743]
 [0.356]
 [0.413]
 [0.413]
 [0.413]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.549]
 [33.897]
 [33.897]
 [38.731]
 [33.897]] [[0.669]
 [0.28 ]
 [0.28 ]
 [0.357]
 [0.28 ]]
printing an ep nov before normalisation:  71.20155117579489
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.76023258970092
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9535,     0.0140,     0.0025,     0.0298],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0005,     0.0000,     0.9229,     0.0306,     0.0459],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0005,     0.0349,     0.7715,     0.1929],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0021, 0.0124, 0.1236, 0.2996, 0.5623], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.79362407792668
printing an ep nov before normalisation:  46.2480838517012
printing an ep nov before normalisation:  40.79588242855876
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.47088192724208
printing an ep nov before normalisation:  33.67462521974148
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.47151041826714
siam score:  -0.88488907
siam score:  -0.8824482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8821428
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.89343862054652
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.84560596046296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.9676,     0.0003,     0.0000,     0.0014,     0.0307],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0032, 0.9670, 0.0014, 0.0017, 0.0266], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0005,     0.0002,     0.8349,     0.0796,     0.0848],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0024,     0.0638,     0.7324,     0.2010],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0025, 0.0053, 0.1055, 0.2848, 0.6018], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.43299453188551
printing an ep nov before normalisation:  35.86864228978481
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.161235694194776
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.94105578507221
UNIT TEST: sample policy line 217 mcts : [0. 0. 1. 0. 0.]
printing an ep nov before normalisation:  58.04142687210937
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 24.4610907598344
printing an ep nov before normalisation:  53.22775619561363
printing an ep nov before normalisation:  53.68785818584519
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9743,     0.0008,     0.0002,     0.0038,     0.0209],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9989,     0.0001,     0.0006,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0096, 0.0012, 0.8989, 0.0302, 0.0601], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0034, 0.0022, 0.0360, 0.6829, 0.2755], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0056, 0.0655, 0.0678, 0.2513, 0.6098], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  29.364646996341648
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.864]
 [26.819]
 [27.307]
 [22.373]
 [27.507]] [[0.514]
 [0.553]
 [0.573]
 [0.372]
 [0.581]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.1172941721905
printing an ep nov before normalisation:  32.8117930240903
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.33507760365804
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.467]
 [74.467]
 [78.541]
 [75.882]
 [75.978]] [[1.156]
 [1.156]
 [1.232]
 [1.182]
 [1.184]]
printing an ep nov before normalisation:  69.60773089136504
UNIT TEST: sample policy line 217 mcts : [0.077 0.154 0.359 0.256 0.154]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.012]
 [41.331]
 [41.75 ]
 [41.75 ]
 [42.825]] [[1.168]
 [1.016]
 [1.029]
 [1.029]
 [1.064]]
printing an ep nov before normalisation:  39.564958785572735
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.6997886281964
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.660523414611816
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.989]
 [45.3  ]
 [38.989]
 [38.989]
 [38.989]] [[0.557]
 [0.701]
 [0.557]
 [0.557]
 [0.557]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.670051933538318
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [39.637]
 [ 0.   ]
 [ 0.   ]] [[-1.173]
 [-1.173]
 [ 0.854]
 [-1.173]
 [-1.173]]
actions average: 
K:  4  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0005,     0.0006],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9660,     0.0035,     0.0021,     0.0282],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9531,     0.0139,     0.0330],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0008, 0.0026, 0.0422, 0.7468, 0.2075], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0026, 0.0137, 0.0529, 0.2904, 0.6405], grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.855]
 [43.431]
 [40.56 ]
 [43.576]
 [42.965]] [[1.396]
 [1.529]
 [1.381]
 [1.536]
 [1.505]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.18099926886078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.806714421747486
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.93333785019087
printing an ep nov before normalisation:  27.889330069915363
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.250863285426554
printing an ep nov before normalisation:  29.576304718524046
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.00806273453091
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.10262934366862
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.745]
 [36.262]
 [35.492]
 [36.262]
 [36.262]] [[1.318]
 [1.003]
 [0.971]
 [1.003]
 [1.003]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.06920679921876172
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.19766840183569
printing an ep nov before normalisation:  28.69154346115297
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.508]
 [56.508]
 [57.247]
 [56.508]
 [56.508]] [[1.666]
 [1.666]
 [1.708]
 [1.666]
 [1.666]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.609]
 [46.541]
 [45.984]
 [45.984]
 [45.984]] [[1.848]
 [1.603]
 [1.575]
 [1.575]
 [1.575]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [35.756]
 [ 0.   ]
 [ 0.   ]] [[-0.55 ]
 [-0.55 ]
 [ 0.554]
 [-0.55 ]
 [-0.55 ]]
line 256 mcts: sample exp_bonus 39.25018004474673
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.80960613380989
siam score:  -0.87649757
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.18782001572374
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.888]
 [30.367]
 [38.261]
 [27.273]
 [27.606]] [[0.645]
 [0.708]
 [1.043]
 [0.576]
 [0.59 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.907]
 [45.268]
 [45.268]
 [45.268]
 [45.268]] [[1.333]
 [1.016]
 [1.016]
 [1.016]
 [1.016]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.513]
 [25.227]
 [21.155]
 [21.474]
 [21.863]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.396]
 [38.707]
 [37.295]
 [23.043]
 [29.653]] [[0.302]
 [0.584]
 [0.552]
 [0.225]
 [0.377]]
printing an ep nov before normalisation:  47.53307084020252
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87612814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0163,     0.9669,     0.0007,     0.0038,     0.0123],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0019,     0.0001,     0.9239,     0.0360,     0.0381],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0006,     0.0441,     0.6591,     0.2960],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0033, 0.0197, 0.0820, 0.2015, 0.6935], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.099]
 [34.142]
 [30.844]
 [35.4  ]
 [36.426]] [[1.094]
 [0.877]
 [0.697]
 [0.946]
 [1.003]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8801299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.70741844177246
printing an ep nov before normalisation:  41.063613800050746
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9993,     0.0001,     0.0000,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9965,     0.0001,     0.0030,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0008,     0.0000,     0.9614,     0.0110,     0.0268],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0017,     0.1057,     0.6399,     0.2527],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0012, 0.0356, 0.0809, 0.1743, 0.7080], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.42022723741316
actions average: 
K:  0  action  0 :  tensor([    0.9996,     0.0002,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9796,     0.0009,     0.0003,     0.0191],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.8909,     0.0256,     0.0834],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0048,     0.0005,     0.0244,     0.7179,     0.2525],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0049, 0.0008, 0.0645, 0.3207, 0.6091], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.35609565281374
line 256 mcts: sample exp_bonus 39.917670144225525
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.478]
 [47.356]
 [28.266]
 [28.266]
 [28.266]] [[0.755]
 [0.984]
 [0.24 ]
 [0.24 ]
 [0.24 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.88359355926514
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.352]
 [50.352]
 [50.352]
 [50.352]
 [50.352]] [[1.845]
 [1.845]
 [1.845]
 [1.845]
 [1.845]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.76953442946938
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.81842789662883
printing an ep nov before normalisation:  62.75993932374971
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.4539747544266
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.05477596906505
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.42107631545874
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.160341024503786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.67330925245946
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.922]
 [29.909]
 [30.855]
 [29.347]
 [30.043]] [[0.914]
 [0.766]
 [0.813]
 [0.738]
 [0.773]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.46584171885106
printing an ep nov before normalisation:  50.989172944054594
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.75156995797571
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.36716948633079
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.87473119528291
siam score:  -0.89063996
printing an ep nov before normalisation:  44.090652385599796
actions average: 
K:  4  action  0 :  tensor([    0.9875,     0.0006,     0.0034,     0.0034,     0.0050],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9996,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0000,     0.8743,     0.0553,     0.0702],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0021, 0.0012, 0.0609, 0.7040, 0.2319], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0027, 0.0010, 0.0424, 0.3241, 0.6298], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.553]
 [36.698]
 [26.887]
 [27.327]
 [24.359]] [[0.372]
 [0.631]
 [0.381]
 [0.392]
 [0.316]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.42371138084268
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.4642658487529
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.23]
 [63.23]
 [63.23]
 [63.23]
 [63.23]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.02664695834271
printing an ep nov before normalisation:  1.6422550973150862
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.662517547607422
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.483066756399495
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.41785441202326
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.621]
 [32.516]
 [41.446]
 [40.228]
 [39.438]] [[0.434]
 [0.572]
 [0.822]
 [0.788]
 [0.766]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.675553789582423
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.4  ]
 [38.732]
 [35.4  ]
 [35.4  ]
 [35.4  ]] [[1.331]
 [1.571]
 [1.331]
 [1.331]
 [1.331]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.887]
 [24.887]
 [24.887]
 [43.536]
 [24.887]] [[0.543]
 [0.543]
 [0.543]
 [1.263]
 [0.543]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.822303220347294
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9969,     0.0004,     0.0000,     0.0010,     0.0017],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9996,     0.0001,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0002,     0.9072,     0.0285,     0.0641],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0011,     0.0006,     0.0356,     0.7002,     0.2625],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0594, 0.0026, 0.0421, 0.2811, 0.6149], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.569]
 [32.646]
 [32.646]
 [32.646]
 [32.646]] [[1.199]
 [0.54 ]
 [0.54 ]
 [0.54 ]
 [0.54 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.88370293
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 49.793930509103625
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.3487952381981
actions average: 
K:  4  action  0 :  tensor([    0.9790,     0.0007,     0.0001,     0.0072,     0.0131],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0157,     0.9480,     0.0001,     0.0031,     0.0331],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9218,     0.0349,     0.0433],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0076,     0.0607,     0.6723,     0.2588],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0006, 0.0026, 0.1986, 0.2515, 0.5467], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  46.7562942872019
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 33.70175394017393
printing an ep nov before normalisation:  36.39132632382124
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.554101364071904
siam score:  -0.87581843
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.09 ]
 [31.09 ]
 [48.128]
 [31.09 ]
 [31.09 ]] [[0.41 ]
 [0.41 ]
 [0.817]
 [0.41 ]
 [0.41 ]]
printing an ep nov before normalisation:  38.36319738255284
printing an ep nov before normalisation:  67.7202543842907
printing an ep nov before normalisation:  34.14430379867554
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9965,     0.0002,     0.0000,     0.0008,     0.0025],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9966,     0.0002,     0.0028,     0.0004],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0015, 0.0303, 0.8656, 0.0537, 0.0489], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0003,     0.0560,     0.8017,     0.1418],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0009, 0.0028, 0.0494, 0.2740, 0.6729], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [     0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 -9.176805570938415e-12
0.0 -9.418983281641231e-12
0.0 -6.400411045797295e-12
0.0 -1.368304091368378e-11
0.0 1.848023548788517e-09
0.0 -1.4937175510585217e-11
0.0 -1.219537780235199e-11
0.0 -1.0854751166604279e-11
0.0 -5.9593016369678805e-12
0.0 -8.58433508959697e-12
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.16383178820482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  29.169036871886508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.93704009056091
printing an ep nov before normalisation:  38.182268142700195
printing an ep nov before normalisation:  32.28083302174323
printing an ep nov before normalisation:  29.042523218889706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.113387667325913
printing an ep nov before normalisation:  0.0005333827243703126
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.5335242040317
siam score:  -0.8769727
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.322261767027314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.45779569400032
siam score:  -0.87377924
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.57622718811035
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.952]
 [45.952]
 [45.952]
 [45.952]
 [45.952]] [[1.623]
 [1.623]
 [1.623]
 [1.623]
 [1.623]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.8781666248354
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.351]
 [25.002]
 [36.742]
 [34.196]
 [26.428]] [[0.14 ]
 [0.104]
 [0.203]
 [0.181]
 [0.116]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9980,     0.0002,     0.0009,     0.0003,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0040,     0.9586,     0.0028,     0.0003,     0.0343],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0003,     0.0001,     0.9048,     0.0342,     0.0607],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0011,     0.0013,     0.0002,     0.6781,     0.3192],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0023, 0.0044, 0.0567, 0.2744, 0.6622], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.0234327598126
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00496453228890914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.10028881104381
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.96498972339389
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.8987126642844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.87560225
siam score:  -0.8760872
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.813]
 [33.657]
 [40.676]
 [22.62 ]
 [33.657]] [[0.807]
 [0.8  ]
 [1.118]
 [0.3  ]
 [0.8  ]]
printing an ep nov before normalisation:  47.94257640838623
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.692]
 [44.692]
 [46.345]
 [45.924]
 [44.425]] [[1.472]
 [1.472]
 [1.569]
 [1.544]
 [1.456]]
printing an ep nov before normalisation:  37.4920265586058
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.756]
 [36.756]
 [36.756]
 [36.756]
 [36.756]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.74270817179747
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.933075613506745
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.83538762370789
printing an ep nov before normalisation:  28.92482280731201
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  36.506428718566895
printing an ep nov before normalisation:  53.04065732527963
printing an ep nov before normalisation:  42.342302191095634
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.82529129911513
printing an ep nov before normalisation:  46.672627287618766
siam score:  -0.87795633
printing an ep nov before normalisation:  64.55604596118035
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8775357
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.040145874023438
siam score:  -0.87744
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.343]
 [28.423]
 [37.507]
 [31.632]
 [28.822]] [[1.311]
 [0.889]
 [1.442]
 [1.085]
 [0.914]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.836717157132206
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.278]
 [56.201]
 [55.207]
 [55.911]
 [56.023]] [[2.   ]
 [1.996]
 [1.951]
 [1.983]
 [1.988]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.056]
 [38.933]
 [31.561]
 [33.647]
 [37.177]] [[1.193]
 [1.119]
 [0.629]
 [0.767]
 [1.002]]
printing an ep nov before normalisation:  38.75809127084359
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.646690916405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.775]
 [39.775]
 [44.057]
 [39.775]
 [39.775]] [[0.955]
 [0.955]
 [1.115]
 [0.955]
 [0.955]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.75168751066882
printing an ep nov before normalisation:  36.41152201583179
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.388]
 [23.699]
 [26.399]
 [26.286]
 [23.619]] [[0.584]
 [0.598]
 [0.719]
 [0.714]
 [0.594]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.704655141357804
siam score:  -0.8795316
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.76637335948999
printing an ep nov before normalisation:  34.57483768463135
printing an ep nov before normalisation:  42.68766004822599
printing an ep nov before normalisation:  40.57871170674762
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.55392163304157
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.69039202280812
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.633]
 [37.633]
 [42.485]
 [37.633]
 [34.76 ]] [[1.071]
 [1.071]
 [1.336]
 [1.071]
 [0.915]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.497041629177126
printing an ep nov before normalisation:  43.75314235687256
printing an ep nov before normalisation:  30.412638804779455
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.912]
 [32.016]
 [43.285]
 [33.029]
 [32.794]] [[1.14 ]
 [0.816]
 [1.436]
 [0.872]
 [0.859]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.882]
 [46.504]
 [48.882]
 [48.882]
 [49.574]] [[1.764]
 [1.632]
 [1.764]
 [1.764]
 [1.803]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.73 ]
 [28.511]
 [32.353]
 [30.04 ]
 [29.827]] [[1.01 ]
 [1.081]
 [1.429]
 [1.22 ]
 [1.2  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.814]
 [37.273]
 [35.599]
 [35.493]
 [35.35 ]] [[1.498]
 [1.391]
 [1.275]
 [1.268]
 [1.258]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.85827526771267
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  74.95614983944932
line 256 mcts: sample exp_bonus 47.86151942690472
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.4827905854225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9975,     0.0003,     0.0000,     0.0004,     0.0018],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9996,     0.0001,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0004,     0.9544,     0.0123,     0.0328],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0009, 0.0011, 0.0910, 0.6775, 0.2295], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0010, 0.0014, 0.1187, 0.2647, 0.6142], grad_fn=<DivBackward0>)
siam score:  -0.8747543
printing an ep nov before normalisation:  68.67414987520785
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.131384084752444
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8763601
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.575862863822046
printing an ep nov before normalisation:  34.16923981968282
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87542796
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9983,     0.0001,     0.0001,     0.0005,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9670,     0.0009,     0.0002,     0.0317],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0078,     0.9018,     0.0407,     0.0497],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0022,     0.0003,     0.0965,     0.6175,     0.2835],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0034, 0.0161, 0.0465, 0.2959, 0.6382], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.706]
 [51.249]
 [51.249]
 [50.732]
 [51.249]] [[1.667]
 [1.595]
 [1.595]
 [1.569]
 [1.595]]
printing an ep nov before normalisation:  0.02780455413812888
printing an ep nov before normalisation:  45.77152158547774
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.538]
 [44.581]
 [47.917]
 [45.338]
 [42.782]] [[0.566]
 [0.784]
 [0.887]
 [0.807]
 [0.728]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.015024532267645
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.09556053115657
printing an ep nov before normalisation:  32.73861547131018
printing an ep nov before normalisation:  33.72153007055991
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.533130974932597
actions average: 
K:  3  action  0 :  tensor([    0.9976,     0.0001,     0.0002,     0.0008,     0.0013],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9940,     0.0005,     0.0012,     0.0041],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0003,     0.9309,     0.0008,     0.0680],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0017,     0.0465,     0.6629,     0.2886],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0014, 0.0251, 0.0829, 0.2241, 0.6666], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9949,     0.0001,     0.0002,     0.0004,     0.0044],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9973,     0.0005,     0.0002,     0.0020],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0067,     0.0004,     0.9177,     0.0266,     0.0486],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0003,     0.0009,     0.7704,     0.2279],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0048, 0.0184, 0.0271, 0.3295, 0.6202], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 50.632385092795
siam score:  -0.87185496
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.749370519960948
printing an ep nov before normalisation:  47.80226843921877
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.07077636760686
printing an ep nov before normalisation:  31.21206623812651
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.02 ]
 [0.027]
 [0.025]
 [0.022]
 [0.026]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  45.22618616691027
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9955,     0.0004,     0.0033,     0.0001,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9949,     0.0014,     0.0007,     0.0029],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0002,     0.9664,     0.0157,     0.0176],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0017,     0.0005,     0.0816,     0.6096,     0.3067],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0246, 0.0414, 0.0903, 0.2520, 0.5917], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  46.136131286621094
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.356]
 [42.594]
 [35.356]
 [35.356]
 [36.481]] [[0.609]
 [0.847]
 [0.609]
 [0.609]
 [0.646]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.28600395019567
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.555]
 [88.481]
 [89.974]
 [90.811]
 [91.112]] [[1.186]
 [1.467]
 [1.502]
 [1.522]
 [1.529]]
printing an ep nov before normalisation:  51.969667299070665
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.478]
 [31.564]
 [33.821]
 [23.797]
 [28.276]] [[0.797]
 [0.967]
 [1.091]
 [0.54 ]
 [0.786]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.071]
 [28.071]
 [28.071]
 [28.071]
 [28.071]] [[0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]]
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.9743258781105
printing an ep nov before normalisation:  45.031023465201805
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87749726
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.30524758574053
printing an ep nov before normalisation:  31.45006852732227
actions average: 
K:  1  action  0 :  tensor([    0.9755,     0.0063,     0.0021,     0.0004,     0.0157],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9291,     0.0464,     0.0196,     0.0046],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0178,     0.8633,     0.0408,     0.0779],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0003,     0.0309,     0.7330,     0.2356],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0014, 0.0007, 0.1063, 0.3473, 0.5442], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  0.0011814062109546546
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.502]
 [37.502]
 [42.556]
 [40.005]
 [40.247]] [[0.402]
 [0.402]
 [0.506]
 [0.454]
 [0.459]]
line 256 mcts: sample exp_bonus 83.97472731940388
line 256 mcts: sample exp_bonus 38.544473956067925
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0010,     0.9777,     0.0003,     0.0006,     0.0205],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9369,     0.0351,     0.0279],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0004,     0.0017,     0.0322,     0.7271,     0.2386],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0054, 0.0241, 0.1364, 0.2862, 0.5479], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.87730813
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.623]
 [40.761]
 [50.635]
 [50.635]
 [50.635]] [[1.529]
 [1.185]
 [1.472]
 [1.472]
 [1.472]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.181]
 [33.391]
 [43.445]
 [32.315]
 [32.585]] [[0.9  ]
 [0.562]
 [0.877]
 [0.529]
 [0.537]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.647]
 [33.391]
 [42.72 ]
 [41.313]
 [33.275]] [[0.86 ]
 [0.548]
 [0.832]
 [0.789]
 [0.544]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.248634122948715
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.77900739845711
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.421]
 [40.602]
 [22.729]
 [27.309]
 [27.309]] [[0.887]
 [0.577]
 [0.204]
 [0.3  ]
 [0.3  ]]
printing an ep nov before normalisation:  43.27652183511635
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.00377974993772
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.44388879514653
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.15360364290536
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.41345834732056
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.63604991837315
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.77170016953412
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.376]
 [45.376]
 [51.464]
 [45.376]
 [45.376]] [[1.478]
 [1.478]
 [1.796]
 [1.478]
 [1.478]]
siam score:  -0.8774515
printing an ep nov before normalisation:  48.30335421557758
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.88001925
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actor:  1 policy actor:  1  step number:  109 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.8754151
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.14 ]
 [47.14 ]
 [52.91 ]
 [54.338]
 [52.962]] [[1.227]
 [1.227]
 [1.513]
 [1.584]
 [1.516]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  58.06640291504621
printing an ep nov before normalisation:  41.71060438830639
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  56.88801865839297
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
UNIT TEST: sample policy line 217 mcts : [0.026 0.051 0.462 0.231 0.231]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.515]
 [40.515]
 [40.596]
 [40.515]
 [42.407]] [[1.764]
 [1.764]
 [1.77 ]
 [1.764]
 [1.9  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  33.81792068481445
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.58218430589343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  50.11795950202832
using explorer policy with actor:  1
printing an ep nov before normalisation:  62.904455378748104
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.79084641377365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  45.638515743469156
printing an ep nov before normalisation:  37.78920148175441
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
UNIT TEST: sample policy line 217 mcts : [0.564 0.256 0.051 0.051 0.077]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.702]
 [49.702]
 [71.132]
 [49.702]
 [49.702]] [[0.583]
 [0.583]
 [1.061]
 [0.583]
 [0.583]]
printing an ep nov before normalisation:  49.149757622874866
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.096199723177165
printing an ep nov before normalisation:  67.90130579364569
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.28449726104736
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.524]
 [31.311]
 [36.588]
 [28.55 ]
 [30.034]] [[1.172]
 [0.866]
 [1.126]
 [0.73 ]
 [0.803]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.345]
 [27.231]
 [26.328]
 [24.194]
 [24.686]] [[1.255]
 [0.666]
 [0.622]
 [0.518]
 [0.542]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.169]
 [31.69 ]
 [34.514]
 [33.723]
 [33.195]] [[0.928]
 [1.326]
 [1.445]
 [1.411]
 [1.389]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  4  action  0 :  tensor([    0.9715,     0.0024,     0.0007,     0.0099,     0.0154],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9957,     0.0000,     0.0032,     0.0011],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0017, 0.0286, 0.9260, 0.0011, 0.0427], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0003,     0.0283,     0.7591,     0.2122],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0128,     0.0004,     0.1327,     0.2910,     0.5630],
       grad_fn=<DivBackward0>)
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.1  ]
 [41.1  ]
 [56.247]
 [41.1  ]
 [41.1  ]] [[0.883]
 [0.883]
 [1.502]
 [0.883]
 [0.883]]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  69.32022054251836
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.217]
 [26.027]
 [34.461]
 [34.878]
 [36.575]] [[1.696]
 [1.098]
 [1.454]
 [1.471]
 [1.543]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  47.63351519413249
printing an ep nov before normalisation:  65.38933435396943
actions average: 
K:  3  action  0 :  tensor([    0.9909,     0.0004,     0.0000,     0.0036,     0.0051],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0013, 0.9157, 0.0020, 0.0017, 0.0793], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0003,     0.0261,     0.8599,     0.0401,     0.0737],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0003,     0.0186,     0.7041,     0.2766],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0010, 0.0008, 0.0884, 0.3204, 0.5893], grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.272]
 [36.612]
 [32.526]
 [30.481]
 [29.469]] [[1.   ]
 [0.97 ]
 [0.783]
 [0.689]
 [0.642]]
printing an ep nov before normalisation:  30.231185766416445
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  37.98655036029464
siam score:  -0.84830636
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.39 ]
 [38.39 ]
 [34.335]
 [37.786]
 [38.39 ]] [[1.713]
 [1.713]
 [1.436]
 [1.672]
 [1.713]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.999]
 [46.797]
 [45.999]
 [46.191]
 [45.254]] [[1.952]
 [2.   ]
 [1.952]
 [1.963]
 [1.906]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  40.855330684008464
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.850199
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.344]
 [46.344]
 [46.344]
 [46.344]
 [46.344]] [[1.724]
 [1.724]
 [1.724]
 [1.724]
 [1.724]]
using explorer policy with actor:  1
siam score:  -0.8456175
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.395]
 [45.395]
 [67.276]
 [65.281]
 [45.395]] [[0.978]
 [0.978]
 [1.62 ]
 [1.561]
 [0.978]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.868]
 [30.868]
 [39.348]
 [30.868]
 [30.868]] [[0.657]
 [0.657]
 [1.   ]
 [0.657]
 [0.657]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  48.85132616493519
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.201]
 [42.945]
 [44.783]
 [42.945]
 [42.945]] [[1.575]
 [1.403]
 [1.463]
 [1.403]
 [1.403]]
printing an ep nov before normalisation:  32.74892330169678
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[35.722]
 [35.722]
 [35.722]
 [35.722]
 [35.722]] [[1.946]
 [1.946]
 [1.946]
 [1.946]
 [1.946]]
siam score:  -0.84198326
siam score:  -0.84327924
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  57.11723821636188
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.14683910062506
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.11715727900539
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.51067524209329
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.43630600997646
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  0  action  0 :  tensor([    0.9996,     0.0001,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0008,     0.9842,     0.0004,     0.0009,     0.0137],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.9157,     0.0338,     0.0504],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0051,     0.0640,     0.6669,     0.2635],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0020,     0.0006,     0.0228,     0.2912,     0.6834],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[38.398]
 [37.338]
 [37.338]
 [37.338]
 [37.338]] [[1.151]
 [1.084]
 [1.084]
 [1.084]
 [1.084]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  27.875308012854866
printing an ep nov before normalisation:  32.308814469257605
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 20.98963689804077
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
siam score:  -0.851762
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.73702096939087
line 256 mcts: sample exp_bonus 24.20129081418617
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  49.87621005166432
printing an ep nov before normalisation:  66.27151278339191
using another actor
printing an ep nov before normalisation:  20.241640009585268
siam score:  -0.8592798
printing an ep nov before normalisation:  35.63078363581988
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.58714793674741
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  62.55448131267789
using explorer policy with actor:  1
using explorer policy with actor:  1
siam score:  -0.84589994
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.578]
 [42.57 ]
 [59.675]
 [43.206]
 [50.315]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  44.49923101187828
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.   ]
 [0.   ]
 [0.001]] [[38.672]
 [47.087]
 [37.682]
 [37.682]
 [38.568]] [[1.233]
 [1.743]
 [1.173]
 [1.173]
 [1.227]]
siam score:  -0.86526793
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  74.08842220909416
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  55.13214783340709
printing an ep nov before normalisation:  34.84670648630678
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.549941539764404
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.85383224
printing an ep nov before normalisation:  57.64609897564932
printing an ep nov before normalisation:  38.533328877244024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  58.46177412306434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  40.942321188104906
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  58.38108775994057
maxi score, test score, baseline:  0.0001 0.0 0.0001
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
siam score:  -0.86471725
using explorer policy with actor:  0
printing an ep nov before normalisation:  44.25101515581275
using another actor
printing an ep nov before normalisation:  45.58803008091929
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  20.41431188583374
siam score:  -0.86234343
printing an ep nov before normalisation:  47.236550102591174
actions average: 
K:  1  action  0 :  tensor([    0.9954,     0.0005,     0.0020,     0.0001,     0.0019],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0009,     0.9525,     0.0027,     0.0007,     0.0431],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9406,     0.0298,     0.0296],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0008, 0.0010, 0.0255, 0.6769, 0.2958], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0010,     0.0004,     0.0533,     0.3476,     0.5977],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  30.826831349041292
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.44434529701219
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  35.708078926208664
line 256 mcts: sample exp_bonus 31.221118139194918
printing an ep nov before normalisation:  37.83273226881979
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  38.369240204295494
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  29.126470518801618
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.85049653
printing an ep nov before normalisation:  38.48708273982247
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 19.67630159854889
printing an ep nov before normalisation:  49.98827453189861
siam score:  -0.85122526
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  1  action  0 :  tensor([    0.9904,     0.0050,     0.0000,     0.0001,     0.0045],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0005,     0.9433,     0.0017,     0.0000,     0.0545],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0000,     0.9056,     0.0506,     0.0435],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0009, 0.0147, 0.0252, 0.6826, 0.2766], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0021, 0.0060, 0.0614, 0.4334, 0.4971], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  50.94543853560117
using explorer policy with actor:  1
siam score:  -0.8505385
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.001]] [[34.39 ]
 [48.065]
 [43.05 ]
 [36.033]
 [36.59 ]] [[0.329]
 [1.06 ]
 [0.792]
 [0.417]
 [0.447]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  60.80396816013335
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  40.644642592263
printing an ep nov before normalisation:  46.620592876554966
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.96134512559092
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.   ]
 [0.006]] [[48.565]
 [48.565]
 [48.565]
 [48.255]
 [45.448]] [[1.786]
 [1.786]
 [1.786]
 [1.769]
 [1.672]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.85705215
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  43.78108024597168
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.827]
 [40.827]
 [50.098]
 [55.116]
 [54.214]] [[0.693]
 [0.693]
 [1.214]
 [1.496]
 [1.445]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 56.75245161802903
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  72.09851831680128
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 35.00724208519124
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.233]
 [35.245]
 [35.245]
 [37.484]
 [37.214]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  45.31273756774862
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  0  action  0 :  tensor([    0.9993,     0.0001,     0.0000,     0.0004,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0010,     0.9839,     0.0009,     0.0021,     0.0122],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.8752,     0.0526,     0.0720],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0019, 0.0007, 0.0426, 0.6575, 0.2973], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0244, 0.0088, 0.0501, 0.3244, 0.5923], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  65.16308272486609
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.962]
 [61.962]
 [78.864]
 [66.548]
 [65.425]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  0
printing an ep nov before normalisation:  40.24778136353313
printing an ep nov before normalisation:  39.01811844950559
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.972]
 [34.143]
 [40.972]
 [43.523]
 [40.972]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.231]
 [42.062]
 [47.164]
 [44.985]
 [45.964]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.845]
 [29.845]
 [49.351]
 [33.145]
 [33.698]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 40.196730842357724
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.508]
 [35.435]
 [35.435]
 [35.435]
 [35.435]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  22.86484785271876
printing an ep nov before normalisation:  34.52802008366427
printing an ep nov before normalisation:  41.937702605655886
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.198]
 [42.771]
 [37.198]
 [37.198]
 [37.198]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  24.206742115984863
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.516]
 [25.028]
 [25.812]
 [27.755]
 [26.54 ]] [[0.265]
 [0.255]
 [0.271]
 [0.31 ]
 [0.286]]
printing an ep nov before normalisation:  23.12771387293574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  43.62556329958725
printing an ep nov before normalisation:  43.211068061371165
printing an ep nov before normalisation:  37.24059698770748
printing an ep nov before normalisation:  50.66952242713313
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.02]
 [49.02]
 [49.02]
 [49.02]
 [49.02]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  34.07126600786846
printing an ep nov before normalisation:  32.034785293266665
printing an ep nov before normalisation:  44.91972963177909
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  26.751972006817386
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  37.813994465272096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.198]
 [32.198]
 [32.198]
 [36.496]
 [32.198]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  56.252406472512945
printing an ep nov before normalisation:  52.72212782105848
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
printing an ep nov before normalisation:  49.567698637700275
printing an ep nov before normalisation:  38.043943367534
printing an ep nov before normalisation:  37.16322171508381
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  114.40395936540635
printing an ep nov before normalisation:  38.68300518295258
printing an ep nov before normalisation:  33.79351938733336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  35.75309545269248
printing an ep nov before normalisation:  29.523553895740907
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.652]
 [50.5  ]
 [50.5  ]
 [55.04 ]
 [50.5  ]] [[0.957]
 [0.632]
 [0.632]
 [0.736]
 [0.632]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.849077
siam score:  -0.8491594
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.027]
 [33.373]
 [33.373]
 [33.373]
 [33.169]] [[1.516]
 [1.248]
 [1.248]
 [1.248]
 [1.233]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  50.6672424675515
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  43.47614951313566
printing an ep nov before normalisation:  48.1399341139084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[50.213]
 [44.768]
 [44.768]
 [49.441]
 [44.768]] [[1.629]
 [1.299]
 [1.299]
 [1.582]
 [1.299]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[42.265]
 [38.35 ]
 [37.902]
 [37.902]
 [38.092]] [[1.464]
 [1.245]
 [1.22 ]
 [1.22 ]
 [1.23 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.001]
 [0.   ]
 [0.   ]] [[68.663]
 [68.663]
 [71.186]
 [68.663]
 [72.484]] [[1.215]
 [1.215]
 [1.284]
 [1.215]
 [1.32 ]]
printing an ep nov before normalisation:  49.77131813508413
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  33.01240300488353
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[27.651]
 [33.976]
 [31.986]
 [33.976]
 [34.262]] [[1.171]
 [1.814]
 [1.612]
 [1.814]
 [1.843]]
printing an ep nov before normalisation:  37.6524019241333
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.63873854425066
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  60.19811975143965
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  49.33396808885134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.684]
 [53.229]
 [53.229]
 [53.229]
 [53.229]] [[1.926]
 [1.422]
 [1.422]
 [1.422]
 [1.422]]
printing an ep nov before normalisation:  56.85683341502974
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  30.68098595943698
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.95593737277388
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[36.054]
 [40.729]
 [43.723]
 [42.292]
 [42.428]] [[1.365]
 [1.676]
 [1.876]
 [1.781]
 [1.79 ]]
printing an ep nov before normalisation:  41.12764591971459
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.88227759451572
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  56.37833848889473
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[36.298]
 [38.216]
 [35.097]
 [37.327]
 [38.341]] [[1.605]
 [1.761]
 [1.507]
 [1.688]
 [1.771]]
printing an ep nov before normalisation:  2.3429456632584333e-05
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.57039530486535
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  45.20249874622399
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.242]
 [41.738]
 [31.582]
 [33.651]
 [39.366]] [[0.625]
 [0.544]
 [0.309]
 [0.357]
 [0.489]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.8605263
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  1  action  0 :  tensor([    0.9717,     0.0070,     0.0000,     0.0000,     0.0212],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0008,     0.9901,     0.0003,     0.0000,     0.0088],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0003,     0.0031,     0.8820,     0.0442,     0.0704],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0010, 0.0011, 0.0435, 0.7112, 0.2432], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0068, 0.0202, 0.0356, 0.3146, 0.6228], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.52 ]
 [49.037]
 [43.529]
 [55.   ]
 [53.716]] [[1.411]
 [1.192]
 [0.973]
 [1.43 ]
 [1.379]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.41 ]
 [44.843]
 [38.088]
 [38.088]
 [44.765]] [[1.398]
 [1.381]
 [1.173]
 [1.173]
 [1.379]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  34.45795793332261
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.36228275299072
siam score:  -0.8625398
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  38.47359878164462
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.85187792778015
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.343]
 [49.343]
 [46.133]
 [49.343]
 [49.343]] [[1.718]
 [1.718]
 [1.606]
 [1.718]
 [1.718]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  41.931124747053886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8602821
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  44.70198732989642
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  43.73232373944555
printing an ep nov before normalisation:  22.277591665743106
actions average: 
K:  3  action  0 :  tensor([    0.9938,     0.0001,     0.0000,     0.0023,     0.0037],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0076, 0.9184, 0.0041, 0.0110, 0.0588], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9397,     0.0013,     0.0589],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0005,     0.0006,     0.0324,     0.6853,     0.2812],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0014, 0.0231, 0.1339, 0.1911, 0.6506], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  41.2039075717421
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.219453084404606
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.   ]
 [0.001]] [[53.439]
 [46.307]
 [53.439]
 [52.326]
 [48.019]] [[1.683]
 [1.331]
 [1.683]
 [1.628]
 [1.415]]
printing an ep nov before normalisation:  40.49788475036621
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.435]
 [55.036]
 [55.036]
 [55.036]
 [55.036]] [[2.   ]
 [1.127]
 [1.127]
 [1.127]
 [1.127]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.897647857666016
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.62138438091472
printing an ep nov before normalisation:  36.21905326843262
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  50.827450016035456
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.789]
 [33.789]
 [40.944]
 [33.789]
 [33.789]] [[1.212]
 [1.212]
 [1.656]
 [1.212]
 [1.212]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.589]
 [38.589]
 [38.995]
 [38.589]
 [38.589]] [[0.935]
 [0.935]
 [0.953]
 [0.935]
 [0.935]]
siam score:  -0.85486305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.85527015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  57.46851344780396
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.587]
 [34.595]
 [34.595]
 [34.595]
 [49.262]] [[1.383]
 [1.24 ]
 [1.24 ]
 [1.24 ]
 [1.766]]
printing an ep nov before normalisation:  53.26405707203267
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.166]
 [26.497]
 [26.715]
 [24.138]
 [23.85 ]] [[1.175]
 [0.446]
 [0.453]
 [0.374]
 [0.365]]
printing an ep nov before normalisation:  34.69246864318848
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.05144594872461994
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.565]
 [37.03 ]
 [28.852]
 [29.161]
 [31.255]] [[1.298]
 [0.772]
 [0.454]
 [0.466]
 [0.548]]
line 256 mcts: sample exp_bonus 69.29273746447537
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.465]
 [20.832]
 [20.832]
 [20.832]
 [20.832]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.38606080864731
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  1  action  0 :  tensor([0.9294, 0.0044, 0.0055, 0.0020, 0.0587], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9892,     0.0005,     0.0020,     0.0081],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0003,     0.0006,     0.9685,     0.0038,     0.0268],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0009, 0.0026, 0.0567, 0.6890, 0.2509], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0007, 0.0012, 0.0734, 0.3017, 0.6229], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
using another actor
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  46.641285676843445
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  37.66160726547241
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.84836507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.8471614
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9977,     0.0001,     0.0000,     0.0006,     0.0016],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0011, 0.9425, 0.0012, 0.0084, 0.0469], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0041,     0.9945,     0.0004,     0.0009],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0002,     0.0353,     0.7656,     0.1985],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0007, 0.0014, 0.1133, 0.3065, 0.5781], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  54.75545584181644
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  2  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9759,     0.0014,     0.0003,     0.0223],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0001,     0.9789,     0.0018,     0.0192],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0011,     0.0004,     0.0584,     0.6770,     0.2632],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0009, 0.0006, 0.0442, 0.4028, 0.5515], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.291]
 [50.949]
 [63.163]
 [51.81 ]
 [52.291]] [[1.001]
 [0.953]
 [1.388]
 [0.984]
 [1.001]]
actions average: 
K:  2  action  0 :  tensor([    0.9932,     0.0002,     0.0000,     0.0034,     0.0032],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9989,     0.0001,     0.0002,     0.0006],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0020,     0.0002,     0.9435,     0.0246,     0.0296],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0014,     0.0246,     0.6954,     0.2783],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0009, 0.0018, 0.0668, 0.2205, 0.7100], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.159]
 [26.386]
 [33.073]
 [31.47 ]
 [33.791]] [[1.319]
 [0.845]
 [1.06 ]
 [1.008]
 [1.083]]
printing an ep nov before normalisation:  46.97588922467206
printing an ep nov before normalisation:  77.9737013732038
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  33.212172985076904
printing an ep nov before normalisation:  29.07628147381838
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0004,     0.9528,     0.0035,     0.0001,     0.0431],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9545,     0.0203,     0.0252],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0002,     0.0467,     0.6253,     0.3274],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0022, 0.0118, 0.0408, 0.2864, 0.6588], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.723]
 [54.723]
 [54.723]
 [54.723]
 [54.723]] [[1.879]
 [1.879]
 [1.879]
 [1.879]
 [1.879]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  44.70461222049571
siam score:  -0.86000603
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.745407581329346
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.964561587232296
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.0024815303436298564
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  46.01308490485781
siam score:  -0.8499132
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  55.77337206101455
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.82993755772011
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.035]
 [58.035]
 [58.035]
 [58.035]
 [58.035]] [[0.581]
 [0.581]
 [0.581]
 [0.581]
 [0.581]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.692]
 [39.781]
 [34.934]
 [35.682]
 [34.51 ]] [[0.326]
 [0.235]
 [0.185]
 [0.193]
 [0.181]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
printing an ep nov before normalisation:  26.89615488052368
printing an ep nov before normalisation:  42.356146066683856
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  37.15422918069644
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.329]
 [38.329]
 [38.329]
 [39.146]
 [38.329]] [[1.724]
 [1.724]
 [1.724]
 [1.781]
 [1.724]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.942]
 [31.462]
 [27.841]
 [27.841]
 [27.841]] [[1.423]
 [1.21 ]
 [0.901]
 [0.901]
 [0.901]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.8488022
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.725]
 [55.592]
 [53.369]
 [39.645]
 [48.545]] [[1.212]
 [1.041]
 [0.967]
 [0.51 ]
 [0.806]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  79.2362750633957
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.541]
 [48.541]
 [48.541]
 [48.541]
 [48.541]] [[1.669]
 [1.669]
 [1.669]
 [1.669]
 [1.669]]
using another actor
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.744]
 [35.744]
 [35.744]
 [35.744]
 [35.744]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  29.99947380685981
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.5858225738612
siam score:  -0.8475871
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  16.295128696259738
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 29.177698793512445
printing an ep nov before normalisation:  0.026229418381262803
actions average: 
K:  3  action  0 :  tensor([    0.9983,     0.0000,     0.0007,     0.0007,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9978,     0.0001,     0.0009,     0.0012],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0007,     0.0025,     0.9267,     0.0208,     0.0493],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0018, 0.0019, 0.0509, 0.6797, 0.2657], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0385, 0.0030, 0.0017, 0.3142, 0.6426], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  46.87632317533619
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  26.847338676452637
printing an ep nov before normalisation:  27.919679117110995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  30.893859650110727
printing an ep nov before normalisation:  28.412735487834425
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  67.06505185207642
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  54.383057775448734
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  38.46965460971266
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  46.733859189333344
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  0.0032575785098742926
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  34.452670279275104
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  26.208253867488725
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  66.72177918989978
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.001]] [[44.945]
 [37.5  ]
 [37.5  ]
 [37.5  ]
 [47.083]] [[1.374]
 [0.92 ]
 [0.92 ]
 [0.92 ]
 [1.505]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.   ]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
printing an ep nov before normalisation:  50.398010655447415
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  41.73024027846693
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 52.37716359790537
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 35.87957140560909
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  45.19618822815805
printing an ep nov before normalisation:  60.859401144738825
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0013, 0.9580, 0.0076, 0.0016, 0.0315], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0022,     0.0003,     0.9423,     0.0191,     0.0361],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0006,     0.0027,     0.0278,     0.7443,     0.2245],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0020, 0.0018, 0.0880, 0.3330, 0.5752], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  72.32253099925555
printing an ep nov before normalisation:  49.41475263195989
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  23.045307918226584
printing an ep nov before normalisation:  56.7946524464726
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.001]] [[54.747]
 [54.747]
 [54.747]
 [56.746]
 [54.229]] [[1.703]
 [1.703]
 [1.703]
 [1.802]
 [1.678]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  58.26367481012358
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  95.62331729632854
printing an ep nov before normalisation:  46.15200159459254
printing an ep nov before normalisation:  33.98349269470245
siam score:  -0.8631131
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[99.85]
 [99.85]
 [99.85]
 [99.85]
 [99.85]] [[1.645]
 [1.645]
 [1.645]
 [1.645]
 [1.645]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.151]
 [36.151]
 [36.151]
 [36.151]
 [36.151]] [[1.443]
 [1.443]
 [1.443]
 [1.443]
 [1.443]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  56.13287142795682
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  30.359852043314913
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  75.61951620548331
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  52.90471556153238
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.25166320800781
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[44.14 ]
 [48.056]
 [41.938]
 [44.447]
 [43.311]] [[1.137]
 [1.345]
 [1.021]
 [1.153]
 [1.093]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  1  action  0 :  tensor([0.9682, 0.0121, 0.0029, 0.0015, 0.0152], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0006,     0.9222,     0.0023,     0.0343,     0.0406],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0061,     0.0003,     0.8703,     0.0343,     0.0891],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0008,     0.0005,     0.1275,     0.5578,     0.3135],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0184, 0.0365, 0.0604, 0.2250, 0.6596], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  35.561845530034375
printing an ep nov before normalisation:  32.98929928850726
actions average: 
K:  0  action  0 :  tensor([    0.9741,     0.0003,     0.0044,     0.0059,     0.0152],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0117, 0.9114, 0.0085, 0.0014, 0.0670], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9656,     0.0007,     0.0337],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0007, 0.0007, 0.0405, 0.6980, 0.2600], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0009, 0.0185, 0.0684, 0.2796, 0.6327], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  48.00200540512997
using another actor
printing an ep nov before normalisation:  74.08400674431462
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  44.716336854327565
using explorer policy with actor:  0
printing an ep nov before normalisation:  55.08426743720847
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.8574289
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[74.335]
 [74.335]
 [74.335]
 [74.335]
 [74.335]] [[2.001]
 [2.001]
 [2.001]
 [2.001]
 [2.001]]
printing an ep nov before normalisation:  48.00065986180154
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  44.464810946606995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9978,     0.0009,     0.0000,     0.0002,     0.0012],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9151,     0.0137,     0.0015,     0.0694],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0004,     0.8576,     0.0516,     0.0903],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0005,     0.0401,     0.7273,     0.2318],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0009, 0.0136, 0.0601, 0.3008, 0.6246], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  52.680794669709776
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  33.65406424468105
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 43.08976768726573
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  53.23296522697126
printing an ep nov before normalisation:  47.88277376125177
actions average: 
K:  1  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0044,     0.9838,     0.0003,     0.0062,     0.0054],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0004,     0.0071,     0.8790,     0.0495,     0.0640],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0008, 0.0006, 0.0654, 0.6390, 0.2941], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0683, 0.0479, 0.0491, 0.3309, 0.5038], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  89.62107441669542
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  4  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9714,     0.0006,     0.0005,     0.0273],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0006,     0.0004,     0.8994,     0.0254,     0.0742],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0087, 0.0186, 0.0166, 0.6397, 0.3164], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0644, 0.0232, 0.1136, 0.3052, 0.4936], grad_fn=<DivBackward0>)
actions average: 
K:  0  action  0 :  tensor([    0.9975,     0.0004,     0.0005,     0.0003,     0.0014],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9965,     0.0002,     0.0005,     0.0027],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0000,     0.9531,     0.0234,     0.0234],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0007,     0.0003,     0.0166,     0.7264,     0.2559],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0062, 0.0680, 0.0188, 0.2668, 0.6402], grad_fn=<DivBackward0>)
siam score:  -0.85909635
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  46.95226457702209
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.84733766
siam score:  -0.8478533
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.97]
 [48.97]
 [48.97]
 [48.97]
 [48.97]] [[1.761]
 [1.761]
 [1.761]
 [1.761]
 [1.761]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.051]
 [42.051]
 [67.548]
 [42.051]
 [42.051]] [[0.728]
 [0.728]
 [1.428]
 [0.728]
 [0.728]]
printing an ep nov before normalisation:  88.42537888668383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.001]
 [0.   ]
 [0.   ]] [[93.043]
 [93.043]
 [68.288]
 [93.509]
 [92.505]] [[1.758]
 [1.758]
 [1.184]
 [1.769]
 [1.746]]
printing an ep nov before normalisation:  46.73187418786668
line 256 mcts: sample exp_bonus 42.75636257624024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  4  action  0 :  tensor([    0.9984,     0.0000,     0.0000,     0.0007,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9995,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0006,     0.0240,     0.9114,     0.0147,     0.0492],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0037, 0.0013, 0.0732, 0.7349, 0.1869], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0512, 0.0427, 0.0337, 0.1967, 0.6757], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  34.54927309676641
printing an ep nov before normalisation:  64.12183314576552
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.8577251
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  51.50046361058031
printing an ep nov before normalisation:  40.45257091522217
printing an ep nov before normalisation:  64.36146443976601
printing an ep nov before normalisation:  30.4477858543396
line 256 mcts: sample exp_bonus 60.09190288914333
printing an ep nov before normalisation:  48.59631074921495
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.811]
 [42.51 ]
 [40.195]
 [59.154]
 [54.299]] [[1.33 ]
 [0.746]
 [0.664]
 [1.343]
 [1.169]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  41.26796906420422
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.718 0.154 0.026 0.026 0.077]
siam score:  -0.8486049
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  55.02876399675452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.88704548036233
printing an ep nov before normalisation:  67.35710843595784
printing an ep nov before normalisation:  22.870296514839804
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  50.5483551037496
using another actor
line 256 mcts: sample exp_bonus 30.637868285179138
line 256 mcts: sample exp_bonus 2.556793511654263
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.101]
 [45.099]
 [40.341]
 [40.341]
 [40.341]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  50.56415557861328
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.698]
 [38.602]
 [37.698]
 [41.007]
 [36.492]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  30.866994857788086
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.902]
 [49.802]
 [50.667]
 [50.667]
 [50.667]] [[1.389]
 [1.869]
 [1.93 ]
 [1.93 ]
 [1.93 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.295]
 [42.295]
 [42.295]
 [42.295]
 [42.295]] [[1.111]
 [1.111]
 [1.111]
 [1.111]
 [1.111]]
printing an ep nov before normalisation:  54.09415997592961
printing an ep nov before normalisation:  47.76664592422413
printing an ep nov before normalisation:  34.66534495104593
printing an ep nov before normalisation:  28.210222721099854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  29.969105039691176
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.759904229856005
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.043541431427002
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.398]
 [36.398]
 [64.084]
 [63.576]
 [36.398]] [[0.432]
 [0.432]
 [1.058]
 [1.047]
 [0.432]]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  25.076342899642977
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  2  action  0 :  tensor([    0.9598,     0.0111,     0.0001,     0.0067,     0.0223],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9093,     0.0412,     0.0003,     0.0491],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0180,     0.9342,     0.0155,     0.0321],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0010,     0.0825,     0.6553,     0.2611],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0265, 0.0187, 0.0569, 0.2919, 0.6060], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  41.850084574505466
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.750616955615687
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 29.81996937101203
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.37009048461914
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  1  action  0 :  tensor([    0.9994,     0.0001,     0.0000,     0.0001,     0.0004],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0056, 0.9660, 0.0040, 0.0053, 0.0190], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0015, 0.0035, 0.9091, 0.0164, 0.0695], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0048,     0.0443,     0.7990,     0.1511],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0131, 0.0190, 0.0434, 0.2898, 0.6347], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  55.335185310051344
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  29.69715679652801
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.   ]
 [0.   ]
 [0.001]] [[44.46 ]
 [49.211]
 [47.484]
 [42.538]
 [50.01 ]] [[1.269]
 [1.579]
 [1.466]
 [1.144]
 [1.631]]
printing an ep nov before normalisation:  68.78698706837439
printing an ep nov before normalisation:  53.94368085410302
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.898]
 [36.256]
 [35.553]
 [39.101]
 [36.462]] [[1.697]
 [1.731]
 [1.664]
 [2.   ]
 [1.75 ]]
siam score:  -0.84233963
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.208]
 [30.567]
 [30.567]
 [30.567]
 [30.567]] [[1.041]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.88 ]]
printing an ep nov before normalisation:  38.88510579020878
actions average: 
K:  2  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9702,     0.0021,     0.0001,     0.0272],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0000,     0.9666,     0.0108,     0.0223],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0137, 0.0034, 0.0135, 0.7341, 0.2353], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0031, 0.0016, 0.1110, 0.1557, 0.7285], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.504]
 [30.748]
 [43.13 ]
 [39.037]
 [37.009]] [[0.764]
 [0.662]
 [0.929]
 [0.84 ]
 [0.797]]
actions average: 
K:  3  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9978,     0.0005,     0.0009,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0144,     0.0003,     0.8604,     0.0545,     0.0704],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0014, 0.0054, 0.0239, 0.7656, 0.2037], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0022, 0.0469, 0.0186, 0.2772, 0.6551], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  41.974311844746744
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  56.54492539491882
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.262]
 [32.88 ]
 [41.664]
 [32.825]
 [29.927]] [[0.594]
 [0.927]
 [1.369]
 [0.924]
 [0.779]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.141]
 [55.141]
 [55.141]
 [56.692]
 [55.141]] [[1.527]
 [1.527]
 [1.527]
 [1.587]
 [1.527]]
siam score:  -0.84286547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  44.484285876135246
siam score:  -0.84438384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.84147155
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  24.53918218612671
printing an ep nov before normalisation:  38.76012325286865
printing an ep nov before normalisation:  47.55110606629962
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.40168494134945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  42.663022014245364
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.66423705709487
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.956]
 [39.664]
 [39.664]
 [39.664]
 [39.664]] [[2.   ]
 [1.552]
 [1.552]
 [1.552]
 [1.552]]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.442140787719076
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.8466802
printing an ep nov before normalisation:  38.964623771933034
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.328071711417138
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.52461905815058
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  3  action  0 :  tensor([    0.9805,     0.0005,     0.0002,     0.0086,     0.0102],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9529,     0.0356,     0.0004,     0.0111],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0014,     0.0005,     0.9072,     0.0253,     0.0656],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0125,     0.0576,     0.7632,     0.1664],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0008, 0.0641, 0.0816, 0.2821, 0.5713], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  49.993359442619045
siam score:  -0.84492093
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  25.135467754042125
printing an ep nov before normalisation:  34.96766274877296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  62.37349199999575
printing an ep nov before normalisation:  36.58933468019636
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.538]
 [42.128]
 [42.128]
 [42.128]
 [42.128]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  32.742375340383084
printing an ep nov before normalisation:  50.14265976452773
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  41.80100097626287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.349]
 [33.349]
 [33.349]
 [33.349]
 [33.349]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  45.590521556036634
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.532]
 [60.532]
 [60.532]
 [60.532]
 [60.532]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  25.25528907775879
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.969]
 [38.969]
 [38.969]
 [38.969]
 [38.969]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.8441265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  56.05117203562465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.406354844729808
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  23.946567507258163
printing an ep nov before normalisation:  44.65807781865508
printing an ep nov before normalisation:  33.84310007095337
printing an ep nov before normalisation:  37.44745199818509
printing an ep nov before normalisation:  34.8095380590177
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.386]
 [31.104]
 [32.386]
 [34.518]
 [33.132]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  27.42565155029297
printing an ep nov before normalisation:  34.670725905674324
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.111]
 [32.111]
 [32.111]
 [32.111]
 [32.111]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.8441765
printing an ep nov before normalisation:  39.65665484207973
line 256 mcts: sample exp_bonus 53.25971431987848
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  1  action  0 :  tensor([    0.9921,     0.0001,     0.0000,     0.0037,     0.0042],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0040,     0.9644,     0.0004,     0.0011,     0.0301],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.9222,     0.0348,     0.0428],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0010, 0.0008, 0.0429, 0.7239, 0.2314], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0447, 0.0714, 0.0926, 0.1306, 0.6607], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.281]
 [45.429]
 [37.281]
 [37.281]
 [37.281]] [[0.824]
 [1.238]
 [0.824]
 [0.824]
 [0.824]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.82 ]
 [32.994]
 [25.82 ]
 [25.82 ]
 [25.82 ]] [[0.517]
 [0.737]
 [0.517]
 [0.517]
 [0.517]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  27.05110073642561
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.04]
 [44.04]
 [44.04]
 [44.04]
 [44.04]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
siam score:  -0.85761863
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
printing an ep nov before normalisation:  39.21854498000078
printing an ep nov before normalisation:  29.652185440063477
printing an ep nov before normalisation:  56.91923684192502
using another actor
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  58.42672177336015
printing an ep nov before normalisation:  26.23999830942317
printing an ep nov before normalisation:  33.542043391054676
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[35.863]
 [44.811]
 [31.855]
 [30.186]
 [33.781]] [[1.2  ]
 [1.499]
 [1.066]
 [1.01 ]
 [1.131]]
printing an ep nov before normalisation:  35.343290834903456
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  22.84863819018859
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.34004252911516
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  21.956210136413574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  27.02856827117205
using another actor
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[20.697]
 [20.697]
 [20.697]
 [20.697]
 [20.697]] [[1.926]
 [1.926]
 [1.926]
 [1.926]
 [1.926]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9888,     0.0007,     0.0000,     0.0056,     0.0049],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9841,     0.0004,     0.0002,     0.0152],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0135,     0.9430,     0.0223,     0.0211],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0011,     0.0004,     0.0698,     0.7525,     0.1762],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0021, 0.0021, 0.0479, 0.3183, 0.6297], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  23.176660704284917
printing an ep nov before normalisation:  45.872596087888915
printing an ep nov before normalisation:  31.539008362625047
printing an ep nov before normalisation:  30.470857879761827
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  36.932588734256875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  63.60785071099964
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.003]
 [0.002]
 [0.003]] [[70.149]
 [59.284]
 [48.333]
 [64.635]
 [62.853]] [[1.513]
 [1.169]
 [0.823]
 [1.339]
 [1.283]]
printing an ep nov before normalisation:  33.85598217397002
printing an ep nov before normalisation:  52.047351945340644
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.007]
 [0.008]] [[22.595]
 [22.595]
 [22.595]
 [28.943]
 [26.264]] [[0.595]
 [0.595]
 [0.595]
 [1.071]
 [0.871]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.8800046
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.930505518260475
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[43.618]
 [48.653]
 [48.653]
 [48.653]
 [48.653]] [[1.608]
 [2.003]
 [2.003]
 [2.003]
 [2.003]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  43.096726203239825
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  49.74674675520213
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[29.713]
 [29.713]
 [29.713]
 [29.885]
 [29.713]] [[1.824]
 [1.824]
 [1.824]
 [1.843]
 [1.824]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  4  action  0 :  tensor([    0.9818,     0.0001,     0.0000,     0.0170,     0.0011],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9955,     0.0003,     0.0006,     0.0035],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0008,     0.0003,     0.9134,     0.0398,     0.0457],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0011, 0.0012, 0.0151, 0.7597, 0.2229], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0343, 0.0024, 0.0287, 0.3258, 0.6088], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[32.326]
 [32.326]
 [32.326]
 [32.326]
 [32.326]] [[1.76]
 [1.76]
 [1.76]
 [1.76]
 [1.76]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  53.878882467715286
siam score:  -0.90415984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  54.283048585779134
printing an ep nov before normalisation:  55.165121874233996
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.19178536305112
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
printing an ep nov before normalisation:  36.3528503871638
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.8994472
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  35.66151619233786
printing an ep nov before normalisation:  25.4466378627173
printing an ep nov before normalisation:  44.09241471333784
printing an ep nov before normalisation:  0.0001741376760833191
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.706662207709496
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[33.649]
 [33.649]
 [61.47 ]
 [33.649]
 [33.649]] [[0.582]
 [0.582]
 [1.495]
 [0.582]
 [0.582]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  26.22237296020011
printing an ep nov before normalisation:  29.494905471801758
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  28.017385933672674
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.5623083114624
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 27.300020990966043
printing an ep nov before normalisation:  50.502152902060296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.9579193415039
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[0.0012],
        [0.0007],
        [0.0011],
        [0.0007],
        [0.0000],
        [0.0007],
        [0.0008],
        [0.0008],
        [0.0008],
        [0.0000]], dtype=torch.float64)
0.0 0.0011588003983047663
0.0 0.0006838181206005512
0.0 0.001058158130294623
0.0 0.0006928263113887727
0.0 0.0
0.0 0.0006742205794787212
0.0 0.0007505079582740098
0.0 0.000763615815698235
0.0 0.0007605840901924599
0.0 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[33.265]
 [25.858]
 [25.858]
 [25.858]
 [25.858]] [[2.001]
 [1.387]
 [1.387]
 [1.387]
 [1.387]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.124]
 [0.124]
 [0.124]
 [0.051]
 [0.124]] [[21.793]
 [21.793]
 [21.793]
 [28.455]
 [21.793]] [[1.232]
 [1.232]
 [1.232]
 [2.051]
 [1.232]]
printing an ep nov before normalisation:  34.59274010797107
printing an ep nov before normalisation:  44.877562376289774
printing an ep nov before normalisation:  44.90938364296838
Printing some Q and Qe and total Qs values:  [[0.062]
 [0.062]
 [0.062]
 [0.062]
 [0.062]] [[43.101]
 [43.101]
 [43.101]
 [43.101]
 [43.101]] [[2.021]
 [2.021]
 [2.021]
 [2.021]
 [2.021]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.63805430793562
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[36.225]
 [36.225]
 [36.225]
 [36.225]
 [36.225]] [[0.883]
 [0.883]
 [0.883]
 [0.883]
 [0.883]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[25.291]
 [30.819]
 [23.545]
 [22.587]
 [30.819]] [[1.334]
 [1.84 ]
 [1.174]
 [1.087]
 [1.84 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.17723032813231
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  72.93513512917808
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.002]
 [0.001]
 [0.001]] [[51.323]
 [51.323]
 [59.716]
 [56.555]
 [59.943]] [[1.45 ]
 [1.45 ]
 [1.79 ]
 [1.662]
 [1.799]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.73611085110578
main train batch thing paused
add a thread
Adding thread: now have 2 threads
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  0.02469122461121742
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[1]
 [1]
 [1]
 [1]
 [1]] [[0]
 [0]
 [0]
 [0]
 [0]] [[1]
 [1]
 [1]
 [1]
 [1]]
printing an ep nov before normalisation:  51.44502112093867
printing an ep nov before normalisation:  66.70170246661316
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.98582246568468
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.89400655
printing an ep nov before normalisation:  66.53588962542503
printing an ep nov before normalisation:  28.40469950438287
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  42.15229034423828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.049005301866092
printing an ep nov before normalisation:  49.43110393543202
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  26.03285789489746
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[43.258]
 [44.348]
 [43.258]
 [47.337]
 [45.484]] [[1.443]
 [1.5  ]
 [1.443]
 [1.655]
 [1.559]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.18720232247595
printing an ep nov before normalisation:  45.1539050583191
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[31.693]
 [31.693]
 [31.693]
 [31.693]
 [31.693]] [[2.001]
 [2.001]
 [2.001]
 [2.001]
 [2.001]]
siam score:  -0.87701905
printing an ep nov before normalisation:  26.36549711227417
printing an ep nov before normalisation:  43.75096393376119
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  38.74904285447152
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[22.793]
 [20.56 ]
 [20.56 ]
 [20.56 ]
 [20.56 ]] [[1.588]
 [1.343]
 [1.343]
 [1.343]
 [1.343]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  33.83012655322146
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.001]
 [0.   ]
 [0.001]] [[24.637]
 [27.639]
 [30.661]
 [24.474]
 [28.643]] [[0.982]
 [1.191]
 [1.403]
 [0.971]
 [1.262]]
printing an ep nov before normalisation:  27.05856223353092
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  40.0643654203418
printing an ep nov before normalisation:  51.79044238294183
printing an ep nov before normalisation:  27.553856372833256
printing an ep nov before normalisation:  42.52510719848311
printing an ep nov before normalisation:  30.77104953340747
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.86933761460718
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  1  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0003,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9482,     0.0005,     0.0003,     0.0507],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0013,     0.0004,     0.9184,     0.0257,     0.0542],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0029,     0.0474,     0.7287,     0.2206],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0020, 0.0307, 0.0032, 0.3143, 0.6498], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  32.115358536673135
printing an ep nov before normalisation:  32.555561372233896
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.001]
 [0.001]
 [0.001]] [[53.098]
 [37.218]
 [32.39 ]
 [38.524]
 [37.611]] [[1.132]
 [0.601]
 [0.44 ]
 [0.645]
 [0.615]]
printing an ep nov before normalisation:  44.05957731996665
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.88455427
printing an ep nov before normalisation:  51.55609248407408
printing an ep nov before normalisation:  32.984018325805664
printing an ep nov before normalisation:  56.06017430214483
printing an ep nov before normalisation:  45.99312294151396
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.888498695758873
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[39.894]
 [45.347]
 [39.894]
 [39.894]
 [39.894]] [[1.143]
 [1.417]
 [1.143]
 [1.143]
 [1.143]]
printing an ep nov before normalisation:  34.270531979446
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[22.293]
 [29.7  ]
 [25.196]
 [24.801]
 [23.312]] [[0.537]
 [0.912]
 [0.684]
 [0.664]
 [0.589]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  30.000784748050837
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.8836087
printing an ep nov before normalisation:  39.83234405517578
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.   ]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  67.50056798361545
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[45.586]
 [45.311]
 [45.815]
 [45.029]
 [43.583]] [[1.175]
 [1.166]
 [1.183]
 [1.157]
 [1.108]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  52.76301426999553
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  26.80100917816162
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  42.832468875638476
printing an ep nov before normalisation:  43.79321918926618
printing an ep nov before normalisation:  59.39497885963333
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  45.40282924910876
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[47.365]
 [38.725]
 [38.725]
 [38.725]
 [38.725]] [[1.519]
 [1.06 ]
 [1.06 ]
 [1.06 ]
 [1.06 ]]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[40.076]
 [43.855]
 [40.076]
 [40.076]
 [40.076]] [[1.455]
 [1.682]
 [1.455]
 [1.455]
 [1.455]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[23.983]
 [23.983]
 [22.968]
 [22.421]
 [23.983]] [[2.004]
 [2.004]
 [1.862]
 [1.785]
 [2.004]]
siam score:  -0.88738036
printing an ep nov before normalisation:  65.0817069623667
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.001]
 [0.003]
 [0.003]
 [0.003]] [[27.099]
 [30.391]
 [33.312]
 [30.529]
 [30.162]] [[0.957]
 [1.177]
 [1.375]
 [1.189]
 [1.164]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[36.172]
 [27.109]
 [27.109]
 [27.109]
 [27.109]] [[1.356]
 [0.805]
 [0.805]
 [0.805]
 [0.805]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[56.598]
 [55.07 ]
 [56.598]
 [56.598]
 [56.598]] [[1.855]
 [1.791]
 [1.855]
 [1.855]
 [1.855]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.706375222541006
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[36.221]
 [36.221]
 [36.221]
 [36.221]
 [36.221]] [[1.381]
 [1.381]
 [1.381]
 [1.381]
 [1.381]]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.96759465707563
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  62.20780852193155
printing an ep nov before normalisation:  39.629485001666595
printing an ep nov before normalisation:  35.62258447400191
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  47.50312805175781
actions average: 
K:  4  action  0 :  tensor([    0.9979,     0.0000,     0.0000,     0.0012,     0.0009],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9836,     0.0022,     0.0003,     0.0137],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0018, 0.0027, 0.9383, 0.0190, 0.0381], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0035, 0.0007, 0.0429, 0.6078, 0.3451], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0030, 0.0796, 0.0938, 0.3062, 0.5174], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  49.67967281868524
printing an ep nov before normalisation:  34.006993628387164
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.   ]
 [0.002]
 [0.003]
 [0.002]] [[42.454]
 [42.705]
 [43.347]
 [45.88 ]
 [39.415]] [[0.58 ]
 [0.585]
 [0.602]
 [0.666]
 [0.505]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 44.950104325719415
printing an ep nov before normalisation:  46.304882379371676
printing an ep nov before normalisation:  34.63679227145204
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  51.92017186532495
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[42.326]
 [40.891]
 [35.113]
 [41.575]
 [45.118]] [[1.486]
 [1.411]
 [1.109]
 [1.447]
 [1.633]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[31.914]
 [31.914]
 [31.914]
 [31.914]
 [31.914]] [[0.328]
 [0.328]
 [0.328]
 [0.328]
 [0.328]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[27.703]
 [29.271]
 [29.271]
 [29.271]
 [29.271]] [[1.133]
 [1.262]
 [1.262]
 [1.262]
 [1.262]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  35.71255751077204
printing an ep nov before normalisation:  29.29617404937744
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.44189587195007
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  48.479156044680266
siam score:  -0.90080965
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[43.057]
 [34.55 ]
 [34.55 ]
 [34.55 ]
 [34.55 ]] [[1.311]
 [0.912]
 [0.912]
 [0.912]
 [0.912]]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.   ]
 [0.001]
 [0.001]] [[27.084]
 [27.071]
 [25.361]
 [24.341]
 [24.341]] [[0.   ]
 [0.   ]
 [0.   ]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[29.397]
 [28.436]
 [35.76 ]
 [28.436]
 [28.436]] [[0.001]
 [0.002]
 [0.002]
 [0.002]
 [0.002]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[28.997]
 [28.997]
 [25.749]
 [23.745]
 [23.819]] [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.63682835257056
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  27.707941191537042
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  62.3571451446445
printing an ep nov before normalisation:  28.961575852814423
printing an ep nov before normalisation:  37.36297130584717
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
printing an ep nov before normalisation:  64.56037584820346
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[56.052]
 [56.052]
 [56.052]
 [56.052]
 [56.052]] [[1.668]
 [1.668]
 [1.668]
 [1.668]
 [1.668]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.12095782305711
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[36.459]
 [29.611]
 [29.611]
 [29.611]
 [29.611]] [[1.516]
 [1.083]
 [1.083]
 [1.083]
 [1.083]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  34.511047095616
printing an ep nov before normalisation:  21.707894802093506
siam score:  -0.90053207
printing an ep nov before normalisation:  31.66875623140017
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.90187025
printing an ep nov before normalisation:  41.99221148381918
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.002]
 [0.   ]
 [0.001]
 [0.001]] [[30.892]
 [48.083]
 [38.983]
 [33.454]
 [35.914]] [[0.426]
 [1.328]
 [0.85 ]
 [0.561]
 [0.69 ]]
printing an ep nov before normalisation:  38.618597984313965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  35.29401779174805
printing an ep nov before normalisation:  42.50033370709159
printing an ep nov before normalisation:  33.095926027709126
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.   ]
 [0.001]
 [0.001]] [[29.991]
 [38.39 ]
 [34.187]
 [29.601]
 [32.208]] [[0.755]
 [1.372]
 [1.063]
 [0.727]
 [0.919]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.001]
 [0.002]
 [0.001]
 [0.001]] [[17.989]
 [24.08 ]
 [22.996]
 [24.08 ]
 [24.08 ]] [[1.172]
 [2.181]
 [2.002]
 [2.181]
 [2.181]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  23.81485939025879
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.434341538915234
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  62.74959749028549
actions average: 
K:  2  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0006,     0.0007],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9981,     0.0001,     0.0005,     0.0013],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0002,     0.9108,     0.0413,     0.0477],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0008, 0.0016, 0.0610, 0.7317, 0.2049], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0019, 0.0690, 0.0807, 0.2539, 0.5944], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.003]
 [0.001]
 [0.001]
 [0.001]] [[35.794]
 [47.39 ]
 [35.794]
 [35.794]
 [35.794]] [[0.885]
 [1.713]
 [0.885]
 [0.885]
 [0.885]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  33.67630267549839
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  53.03949520551298
actions average: 
K:  2  action  0 :  tensor([    0.9990,     0.0000,     0.0000,     0.0003,     0.0007],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9992,     0.0000,     0.0001,     0.0006],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0002,     0.9763,     0.0102,     0.0133],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0031, 0.0010, 0.0586, 0.6170, 0.3203], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0029, 0.0438, 0.1359, 0.3214, 0.4961], grad_fn=<DivBackward0>)
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[39.081]
 [39.081]
 [39.081]
 [39.048]
 [39.081]] [[1.617]
 [1.617]
 [1.617]
 [1.615]
 [1.617]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[32.558]
 [42.65 ]
 [32.558]
 [32.558]
 [38.601]] [[0.778]
 [1.247]
 [0.778]
 [0.778]
 [1.059]]
printing an ep nov before normalisation:  34.59958852269993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  54.05174711819581
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.524824073050542
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.04879273238887
printing an ep nov before normalisation:  53.25948987330364
printing an ep nov before normalisation:  39.32505210998329
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[27.959]
 [30.263]
 [36.487]
 [33.055]
 [30.263]] [[1.062]
 [1.228]
 [1.677]
 [1.43 ]
 [1.228]]
printing an ep nov before normalisation:  32.4257362637061
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.704578662415884
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.47220288915123
printing an ep nov before normalisation:  32.23492857975012
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.089516184747705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.93948149543529
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[39.941]
 [39.941]
 [49.695]
 [39.941]
 [39.941]] [[0.595]
 [0.595]
 [0.854]
 [0.595]
 [0.595]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[36.548]
 [45.688]
 [52.304]
 [47.932]
 [47.899]] [[0.484]
 [0.7  ]
 [0.856]
 [0.753]
 [0.752]]
printing an ep nov before normalisation:  83.88465552958607
printing an ep nov before normalisation:  35.309870195968074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  29.486405849456787
printing an ep nov before normalisation:  29.227911592857
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[34.223]
 [32.57 ]
 [32.57 ]
 [30.325]
 [33.024]] [[1.334]
 [1.223]
 [1.223]
 [1.071]
 [1.253]]
printing an ep nov before normalisation:  42.30540556850819
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  5.741885232106938
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  32.87071209333787
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  36.77477453235067
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  53.2857127829872
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  44.32812080727848
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  23.75527780102065
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
siam score:  -0.8750138
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.06 ]
 [44.31 ]
 [44.187]
 [44.187]
 [44.965]] [[1.752]
 [1.766]
 [1.759]
 [1.759]
 [1.803]]
printing an ep nov before normalisation:  41.10941926736227
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.8752602
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  42.19304767889958
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.   ]
 [0.   ]
 [0.001]] [[28.006]
 [22.898]
 [23.101]
 [29.155]
 [22.898]] [[1.32 ]
 [0.814]
 [0.834]
 [1.433]
 [0.814]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  29.647064503652615
printing an ep nov before normalisation:  22.94522559556623
printing an ep nov before normalisation:  46.324270257835806
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  42.99644629115299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[50.023]
 [45.548]
 [43.862]
 [43.862]
 [43.862]] [[1.519]
 [1.319]
 [1.242]
 [1.242]
 [1.242]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.   ]
 [0.001]
 [0.001]] [[24.45 ]
 [25.999]
 [20.324]
 [26.476]
 [24.502]] [[1.159]
 [1.233]
 [0.963]
 [1.255]
 [1.162]]
printing an ep nov before normalisation:  40.70466716908984
printing an ep nov before normalisation:  46.841946492218334
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.28626096333361
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[29.784]
 [27.577]
 [35.444]
 [29.826]
 [30.921]] [[0.787]
 [0.67 ]
 [1.087]
 [0.789]
 [0.848]]
printing an ep nov before normalisation:  28.212753691860836
printing an ep nov before normalisation:  0.36560776328163536
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 27.763096371720433
printing an ep nov before normalisation:  35.63580516397836
siam score:  -0.8719731
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  34.18376068784528
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.002]
 [0.002]
 [0.003]] [[33.92 ]
 [31.037]
 [21.124]
 [20.683]
 [20.264]] [[1.154]
 [1.016]
 [0.544]
 [0.523]
 [0.504]]
printing an ep nov before normalisation:  37.61942175844273
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.19776407877604
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  28.82615969396037
printing an ep nov before normalisation:  31.295339555517963
printing an ep nov before normalisation:  46.45347788957602
actions average: 
K:  3  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9993,     0.0000,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0007,     0.0202,     0.8854,     0.0377,     0.0560],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0117, 0.0015, 0.0584, 0.7446, 0.1839], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0008, 0.0779, 0.0758, 0.2251, 0.6203], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  27.974636554718018
printing an ep nov before normalisation:  53.199344770737454
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  30.22453826481771
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.004]
 [0.005]
 [0.005]
 [0.005]] [[31.918]
 [21.378]
 [23.989]
 [20.296]
 [20.296]] [[0.005]
 [0.004]
 [0.005]
 [0.005]
 [0.005]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.43616344736489
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
UNIT TEST: sample policy line 217 mcts : [0.205 0.205 0.385 0.051 0.154]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.839373111724854
printing an ep nov before normalisation:  28.38856844981587
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.71679272588063
printing an ep nov before normalisation:  33.6131188669361
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  36.03533579918903
printing an ep nov before normalisation:  32.2904316339483
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  29.068402427198457
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.02213242790785
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.01 ]
 [0.008]
 [0.01 ]
 [0.01 ]] [[42.552]
 [42.552]
 [48.456]
 [42.552]
 [42.552]] [[1.437]
 [1.437]
 [1.755]
 [1.437]
 [1.437]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.92493093
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[31.886]
 [31.886]
 [31.886]
 [31.886]
 [31.886]] [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.006]
 [0.005]
 [0.005]] [[25.155]
 [25.155]
 [30.662]
 [25.155]
 [25.155]] [[0.882]
 [0.882]
 [1.339]
 [0.882]
 [0.882]]
printing an ep nov before normalisation:  27.09003406431085
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  40.04808355900498
using explorer policy with actor:  0
actions average: 
K:  2  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9902,     0.0092,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0004,     0.0000,     0.9148,     0.0388,     0.0460],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0018, 0.0013, 0.0490, 0.7489, 0.1991], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0093, 0.0016, 0.0989, 0.2611, 0.6290], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 40.17961365996452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.013]
 [0.011]
 [0.012]
 [0.012]] [[31.711]
 [31.711]
 [33.696]
 [31.233]
 [32.833]] [[1.111]
 [1.111]
 [1.218]
 [1.084]
 [1.172]]
printing an ep nov before normalisation:  0.0031313462343973697
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  41.77873611450195
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9988,     0.0000,     0.0000,     0.0004,     0.0008],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0053,     0.9732,     0.0001,     0.0001,     0.0213],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0001,     0.8597,     0.0458,     0.0943],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0039,     0.0005,     0.0351,     0.6786,     0.2819],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0042, 0.0163, 0.0151, 0.2611, 0.7033], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.013]
 [0.013]
 [0.013]
 [0.013]] [[31.129]
 [31.129]
 [31.129]
 [31.129]
 [31.129]] [[0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.832]]
printing an ep nov before normalisation:  78.40626553230692
siam score:  -0.94227934
printing an ep nov before normalisation:  37.039144369187
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  0.17811462254329058
printing an ep nov before normalisation:  47.43923403046284
printing an ep nov before normalisation:  35.03826507853492
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Starting evaluation
printing an ep nov before normalisation:  80.39823086652852
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  43.96239180304377
actions average: 
K:  4  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0419,     0.9374,     0.0002,     0.0013,     0.0192],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0005,     0.8949,     0.0550,     0.0496],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0007, 0.0009, 0.0757, 0.6518, 0.2709], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0050, 0.0270, 0.1646, 0.3472, 0.4563], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  52.079232378739576
printing an ep nov before normalisation:  27.597708702087402
using explorer policy with actor:  0
printing an ep nov before normalisation:  42.37079609462774
printing an ep nov before normalisation:  30.706477153305773
printing an ep nov before normalisation:  33.76305341720581
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.530226591619304
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  36.75655615166402
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[25.686]
 [25.686]
 [25.686]
 [25.686]
 [25.686]] [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.007]] [[42.215]
 [30.126]
 [20.922]
 [23.886]
 [26.493]] [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.007]]
printing an ep nov before normalisation:  31.545163133685882
printing an ep nov before normalisation:  28.922330849141474
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.01 ]
 [0.01 ]
 [0.007]
 [0.01 ]] [[25.862]
 [25.862]
 [25.862]
 [27.372]
 [25.862]] [[0.01 ]
 [0.01 ]
 [0.01 ]
 [0.007]
 [0.01 ]]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.007]
 [0.006]] [[32.588]
 [32.448]
 [28.865]
 [25.635]
 [28.975]] [[0.006]
 [0.006]
 [0.006]
 [0.007]
 [0.006]]
using explorer policy with actor:  0
printing an ep nov before normalisation:  24.463140989256672
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.15966102230895
printing an ep nov before normalisation:  39.030022687455734
using explorer policy with actor:  0
using explorer policy with actor:  0
printing an ep nov before normalisation:  38.09815063380693
printing an ep nov before normalisation:  24.6750807762146
printing an ep nov before normalisation:  24.81279259956134
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[30.918]
 [30.918]
 [31.219]
 [30.918]
 [30.918]] [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]]
printing an ep nov before normalisation:  36.58146858215332
printing an ep nov before normalisation:  46.51980523160821
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[40.179]
 [38.65 ]
 [33.39 ]
 [33.39 ]
 [33.39 ]] [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]]
printing an ep nov before normalisation:  43.63814830780029
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
printing an ep nov before normalisation:  45.14270873468498
printing an ep nov before normalisation:  35.12580252457784
printing an ep nov before normalisation:  56.70634272213776
printing an ep nov before normalisation:  36.06790730203631
printing an ep nov before normalisation:  50.73519476559785
printing an ep nov before normalisation:  36.84599266221688
printing an ep nov before normalisation:  45.04436603071738
printing an ep nov before normalisation:  31.717402145554356
printing an ep nov before normalisation:  37.443167004807506
printing an ep nov before normalisation:  41.35457632697105
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[56.288]
 [56.288]
 [56.288]
 [56.288]
 [58.398]] [[1.899]
 [1.899]
 [1.899]
 [1.899]
 [2.007]]
printing an ep nov before normalisation:  49.6421361914306
using explorer policy with actor:  0
printing an ep nov before normalisation:  51.93251959296973
Printing some Q and Qe and total Qs values:  [[0.01]
 [0.01]
 [0.01]
 [0.01]
 [0.01]] [[32.563]
 [32.563]
 [63.59 ]
 [32.563]
 [32.563]] [[0.732]
 [0.732]
 [1.57 ]
 [0.732]
 [0.732]]
printing an ep nov before normalisation:  33.20827503427481
printing an ep nov before normalisation:  0.0007636505756636325
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.008]
 [0.007]
 [0.007]] [[35.677]
 [35.314]
 [34.47 ]
 [33.996]
 [37.185]] [[0.006]
 [0.006]
 [0.008]
 [0.007]
 [0.007]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  34.800083697468246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.399361890932337
printing an ep nov before normalisation:  68.32095368032547
siam score:  -0.95001626
printing an ep nov before normalisation:  42.02618331645683
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.012]
 [0.01 ]
 [0.012]
 [0.012]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.012]
 [0.012]
 [0.01 ]
 [0.012]
 [0.012]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.10885971276414
printing an ep nov before normalisation:  40.82242810614412
printing an ep nov before normalisation:  21.28215493377883
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.008]
 [0.007]
 [0.01 ]
 [0.007]] [[38.671]
 [43.336]
 [33.25 ]
 [35.981]
 [33.25 ]] [[0.961]
 [1.193]
 [0.689]
 [0.828]
 [0.689]]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.009]] [[33.764]
 [33.764]
 [43.403]
 [33.764]
 [33.764]] [[0.663]
 [0.663]
 [0.927]
 [0.663]
 [0.663]]
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.007]
 [0.01 ]
 [0.008]
 [0.009]] [[29.444]
 [32.389]
 [38.979]
 [29.444]
 [31.035]] [[0.389]
 [0.474]
 [0.669]
 [0.389]
 [0.436]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  42.22091077917749
printing an ep nov before normalisation:  44.36590703838137
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  83.74726733909178
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.007]] [[30.693]
 [30.693]
 [30.693]
 [30.693]
 [31.558]] [[1.602]
 [1.602]
 [1.602]
 [1.602]
 [1.674]]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.003]
 [0.005]
 [0.005]] [[36.246]
 [47.253]
 [46.214]
 [40.443]
 [48.176]] [[0.955]
 [1.476]
 [1.425]
 [1.154]
 [1.52 ]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.966440128449996
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  45.87538546423286
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  74.81921925257316
printing an ep nov before normalisation:  24.96220588684082
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  27.69937715325852
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[58.531]
 [56.501]
 [58.531]
 [58.531]
 [59.643]] [[1.827]
 [1.737]
 [1.827]
 [1.827]
 [1.878]]
printing an ep nov before normalisation:  43.08448252630798
printing an ep nov before normalisation:  45.450912712196725
printing an ep nov before normalisation:  36.31548526648218
printing an ep nov before normalisation:  52.59709827009602
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.882521959896756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  45.67036259604683
printing an ep nov before normalisation:  44.050808717729694
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9945,     0.0009,     0.0023,     0.0001,     0.0022],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9711,     0.0029,     0.0004,     0.0253],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0000,     0.8357,     0.0725,     0.0916],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0128, 0.0038, 0.1254, 0.5525, 0.3056], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0412, 0.0282, 0.0723, 0.2422, 0.6162], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  44.27141332213471
using explorer policy with actor:  1
using explorer policy with actor:  1
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0004,     0.9722,     0.0004,     0.0018,     0.0252],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.8765,     0.0549,     0.0684],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0019,     0.0005,     0.1313,     0.5594,     0.3069],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0034, 0.0243, 0.0210, 0.3437, 0.6077], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[55.046]
 [55.046]
 [55.671]
 [55.967]
 [55.046]] [[1.52 ]
 [1.52 ]
 [1.543]
 [1.554]
 [1.52 ]]
printing an ep nov before normalisation:  100.76782922494733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
line 256 mcts: sample exp_bonus 52.923187243624035
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[48.346]
 [54.295]
 [48.346]
 [48.346]
 [48.346]] [[1.432]
 [1.673]
 [1.432]
 [1.432]
 [1.432]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  38.22028261420314
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[35.34]
 [35.34]
 [35.34]
 [35.34]
 [35.34]] [[1.672]
 [1.672]
 [1.672]
 [1.672]
 [1.672]]
printing an ep nov before normalisation:  35.88407883118824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
siam score:  -0.9411499
printing an ep nov before normalisation:  27.405040195976667
printing an ep nov before normalisation:  55.93331216951827
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.005]
 [0.005]
 [0.005]] [[49.44 ]
 [49.44 ]
 [56.032]
 [56.717]
 [56.53 ]] [[1.198]
 [1.198]
 [1.473]
 [1.502]
 [1.494]]
printing an ep nov before normalisation:  54.37512759500277
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.001]
 [0.005]
 [0.005]
 [0.004]] [[61.314]
 [54.9  ]
 [49.813]
 [65.799]
 [59.984]] [[0.465]
 [0.387]
 [0.331]
 [0.52 ]
 [0.451]]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[48.413]
 [58.165]
 [48.413]
 [48.413]
 [48.413]] [[1.271]
 [1.715]
 [1.271]
 [1.271]
 [1.271]]
printing an ep nov before normalisation:  60.122975605244235
printing an ep nov before normalisation:  25.96670571640025
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.56765370944468
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.893845200411675
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  34.4632088397719
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[26.024]
 [38.255]
 [34.892]
 [36.52 ]
 [37.268]] [[0.241]
 [0.433]
 [0.381]
 [0.406]
 [0.418]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.21946144104004
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  35.15988349914551
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  30.315978527069092
printing an ep nov before normalisation:  54.94453524006876
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[41.529]
 [41.529]
 [41.529]
 [41.529]
 [41.529]] [[1.172]
 [1.172]
 [1.172]
 [1.172]
 [1.172]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  25.484252109670933
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[73.232]
 [73.232]
 [73.232]
 [73.232]
 [73.232]] [[2.004]
 [2.004]
 [2.004]
 [2.004]
 [2.004]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  41.34718871941853
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.004]
 [0.   ]
 [0.003]
 [0.004]] [[26.061]
 [20.315]
 [26.421]
 [38.631]
 [27.228]] [[0.552]
 [0.3  ]
 [0.568]
 [1.113]
 [0.608]]
printing an ep nov before normalisation:  43.27360201828129
printing an ep nov before normalisation:  42.75685795315363
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.06163263320923
siam score:  -0.9317024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.622810790834215
printing an ep nov before normalisation:  31.169328647366267
printing an ep nov before normalisation:  48.333934872766314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  28.017438550124343
printing an ep nov before normalisation:  36.97944007872838
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  45.77069273850991
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  48.16508448511109
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.74031828984202
actions average: 
K:  3  action  0 :  tensor([    0.9998,     0.0001,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9545,     0.0002,     0.0001,     0.0451],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0042,     0.9108,     0.0463,     0.0387],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0158, 0.0036, 0.0856, 0.6166, 0.2784], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0301, 0.0308, 0.0497, 0.2422, 0.6472], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  42.45058574021681
printing an ep nov before normalisation:  44.806158232883526
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
UNIT TEST: sample policy line 217 mcts : [0.923 0.    0.077 0.    0.   ]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.004]
 [0.004]
 [0.004]
 [0.004]]
line 256 mcts: sample exp_bonus 54.69453538563929
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.006]
 [0.003]] [[32.702]
 [35.346]
 [39.708]
 [31.902]
 [32.702]] [[0.818]
 [0.948]
 [1.162]
 [0.782]
 [0.818]]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.005]
 [0.004]
 [0.005]
 [0.004]] [[45.598]
 [47.088]
 [37.878]
 [42.937]
 [45.252]] [[1.648]
 [1.729]
 [1.238]
 [1.508]
 [1.63 ]]
printing an ep nov before normalisation:  90.056903226262
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.92537385
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  45.18228739776712
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.419169902801514
using explorer policy with actor:  1
siam score:  -0.91994613
printing an ep nov before normalisation:  42.626009481004
maxi score, test score, baseline:  0.0001 0.0 0.0001
using another actor
printing an ep nov before normalisation:  45.89928150177002
printing an ep nov before normalisation:  47.291967781017156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  0.17602452937580892
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.005]
 [0.005]] [[23.682]
 [35.106]
 [45.096]
 [32.878]
 [32.11 ]] [[0.154]
 [0.744]
 [1.259]
 [0.629]
 [0.589]]
actions average: 
K:  2  action  0 :  tensor([    0.9907,     0.0024,     0.0000,     0.0015,     0.0055],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0065, 0.9114, 0.0154, 0.0031, 0.0636], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9092,     0.0415,     0.0491],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0040,     0.0888,     0.6740,     0.2329],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0014, 0.0406, 0.0950, 0.2920, 0.5710], grad_fn=<DivBackward0>)
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.09146001513101
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.004]
 [0.005]
 [0.005]] [[34.303]
 [34.303]
 [39.701]
 [34.303]
 [34.303]] [[1.406]
 [1.406]
 [1.758]
 [1.406]
 [1.406]]
printing an ep nov before normalisation:  24.319686889648438
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.004]
 [0.004]
 [0.004]] [[24.43 ]
 [25.867]
 [24.211]
 [20.123]
 [20.123]] [[0.003]
 [0.003]
 [0.004]
 [0.004]
 [0.004]]
printing an ep nov before normalisation:  29.88890245028436
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  19.607655150722564
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  24.790751934051514
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  49.663306273494534
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.68049288477994
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  29.572834968566895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  24.75893140121119
printing an ep nov before normalisation:  48.854571856168654
printing an ep nov before normalisation:  37.75517780097117
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.601241147808516
printing an ep nov before normalisation:  29.967727661132812
printing an ep nov before normalisation:  32.61544694939943
siam score:  -0.9165718
printing an ep nov before normalisation:  44.30737292228073
printing an ep nov before normalisation:  26.147075948355898
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.460517363557294
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.   ]
 [0.004]
 [0.004]] [[23.782]
 [23.782]
 [22.308]
 [23.782]
 [23.782]] [[0.994]
 [0.994]
 [0.867]
 [0.994]
 [0.994]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[23.521]
 [25.424]
 [28.509]
 [29.97 ]
 [25.424]] [[1.047]
 [1.24 ]
 [1.562]
 [1.713]
 [1.24 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.835122533577454
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[28.414]
 [27.108]
 [27.108]
 [27.108]
 [27.108]] [[1.331]
 [1.215]
 [1.215]
 [1.215]
 [1.215]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.92513883
printing an ep nov before normalisation:  32.34199433873878
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  3  action  0 :  tensor([    0.9963,     0.0020,     0.0001,     0.0001,     0.0014],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9282,     0.0022,     0.0010,     0.0686],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9575,     0.0235,     0.0190],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0019, 0.0020, 0.0542, 0.7810, 0.1609], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0028, 0.0608, 0.0907, 0.3607, 0.4849], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.04171419143677
actions average: 
K:  2  action  0 :  tensor([    0.9994,     0.0005,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0005,     0.9847,     0.0001,     0.0033,     0.0114],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0145,     0.9304,     0.0252,     0.0298],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0022,     0.0003,     0.0218,     0.8253,     0.1503],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0020, 0.0446, 0.1047, 0.3057, 0.5429], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  72.68089334157749
printing an ep nov before normalisation:  40.47635752055917
printing an ep nov before normalisation:  40.24239915016208
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.066659927368164
printing an ep nov before normalisation:  64.1721604507587
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  59.2493048634728
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  1  action  0 :  tensor([    0.9639,     0.0011,     0.0000,     0.0097,     0.0253],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9868,     0.0003,     0.0005,     0.0124],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0000,     0.9047,     0.0538,     0.0413],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0004,     0.0011,     0.0244,     0.7240,     0.2501],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0009, 0.0023, 0.0929, 0.3361, 0.5678], grad_fn=<DivBackward0>)
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  42.32761519309873
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.008]
 [0.007]
 [0.008]
 [0.008]] [[37.653]
 [37.653]
 [42.876]
 [37.653]
 [37.653]] [[1.29]
 [1.29]
 [1.66]
 [1.29]
 [1.29]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.035]
 [0.035]
 [0.035]
 [0.031]
 [0.035]] [[30.324]
 [30.324]
 [30.324]
 [31.287]
 [30.324]] [[1.539]
 [1.539]
 [1.539]
 [1.625]
 [1.539]]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  42.709998394614104
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  40.089092006314864
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.93498886
printing an ep nov before normalisation:  5.307981894020486e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  26.556879086141283
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.10914414737669
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.008]
 [0.007]
 [0.009]] [[40.07 ]
 [40.07 ]
 [47.899]
 [45.886]
 [40.07 ]] [[1.079]
 [1.079]
 [1.481]
 [1.377]
 [1.079]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  48.79874974968504
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  94.66680521374577
using explorer policy with actor:  0
printing an ep nov before normalisation:  58.241236391091846
printing an ep nov before normalisation:  63.86495791903774
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  33.027199853642486
printing an ep nov before normalisation:  39.95197824156639
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.921889587682685
printing an ep nov before normalisation:  71.62236862162565
printing an ep nov before normalisation:  53.51858007518993
printing an ep nov before normalisation:  31.447192856745787
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.008]
 [0.007]
 [0.008]
 [0.008]] [[44.838]
 [42.666]
 [33.837]
 [45.974]
 [46.018]] [[1.139]
 [1.036]
 [0.612]
 [1.194]
 [1.196]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.008]
 [0.009]
 [0.009]
 [0.009]] [[48.933]
 [52.671]
 [38.701]
 [50.028]
 [52.01 ]] [[1.621]
 [1.801]
 [1.131]
 [1.675]
 [1.77 ]]
printing an ep nov before normalisation:  28.53902816772461
printing an ep nov before normalisation:  46.1922304668164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.480702961303628
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.008]
 [0.008]
 [0.008]] [[26.397]
 [26.397]
 [30.138]
 [29.571]
 [25.75 ]] [[0.993]
 [0.993]
 [1.26 ]
 [1.219]
 [0.946]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  40.85552018579403
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  92.52240497484637
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  39.11657990048234
printing an ep nov before normalisation:  30.41541930940283
printing an ep nov before normalisation:  60.36066136069746
printing an ep nov before normalisation:  100.82671519686279
printing an ep nov before normalisation:  63.26480769748665
printing an ep nov before normalisation:  53.30347792796411
actions average: 
K:  0  action  0 :  tensor([    0.9991,     0.0002,     0.0000,     0.0003,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0042,     0.9910,     0.0001,     0.0011,     0.0036],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9639,     0.0213,     0.0147],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0011,     0.0004,     0.0219,     0.7917,     0.1849],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0011, 0.0012, 0.0323, 0.3950, 0.5703], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[50.37 ]
 [48.454]
 [50.37 ]
 [50.37 ]
 [50.37 ]] [[1.845]
 [1.775]
 [1.845]
 [1.845]
 [1.845]]
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.008]
 [0.007]
 [0.008]
 [0.008]] [[37.548]
 [37.548]
 [41.339]
 [40.485]
 [37.548]] [[1.352]
 [1.352]
 [1.597]
 [1.543]
 [1.352]]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.008]
 [0.007]
 [0.007]
 [0.008]] [[32.721]
 [26.265]
 [31.998]
 [32.983]
 [27.899]] [[1.009]
 [0.704]
 [0.975]
 [1.021]
 [0.782]]
siam score:  -0.93672514
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  41.990092124832934
printing an ep nov before normalisation:  29.536746428235986
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.007]
 [0.006]
 [0.007]] [[39.581]
 [38.178]
 [43.278]
 [35.016]
 [40.992]] [[0.958]
 [0.896]
 [1.123]
 [0.756]
 [1.022]]
UNIT TEST: sample policy line 217 mcts : [0.103 0.692 0.077 0.103 0.026]
printing an ep nov before normalisation:  48.0300461998164
printing an ep nov before normalisation:  55.17733036515971
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.24776254398122
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  23.72151095257171
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[41.003]
 [41.003]
 [44.491]
 [41.259]
 [41.003]] [[1.578]
 [1.578]
 [1.807]
 [1.595]
 [1.578]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  31.904532570443354
printing an ep nov before normalisation:  38.57990011871677
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[36.563]
 [47.679]
 [48.298]
 [46.506]
 [47.679]] [[1.035]
 [1.794]
 [1.836]
 [1.714]
 [1.794]]
printing an ep nov before normalisation:  69.79957862679075
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
line 256 mcts: sample exp_bonus 40.65809843279948
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
UNIT TEST: sample policy line 217 mcts : [0.231 0.026 0.103 0.59  0.051]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.715972570857716
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  79.38688499058428
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  32.16731073337748
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[32.905]
 [39.384]
 [31.638]
 [31.347]
 [33.088]] [[1.38 ]
 [1.652]
 [1.328]
 [1.316]
 [1.388]]
printing an ep nov before normalisation:  25.061958842672645
printing an ep nov before normalisation:  38.82115840911865
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.004]
 [0.   ]
 [0.005]
 [0.004]] [[33.145]
 [51.958]
 [54.71 ]
 [52.699]
 [53.925]] [[0.221]
 [1.292]
 [1.445]
 [1.334]
 [1.404]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.24708584402967
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.   ]
 [0.005]
 [0.006]] [[22.949]
 [22.852]
 [24.01 ]
 [25.324]
 [23.321]] [[0.95 ]
 [0.942]
 [1.036]
 [1.154]
 [0.982]]
printing an ep nov before normalisation:  28.843826656328233
printing an ep nov before normalisation:  22.676584212057367
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  53.60839666713629
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
actions average: 
K:  2  action  0 :  tensor([    0.9989,     0.0007,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0013, 0.9622, 0.0196, 0.0015, 0.0155], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0008,     0.0116,     0.9249,     0.0286,     0.0341],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0006,     0.0005,     0.0535,     0.7934,     0.1520],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0110, 0.0034, 0.0309, 0.3992, 0.5555], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  46.71017186743953
printing an ep nov before normalisation:  84.27338129203049
printing an ep nov before normalisation:  48.57366216165173
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  41.99110559732302
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
siam score:  -0.9301651
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  37.820227632767995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.21055424847724
printing an ep nov before normalisation:  35.80787989227221
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.025379180908203
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  29.317740004325522
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  31.01076287708848
printing an ep nov before normalisation:  23.577724329008184
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  42.68972255458965
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.48203115418996
printing an ep nov before normalisation:  62.534792864062744
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.004]
 [0.005]
 [0.004]
 [0.004]] [[47.564]
 [44.016]
 [38.173]
 [43.859]
 [48.17 ]] [[0.   ]
 [0.004]
 [0.005]
 [0.004]
 [0.004]]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.   ]
 [0.006]
 [0.007]
 [0.006]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.006]
 [0.   ]
 [0.006]
 [0.007]
 [0.006]]
printing an ep nov before normalisation:  36.44559621810913
using another actor
printing an ep nov before normalisation:  47.54650986216102
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.72506849673815
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.007]
 [0.001]
 [0.007]
 [0.007]] [[32.225]
 [28.699]
 [23.289]
 [36.608]
 [31.722]] [[1.197]
 [1.066]
 [0.859]
 [1.358]
 [1.178]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  0.020342683907301762
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.   ]
 [0.009]
 [0.008]
 [0.009]] [[34.655]
 [31.141]
 [33.673]
 [43.506]
 [30.147]] [[0.528]
 [0.429]
 [0.504]
 [0.76 ]
 [0.411]]
line 256 mcts: sample exp_bonus 44.78463535201891
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.008]
 [0.007]
 [0.007]] [[24.856]
 [24.782]
 [28.959]
 [20.357]
 [21.054]] [[0.202]
 [0.201]
 [0.257]
 [0.146]
 [0.155]]
printing an ep nov before normalisation:  42.33805019243359
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]]
printing an ep nov before normalisation:  47.46800915935899
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.011]
 [0.009]
 [0.011]
 [0.011]] [[47.589]
 [47.589]
 [67.002]
 [47.589]
 [50.075]] [[0.837]
 [0.837]
 [1.477]
 [0.837]
 [0.919]]
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.01 ]
 [0.009]
 [0.011]
 [0.011]] [[33.756]
 [41.088]
 [56.52 ]
 [46.182]
 [45.934]] [[0.285]
 [0.665]
 [1.466]
 [0.931]
 [0.918]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  49.03709565179862
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  25.081862900479354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
printing an ep nov before normalisation:  21.6227388381958
maxi score, test score, baseline:  0.0001 0.0 0.0001
using another actor
printing an ep nov before normalisation:  26.31322145462036
Printing some Q and Qe and total Qs values:  [[0.01]
 [0.01]
 [0.01]
 [0.01]
 [0.01]] [[34.141]
 [34.141]
 [35.751]
 [34.141]
 [34.141]] [[1.878]
 [1.878]
 [2.01 ]
 [1.878]
 [1.878]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.875797271728516
printing an ep nov before normalisation:  44.94723320007324
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.02261654319749
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9312659
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  48.60614652665869
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9293085
Printing some Q and Qe and total Qs values:  [[0.01]
 [0.01]
 [0.01]
 [0.01]
 [0.01]] [[40.636]
 [40.636]
 [50.429]
 [40.636]
 [40.636]] [[1.01 ]
 [1.01 ]
 [1.408]
 [1.01 ]
 [1.01 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9312114
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.866221513076255
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.035101880647392
printing an ep nov before normalisation:  44.44386247827041
printing an ep nov before normalisation:  40.121167046683176
printing an ep nov before normalisation:  45.053510665893555
printing an ep nov before normalisation:  28.58012252383762
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.01 ]
 [0.012]
 [0.012]
 [0.012]] [[24.525]
 [23.858]
 [26.427]
 [24.525]
 [24.525]] [[1.778]
 [1.695]
 [2.012]
 [1.778]
 [1.778]]
printing an ep nov before normalisation:  45.996108055114746
printing an ep nov before normalisation:  70.8206033706665
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.01 ]
 [0.011]
 [0.01 ]
 [0.01 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.009]
 [0.01 ]
 [0.011]
 [0.01 ]
 [0.01 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.90735076715947
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.009]
 [0.009]
 [0.009]
 [0.009]] [[65.036]
 [66.769]
 [66.769]
 [66.769]
 [66.769]] [[1.611]
 [1.676]
 [1.676]
 [1.676]
 [1.676]]
printing an ep nov before normalisation:  48.25131252481531
printing an ep nov before normalisation:  33.005472965908
printing an ep nov before normalisation:  81.3897533389664
siam score:  -0.93876314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9638,     0.0007,     0.0004,     0.0318,     0.0033],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0006,     0.9599,     0.0004,     0.0007,     0.0384],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0004,     0.0002,     0.9519,     0.0214,     0.0261],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0041, 0.0019, 0.0362, 0.7358, 0.2220], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0012, 0.0006, 0.1860, 0.3161, 0.4961], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  50.47166682152478
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.80555653780495
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.998]
 [0.998]
 [0.002]
 [0.998]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.998]
 [0.998]
 [0.002]
 [0.998]]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.836567450608978
printing an ep nov before normalisation:  26.430862387069364
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.56780500781136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.20240152018416
printing an ep nov before normalisation:  69.54121298266274
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.95913152133503
printing an ep nov before normalisation:  30.552944077351974
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.361553113428634
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.918499824971015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.13434478631248
printing an ep nov before normalisation:  63.60255472445315
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.513879844032495
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.004]
 [0.005]
 [0.005]] [[51.64 ]
 [51.64 ]
 [74.148]
 [58.899]
 [51.64 ]] [[0.646]
 [0.646]
 [1.084]
 [0.787]
 [0.646]]
printing an ep nov before normalisation:  48.68520582540256
printing an ep nov before normalisation:  53.18793341576618
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9976,     0.0001,     0.0000,     0.0016,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9738,     0.0001,     0.0005,     0.0256],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0003,     0.9193,     0.0389,     0.0412],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0004,     0.0009,     0.0368,     0.8069,     0.1549],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0021, 0.0086, 0.0417, 0.2474, 0.7002], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9973,     0.0001,     0.0000,     0.0022,     0.0004],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0005,     0.9971,     0.0002,     0.0018,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0004,     0.0000,     0.8104,     0.0981,     0.0911],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0020,     0.0002,     0.0275,     0.7940,     0.1763],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0009, 0.0243, 0.1072, 0.3341, 0.5334], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.495373725891113
siam score:  -0.9249076
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.94087312569043
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
siam score:  -0.92609316
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.011253356933594
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[36.959]
 [34.87 ]
 [30.909]
 [32.208]
 [33.376]] [[0.468]
 [0.424]
 [0.342]
 [0.369]
 [0.393]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[24.725]
 [30.294]
 [35.802]
 [34.769]
 [33.597]] [[0.344]
 [0.561]
 [0.777]
 [0.737]
 [0.691]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.109777467103726
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.89871520117222
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.045672086031345316
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.77076208625363
printing an ep nov before normalisation:  59.285435877914416
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.59841882073652
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.81460475921631
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.02056983125294
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.63847916503953
line 256 mcts: sample exp_bonus 0.00012002937145325631
printing an ep nov before normalisation:  36.77978374406801
printing an ep nov before normalisation:  57.06933225133775
siam score:  -0.9163063
printing an ep nov before normalisation:  39.316181012896536
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.89283782733222
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9686,     0.0003,     0.0010,     0.0299],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0001,     0.9048,     0.0425,     0.0524],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0004,     0.0544,     0.7995,     0.1453],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0018, 0.0008, 0.0742, 0.3196, 0.6036], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  25.84202289581299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.38717498518872
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.355747702382345
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.96054874696619
printing an ep nov before normalisation:  36.20357987283378
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.002]
 [0.006]
 [0.005]] [[41.367]
 [49.028]
 [40.613]
 [34.262]
 [50.407]] [[0.535]
 [0.744]
 [0.51 ]
 [0.342]
 [0.781]]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.005]
 [0.006]
 [0.006]
 [0.006]] [[20.722]
 [26.622]
 [27.949]
 [26.48 ]
 [24.285]] [[0.468]
 [0.816]
 [0.896]
 [0.809]
 [0.679]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.69123837013404
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  34.022477859447356
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.701019525527954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.005]
 [0.005]
 [0.007]
 [0.006]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.006]
 [0.005]
 [0.005]
 [0.007]
 [0.006]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.5099683399991
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.03861184535329
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.226195537076045
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.62747979600837
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.018]
 [0.018]
 [0.018]
 [0.018]] [[23.424]
 [23.424]
 [23.424]
 [23.424]
 [23.424]] [[1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]]
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.018]
 [0.018]
 [0.018]
 [0.018]] [[31.124]
 [31.124]
 [31.124]
 [31.124]
 [31.124]] [[1.876]
 [1.876]
 [1.876]
 [1.876]
 [1.876]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.31778223836351
printing an ep nov before normalisation:  41.452927589416504
printing an ep nov before normalisation:  42.083459276885435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.36509958295395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.9478781
printing an ep nov before normalisation:  32.3336794740539
printing an ep nov before normalisation:  50.27123559874509
line 256 mcts: sample exp_bonus 67.37951647039179
printing an ep nov before normalisation:  36.822122759711824
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.59208508498386
siam score:  -0.95341676
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.48409272484702
printing an ep nov before normalisation:  72.1056396800259
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.00015540125267
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  52.29140565570363
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.554560926770804
siam score:  -0.95570874
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.092965065555504
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.26011562347412
UNIT TEST: sample policy line 217 mcts : [0.051 0.026 0.487 0.231 0.205]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.33038381906163
line 256 mcts: sample exp_bonus 31.779444726814884
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.14856784731245
siam score:  -0.95161486
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.54832111677443
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.023]
 [0.024]
 [0.024]
 [0.025]
 [0.025]] [[32.526]
 [30.74 ]
 [48.985]
 [33.15 ]
 [28.798]] [[0.422]
 [0.385]
 [0.768]
 [0.437]
 [0.345]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.874982044784595
printing an ep nov before normalisation:  36.27977008582544
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.47080135345459
siam score:  -0.9553627
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.021]
 [0.02 ]
 [0.021]
 [0.023]
 [0.023]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.021]
 [0.02 ]
 [0.021]
 [0.023]
 [0.023]]
printing an ep nov before normalisation:  53.25417880451137
Printing some Q and Qe and total Qs values:  [[0.022]
 [0.019]
 [0.021]
 [0.023]
 [0.022]] [[24.801]
 [32.53 ]
 [47.031]
 [33.46 ]
 [30.509]] [[0.44 ]
 [0.685]
 [1.152]
 [0.719]
 [0.623]]
printing an ep nov before normalisation:  48.50567254132291
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  31.797710415360143
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9640258
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.044218977111385
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.01 ]
 [0.012]
 [0.014]
 [0.014]] [[35.662]
 [38.055]
 [33.514]
 [36.436]
 [33.249]] [[0.013]
 [0.01 ]
 [0.012]
 [0.014]
 [0.014]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.30753451632066
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0005,     0.9830,     0.0000,     0.0046,     0.0118],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9677,     0.0154,     0.0168],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0020, 0.0016, 0.0904, 0.6241, 0.2819], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0067, 0.0249, 0.0832, 0.2664, 0.6188], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.27846572957423
using explorer policy with actor:  1
printing an ep nov before normalisation:  58.286229605678926
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.021]
 [0.016]
 [0.022]
 [0.021]
 [0.021]] [[20.903]
 [27.097]
 [55.992]
 [25.694]
 [26.073]] [[0.145]
 [0.311]
 [1.109]
 [0.276]
 [0.287]]
printing an ep nov before normalisation:  42.481066498479905
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.53746191624836
printing an ep nov before normalisation:  62.18121115111323
printing an ep nov before normalisation:  28.431123329642322
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.74163821379142
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.329544465534326
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.014]
 [0.019]
 [0.018]
 [0.017]] [[33.239]
 [31.421]
 [35.533]
 [32.271]
 [31.92 ]] [[0.856]
 [0.808]
 [0.917]
 [0.833]
 [0.823]]
printing an ep nov before normalisation:  42.07543417689836
printing an ep nov before normalisation:  35.11979579925537
printing an ep nov before normalisation:  42.82281082883757
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.408863044171106
printing an ep nov before normalisation:  57.65045205056509
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.16737792604795
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.659929077201
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.94914888478261
printing an ep nov before normalisation:  23.072937003310212
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.86287087989361
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.251901626586914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.7470615354183
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.01]
 [0.01]
 [0.01]
 [0.01]
 [0.01]] [[65.486]
 [65.486]
 [65.486]
 [65.486]
 [65.486]] [[1.213]
 [1.213]
 [1.213]
 [1.213]
 [1.213]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.44653312412986
printing an ep nov before normalisation:  34.26642208654198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.56781374903181
printing an ep nov before normalisation:  75.15171843152143
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.471952279494918
printing an ep nov before normalisation:  50.39693891818138
printing an ep nov before normalisation:  40.15967202486738
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.282 0.026 0.436 0.231 0.026]
printing an ep nov before normalisation:  29.369423389434814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.84145656585838
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.06276966607458
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.012]
 [0.01 ]
 [0.011]
 [0.011]] [[41.152]
 [41.152]
 [46.46 ]
 [43.076]
 [42.761]] [[1.4  ]
 [1.4  ]
 [1.671]
 [1.498]
 [1.482]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.011]
 [0.011]
 [0.011]
 [0.013]] [[29.897]
 [35.725]
 [39.061]
 [38.915]
 [37.203]] [[0.811]
 [1.174]
 [1.381]
 [1.372]
 [1.267]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.12075042728736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.76224498330512
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.   ]
 [0.006]
 [0.007]] [[33.976]
 [40.133]
 [40.071]
 [42.305]
 [41.119]] [[0.505]
 [0.725]
 [0.716]
 [0.802]
 [0.76 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.006]
 [0.009]
 [0.009]
 [0.006]] [[32.711]
 [37.547]
 [32.513]
 [31.413]
 [33.649]] [[0.453]
 [0.595]
 [0.448]
 [0.416]
 [0.48 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.48302431277626
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9902,     0.0004,     0.0000,     0.0020,     0.0074],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0357, 0.9029, 0.0013, 0.0052, 0.0549], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0016, 0.0506, 0.8626, 0.0406, 0.0446], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0020,     0.0006,     0.0424,     0.7517,     0.2033],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0105, 0.0838, 0.0503, 0.2816, 0.5738], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.735218997011266
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.39727337556286
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.007]
 [0.006]] [[ 0.   ]
 [31.165]
 [ 0.   ]
 [28.239]
 [ 0.   ]] [[-0.201]
 [ 0.226]
 [-0.201]
 [ 0.187]
 [-0.201]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.78333347805266
actions average: 
K:  4  action  0 :  tensor([0.9291, 0.0307, 0.0011, 0.0033, 0.0358], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9883,     0.0000,     0.0000,     0.0116],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0004,     0.8661,     0.0664,     0.0669],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0068,     0.1482,     0.6462,     0.1985],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0023, 0.0273, 0.0841, 0.3834, 0.5029], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.07217963199449
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.008]
 [0.009]
 [0.009]] [[30.338]
 [30.338]
 [31.687]
 [30.338]
 [30.338]] [[1.093]
 [1.093]
 [1.182]
 [1.093]
 [1.093]]
printing an ep nov before normalisation:  28.784935578320617
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[32.547]
 [32.547]
 [32.547]
 [32.547]
 [32.547]] [[32.554]
 [32.554]
 [32.554]
 [32.554]
 [32.554]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.932685
printing an ep nov before normalisation:  38.1799578666687
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.407]
 [37.407]
 [37.407]
 [37.407]
 [37.407]] [[0.886]
 [0.886]
 [0.886]
 [0.886]
 [0.886]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.740890708947944
printing an ep nov before normalisation:  50.26192583839208
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.65870952250242
printing an ep nov before normalisation:  23.114753565685604
printing an ep nov before normalisation:  22.362907663947002
printing an ep nov before normalisation:  26.997522013952146
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.565111658189466
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.957613024149996
printing an ep nov before normalisation:  22.26929918690753
printing an ep nov before normalisation:  20.047255981979202
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.006]] [[36.776]
 [36.776]
 [40.113]
 [37.463]
 [37.608]] [[1.011]
 [1.011]
 [1.166]
 [1.042]
 [1.048]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.908477783203125
printing an ep nov before normalisation:  34.18072990425516
siam score:  -0.92955476
printing an ep nov before normalisation:  44.75190331040468
siam score:  -0.92838407
siam score:  -0.92779917
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9266452
printing an ep nov before normalisation:  36.65549278259277
printing an ep nov before normalisation:  27.97435221894571
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.1318192718193245
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.968270099215765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.586773845190244
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.   ]
 [0.005]
 [0.005]
 [0.004]] [[44.8  ]
 [34.065]
 [35.369]
 [35.457]
 [43.758]] [[0.986]
 [0.747]
 [0.78 ]
 [0.783]
 [0.964]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  39.474435689483634
siam score:  -0.9209492
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.641331672668457
actions average: 
K:  0  action  0 :  tensor([    0.9448,     0.0071,     0.0322,     0.0009,     0.0149],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0035,     0.9580,     0.0005,     0.0020,     0.0360],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0000,     0.9783,     0.0114,     0.0101],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0013, 0.0008, 0.0802, 0.6385, 0.2792], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0025, 0.0525, 0.0446, 0.2301, 0.6703], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[36.233]
 [36.233]
 [36.233]
 [36.233]
 [36.233]] [[1.071]
 [1.071]
 [1.071]
 [1.071]
 [1.071]]
line 256 mcts: sample exp_bonus 47.51543408883597
printing an ep nov before normalisation:  28.4004632287122
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.005]
 [0.004]] [[27.413]
 [27.413]
 [27.413]
 [32.317]
 [33.19 ]] [[0.817]
 [0.817]
 [0.817]
 [1.166]
 [1.228]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.972771644592285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.65508035310893
printing an ep nov before normalisation:  35.08207469732558
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[50.586]
 [40.553]
 [40.553]
 [40.553]
 [40.553]] [[1.283]
 [0.921]
 [0.921]
 [0.921]
 [0.921]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.29002957596968
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[47.29]
 [47.29]
 [47.29]
 [47.29]
 [47.29]] [[1.496]
 [1.496]
 [1.496]
 [1.496]
 [1.496]]
printing an ep nov before normalisation:  42.158115922709385
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91364443
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.60372096519665
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.91067266
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.68233871459961
printing an ep nov before normalisation:  32.89271609705137
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.31720223574704
printing an ep nov before normalisation:  47.163904062826255
printing an ep nov before normalisation:  29.188990962604603
printing an ep nov before normalisation:  24.28139787903908
printing an ep nov before normalisation:  27.600219249725342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9042637
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.050249144689296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.24731454579603
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.   ]
 [0.004]
 [0.004]
 [0.004]] [[49.437]
 [44.983]
 [33.01 ]
 [34.026]
 [40.993]] [[0.432]
 [0.367]
 [0.204]
 [0.218]
 [0.315]]
printing an ep nov before normalisation:  46.2703425749778
printing an ep nov before normalisation:  28.402041078748816
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[44.448]
 [44.448]
 [44.448]
 [44.448]
 [44.448]] [[0.418]
 [0.418]
 [0.418]
 [0.418]
 [0.418]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.0601017398969
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.540586948394775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.53150574472369
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.005]
 [0.004]
 [0.004]
 [0.006]] [[48.29 ]
 [53.616]
 [48.29 ]
 [40.655]
 [48.526]] [[0.761]
 [0.921]
 [0.761]
 [0.533]
 [0.769]]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.005]
 [0.005]
 [0.004]] [[27.544]
 [42.402]
 [48.334]
 [42.445]
 [34.594]] [[0.285]
 [0.594]
 [0.718]
 [0.596]
 [0.432]]
siam score:  -0.90691257
printing an ep nov before normalisation:  0.18197922455840398
actions average: 
K:  4  action  0 :  tensor([    0.9995,     0.0003,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0178,     0.9515,     0.0004,     0.0002,     0.0301],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0003,     0.0016,     0.8721,     0.0583,     0.0678],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0009, 0.0018, 0.0824, 0.7160, 0.1989], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0218, 0.0255, 0.0555, 0.2943, 0.6029], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.87645706390911
printing an ep nov before normalisation:  36.22306781499486
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.93362969570532
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[46.414]
 [46.414]
 [46.414]
 [46.414]
 [46.414]] [[0.949]
 [0.949]
 [0.949]
 [0.949]
 [0.949]]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.006]
 [0.006]
 [0.005]
 [0.005]] [[36.092]
 [44.032]
 [45.707]
 [45.837]
 [46.293]] [[0.664]
 [0.881]
 [0.927]
 [0.93 ]
 [0.943]]
printing an ep nov before normalisation:  0.21465914120256002
printing an ep nov before normalisation:  48.37409564294847
printing an ep nov before normalisation:  27.785904837804026
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.54019803232398
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.65006386643097
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[40.917]
 [33.119]
 [33.119]
 [33.119]
 [33.119]] [[1.545]
 [1.069]
 [1.069]
 [1.069]
 [1.069]]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.005]
 [0.007]
 [0.007]
 [0.007]] [[26.298]
 [29.14 ]
 [29.86 ]
 [28.878]
 [29.16 ]] [[1.184]
 [1.448]
 [1.517]
 [1.425]
 [1.452]]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[56.854]
 [50.669]
 [50.669]
 [50.669]
 [50.669]] [[1.362]
 [1.148]
 [1.148]
 [1.148]
 [1.148]]
printing an ep nov before normalisation:  33.88346326602132
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.379749004312
printing an ep nov before normalisation:  44.64980743699133
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.11494292870051
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.008]
 [0.008]
 [0.008]
 [0.008]] [[36.66 ]
 [22.45 ]
 [32.612]
 [34.063]
 [31.515]] [[0.287]
 [0.12 ]
 [0.24 ]
 [0.257]
 [0.227]]
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.009]
 [0.009]
 [0.009]
 [0.009]] [[31.005]
 [23.616]
 [23.616]
 [23.616]
 [23.616]] [[0.631]
 [0.483]
 [0.483]
 [0.483]
 [0.483]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.5392198385029
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.74048804013714
printing an ep nov before normalisation:  36.068888505131746
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[33.326]
 [36.922]
 [33.326]
 [33.326]
 [33.326]] [[1.308]
 [1.572]
 [1.308]
 [1.308]
 [1.308]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  48.6042840663071
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9955,     0.0008,     0.0022,     0.0002,     0.0013],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9976,     0.0005,     0.0010,     0.0009],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0003,     0.0000,     0.8900,     0.0539,     0.0557],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0010, 0.0018, 0.0369, 0.7538, 0.2065], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0030, 0.0039, 0.1137, 0.2254, 0.6540], grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9279,     0.0498,     0.0012,     0.0009,     0.0201],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0055,     0.9845,     0.0001,     0.0002,     0.0098],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0000,     0.9657,     0.0006,     0.0336],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0006,     0.0176,     0.7907,     0.1907],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0031, 0.0357, 0.0589, 0.2968, 0.6055], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.006]
 [0.005]
 [0.005]
 [0.005]] [[32.652]
 [33.363]
 [32.713]
 [34.701]
 [33.848]] [[0.005]
 [0.006]
 [0.005]
 [0.005]
 [0.005]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.99197295925712
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.067854662788875
using explorer policy with actor:  1
siam score:  -0.9027122
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.922802854140485
printing an ep nov before normalisation:  28.721543725248704
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[2.677]
 [8.328]
 [9.041]
 [5.752]
 [5.992]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.32050516974878
printing an ep nov before normalisation:  28.68510490563399
printing an ep nov before normalisation:  59.31416123029601
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.075036201756475
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.006]
 [0.006]
 [0.006]
 [0.005]] [[40.284]
 [38.748]
 [38.748]
 [37.471]
 [41.255]] [[1.147]
 [1.105]
 [1.105]
 [1.068]
 [1.175]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.85078302530037
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.07890796661377
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.003]
 [0.004]
 [0.005]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.005]
 [0.003]
 [0.004]
 [0.005]
 [0.004]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9970,     0.0003,     0.0000,     0.0010,     0.0016],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0117,     0.9374,     0.0031,     0.0006,     0.0472],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0011, 0.0392, 0.8050, 0.0732, 0.0815], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0003,     0.0623,     0.8036,     0.1336],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0003,     0.0020,     0.0617,     0.3107,     0.6254],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  24.306368827819824
printing an ep nov before normalisation:  21.179863918258924
printing an ep nov before normalisation:  34.672129050509646
line 256 mcts: sample exp_bonus 68.4177583453021
printing an ep nov before normalisation:  21.88074827194214
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[33.149]
 [24.574]
 [24.574]
 [24.574]
 [24.574]] [[0.005]
 [0.003]
 [0.003]
 [0.003]
 [0.003]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.005]
 [0.004]
 [0.005]] [[46.447]
 [24.039]
 [31.118]
 [31.29 ]
 [34.44 ]] [[0.004]
 [0.004]
 [0.005]
 [0.004]
 [0.005]]
printing an ep nov before normalisation:  29.570316446343064
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[43.428]
 [46.482]
 [43.428]
 [43.428]
 [43.428]] [[1.206]
 [1.338]
 [1.206]
 [1.206]
 [1.206]]
printing an ep nov before normalisation:  34.19292355159821
printing an ep nov before normalisation:  28.798051820533267
printing an ep nov before normalisation:  29.198757658549056
printing an ep nov before normalisation:  29.36887284168243
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]]
printing an ep nov before normalisation:  0.039611157997256896
printing an ep nov before normalisation:  55.57683653796374
printing an ep nov before normalisation:  56.5478409061981
printing an ep nov before normalisation:  36.329988277035596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.278692467944595
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.411514865661474
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.006]
 [0.005]
 [0.005]] [[46.556]
 [46.556]
 [38.252]
 [46.556]
 [46.556]] [[0.338]
 [0.338]
 [0.243]
 [0.338]
 [0.338]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.53986685236168
printing an ep nov before normalisation:  41.44895274843481
printing an ep nov before normalisation:  72.8187844172017
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.007]
 [0.006]
 [0.006]] [[30.514]
 [34.336]
 [29.676]
 [28.784]
 [28.808]] [[1.005]
 [1.232]
 [0.957]
 [0.903]
 [0.904]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9072478
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[35.598]
 [35.598]
 [35.598]
 [35.598]
 [35.598]] [[0.21]
 [0.21]
 [0.21]
 [0.21]
 [0.21]]
printing an ep nov before normalisation:  25.453463721375645
line 256 mcts: sample exp_bonus 42.40583462545568
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.004]
 [0.006]
 [0.006]
 [0.006]] [[29.89 ]
 [27.369]
 [37.211]
 [32.014]
 [23.701]] [[0.25 ]
 [0.215]
 [0.344]
 [0.277]
 [0.169]]
printing an ep nov before normalisation:  33.2531736941947
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[28.313]
 [29.298]
 [23.853]
 [30.007]
 [29.274]] [[0.998]
 [1.063]
 [0.702]
 [1.11 ]
 [1.061]]
printing an ep nov before normalisation:  18.147798730269095
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.79841709136963
printing an ep nov before normalisation:  20.04868507385254
printing an ep nov before normalisation:  35.272486451462214
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.87514071074179
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.   ]
 [0.005]
 [0.005]
 [0.004]] [[28.344]
 [25.136]
 [34.054]
 [33.271]
 [30.536]] [[0.99 ]
 [0.874]
 [1.189]
 [1.162]
 [1.066]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.65373206018559
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.165576864349443
actions average: 
K:  4  action  0 :  tensor([    0.9963,     0.0000,     0.0000,     0.0015,     0.0021],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0387, 0.8933, 0.0172, 0.0042, 0.0465], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0001,     0.8950,     0.0605,     0.0442],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0093,     0.0006,     0.0665,     0.7390,     0.1846],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0116, 0.0258, 0.0464, 0.2843, 0.6319], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.65356123445947
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.16985461775466
printing an ep nov before normalisation:  36.77697380406032
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.970443411984995
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.   ]
 [0.005]
 [0.006]
 [0.005]] [[43.053]
 [38.493]
 [47.476]
 [52.625]
 [49.537]] [[0.444]
 [0.393]
 [0.49 ]
 [0.543]
 [0.51 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.10590076446533
printing an ep nov before normalisation:  49.0962953699085
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 29.499921076260122
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[45.21 ]
 [45.21 ]
 [45.21 ]
 [48.238]
 [45.21 ]] [[1.222]
 [1.222]
 [1.222]
 [1.338]
 [1.222]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.01009747905051
printing an ep nov before normalisation:  48.4440129077697
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.004]
 [0.005]
 [0.005]
 [0.005]] [[36.197]
 [48.514]
 [55.818]
 [48.987]
 [52.308]] [[0.239]
 [0.431]
 [0.546]
 [0.439]
 [0.491]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 53.00050264483033
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[52.159]
 [37.605]
 [33.42 ]
 [40.887]
 [40.75 ]] [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.595469592388895
printing an ep nov before normalisation:  49.90230881696637
printing an ep nov before normalisation:  39.30662347589252
printing an ep nov before normalisation:  32.723161744219524
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.063713369612174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.347970458194624
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.101007479036696
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.19738716972252
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.004]
 [0.005]
 [0.005]] [[42.916]
 [42.916]
 [52.846]
 [42.916]
 [42.916]] [[1.019]
 [1.019]
 [1.254]
 [1.019]
 [1.019]]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.004]
 [0.004]
 [0.005]] [[52.878]
 [49.466]
 [50.093]
 [43.815]
 [52.644]] [[1.144]
 [1.038]
 [1.057]
 [0.86 ]
 [1.137]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.45721377427853
printing an ep nov before normalisation:  49.343949451898176
printing an ep nov before normalisation:  28.353259563446045
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.990319089821355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.47225674218976
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.014101981138495
printing an ep nov before normalisation:  31.163931453820584
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.30514669418335
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[47.103]
 [47.103]
 [47.103]
 [47.103]
 [47.103]] [[0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.672]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.90596765
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[52.679]
 [52.679]
 [52.679]
 [52.679]
 [52.679]] [[1.602]
 [1.602]
 [1.602]
 [1.602]
 [1.602]]
printing an ep nov before normalisation:  38.90152931520725
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.86989215095232
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  34.59801313877929
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.061384660225926
printing an ep nov before normalisation:  46.43160094939143
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.66551733016968
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.003]
 [0.002]] [[30.475]
 [30.34 ]
 [28.038]
 [35.704]
 [26.271]] [[0.1  ]
 [0.099]
 [0.083]
 [0.136]
 [0.071]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  23.477484594221018
printing an ep nov before normalisation:  26.08048213799747
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.28727566661616
printing an ep nov before normalisation:  39.335541620692055
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]]
printing an ep nov before normalisation:  16.252885799257523
printing an ep nov before normalisation:  33.46546032322974
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.353]
 [28.353]
 [28.353]
 [28.353]
 [26.549]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.52021348508336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9077887
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9826,     0.0049,     0.0000,     0.0039,     0.0085],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0030,     0.9271,     0.0007,     0.0007,     0.0685],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0007,     0.0144,     0.8742,     0.0546,     0.0562],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0005,     0.0031,     0.0555,     0.8053,     0.1356],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0017, 0.0216, 0.1375, 0.2715, 0.5677], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  45.88135434025187
printing an ep nov before normalisation:  26.153271198272705
actions average: 
K:  0  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0001,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9975,     0.0002,     0.0014,     0.0008],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0004,     0.0001,     0.8862,     0.0673,     0.0460],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0005,     0.0599,     0.7447,     0.1944],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0020, 0.0498, 0.2039, 0.1123, 0.6320], grad_fn=<DivBackward0>)
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  28.776802211319502
printing an ep nov before normalisation:  43.12499608373726
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.002]
 [0.002]
 [0.002]] [[34.761]
 [31.775]
 [31.052]
 [33.435]
 [32.418]] [[0.001]
 [0.001]
 [0.002]
 [0.002]
 [0.002]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.666414260864258
printing an ep nov before normalisation:  44.32793084781525
printing an ep nov before normalisation:  39.57041930010323
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.891500360279316
siam score:  -0.9140268
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  47.51941743808415
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.44594469173066
printing an ep nov before normalisation:  50.6373765972292
printing an ep nov before normalisation:  40.2904135024334
actions average: 
K:  4  action  0 :  tensor([0.9125, 0.0349, 0.0010, 0.0011, 0.0505], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9940,     0.0005,     0.0027,     0.0027],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0004,     0.0001,     0.8874,     0.0376,     0.0746],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0009,     0.0002,     0.1217,     0.5881,     0.2892],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0013, 0.0509, 0.1321, 0.2263, 0.5893], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  30.666202969021267
printing an ep nov before normalisation:  30.85724886737953
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.39210117154581
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.385 0.256 0.128 0.077 0.154]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[50.563]
 [50.563]
 [50.563]
 [50.563]
 [50.563]] [[0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[33.087]
 [28.758]
 [42.549]
 [37.758]
 [37.702]] [[0.369]
 [0.268]
 [0.589]
 [0.478]
 [0.477]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  38.0358494733859
actions average: 
K:  0  action  0 :  tensor([    0.9974,     0.0001,     0.0021,     0.0001,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9808,     0.0005,     0.0004,     0.0179],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0008,     0.0002,     0.9352,     0.0364,     0.0274],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0091, 0.0010, 0.0299, 0.8230, 0.1370], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0457, 0.0327, 0.1434, 0.3021, 0.4761], grad_fn=<DivBackward0>)
UNIT TEST: sample policy line 217 mcts : [0.538 0.051 0.051 0.333 0.026]
printing an ep nov before normalisation:  32.44020079789778
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.002]
 [0.002]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.   ]
 [0.002]
 [0.002]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.74089241027832
printing an ep nov before normalisation:  32.09250437301158
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.102049278761875
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
printing an ep nov before normalisation:  37.88043151481538
printing an ep nov before normalisation:  30.83398712783557
printing an ep nov before normalisation:  37.69234827503881
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.029808099433772
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[35.756]
 [32.44 ]
 [26.747]
 [30.845]
 [30.975]] [[0.511]
 [0.437]
 [0.309]
 [0.401]
 [0.404]]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[30.827]
 [30.827]
 [30.827]
 [30.827]
 [30.827]] [[1.298]
 [1.298]
 [1.298]
 [1.298]
 [1.298]]
printing an ep nov before normalisation:  32.70028853443831
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.608]
 [28.608]
 [28.608]
 [28.608]
 [28.608]] [[0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.712]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 27.53708547588345
printing an ep nov before normalisation:  40.55582921052377
printing an ep nov before normalisation:  27.01181411743164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.57479844965065
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.92075835532969
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.862936896515514
printing an ep nov before normalisation:  57.92002699276285
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[30.85 ]
 [31.657]
 [36.067]
 [35.743]
 [35.809]] [[0.8  ]
 [0.844]
 [1.088]
 [1.07 ]
 [1.074]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[38.59 ]
 [38.537]
 [38.59 ]
 [41.354]
 [41.699]] [[1.202]
 [1.2  ]
 [1.202]
 [1.319]
 [1.334]]
printing an ep nov before normalisation:  47.54402665444602
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.85145639411938
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[52.442]
 [52.442]
 [52.442]
 [52.442]
 [52.442]] [[1.168]
 [1.168]
 [1.168]
 [1.168]
 [1.168]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.0536764002577
actions average: 
K:  4  action  0 :  tensor([    0.9993,     0.0000,     0.0001,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0015,     0.9577,     0.0020,     0.0007,     0.0381],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0018,     0.0000,     0.9053,     0.0595,     0.0333],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0042, 0.0050, 0.0838, 0.7535, 0.1535], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0018, 0.0018, 0.0346, 0.2167, 0.7451], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.051 0.077 0.    0.846 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.6241998801552
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.176113523578564
printing an ep nov before normalisation:  60.790888584818155
using explorer policy with actor:  1
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9967,     0.0002,     0.0015,     0.0016],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0006,     0.0002,     0.8981,     0.0383,     0.0629],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0001,     0.0873,     0.7309,     0.1813],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0011, 0.0007, 0.1292, 0.2149, 0.6541], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.52 ]
 [43.971]
 [41.52 ]
 [41.52 ]
 [41.52 ]] [[1.828]
 [2.   ]
 [1.828]
 [1.828]
 [1.828]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.94922060287584
printing an ep nov before normalisation:  24.561547661467667
printing an ep nov before normalisation:  25.98011658737729
siam score:  -0.90570176
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  18.153128027915955
printing an ep nov before normalisation:  28.582139735626136
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.001]
 [0.001]
 [0.001]] [[21.23 ]
 [29.93 ]
 [19.537]
 [20.238]
 [19.779]] [[0.675]
 [1.187]
 [0.576]
 [0.617]
 [0.59 ]]
printing an ep nov before normalisation:  44.68230540422171
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.664]
 [45.683]
 [55.377]
 [52.629]
 [53.136]] [[1.524]
 [1.194]
 [1.652]
 [1.523]
 [1.547]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.43900806419116
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[24.344]
 [26.662]
 [31.458]
 [31.493]
 [31.745]] [[0.638]
 [0.766]
 [1.032]
 [1.034]
 [1.048]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.32321867490142
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9986,     0.0008,     0.0000,     0.0002,     0.0004],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9947,     0.0000,     0.0019,     0.0034],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9224,     0.0435,     0.0341],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0006,     0.0754,     0.7594,     0.1645],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0006, 0.0015, 0.1738, 0.2921, 0.5319], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.812547262381145
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.94703117652561
printing an ep nov before normalisation:  41.4820939225948
printing an ep nov before normalisation:  51.67079554191524
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[45.706]
 [55.777]
 [63.729]
 [56.655]
 [58.094]] [[0.969]
 [1.319]
 [1.596]
 [1.35 ]
 [1.4  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9796,     0.0098,     0.0001,     0.0006,     0.0099],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0287,     0.9271,     0.0140,     0.0000,     0.0301],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0005,     0.8783,     0.0558,     0.0651],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0038, 0.0052, 0.0276, 0.7486, 0.2148], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0010, 0.0026, 0.0796, 0.1661, 0.7507], grad_fn=<DivBackward0>)
siam score:  -0.9111419
printing an ep nov before normalisation:  30.5755877494812
siam score:  -0.90965074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.87882640588474
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.501]
 [21.751]
 [25.233]
 [27.998]
 [23.253]] [[0.278]
 [0.285]
 [0.377]
 [0.45 ]
 [0.324]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.97 ]
 [32.672]
 [30.422]
 [32.932]
 [34.218]] [[0.728]
 [0.759]
 [0.661]
 [0.77 ]
 [0.826]]
printing an ep nov before normalisation:  43.37320230380675
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.153766930384485
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.813437807250196
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.13611937308182
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.615]
 [43.669]
 [40.615]
 [37.795]
 [36.986]] [[0.719]
 [0.822]
 [0.719]
 [0.624]
 [0.597]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.494524807827425
printing an ep nov before normalisation:  49.57913795580157
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.765]
 [40.348]
 [43.291]
 [43.881]
 [43.309]] [[0.42 ]
 [0.701]
 [0.787]
 [0.804]
 [0.788]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.530639018359423
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.889]
 [41.758]
 [41.758]
 [41.758]
 [41.758]] [[2.   ]
 [3.513]
 [3.513]
 [3.513]
 [3.513]]
printing an ep nov before normalisation:  23.521313667297363
actions average: 
K:  1  action  0 :  tensor([    0.9992,     0.0000,     0.0001,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9987,     0.0001,     0.0001,     0.0011],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0043,     0.0003,     0.9153,     0.0263,     0.0538],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0008,     0.0999,     0.7373,     0.1617],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0012, 0.0353, 0.1101, 0.2144, 0.6390], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  39.251320635797065
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.168347358703613
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.93517322842116
printing an ep nov before normalisation:  41.552382232551665
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.905611038208008
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.86508219281363
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.004331986597904
printing an ep nov before normalisation:  43.64723703459003
siam score:  -0.91616577
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9951,     0.0034,     0.0000,     0.0000,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9945,     0.0023,     0.0016,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0004,     0.0002,     0.9530,     0.0232,     0.0231],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0003,     0.0179,     0.8386,     0.1429],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0011, 0.0048, 0.0401, 0.2661, 0.6879], grad_fn=<DivBackward0>)
actions average: 
K:  2  action  0 :  tensor([    0.9982,     0.0001,     0.0000,     0.0002,     0.0015],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0182,     0.9725,     0.0003,     0.0012,     0.0077],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0002,     0.9260,     0.0388,     0.0347],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0006,     0.0010,     0.0339,     0.8266,     0.1379],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0025, 0.0911, 0.0224, 0.3768, 0.5073], grad_fn=<DivBackward0>)
siam score:  -0.91674525
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0230,     0.9064,     0.0017,     0.0000,     0.0689],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0003,     0.0002,     0.9040,     0.0408,     0.0548],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0015, 0.0025, 0.0998, 0.6806, 0.2156], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0041, 0.0019, 0.1093, 0.2336, 0.6511], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.514564590347504
printing an ep nov before normalisation:  35.12621979920701
printing an ep nov before normalisation:  30.93214838773818
printing an ep nov before normalisation:  24.737864107042018
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.71952168965971
printing an ep nov before normalisation:  65.43982276267009
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91434705
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.702585498067513
siam score:  -0.9133342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.37821068966687
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  45.74418924446787
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.614]
 [28.614]
 [28.614]
 [30.755]
 [28.614]] [[1.672]
 [1.672]
 [1.672]
 [1.91 ]
 [1.672]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.68817832568917
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9143037
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.212]
 [32.219]
 [32.219]
 [36.601]
 [32.219]] [[1.694]
 [1.545]
 [1.545]
 [1.871]
 [1.545]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.041853836742746
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.586]
 [35.586]
 [35.586]
 [26.594]
 [35.586]] [[0.667]
 [0.667]
 [0.667]
 [0.346]
 [0.667]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.673]
 [27.889]
 [41.58 ]
 [41.663]
 [35.138]] [[0.048]
 [0.089]
 [0.196]
 [0.197]
 [0.146]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.938]
 [34.074]
 [29.422]
 [25.206]
 [11.193]] [[0.312]
 [0.333]
 [0.288]
 [0.246]
 [0.109]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9617,     0.0008,     0.0001,     0.0324,     0.0050],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0019,     0.9182,     0.0184,     0.0002,     0.0614],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0002,     0.8987,     0.0440,     0.0568],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0113, 0.0009, 0.0729, 0.7460, 0.1689], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0203, 0.0556, 0.0765, 0.3223, 0.5254], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  37.55609294064988
actions average: 
K:  1  action  0 :  tensor([0.9767, 0.0010, 0.0023, 0.0044, 0.0156], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9936,     0.0000,     0.0049,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0013, 0.0013, 0.8524, 0.0591, 0.0859], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0026, 0.0028, 0.0614, 0.6908, 0.2424], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0331, 0.0028, 0.0553, 0.3459, 0.5628], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.79314413907406
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.69 ]
 [28.01 ]
 [40.192]
 [27.791]
 [28.497]] [[0.468]
 [0.446]
 [0.85 ]
 [0.438]
 [0.462]]
printing an ep nov before normalisation:  53.21181418552145
printing an ep nov before normalisation:  61.696116312517596
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.868]
 [22.325]
 [62.224]
 [19.442]
 [20.083]] [[0.23 ]
 [0.219]
 [1.012]
 [0.162]
 [0.175]]
printing an ep nov before normalisation:  25.907427668490403
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.901]
 [34.344]
 [34.098]
 [41.748]
 [39.619]] [[1.015]
 [1.06 ]
 [1.052]
 [1.288]
 [1.223]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.203]
 [47.154]
 [43.76 ]
 [40.873]
 [51.864]] [[0.744]
 [0.618]
 [0.533]
 [0.461]
 [0.736]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.59446449789583
printing an ep nov before normalisation:  37.98750276895611
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.82324977055633
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  55.72454414723305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.182994842051986
printing an ep nov before normalisation:  25.51745696227951
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.121]
 [24.599]
 [25.671]
 [34.787]
 [31.449]] [[0.388]
 [0.342]
 [0.374]
 [0.647]
 [0.547]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.705496008048414
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.8558671950781
siam score:  -0.9140974
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.29820156819287
siam score:  -0.9184232
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92022353
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.28584239800104
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  3  action  0 :  tensor([    0.9891,     0.0023,     0.0000,     0.0029,     0.0057],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9992,     0.0002,     0.0002,     0.0004],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0062,     0.0001,     0.9192,     0.0449,     0.0296],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0117, 0.0015, 0.1051, 0.7693, 0.1123], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0008, 0.0064, 0.0831, 0.2688, 0.6409], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.24447589851231
printing an ep nov before normalisation:  56.978120288455095
printing an ep nov before normalisation:  48.19195404330508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.81720781326294
printing an ep nov before normalisation:  47.197322897745536
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.8700008392334
printing an ep nov before normalisation:  39.00317980683274
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.092]
 [42.424]
 [32.233]
 [32.233]
 [32.233]] [[1.066]
 [0.862]
 [0.55 ]
 [0.55 ]
 [0.55 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9904,     0.0004,     0.0000,     0.0011,     0.0080],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9904,     0.0042,     0.0025,     0.0029],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0023,     0.8709,     0.0792,     0.0474],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0002,     0.0675,     0.7478,     0.1842],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0004,     0.0014,     0.1117,     0.2795,     0.6070],
       grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  55.38231895796192
printing an ep nov before normalisation:  24.623432126264795
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.195]
 [23.997]
 [23.997]
 [32.009]
 [23.997]] [[0.864]
 [0.71 ]
 [0.71 ]
 [0.948]
 [0.71 ]]
siam score:  -0.9100914
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.092035996173436
printing an ep nov before normalisation:  23.963546752929688
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.90872824
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.982]
 [24.982]
 [27.597]
 [27.574]
 [24.982]] [[0.308]
 [0.308]
 [0.364]
 [0.364]
 [0.308]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.22831793311866022
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.083]
 [26.819]
 [28.962]
 [23.929]
 [24.804]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.9061174
printing an ep nov before normalisation:  34.10926342010498
printing an ep nov before normalisation:  35.310990999949766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00046830228086491843
actions average: 
K:  1  action  0 :  tensor([    0.9996,     0.0001,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0210,     0.9689,     0.0004,     0.0002,     0.0095],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0007,     0.0002,     0.8398,     0.0886,     0.0707],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0004,     0.0973,     0.7752,     0.1268],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0070, 0.0829, 0.1084, 0.3131, 0.4886], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  31.173591484369872
printing an ep nov before normalisation:  34.38991334688502
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  48.43595625151068
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.410377502441406
printing an ep nov before normalisation:  59.83540064055595
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  1  action  0 :  tensor([    0.9816,     0.0076,     0.0001,     0.0007,     0.0100],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0282, 0.8981, 0.0119, 0.0049, 0.0569], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0026,     0.0002,     0.9174,     0.0519,     0.0279],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0028, 0.0075, 0.0468, 0.7264, 0.2165], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0062, 0.0415, 0.0679, 0.2007, 0.6837], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.00079361642721
printing an ep nov before normalisation:  46.695629011376084
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.213011078702046
printing an ep nov before normalisation:  31.932098191220174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.051897634896072
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.90604097
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.86697425604264
printing an ep nov before normalisation:  57.306634663599276
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.679]
 [44.679]
 [34.959]
 [44.679]
 [46.674]] [[0.311]
 [0.311]
 [0.206]
 [0.311]
 [0.333]]
printing an ep nov before normalisation:  33.64153861999512
printing an ep nov before normalisation:  43.77612560360013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.633279123278434
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.446]
 [49.119]
 [39.446]
 [39.446]
 [41.842]] [[0.646]
 [0.948]
 [0.646]
 [0.646]
 [0.721]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.590125908706625
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.78814053688284
printing an ep nov before normalisation:  35.51445258872741
printing an ep nov before normalisation:  25.484023744240236
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.781588554382324
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.311162131173273
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.19742298126221
printing an ep nov before normalisation:  39.910896783606624
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.508952800709665
printing an ep nov before normalisation:  0.0013420036594880003
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9800,     0.0005,     0.0001,     0.0105,     0.0089],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9488,     0.0019,     0.0116,     0.0375],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9102,     0.0450,     0.0446],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0015,     0.0262,     0.8091,     0.1629],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0008, 0.0011, 0.1496, 0.3021, 0.5463], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.784854025721415
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  30.71906296762053
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.259595327070052
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.859]
 [58.194]
 [51.859]
 [53.287]
 [53.14 ]] [[0.773]
 [0.907]
 [0.773]
 [0.803]
 [0.8  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.9161438
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.037]
 [43.037]
 [43.037]
 [43.037]
 [43.037]] [[1.289]
 [1.289]
 [1.289]
 [1.289]
 [1.289]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.20135171167409
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  41.41329507006966
printing an ep nov before normalisation:  30.365309715270996
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  69.55413305366848
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  25.965232508523126
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.78162386787873
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.05940819590902
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.489277839660645
printing an ep nov before normalisation:  36.61600291972408
printing an ep nov before normalisation:  26.29568740188436
siam score:  -0.9094658
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.737]
 [50.493]
 [40.737]
 [40.737]
 [40.737]] [[0.526]
 [0.717]
 [0.526]
 [0.526]
 [0.526]]
printing an ep nov before normalisation:  22.479469776153564
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.92420482635498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.1380955329107
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.087]
 [44.162]
 [37.346]
 [44.162]
 [44.162]] [[1.761]
 [1.617]
 [1.367]
 [1.617]
 [1.617]]
printing an ep nov before normalisation:  41.84899463102075
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.33773136138916
printing an ep nov before normalisation:  39.74123910247013
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.64525740723281
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.421]
 [30.17 ]
 [26.378]
 [30.185]
 [26.342]] [[0.301]
 [0.264]
 [0.2  ]
 [0.264]
 [0.2  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.287184641964934
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.199]
 [32.166]
 [29.68 ]
 [22.123]
 [25.674]] [[0.221]
 [0.348]
 [0.309]
 [0.188]
 [0.245]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.69423090846274
printing an ep nov before normalisation:  33.79244107933493
printing an ep nov before normalisation:  15.768744666296685
printing an ep nov before normalisation:  27.56137378325741
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.073]
 [23.073]
 [23.073]
 [23.073]
 [23.073]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  36.537870393516215
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.53373656249769
printing an ep nov before normalisation:  46.349575678016386
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0008,     0.9708,     0.0027,     0.0005,     0.0252],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0004,     0.0001,     0.9199,     0.0487,     0.0309],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0021, 0.0009, 0.0798, 0.7363, 0.1810], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0017, 0.0011, 0.0690, 0.2843, 0.6438], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  23.950652500332286
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.992]
 [58.992]
 [58.992]
 [58.992]
 [58.992]] [[1.952]
 [1.952]
 [1.952]
 [1.952]
 [1.952]]
printing an ep nov before normalisation:  53.472839101356406
printing an ep nov before normalisation:  35.65048176602868
printing an ep nov before normalisation:  24.32351736489023
printing an ep nov before normalisation:  24.806050220283176
printing an ep nov before normalisation:  30.95582919431873
siam score:  -0.915727
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.713637237596608
printing an ep nov before normalisation:  47.64017076927218
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.83936236035127
printing an ep nov before normalisation:  65.36979321787086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.794510434466208
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.02413771035339
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.684340777420196
printing an ep nov before normalisation:  36.704521757104224
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.212090377642795
printing an ep nov before normalisation:  37.319262816901855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.8324453558915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.37686437870925
printing an ep nov before normalisation:  38.62503555325755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.835431071434193
printing an ep nov before normalisation:  38.69829842987262
printing an ep nov before normalisation:  34.02792995487154
printing an ep nov before normalisation:  44.86322942356321
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.397]
 [33.397]
 [33.397]
 [33.397]
 [33.397]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
printing an ep nov before normalisation:  58.655524824458425
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.715]
 [33.389]
 [34.3  ]
 [34.59 ]
 [35.032]] [[0.606]
 [0.715]
 [0.752]
 [0.763]
 [0.781]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.958]
 [35.363]
 [37.967]
 [35.936]
 [32.477]] [[0.202]
 [0.23 ]
 [0.261]
 [0.237]
 [0.197]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  61.45929214704825
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.10303212382259
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 45.32059462089549
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.58]
 [42.58]
 [42.58]
 [42.58]
 [42.58]] [[1.603]
 [1.603]
 [1.603]
 [1.603]
 [1.603]]
printing an ep nov before normalisation:  35.442383982773684
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.79737288392903
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00014003424098518735
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.91 ]
 [55.458]
 [58.91 ]
 [58.91 ]
 [61.511]] [[1.558]
 [1.413]
 [1.558]
 [1.558]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.814]
 [32.814]
 [32.814]
 [32.814]
 [32.814]] [[0.988]
 [0.988]
 [0.988]
 [0.988]
 [0.988]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.54832220077515
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.73196772412499
printing an ep nov before normalisation:  66.3303695128129
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.04249804332837
printing an ep nov before normalisation:  0.00047123676608862297
actions average: 
K:  2  action  0 :  tensor([    0.9861,     0.0003,     0.0002,     0.0069,     0.0066],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9988,     0.0005,     0.0004,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0004,     0.9468,     0.0327,     0.0201],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0010,     0.0751,     0.7514,     0.1725],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0057, 0.0024, 0.0955, 0.3437, 0.5527], grad_fn=<DivBackward0>)
actions average: 
K:  3  action  0 :  tensor([    0.9794,     0.0001,     0.0000,     0.0049,     0.0157],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9998,     0.0001,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0058, 0.0018, 0.7804, 0.1269, 0.0851], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0010, 0.0073, 0.0888, 0.7302, 0.1727], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0073, 0.0450, 0.1099, 0.3128, 0.5251], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.595]
 [21.787]
 [27.156]
 [22.605]
 [22.298]] [[0.1  ]
 [0.093]
 [0.138]
 [0.1  ]
 [0.098]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.587169106186074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.89241886863777
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.51487730569353
printing an ep nov before normalisation:  69.02681397976947
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.9170842
printing an ep nov before normalisation:  38.987405940984786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.404]
 [23.004]
 [19.033]
 [23.262]
 [23.133]] [[0.672]
 [0.645]
 [0.374]
 [0.662]
 [0.654]]
siam score:  -0.9164935
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.092]
 [32.092]
 [54.493]
 [33.99 ]
 [33.108]] [[0.468]
 [0.468]
 [0.957]
 [0.51 ]
 [0.49 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.039532825982604
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.208]
 [33.745]
 [28.971]
 [30.676]
 [31.185]] [[1.026]
 [0.505]
 [0.384]
 [0.427]
 [0.44 ]]
actions average: 
K:  3  action  0 :  tensor([    0.9976,     0.0000,     0.0000,     0.0017,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9774,     0.0011,     0.0016,     0.0197],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0008,     0.9293,     0.0379,     0.0319],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0036, 0.0019, 0.0494, 0.6925, 0.2527], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0046, 0.0722, 0.0591, 0.2403, 0.6239], grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  1
printing an ep nov before normalisation:  50.345645136505674
printing an ep nov before normalisation:  29.31224167086204
printing an ep nov before normalisation:  50.84407696453809
printing an ep nov before normalisation:  60.36149748540542
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.55170042744877
siam score:  -0.9112599
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.513199128288164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.1523795281966
printing an ep nov before normalisation:  33.52876742058378
siam score:  -0.91035676
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.725120139162556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 49.48572705933944
printing an ep nov before normalisation:  43.05278618744336
printing an ep nov before normalisation:  24.997390899976054
printing an ep nov before normalisation:  27.19176288928197
printing an ep nov before normalisation:  45.05445977769405
printing an ep nov before normalisation:  41.8160875522539
printing an ep nov before normalisation:  27.91935837538805
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.66794795782655
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0159, 0.9449, 0.0019, 0.0129, 0.0243], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.8896,     0.0515,     0.0586],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0044,     0.0007,     0.0528,     0.7684,     0.1737],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0002,     0.0008,     0.0769,     0.2591,     0.6630],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.569]
 [29.835]
 [33.604]
 [31.757]
 [27.728]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.50179552077908
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.336156845092773
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.02596601242071
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.345693002551467
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[4.434]
 [2.695]
 [3.358]
 [3.267]
 [3.77 ]] [[0.337]
 [0.205]
 [0.255]
 [0.248]
 [0.286]]
printing an ep nov before normalisation:  23.785403306628826
using explorer policy with actor:  1
printing an ep nov before normalisation:  17.88582506563101
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.19548350346296
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 29.266536729046834
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.695]
 [29.77 ]
 [29.262]
 [29.77 ]
 [29.578]] [[0.562]
 [0.918]
 [0.888]
 [0.918]
 [0.907]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  4.412308385326469e-05
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.5288507550349
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.876]
 [32.646]
 [32.114]
 [31.353]
 [31.841]] [[0.976]
 [1.257]
 [1.218]
 [1.161]
 [1.197]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.252]
 [32.696]
 [25.193]
 [25.044]
 [24.775]] [[0.668]
 [0.841]
 [0.548]
 [0.543]
 [0.532]]
actions average: 
K:  4  action  0 :  tensor([    0.9996,     0.0003,     0.0001,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9768,     0.0014,     0.0000,     0.0217],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0009,     0.0003,     0.8988,     0.0596,     0.0404],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0017, 0.0051, 0.1031, 0.6365, 0.2537], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0607, 0.1240, 0.0283, 0.2229, 0.5641], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.128 0.231 0.154 0.436 0.051]
actions average: 
K:  2  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9740,     0.0000,     0.0001,     0.0258],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0006,     0.0092,     0.8994,     0.0489,     0.0420],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0082, 0.0016, 0.0717, 0.7189, 0.1996], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0206, 0.0297, 0.1081, 0.2754, 0.5662], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.53483157289455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.846]
 [33.249]
 [33.249]
 [33.134]
 [33.249]] [[1.625]
 [1.356]
 [1.356]
 [1.351]
 [1.356]]
printing an ep nov before normalisation:  58.126898588914294
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.142]
 [33.142]
 [33.142]
 [33.142]
 [33.142]] [[1.866]
 [1.866]
 [1.866]
 [1.866]
 [1.866]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.606]
 [28.606]
 [35.7  ]
 [28.606]
 [28.606]] [[0.648]
 [0.648]
 [0.954]
 [0.648]
 [0.648]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.07089926696543
printing an ep nov before normalisation:  26.70280602941368
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.046888117149585
printing an ep nov before normalisation:  60.10000543574957
printing an ep nov before normalisation:  48.48347207026591
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.74042169127114
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.655]
 [32.719]
 [32.719]
 [29.854]
 [36.097]] [[0.648]
 [0.462]
 [0.462]
 [0.385]
 [0.553]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.884531697778556
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.306]
 [34.306]
 [34.306]
 [34.306]
 [34.306]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.848804235458374
printing an ep nov before normalisation:  40.336176079867535
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9127483
printing an ep nov before normalisation:  45.89235193274119
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.89744474826831
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.914]
 [61.122]
 [46.851]
 [59.371]
 [53.683]] [[1.991]
 [2.   ]
 [1.356]
 [1.921]
 [1.665]]
printing an ep nov before normalisation:  34.1596794128418
using explorer policy with actor:  1
siam score:  -0.91360235
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.36485390727115
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.40093571554824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.18525598597691
printing an ep nov before normalisation:  34.85369931292508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.385712762370055
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.45132073743713
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.399]
 [34.399]
 [34.399]
 [34.399]
 [34.399]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.762]
 [26.448]
 [28.18 ]
 [26.835]
 [25.517]] [[0.356]
 [0.528]
 [0.592]
 [0.543]
 [0.494]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.90560537984082
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9189862
printing an ep nov before normalisation:  55.714252704934516
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.302]
 [21.302]
 [21.302]
 [21.302]
 [21.302]] [[0.098]
 [0.098]
 [0.098]
 [0.098]
 [0.098]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.431592036708295
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.176093562778252
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.371]
 [28.371]
 [28.371]
 [23.031]
 [28.371]] [[2.   ]
 [2.   ]
 [2.   ]
 [1.624]
 [2.   ]]
printing an ep nov before normalisation:  32.62195825576782
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.69291941988347
printing an ep nov before normalisation:  54.69539125690155
printing an ep nov before normalisation:  36.23487184236646
printing an ep nov before normalisation:  34.923306194025876
printing an ep nov before normalisation:  38.17019759638159
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.98227071762085
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.043]
 [38.696]
 [44.395]
 [41.951]
 [39.994]] [[0.441]
 [0.746]
 [0.947]
 [0.861]
 [0.792]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.325750645832084
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.490423946124295
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.265]
 [45.265]
 [60.441]
 [49.935]
 [47.222]] [[0.836]
 [0.836]
 [1.225]
 [0.956]
 [0.887]]
line 256 mcts: sample exp_bonus 33.78118954141572
siam score:  -0.9131423
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.5193488169581
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.142]
 [23.63 ]
 [43.44 ]
 [42.033]
 [21.98 ]] [[0.234]
 [0.225]
 [0.556]
 [0.532]
 [0.197]]
printing an ep nov before normalisation:  34.34536339237789
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.094]
 [33.487]
 [37.685]
 [32.644]
 [33.487]] [[0.519]
 [0.994]
 [1.206]
 [0.951]
 [0.994]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.4158728970152
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.52371004035095
printing an ep nov before normalisation:  34.010635091815836
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.299842187421827
printing an ep nov before normalisation:  48.56033683691343
printing an ep nov before normalisation:  45.2282644392652
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.67958066230526
printing an ep nov before normalisation:  31.283009057850595
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.376]
 [32.376]
 [53.722]
 [32.376]
 [32.376]] [[0.369]
 [0.369]
 [0.8  ]
 [0.369]
 [0.369]]
printing an ep nov before normalisation:  24.42125678062439
printing an ep nov before normalisation:  30.32600154373718
printing an ep nov before normalisation:  52.77997107609028
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.948215101662505
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  16198
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.267]
 [31.388]
 [31.388]
 [31.388]
 [31.388]] [[0.772]
 [0.533]
 [0.533]
 [0.533]
 [0.533]]
printing an ep nov before normalisation:  19.447035497053808
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.223]
 [32.554]
 [27.223]
 [27.223]
 [27.223]] [[1.147]
 [1.667]
 [1.147]
 [1.147]
 [1.147]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9186012
siam score:  -0.91990995
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.287]
 [37.495]
 [32.287]
 [32.287]
 [32.287]] [[0.216]
 [0.292]
 [0.216]
 [0.216]
 [0.216]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 37.10899179889975
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.037]
 [43.037]
 [48.384]
 [43.037]
 [43.037]] [[0.953]
 [0.953]
 [1.145]
 [0.953]
 [0.953]]
printing an ep nov before normalisation:  45.75541241472167
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.32207582973353
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.03907305042629
actions average: 
K:  4  action  0 :  tensor([    0.9986,     0.0001,     0.0000,     0.0008,     0.0005],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9657,     0.0001,     0.0008,     0.0333],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0001,     0.9098,     0.0536,     0.0364],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0014, 0.0011, 0.1023, 0.6346, 0.2606], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0246, 0.0724, 0.0661, 0.2799, 0.5570], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.36778725318984
printing an ep nov before normalisation:  25.335144482800782
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.253008217580714
printing an ep nov before normalisation:  33.23602133747052
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 28.548950073000128
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.48724413418476
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.43521499633789
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.29 ]
 [37.565]
 [58.427]
 [51.689]
 [39.873]] [[0.298]
 [0.484]
 [1.02 ]
 [0.847]
 [0.544]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.026 0.538 0.077 0.154 0.205]
using explorer policy with actor:  1
Starting evaluation
printing an ep nov before normalisation:  28.768809750288266
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  16.278048663249873
printing an ep nov before normalisation:  31.860272692249062
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.392]
 [18.915]
 [23.671]
 [17.463]
 [18.483]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  42.792748809996176
rdn beta is 0 so we're just using the maxi policy
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  0.00010792500461320742
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.319]
 [32.782]
 [47.671]
 [32.782]
 [32.782]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.181]
 [33.464]
 [43.834]
 [32.168]
 [33.802]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.876]
 [54.955]
 [41.876]
 [41.876]
 [42.318]] [[0.586]
 [1.034]
 [0.586]
 [0.586]
 [0.601]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.4155586827673
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  63.59882485398849
printing an ep nov before normalisation:  42.67369679583593
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.89755070969941
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.531780521598066
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.93686067691337
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.794]
 [31.794]
 [48.289]
 [31.794]
 [31.794]] [[0.198]
 [0.198]
 [0.41 ]
 [0.198]
 [0.198]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.391776084899902
actions average: 
K:  3  action  0 :  tensor([    0.9995,     0.0001,     0.0000,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9963,     0.0011,     0.0013,     0.0011],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0005,     0.0004,     0.9608,     0.0223,     0.0160],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0026, 0.0012, 0.0415, 0.7333, 0.2215], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0077, 0.0027, 0.0987, 0.2012, 0.6897], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.08047049652557
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9159802
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.608678559232953
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.917935
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.118755339451454
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.39997577667236
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.24902170003707
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
