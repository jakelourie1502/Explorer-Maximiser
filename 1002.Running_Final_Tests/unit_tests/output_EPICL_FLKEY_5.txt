append_mcts_svs:False
dirichlet_alpha:0.3
noise:0.3
dirichlet_alpha:0.5
noise:0.5
sims:{-1: 6, 6000: 40}
c1:1
c2:19652
temperature_init:1
temperature_changes:{-1: 1, 3000000.0: 0.5}
manual_over_ride_play_limit:None
exponent_node_n:1
ucb_denom_k:1
use_policy:True
model_expV_on_dones:True
norm_Qs_OnMaxi:True
norm_Qs_OnAll:True
norm_each_turn:False
state_channels:64
res_block_kernel_size:3
res_block_channels:[32, 32, 64, 64, 64]
res_block_ds:[False, True, False, False, False]
conv1:{'channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1}
conv2:{'channels': 64, 'kernel_size': 3, 'stride': 2, 'padding': 1}
reward_support:[-1, 1, 51]
conv1:{'kernel_size': 3, 'stride': 1, 'padding': 1}
res_blocks:[64]
reward_conv_channels:32
reward_hidden_dim:128
terminal_conv_channels:32
terminal_hidden_dim:64
value_support:[-1, 1, 51]
res_block:[64]
value_conv_channels:32
value_hidden_dim:128
policy_conv_channels:32
policy_hidden_dim:128
expV_conv_channels:32
expV_hidden_dim:128
expV_support:[-10, 10, 51]
proj_l1:256
proj_out:128
pred_hid:256
replay_buffer_size:50000
replay_buffer_size_exploration:200000
all_time_buffer_size:200000
batch_size:128
play_workers:2
min_workers:1
max_workers:6
lr:0.001
lr_warmup:1000
lr_decay:1
lr_decay_step:100000
optimizer:<class 'torch.optim.rmsprop.RMSprop'>
momentum:0.9
l2:0.0001
rho:0.99
k:5
value:0.25
dones:2.0
siam:2
rdn:0.5
expV:0.5
train_start_batch_multiple:2
prioritised_replay:True
ep_to_batch_ratio:[15, 16]
main_to_rdn_ratio:2
train_to_RS_ratio:4
on_policy_expV:False
rgb_im:True
channels:3
state_size:[6, 6]
timesteps_in_obs:2
store_prev_actions:True
env:<class 'game_play.frozen_lake_KEY.gridWorld'>
same_env_each_time:True
env_size:[7, 7]
observable_size:[7, 7]
game_modes:2
env_map:[['H' 'H' 'H' 'H' 'H' 'F' 'G']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F']
 ['S' 'F' 'H' 'H' 'H' 'H' 'H']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'K' 'F']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']]
max_steps:120
actions_size:5
optimal_score:1
total_frames:255000
exp_gamma:0.95
atari_env:False
memory_size:30
reward_clipping:False
image_size:[48, 48]
deque_length:3
PRESET_CONFIG:7
VK:True
use_two_heads:True
follow_better_policy:0.5
use_siam:True
exploration_type:episodic
rdn_beta:[0.3333333333333333, 2, 6]
explorer_percentage:0.8
reward_exploration:False
train_dones:True
contrast_vector:True
norm_state_vecs:False
RND_output_vector:256
RND_loss:cosine
prediction_bias:True
distance_measure:False
update_play_model:16
gamma:0.99
calc_n_step_rewards_after_frames:10000
N_steps_reward:5
start_frame_count:0
load_in_model:False
log_states:True
log_metrics:False
exploration_logger_dims:(2, 49)
device_train:cpu
device_selfplay:cpu
eval_x_frames:10000
eval_count:20
detach_expV_calc:True
use_new_episode_expV:False
start_training_expV_min:10000
start_training_expV_max:20000
start_training_expV_siam_override:0.8
value_only:False
[['H' 'H' 'H' 'H' 'H' 'F' 'G']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F']
 ['S' 'F' 'H' 'H' 'H' 'H' 'H']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'K' 'F']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
from probs:  [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]
Starting evaluation
siam score:  0.0029662597755139523
printing an ep nov before normalisation:  8.021407805103706
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
deleting a thread, now have 2 threads
Frames:  1924 train batches done:  42 episodes:  140
actions average: 
K:  3  action  0 :  tensor([0.4219, 0.1560, 0.0975, 0.1618, 0.1628], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.1708, 0.5656, 0.1126, 0.0099, 0.1411], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.1051, 0.1426, 0.3451, 0.2000, 0.2072], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.2487, 0.0262, 0.1874, 0.3130, 0.2247], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1951, 0.1511, 0.2274, 0.2063, 0.2201], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.40270287
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([0.4479, 0.1838, 0.0622, 0.1579, 0.1482], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.2153, 0.5754, 0.0767, 0.0157, 0.1169], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0736, 0.1198, 0.4566, 0.1832, 0.1668], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.2171, 0.0526, 0.2486, 0.2890, 0.1927], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.3194, 0.1614, 0.1518, 0.1786, 0.1887], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
deleting a thread, now have 1 threads
Frames:  1924 train batches done:  112 episodes:  140
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([0.7424, 0.0182, 0.0149, 0.1159, 0.1085], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.1078, 0.7491, 0.0331, 0.0033, 0.1067], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0391, 0.0809, 0.5243, 0.1842, 0.1715], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.1371, 0.0153, 0.1717, 0.4734, 0.2025], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.2276, 0.0593, 0.1285, 0.2734, 0.3112], grad_fn=<DivBackward0>)
siam score:  -0.50966793
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.52134657
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([0.6676, 0.0526, 0.0034, 0.1390, 0.1374], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0763, 0.8384, 0.0049, 0.0049, 0.0755], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0197, 0.0700, 0.6423, 0.1182, 0.1497], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.1119, 0.0044, 0.1291, 0.5063, 0.2484], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.1221, 0.1067, 0.1692, 0.2809, 0.3212], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.36259078979492
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  45.351506744535826
line 256 mcts: sample exp_bonus 51.80656290054321
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.8751,     0.0050,     0.0005,     0.0571,     0.0623],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0192, 0.8893, 0.0336, 0.0019, 0.0559], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0012, 0.0129, 0.8253, 0.0683, 0.0922], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0974, 0.0061, 0.1107, 0.5124, 0.2733], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0560, 0.1055, 0.1468, 0.2867, 0.4050], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9573,     0.0027,     0.0000,     0.0108,     0.0291],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0319,     0.9148,     0.0045,     0.0005,     0.0482],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0024, 0.0051, 0.8644, 0.0527, 0.0753], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0362, 0.0045, 0.0380, 0.6121, 0.3091], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0372, 0.0108, 0.0709, 0.3140, 0.5672], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.193]
 [33.201]
 [32.813]
 [33.201]
 [33.201]] [[1.464]
 [0.761]
 [0.744]
 [0.761]
 [0.761]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.6210484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  17.207844257354736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([0.8146, 0.0838, 0.0055, 0.0307, 0.0654], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0596, 0.7168, 0.0194, 0.0060, 0.1981], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0016, 0.0542, 0.6523, 0.1878, 0.1041], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0786, 0.0007, 0.1141, 0.5779, 0.2287], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1065, 0.0892, 0.1565, 0.2820, 0.3658], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.67976654
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9832,     0.0004,     0.0000,     0.0097,     0.0066],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0043,     0.9686,     0.0029,     0.0009,     0.0233],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0009,     0.9304,     0.0271,     0.0416],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0048,     0.0003,     0.0127,     0.8058,     0.1764],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0299, 0.0031, 0.0530, 0.4037, 0.5104], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.394259452819824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.553733141075035
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([0.7896, 0.0122, 0.0014, 0.0714, 0.1254], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0055,     0.9482,     0.0029,     0.0003,     0.0432],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0240,     0.6032,     0.1512,     0.2213],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0423, 0.0014, 0.0752, 0.5595, 0.3217], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0412, 0.1302, 0.0344, 0.3028, 0.4913], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7082634
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.  0.8 0.2 0.  0. ]
line 256 mcts: sample exp_bonus 0.0
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.060280329594185
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.627]
 [32.735]
 [32.735]
 [32.735]
 [32.735]] [[1.333]
 [0.693]
 [0.693]
 [0.693]
 [0.693]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7143089
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.719495860779894
printing an ep nov before normalisation:  24.578875772451916
printing an ep nov before normalisation:  69.81387138366699
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([0.8718, 0.0031, 0.0013, 0.0446, 0.0792], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0342,     0.8470,     0.0311,     0.0004,     0.0873],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0069, 0.0275, 0.7444, 0.0570, 0.1641], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0124, 0.0017, 0.1313, 0.5537, 0.3009], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0449, 0.0806, 0.0563, 0.2769, 0.5414], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.7141127
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.827752590179443
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.03900026236742
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7216539
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.992]
 [69.992]
 [69.992]
 [69.992]
 [69.992]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.7259334111441
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.997]
 [46.447]
 [53.481]
 [41.476]
 [41.389]] [[0.539]
 [0.986]
 [1.358]
 [0.723]
 [0.718]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.284799575805664
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.14053884410967
printing an ep nov before normalisation:  82.45119896764535
printing an ep nov before normalisation:  46.23751587762342
siam score:  -0.70939577
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 59.7601970900446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
siam score:  -0.6938861
printing an ep nov before normalisation:  51.00624553985071
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.727]
 [46.048]
 [53.752]
 [51.696]
 [48.813]] [[1.539]
 [1.182]
 [1.466]
 [1.391]
 [1.284]]
line 256 mcts: sample exp_bonus 71.04563871450118
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.34207326873022
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.179]
 [37.439]
 [48.881]
 [41.584]
 [37.764]] [[0.288]
 [0.281]
 [0.389]
 [0.32 ]
 [0.284]]
printing an ep nov before normalisation:  56.47885086717216
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.45437894094063
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.28611895261068
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.25133324111198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.9240110784127
maxi score, test score, baseline:  0.0001 0.0 0.0001
main train batch thing paused
add a thread
Adding thread: now have 2 threads
printing an ep nov before normalisation:  31.43275213778054
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.782]
 [61.782]
 [61.782]
 [66.239]
 [61.782]] [[0.509]
 [0.509]
 [0.509]
 [0.586]
 [0.509]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.048]
 [36.041]
 [35.128]
 [46.406]
 [48.478]] [[0.743]
 [0.603]
 [0.571]
 [0.965]
 [1.038]]
printing an ep nov before normalisation:  86.61625966728704
printing an ep nov before normalisation:  34.173515089421755
printing an ep nov before normalisation:  56.42524242401123
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.76731576583101
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 87.92815866947912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.787075996398926
printing an ep nov before normalisation:  70.46926729817304
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.35418479589381
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.33 ]
 [50.987]
 [44.691]
 [34.098]
 [34.104]] [[0.704]
 [1.043]
 [0.822]
 [0.45 ]
 [0.45 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.55232184818905
printing an ep nov before normalisation:  35.95092500571013
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  17.341359577451385
printing an ep nov before normalisation:  30.903269146108414
printing an ep nov before normalisation:  49.68401096988579
siam score:  -0.74397326
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.35480286674472
printing an ep nov before normalisation:  53.15890498662803
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.48 ]
 [25.359]
 [29.521]
 [25.162]
 [43.132]] [[0.333]
 [0.411]
 [0.524]
 [0.406]
 [0.895]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.226611289846
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.425]
 [79.425]
 [79.425]
 [79.425]
 [79.425]] [[1.451]
 [1.451]
 [1.451]
 [1.451]
 [1.451]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.913021087646484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[106.917]
 [106.917]
 [106.917]
 [106.917]
 [106.917]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.54112687602442
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.8971,     0.0119,     0.0001,     0.0346,     0.0563],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0019,     0.9359,     0.0236,     0.0002,     0.0384],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0019, 0.0054, 0.7718, 0.0625, 0.1584], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0741, 0.0005, 0.0517, 0.4786, 0.3951], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.1311, 0.1217, 0.1616, 0.1378, 0.4479], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.75120527
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9343,     0.0371,     0.0000,     0.0087,     0.0199],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0065,     0.9796,     0.0033,     0.0001,     0.0105],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0090,     0.8192,     0.1051,     0.0667],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.2421,     0.0002,     0.2081,     0.4006,     0.1491],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.1404, 0.1511, 0.0779, 0.2337, 0.3970], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.419]
 [40.419]
 [47.114]
 [40.419]
 [40.419]] [[1.423]
 [1.423]
 [1.746]
 [1.423]
 [1.423]]
printing an ep nov before normalisation:  34.420228789697504
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.53975895857333
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.339]
 [29.92 ]
 [38.773]
 [34.799]
 [29.92 ]] [[1.148]
 [0.718]
 [1.231]
 [1.001]
 [0.718]]
printing an ep nov before normalisation:  113.62885056435061
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.837]
 [54.445]
 [54.199]
 [53.482]
 [52.507]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.793154074141867
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.74234612785222
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.9087727361846
actions average: 
K:  2  action  0 :  tensor([    0.9457,     0.0041,     0.0004,     0.0131,     0.0367],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0008,     0.9847,     0.0048,     0.0011,     0.0087],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0022,     0.9447,     0.0283,     0.0248],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0628,     0.0005,     0.0225,     0.6023,     0.3118],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0553, 0.0560, 0.0198, 0.3441, 0.5247], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.389252531336986
actions average: 
K:  2  action  0 :  tensor([    0.9313,     0.0003,     0.0002,     0.0186,     0.0496],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0425,     0.8735,     0.0149,     0.0005,     0.0685],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0012,     0.8464,     0.0304,     0.1217],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0018,     0.0001,     0.0389,     0.6631,     0.2961],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0630, 0.0041, 0.0816, 0.2520, 0.5991], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.97 ]
 [57.893]
 [62.915]
 [57.556]
 [56.607]] [[0.968]
 [1.142]
 [1.365]
 [1.127]
 [1.085]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.813]
 [50.17 ]
 [62.734]
 [60.421]
 [48.1  ]] [[0.473]
 [0.46 ]
 [0.715]
 [0.668]
 [0.419]]
printing an ep nov before normalisation:  81.81472920145914
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.24316959720899
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.79217592441549
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.903]
 [72.755]
 [79.292]
 [72.755]
 [72.755]] [[1.228]
 [1.294]
 [1.529]
 [1.294]
 [1.294]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.1542118513842
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.9566244069899
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.581]
 [69.833]
 [62.409]
 [57.581]
 [57.581]] [[1.302]
 [1.775]
 [1.488]
 [1.302]
 [1.302]]
printing an ep nov before normalisation:  106.86345098306451
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  97.64280862418516
printing an ep nov before normalisation:  66.77302441395128
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.928]
 [50.928]
 [50.928]
 [50.928]
 [50.928]] [[1.205]
 [1.205]
 [1.205]
 [1.205]
 [1.205]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.007]
 [19.007]
 [20.73 ]
 [23.211]
 [19.007]] [[1.194]
 [1.194]
 [1.368]
 [1.619]
 [1.194]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.802]
 [70.374]
 [72.277]
 [57.505]
 [56.302]] [[0.561]
 [0.832]
 [0.855]
 [0.678]
 [0.663]]
actions average: 
K:  3  action  0 :  tensor([    0.7859,     0.1170,     0.0000,     0.0419,     0.0551],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0341,     0.9524,     0.0016,     0.0002,     0.0117],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0086,     0.8927,     0.0123,     0.0864],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0023,     0.0003,     0.0856,     0.6042,     0.3076],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0303, 0.0825, 0.1582, 0.1936, 0.5353], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.023]
 [67.352]
 [67.966]
 [67.352]
 [67.352]] [[0.765]
 [0.681]
 [0.692]
 [0.681]
 [0.681]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.126]
 [62.446]
 [67.905]
 [74.288]
 [64.409]] [[0.907]
 [0.788]
 [0.886]
 [1.   ]
 [0.823]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.111037345275435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  32.1140554881155
printing an ep nov before normalisation:  53.02318572998047
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  99.92243549681913
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.612]
 [68.612]
 [68.612]
 [68.612]
 [68.612]] [[1.306]
 [1.306]
 [1.306]
 [1.306]
 [1.306]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.713]
 [29.373]
 [27.308]
 [29.905]
 [26.99 ]] [[0.786]
 [0.471]
 [0.437]
 [0.479]
 [0.432]]
printing an ep nov before normalisation:  0.09595113325417515
printing an ep nov before normalisation:  83.48001594896729
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.49691141575899
printing an ep nov before normalisation:  47.5838049383816
actions average: 
K:  3  action  0 :  tensor([    0.9869,     0.0025,     0.0005,     0.0024,     0.0077],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0020,     0.9967,     0.0000,     0.0000,     0.0013],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0019, 0.0099, 0.8522, 0.0499, 0.0860], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.1298, 0.0014, 0.1315, 0.4564, 0.2809], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1159, 0.0112, 0.1645, 0.2641, 0.4443], grad_fn=<DivBackward0>)
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  82.47081223329528
printing an ep nov before normalisation:  47.03838343610565
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  88.7732403640471
printing an ep nov before normalisation:  73.82169790031956
printing an ep nov before normalisation:  50.97806886465868
printing an ep nov before normalisation:  1.5029615283049225
printing an ep nov before normalisation:  43.60763072967529
printing an ep nov before normalisation:  49.17263524572783
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.147113474833716
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.564]
 [15.115]
 [38.413]
 [20.885]
 [12.404]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  68.08938293493735
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  255000
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.782]
 [34.653]
 [32.641]
 [34.563]
 [29.566]] [[1.236]
 [1.228]
 [1.103]
 [1.222]
 [0.913]]
printing an ep nov before normalisation:  84.63164225388077
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.89 ]
 [39.191]
 [35.386]
 [25.58 ]
 [26.918]] [[0.529]
 [0.989]
 [0.847]
 [0.48 ]
 [0.53 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7591577
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.893621622601394
printing an ep nov before normalisation:  8.380770504428483
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  59.39200870329111
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.592]
 [45.098]
 [45.098]
 [54.708]
 [45.098]] [[0.957]
 [0.863]
 [0.863]
 [1.225]
 [0.863]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.852800564972352
printing an ep nov before normalisation:  47.76291810466602
printing an ep nov before normalisation:  75.97532996268492
printing an ep nov before normalisation:  50.756200169561836
siam score:  -0.7708888
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  84.28419019901719
printing an ep nov before normalisation:  90.92900276184082
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.06845640323074
printing an ep nov before normalisation:  72.07803955318536
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.8046875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.822444077084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.337]
 [30.723]
 [24.495]
 [22.148]
 [24.228]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.77408075
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.492038021994816
printing an ep nov before normalisation:  41.206793785095215
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.89 ]
 [50.289]
 [66.891]
 [70.864]
 [63.189]] [[0.629]
 [0.503]
 [0.67 ]
 [0.709]
 [0.632]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  57.300250678796694
printing an ep nov before normalisation:  1.4242186798941248
printing an ep nov before normalisation:  73.83050717705501
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.922570780535345
printing an ep nov before normalisation:  130.2181567978759
using explorer policy with actor:  1
printing an ep nov before normalisation:  82.04912529092766
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.419]
 [45.001]
 [41.062]
 [46.601]
 [46.   ]] [[1.555]
 [1.234]
 [1.037]
 [1.314]
 [1.284]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.055]
 [62.547]
 [84.903]
 [88.807]
 [82.571]] [[0.546]
 [0.416]
 [0.565]
 [0.591]
 [0.549]]
actions average: 
K:  1  action  0 :  tensor([    0.9986,     0.0001,     0.0000,     0.0008,     0.0006],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0391,     0.9433,     0.0005,     0.0002,     0.0170],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0009,     0.8656,     0.0523,     0.0812],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0008,     0.0003,     0.0521,     0.6148,     0.3320],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0369, 0.0015, 0.0269, 0.3000, 0.6347], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.120764978017945
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 1.9573472805723213
actions average: 
K:  0  action  0 :  tensor([    0.9960,     0.0012,     0.0000,     0.0014,     0.0015],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0466,     0.9467,     0.0026,     0.0001,     0.0039],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0249, 0.0021, 0.9374, 0.0185, 0.0171], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0008,     0.0002,     0.0486,     0.7127,     0.2377],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0031, 0.0011, 0.0651, 0.2083, 0.7225], grad_fn=<DivBackward0>)
actions average: 
K:  2  action  0 :  tensor([    0.9788,     0.0035,     0.0000,     0.0086,     0.0091],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0626,     0.8863,     0.0004,     0.0004,     0.0504],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0005,     0.9449,     0.0213,     0.0333],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0020,     0.0497,     0.7404,     0.2077],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0034, 0.0090, 0.0592, 0.3565, 0.5719], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  84.64070698346576
using explorer policy with actor:  1
printing an ep nov before normalisation:  70.91451705570421
printing an ep nov before normalisation:  36.29286527633667
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.42505704528311
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.04796205903048
printing an ep nov before normalisation:  74.9435329597107
siam score:  -0.7767811
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  59.19352054595947
printing an ep nov before normalisation:  62.283609977386064
printing an ep nov before normalisation:  49.73419084268503
printing an ep nov before normalisation:  64.42038809580869
printing an ep nov before normalisation:  76.91225024892229
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0. 0. 1. 0. 0.]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.337]
 [67.902]
 [67.7  ]
 [63.409]
 [64.292]] [[0.606]
 [0.829]
 [0.826]
 [0.772]
 [0.783]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.641447508060146
printing an ep nov before normalisation:  78.24742324885662
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  79.17993087251591
using explorer policy with actor:  1
printing an ep nov before normalisation:  141.71341580818213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
deleting a thread, now have 1 threads
Frames:  12618 train batches done:  1474 episodes:  681
siam score:  -0.74773544
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.36485298605048
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.058]
 [62.259]
 [58.107]
 [67.889]
 [65.442]] [[0.992]
 [1.024]
 [0.913]
 [1.175]
 [1.11 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.21638528220165
printing an ep nov before normalisation:  34.39529620929844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.31113284238516
printing an ep nov before normalisation:  66.97378128237645
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7701828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.95318920719235
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.159]
 [68.082]
 [68.082]
 [68.082]
 [68.082]] [[1.667]
 [1.496]
 [1.496]
 [1.496]
 [1.496]]
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9670,     0.0020,     0.0000,     0.0160,     0.0150],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0089,     0.9811,     0.0001,     0.0005,     0.0095],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0259,     0.8938,     0.0167,     0.0635],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0008, 0.0027, 0.0505, 0.6786, 0.2674], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0014, 0.0228, 0.0925, 0.2586, 0.6247], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.03181090851741
printing an ep nov before normalisation:  67.01127479507161
printing an ep nov before normalisation:  86.8409669583655
siam score:  -0.7798927
actions average: 
K:  1  action  0 :  tensor([    0.9910,     0.0033,     0.0000,     0.0003,     0.0055],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0100,     0.9777,     0.0033,     0.0008,     0.0081],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0002,     0.9632,     0.0146,     0.0218],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0011,     0.0003,     0.1527,     0.6487,     0.1972],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0545, 0.0113, 0.0031, 0.4093, 0.5218], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.670494229849126
printing an ep nov before normalisation:  52.615916259310076
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.02039294396596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.25495510901825
actions average: 
K:  0  action  0 :  tensor([    0.9906,     0.0014,     0.0006,     0.0031,     0.0044],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0009,     0.9421,     0.0013,     0.0015,     0.0543],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0002,     0.8603,     0.0462,     0.0932],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0009,     0.0005,     0.0790,     0.7022,     0.2174],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0044, 0.0018, 0.0247, 0.3948, 0.5744], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9504,     0.0004,     0.0004,     0.0219,     0.0270],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0068, 0.8360, 0.0296, 0.0302, 0.0975], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9698,     0.0125,     0.0177],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.1141, 0.0006, 0.0555, 0.5355, 0.2944], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0979, 0.0404, 0.1173, 0.1473, 0.5970], grad_fn=<DivBackward0>)
actions average: 
K:  2  action  0 :  tensor([    0.9950,     0.0007,     0.0000,     0.0015,     0.0028],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0332,     0.9586,     0.0003,     0.0003,     0.0076],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0029, 0.0064, 0.7989, 0.0528, 0.1389], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0065,     0.0003,     0.0746,     0.6003,     0.3184],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0104, 0.0171, 0.1042, 0.1557, 0.7126], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.60836187011076
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.218]
 [75.577]
 [55.601]
 [70.957]
 [75.577]] [[1.403]
 [1.625]
 [1.021]
 [1.485]
 [1.625]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.97292630174037
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  68.21375670756981
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.641388665293604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.63509876847912
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.328]
 [70.328]
 [69.775]
 [70.328]
 [73.547]] [[0.452]
 [0.452]
 [0.446]
 [0.452]
 [0.488]]
printing an ep nov before normalisation:  57.31398491223084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.97346163521902
printing an ep nov before normalisation:  72.89187736658286
printing an ep nov before normalisation:  78.6311274147216
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.684]
 [45.464]
 [56.715]
 [57.332]
 [56.715]] [[1.217]
 [0.571]
 [0.97 ]
 [0.992]
 [0.97 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.426]
 [37.651]
 [37.651]
 [37.651]
 [37.651]] [[0.597]
 [0.462]
 [0.462]
 [0.462]
 [0.462]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.31501181855096
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.7964897
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.687]
 [71.687]
 [68.86 ]
 [75.285]
 [71.687]] [[1.449]
 [1.449]
 [1.34 ]
 [1.588]
 [1.449]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.56725338693247
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.053]
 [69.053]
 [69.053]
 [69.053]
 [69.053]] [[1.517]
 [1.517]
 [1.517]
 [1.517]
 [1.517]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.51463919969198
printing an ep nov before normalisation:  46.964030265808105
printing an ep nov before normalisation:  37.55589008331299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.202]
 [83.202]
 [83.202]
 [83.202]
 [83.202]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
printing an ep nov before normalisation:  50.126594114702606
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.18323392673739
actions average: 
K:  1  action  0 :  tensor([    0.9986,     0.0002,     0.0000,     0.0002,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9980,     0.0001,     0.0000,     0.0017],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0001,     0.9480,     0.0278,     0.0239],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0062,     0.0002,     0.0014,     0.6608,     0.3314],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0028, 0.0018, 0.0357, 0.3546, 0.6051], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  72.34208309701
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.97642195688945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.574]
 [93.574]
 [93.574]
 [93.574]
 [93.574]] [[0.955]
 [0.955]
 [0.955]
 [0.955]
 [0.955]]
STARTED EXPV TRAINING ON FRAME NO.  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.19014525098987
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.38283635556206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.61404666934619
printing an ep nov before normalisation:  57.57269043922548
siam score:  -0.78567183
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.232]
 [62.232]
 [62.232]
 [62.232]
 [62.232]] [[0.969]
 [0.969]
 [0.969]
 [0.969]
 [0.969]]
printing an ep nov before normalisation:  70.94146507109019
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.77678216
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  19.401326179504395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.91920059802587
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.983565147331554
siam score:  -0.77136964
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.7152358306888
printing an ep nov before normalisation:  69.29196137489048
printing an ep nov before normalisation:  57.902135677236544
printing an ep nov before normalisation:  118.16449243193249
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.7809416
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.16 ]
 [65.16 ]
 [77.469]
 [65.16 ]
 [65.16 ]] [[1.079]
 [1.079]
 [1.409]
 [1.079]
 [1.079]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.78983974456787
siam score:  -0.7870198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.2369299959057
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  14482
printing an ep nov before normalisation:  79.98257126015687
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.153]
 [50.636]
 [49.308]
 [44.792]
 [46.153]] [[1.176]
 [1.393]
 [1.329]
 [1.11 ]
 [1.176]]
printing an ep nov before normalisation:  64.3482052342673
line 256 mcts: sample exp_bonus 65.4476889850578
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.12971257738789
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  87.4285232196466
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.30079746246338
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.87 ]
 [41.861]
 [39.882]
 [33.816]
 [41.657]] [[1.183]
 [0.707]
 [0.651]
 [0.481]
 [0.701]]
printing an ep nov before normalisation:  56.901532025941606
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.035]
 [49.217]
 [49.217]
 [49.217]
 [49.217]] [[1.515]
 [0.936]
 [0.936]
 [0.936]
 [0.936]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.778]
 [66.778]
 [66.778]
 [66.778]
 [66.778]] [[1.487]
 [1.487]
 [1.487]
 [1.487]
 [1.487]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.62591131609537
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.79209285868914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.11479519795768
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.79648964217274
printing an ep nov before normalisation:  80.34132431134708
siam score:  -0.80296344
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.9870548248291
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.736]
 [83.736]
 [83.736]
 [83.736]
 [83.736]] [[1.419]
 [1.419]
 [1.419]
 [1.419]
 [1.419]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.9613754527533
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.79161341846442
main train batch thing paused
add a thread
Adding thread: now have 2 threads
printing an ep nov before normalisation:  87.29747346857336
using explorer policy with actor:  1
printing an ep nov before normalisation:  62.62092671249255
line 256 mcts: sample exp_bonus 67.5138374454494
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.76425071203829
printing an ep nov before normalisation:  56.612837490990984
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.166]
 [64.166]
 [71.195]
 [64.166]
 [64.166]] [[1.59 ]
 [1.59 ]
 [1.825]
 [1.59 ]
 [1.59 ]]
printing an ep nov before normalisation:  115.64726401085862
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  79.82284366375883
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.36047887802124
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.76637336022115
printing an ep nov before normalisation:  81.63500021099954
line 256 mcts: sample exp_bonus 91.56469951532327
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.183]
 [44.372]
 [44.372]
 [44.372]
 [44.372]] [[1.16 ]
 [0.288]
 [0.288]
 [0.288]
 [0.288]]
UNIT TEST: sample policy line 217 mcts : [0.051 0.128 0.051 0.744 0.026]
printing an ep nov before normalisation:  65.89845561604265
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.2360447169972
using explorer policy with actor:  1
printing an ep nov before normalisation:  82.23150170753826
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.505988121032715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.20879666724622
printing an ep nov before normalisation:  82.59590389633411
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.19565275849106
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.337]
 [80.966]
 [86.993]
 [48.254]
 [83.114]] [[0.423]
 [0.411]
 [0.442]
 [0.245]
 [0.422]]
printing an ep nov before normalisation:  0.9471820709677559
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.11292485171742
siam score:  -0.7921164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.41521424124589
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.587]
 [31.315]
 [31.902]
 [29.727]
 [29.403]] [[0.34 ]
 [0.504]
 [0.521]
 [0.459]
 [0.449]]
siam score:  -0.791651
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.54808536277257
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  113.12064170837402
printing an ep nov before normalisation:  90.50466724059004
printing an ep nov before normalisation:  44.63626335205478
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.79679290305582
printing an ep nov before normalisation:  55.85488419523396
actions average: 
K:  3  action  0 :  tensor([    0.9268,     0.0006,     0.0000,     0.0337,     0.0389],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0005,     0.9921,     0.0001,     0.0000,     0.0072],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0041, 0.0055, 0.9159, 0.0347, 0.0399], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0013,     0.0991,     0.7282,     0.1711],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0002,     0.0033,     0.0809,     0.3359,     0.5795],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.752]
 [68.752]
 [68.752]
 [68.752]
 [68.752]] [[68.752]
 [68.752]
 [68.752]
 [68.752]
 [68.752]]
printing an ep nov before normalisation:  91.3897698477345
siam score:  -0.80571747
printing an ep nov before normalisation:  57.37559359273334
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.881]
 [50.886]
 [55.241]
 [43.358]
 [40.537]] [[0.648]
 [1.009]
 [1.152]
 [0.762]
 [0.67 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.538]
 [54.538]
 [64.511]
 [76.134]
 [54.538]] [[0.622]
 [0.622]
 [0.838]
 [1.091]
 [0.622]]
printing an ep nov before normalisation:  67.85461396550978
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.60748976723362
printing an ep nov before normalisation:  77.8407590356677
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.309126024248805
printing an ep nov before normalisation:  52.76707711348134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.10686341095878
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.610710387570407
printing an ep nov before normalisation:  71.97910672701873
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8046166
printing an ep nov before normalisation:  35.68184277423282
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.131]
 [42.844]
 [38.453]
 [37.131]
 [37.131]] [[0.48 ]
 [0.641]
 [0.517]
 [0.48 ]
 [0.48 ]]
printing an ep nov before normalisation:  52.68744355963156
printing an ep nov before normalisation:  45.49421310424805
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.51018158182937
printing an ep nov before normalisation:  99.00282546217014
printing an ep nov before normalisation:  52.179145112068085
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.2118042721595
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  124.38455187513574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.248]
 [54.984]
 [81.876]
 [73.714]
 [45.058]] [[0.134]
 [0.302]
 [0.544]
 [0.471]
 [0.213]]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 0.0
0.0 -4.1478123266842726e-10
0.0 0.0
0.0 -3.090879583717104e-10
0.0 -4.8674261094433e-10
0.0 -3.035870645490052e-10
0.0 -7.034916661178084e-10
0.0 -5.74687718385996e-10
0.0 0.0
0.0 -9.124564376348236e-10
printing an ep nov before normalisation:  91.66754174632929
printing an ep nov before normalisation:  89.28489444891792
printing an ep nov before normalisation:  104.18888481368498
printing an ep nov before normalisation:  77.2243776473606
actions average: 
K:  3  action  0 :  tensor([    0.9881,     0.0009,     0.0000,     0.0040,     0.0070],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0017,     0.9957,     0.0004,     0.0000,     0.0022],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0004,     0.0024,     0.8497,     0.0641,     0.0834],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0020, 0.0237, 0.1147, 0.6456, 0.2140], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0035, 0.0095, 0.1031, 0.2871, 0.5969], grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 36.56068973308443
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.14518045441037
printing an ep nov before normalisation:  48.75891497179076
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.68246749961416
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.46959114074707
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  115.7845687866211
printing an ep nov before normalisation:  26.330115408840555
line 256 mcts: sample exp_bonus 98.35567790726806
printing an ep nov before normalisation:  97.91967874799568
siam score:  -0.7968788
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  91.74794989834012
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.7346221273032
printing an ep nov before normalisation:  69.78362584894413
actions average: 
K:  0  action  0 :  tensor([0.9747, 0.0158, 0.0018, 0.0057, 0.0019], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0006,     0.9761,     0.0027,     0.0000,     0.0205],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0020,     0.0009,     0.9703,     0.0257,     0.0011],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0012, 0.0009, 0.0293, 0.6569, 0.3117], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0009, 0.0029, 0.0877, 0.3609, 0.5475], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  120.92909974386373
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.496]
 [ 0.   ]
 [ 0.   ]
 [46.518]
 [ 0.   ]] [[ 0.647]
 [-0.375]
 [-0.375]
 [ 0.309]
 [-0.375]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.5497555339627525
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.68919434238451
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.59286662873997
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.747]
 [52.87 ]
 [52.87 ]
 [52.87 ]
 [52.87 ]] [[1.343]
 [1.12 ]
 [1.12 ]
 [1.12 ]
 [1.12 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
siam score:  -0.8132517
siam score:  -0.81401926
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.6627102488901
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.83875714964461
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.30875492095947
printing an ep nov before normalisation:  42.10853596348322
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.84222403613279
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.86990129936055
printing an ep nov before normalisation:  48.947977218424
printing an ep nov before normalisation:  38.61839294433594
printing an ep nov before normalisation:  83.6196295004924
siam score:  -0.813981
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[150.198]
 [155.824]
 [155.176]
 [155.824]
 [155.824]] [[1.56 ]
 [1.654]
 [1.643]
 [1.654]
 [1.654]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.68945264816284
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.44427564572405
printing an ep nov before normalisation:  96.37333937912209
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.66846030099052
printing an ep nov before normalisation:  0.09487685917974886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.20347541548614
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.629]
 [47.748]
 [47.24 ]
 [66.298]
 [53.977]] [[0.763]
 [0.602]
 [0.585]
 [1.213]
 [0.807]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.736]
 [48.736]
 [48.736]
 [48.736]
 [48.736]] [[1.579]
 [1.579]
 [1.579]
 [1.579]
 [1.579]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.7894535
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  67.59102256959105
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.08943176269531
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.64007249227049
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.822]
 [73.903]
 [81.284]
 [86.681]
 [72.848]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  58.23539193834223
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.95367305004355
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.43704496744162
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.55741958524403
printing an ep nov before normalisation:  44.3111936423609
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.50927299305545
printing an ep nov before normalisation:  76.80317839360626
printing an ep nov before normalisation:  89.92174556267527
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.08522792446105
actions average: 
K:  2  action  0 :  tensor([    0.9733,     0.0004,     0.0000,     0.0099,     0.0164],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9870,     0.0016,     0.0010,     0.0104],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0003,     0.0033,     0.9105,     0.0337,     0.0523],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0006,     0.0381,     0.6756,     0.2854],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0001,     0.0053,     0.0727,     0.2772,     0.6447],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  122.42171793312589
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  108.22846268486865
printing an ep nov before normalisation:  88.49482257384908
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.27511308806721
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.93137160519532
siam score:  -0.8059456
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.38420548488335
printing an ep nov before normalisation:  80.55559823022037
printing an ep nov before normalisation:  56.39256343756192
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.66980070120065
printing an ep nov before normalisation:  45.25697783710126
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.48180853671401
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  137.8213831105566
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.136]
 [52.799]
 [65.924]
 [52.799]
 [52.799]] [[0.481]
 [0.509]
 [0.732]
 [0.509]
 [0.509]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.53733825683594
printing an ep nov before normalisation:  52.040035611433396
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.154]
 [59.154]
 [59.154]
 [59.154]
 [59.154]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.945]
 [73.067]
 [74.284]
 [73.618]
 [71.692]] [[1.252]
 [1.256]
 [1.294]
 [1.273]
 [1.212]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.63 ]
 [53.397]
 [53.397]
 [53.397]
 [53.397]] [[0.826]
 [0.735]
 [0.735]
 [0.735]
 [0.735]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.672]
 [67.672]
 [69.566]
 [67.672]
 [67.672]] [[1.455]
 [1.455]
 [1.525]
 [1.455]
 [1.455]]
printing an ep nov before normalisation:  43.46933043046947
printing an ep nov before normalisation:  59.674664951490755
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.65519549697809
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.94381282259685
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.512]
 [69.512]
 [69.512]
 [69.512]
 [69.512]] [[1.942]
 [1.942]
 [1.942]
 [1.942]
 [1.942]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.906]
 [38.906]
 [43.517]
 [38.906]
 [38.906]] [[1.256]
 [1.256]
 [1.493]
 [1.256]
 [1.256]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.676973743266785
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.702]
 [64.847]
 [74.25 ]
 [64.847]
 [64.847]] [[1.004]
 [1.192]
 [1.408]
 [1.192]
 [1.192]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  92.78962441363927
printing an ep nov before normalisation:  57.36511866895043
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.393]
 [66.393]
 [85.802]
 [66.393]
 [66.393]] [[0.541]
 [0.541]
 [0.797]
 [0.541]
 [0.541]]
siam score:  -0.82074845
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.97792526152985
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.795]
 [59.422]
 [62.79 ]
 [59.422]
 [59.422]] [[1.765]
 [1.614]
 [1.73 ]
 [1.614]
 [1.614]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.40017771720886
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.321]
 [86.321]
 [76.466]
 [86.136]
 [86.321]] [[0.965]
 [0.965]
 [0.797]
 [0.962]
 [0.965]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  123.01337916529917
printing an ep nov before normalisation:  52.22637176513672
printing an ep nov before normalisation:  53.046464920043945
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 41.29112241467008
printing an ep nov before normalisation:  49.97776470656486
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.178078234880196
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.830020425662084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.828221797943115
printing an ep nov before normalisation:  87.45266269402885
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.49431027386042
printing an ep nov before normalisation:  33.648704886439
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
deleting a thread, now have 1 threads
Frames:  22522 train batches done:  2637 episodes:  934
printing an ep nov before normalisation:  2.6380309750464903
printing an ep nov before normalisation:  3.629275936372096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8093895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.02314516813283
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.26409888922177
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9894,     0.0006,     0.0000,     0.0053,     0.0047],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0873,     0.9112,     0.0000,     0.0000,     0.0015],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0008,     0.0017,     0.8895,     0.0449,     0.0631],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0013, 0.0020, 0.0015, 0.8077, 0.1875], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0110, 0.0868, 0.1103, 0.2730, 0.5189], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.295685827637612
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.912]
 [77.983]
 [77.983]
 [77.983]
 [77.983]] [[1.686]
 [2.   ]
 [2.   ]
 [2.   ]
 [2.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.66460214223778
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.98 ]
 [59.661]
 [59.661]
 [59.661]
 [59.661]] [[1.826]
 [1.753]
 [1.753]
 [1.753]
 [1.753]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.969]
 [65.969]
 [65.969]
 [65.969]
 [65.969]] [[1.373]
 [1.373]
 [1.373]
 [1.373]
 [1.373]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.409373489755936
printing an ep nov before normalisation:  57.532917501333564
actions average: 
K:  1  action  0 :  tensor([    0.9975,     0.0000,     0.0000,     0.0009,     0.0016],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9995,     0.0001,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0001,     0.8860,     0.0632,     0.0505],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0183, 0.0151, 0.0226, 0.6605, 0.2834], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0018, 0.0008, 0.0451, 0.2894, 0.6629], grad_fn=<DivBackward0>)
siam score:  -0.80026686
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.87800555456298
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.81210611612768
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.76 ]
 [73.133]
 [73.133]
 [73.133]
 [73.133]] [[1.779]
 [1.588]
 [1.588]
 [1.588]
 [1.588]]
actions average: 
K:  3  action  0 :  tensor([    0.9983,     0.0001,     0.0000,     0.0008,     0.0009],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9995,     0.0001,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0007,     0.0016,     0.8904,     0.0392,     0.0681],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0385, 0.0010, 0.0887, 0.6217, 0.2501], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0062, 0.0530, 0.1042, 0.3382, 0.4984], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.81294215
printing an ep nov before normalisation:  54.07987960829881
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.342]
 [60.342]
 [60.342]
 [60.342]
 [60.342]] [[1.036]
 [1.036]
 [1.036]
 [1.036]
 [1.036]]
printing an ep nov before normalisation:  58.63991760386842
printing an ep nov before normalisation:  62.395893639826916
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.2597220492045
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.516]
 [52.516]
 [80.266]
 [52.516]
 [52.516]] [[0.6  ]
 [0.6  ]
 [1.156]
 [0.6  ]
 [0.6  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9969,     0.0005,     0.0001,     0.0008,     0.0016],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0147,     0.9813,     0.0007,     0.0002,     0.0031],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0004,     0.9433,     0.0302,     0.0260],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0926, 0.0074, 0.0455, 0.6729, 0.1816], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0047, 0.0382, 0.0793, 0.3757, 0.5022], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.229]
 [52.229]
 [56.65 ]
 [52.229]
 [49.175]] [[0.271]
 [0.271]
 [0.31 ]
 [0.271]
 [0.245]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8228204
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.07993221282959
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 64.0342362685564
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.413841480775105
printing an ep nov before normalisation:  44.59559361274704
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.8569373969016
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8087889
printing an ep nov before normalisation:  124.25527847784758
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.8858003616333
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.24206744428473
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8085122
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.219445007268014
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.54832964668139
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.7185910983485
siam score:  -0.8057915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.77772146165284
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.845872674019994
printing an ep nov before normalisation:  34.39066410064697
printing an ep nov before normalisation:  79.31453824529174
printing an ep nov before normalisation:  75.85805788734683
printing an ep nov before normalisation:  54.666056632995605
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.99458503723145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.85 ]
 [74.122]
 [68.487]
 [63.945]
 [65.325]] [[0.273]
 [0.333]
 [0.292]
 [0.259]
 [0.269]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.40579296665321
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.9284763061266
siam score:  -0.8003049
printing an ep nov before normalisation:  18.6652148079273
printing an ep nov before normalisation:  19.305818395574015
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.946]
 [17.946]
 [17.946]
 [17.946]
 [17.946]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 53.612548398566304
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.117]
 [39.524]
 [60.267]
 [67.814]
 [51.596]] [[0.783]
 [0.583]
 [0.889]
 [1.   ]
 [0.761]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.81257415
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9648,     0.0041,     0.0000,     0.0155,     0.0156],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0005,     0.9833,     0.0020,     0.0003,     0.0140],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0010,     0.8623,     0.0693,     0.0672],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0069,     0.0003,     0.0053,     0.7471,     0.2404],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0012, 0.0008, 0.1253, 0.3624, 0.5104], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.02 ]
 [65.02 ]
 [67.123]
 [65.02 ]
 [65.02 ]] [[1.165]
 [1.165]
 [1.244]
 [1.165]
 [1.165]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.81180555
printing an ep nov before normalisation:  37.88224012101949
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.0257446713245
siam score:  -0.8103572
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.6  ]
 [46.559]
 [45.403]
 [55.884]
 [49.314]] [[1.204]
 [0.807]
 [0.769]
 [1.115]
 [0.898]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.44988244051014
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.06642004377502
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.226]
 [32.424]
 [51.494]
 [33.861]
 [30.843]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  3  action  0 :  tensor([    0.9193,     0.0035,     0.0000,     0.0316,     0.0456],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0059, 0.9479, 0.0072, 0.0017, 0.0373], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0011, 0.0016, 0.9431, 0.0309, 0.0232], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0013, 0.0061, 0.1721, 0.5837, 0.2368], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0004,     0.0313,     0.1627,     0.3424,     0.4632],
       grad_fn=<DivBackward0>)
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9539,     0.0011,     0.0000,     0.0141,     0.0309],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0076,     0.9674,     0.0044,     0.0004,     0.0201],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0008,     0.0040,     0.8452,     0.0375,     0.1126],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0000,     0.0029,     0.0615,     0.7449,     0.1907],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0218, 0.0031, 0.0320, 0.3824, 0.5606], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.67404700021123
siam score:  -0.82247573
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.86591911315918
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.343]
 [47.128]
 [54.666]
 [56.677]
 [47.128]] [[0.616]
 [0.694]
 [0.905]
 [0.962]
 [0.694]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
main train batch thing paused
add a thread
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Adding thread: now have 2 threads
printing an ep nov before normalisation:  57.12625602561167
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.96232750252163
printing an ep nov before normalisation:  55.55991916811892
printing an ep nov before normalisation:  46.1847290249732
printing an ep nov before normalisation:  58.76026602752993
using explorer policy with actor:  1
printing an ep nov before normalisation:  18.863922357559204
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.09072407114593
printing an ep nov before normalisation:  0.47340354091919123
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.167]
 [44.112]
 [42.579]
 [44.112]
 [44.112]] [[1.274]
 [0.976]
 [0.912]
 [0.976]
 [0.976]]
printing an ep nov before normalisation:  75.47645593323837
UNIT TEST: sample policy line 217 mcts : [0.026 0.564 0.333 0.051 0.026]
printing an ep nov before normalisation:  47.19073275704204
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.12062168121338
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8143193
printing an ep nov before normalisation:  58.99190593124434
siam score:  -0.8168
actions average: 
K:  4  action  0 :  tensor([    0.9614,     0.0010,     0.0000,     0.0181,     0.0196],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9958,     0.0004,     0.0001,     0.0037],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0007,     0.0026,     0.9392,     0.0251,     0.0324],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0012,     0.0003,     0.0776,     0.7859,     0.1350],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0009, 0.0726, 0.0506, 0.2922, 0.5837], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 87.26193742346673
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8182763
printing an ep nov before normalisation:  78.41545570095221
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.551]
 [54.417]
 [40.809]
 [37.559]
 [39.28 ]] [[0.167]
 [0.15 ]
 [0.094]
 [0.081]
 [0.088]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.503]
 [24.806]
 [29.266]
 [25.77 ]
 [24.788]] [[0.147]
 [0.044]
 [0.061]
 [0.048]
 [0.044]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9985,     0.0003,     0.0000,     0.0002,     0.0011],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0014, 0.9583, 0.0029, 0.0043, 0.0331], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0003,     0.0162,     0.9510,     0.0110,     0.0215],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0001,     0.0363,     0.6574,     0.3057],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0004,     0.0170,     0.0259,     0.3332,     0.6235],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  60.8502250684785
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.666]
 [57.39 ]
 [64.316]
 [57.719]
 [57.862]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.982950956448136
printing an ep nov before normalisation:  100.34411201799769
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.730251880162776
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.40067993297677
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.85869292961925
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.95555310719021
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.46029534413827
printing an ep nov before normalisation:  61.49218821103403
printing an ep nov before normalisation:  69.41440455544927
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.229]
 [42.522]
 [46.103]
 [49.806]
 [45.057]] [[1.   ]
 [0.632]
 [0.768]
 [0.908]
 [0.728]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  59.61985991279104
printing an ep nov before normalisation:  91.53958125984987
actions average: 
K:  3  action  0 :  tensor([    0.9497,     0.0012,     0.0000,     0.0278,     0.0213],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0036,     0.9866,     0.0014,     0.0000,     0.0083],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0014,     0.8877,     0.0470,     0.0639],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0036, 0.0008, 0.0984, 0.7339, 0.1633], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1242, 0.0061, 0.0505, 0.2140, 0.6052], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8095291
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.053]
 [40.941]
 [40.685]
 [40.941]
 [40.941]] [[1.039]
 [0.803]
 [0.794]
 [0.803]
 [0.803]]
printing an ep nov before normalisation:  80.12917479135524
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.823]
 [44.009]
 [66.864]
 [89.369]
 [60.451]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.530697600240885
printing an ep nov before normalisation:  72.5007896841275
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.779053688049316
printing an ep nov before normalisation:  128.53484789602578
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 70.12079861683344
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.681]
 [53.581]
 [54.597]
 [51.125]
 [52.015]] [[1.068]
 [1.28 ]
 [1.305]
 [1.222]
 [1.243]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8156967
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0002,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9971,     0.0000,     0.0000,     0.0025],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0012, 0.0013, 0.8941, 0.0450, 0.0585], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0024, 0.0011, 0.0363, 0.6475, 0.3128], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0202, 0.0018, 0.0700, 0.2698, 0.6381], grad_fn=<DivBackward0>)
siam score:  -0.81613296
printing an ep nov before normalisation:  35.05012748440757
printing an ep nov before normalisation:  44.099248162187045
printing an ep nov before normalisation:  38.77813328655116
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.074]
 [44.015]
 [49.524]
 [35.074]
 [28.225]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  33.92913103103638
printing an ep nov before normalisation:  41.82481123716117
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  46.83131217956543
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.93999431662073
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  113.52078313050873
printing an ep nov before normalisation:  84.714299350607
siam score:  -0.8276158
actions average: 
K:  1  action  0 :  tensor([    0.9972,     0.0007,     0.0000,     0.0010,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9981,     0.0002,     0.0001,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0004,     0.9305,     0.0136,     0.0555],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0044,     0.0004,     0.0005,     0.7743,     0.2204],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0180, 0.0011, 0.0636, 0.4916, 0.4257], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  61.48647510930756
printing an ep nov before normalisation:  60.30199191233343
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.57432842254639
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8288853
printing an ep nov before normalisation:  95.78864055346594
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.833]
 [48.944]
 [52.053]
 [52.88 ]
 [48.708]] [[1.209]
 [0.994]
 [1.107]
 [1.137]
 [0.986]]
actions average: 
K:  3  action  0 :  tensor([    0.9824,     0.0002,     0.0000,     0.0092,     0.0082],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0044,     0.9712,     0.0002,     0.0008,     0.0234],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0004,     0.9486,     0.0137,     0.0371],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0043, 0.0032, 0.0478, 0.6731, 0.2716], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0039, 0.0020, 0.0390, 0.3924, 0.5626], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  71.18030625705441
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.498]
 [65.053]
 [63.617]
 [58.695]
 [62.626]] [[0.093]
 [1.087]
 [1.041]
 [0.886]
 [1.01 ]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.64418697357178
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.09767592490658
printing an ep nov before normalisation:  43.97071379812589
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.42707948053475
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.23910427093506
printing an ep nov before normalisation:  30.439984798431396
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  101.90412808741438
printing an ep nov before normalisation:  121.03333116203702
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.419]
 [50.957]
 [45.941]
 [46.568]
 [39.389]] [[1.317]
 [1.667]
 [1.434]
 [1.463]
 [1.13 ]]
printing an ep nov before normalisation:  61.286775453415935
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.2161053702361
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.51000785827637
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.553]
 [46.016]
 [46.016]
 [50.382]
 [46.016]] [[1.31 ]
 [0.973]
 [0.973]
 [1.113]
 [0.973]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  99.2010161562668
printing an ep nov before normalisation:  56.73273136638338
siam score:  -0.8218297
printing an ep nov before normalisation:  58.2808368644077
printing an ep nov before normalisation:  68.67680243339468
printing an ep nov before normalisation:  69.32692590790397
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.82116365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 78.55781492377048
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.89789831149906
printing an ep nov before normalisation:  85.48710323976029
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.831]
 [24.269]
 [34.869]
 [32.853]
 [24.269]] [[1.284]
 [0.491]
 [0.9  ]
 [0.822]
 [0.491]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.376]
 [54.533]
 [54.436]
 [55.999]
 [46.917]] [[0.433]
 [0.847]
 [0.844]
 [0.887]
 [0.639]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  2.1288890748331823
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.178]
 [48.178]
 [76.139]
 [39.296]
 [48.178]] [[0.38 ]
 [0.38 ]
 [1.037]
 [0.172]
 [0.38 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.099]
 [40.807]
 [40.807]
 [40.807]
 [40.533]] [[1.048]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.382]]
printing an ep nov before normalisation:  60.594874028662346
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.581]
 [ 7.833]
 [19.434]
 [21.043]
 [15.245]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.56368804618793
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.818]
 [66.8  ]
 [59.855]
 [70.712]
 [69.801]] [[0.605]
 [0.515]
 [0.411]
 [0.574]
 [0.56 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.219661986882954
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.49741646618538
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.53157975938585
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.20935677510125
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.36 ]
 [59.36 ]
 [56.715]
 [59.36 ]
 [59.36 ]] [[2.178]
 [2.178]
 [2.   ]
 [2.178]
 [2.178]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.35 ]
 [51.914]
 [50.96 ]
 [42.335]
 [46.009]] [[0.644]
 [0.962]
 [0.933]
 [0.673]
 [0.784]]
actions average: 
K:  3  action  0 :  tensor([    0.9687,     0.0283,     0.0004,     0.0001,     0.0026],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0044,     0.9879,     0.0000,     0.0001,     0.0077],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0254,     0.9037,     0.0297,     0.0411],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0008,     0.0006,     0.0801,     0.7388,     0.1797],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0513, 0.0037, 0.0789, 0.3026, 0.5636], grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 68.02754688793596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  110.44179678301695
printing an ep nov before normalisation:  66.94935321807861
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 87.185]
 [ 87.185]
 [107.87 ]
 [ 87.185]
 [ 87.185]] [[0.922]
 [0.922]
 [1.237]
 [0.922]
 [0.922]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  64.37596328816953
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.391]
 [74.602]
 [47.866]
 [60.853]
 [69.622]] [[1.139]
 [0.99 ]
 [0.482]
 [0.729]
 [0.896]]
printing an ep nov before normalisation:  44.414496421813965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 58.538056358791444
printing an ep nov before normalisation:  63.64547756733418
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9984,     0.0000,     0.0000,     0.0005,     0.0011],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9983,     0.0001,     0.0001,     0.0015],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0002,     0.9190,     0.0305,     0.0502],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0005,     0.0387,     0.6456,     0.3150],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0030, 0.0400, 0.0424, 0.2656, 0.6490], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  59.47024709181541
printing an ep nov before normalisation:  81.73175012776446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.48048273444365
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.99034848179933
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.695]
 [72.695]
 [72.695]
 [72.695]
 [72.695]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0017,     0.9970,     0.0000,     0.0001,     0.0012],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0002,     0.9200,     0.0422,     0.0376],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0001,     0.0172,     0.6811,     0.3016],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0018, 0.0011, 0.1162, 0.3043, 0.5766], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.378]
 [68.378]
 [56.181]
 [68.378]
 [68.378]] [[1.519]
 [1.519]
 [1.076]
 [1.519]
 [1.519]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.825217
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[90.539]
 [90.539]
 [90.539]
 [90.539]
 [90.539]] [[1.188]
 [1.188]
 [1.188]
 [1.188]
 [1.188]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.456]
 [55.368]
 [76.653]
 [63.601]
 [59.49 ]] [[0.308]
 [0.4  ]
 [0.681]
 [0.509]
 [0.454]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.397650774299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.45812821921398
printing an ep nov before normalisation:  6.457064512989632
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  57.769218876485894
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.778]
 [43.052]
 [42.068]
 [42.068]
 [42.068]] [[1.464]
 [1.083]
 [1.034]
 [1.034]
 [1.034]]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  61.48532250668561
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.410783831013845
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.95920620071042
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.645]
 [39.398]
 [37.769]
 [38.959]
 [37.769]] [[1.162]
 [0.607]
 [0.555]
 [0.593]
 [0.555]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.862]
 [39.862]
 [39.862]
 [39.862]
 [39.862]] [[0.937]
 [0.937]
 [0.937]
 [0.937]
 [0.937]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.89223940804882
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.500384406161174
printing an ep nov before normalisation:  76.03924558974782
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.273]
 [84.273]
 [84.273]
 [84.273]
 [84.273]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
actions average: 
K:  2  action  0 :  tensor([    0.9864,     0.0001,     0.0000,     0.0054,     0.0082],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9987,     0.0000,     0.0000,     0.0012],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0011,     0.9421,     0.0220,     0.0348],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0005,     0.0318,     0.7178,     0.2497],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0117, 0.0035, 0.0949, 0.4055, 0.4845], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.60315120353965
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.33507322085568
siam score:  -0.8314683
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8306114
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  100.57833278171225
printing an ep nov before normalisation:  83.31240206468777
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.81668204
printing an ep nov before normalisation:  84.33667514115535
printing an ep nov before normalisation:  71.19965392043581
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.375178449015717
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  130.7316905224723
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.972]
 [35.972]
 [35.972]
 [35.972]
 [35.972]] [[0.245]
 [0.245]
 [0.245]
 [0.245]
 [0.245]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.70762728301993
printing an ep nov before normalisation:  46.48405557431461
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.21854509390293
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.253]
 [39.27 ]
 [39.27 ]
 [52.158]
 [39.27 ]] [[0.765]
 [0.695]
 [0.695]
 [0.923]
 [0.695]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.80643713
printing an ep nov before normalisation:  40.86518517799464
printing an ep nov before normalisation:  65.41373449015816
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.789]
 [58.701]
 [61.499]
 [72.69 ]
 [58.701]] [[0.213]
 [0.6  ]
 [0.66 ]
 [0.902]
 [0.6  ]]
printing an ep nov before normalisation:  77.93149204789655
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  56.05201352387199
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.941]
 [72.175]
 [70.782]
 [70.941]
 [70.941]] [[1.457]
 [1.504]
 [1.451]
 [1.457]
 [1.457]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.77592358578929
printing an ep nov before normalisation:  52.71796226501465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.57920837534056
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.149]
 [42.851]
 [51.467]
 [42.313]
 [39.838]] [[0.42 ]
 [0.415]
 [0.556]
 [0.406]
 [0.365]]
printing an ep nov before normalisation:  37.31634736953371
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.44968056084178
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.30939901662225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.735]
 [42.83 ]
 [50.022]
 [45.904]
 [45.285]] [[0.823]
 [0.727]
 [0.965]
 [0.829]
 [0.808]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.5163488736757
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.73676731127838
actions average: 
K:  4  action  0 :  tensor([    0.9872,     0.0015,     0.0000,     0.0038,     0.0075],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0568,     0.8641,     0.0033,     0.0007,     0.0751],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0501,     0.8645,     0.0424,     0.0429],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0495,     0.0006,     0.0124,     0.7319,     0.2056],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0022, 0.0291, 0.1248, 0.4576, 0.3864], grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 46.6470815457819
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.02187596530061
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.86906846336307
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  93.42161187014175
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.42010184251427
siam score:  -0.8261793
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.516]
 [37.389]
 [46.52 ]
 [34.954]
 [34.946]] [[0.549]
 [0.71 ]
 [1.011]
 [0.63 ]
 [0.629]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.925]
 [41.195]
 [61.652]
 [62.511]
 [52.589]] [[1.236]
 [0.909]
 [1.363]
 [1.382]
 [1.162]]
printing an ep nov before normalisation:  69.20934942572876
printing an ep nov before normalisation:  75.29220581054688
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.8266354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.82708746
printing an ep nov before normalisation:  41.34385585784912
printing an ep nov before normalisation:  44.51804978385526
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.61021196469561
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.356743483534295
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  118.38820865715186
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.73150244371471
printing an ep nov before normalisation:  50.8731162396348
printing an ep nov before normalisation:  111.34228905155265
printing an ep nov before normalisation:  80.15736852373396
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.103 0.333 0.333 0.077 0.154]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[124.484]
 [124.484]
 [124.484]
 [124.484]
 [124.484]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
printing an ep nov before normalisation:  99.48880082175134
printing an ep nov before normalisation:  50.938563148177494
printing an ep nov before normalisation:  62.916693560685715
actions average: 
K:  2  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0021,     0.9879,     0.0045,     0.0000,     0.0054],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0008,     0.9020,     0.0312,     0.0659],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0009,     0.0004,     0.0631,     0.6723,     0.2633],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0220,     0.0010,     0.0007,     0.2055,     0.7709],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  52.217222342056644
line 256 mcts: sample exp_bonus 41.26596909348992
printing an ep nov before normalisation:  28.45967433916329
printing an ep nov before normalisation:  59.16815021171864
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.826]
 [51.621]
 [54.281]
 [51.123]
 [44.178]] [[0.632]
 [0.587]
 [0.641]
 [0.577]
 [0.436]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.295]
 [59.295]
 [59.295]
 [59.295]
 [59.295]] [[0.742]
 [0.742]
 [0.742]
 [0.742]
 [0.742]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.81439364
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.104]
 [76.104]
 [76.104]
 [77.179]
 [76.104]] [[1.257]
 [1.257]
 [1.257]
 [1.282]
 [1.257]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.572]
 [35.751]
 [35.751]
 [35.751]
 [35.751]] [[0.855]
 [0.722]
 [0.722]
 [0.722]
 [0.722]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.719]
 [61.719]
 [57.565]
 [61.473]
 [61.719]] [[1.667]
 [1.667]
 [1.453]
 [1.654]
 [1.667]]
printing an ep nov before normalisation:  56.47974423709332
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.52221048155829
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.15666188765334
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.549]
 [50.549]
 [52.028]
 [64.582]
 [50.549]] [[1.286]
 [1.286]
 [1.323]
 [1.643]
 [1.286]]
printing an ep nov before normalisation:  55.43348102504652
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.098]
 [44.098]
 [55.494]
 [44.098]
 [44.098]] [[0.269]
 [0.269]
 [0.402]
 [0.269]
 [0.269]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  59.78019432218712
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.052]
 [45.468]
 [49.857]
 [53.122]
 [53.122]] [[1.03 ]
 [0.585]
 [0.68 ]
 [0.751]
 [0.751]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.42649633423002
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.96330053354919
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.49597646349005
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.568]
 [39.752]
 [47.657]
 [44.219]
 [38.571]] [[0.864]
 [0.612]
 [0.838]
 [0.74 ]
 [0.579]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.164885365109
printing an ep nov before normalisation:  81.16674916540103
actions average: 
K:  4  action  0 :  tensor([    0.9872,     0.0004,     0.0000,     0.0065,     0.0059],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9919,     0.0051,     0.0000,     0.0030],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9794,     0.0105,     0.0101],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0074, 0.0015, 0.1234, 0.5737, 0.2941], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0035, 0.0012, 0.0062, 0.3248, 0.6643], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.918]
 [49.918]
 [62.291]
 [49.669]
 [49.918]] [[0.912]
 [0.912]
 [1.343]
 [0.904]
 [0.912]]
printing an ep nov before normalisation:  38.08016538619995
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.82961047
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.91287997650531
printing an ep nov before normalisation:  54.94464105538022
printing an ep nov before normalisation:  62.00141552056567
printing an ep nov before normalisation:  126.28216575376666
printing an ep nov before normalisation:  107.73418066134461
printing an ep nov before normalisation:  82.06504598617165
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.29325393948207
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9897,     0.0001,     0.0000,     0.0010,     0.0092],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0025,     0.9926,     0.0004,     0.0001,     0.0045],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0016,     0.9071,     0.0224,     0.0688],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0016, 0.0015, 0.0888, 0.6291, 0.2790], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0013, 0.0037, 0.0799, 0.2183, 0.6969], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  95.4110805695875
printing an ep nov before normalisation:  60.8910606876319
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.01539009512207
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  107.90585070801929
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.717]
 [50.87 ]
 [56.072]
 [39.25 ]
 [37.905]] [[0.153]
 [0.352]
 [0.405]
 [0.231]
 [0.217]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  62.254971066880664
printing an ep nov before normalisation:  66.91971155199906
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.19386672973633
printing an ep nov before normalisation:  66.87253142026599
printing an ep nov before normalisation:  70.16613795988727
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[78.193]
 [78.193]
 [78.193]
 [78.193]
 [78.193]] [[1.406]
 [1.406]
 [1.406]
 [1.406]
 [1.406]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.611]
 [48.611]
 [48.611]
 [48.611]
 [48.611]] [[1.137]
 [1.137]
 [1.137]
 [1.137]
 [1.137]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  1.1796030291621662
printing an ep nov before normalisation:  47.47204780578613
printing an ep nov before normalisation:  41.730685234069824
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.877]
 [68.877]
 [58.37 ]
 [68.877]
 [68.877]] [[2.686]
 [2.686]
 [2.   ]
 [2.686]
 [2.686]]
printing an ep nov before normalisation:  53.6710327139697
printing an ep nov before normalisation:  80.68435390035721
printing an ep nov before normalisation:  33.90415384203256
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.42 ]
 [56.269]
 [56.456]
 [72.145]
 [72.145]] [[1.667]
 [1.189]
 [1.194]
 [1.631]
 [1.631]]
printing an ep nov before normalisation:  72.41005503907748
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.81138143519698
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.91168436872343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.069]
 [36.647]
 [42.001]
 [51.38 ]
 [35.07 ]] [[0.721]
 [0.562]
 [0.719]
 [0.993]
 [0.516]]
printing an ep nov before normalisation:  67.24882543456557
printing an ep nov before normalisation:  60.85880415448012
line 256 mcts: sample exp_bonus 37.70133311776822
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9919,     0.0001,     0.0000,     0.0045,     0.0034],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0387, 0.8925, 0.0019, 0.0062, 0.0608], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0004,     0.0025,     0.8696,     0.0451,     0.0824],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0004,     0.0846,     0.6437,     0.2710],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0002,     0.0013,     0.0801,     0.3804,     0.5379],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  47.21299171447754
actions average: 
K:  0  action  0 :  tensor([    0.9886,     0.0001,     0.0000,     0.0031,     0.0082],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0007,     0.9961,     0.0007,     0.0001,     0.0024],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0004,     0.8791,     0.0299,     0.0905],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0027, 0.0307, 0.0191, 0.7404, 0.2070], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0006,     0.0005,     0.0981,     0.2936,     0.6073],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.549]
 [87.549]
 [87.549]
 [87.549]
 [87.549]] [[0.27]
 [0.27]
 [0.27]
 [0.27]
 [0.27]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.79435634613037
using explorer policy with actor:  1
printing an ep nov before normalisation:  86.53110911544125
printing an ep nov before normalisation:  58.508220909547106
printing an ep nov before normalisation:  70.30435471971431
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  86.99627143502225
printing an ep nov before normalisation:  70.50878349926859
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9961,     0.0004,     0.0000,     0.0019,     0.0016],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9929,     0.0001,     0.0001,     0.0067],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0001,     0.9451,     0.0329,     0.0217],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0015,     0.0007,     0.0003,     0.8708,     0.1266],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0127, 0.0470, 0.0407, 0.3171, 0.5825], grad_fn=<DivBackward0>)
siam score:  -0.8307098
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.59204765325501
printing an ep nov before normalisation:  63.97013161962862
printing an ep nov before normalisation:  76.53685174287729
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  55.642782987005425
printing an ep nov before normalisation:  45.26494391846839
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 97.971]
 [ 97.971]
 [102.823]
 [ 97.971]
 [ 97.971]] [[0.594]
 [0.594]
 [0.639]
 [0.594]
 [0.594]]
printing an ep nov before normalisation:  51.920456886291504
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.71]
 [49.71]
 [49.71]
 [49.71]
 [49.71]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.36217629786922
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.12290472712546
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.13453793525696
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.61878747536127
siam score:  -0.83839506
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.39978313446045
printing an ep nov before normalisation:  72.23150542810481
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.57600550956495
printing an ep nov before normalisation:  37.182385272946725
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.989729200315786
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  113.5356005464915
printing an ep nov before normalisation:  98.59203683915787
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.508250767543906
printing an ep nov before normalisation:  75.93331306231441
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.82053544875833
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.31675083080627
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.25 ]
 [48.092]
 [48.092]
 [48.092]
 [48.092]] [[0.667]
 [0.994]
 [0.994]
 [0.994]
 [0.994]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.86749927761362
printing an ep nov before normalisation:  46.280112133071256
printing an ep nov before normalisation:  132.06709900525613
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.786]
 [53.786]
 [53.786]
 [53.786]
 [53.786]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0003,     0.9303,     0.0252,     0.0442],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0002,     0.0468,     0.6945,     0.2584],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0004,     0.0003,     0.0556,     0.3104,     0.6333],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.83894885
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.883]
 [54.883]
 [54.883]
 [54.883]
 [54.883]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  75.99968731143736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.350733652070577
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.3086495755019
printing an ep nov before normalisation:  37.013028231882174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.05339541515956
printing an ep nov before normalisation:  49.46971054974317
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.14180237501863
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.27180671691895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.09542095670835
siam score:  -0.8299005
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.943]
 [77.943]
 [77.943]
 [77.943]
 [77.943]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
printing an ep nov before normalisation:  53.463826179504395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.705]
 [49.705]
 [49.705]
 [49.705]
 [49.705]] [[1.525]
 [1.525]
 [1.525]
 [1.525]
 [1.525]]
printing an ep nov before normalisation:  80.34152178915306
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.228]
 [45.228]
 [47.597]
 [45.228]
 [45.228]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.804]
 [28.438]
 [22.498]
 [28.438]
 [18.048]] [[0.196]
 [0.175]
 [0.123]
 [0.175]
 [0.083]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.82328147
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.235589044381896
line 256 mcts: sample exp_bonus 69.36394021026842
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  110.08966232418759
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8337847
deleting a thread, now have 1 threads
Frames:  37555 train batches done:  4393 episodes:  1373
printing an ep nov before normalisation:  45.7303421837943
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.703]
 [83.703]
 [83.703]
 [83.703]
 [83.703]] [[1.64]
 [1.64]
 [1.64]
 [1.64]
 [1.64]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  82.21937262865119
printing an ep nov before normalisation:  54.7209734941202
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.807]
 [70.102]
 [71.362]
 [80.842]
 [78.371]] [[1.433]
 [1.236]
 [1.273]
 [1.552]
 [1.479]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0002,     0.9260,     0.0364,     0.0373],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0032,     0.0002,     0.0197,     0.7611,     0.2157],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0071, 0.0007, 0.0619, 0.2851, 0.6452], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.04 ]
 [42.009]
 [42.009]
 [42.009]
 [42.009]] [[1.822]
 [2.   ]
 [2.   ]
 [2.   ]
 [2.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9944,     0.0003,     0.0000,     0.0007,     0.0045],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9973,     0.0000,     0.0000,     0.0024],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0015, 0.0110, 0.9286, 0.0158, 0.0431], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0023, 0.0033, 0.0876, 0.7543, 0.1525], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0028, 0.0024, 0.1278, 0.3625, 0.5044], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9995,     0.0001,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9549,     0.0146,     0.0304],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0002,     0.0433,     0.7614,     0.1948],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0011,     0.0004,     0.0374,     0.4634,     0.4978],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  63.05748092616582
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.95631004798365
printing an ep nov before normalisation:  73.19272178648582
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.821]
 [64.738]
 [67.007]
 [67.151]
 [60.78 ]] [[1.451]
 [1.548]
 [1.624]
 [1.629]
 [1.416]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8409424
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  72.5115612335454
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.478]
 [39.478]
 [44.306]
 [39.478]
 [39.478]] [[0.228]
 [0.228]
 [0.278]
 [0.228]
 [0.228]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.71614577188102
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0099,     0.9870,     0.0015,     0.0001,     0.0016],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0002,     0.9210,     0.0421,     0.0365],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0082,     0.0003,     0.0537,     0.6965,     0.2414],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0045,     0.0004,     0.0373,     0.4817,     0.4762],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.8337589194405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8384193
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[80.086]
 [80.086]
 [66.803]
 [80.086]
 [80.086]] [[1.494]
 [1.494]
 [1.156]
 [1.494]
 [1.494]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.99644584338693
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.454]
 [57.366]
 [66.901]
 [73.896]
 [72.076]] [[0.969]
 [0.703]
 [0.982]
 [1.187]
 [1.133]]
printing an ep nov before normalisation:  43.18740505666872
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.677]
 [32.31 ]
 [32.31 ]
 [56.72 ]
 [51.707]] [[0.807]
 [0.117]
 [0.117]
 [0.756]
 [0.625]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.788]
 [49.788]
 [49.788]
 [40.789]
 [49.788]] [[0.733]
 [0.733]
 [0.733]
 [0.532]
 [0.733]]
printing an ep nov before normalisation:  42.590718269348145
printing an ep nov before normalisation:  75.09902974886394
actions average: 
K:  1  action  0 :  tensor([    0.9992,     0.0001,     0.0000,     0.0002,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9939,     0.0003,     0.0005,     0.0052],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.8990,     0.0516,     0.0491],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0003,     0.0235,     0.7685,     0.2070],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0004,     0.0011,     0.2571,     0.3163,     0.4252],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  136.85111222014373
UNIT TEST: sample policy line 217 mcts : [0.282 0.128 0.154 0.359 0.077]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.292]
 [66.932]
 [40.389]
 [65.794]
 [65.548]] [[0.898]
 [1.   ]
 [0.419]
 [0.975]
 [0.97 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.8223578
printing an ep nov before normalisation:  45.66986215990703
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.79896784549336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.83401674
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.82386549261227
printing an ep nov before normalisation:  45.632057189941406
printing an ep nov before normalisation:  64.03676685819525
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  55.275267446289924
siam score:  -0.8458798
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8465744
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8415863
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.5842067354251412
actions average: 
K:  4  action  0 :  tensor([    0.9968,     0.0003,     0.0000,     0.0013,     0.0016],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0014,     0.9480,     0.0340,     0.0001,     0.0164],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0053, 0.0172, 0.9017, 0.0491, 0.0267], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0016, 0.0008, 0.0461, 0.6698, 0.2817], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0052, 0.1289, 0.0679, 0.2286, 0.5695], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.77435365591509
printing an ep nov before normalisation:  64.18602856002846
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8438074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.93668873089806
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.570732111385
siam score:  -0.83978075
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.765786655894715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.82180015012419
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.95215088004787
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 78.53217459380535
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.07776774723849
printing an ep nov before normalisation:  60.413873583587765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  21.375532072657677
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.94271076846545
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.76878053265256
printing an ep nov before normalisation:  41.000647927845066
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.258]
 [41.441]
 [35.932]
 [36.448]
 [34.465]] [[0.698]
 [0.838]
 [0.654]
 [0.671]
 [0.605]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.24362659454346
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8412831
printing an ep nov before normalisation:  40.03891944885254
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  129.16242267189415
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.459275060449954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.31114779265306
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.954]
 [ 9.576]
 [16.253]
 [17.164]
 [63.954]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.193]
 [25.41 ]
 [25.41 ]
 [25.41 ]
 [25.41 ]] [[0.738]
 [0.334]
 [0.334]
 [0.334]
 [0.334]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.09155157763207
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.10243225097656
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  132.65608043745618
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  79.43194901349166
actions average: 
K:  3  action  0 :  tensor([    0.9980,     0.0006,     0.0000,     0.0008,     0.0007],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0069,     0.9543,     0.0261,     0.0003,     0.0125],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0297,     0.9171,     0.0291,     0.0241],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0002,     0.0471,     0.7105,     0.2420],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0146, 0.0538, 0.0771, 0.1981, 0.6564], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.855]
 [42.585]
 [40.937]
 [43.498]
 [38.56 ]] [[0.148]
 [0.258]
 [0.239]
 [0.268]
 [0.212]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.838405
printing an ep nov before normalisation:  52.72919851592701
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.32625165644892
printing an ep nov before normalisation:  41.13369161704198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.73546028137207
printing an ep nov before normalisation:  68.89337728521876
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.821516036987305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.49691735233616
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.850135
siam score:  -0.85097957
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  56.31480062050191
printing an ep nov before normalisation:  70.57906012095368
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.74762146442274
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.352]
 [46.352]
 [46.352]
 [46.352]
 [46.352]] [[1.274]
 [1.274]
 [1.274]
 [1.274]
 [1.274]]
printing an ep nov before normalisation:  53.655758263578065
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.217]
 [63.217]
 [63.217]
 [63.217]
 [63.217]] [[1.149]
 [1.149]
 [1.149]
 [1.149]
 [1.149]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.137]
 [47.209]
 [47.755]
 [36.673]
 [33.285]] [[0.589]
 [0.774]
 [0.791]
 [0.453]
 [0.35 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  83.53621403900318
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 76.088]
 [119.035]
 [131.502]
 [120.336]
 [118.601]] [[0.267]
 [0.544]
 [0.624]
 [0.552]
 [0.541]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.12 ]
 [68.62 ]
 [66.951]
 [70.248]
 [73.057]] [[1.203]
 [1.442]
 [1.381]
 [1.502]
 [1.605]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.02022838592529
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.37465768010317
printing an ep nov before normalisation:  94.06410514834916
printing an ep nov before normalisation:  70.92996731853387
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.28409350592291
actions average: 
K:  1  action  0 :  tensor([    0.9960,     0.0006,     0.0000,     0.0018,     0.0016],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9966,     0.0010,     0.0002,     0.0020],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0010,     0.8857,     0.0456,     0.0675],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0035,     0.0002,     0.0513,     0.7186,     0.2264],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0030, 0.0011, 0.0280, 0.4465, 0.5214], grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  59.50446081297331
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.30724295415003
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.449]
 [37.449]
 [35.211]
 [37.449]
 [37.449]] [[0.373]
 [0.373]
 [0.333]
 [0.373]
 [0.373]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  52.46338946069415
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.527]
 [74.527]
 [74.527]
 [74.527]
 [74.527]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
printing an ep nov before normalisation:  43.108839988708496
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.688]
 [38.901]
 [65.177]
 [60.672]
 [38.901]] [[0.358]
 [0.489]
 [0.967]
 [0.885]
 [0.489]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.224458845693114
printing an ep nov before normalisation:  80.12911106008193
printing an ep nov before normalisation:  53.02409911100011
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.71881898070462
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  78.49813257274495
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.94834151669547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9915,     0.0000,     0.0000,     0.0044,     0.0040],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9690,     0.0136,     0.0010,     0.0163],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9471,     0.0128,     0.0398],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0010,     0.0424,     0.7662,     0.1900],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0006,     0.0057,     0.0704,     0.3005,     0.6228],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.72166674973708
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.234]
 [72.589]
 [68.456]
 [73.683]
 [72.589]] [[1.403]
 [1.177]
 [1.08 ]
 [1.202]
 [1.177]]
printing an ep nov before normalisation:  44.18263912200928
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.57385937609786
siam score:  -0.848017
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.68535466697696
printing an ep nov before normalisation:  38.891956626186015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.998]
 [27.733]
 [32.683]
 [29.803]
 [27.733]] [[1.066]
 [0.41 ]
 [0.55 ]
 [0.468]
 [0.41 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.958014488220215
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  95.80882032775966
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
actions average: 
K:  1  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0006,     0.9970,     0.0001,     0.0001,     0.0022],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9669,     0.0092,     0.0239],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0108,     0.0002,     0.0466,     0.7120,     0.2305],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0054, 0.0083, 0.0020, 0.4476, 0.5366], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  0.21536748263429217
printing an ep nov before normalisation:  108.46012909057993
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.055]
 [38.099]
 [38.099]
 [46.621]
 [38.099]] [[1.162]
 [0.819]
 [0.819]
 [1.002]
 [0.819]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.73083089515248
actions average: 
K:  2  action  0 :  tensor([    0.9976,     0.0000,     0.0000,     0.0011,     0.0013],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9992,     0.0001,     0.0000,     0.0007],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9659,     0.0141,     0.0199],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0007,     0.0003,     0.0231,     0.7216,     0.2543],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0001,     0.0007,     0.1937,     0.2832,     0.5223],
       grad_fn=<DivBackward0>)
siam score:  -0.8410701
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.84144632262787
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.74979782104492
printing an ep nov before normalisation:  54.42573361196954
using explorer policy with actor:  1
siam score:  -0.83796823
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.744]
 [47.085]
 [60.593]
 [53.218]
 [47.215]] [[0.466]
 [0.55 ]
 [0.81 ]
 [0.668]
 [0.552]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.556]
 [64.556]
 [64.556]
 [64.556]
 [64.556]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 51.831960413685955
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.307]
 [68.307]
 [68.307]
 [68.307]
 [68.307]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
printing an ep nov before normalisation:  51.17740384482132
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 8.879]
 [12.536]
 [ 8.862]
 [12.4  ]
 [13.082]] [[0.051]
 [0.075]
 [0.051]
 [0.074]
 [0.079]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.818]
 [44.105]
 [42.08 ]
 [42.08 ]
 [42.08 ]] [[1.39 ]
 [1.122]
 [1.042]
 [1.042]
 [1.042]]
printing an ep nov before normalisation:  55.97507156861905
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.04706135103308
printing an ep nov before normalisation:  44.417239216326756
printing an ep nov before normalisation:  82.44323659809893
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.371]
 [45.371]
 [45.371]
 [45.371]
 [45.371]] [[0.855]
 [0.855]
 [0.855]
 [0.855]
 [0.855]]
siam score:  -0.8426541
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.01 ]
 [69.01 ]
 [71.454]
 [69.01 ]
 [69.01 ]] [[1.587]
 [1.587]
 [1.667]
 [1.587]
 [1.587]]
printing an ep nov before normalisation:  115.90474250433441
printing an ep nov before normalisation:  33.266663551330566
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9560,     0.0122,     0.0005,     0.0096,     0.0217],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9991,     0.0000,     0.0000,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9691,     0.0012,     0.0295],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0000,     0.0010,     0.0547,     0.7574,     0.1868],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0001,     0.0068,     0.1202,     0.3332,     0.5396],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.28973735813115
printing an ep nov before normalisation:  76.7843325121537
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.971]
 [40.078]
 [41.054]
 [64.424]
 [38.904]] [[0.615]
 [0.412]
 [0.437]
 [1.038]
 [0.382]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.06830796410598
printing an ep nov before normalisation:  53.73246203445109
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.27070004877458587
printing an ep nov before normalisation:  57.778368875899815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.05737737365478779
printing an ep nov before normalisation:  74.13747247210587
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.023]
 [24.813]
 [24.813]
 [24.813]
 [24.813]] [[0.183]
 [0.114]
 [0.114]
 [0.114]
 [0.114]]
printing an ep nov before normalisation:  19.443878620845854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  18.452724534345652
printing an ep nov before normalisation:  66.5550265992337
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.520447135789546
printing an ep nov before normalisation:  51.29946538823383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.681]
 [50.443]
 [45.542]
 [61.558]
 [57.482]] [[1.425]
 [1.095]
 [0.92 ]
 [1.492]
 [1.347]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.106]
 [26.569]
 [24.19 ]
 [25.367]
 [24.005]] [[0.777]
 [0.665]
 [0.561]
 [0.613]
 [0.553]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8411679
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  45.52760552880991
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.112719776935954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.921]
 [47.64 ]
 [47.64 ]
 [47.64 ]
 [47.64 ]] [[1.603]
 [1.281]
 [1.281]
 [1.281]
 [1.281]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.433]
 [48.911]
 [48.911]
 [45.211]
 [48.911]] [[1.398]
 [1.164]
 [1.164]
 [1.032]
 [1.164]]
actions average: 
K:  4  action  0 :  tensor([    0.9629,     0.0007,     0.0000,     0.0224,     0.0140],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9692,     0.0001,     0.0000,     0.0304],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0003,     0.0008,     0.8772,     0.0684,     0.0533],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0010,     0.0063,     0.8249,     0.1673],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0005, 0.0606, 0.2779, 0.2659, 0.3952], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.03486124727017
printing an ep nov before normalisation:  50.733609199523926
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.38189897161894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.325]
 [50.325]
 [50.325]
 [50.325]
 [50.325]] [[1.315]
 [1.315]
 [1.315]
 [1.315]
 [1.315]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.56454099058644
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.873]
 [45.058]
 [43.521]
 [48.653]
 [45.079]] [[1.195]
 [1.155]
 [1.08 ]
 [1.33 ]
 [1.156]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 67.5181452760456
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.189]
 [59.209]
 [68.315]
 [59.209]
 [59.209]] [[1.404]
 [1.081]
 [1.326]
 [1.081]
 [1.081]]
printing an ep nov before normalisation:  74.55137768079561
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  79.87703213853732
printing an ep nov before normalisation:  44.849180776231535
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.439]
 [60.52 ]
 [73.199]
 [66.307]
 [58.379]] [[0.748]
 [0.811]
 [1.072]
 [0.931]
 [0.767]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9990,     0.0001,     0.0000,     0.0005,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0004,     0.9911,     0.0001,     0.0003,     0.0081],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0009,     0.9701,     0.0050,     0.0239],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0106, 0.0007, 0.0227, 0.7191, 0.2470], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0015, 0.0030, 0.1096, 0.3180, 0.5680], grad_fn=<DivBackward0>)
actions average: 
K:  1  action  0 :  tensor([    0.9887,     0.0025,     0.0000,     0.0005,     0.0083],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0067, 0.9615, 0.0015, 0.0038, 0.0264], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.9451,     0.0337,     0.0211],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0008,     0.0823,     0.6816,     0.2349],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0005, 0.0021, 0.1295, 0.4590, 0.4089], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  55.09492452683083
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.102]
 [54.102]
 [54.102]
 [54.102]
 [54.102]] [[1.235]
 [1.235]
 [1.235]
 [1.235]
 [1.235]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9891,     0.0000,     0.0000,     0.0061,     0.0048],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9981,     0.0006,     0.0001,     0.0011],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0073,     0.9734,     0.0004,     0.0189],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0001,     0.0452,     0.8084,     0.1462],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0500, 0.0110, 0.0470, 0.3087, 0.5833], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  71.18173637827853
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.95020482883758
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.091]
 [43.482]
 [63.156]
 [43.482]
 [43.482]] [[0.597]
 [0.747]
 [1.296]
 [0.747]
 [0.747]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.467851428270706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9969,     0.0003,     0.0000,     0.0000,     0.0027],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9865,     0.0004,     0.0001,     0.0130],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0004,     0.9204,     0.0399,     0.0392],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0009,     0.0004,     0.0663,     0.6469,     0.2855],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0015, 0.0051, 0.0563, 0.3580, 0.5791], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  38.620736598968506
printing an ep nov before normalisation:  25.925663888916837
printing an ep nov before normalisation:  87.20286256759323
printing an ep nov before normalisation:  67.33324736345283
printing an ep nov before normalisation:  44.68205596635632
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.26989950558486
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.19357338395697
printing an ep nov before normalisation:  109.58824415003299
printing an ep nov before normalisation:  105.27044478617486
siam score:  -0.84589416
printing an ep nov before normalisation:  65.0151811936375
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.242]
 [35.242]
 [38.372]
 [35.242]
 [35.242]] [[1.248]
 [1.248]
 [1.449]
 [1.248]
 [1.248]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.863686432945666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.84855384
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.088]
 [53.088]
 [53.088]
 [53.088]
 [53.088]] [[0.333]
 [0.333]
 [0.333]
 [0.333]
 [0.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.41366147994995
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.248]
 [48.99 ]
 [53.251]
 [56.813]
 [49.179]] [[0.407]
 [0.458]
 [0.537]
 [0.604]
 [0.461]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.51 ]
 [29.395]
 [36.537]
 [42.928]
 [26.727]] [[0.238]
 [0.171]
 [0.286]
 [0.389]
 [0.128]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.355]
 [33.355]
 [33.355]
 [33.355]
 [33.355]] [[22.248]
 [22.248]
 [22.248]
 [22.248]
 [22.248]]
printing an ep nov before normalisation:  53.366491730972996
printing an ep nov before normalisation:  59.226238894627315
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.204]
 [44.204]
 [63.669]
 [62.537]
 [44.204]] [[0.669]
 [0.669]
 [1.097]
 [1.072]
 [0.669]]
printing an ep nov before normalisation:  54.90898210821267
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.759]
 [50.073]
 [56.449]
 [49.856]
 [47.53 ]] [[0.644]
 [0.698]
 [0.847]
 [0.693]
 [0.639]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.84331053
printing an ep nov before normalisation:  62.154298178794605
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.75807960769619
printing an ep nov before normalisation:  69.33169902962138
printing an ep nov before normalisation:  86.58927203371466
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9691,     0.0002,     0.0000,     0.0238,     0.0069],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0006,     0.9395,     0.0072,     0.0028,     0.0500],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0003,     0.8268,     0.0941,     0.0786],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0009,     0.0225,     0.6739,     0.3024],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0004,     0.0089,     0.0041,     0.2755,     0.7111],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.830164087952156
printing an ep nov before normalisation:  41.06972850989998
siam score:  -0.8442034
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.81249130417797
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.752738764264972
printing an ep nov before normalisation:  61.72267060176299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  18.660567737239198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.631]
 [56.631]
 [56.631]
 [56.631]
 [56.631]] [[1.716]
 [1.716]
 [1.716]
 [1.716]
 [1.716]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.453]
 [35.005]
 [35.005]
 [35.005]
 [35.005]] [[1.702]
 [1.078]
 [1.078]
 [1.078]
 [1.078]]
printing an ep nov before normalisation:  60.96503639309556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.1133073551453
printing an ep nov before normalisation:  79.62997332780596
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.1728836660196
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[103.634]
 [ 92.917]
 [104.237]
 [109.294]
 [110.513]] [[1.393]
 [1.144]
 [1.407]
 [1.525]
 [1.553]]
printing an ep nov before normalisation:  47.45994692932477
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.14228555246383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.924590743837996
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.577]
 [50.48 ]
 [60.96 ]
 [60.685]
 [48.655]] [[1.112]
 [0.956]
 [1.355]
 [1.344]
 [0.887]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.994]
 [61.032]
 [65.615]
 [62.05 ]
 [57.669]] [[1.246]
 [1.282]
 [1.44 ]
 [1.317]
 [1.166]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.14287197924386
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.4656209649986
printing an ep nov before normalisation:  59.036769879386725
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.949]
 [53.949]
 [54.987]
 [53.949]
 [53.949]] [[1.943]
 [1.943]
 [2.   ]
 [1.943]
 [1.943]]
printing an ep nov before normalisation:  68.20713269966531
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.24892007766196
printing an ep nov before normalisation:  50.131193051775924
printing an ep nov before normalisation:  64.13172025409244
printing an ep nov before normalisation:  58.305199626056776
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.202306747436523
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.482]
 [37.373]
 [36.294]
 [40.109]
 [31.85 ]] [[0.294]
 [0.34 ]
 [0.323]
 [0.383]
 [0.252]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.695172313115435
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.22202483028322
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.807]
 [41.807]
 [43.014]
 [41.807]
 [41.807]] [[0.367]
 [0.367]
 [0.39 ]
 [0.367]
 [0.367]]
printing an ep nov before normalisation:  31.89135118404156
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.666860580444336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.399]
 [48.399]
 [48.399]
 [64.652]
 [48.399]] [[0.671]
 [0.671]
 [0.671]
 [1.3  ]
 [0.671]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.74 ]
 [53.354]
 [53.354]
 [62.297]
 [45.368]] [[1.118]
 [0.942]
 [0.942]
 [1.301]
 [0.622]]
printing an ep nov before normalisation:  70.81228072556067
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.577]
 [74.437]
 [65.215]
 [74.437]
 [74.437]] [[1.385]
 [1.644]
 [1.34 ]
 [1.644]
 [1.644]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.639831687275155
printing an ep nov before normalisation:  55.57820928186632
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.211936267571616
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  114.00628951849117
siam score:  -0.84557116
actions average: 
K:  3  action  0 :  tensor([    0.9726,     0.0002,     0.0000,     0.0115,     0.0157],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0003,     0.9445,     0.0234,     0.0006,     0.0313],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9539,     0.0002,     0.0459],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0040, 0.0016, 0.1070, 0.7137, 0.1737], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0011, 0.0372, 0.0823, 0.2313, 0.6481], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.608]
 [56.541]
 [48.816]
 [42.958]
 [42.958]] [[1.369]
 [1.332]
 [1.062]
 [0.857]
 [0.857]]
printing an ep nov before normalisation:  69.07871575377216
UNIT TEST: sample policy line 217 mcts : [0.154 0.077 0.205 0.436 0.128]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.8501526
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.98784362163391
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.031493186950684
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.03505204689472
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.626678021151974
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.933942822443626
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.501]
 [65.451]
 [47.518]
 [65.937]
 [65.227]] [[1.92 ]
 [1.919]
 [1.286]
 [1.936]
 [1.911]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.258]
 [46.258]
 [46.258]
 [46.258]
 [46.258]] [[0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.778]]
siam score:  -0.84814787
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.859896659851074
printing an ep nov before normalisation:  29.241698200416124
printing an ep nov before normalisation:  48.989521710939414
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 52.108323832328985
printing an ep nov before normalisation:  79.4558144226753
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.09467119044405
printing an ep nov before normalisation:  37.380217380977115
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.45090996545026
printing an ep nov before normalisation:  46.656931088362725
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8498471
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.17507549173517
printing an ep nov before normalisation:  61.561098861236175
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.831448793411255
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.82023620605469
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.488033294677734
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.00890426093616
printing an ep nov before normalisation:  64.25656585883375
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.06 ]
 [36.75 ]
 [32.648]
 [37.582]
 [34.978]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  24.54508125687149
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.7158840268871
actions average: 
K:  1  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0003,     0.0004],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0005,     0.9909,     0.0040,     0.0001,     0.0045],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9685,     0.0217,     0.0097],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0009,     0.0356,     0.6315,     0.3316],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0058, 0.0374, 0.1205, 0.3250, 0.5112], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.528093045126326
printing an ep nov before normalisation:  20.50394532328577
printing an ep nov before normalisation:  44.013373787973094
printing an ep nov before normalisation:  26.600274279959546
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.58553552232442
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9989,     0.0001,     0.0000,     0.0001,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0060, 0.9823, 0.0028, 0.0024, 0.0065], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9286,     0.0408,     0.0305],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0008,     0.0002,     0.0585,     0.7872,     0.1533],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0033, 0.2126, 0.0036, 0.1551, 0.6254], grad_fn=<DivBackward0>)
actions average: 
K:  1  action  0 :  tensor([    0.9994,     0.0004,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9528,     0.0133,     0.0274,     0.0061],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0021,     0.9623,     0.0137,     0.0218],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0011,     0.0005,     0.0466,     0.7280,     0.2238],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0014, 0.0016, 0.1643, 0.2190, 0.6137], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.70288536571955
printing an ep nov before normalisation:  45.35953736309957
printing an ep nov before normalisation:  65.31501404880053
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  49.92330551147461
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.613115258998782
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[97.08]
 [97.08]
 [97.08]
 [97.08]
 [97.08]] [[1.166]
 [1.166]
 [1.166]
 [1.166]
 [1.166]]
printing an ep nov before normalisation:  64.46980013778797
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  18.492142856121063
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.221]
 [62.238]
 [67.715]
 [66.462]
 [65.393]] [[0.557]
 [1.427]
 [1.678]
 [1.62 ]
 [1.571]]
printing an ep nov before normalisation:  50.30530172894157
printing an ep nov before normalisation:  86.95005944638788
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.85009784
line 256 mcts: sample exp_bonus 39.487710511841094
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.8701213028827
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.73544365948178
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.010858793026685
printing an ep nov before normalisation:  44.88868131527521
printing an ep nov before normalisation:  76.50525263324
actions average: 
K:  2  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0007,     0.9606,     0.0003,     0.0294,     0.0090],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0014,     0.9212,     0.0256,     0.0517],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0003,     0.0394,     0.7173,     0.2426],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0094, 0.0008, 0.0536, 0.2307, 0.7055], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.42616169414131
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.478]
 [46.478]
 [46.478]
 [46.478]
 [46.478]] [[0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]]
siam score:  -0.8487776
printing an ep nov before normalisation:  27.51566773297241
printing an ep nov before normalisation:  32.14498996734619
siam score:  -0.8500879
printing an ep nov before normalisation:  34.277403354644775
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.48243153457079
siam score:  -0.85572934
printing an ep nov before normalisation:  61.61734845695088
printing an ep nov before normalisation:  57.190662227385225
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.85543627
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.142]
 [32.694]
 [34.168]
 [35.324]
 [32.083]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.41 ]
 [27.272]
 [26.836]
 [26.494]
 [27.787]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.70019410655238
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.696597561298404
printing an ep nov before normalisation:  35.42936444282532
using explorer policy with actor:  1
siam score:  -0.857315
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.85871553
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.012290954589844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.30649002634481
using explorer policy with actor:  1
printing an ep nov before normalisation:  60.10297775268555
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.602]
 [87.602]
 [87.602]
 [87.602]
 [87.602]] [[1.69]
 [1.69]
 [1.69]
 [1.69]
 [1.69]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.52353693266624
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.743]
 [40.947]
 [54.195]
 [54.592]
 [33.532]] [[0.574]
 [0.73 ]
 [1.126]
 [1.138]
 [0.508]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.83 ]
 [65.83 ]
 [65.83 ]
 [75.415]
 [65.83 ]] [[1.074]
 [1.074]
 [1.074]
 [1.274]
 [1.074]]
actions average: 
K:  3  action  0 :  tensor([    0.9684,     0.0004,     0.0000,     0.0194,     0.0118],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0057,     0.9297,     0.0243,     0.0403],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0005,     0.0199,     0.7705,     0.2091],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0012, 0.0057, 0.0858, 0.3873, 0.5200], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.45 ]
 [53.45 ]
 [50.767]
 [53.924]
 [53.45 ]] [[1.645]
 [1.645]
 [1.522]
 [1.667]
 [1.645]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.64896522893002
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.69480169141717
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.606551830848666
printing an ep nov before normalisation:  29.31976662710329
siam score:  -0.86792773
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.777]
 [35.777]
 [35.777]
 [35.777]
 [35.777]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  28.883665721614157
printing an ep nov before normalisation:  41.54739856719971
printing an ep nov before normalisation:  98.6307216865404
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.318]
 [42.289]
 [32.338]
 [39.318]
 [39.318]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.086]
 [82.086]
 [95.972]
 [82.086]
 [82.086]] [[0.784]
 [0.784]
 [0.927]
 [0.784]
 [0.784]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.01089204473324
actions average: 
K:  1  action  0 :  tensor([    0.9993,     0.0001,     0.0000,     0.0002,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0013, 0.8779, 0.0699, 0.0097, 0.0411], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0002,     0.9525,     0.0192,     0.0279],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0008,     0.0007,     0.0003,     0.7035,     0.2946],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0195, 0.0161, 0.0925, 0.4160, 0.4558], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  126.9828989934334
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 26.72199010848999
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.58192554113022
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.74 ]
 [48.485]
 [56.772]
 [44.526]
 [40.465]] [[0.889]
 [0.955]
 [1.27 ]
 [0.805]
 [0.651]]
printing an ep nov before normalisation:  44.140496253967285
printing an ep nov before normalisation:  35.55551052093506
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.54278630296241
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.85 ]
 [45.841]
 [41.11 ]
 [63.368]
 [46.804]] [[0.746]
 [0.537]
 [0.413]
 [0.995]
 [0.562]]
printing an ep nov before normalisation:  61.615558907580535
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.938173219664186
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.19077681445395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     1.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.9647,     0.0110,     0.0239],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0021, 0.0017, 0.1369, 0.6761, 0.1832], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0534, 0.0028, 0.1269, 0.3908, 0.4263], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  33.97469997406006
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  125.44152582474348
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9994,     0.0001,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0007,     0.9311,     0.0307,     0.0070,     0.0304],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0003,     0.9125,     0.0471,     0.0399],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0198, 0.0018, 0.0034, 0.7965, 0.1785], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0114, 0.0085, 0.0866, 0.3978, 0.4957], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.803]
 [46.596]
 [62.464]
 [62.464]
 [62.464]] [[1.447]
 [2.   ]
 [3.127]
 [3.127]
 [3.127]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  109.64574232387868
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.422]
 [48.719]
 [53.572]
 [42.952]
 [42.952]] [[0.671]
 [0.908]
 [1.066]
 [0.721]
 [0.721]]
printing an ep nov before normalisation:  36.0180037077437
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.851918985006975
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  40.072364807128906
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9064209
printing an ep nov before normalisation:  80.13528391563115
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.469]
 [62.469]
 [87.02 ]
 [62.469]
 [62.469]] [[0.752]
 [0.752]
 [1.391]
 [0.752]
 [0.752]]
printing an ep nov before normalisation:  70.16016056347333
printing an ep nov before normalisation:  93.66289242281108
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  62.267771901997264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.952]
 [51.133]
 [52.283]
 [56.69 ]
 [51.168]] [[0.947]
 [0.812]
 [0.845]
 [0.968]
 [0.813]]
printing an ep nov before normalisation:  53.62454982145597
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0006,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9986,     0.0000,     0.0000,     0.0012],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0048,     0.9871,     0.0016,     0.0064],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0043,     0.0007,     0.0460,     0.7509,     0.1982],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0030, 0.0008, 0.0774, 0.4921, 0.4267], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  20.77434674988695
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.45877607480496
printing an ep nov before normalisation:  20.965075492858887
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9581,     0.0004,     0.0000,     0.0036,     0.0379],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0012,     0.9621,     0.0085,     0.0280],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0008,     0.0003,     0.0006,     0.7715,     0.2268],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0026, 0.0043, 0.1313, 0.2726, 0.5892], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  42.98205434176949
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  38.12937526316186
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 67.67430327930765
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9945,     0.0000,     0.0000,     0.0032,     0.0023],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9321,     0.0302,     0.0006,     0.0370],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0001,     0.9688,     0.0167,     0.0144],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0009,     0.0425,     0.7530,     0.2033],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0063, 0.0009, 0.1405, 0.2788, 0.5734], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.29195785522461
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.012]
 [31.399]
 [28.265]
 [33.853]
 [29.333]] [[0.22 ]
 [0.129]
 [0.107]
 [0.145]
 [0.115]]
printing an ep nov before normalisation:  46.04786396026611
printing an ep nov before normalisation:  48.46589882401021
printing an ep nov before normalisation:  57.18465099077157
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  100.8165352562625
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.962]
 [62.593]
 [90.32 ]
 [81.315]
 [69.761]] [[0.153]
 [0.297]
 [0.481]
 [0.421]
 [0.344]]
printing an ep nov before normalisation:  54.391988403121815
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.108]
 [32.737]
 [46.699]
 [32.603]
 [32.763]] [[0.37 ]
 [0.469]
 [0.85 ]
 [0.465]
 [0.469]]
actions average: 
K:  2  action  0 :  tensor([    0.9996,     0.0001,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9999,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0006,     0.0009,     0.8554,     0.0894,     0.0537],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0012,     0.0005,     0.0185,     0.8182,     0.1616],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0052, 0.0039, 0.1064, 0.4604, 0.4242], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.35835179271618
siam score:  -0.8835094
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.994]
 [70.994]
 [91.809]
 [81.116]
 [70.994]] [[0.532]
 [0.532]
 [0.812]
 [0.668]
 [0.532]]
printing an ep nov before normalisation:  57.05116622434715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.73216933926205
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  81.12970617280457
siam score:  -0.89386255
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.143]
 [63.143]
 [63.143]
 [63.143]
 [63.143]] [[1.308]
 [1.308]
 [1.308]
 [1.308]
 [1.308]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  67.31626331938136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.08944033176113
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9837,     0.0001,     0.0001,     0.0025,     0.0136],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9738,     0.0060,     0.0003,     0.0200],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9599,     0.0146,     0.0254],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0002,     0.0192,     0.6716,     0.3088],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0024, 0.0706, 0.0394, 0.3136, 0.5740], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  59.9052095413208
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.754]
 [34.442]
 [40.58 ]
 [45.068]
 [36.375]] [[0.505]
 [0.31 ]
 [0.426]
 [0.511]
 [0.347]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.098]
 [51.387]
 [57.925]
 [55.992]
 [52.413]] [[0.683]
 [0.802]
 [0.982]
 [0.929]
 [0.83 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.603105545043945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9966,     0.0001,     0.0000,     0.0009,     0.0024],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9755,     0.0005,     0.0007,     0.0230],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0056,     0.9517,     0.0130,     0.0295],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0012,     0.0002,     0.0053,     0.8745,     0.1189],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0047, 0.0045, 0.1091, 0.4783, 0.4033], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.001]
 [69.001]
 [69.001]
 [69.001]
 [69.001]] [[0.26]
 [0.26]
 [0.26]
 [0.26]
 [0.26]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.427]
 [41.427]
 [45.447]
 [41.427]
 [41.427]] [[0.563]
 [0.563]
 [0.667]
 [0.563]
 [0.563]]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 36.519990831123266
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  67.03656016186076
line 256 mcts: sample exp_bonus 31.583524807794085
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.530330657958984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  66.87276029178778
printing an ep nov before normalisation:  56.50679588317871
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.17101912752495
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.565]
 [22.842]
 [22.22 ]
 [48.375]
 [21.166]] [[0.26 ]
 [0.29 ]
 [0.275]
 [0.893]
 [0.251]]
printing an ep nov before normalisation:  46.4652946490165
printing an ep nov before normalisation:  53.98613015105839
printing an ep nov before normalisation:  35.699622631073
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.346]
 [33.862]
 [39.057]
 [20.001]
 [43.687]] [[0.258]
 [0.547]
 [0.667]
 [0.227]
 [0.774]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  97.17007691677841
printing an ep nov before normalisation:  41.49471122424701
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.46009571176237
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.37876023091362
printing an ep nov before normalisation:  79.55304991170492
actions average: 
K:  4  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0005,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9961,     0.0000,     0.0002,     0.0034],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0275,     0.8586,     0.0754,     0.0384],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0040,     0.0004,     0.0850,     0.6955,     0.2152],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0392, 0.0533, 0.0651, 0.4253, 0.4171], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.178]
 [54.634]
 [51.333]
 [59.022]
 [53.178]] [[1.717]
 [1.788]
 [1.628]
 [2.   ]
 [1.717]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.30952810795952
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.100411891937256
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.77546310424805
actions average: 
K:  4  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9927,     0.0001,     0.0001,     0.0071],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0009,     0.9060,     0.0434,     0.0495],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0005,     0.0698,     0.6994,     0.2298],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0109, 0.0899, 0.0348, 0.5069, 0.3575], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.232]
 [37.207]
 [37.207]
 [29.686]
 [37.207]] [[1.179]
 [0.997]
 [0.997]
 [0.657]
 [0.997]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8901323
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.565780754141336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.19853492357265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.330570831150965
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.401]
 [45.401]
 [63.324]
 [45.401]
 [45.401]] [[0.732]
 [0.732]
 [1.276]
 [0.732]
 [0.732]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.10453425508737
printing an ep nov before normalisation:  56.272440048158586
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.89445466
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.08220958709717
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.57017461849263
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.59411398940122
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  50.55598829557101
printing an ep nov before normalisation:  59.84094873713281
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.46700333844685
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.6115951892362
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.61469137084303
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  14.791824597317316
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.569937570541526
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.753]
 [38.19 ]
 [56.09 ]
 [38.19 ]
 [38.19 ]] [[0.619]
 [0.58 ]
 [1.034]
 [0.58 ]
 [0.58 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0066,     0.9636,     0.0020,     0.0006,     0.0272],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0001,     0.9333,     0.0321,     0.0344],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0002,     0.0613,     0.7933,     0.1445],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0031, 0.0073, 0.0682, 0.3925, 0.5289], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.61331955370815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.243675873247803
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.019601821899414
printing an ep nov before normalisation:  87.33608574643435
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.308 0.205 0.077 0.026 0.385]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.2924658648247
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.89620475281096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.458443116475934
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.435]
 [33.9  ]
 [32.525]
 [35.666]
 [32.525]] [[0.954]
 [0.723]
 [0.674]
 [0.785]
 [0.674]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.8992421
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9011674
actions average: 
K:  2  action  0 :  tensor([    0.9578,     0.0001,     0.0000,     0.0025,     0.0396],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0023, 0.9533, 0.0290, 0.0011, 0.0143], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0005,     0.0018,     0.9415,     0.0348,     0.0213],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0009,     0.0001,     0.0001,     0.8896,     0.1093],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0017,     0.0003,     0.0451,     0.5980,     0.3549],
       grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 61.20852442656447
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.58579670349529
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.68190066327844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.483]
 [40.088]
 [56.813]
 [56.985]
 [37.456]] [[0.593]
 [0.562]
 [0.936]
 [0.94 ]
 [0.503]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.12809085000849
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.90696191399388
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.281]
 [66.281]
 [66.281]
 [66.281]
 [66.281]] [[1.205]
 [1.205]
 [1.205]
 [1.205]
 [1.205]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.89893335
printing an ep nov before normalisation:  65.68104448469225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.386195712619354
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.23696548959313
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.62321780292253
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.7402694966182
printing an ep nov before normalisation:  42.74531241379722
printing an ep nov before normalisation:  80.29362487013101
printing an ep nov before normalisation:  47.47462973565655
printing an ep nov before normalisation:  84.67948071076923
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.6643208979266
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.08453216232233
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.105]
 [51.78 ]
 [57.312]
 [47.844]
 [43.617]] [[0.693]
 [1.4  ]
 [1.667]
 [1.211]
 [1.007]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0148,     0.9840,     0.0000,     0.0002,     0.0010],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0005,     0.8749,     0.0430,     0.0814],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0002,     0.0432,     0.7065,     0.2496],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0016,     0.0011,     0.0002,     0.3431,     0.6540],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.59766430054528
printing an ep nov before normalisation:  36.82711080506834
printing an ep nov before normalisation:  42.24464667518126
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.00337029772951
siam score:  -0.90256685
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.40541385068146
siam score:  -0.90064025
line 256 mcts: sample exp_bonus 75.56473465809269
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.20186335578214
printing an ep nov before normalisation:  58.82613331052611
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.897 0.026 0.026 0.026 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9993,     0.0000,     0.0000,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.9396,     0.0361,     0.0242],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0046,     0.0637,     0.6949,     0.2365],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0185, 0.0502, 0.0009, 0.2891, 0.6413], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  35.702475719783685
printing an ep nov before normalisation:  74.5470116565351
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9054213
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 31.429]
 [ 87.189]
 [108.754]
 [104.604]
 [ 77.886]] [[0.   ]
 [0.883]
 [1.224]
 [1.159]
 [0.736]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.90379745
printing an ep nov before normalisation:  66.67677028674576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.127]
 [77.127]
 [77.127]
 [77.127]
 [77.127]] [[1.177]
 [1.177]
 [1.177]
 [1.177]
 [1.177]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.433993485638126
printing an ep nov before normalisation:  50.27396819979465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.705008797249285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.981]
 [30.981]
 [30.981]
 [30.981]
 [30.981]] [[0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.756]]
printing an ep nov before normalisation:  34.866449044885215
siam score:  -0.8929242
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.891342938808855
printing an ep nov before normalisation:  50.512047502514164
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.508]
 [37.104]
 [51.784]
 [40.755]
 [40.421]] [[0.74 ]
 [0.538]
 [1.   ]
 [0.653]
 [0.643]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.641]
 [44.718]
 [61.38 ]
 [49.436]
 [43.229]] [[0.766]
 [0.824]
 [1.293]
 [0.957]
 [0.783]]
siam score:  -0.8886341
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.83041954040527
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.39502237670966
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.654]
 [57.597]
 [91.199]
 [64.028]
 [52.447]] [[0.4  ]
 [0.769]
 [1.309]
 [0.872]
 [0.686]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.37785625457764
printing an ep nov before normalisation:  22.019665573909425
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  98.65528135053864
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.751383781433105
printing an ep nov before normalisation:  52.97015512908467
line 256 mcts: sample exp_bonus 94.15667815015382
printing an ep nov before normalisation:  50.86931805218506
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9907,     0.0005,     0.0000,     0.0052,     0.0035],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0019,     0.9828,     0.0043,     0.0005,     0.0106],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9485,     0.0257,     0.0257],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0007,     0.0467,     0.7933,     0.1592],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0005,     0.0099,     0.0616,     0.3959,     0.5321],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.434]
 [30.692]
 [52.302]
 [31.615]
 [28.826]] [[0.601]
 [0.517]
 [1.175]
 [0.546]
 [0.461]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.565]
 [39.831]
 [39.831]
 [39.831]
 [39.831]] [[1.782]
 [1.477]
 [1.477]
 [1.477]
 [1.477]]
printing an ep nov before normalisation:  44.587882533605324
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.627]
 [39.213]
 [50.45 ]
 [29.556]
 [44.18 ]] [[0.544]
 [0.535]
 [0.76 ]
 [0.342]
 [0.635]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.282]
 [49.866]
 [38.771]
 [55.629]
 [48.946]] [[0.661]
 [0.614]
 [0.399]
 [0.726]
 [0.596]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.081618102963
siam score:  -0.8990007
actions average: 
K:  1  action  0 :  tensor([0.9599, 0.0124, 0.0099, 0.0016, 0.0162], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0148,     0.8759,     0.0003,     0.0023,     0.1068],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0039,     0.9182,     0.0428,     0.0351],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0006,     0.0003,     0.0581,     0.7399,     0.2012],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0040,     0.0003,     0.0002,     0.5488,     0.4466],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.61418217664379
printing an ep nov before normalisation:  63.775850056640735
siam score:  -0.8956495
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  105.19596534150395
printing an ep nov before normalisation:  61.16357612181507
printing an ep nov before normalisation:  84.766733486367
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.34727821241499
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 30.932376749979774
printing an ep nov before normalisation:  56.01299929377668
printing an ep nov before normalisation:  81.16349690200802
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 50.2037611311844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.59495624876625
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 63.6499547958374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9984,     0.0001,     0.0000,     0.0010,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0014, 0.9500, 0.0131, 0.0069, 0.0286], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0005,     0.9528,     0.0250,     0.0216],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0111, 0.0137, 0.0496, 0.7766, 0.1490], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0022, 0.0057, 0.0795, 0.4660, 0.4466], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.65136909484863
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  58.8109210292059
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.90714526
printing an ep nov before normalisation:  52.662291526794434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.22261047363281
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[80.581]
 [73.215]
 [82.475]
 [83.9  ]
 [67.633]] [[1.619]
 [1.409]
 [1.673]
 [1.714]
 [1.25 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.34458637237549
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  121.34935005614476
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.41111539313705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.96301163901353
actions average: 
K:  3  action  0 :  tensor([    0.9944,     0.0001,     0.0000,     0.0021,     0.0034],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9703,     0.0007,     0.0029,     0.0260],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0003,     0.9704,     0.0123,     0.0170],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0003,     0.0108,     0.0578,     0.7309,     0.2003],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0001,     0.0003,     0.1648,     0.5226,     0.3121],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  74.24588793532222
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9084325
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 1.928564937689798e-09
0.0 1.0760993797766029e-09
0.0 1.928564937689798e-09
0.0 1.4382588544400317e-09
0.0 8.671346081435927e-10
0.0 3.7516787788846057e-10
0.0 1.6794678589043887e-09
0.0 1.928564937689798e-09
0.0 2.0587873546574703e-09
0.0 0.0
printing an ep nov before normalisation:  71.77551672116608
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  97.23912247554365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.557]
 [34.742]
 [40.765]
 [56.13 ]
 [38.54 ]] [[0.475]
 [0.344]
 [0.48 ]
 [0.827]
 [0.43 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  87.38896576854546
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.468]
 [38.083]
 [49.283]
 [66.745]
 [42.733]] [[0.421]
 [0.351]
 [0.582]
 [0.942]
 [0.447]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.908]
 [31.69 ]
 [20.969]
 [18.435]
 [16.861]] [[0.696]
 [0.456]
 [0.245]
 [0.196]
 [0.165]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 88.6863410184032
printing an ep nov before normalisation:  102.81976793434417
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[100.769]
 [100.769]
 [100.769]
 [100.769]
 [100.769]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
printing an ep nov before normalisation:  28.55538003070449
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  61.46112411338536
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.21345457449631
siam score:  -0.9085634
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.077 0.462 0.205 0.154 0.103]
line 256 mcts: sample exp_bonus 0.0
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  95.74356510630642
printing an ep nov before normalisation:  87.72768729926064
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.947]
 [65.947]
 [81.766]
 [65.947]
 [65.947]] [[1.018]
 [1.018]
 [1.351]
 [1.018]
 [1.018]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.187]
 [44.187]
 [44.187]
 [44.187]
 [44.187]] [[0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.50704624366152
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.599750241220775
printing an ep nov before normalisation:  82.32327063570035
printing an ep nov before normalisation:  27.20602512359619
using explorer policy with actor:  1
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.80288414132892
printing an ep nov before normalisation:  29.89824612248132
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  79.65502288024511
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.10844421386719
printing an ep nov before normalisation:  36.146604035001715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.784579157829285
siam score:  -0.9095407
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.564]
 [37.866]
 [42.913]
 [41.932]
 [34.823]] [[0.73 ]
 [0.741]
 [0.927]
 [0.891]
 [0.629]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.326]
 [52.606]
 [62.691]
 [62.503]
 [52.606]] [[1.702]
 [1.39 ]
 [1.751]
 [1.744]
 [1.39 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  21.677067279815674
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.3432558953143
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.129]
 [29.973]
 [35.078]
 [34.684]
 [33.858]] [[1.133]
 [1.056]
 [1.398]
 [1.372]
 [1.316]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.07731423145582
printing an ep nov before normalisation:  59.5839778616778
siam score:  -0.9134461
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.371]
 [29.456]
 [38.196]
 [47.466]
 [33.239]] [[0.608]
 [0.308]
 [0.602]
 [0.914]
 [0.435]]
line 256 mcts: sample exp_bonus 66.54197251204977
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.39371505347482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.526]
 [66.526]
 [66.526]
 [66.526]
 [66.526]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  106.89880523084446
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.918]
 [57.918]
 [57.918]
 [57.918]
 [57.918]] [[0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.575]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.214]
 [34.256]
 [38.104]
 [55.376]
 [37.163]] [[0.313]
 [0.253]
 [0.311]
 [0.569]
 [0.297]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.079]
 [48.431]
 [27.404]
 [37.345]
 [43.079]] [[1.375]
 [1.667]
 [0.522]
 [1.063]
 [1.375]]
printing an ep nov before normalisation:  52.95400731791915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.30334118058575
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.25714588165283
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.59835233540012
printing an ep nov before normalisation:  55.86421050067416
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.9060432172185
using explorer policy with actor:  1
printing an ep nov before normalisation:  63.58479376440697
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
UNIT TEST: sample policy line 217 mcts : [0.103 0.154 0.513 0.103 0.128]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.602]
 [49.456]
 [58.941]
 [47.096]
 [38.454]] [[0.146]
 [0.246]
 [0.333]
 [0.224]
 [0.144]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  73.85422071155612
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.29076957702637
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.932]
 [31.213]
 [41.627]
 [22.074]
 [20.932]] [[0.063]
 [0.122]
 [0.182]
 [0.07 ]
 [0.063]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.155]
 [40.435]
 [41.155]
 [40.86 ]
 [41.155]] [[1.014]
 [0.98 ]
 [1.014]
 [1.   ]
 [1.014]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  7.298747050299426e-05
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.57976204463877
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.52444251196873
printing an ep nov before normalisation:  65.56287189930447
printing an ep nov before normalisation:  77.4414004148031
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.894069750915
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.90535057
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 37.92485922619433
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  74.228785473261
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.615 0.128 0.154 0.077 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9988,     0.0000,     0.0000,     0.0010],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9641,     0.0122,     0.0235],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0014,     0.0003,     0.0193,     0.7958,     0.1833],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0015, 0.0011, 0.0471, 0.5120, 0.4383], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.157]
 [21.849]
 [33.442]
 [17.224]
 [17.157]] [[0.053]
 [0.081]
 [0.149]
 [0.054]
 [0.053]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.857]
 [46.032]
 [32.987]
 [45.908]
 [46.032]] [[0.493]
 [0.509]
 [0.331]
 [0.507]
 [0.509]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.139182090759277
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.088]
 [37.088]
 [37.088]
 [59.824]
 [37.088]] [[0.403]
 [0.403]
 [0.403]
 [0.863]
 [0.403]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.649]
 [41.649]
 [38.717]
 [43.633]
 [42.063]] [[1.236]
 [1.127]
 [0.967]
 [1.235]
 [1.15 ]]
actions average: 
K:  0  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9995,     0.0000,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0030, 0.0075, 0.9566, 0.0146, 0.0183], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0007,     0.0005,     0.0695,     0.7467,     0.1826],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0010, 0.0010, 0.0601, 0.5559, 0.3820], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.565016690714174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.60755015543619
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.78004478957669
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.245]
 [64.245]
 [70.93 ]
 [64.245]
 [64.245]] [[1.683]
 [1.683]
 [2.   ]
 [1.683]
 [1.683]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.41270671752699
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.127962589263916
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.307948039389764
printing an ep nov before normalisation:  76.25294458643755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.5554186724782
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.62145522670249
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.48995714924511
siam score:  -0.9077437
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.6426305770874
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.33971931983945
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.01119340811302
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.20026693947164
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.547]
 [49.551]
 [52.014]
 [49.551]
 [49.551]] [[1.733]
 [1.566]
 [1.703]
 [1.566]
 [1.566]]
printing an ep nov before normalisation:  61.24501212843618
using explorer policy with actor:  1
siam score:  -0.9023967
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.90220255
printing an ep nov before normalisation:  63.24943317487111
printing an ep nov before normalisation:  42.98176810045455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.98769121606299
printing an ep nov before normalisation:  44.35290336608887
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  86.84087819228799
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9977,     0.0006,     0.0000,     0.0007,     0.0010],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9991,     0.0003,     0.0001,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9588,     0.0206,     0.0206],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0002,     0.0505,     0.8133,     0.1356],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0258, 0.0013, 0.1082, 0.4824, 0.3824], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.057]
 [72.057]
 [75.934]
 [72.057]
 [72.057]] [[1.552]
 [1.552]
 [1.667]
 [1.552]
 [1.552]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.93929841277649
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.90646154
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.891]
 [39.081]
 [47.492]
 [42.083]
 [39.081]] [[0.964]
 [0.355]
 [0.516]
 [0.413]
 [0.355]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  85.15462668964261
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.90350676
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9936,     0.0002,     0.0001,     0.0019,     0.0041],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9987,     0.0000,     0.0000,     0.0013],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0002,     0.9584,     0.0246,     0.0167],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0006,     0.0647,     0.7894,     0.1449],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0002,     0.0014,     0.1874,     0.3312,     0.4798],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  46.277974673412615
printing an ep nov before normalisation:  53.436760340868176
printing an ep nov before normalisation:  66.47249684702047
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.23887423113011
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.44685186785357
siam score:  -0.9095615
printing an ep nov before normalisation:  48.92735313804779
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.281]
 [60.06 ]
 [71.864]
 [83.836]
 [49.281]] [[0.562]
 [0.78 ]
 [1.02 ]
 [1.262]
 [0.562]]
printing an ep nov before normalisation:  73.53787434184754
printing an ep nov before normalisation:  82.66389195489351
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.0490589583639
actions average: 
K:  2  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0008,     0.9681,     0.0005,     0.0002,     0.0303],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9994,     0.0003,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0024, 0.0034, 0.0057, 0.8194, 0.1691], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0050, 0.0014, 0.2429, 0.5249, 0.2258], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9041295
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.90421736
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.754]
 [83.754]
 [83.754]
 [83.754]
 [83.754]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.409]
 [57.345]
 [70.993]
 [64.432]
 [62.323]] [[0.71 ]
 [0.734]
 [1.096]
 [0.922]
 [0.866]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  90.04703817935678
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.046]
 [39.819]
 [38.08 ]
 [38.544]
 [64.088]] [[2.   ]
 [1.609]
 [1.479]
 [1.514]
 [3.424]]
printing an ep nov before normalisation:  48.180227279663086
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.309]
 [47.309]
 [69.188]
 [47.309]
 [47.309]] [[1.142]
 [1.142]
 [2.   ]
 [1.142]
 [1.142]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9098366
siam score:  -0.91110206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.76243280748591
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.288]
 [33.1  ]
 [33.1  ]
 [33.1  ]
 [33.1  ]] [[0.659]
 [0.375]
 [0.375]
 [0.375]
 [0.375]]
siam score:  -0.9113734
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[98.715]
 [98.715]
 [98.715]
 [98.715]
 [98.715]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.551]
 [61.551]
 [61.551]
 [61.551]
 [61.551]] [[1.383]
 [1.383]
 [1.383]
 [1.383]
 [1.383]]
printing an ep nov before normalisation:  66.3836878763716
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.364]
 [77.364]
 [77.364]
 [93.665]
 [77.364]] [[1.393]
 [1.393]
 [1.393]
 [1.767]
 [1.393]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  100.72844731736502
siam score:  -0.913563
printing an ep nov before normalisation:  52.285283275648865
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  79.66063452557904
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[81.31 ]
 [81.31 ]
 [81.31 ]
 [92.905]
 [81.31 ]] [[1.294]
 [1.294]
 [1.294]
 [1.515]
 [1.294]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.91259885
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  1
printing an ep nov before normalisation:  67.78162166084307
printing an ep nov before normalisation:  28.3242130279541
printing an ep nov before normalisation:  34.13704541952119
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.243701792128874
printing an ep nov before normalisation:  23.594411694167327
UNIT TEST: sample policy line 217 mcts : [0.103 0.128 0.282 0.462 0.026]
printing an ep nov before normalisation:  70.6355205947965
printing an ep nov before normalisation:  40.7311217396988
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.90065786139469
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.877]
 [48.744]
 [50.505]
 [42.684]
 [38.942]] [[0.696]
 [0.745]
 [0.791]
 [0.586]
 [0.488]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  78.38992581801585
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.258]
 [60.577]
 [65.025]
 [60.577]
 [60.577]] [[1.15 ]
 [0.749]
 [0.844]
 [0.749]
 [0.749]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  82.95670365400632
printing an ep nov before normalisation:  30.532989501953125
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.762]
 [57.762]
 [57.762]
 [57.762]
 [57.762]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  45.044864497799004
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  67.7801924273982
printing an ep nov before normalisation:  57.34240531921387
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.56152505860382
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.057]
 [51.057]
 [51.057]
 [51.057]
 [51.057]] [[1.022]
 [1.022]
 [1.022]
 [1.022]
 [1.022]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0006,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9911,     0.0001,     0.0003,     0.0083],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0003,     0.9124,     0.0512,     0.0359],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0003,     0.0580,     0.7346,     0.2069],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0145, 0.0077, 0.1185, 0.3680, 0.4913], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.17131598639
printing an ep nov before normalisation:  79.47849347957177
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.84166717529297
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([0.9856, 0.0066, 0.0021, 0.0019, 0.0037], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9812,     0.0001,     0.0004,     0.0181],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0004,     0.8994,     0.0552,     0.0448],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0001,     0.0186,     0.8171,     0.1639],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0004,     0.0003,     0.0596,     0.5566,     0.3831],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.165]
 [62.398]
 [62.753]
 [65.792]
 [62.398]] [[0.837]
 [0.875]
 [0.881]
 [0.933]
 [0.875]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.478]
 [38.812]
 [29.521]
 [30.897]
 [28.982]] [[0.568]
 [0.741]
 [0.44 ]
 [0.484]
 [0.422]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.16275704840768
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  69.8392177198918
siam score:  -0.90548265
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.12057731878604
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.994]
 [79.994]
 [80.315]
 [79.994]
 [79.994]] [[0.833]
 [0.833]
 [0.837]
 [0.833]
 [0.833]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.32505412422337
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.90065444
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.9372474825079
siam score:  -0.89707446
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.746]
 [51.746]
 [51.746]
 [51.746]
 [51.746]] [[1.535]
 [1.535]
 [1.535]
 [1.535]
 [1.535]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  90.4014139486774
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.83751964569092
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.085]
 [52.085]
 [52.085]
 [68.632]
 [52.085]] [[0.535]
 [0.535]
 [0.535]
 [0.849]
 [0.535]]
printing an ep nov before normalisation:  82.2730581385241
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.412]
 [35.233]
 [35.233]
 [31.453]
 [35.233]] [[0.859]
 [0.344]
 [0.344]
 [0.272]
 [0.344]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.27319247065637
actions average: 
K:  2  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9989,     0.0000,     0.0000,     0.0008],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0003,     0.9228,     0.0320,     0.0448],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0025, 0.0008, 0.0366, 0.7792, 0.1808], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0480, 0.0049, 0.0383, 0.2921, 0.6166], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.79662201269138
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9907,     0.0011,     0.0004,     0.0060,     0.0018],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9952,     0.0025,     0.0000,     0.0021],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0002,     0.9262,     0.0141,     0.0596],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0021,     0.0007,     0.0656,     0.7087,     0.2229],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0139, 0.0326, 0.0033, 0.4255, 0.5247], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.63033620694244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.942]
 [67.942]
 [67.942]
 [67.942]
 [67.942]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.80770583357311
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  68.44889462363297
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  102.52342459896937
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.392]
 [51.392]
 [51.392]
 [72.168]
 [51.392]] [[0.407]
 [0.407]
 [0.407]
 [0.681]
 [0.407]]
actions average: 
K:  1  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0008,     0.9991,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0122,     0.9178,     0.0336,     0.0362],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0010,     0.0005,     0.0414,     0.8167,     0.1404],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0420, 0.0477, 0.0081, 0.3747, 0.5274], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.27966042787808
printing an ep nov before normalisation:  94.6715207867623
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.235654963498256
siam score:  -0.90746385
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.034659155538314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.1775633229152
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.040093573631886
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.964]
 [32.3  ]
 [32.3  ]
 [34.076]
 [32.3  ]] [[1.194]
 [0.693]
 [0.693]
 [0.75 ]
 [0.693]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9966,     0.0003,     0.0000,     0.0022,     0.0009],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0029, 0.8826, 0.0013, 0.0029, 0.1103], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9641,     0.0226,     0.0132],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0007,     0.0001,     0.0014,     0.8515,     0.1463],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0841, 0.0225, 0.0009, 0.4148, 0.4777], grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 61.29591826430125
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  105.33030683492474
printing an ep nov before normalisation:  48.02166065200096
using explorer policy with actor:  1
printing an ep nov before normalisation:  82.35655593102425
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.298197150659405
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.68810982863463
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.130086490086146
printing an ep nov before normalisation:  64.37108770496903
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.02405607050967
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.184]
 [93.184]
 [80.66 ]
 [99.114]
 [93.184]] [[1.168]
 [1.168]
 [0.963]
 [1.265]
 [1.168]]
printing an ep nov before normalisation:  76.53660209413324
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.7301510755697
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.28617573781579
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9079794
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.173]
 [57.173]
 [57.173]
 [57.173]
 [57.173]] [[0.982]
 [0.982]
 [0.982]
 [0.982]
 [0.982]]
line 256 mcts: sample exp_bonus 41.379761695861816
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.362]
 [45.469]
 [29.362]
 [29.362]
 [29.362]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  58.29457225271658
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.445445032053314
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.504]
 [49.504]
 [68.253]
 [57.564]
 [49.504]] [[0.826]
 [0.826]
 [1.319]
 [1.038]
 [0.826]]
printing an ep nov before normalisation:  72.15250295992897
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 52.84696578979492
printing an ep nov before normalisation:  42.33573913574219
actions average: 
K:  3  action  0 :  tensor([    0.9968,     0.0000,     0.0000,     0.0018,     0.0014],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0003,     0.9876,     0.0004,     0.0002,     0.0115],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0005,     0.0045,     0.9788,     0.0047,     0.0115],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0002,     0.0543,     0.7686,     0.1764],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0039,     0.0029,     0.0004,     0.5286,     0.4641],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  39.38826635856297
printing an ep nov before normalisation:  55.260497498931706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.12816524505615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  52.764368946613985
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.311]
 [50.16 ]
 [49.166]
 [63.498]
 [46.641]] [[0.339]
 [0.715]
 [0.693]
 [1.013]
 [0.636]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.78977464439734
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.16496594441364
siam score:  -0.9074211
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.55286839329381
actions average: 
K:  1  action  0 :  tensor([    0.9821,     0.0153,     0.0000,     0.0002,     0.0024],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0005,     0.9338,     0.0387,     0.0269],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0005,     0.0190,     0.8117,     0.1686],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0005,     0.0006,     0.0271,     0.5429,     0.4289],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  44.25303042910755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.27366353639427
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.33257013503099
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.0714829660127
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.173779715870225
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.887]
 [33.88 ]
 [33.88 ]
 [33.88 ]
 [33.88 ]] [[1.293]
 [0.564]
 [0.564]
 [0.564]
 [0.564]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91381526
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.16406260463962
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.101]
 [37.788]
 [48.056]
 [36.197]
 [35.251]] [[0.422]
 [0.459]
 [0.688]
 [0.424]
 [0.403]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 37.0920187609371
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.057]
 [38.076]
 [38.076]
 [39.991]
 [38.076]] [[0.787]
 [0.583]
 [0.583]
 [0.639]
 [0.583]]
printing an ep nov before normalisation:  40.12653827667236
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 5.981097632187745e-10
0.0 1.022958669366951e-09
0.0 4.0492114011187426e-10
0.0 1.393282993070354e-09
0.0 3.329597618069728e-10
0.0 0.0
0.0 2.272318906188375e-10
0.0 6.8557051532442e-10
0.0 5.981097632187745e-10
0.0 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  45.25742053985596
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.164]
 [40.164]
 [40.164]
 [46.593]
 [40.164]] [[0.734]
 [0.734]
 [0.734]
 [0.962]
 [0.734]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.1895120400401
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  48.24528007485722
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.036753434249334
printing an ep nov before normalisation:  65.89558025344802
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0004,     0.0007],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9987,     0.0001,     0.0001,     0.0010],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9580,     0.0251,     0.0168],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0044,     0.0001,     0.0201,     0.8492,     0.1261],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0019, 0.0025, 0.0729, 0.5148, 0.4080], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.528417138449182
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.32367821304335
printing an ep nov before normalisation:  52.82886936837369
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.00375999733457
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.48930297037836
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.615757679612756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.963]
 [40.501]
 [40.501]
 [40.501]
 [40.501]] [[0.984]
 [0.652]
 [0.652]
 [0.652]
 [0.652]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.4  ]
 [38.56 ]
 [23.539]
 [23.527]
 [22.949]] [[0.37 ]
 [0.831]
 [0.374]
 [0.374]
 [0.356]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.16232126526737
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0020,     0.9949,     0.0019,     0.0000,     0.0012],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9270,     0.0473,     0.0255],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0004,     0.0466,     0.7618,     0.1907],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0003,     0.0008,     0.0648,     0.6265,     0.3077],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.988]
 [66.988]
 [76.582]
 [81.104]
 [66.988]] [[1.146]
 [1.146]
 [1.358]
 [1.457]
 [1.146]]
actions average: 
K:  4  action  0 :  tensor([    0.9981,     0.0000,     0.0000,     0.0001,     0.0018],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9958,     0.0005,     0.0002,     0.0035],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0002,     0.9386,     0.0269,     0.0342],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0032,     0.0003,     0.0903,     0.7267,     0.1796],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0058, 0.0014, 0.0454, 0.5292, 0.4182], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  62.90927922367588
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.585]
 [31.927]
 [43.597]
 [29.935]
 [28.956]] [[0.72 ]
 [0.785]
 [1.347]
 [0.689]
 [0.642]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 88.45265847843005
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 33.41956736949704
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.57283020019531
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.40156650543213
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.142]
 [46.142]
 [46.142]
 [52.064]
 [46.142]] [[0.336]
 [0.336]
 [0.336]
 [0.415]
 [0.336]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
printing an ep nov before normalisation:  19.363829067775182
printing an ep nov before normalisation:  40.83296345520956
printing an ep nov before normalisation:  77.77357258191964
printing an ep nov before normalisation:  41.47165716556567
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.987]
 [25.616]
 [20.987]
 [20.987]
 [20.987]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.739457006989706
printing an ep nov before normalisation:  38.52122561239494
printing an ep nov before normalisation:  0.14779690663999645
printing an ep nov before normalisation:  22.282081367099998
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.316608108867925
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.22753720234408
siam score:  -0.91248477
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  82.55820390337249
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
line 256 mcts: sample exp_bonus 31.804892069147193
printing an ep nov before normalisation:  53.78582099183217
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.812]
 [23.812]
 [53.869]
 [23.812]
 [23.812]] [[0.066]
 [0.066]
 [0.202]
 [0.066]
 [0.066]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0035,     0.9388,     0.0008,     0.0015,     0.0555],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0011, 0.0024, 0.9219, 0.0310, 0.0435], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0019, 0.0010, 0.0333, 0.7909, 0.1728], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0013, 0.0011, 0.1423, 0.3339, 0.5214], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.9761544331437
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.692256544568444
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.923]
 [58.923]
 [63.728]
 [58.923]
 [58.923]] [[1.583]
 [1.583]
 [1.787]
 [1.583]
 [1.583]]
siam score:  -0.91689837
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.90547670000478
printing an ep nov before normalisation:  71.11874417137783
printing an ep nov before normalisation:  87.31465295887818
printing an ep nov before normalisation:  52.06370638717803
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 55.17171898174586
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.795181857484856
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.692]
 [68.692]
 [68.692]
 [68.174]
 [68.692]] [[0.229]
 [0.229]
 [0.229]
 [0.226]
 [0.229]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.30040461802831
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.43691838695459
printing an ep nov before normalisation:  49.80318101016634
printing an ep nov before normalisation:  40.204763412475586
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.51459205161884
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.00424575805664
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.989708476819715
printing an ep nov before normalisation:  84.58167539145238
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0015, 0.9455, 0.0010, 0.0114, 0.0407], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0004,     0.9447,     0.0355,     0.0194],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0058, 0.0013, 0.0223, 0.8160, 0.1546], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0256, 0.0572, 0.0041, 0.5292, 0.3839], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0023,     0.9951,     0.0004,     0.0000,     0.0022],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9295,     0.0481,     0.0224],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0413,     0.0002,     0.0493,     0.7072,     0.2020],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0012, 0.0017, 0.2358, 0.4061, 0.3552], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 41.36244297027588
printing an ep nov before normalisation:  74.79888474925326
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9083029
line 256 mcts: sample exp_bonus 42.73888385299384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91157496
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.912686
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.189]
 [68.189]
 [68.189]
 [81.879]
 [68.189]] [[0.978]
 [0.978]
 [0.978]
 [1.223]
 [0.978]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.094]
 [41.783]
 [36.07 ]
 [55.55 ]
 [29.713]] [[0.298]
 [0.496]
 [0.391]
 [0.752]
 [0.273]]
printing an ep nov before normalisation:  65.08965499090193
using explorer policy with actor:  1
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[     0.0000],
        [     0.0000],
        [     0.0000],
        [    -0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000]], dtype=torch.float64)
0.0 8.389727995043863e-12
0.0 7.80158211546349e-12
0.0 0.0
0.0 -1.4098202683552187e-12
0.0 7.520482983071008e-12
0.0 7.36912190874656e-12
0.0 6.197154749937225e-12
0.0 3.0358706451034026e-12
0.0 5.27601451300529e-12
0.0 8.523790659303325e-12
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9907,     0.0000,     0.0000,     0.0054,     0.0039],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9975,     0.0002,     0.0000,     0.0023],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0004,     0.9134,     0.0483,     0.0378],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0002,     0.0409,     0.8024,     0.1563],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0016, 0.0168, 0.0053, 0.4521, 0.5242], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.50000770000627
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.650708711509715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.60110920527924
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.524]
 [40.524]
 [46.886]
 [43.434]
 [40.524]] [[1.068]
 [1.068]
 [1.387]
 [1.214]
 [1.068]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.32719620723518
printing an ep nov before normalisation:  44.94971285982048
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.217]
 [29.83 ]
 [38.098]
 [27.477]
 [25.581]] [[0.794]
 [0.734]
 [1.095]
 [0.631]
 [0.548]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.51057916748842
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.04941429228123
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.975]
 [20.833]
 [20.975]
 [27.616]
 [20.975]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.173]
 [47.173]
 [47.173]
 [50.805]
 [47.173]] [[0.917]
 [0.917]
 [0.917]
 [1.035]
 [0.917]]
printing an ep nov before normalisation:  36.39835139346635
actions average: 
K:  3  action  0 :  tensor([    0.9967,     0.0000,     0.0000,     0.0021,     0.0011],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9976,     0.0000,     0.0002,     0.0021],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9762,     0.0105,     0.0132],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0001,     0.0325,     0.8192,     0.1480],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0024, 0.0063, 0.2500, 0.2197, 0.5216], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.147]
 [29.147]
 [42.541]
 [30.837]
 [29.147]] [[0.638]
 [0.638]
 [1.196]
 [0.708]
 [0.638]]
printing an ep nov before normalisation:  62.24106832518306
actions average: 
K:  2  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9693,     0.0198,     0.0108],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0011,     0.0002,     0.0697,     0.7398,     0.1892],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0041, 0.0801, 0.0502, 0.5066, 0.3590], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.787]
 [35.694]
 [35.694]
 [51.101]
 [35.694]] [[0.595]
 [0.535]
 [0.535]
 [0.976]
 [0.535]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.24034212865829
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.33784580230713
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.029]
 [29.69 ]
 [34.975]
 [54.388]
 [28.222]] [[0.139]
 [0.187]
 [0.257]
 [0.514]
 [0.168]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.37601209659422
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.334]
 [51.334]
 [35.283]
 [51.334]
 [51.334]] [[0.792]
 [0.792]
 [0.502]
 [0.792]
 [0.792]]
printing an ep nov before normalisation:  23.631849309180463
printing an ep nov before normalisation:  85.24940441641608
siam score:  -0.9074211
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9069168
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.458]
 [29.583]
 [29.194]
 [29.731]
 [29.194]] [[0.613]
 [0.334]
 [0.326]
 [0.337]
 [0.326]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.740685339477686
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9941,     0.0016,     0.0000,     0.0007,     0.0036],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9981,     0.0007,     0.0000,     0.0012],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9228,     0.0348,     0.0423],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0002,     0.0010,     0.8242,     0.1740],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0002,     0.0012,     0.0130,     0.5425,     0.4431],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.10345413093795
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  95.535464030978
printing an ep nov before normalisation:  102.94615487188003
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.66990288817962
siam score:  -0.91379267
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.47681194858304
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0002,     0.9576,     0.0157,     0.0264],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0062,     0.0003,     0.0061,     0.8401,     0.1473],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0172, 0.0032, 0.1080, 0.4097, 0.4618], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9961,     0.0005,     0.0000,     0.0012,     0.0022],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9990,     0.0003,     0.0000,     0.0007],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0001,     0.9351,     0.0444,     0.0203],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0011,     0.0905,     0.7187,     0.1894],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0008, 0.0051, 0.1393, 0.3913, 0.4635], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.483]
 [42.483]
 [42.483]
 [59.018]
 [42.483]] [[0.639]
 [0.639]
 [0.639]
 [1.07 ]
 [0.639]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.92280357356688
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.338]
 [43.338]
 [42.971]
 [65.098]
 [43.338]] [[0.484]
 [0.484]
 [0.478]
 [0.886]
 [0.484]]
printing an ep nov before normalisation:  92.45352595564484
printing an ep nov before normalisation:  77.81188658206311
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.936]
 [77.936]
 [77.936]
 [77.936]
 [77.936]] [[1.028]
 [1.028]
 [1.028]
 [1.028]
 [1.028]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.22872620503955
printing an ep nov before normalisation:  81.59158039383583
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.386]
 [28.966]
 [38.785]
 [65.31 ]
 [20.487]] [[0.394]
 [0.176]
 [0.299]
 [0.63 ]
 [0.071]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.97924358314428
printing an ep nov before normalisation:  78.76609212563416
printing an ep nov before normalisation:  77.92983527319112
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.91218305
line 256 mcts: sample exp_bonus 89.77722475700887
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.03255427313795
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.0719565711731
printing an ep nov before normalisation:  63.8938183924291
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.982036113739014
using explorer policy with actor:  1
printing an ep nov before normalisation:  77.86851459079318
line 256 mcts: sample exp_bonus 75.4605102696714
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.123]
 [39.123]
 [50.783]
 [39.123]
 [39.123]] [[0.518]
 [0.518]
 [0.928]
 [0.518]
 [0.518]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.35268248392786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.79193289711918
printing an ep nov before normalisation:  48.92636411194644
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.4141844197443
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.76203759648615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.90565623529868
printing an ep nov before normalisation:  35.73716980483043
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  86.65308204408903
printing an ep nov before normalisation:  24.889004230499268
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.53394714780231
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.962]
 [37.141]
 [34.617]
 [46.703]
 [33.438]] [[0.412]
 [0.396]
 [0.347]
 [0.58 ]
 [0.324]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.09160740850963
printing an ep nov before normalisation:  21.678853034973145
printing an ep nov before normalisation:  32.23912053095162
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.46]
 [77.46]
 [82.87]
 [77.46]
 [77.46]] [[1.135]
 [1.135]
 [1.228]
 [1.135]
 [1.135]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.0750644530971
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.198287694824327
printing an ep nov before normalisation:  66.14261605014437
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  80.98908929523117
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.177]
 [82.177]
 [86.941]
 [90.712]
 [82.177]] [[1.438]
 [1.438]
 [1.533]
 [1.608]
 [1.438]]
printing an ep nov before normalisation:  58.5226479312037
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.419]
 [50.419]
 [63.828]
 [64.101]
 [50.419]] [[0.75 ]
 [0.75 ]
 [1.043]
 [1.049]
 [0.75 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.31361124239831
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.113]
 [39.113]
 [39.113]
 [39.113]
 [39.113]] [[0.592]
 [0.592]
 [0.592]
 [0.592]
 [0.592]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.64298237169383
printing an ep nov before normalisation:  67.82201936405491
printing an ep nov before normalisation:  28.59818935394287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  46.820915748686744
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.824]
 [61.045]
 [76.85 ]
 [77.624]
 [58.014]] [[0.891]
 [0.92 ]
 [1.294]
 [1.313]
 [0.848]]
siam score:  -0.9148987
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.819]
 [55.819]
 [63.105]
 [55.819]
 [55.819]] [[1.35 ]
 [1.35 ]
 [1.602]
 [1.35 ]
 [1.35 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.057]
 [79.057]
 [73.161]
 [84.636]
 [79.057]] [[1.45 ]
 [1.45 ]
 [1.313]
 [1.58 ]
 [1.45 ]]
line 256 mcts: sample exp_bonus 68.05680706412518
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.44779143561941
printing an ep nov before normalisation:  28.848981857299805
printing an ep nov before normalisation:  67.31822565525431
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9045494
printing an ep nov before normalisation:  49.55833334584129
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.24306322509937
printing an ep nov before normalisation:  68.91994585802688
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.29537524966892
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.66282867689678
line 256 mcts: sample exp_bonus 57.16233350982252
printing an ep nov before normalisation:  38.85325353308047
printing an ep nov before normalisation:  61.72856033075374
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.725934585180006
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 44.70871328517542
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  64.99098319970446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9433,     0.0001,     0.0000,     0.0143,     0.0424],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9425,     0.0074,     0.0006,     0.0494],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0001,     0.9190,     0.0546,     0.0262],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0010,     0.0223,     0.7570,     0.2195],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0006, 0.0034, 0.0835, 0.4578, 0.4547], grad_fn=<DivBackward0>)
siam score:  -0.91840315
printing an ep nov before normalisation:  85.96064979060566
printing an ep nov before normalisation:  65.07451533283991
printing an ep nov before normalisation:  86.93025771270129
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.980454372811
printing an ep nov before normalisation:  74.02056388815177
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.233701723220214
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.36316435677665
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.70173955252375
siam score:  -0.9185839
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  84.07644921728341
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.159]
 [41.267]
 [41.267]
 [44.246]
 [41.267]] [[1.172]
 [0.996]
 [0.996]
 [1.103]
 [0.996]]
printing an ep nov before normalisation:  41.30320898883256
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.605]
 [59.605]
 [63.571]
 [73.704]
 [59.605]] [[0.905]
 [0.905]
 [0.977]
 [1.163]
 [0.905]]
printing an ep nov before normalisation:  45.68373154893063
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.02242779773131
printing an ep nov before normalisation:  65.53484128265778
printing an ep nov before normalisation:  51.2239933013916
siam score:  -0.9193933
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  67.40933761572869
main train batch thing paused
add a thread
Adding thread: now have 2 threads
printing an ep nov before normalisation:  44.96271814958557
using explorer policy with actor:  1
printing an ep nov before normalisation:  48.780817710354654
printing an ep nov before normalisation:  72.66099369524169
siam score:  -0.9222752
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.37276702158448
printing an ep nov before normalisation:  41.919097900390625
printing an ep nov before normalisation:  2.520140286576691
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.628]
 [30.857]
 [31.097]
 [26.041]
 [35.628]] [[0.425]
 [0.328]
 [0.333]
 [0.231]
 [0.425]]
printing an ep nov before normalisation:  33.72577652005103
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.46151335467397
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.654149532318115
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.053168296813965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.27441194538062
line 256 mcts: sample exp_bonus 75.14928138510288
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.855]
 [46.855]
 [46.855]
 [46.855]
 [46.855]] [[0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  67.0357851464409
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.181]
 [29.181]
 [47.648]
 [29.181]
 [29.181]] [[0.374]
 [0.374]
 [0.824]
 [0.374]
 [0.374]]
printing an ep nov before normalisation:  59.00844702222424
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.4238006745191
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.355]
 [70.355]
 [81.599]
 [82.699]
 [70.355]] [[1.039]
 [1.039]
 [1.242]
 [1.262]
 [1.039]]
actions average: 
K:  3  action  0 :  tensor([    0.9556,     0.0005,     0.0000,     0.0267,     0.0172],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9996,     0.0001,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0003,     0.8780,     0.0624,     0.0592],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0006,     0.0009,     0.0205,     0.8014,     0.1766],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0030, 0.0020, 0.0983, 0.5115, 0.3852], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.74402952194214
printing an ep nov before normalisation:  57.773582783755884
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.32598391481645
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.452]
 [55.452]
 [62.146]
 [55.452]
 [55.452]] [[1.289]
 [1.289]
 [1.512]
 [1.289]
 [1.289]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.994]
 [41.994]
 [66.731]
 [68.93 ]
 [41.994]] [[0.606]
 [0.606]
 [1.245]
 [1.301]
 [0.606]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.891]
 [41.891]
 [52.826]
 [41.891]
 [41.891]] [[0.985]
 [0.985]
 [1.455]
 [0.985]
 [0.985]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.872]
 [34.638]
 [33.652]
 [33.769]
 [32.96 ]] [[0.941]
 [1.182]
 [1.119]
 [1.126]
 [1.074]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.24989414215088
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.171]
 [30.67 ]
 [53.299]
 [37.378]
 [30.69 ]] [[0.335]
 [0.265]
 [0.712]
 [0.398]
 [0.266]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91736484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.163246855962825
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  33.355871836344406
actions average: 
K:  4  action  0 :  tensor([    0.9256,     0.0007,     0.0000,     0.0563,     0.0174],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9990,     0.0001,     0.0000,     0.0009],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9448,     0.0387,     0.0165],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0000,     0.0002,     0.0539,     0.8186,     0.1273],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0001,     0.0027,     0.1239,     0.4349,     0.4385],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  48.77691327776696
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.219664345505635
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  78.95810214384525
printing an ep nov before normalisation:  18.378066262588668
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.011]
 [0.011]
 [0.016]
 [0.011]
 [0.011]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
line 256 mcts: sample exp_bonus 75.64698333675885
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.193]
 [37.059]
 [53.76 ]
 [68.775]
 [39.103]] [[0.244]
 [0.17 ]
 [0.323]
 [0.461]
 [0.189]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.222]
 [29.327]
 [29.327]
 [38.841]
 [29.327]] [[0.329]
 [0.14 ]
 [0.14 ]
 [0.226]
 [0.14 ]]
siam score:  -0.91432357
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9557,     0.0002,     0.0000,     0.0325,     0.0116],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9992,     0.0002,     0.0000,     0.0006],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9631,     0.0348,     0.0020],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0004,     0.0237,     0.8283,     0.1475],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0005,     0.0416,     0.0109,     0.6081,     0.3390],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  34.476395200793995
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 15.187300075911251
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.225993806113145
printing an ep nov before normalisation:  44.86518940353337
printing an ep nov before normalisation:  1.3420378763839835e-05
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.327]
 [43.857]
 [66.075]
 [36.027]
 [34.021]] [[0.219]
 [0.449]
 [0.776]
 [0.333]
 [0.303]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.35607072158308
printing an ep nov before normalisation:  29.562814153651185
printing an ep nov before normalisation:  71.14051919355916
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.521]
 [82.521]
 [91.199]
 [88.515]
 [82.521]] [[1.106]
 [1.106]
 [1.254]
 [1.209]
 [1.106]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.235147537406164
printing an ep nov before normalisation:  29.69505786895752
siam score:  -0.92435753
printing an ep nov before normalisation:  92.49325743941698
siam score:  -0.9234096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.90360940888912
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.134781719192
siam score:  -0.9242537
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.69]
 [28.69]
 [28.69]
 [28.69]
 [28.69]] [[0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]]
printing an ep nov before normalisation:  73.39017642806517
printing an ep nov before normalisation:  40.539135389946786
printing an ep nov before normalisation:  38.71235804101952
line 256 mcts: sample exp_bonus 64.26219099108313
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92227393
printing an ep nov before normalisation:  48.17309054140529
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.44960534897044
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.97581162465028
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.24467155908673
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.06536054611206
printing an ep nov before normalisation:  60.113205176290556
printing an ep nov before normalisation:  40.52378813635757
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9111904
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.257]
 [36.257]
 [57.037]
 [41.793]
 [36.257]] [[0.458]
 [0.458]
 [0.974]
 [0.595]
 [0.458]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.7310535591665
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.295019694599304
printing an ep nov before normalisation:  27.469749450683594
printing an ep nov before normalisation:  0.006854241602241018
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.8958789832455
siam score:  -0.9111388
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.03244078794614
printing an ep nov before normalisation:  59.43293680723782
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  76.4484520128457
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.67167622189633
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.42 ]
 [32.42 ]
 [32.42 ]
 [49.875]
 [32.42 ]] [[0.685]
 [0.685]
 [0.685]
 [1.387]
 [0.685]]
printing an ep nov before normalisation:  80.34437532852343
siam score:  -0.92281663
actions average: 
K:  3  action  0 :  tensor([    0.9883,     0.0000,     0.0000,     0.0078,     0.0039],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9996,     0.0001,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0003,     0.8595,     0.0797,     0.0605],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0000,     0.0001,     0.0335,     0.7479,     0.2185],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0001,     0.0002,     0.0615,     0.4429,     0.4952],
       grad_fn=<DivBackward0>)
actions average: 
K:  0  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0025,     0.9600,     0.0010,     0.0006,     0.0359],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9506,     0.0315,     0.0178],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0026,     0.0007,     0.0325,     0.7751,     0.1891],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0162, 0.0020, 0.0684, 0.4960, 0.4175], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.901]
 [77.901]
 [83.482]
 [85.385]
 [77.901]] [[1.323]
 [1.323]
 [1.453]
 [1.498]
 [1.323]]
printing an ep nov before normalisation:  20.447044372558594
actions average: 
K:  0  action  0 :  tensor([    0.9961,     0.0000,     0.0000,     0.0032,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0079, 0.9618, 0.0119, 0.0034, 0.0150], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9483,     0.0343,     0.0173],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0010,     0.0541,     0.8209,     0.1239],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0001,     0.0001,     0.0027,     0.5796,     0.4174],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  88.57274220758481
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.03448366452118
printing an ep nov before normalisation:  86.87965117273765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  34.76804521982654
siam score:  -0.9202647
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.27766513824463
siam score:  -0.9183229
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  18.32168698310852
printing an ep nov before normalisation:  29.4160904382891
printing an ep nov before normalisation:  51.14770661294456
printing an ep nov before normalisation:  47.08192791011196
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.09333096935981
printing an ep nov before normalisation:  42.692015452840366
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.762870599065433
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]] [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.80016474696474
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.431]
 [23.276]
 [31.082]
 [23.276]
 [23.276]] [[0.423]
 [0.499]
 [0.817]
 [0.499]
 [0.499]]
printing an ep nov before normalisation:  26.83797597885132
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 89.08661356008459
printing an ep nov before normalisation:  34.68090248587774
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9993,     0.0000,     0.0000,     0.0005,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0009,     0.9946,     0.0001,     0.0001,     0.0042],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9327,     0.0472,     0.0200],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0182, 0.0008, 0.0585, 0.7411, 0.1814], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0084, 0.0010, 0.0647, 0.4842, 0.4417], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.61378203215094
actions average: 
K:  0  action  0 :  tensor([    0.9986,     0.0000,     0.0000,     0.0004,     0.0009],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9634,     0.0238,     0.0128],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0014, 0.0011, 0.0394, 0.7948, 0.1632], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0158, 0.0012, 0.0048, 0.2254, 0.7528], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  89.69843777443309
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  91.68615774986768
siam score:  -0.9229156
printing an ep nov before normalisation:  64.0069881497991
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.684]
 [33.06 ]
 [46.438]
 [39.374]
 [34.361]] [[0.66 ]
 [0.479]
 [0.845]
 [0.652]
 [0.515]]
printing an ep nov before normalisation:  0.011968255104193304
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.8217738143778
printing an ep nov before normalisation:  43.829709315700285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.715]
 [32.59 ]
 [36.791]
 [61.335]
 [33.768]] [[0.346]
 [0.252]
 [0.317]
 [0.691]
 [0.27 ]]
printing an ep nov before normalisation:  22.070529460906982
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 88.72979831378952
using explorer policy with actor:  1
printing an ep nov before normalisation:  103.70560631804852
printing an ep nov before normalisation:  27.44772434234619
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.371]
 [64.371]
 [62.347]
 [67.719]
 [64.371]] [[1.241]
 [1.241]
 [1.186]
 [1.333]
 [1.241]]
printing an ep nov before normalisation:  65.75943149033078
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.551]
 [49.551]
 [48.848]
 [70.853]
 [49.551]] [[0.514]
 [0.514]
 [0.501]
 [0.918]
 [0.514]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.573695781705897
printing an ep nov before normalisation:  86.81637421022901
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.743]
 [47.352]
 [52.897]
 [64.866]
 [50.743]] [[0.66 ]
 [0.592]
 [0.704]
 [0.946]
 [0.66 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.892222802651474
UNIT TEST: sample policy line 217 mcts : [0.385 0.051 0.128 0.385 0.051]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9253531
printing an ep nov before normalisation:  40.59120707800979
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.02031807648484
printing an ep nov before normalisation:  45.612734219945494
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  91.58101532896623
siam score:  -0.9247944
printing an ep nov before normalisation:  32.01549572347646
printing an ep nov before normalisation:  41.53535904898682
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.2985045011078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 47.535421748914125
printing an ep nov before normalisation:  46.65729600286049
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.42948115941536
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.45000829171933
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.869]
 [29.192]
 [37.428]
 [42.353]
 [24.481]] [[0.159]
 [0.217]
 [0.307]
 [0.36 ]
 [0.166]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.268]
 [40.268]
 [40.268]
 [71.727]
 [40.268]] [[0.59 ]
 [0.59 ]
 [0.59 ]
 [1.296]
 [0.59 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.148]
 [33.148]
 [33.148]
 [33.148]
 [33.148]] [[0.16]
 [0.16]
 [0.16]
 [0.16]
 [0.16]]
siam score:  -0.92368585
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.856]
 [54.856]
 [61.185]
 [54.856]
 [54.856]] [[1.271]
 [1.271]
 [1.491]
 [1.271]
 [1.271]]
printing an ep nov before normalisation:  86.23876112856072
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92404556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9257509
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.4566252180372
siam score:  -0.9273741
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9266641
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.219]
 [50.219]
 [50.219]
 [50.219]
 [50.219]] [[1.631]
 [1.631]
 [1.631]
 [1.631]
 [1.631]]
actions average: 
K:  1  action  0 :  tensor([    0.9946,     0.0001,     0.0000,     0.0038,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9638,     0.0010,     0.0118,     0.0233],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0164, 0.0076, 0.8778, 0.0580, 0.0401], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0014,     0.0005,     0.0091,     0.8469,     0.1420],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0018, 0.0021, 0.1076, 0.5682, 0.3203], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.116147394774124
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.812]
 [36.812]
 [36.812]
 [36.812]
 [36.812]] [[1.4]
 [1.4]
 [1.4]
 [1.4]
 [1.4]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.972]
 [28.166]
 [34.664]
 [61.516]
 [28.166]] [[0.217]
 [0.116]
 [0.167]
 [0.378]
 [0.116]]
siam score:  -0.92698306
printing an ep nov before normalisation:  71.10113489203749
printing an ep nov before normalisation:  66.06787356999747
printing an ep nov before normalisation:  38.250179290771484
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.815]
 [44.815]
 [72.898]
 [75.573]
 [44.815]] [[0.362]
 [0.362]
 [0.756]
 [0.793]
 [0.362]]
printing an ep nov before normalisation:  37.54992623273327
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[3.038]
 [3.136]
 [1.989]
 [2.534]
 [2.69 ]] [[0.078]
 [0.081]
 [0.05 ]
 [0.065]
 [0.069]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  85.34453792961827
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.539]
 [30.539]
 [57.365]
 [30.539]
 [30.539]] [[0.653]
 [0.653]
 [1.442]
 [0.653]
 [0.653]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
siam score:  -0.91552794
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  26.331868971904488
printing an ep nov before normalisation:  26.997890574793473
printing an ep nov before normalisation:  35.1680642776338
printing an ep nov before normalisation:  47.434713278977966
line 256 mcts: sample exp_bonus 84.52846470468045
printing an ep nov before normalisation:  23.05424213409424
printing an ep nov before normalisation:  43.5389518737793
printing an ep nov before normalisation:  95.44761687568682
printing an ep nov before normalisation:  47.84892929924859
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 70.88253101435924
printing an ep nov before normalisation:  68.87522887128769
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.482]
 [27.929]
 [45.846]
 [31.263]
 [29.144]] [[0.619]
 [0.408]
 [0.985]
 [0.515]
 [0.447]]
printing an ep nov before normalisation:  100.79793725148053
printing an ep nov before normalisation:  85.11595127744916
printing an ep nov before normalisation:  47.79017879022896
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.167]
 [29.749]
 [32.065]
 [29.316]
 [29.147]] [[1.583]
 [1.752]
 [2.   ]
 [1.706]
 [1.688]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  89.55523855622197
actions average: 
K:  0  action  0 :  tensor([    0.9977,     0.0000,     0.0000,     0.0007,     0.0015],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9977,     0.0000,     0.0001,     0.0022],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9743,     0.0203,     0.0053],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0002,     0.0188,     0.8301,     0.1506],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0094, 0.0021, 0.0263, 0.4654, 0.4969], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.258735106566775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.78168625528753
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 43.73787035427408
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.341]
 [21.385]
 [29.352]
 [64.642]
 [20.434]] [[0.252]
 [0.129]
 [0.218]
 [0.615]
 [0.118]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.99284825043011
printing an ep nov before normalisation:  85.18812703780979
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.4856269411577
siam score:  -0.9256929
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  92.42924128611538
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.394]
 [55.394]
 [55.394]
 [85.351]
 [55.394]] [[0.626]
 [0.626]
 [0.626]
 [1.065]
 [0.626]]
printing an ep nov before normalisation:  56.8251070567728
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.333]
 [43.123]
 [43.123]
 [40.276]
 [43.123]] [[0.554]
 [0.307]
 [0.307]
 [0.274]
 [0.307]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.398]
 [63.398]
 [63.398]
 [74.057]
 [63.398]] [[0.805]
 [0.805]
 [0.805]
 [0.978]
 [0.805]]
printing an ep nov before normalisation:  76.18038256682006
printing an ep nov before normalisation:  43.8251199372937
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.553056716918945
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9244571
printing an ep nov before normalisation:  43.83221295333363
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.846]
 [48.846]
 [48.846]
 [43.554]
 [48.846]] [[0.213]
 [0.213]
 [0.213]
 [0.173]
 [0.213]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.703]
 [55.703]
 [55.703]
 [55.703]
 [55.703]] [[1.09]
 [1.09]
 [1.09]
 [1.09]
 [1.09]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9133741
printing an ep nov before normalisation:  36.6535666522768
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.810837745666504
printing an ep nov before normalisation:  12.656139066378127
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.314372062683105
printing an ep nov before normalisation:  28.765346424003827
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  17.701808431873047
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.589]
 [58.523]
 [50.204]
 [58.49 ]
 [56.652]] [[0.226]
 [0.181]
 [0.134]
 [0.181]
 [0.17 ]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.882]
 [34.883]
 [31.477]
 [44.838]
 [36.327]] [[0.223]
 [0.126]
 [0.098]
 [0.206]
 [0.138]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.74375520726271
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.401]
 [32.552]
 [26.189]
 [37.877]
 [36.633]] [[0.223]
 [0.123]
 [0.073]
 [0.164]
 [0.155]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.73413515760109
siam score:  -0.91821826
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.31781836947093
printing an ep nov before normalisation:  27.204289436340332
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  91.10884286845123
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.156]
 [29.156]
 [29.156]
 [67.761]
 [29.156]] [[0.176]
 [0.176]
 [0.176]
 [0.658]
 [0.176]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.66584421148215
UNIT TEST: sample policy line 217 mcts : [0.821 0.051 0.051 0.051 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.139036628481072
using explorer policy with actor:  1
using explorer policy with actor:  1
siam score:  -0.9168535
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.982598268610015
siam score:  -0.91630524
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.20143258306723
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  109.33967949180217
printing an ep nov before normalisation:  45.87229139378217
printing an ep nov before normalisation:  48.33129337275503
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.605]
 [26.111]
 [42.861]
 [27.843]
 [28.719]] [[0.255]
 [0.196]
 [0.476]
 [0.225]
 [0.24 ]]
printing an ep nov before normalisation:  22.8067946434021
printing an ep nov before normalisation:  42.281203991955344
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.383]
 [35.98 ]
 [38.677]
 [66.221]
 [46.413]] [[0.262]
 [0.332]
 [0.374]
 [0.797]
 [0.493]]
printing an ep nov before normalisation:  36.84309836867958
printing an ep nov before normalisation:  100.83447785713409
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.439]
 [30.756]
 [36.696]
 [49.711]
 [32.834]] [[0.229]
 [0.192]
 [0.273]
 [0.45 ]
 [0.221]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.43596701074997
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.115]
 [32.95 ]
 [30.044]
 [32.197]
 [30.006]] [[0.733]
 [0.691]
 [0.586]
 [0.663]
 [0.584]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.8782,     0.0001,     0.0000,     0.1049,     0.0169],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0046,     0.9784,     0.0002,     0.0001,     0.0167],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0003,     0.9358,     0.0334,     0.0304],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0006,     0.0006,     0.0359,     0.8412,     0.1217],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0787, 0.0185, 0.0119, 0.5511, 0.3397], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.524607840024416
printing an ep nov before normalisation:  34.330607572118566
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.942583084106445
printing an ep nov before normalisation:  24.853909015655518
printing an ep nov before normalisation:  49.48336520132379
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.499]
 [22.69 ]
 [19.246]
 [22.004]
 [20.76 ]] [[0.607]
 [0.275]
 [0.203]
 [0.261]
 [0.235]]
printing an ep nov before normalisation:  26.122748693041828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.235]
 [41.235]
 [41.235]
 [74.046]
 [41.235]] [[0.247]
 [0.247]
 [0.247]
 [0.737]
 [0.247]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.774]
 [53.774]
 [53.774]
 [80.41 ]
 [53.774]] [[0.52 ]
 [0.52 ]
 [0.52 ]
 [0.852]
 [0.52 ]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.54864424641125
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.76029698162018
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  88.4641017942618
printing an ep nov before normalisation:  74.85595301769177
printing an ep nov before normalisation:  54.264558027982204
actions average: 
K:  1  action  0 :  tensor([    0.9991,     0.0000,     0.0000,     0.0005,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0008,     0.9766,     0.0089,     0.0005,     0.0131],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0002,     0.8939,     0.0785,     0.0273],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0078, 0.0052, 0.0521, 0.8303, 0.1045], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0015, 0.0011, 0.0306, 0.3994, 0.5676], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  93.82101108581809
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.297]
 [28.297]
 [67.405]
 [28.297]
 [28.297]] [[0.373]
 [0.373]
 [1.304]
 [0.373]
 [0.373]]
printing an ep nov before normalisation:  99.59020632458024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.43033277011033
printing an ep nov before normalisation:  80.93923750042477
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.83491897583008
printing an ep nov before normalisation:  34.85170125961304
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  99.64917515612699
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.942]
 [36.598]
 [23.974]
 [69.327]
 [32.789]] [[0.332]
 [0.246]
 [0.098]
 [0.629]
 [0.202]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0008,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9978,     0.0007,     0.0000,     0.0015],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9249,     0.0545,     0.0204],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0015,     0.0001,     0.0007,     0.8828,     0.1149],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0076, 0.0298, 0.0479, 0.4405, 0.4742], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.31091401763165
line 256 mcts: sample exp_bonus 67.30976650502771
printing an ep nov before normalisation:  82.69326171275964
printing an ep nov before normalisation:  96.95121386072033
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.52455171421429
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.84]
 [61.84]
 [61.84]
 [93.05]
 [61.84]] [[0.709]
 [0.709]
 [0.709]
 [1.176]
 [0.709]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[80.287]
 [80.287]
 [80.287]
 [80.287]
 [80.287]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.441383210311205
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.522149970756058
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  79.30372940367911
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.58288602134356
printing an ep nov before normalisation:  23.244986534118652
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  87.8147230588928
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.92317026112872
printing an ep nov before normalisation:  91.08920412149247
printing an ep nov before normalisation:  73.35393152524648
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  85.90408020100035
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.75095362111155
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.961546633813185
actions average: 
K:  1  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9985,     0.0005,     0.0000,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9067,     0.0776,     0.0157],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0002,     0.0242,     0.8501,     0.1254],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0031, 0.0446, 0.0850, 0.5654, 0.3019], grad_fn=<DivBackward0>)
siam score:  -0.9235173
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  97.96102807565902
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[96.209]
 [96.209]
 [96.209]
 [97.877]
 [96.209]] [[0.981]
 [0.981]
 [0.981]
 [1.   ]
 [0.981]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.048]
 [31.319]
 [40.734]
 [30.656]
 [30.673]] [[0.157]
 [0.263]
 [0.451]
 [0.249]
 [0.25 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.32 ]
 [34.676]
 [35.714]
 [63.535]
 [30.948]] [[0.294]
 [0.23 ]
 [0.242]
 [0.556]
 [0.188]]
printing an ep nov before normalisation:  57.616361265883434
using explorer policy with actor:  1
printing an ep nov before normalisation:  104.75806067474886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  97.7553685999259
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.729]
 [51.124]
 [65.677]
 [35.923]
 [27.285]] [[0.064]
 [0.276]
 [0.402]
 [0.144]
 [0.069]]
siam score:  -0.9192783
printing an ep nov before normalisation:  57.84080311382676
printing an ep nov before normalisation:  52.42423359010302
printing an ep nov before normalisation:  66.7995047036996
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.643]
 [51.643]
 [51.643]
 [51.643]
 [51.643]] [[0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]]
printing an ep nov before normalisation:  33.65695042291584
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.016]
 [33.016]
 [33.016]
 [57.311]
 [33.016]] [[0.447]
 [0.447]
 [0.447]
 [1.   ]
 [0.447]]
printing an ep nov before normalisation:  42.142704006835686
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[96.861]
 [96.861]
 [96.861]
 [96.861]
 [96.861]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  101.9482800670924
printing an ep nov before normalisation:  80.45901167930579
printing an ep nov before normalisation:  24.389348030090332
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.77]
 [30.89]
 [30.89]
 [30.89]
 [30.89]] [[0.424]
 [0.233]
 [0.233]
 [0.233]
 [0.233]]
printing an ep nov before normalisation:  104.16438414823723
printing an ep nov before normalisation:  52.43210225495132
printing an ep nov before normalisation:  33.71168991393501
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.21898208708
actions average: 
K:  4  action  0 :  tensor([    0.9993,     0.0000,     0.0000,     0.0002,     0.0004],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9980,     0.0002,     0.0001,     0.0017],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9777,     0.0157,     0.0064],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0301, 0.0031, 0.0284, 0.7994, 0.1390], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0002,     0.0110,     0.0748,     0.5828,     0.3313],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  94.74571821650294
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.888]
 [35.888]
 [35.888]
 [42.056]
 [35.888]] [[1.044]
 [1.044]
 [1.044]
 [1.333]
 [1.044]]
actions average: 
K:  2  action  0 :  tensor([0.9569, 0.0046, 0.0049, 0.0248, 0.0088], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9995,     0.0002,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0005,     0.9451,     0.0147,     0.0396],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0023,     0.0004,     0.0259,     0.8258,     0.1455],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0011, 0.0008, 0.0901, 0.6858, 0.2222], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.58952294431776
siam score:  -0.92266893
printing an ep nov before normalisation:  91.5580318399385
printing an ep nov before normalisation:  78.22225150331342
printing an ep nov before normalisation:  36.7934042989429
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.026 0.026 0.897 0.026 0.026]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.439]
 [45.439]
 [52.622]
 [63.046]
 [45.439]] [[0.958]
 [0.958]
 [1.172]
 [1.482]
 [0.958]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.685]
 [23.685]
 [62.277]
 [23.685]
 [23.685]] [[0.31 ]
 [0.31 ]
 [1.271]
 [0.31 ]
 [0.31 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.303]
 [32.285]
 [39.812]
 [63.053]
 [32.285]] [[0.475]
 [0.475]
 [0.681]
 [1.318]
 [0.475]]
actions average: 
K:  3  action  0 :  tensor([    0.9948,     0.0000,     0.0000,     0.0038,     0.0014],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0026,     0.9867,     0.0008,     0.0008,     0.0091],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9805,     0.0026,     0.0167],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0096,     0.0003,     0.0383,     0.8341,     0.1178],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0083, 0.0028, 0.0010, 0.6464, 0.3414], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  39.24786427562871
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.416784819799062
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.97818541487011
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
siam score:  -0.92097735
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9208809
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.772]
 [22.665]
 [31.791]
 [20.703]
 [21.511]] [[2.303]
 [0.779]
 [1.333]
 [0.66 ]
 [0.709]]
UNIT TEST: sample policy line 217 mcts : [0.128 0.077 0.282 0.436 0.077]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.548]
 [20.278]
 [31.041]
 [24.923]
 [26.042]] [[0.116]
 [0.109]
 [0.167]
 [0.134]
 [0.14 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9931,     0.0023,     0.0001,     0.0044],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9491,     0.0321,     0.0186],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0016,     0.0003,     0.0347,     0.8039,     0.1595],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0002,     0.0010,     0.2713,     0.3112,     0.4164],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0018,     0.9925,     0.0001,     0.0004,     0.0051],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0004,     0.0170,     0.9480,     0.0249,     0.0097],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0053,     0.0002,     0.0204,     0.8509,     0.1232],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0092, 0.0016, 0.1287, 0.5459, 0.3146], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  89.72691411852435
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.00114917755127
printing an ep nov before normalisation:  32.91372060775757
actions average: 
K:  4  action  0 :  tensor([    0.9930,     0.0000,     0.0000,     0.0040,     0.0030],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9932,     0.0002,     0.0000,     0.0064],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0002,     0.8844,     0.0776,     0.0377],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0001,     0.0184,     0.8303,     0.1509],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0010, 0.0026, 0.0337, 0.6637, 0.2990], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 61.267901693483104
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.41042690477983
printing an ep nov before normalisation:  64.4444972054066
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.586]
 [34.606]
 [34.606]
 [61.75 ]
 [34.606]] [[0.876]
 [0.455]
 [0.455]
 [1.057]
 [0.455]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.405]
 [39.369]
 [30.009]
 [51.717]
 [36.382]] [[0.501]
 [0.42 ]
 [0.231]
 [0.669]
 [0.36 ]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  97.24620972963186
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.824]
 [48.824]
 [48.824]
 [48.824]
 [48.824]] [[97.647]
 [97.647]
 [97.647]
 [97.647]
 [97.647]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.464]
 [30.9  ]
 [39.009]
 [28.843]
 [28.759]] [[0.441]
 [0.601]
 [0.892]
 [0.527]
 [0.524]]
line 256 mcts: sample exp_bonus 89.87509158664312
printing an ep nov before normalisation:  26.925246715545654
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.145]
 [14.211]
 [11.565]
 [11.968]
 [12.468]] [[0.457]
 [0.126]
 [0.087]
 [0.093]
 [0.1  ]]
printing an ep nov before normalisation:  98.65136592409769
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.495]
 [26.538]
 [39.009]
 [24.827]
 [25.292]] [[0.262]
 [0.387]
 [0.77 ]
 [0.334]
 [0.348]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.842]
 [54.361]
 [83.447]
 [90.224]
 [54.361]] [[1.086]
 [0.71 ]
 [1.244]
 [1.368]
 [0.71 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.266282021755664
printing an ep nov before normalisation:  30.42912244796753
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.58176920551979
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.669]
 [32.112]
 [33.497]
 [35.468]
 [30.676]] [[0.126]
 [0.084]
 [0.092]
 [0.103]
 [0.076]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.695646845240866
printing an ep nov before normalisation:  31.361455559457315
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.035226821899414
actions average: 
K:  3  action  0 :  tensor([    0.9976,     0.0000,     0.0000,     0.0018,     0.0007],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9945,     0.0000,     0.0000,     0.0051],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9714,     0.0221,     0.0065],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0004,     0.0008,     0.8618,     0.1367],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0003,     0.0047,     0.1050,     0.4904,     0.3997],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[108.123]
 [108.123]
 [108.123]
 [108.123]
 [108.123]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
printing an ep nov before normalisation:  97.97876060654215
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.47259260959656
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9991,     0.0002,     0.0001,     0.0004,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0014,     0.9960,     0.0001,     0.0000,     0.0025],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0002,     0.0014,     0.9184,     0.0469,     0.0330],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0003,     0.0257,     0.8478,     0.1259],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0015, 0.0007, 0.0454, 0.6429, 0.3095], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.99 ]
 [32.99 ]
 [32.99 ]
 [79.667]
 [32.99 ]] [[0.151]
 [0.151]
 [0.151]
 [0.524]
 [0.151]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.595]
 [30.478]
 [33.52 ]
 [31.005]
 [30.478]] [[0.298]
 [0.187]
 [0.221]
 [0.193]
 [0.187]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.98744613262404
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.58006079503443
printing an ep nov before normalisation:  46.103691839559026
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.14793292435937
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.15069656523110098
siam score:  -0.92241687
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.712070751413805
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9130,     0.0004,     0.0000,     0.0571,     0.0295],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.9146,     0.0513,     0.0338],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0005,     0.0549,     0.8130,     0.1313],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0004,     0.0032,     0.2266,     0.5429,     0.2270],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.921]
 [28.553]
 [30.944]
 [39.843]
 [30.881]] [[0.163]
 [0.118]
 [0.138]
 [0.213]
 [0.138]]
printing an ep nov before normalisation:  32.25916433403409
printing an ep nov before normalisation:  28.20533100928186
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  47.735780218451076
line 256 mcts: sample exp_bonus 79.45579279843503
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  78.20426847185324
printing an ep nov before normalisation:  87.12717684478966
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.482]
 [32.631]
 [26.797]
 [36.888]
 [27.408]] [[0.975]
 [0.755]
 [0.535]
 [0.915]
 [0.558]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.05456701579399
actions average: 
K:  4  action  0 :  tensor([    0.9986,     0.0000,     0.0000,     0.0011,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0019,     0.9914,     0.0001,     0.0006,     0.0061],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9486,     0.0368,     0.0144],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0006,     0.0647,     0.8033,     0.1310],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0040, 0.0843, 0.0989, 0.3527, 0.4601], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  79.24198012919241
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.57 ]
 [68.387]
 [74.117]
 [84.418]
 [50.894]] [[0.674]
 [0.618]
 [0.68 ]
 [0.791]
 [0.429]]
printing an ep nov before normalisation:  74.70800178163427
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.36 ]
 [44.759]
 [44.759]
 [44.759]
 [44.759]] [[0.806]
 [0.434]
 [0.434]
 [0.434]
 [0.434]]
actions average: 
K:  3  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0003,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0008,     0.9854,     0.0003,     0.0002,     0.0133],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0128, 0.0055, 0.9246, 0.0432, 0.0140], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0020,     0.0002,     0.0144,     0.8712,     0.1121],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0179, 0.0786, 0.0790, 0.4593, 0.3651], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  77.5029234804158
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  56.37894195039219
printing an ep nov before normalisation:  49.013129275007145
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0004,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0026,     0.9807,     0.0093,     0.0002,     0.0072],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9692,     0.0245,     0.0063],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0006,     0.0001,     0.0439,     0.8193,     0.1361],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0049, 0.0033, 0.0015, 0.5552, 0.4351], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.167589143158988
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  17.465372793249884
printing an ep nov before normalisation:  46.239967796915735
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.205838389602526
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.879]
 [30.774]
 [54.126]
 [40.02 ]
 [31.845]] [[0.174]
 [0.128]
 [0.338]
 [0.211]
 [0.137]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.52040948478434
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  94.0068900012827
printing an ep nov before normalisation:  27.146433821750744
printing an ep nov before normalisation:  55.28818521902789
printing an ep nov before normalisation:  18.33862256171352
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  93.85365844474231
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.43845771852034
printing an ep nov before normalisation:  102.06496247481341
printing an ep nov before normalisation:  89.4980137601179
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.59805965423584
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.486]
 [59.276]
 [59.276]
 [21.8  ]
 [59.276]] [[1.667]
 [5.39 ]
 [5.39 ]
 [1.261]
 [5.39 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  93.41958378267097
printing an ep nov before normalisation:  23.924787429504068
printing an ep nov before normalisation:  15.420481082799586
printing an ep nov before normalisation:  18.44908595085144
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9922,     0.0001,     0.0000,     0.0050,     0.0027],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0053, 0.9574, 0.0257, 0.0052, 0.0064], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9448,     0.0454,     0.0098],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0001,     0.0225,     0.8702,     0.1071],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0027,     0.0002,     0.0370,     0.5830,     0.3771],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  44.427763386859134
siam score:  -0.9306482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.212465313699134
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.476]
 [27.597]
 [27.597]
 [27.597]
 [27.597]] [[1.099]
 [0.668]
 [0.668]
 [0.668]
 [0.668]]
printing an ep nov before normalisation:  31.09968311729232
printing an ep nov before normalisation:  34.39665079116821
printing an ep nov before normalisation:  50.621550674641774
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9974,     0.0000,     0.0000,     0.0019,     0.0007],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0177, 0.9433, 0.0211, 0.0010, 0.0169], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9716,     0.0213,     0.0071],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0002,     0.0203,     0.8486,     0.1307],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0001,     0.0006,     0.1277,     0.5781,     0.2936],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  84.55756115590395
printing an ep nov before normalisation:  81.34428891155505
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  39.92056287339105
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.100268524968
using explorer policy with actor:  1
printing an ep nov before normalisation:  60.70824083224906
printing an ep nov before normalisation:  30.263916121182817
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.12870229691043
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.19044873019751
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9285251
printing an ep nov before normalisation:  93.29293602140075
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9283782
printing an ep nov before normalisation:  63.767183817364156
printing an ep nov before normalisation:  98.41678229087475
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.661031166127575
siam score:  -0.9282301
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.28504572974311
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  102.23918051837177
printing an ep nov before normalisation:  88.5823451374354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.97439852652357
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[94.125]
 [94.125]
 [94.125]
 [97.442]
 [94.125]] [[0.958]
 [0.958]
 [0.958]
 [1.   ]
 [0.958]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.882]
 [25.869]
 [21.126]
 [55.393]
 [23.079]] [[0.312]
 [0.182]
 [0.126]
 [0.529]
 [0.149]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.044]
 [45.044]
 [45.044]
 [45.044]
 [45.044]] [[0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9184801
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([0.9812, 0.0013, 0.0049, 0.0086, 0.0040], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0004,     0.9723,     0.0004,     0.0008,     0.0262],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9996,     0.0003,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0002,     0.0188,     0.8574,     0.1235],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0016, 0.0009, 0.0470, 0.3975, 0.5530], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.578421440858968
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.422]
 [29.422]
 [29.422]
 [69.7  ]
 [29.422]] [[0.193]
 [0.193]
 [0.193]
 [0.693]
 [0.193]]
printing an ep nov before normalisation:  97.19385515800212
printing an ep nov before normalisation:  75.7514727592811
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.118641469668106
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.026]
 [33.135]
 [27.818]
 [37.359]
 [27.715]] [[0.865]
 [0.75 ]
 [0.539]
 [0.918]
 [0.535]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  72.11090005651792
printing an ep nov before normalisation:  66.1236191953979
printing an ep nov before normalisation:  92.5016579143608
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.825]
 [71.825]
 [71.825]
 [71.825]
 [71.825]] [[1.183]
 [1.183]
 [1.183]
 [1.183]
 [1.183]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.96020579334018
printing an ep nov before normalisation:  99.84520120547211
using explorer policy with actor:  1
printing an ep nov before normalisation:  91.88654437441657
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.146]
 [40.146]
 [44.712]
 [68.635]
 [40.146]] [[0.637]
 [0.637]
 [0.759]
 [1.393]
 [0.637]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.532]
 [30.175]
 [49.662]
 [26.426]
 [24.973]] [[0.284]
 [0.332]
 [0.686]
 [0.263]
 [0.237]]
printing an ep nov before normalisation:  60.24589678345961
siam score:  -0.9273559
printing an ep nov before normalisation:  74.21924338220511
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.325]
 [32.2  ]
 [32.2  ]
 [32.2  ]
 [32.2  ]] [[0.857]
 [0.569]
 [0.569]
 [0.569]
 [0.569]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.92798614501953
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.154 0.154 0.385 0.154 0.154]
printing an ep nov before normalisation:  90.45706552202725
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.479]
 [45.479]
 [45.479]
 [45.479]
 [45.479]] [[0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.404]]
printing an ep nov before normalisation:  0.03777941670335849
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.763]
 [16.763]
 [68.895]
 [21.465]
 [16.763]] [[0.091]
 [0.091]
 [0.633]
 [0.14 ]
 [0.091]]
printing an ep nov before normalisation:  30.287918081578557
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.06 ]
 [44.563]
 [46.507]
 [61.094]
 [41.06 ]] [[0.296]
 [0.344]
 [0.371]
 [0.571]
 [0.296]]
printing an ep nov before normalisation:  86.33284757094788
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.144624624631433
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9923,     0.0049,     0.0000,     0.0017,     0.0010],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0047, 0.9479, 0.0100, 0.0027, 0.0347], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9997,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0005,     0.0003,     0.0139,     0.8591,     0.1262],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0009, 0.0047, 0.0734, 0.4614, 0.4596], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.773337545197066
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  47.09368607385611
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9195742
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.724]
 [55.724]
 [55.724]
 [55.724]
 [55.724]] [[1.633]
 [1.633]
 [1.633]
 [1.633]
 [1.633]]
printing an ep nov before normalisation:  37.563276290893555
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0003,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0003,     0.8538,     0.1167,     0.0289],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0057,     0.0264,     0.8485,     0.1192],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0015, 0.0048, 0.0491, 0.7362, 0.2084], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.34304952418246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.318]
 [47.318]
 [47.318]
 [47.318]
 [47.318]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.967]
 [27.467]
 [27.03 ]
 [30.053]
 [28.18 ]] [[1.25 ]
 [0.872]
 [0.847]
 [1.023]
 [0.914]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.064]
 [51.064]
 [51.064]
 [75.849]
 [51.064]] [[0.739]
 [0.739]
 [0.739]
 [1.228]
 [0.739]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.2  ]
 [44.2  ]
 [44.2  ]
 [60.349]
 [44.2  ]] [[0.75 ]
 [0.75 ]
 [0.75 ]
 [1.114]
 [0.75 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.85499429702759
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.118]
 [33.057]
 [33.807]
 [31.691]
 [33.057]] [[0.333]
 [0.27 ]
 [0.282]
 [0.249]
 [0.27 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.147]
 [27.43 ]
 [27.43 ]
 [27.43 ]
 [27.43 ]] [[0.479]
 [0.403]
 [0.403]
 [0.403]
 [0.403]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.643]
 [29.667]
 [38.453]
 [26.48 ]
 [24.798]] [[0.854]
 [0.758]
 [1.185]
 [0.603]
 [0.521]]
siam score:  -0.92717826
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  60.35953864448158
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.81009217727372
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.58 ]
 [26.574]
 [36.339]
 [45.675]
 [33.754]] [[0.815]
 [0.576]
 [0.788]
 [0.991]
 [0.732]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.747]
 [32.979]
 [32.979]
 [28.528]
 [32.979]] [[0.779]
 [0.471]
 [0.471]
 [0.315]
 [0.471]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.85599899291992
printing an ep nov before normalisation:  75.17721754503494
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.2897340376828
printing an ep nov before normalisation:  28.90672206878662
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.185581699410626
printing an ep nov before normalisation:  42.06123362226922
printing an ep nov before normalisation:  86.12148179483367
printing an ep nov before normalisation:  89.84882998504013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.549]
 [29.847]
 [31.673]
 [32.238]
 [31.108]] [[1.271]
 [0.994]
 [1.131]
 [1.173]
 [1.089]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.05718452186798
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.94244380111868
siam score:  -0.9210619
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.175736234966315
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.735]
 [56.735]
 [56.735]
 [69.971]
 [56.735]] [[1.212]
 [1.212]
 [1.212]
 [1.577]
 [1.212]]
printing an ep nov before normalisation:  31.929212803255474
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.796]
 [40.796]
 [43.552]
 [43.82 ]
 [40.796]] [[0.355]
 [0.355]
 [0.4  ]
 [0.405]
 [0.355]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.956]
 [30.13 ]
 [33.607]
 [49.928]
 [29.627]] [[0.059]
 [0.141]
 [0.169]
 [0.3  ]
 [0.136]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92512864
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.107946769467212
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.938]
 [25.938]
 [31.209]
 [25.938]
 [25.938]] [[0.303]
 [0.303]
 [0.365]
 [0.303]
 [0.303]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.377]
 [53.605]
 [29.343]
 [34.925]
 [20.263]] [[0.393]
 [0.506]
 [0.211]
 [0.278]
 [0.1  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.69238364949346
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.828]
 [35.828]
 [35.828]
 [35.828]
 [35.828]] [[0.48]
 [0.48]
 [0.48]
 [0.48]
 [0.48]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.524]
 [35.052]
 [40.324]
 [61.973]
 [35.052]] [[0.583]
 [0.514]
 [0.661]
 [1.262]
 [0.514]]
siam score:  -0.93097544
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.93139505
printing an ep nov before normalisation:  14.75287892143596
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.362493945996896
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.937737019354973
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.357]
 [32.648]
 [32.648]
 [24.253]
 [32.648]] [[0.453]
 [0.433]
 [0.433]
 [0.195]
 [0.433]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.76251856677501
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.335]
 [50.335]
 [50.335]
 [50.282]
 [50.335]] [[2.   ]
 [2.   ]
 [2.   ]
 [1.996]
 [2.   ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[96.648]
 [96.648]
 [96.648]
 [96.718]
 [96.648]] [[0.666]
 [0.666]
 [0.666]
 [0.667]
 [0.666]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 59.94072657017552
siam score:  -0.92219114
printing an ep nov before normalisation:  88.16939758504444
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.65337566668929
printing an ep nov before normalisation:  41.10325772779096
printing an ep nov before normalisation:  50.48956508844401
printing an ep nov before normalisation:  34.52089309692383
printing an ep nov before normalisation:  80.6501379856892
printing an ep nov before normalisation:  70.53692586936033
printing an ep nov before normalisation:  22.79158115386963
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.479]
 [39.807]
 [51.142]
 [54.429]
 [41.182]] [[0.466]
 [0.411]
 [0.646]
 [0.714]
 [0.44 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.9861348037611
printing an ep nov before normalisation:  95.01082970686198
printing an ep nov before normalisation:  83.54418649653356
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.7233293741188
siam score:  -0.92083585
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.81223964691162
printing an ep nov before normalisation:  84.19491504389767
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.326]
 [64.326]
 [64.326]
 [74.098]
 [64.326]] [[0.94 ]
 [0.94 ]
 [0.94 ]
 [1.133]
 [0.94 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.02807265704507
printing an ep nov before normalisation:  39.14264678955078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.701]
 [47.701]
 [57.623]
 [67.843]
 [47.701]] [[0.545]
 [0.545]
 [0.73 ]
 [0.921]
 [0.545]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  92.074881788062
printing an ep nov before normalisation:  68.38480365372385
printing an ep nov before normalisation:  35.50616888701153
using explorer policy with actor:  1
printing an ep nov before normalisation:  86.46486958557689
printing an ep nov before normalisation:  46.866016843256205
printing an ep nov before normalisation:  90.83749462669104
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.543991461600854
printing an ep nov before normalisation:  31.168593538911853
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9222012
line 256 mcts: sample exp_bonus 49.27617356921452
printing an ep nov before normalisation:  25.71205634228392
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.752]
 [30.559]
 [38.716]
 [59.558]
 [55.068]] [[0.249]
 [0.135]
 [0.196]
 [0.353]
 [0.32 ]]
printing an ep nov before normalisation:  28.19174221145289
actions average: 
K:  0  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9986,     0.0007,     0.0000,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.9590,     0.0219,     0.0189],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0010,     0.0001,     0.0360,     0.8039,     0.1590],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0006,     0.0003,     0.1274,     0.4437,     0.4280],
       grad_fn=<DivBackward0>)
actions average: 
K:  2  action  0 :  tensor([    0.9821,     0.0001,     0.0000,     0.0013,     0.0165],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9982,     0.0003,     0.0001,     0.0015],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9287,     0.0459,     0.0253],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0001,     0.0517,     0.8114,     0.1365],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0000,     0.0005,     0.0534,     0.4483,     0.4978],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  97.20888482495947
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.121]
 [30.121]
 [30.121]
 [30.121]
 [30.121]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 100.39798633689657
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.18582663361996
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.31282377243042
printing an ep nov before normalisation:  51.4000297459144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.355]
 [42.884]
 [42.884]
 [68.788]
 [42.884]] [[0.567]
 [0.363]
 [0.363]
 [0.704]
 [0.363]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.69860310249527
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.052096807105855
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.999145487660414
line 256 mcts: sample exp_bonus 19.447895191118874
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.829]
 [44.314]
 [28.115]
 [69.626]
 [36.463]] [[0.344]
 [0.288]
 [0.089]
 [0.599]
 [0.192]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.92 ]
 [38.572]
 [38.572]
 [78.576]
 [38.572]] [[0.855]
 [0.383]
 [0.383]
 [1.027]
 [0.383]]
printing an ep nov before normalisation:  93.22726088068549
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  102.2242344035448
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.919711
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.746]
 [39.852]
 [33.156]
 [47.276]
 [37.032]] [[0.512]
 [0.514]
 [0.356]
 [0.69 ]
 [0.447]]
printing an ep nov before normalisation:  88.32317270675469
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.588]
 [33.588]
 [33.588]
 [33.588]
 [33.588]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
actions average: 
K:  3  action  0 :  tensor([    0.9953,     0.0001,     0.0000,     0.0034,     0.0012],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9996,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9364,     0.0508,     0.0128],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0006,     0.0231,     0.8179,     0.1582],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0645, 0.0054, 0.0341, 0.3784, 0.5175], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  21.82835102081299
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.009]
 [25.504]
 [22.845]
 [55.147]
 [18.679]] [[0.294]
 [0.269]
 [0.226]
 [0.749]
 [0.159]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.717]
 [ 0.   ]
 [ 0.   ]
 [52.079]
 [ 0.   ]] [[ 0.179]
 [-0.175]
 [-0.175]
 [ 0.714]
 [-0.175]]
printing an ep nov before normalisation:  83.77112966532097
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.019897576653825
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.586]
 [61.586]
 [61.586]
 [82.674]
 [61.586]] [[0.59 ]
 [0.59 ]
 [0.59 ]
 [0.858]
 [0.59 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.0576876765792
printing an ep nov before normalisation:  35.2687931060791
printing an ep nov before normalisation:  57.16553614956836
printing an ep nov before normalisation:  83.93420700781773
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.93014604
printing an ep nov before normalisation:  38.20103810292743
printing an ep nov before normalisation:  68.5381151299237
printing an ep nov before normalisation:  47.97128630909828
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.734]
 [38.059]
 [38.059]
 [60.881]
 [38.059]] [[0.822]
 [0.434]
 [0.434]
 [0.824]
 [0.434]]
printing an ep nov before normalisation:  56.45402425819227
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.051 0.077 0.051 0.795 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.81044551410062
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.12453817490756
actions average: 
K:  2  action  0 :  tensor([    0.9657,     0.0313,     0.0000,     0.0024,     0.0006],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9989,     0.0001,     0.0000,     0.0009],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0001,     0.8918,     0.0832,     0.0248],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0032, 0.0023, 0.0179, 0.8360, 0.1406], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0674, 0.0878, 0.0006, 0.5649, 0.2794], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.09103628072126
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  95.79464751220816
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.4119828449078
printing an ep nov before normalisation:  85.13232834712545
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.990460153298244
printing an ep nov before normalisation:  47.72197196598554
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  84.69596632062112
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.657]
 [34.657]
 [34.657]
 [43.141]
 [34.657]] [[0.356]
 [0.356]
 [0.356]
 [0.544]
 [0.356]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.301932401433525
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.247]
 [86.247]
 [86.247]
 [93.197]
 [86.247]] [[1.188]
 [1.188]
 [1.188]
 [1.305]
 [1.188]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  79.06210703275916
printing an ep nov before normalisation:  49.92917030615885
printing an ep nov before normalisation:  88.91749167001444
printing an ep nov before normalisation:  22.736158692838885
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.652]
 [31.652]
 [45.627]
 [31.652]
 [31.652]] [[0.963]
 [0.963]
 [1.667]
 [0.963]
 [0.963]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.94172471556081
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9622,     0.0019,     0.0000,     0.0256,     0.0102],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9929,     0.0019,     0.0000,     0.0051],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9017,     0.0770,     0.0212],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0007,     0.0437,     0.8172,     0.1383],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0001,     0.0013,     0.0598,     0.6449,     0.2939],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.63437340980391
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.299234674522936
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.537818908691406
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.72769252068314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.78469638671336
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.844]
 [37.892]
 [36.428]
 [43.659]
 [34.944]] [[0.583]
 [0.867]
 [0.808]
 [1.099]
 [0.748]]
printing an ep nov before normalisation:  47.87355356772628
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.504]
 [30.965]
 [26.368]
 [29.32 ]
 [26.146]] [[0.391]
 [0.38 ]
 [0.283]
 [0.345]
 [0.278]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  47.54812556903971
line 256 mcts: sample exp_bonus 27.038702964782715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.06956082286666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.65717725927513
printing an ep nov before normalisation:  38.57679843902588
siam score:  -0.91720825
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.08117696276848
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.819]
 [27.874]
 [23.444]
 [33.517]
 [25.832]] [[0.743]
 [0.352]
 [0.228]
 [0.51 ]
 [0.295]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.113]
 [37.962]
 [25.311]
 [37.962]
 [37.962]] [[1.667]
 [2.05 ]
 [1.05 ]
 [2.05 ]
 [2.05 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  99.07134799082596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.032999633690295
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.224925206499215
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.973381996154785
printing an ep nov before normalisation:  73.29966548088353
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  94.83331632220656
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.273]
 [51.273]
 [63.381]
 [77.754]
 [51.273]] [[0.834]
 [0.834]
 [1.066]
 [1.34 ]
 [0.834]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.424]
 [23.487]
 [20.232]
 [19.953]
 [19.93 ]] [[1.057]
 [0.364]
 [0.277]
 [0.269]
 [0.269]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.43814191248057
printing an ep nov before normalisation:  40.71530203272088
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.83668741549224
printing an ep nov before normalisation:  80.95243830132888
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.77205980623141
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.02806460484008
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.88937820107686
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.71750764197287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.840218544006348
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9282738
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.045]
 [16.802]
 [49.947]
 [14.66 ]
 [16.71 ]] [[0.09 ]
 [0.1  ]
 [0.519]
 [0.073]
 [0.098]]
printing an ep nov before normalisation:  34.712886810302734
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.084]
 [40.084]
 [40.084]
 [66.321]
 [40.084]] [[0.708]
 [0.708]
 [0.708]
 [1.355]
 [0.708]]
siam score:  -0.9297406
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.346981048583984
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.737396384428447
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.6594186782304
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.906]
 [37.906]
 [37.906]
 [37.906]
 [37.906]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.343]
 [29.3  ]
 [26.619]
 [23.493]
 [22.963]] [[0.6  ]
 [0.678]
 [0.571]
 [0.445]
 [0.424]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.326]
 [34.172]
 [34.172]
 [44.206]
 [34.172]] [[0.648]
 [0.434]
 [0.434]
 [0.626]
 [0.434]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  99.05569528122804
printing an ep nov before normalisation:  82.85509087346534
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9297842
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.81776986902088
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 73.81149776976994
printing an ep nov before normalisation:  83.13088139852795
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.93959575833864
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  83.22477788626644
printing an ep nov before normalisation:  89.13727890397202
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0117, 0.9471, 0.0203, 0.0085, 0.0124], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0003,     0.8571,     0.0975,     0.0451],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0001,     0.0081,     0.8484,     0.1427],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0004,     0.0003,     0.0187,     0.5587,     0.4219],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  42.886029082591755
printing an ep nov before normalisation:  47.25857231554964
printing an ep nov before normalisation:  40.64599247046879
using explorer policy with actor:  1
printing an ep nov before normalisation:  76.00826946683188
printing an ep nov before normalisation:  90.0935054827782
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.245]
 [36.245]
 [36.245]
 [36.245]
 [36.245]] [[0.198]
 [0.198]
 [0.198]
 [0.198]
 [0.198]]
printing an ep nov before normalisation:  36.0356068611145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.38111234068324
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  87.12369186239451
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.807]
 [39.628]
 [39.628]
 [27.503]
 [26.387]] [[1.667]
 [2.86 ]
 [2.86 ]
 [1.523]
 [1.4  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.675]
 [88.675]
 [88.675]
 [88.675]
 [88.675]] [[1.584]
 [1.584]
 [1.584]
 [1.584]
 [1.584]]
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0005,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0005,     0.9958,     0.0005,     0.0000,     0.0032],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0005,     0.0001,     0.8950,     0.0775,     0.0269],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0036,     0.0003,     0.0096,     0.8791,     0.1074],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0532, 0.0082, 0.0580, 0.5085, 0.3721], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.15563445179113
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9169769
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  17.696693311741623
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.34 ]
 [49.34 ]
 [49.34 ]
 [75.267]
 [49.34 ]] [[0.424]
 [0.424]
 [0.424]
 [0.748]
 [0.424]]
Starting evaluation
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.903]
 [29.981]
 [27.71 ]
 [27.2  ]
 [23.137]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.441958349597336
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.38 ]
 [24.334]
 [32.024]
 [27.38 ]
 [27.38 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  38.990162013516105
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.903]
 [23.903]
 [54.757]
 [24.366]
 [23.903]] [[0.165]
 [0.165]
 [0.571]
 [0.171]
 [0.165]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.42 ]
 [24.42 ]
 [24.42 ]
 [71.822]
 [24.42 ]] [[0.234]
 [0.234]
 [0.234]
 [0.989]
 [0.234]]
printing an ep nov before normalisation:  28.66123383402579
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.295]
 [48.295]
 [48.295]
 [80.512]
 [48.295]] [[0.59 ]
 [0.59 ]
 [0.59 ]
 [1.121]
 [0.59 ]]
printing an ep nov before normalisation:  97.20088331919322
siam score:  -0.9224774
printing an ep nov before normalisation:  86.54462679784174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.190661023318
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.379]
 [40.379]
 [40.379]
 [64.436]
 [40.379]] [[0.39 ]
 [0.39 ]
 [0.39 ]
 [0.702]
 [0.39 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  34.32560723551123
printing an ep nov before normalisation:  34.59696292877197
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.35687732696533
printing an ep nov before normalisation:  32.079662425405814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.04984565497338
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.80841773818642
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.603030681610107
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.487]
 [37.588]
 [39.724]
 [42.462]
 [37.087]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  83.65671679392132
printing an ep nov before normalisation:  76.48964802701323
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.85498879989619
printing an ep nov before normalisation:  57.557859766095525
line 256 mcts: sample exp_bonus 67.23680234057791
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.694]
 [47.694]
 [31.042]
 [47.694]
 [36.815]] [[2.986]
 [2.986]
 [1.477]
 [2.986]
 [2.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9965,     0.0003,     0.0000,     0.0022,     0.0010],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0523,     0.8951,     0.0000,     0.0382,     0.0144],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0020,     0.9527,     0.0215,     0.0237],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0005,     0.0133,     0.8564,     0.1295],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0052, 0.0081, 0.1292, 0.2119, 0.6456], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.867]
 [57.867]
 [57.867]
 [75.559]
 [57.867]] [[1.315]
 [1.315]
 [1.315]
 [1.796]
 [1.315]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.567]
 [86.567]
 [86.567]
 [86.567]
 [86.567]] [[1.908]
 [1.908]
 [1.908]
 [1.908]
 [1.908]]
actions average: 
K:  4  action  0 :  tensor([    0.9946,     0.0022,     0.0000,     0.0024,     0.0009],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9991,     0.0000,     0.0000,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0002,     0.9371,     0.0484,     0.0142],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0002,     0.0414,     0.8306,     0.1276],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0000,     0.1083,     0.0477,     0.6561,     0.1879],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.738029030683805
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.062]
 [25.808]
 [23.089]
 [50.661]
 [25.358]] [[0.468]
 [0.379]
 [0.305]
 [1.06 ]
 [0.367]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.106555461883545
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.513]
 [22.513]
 [59.55 ]
 [22.513]
 [22.513]] [[0.217]
 [0.217]
 [0.897]
 [0.217]
 [0.217]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.155]
 [30.585]
 [41.781]
 [30.829]
 [30.414]] [[0.42 ]
 [0.556]
 [0.899]
 [0.563]
 [0.551]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.328]
 [28.328]
 [28.328]
 [75.054]
 [28.328]] [[0.274]
 [0.274]
 [0.274]
 [1.05 ]
 [0.274]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.103 0.718 0.026 0.103 0.051]
printing an ep nov before normalisation:  79.64530334361473
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.737]
 [19.485]
 [15.379]
 [16.23 ]
 [14.855]] [[0.39 ]
 [0.111]
 [0.065]
 [0.075]
 [0.059]]
printing an ep nov before normalisation:  33.35808294552457
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.483]
 [88.483]
 [88.483]
 [88.483]
 [88.483]] [[0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]]
actions average: 
K:  0  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0086, 0.9675, 0.0130, 0.0015, 0.0093], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0002,     0.9111,     0.0694,     0.0192],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0014,     0.0077,     0.8664,     0.1242],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0003,     0.0004,     0.0645,     0.7614,     0.1735],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  26.307759284973145
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[99.195]
 [99.195]
 [99.195]
 [99.195]
 [99.195]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.42242689699361
printing an ep nov before normalisation:  76.72227074807111
printing an ep nov before normalisation:  90.24077454280359
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.054224967956543
printing an ep nov before normalisation:  32.31388940487907
siam score:  -0.9197714
printing an ep nov before normalisation:  83.62466025749055
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
deleting a thread, now have 1 threads
Frames:  101330 train batches done:  11867 episodes:  2702
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.154]
 [39.154]
 [58.601]
 [63.812]
 [39.154]] [[0.511]
 [0.511]
 [0.877]
 [0.975]
 [0.511]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.199]
 [66.199]
 [66.199]
 [76.048]
 [66.199]] [[1.135]
 [1.135]
 [1.135]
 [1.333]
 [1.135]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  88.34199709933054
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.105443006381023
printing an ep nov before normalisation:  31.063150934197523
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.93831761829605
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.26833919967995
printing an ep nov before normalisation:  90.6548576478539
printing an ep nov before normalisation:  91.88991000091477
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.363906383514404
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.75100326538086
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  1
siam score:  -0.92534524
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.311846879691682
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.522]
 [40.522]
 [40.522]
 [40.522]
 [40.522]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  3.408318909632726
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.564871507641215
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  32.21865530709593
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.0859045590299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.402]
 [60.402]
 [68.009]
 [73.644]
 [60.402]] [[1.08 ]
 [1.08 ]
 [1.259]
 [1.391]
 [1.08 ]]
printing an ep nov before normalisation:  29.94231939315796
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.16525501790048
printing an ep nov before normalisation:  99.48470833000434
UNIT TEST: sample policy line 217 mcts : [0.026 0.026 0.897 0.026 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9719,     0.0000,     0.0000,     0.0244,     0.0037],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9984,     0.0006,     0.0001,     0.0009],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9566,     0.0282,     0.0152],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0002,     0.0305,     0.8671,     0.1021],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0002,     0.0006,     0.0373,     0.6895,     0.2724],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  24.751596450805664
printing an ep nov before normalisation:  28.115940108909815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.235891601119505
using explorer policy with actor:  1
printing an ep nov before normalisation:  28.650957748774715
printing an ep nov before normalisation:  32.07102680884031
printing an ep nov before normalisation:  37.909945852004604
printing an ep nov before normalisation:  26.109938327287615
siam score:  -0.93034285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  90.37637517905962
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  98.6207817880761
siam score:  -0.9333223
siam score:  -0.93209577
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.626]
 [25.801]
 [33.066]
 [20.538]
 [20.838]] [[0.2  ]
 [0.281]
 [0.421]
 [0.179]
 [0.185]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  101.68763087227269
printing an ep nov before normalisation:  48.73197909092224
actions average: 
K:  2  action  0 :  tensor([    0.9991,     0.0000,     0.0000,     0.0006,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9970,     0.0002,     0.0001,     0.0025],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9743,     0.0148,     0.0108],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0006,     0.0001,     0.0172,     0.8595,     0.1226],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0037,     0.0005,     0.0856,     0.5904,     0.3198],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.261]
 [64.261]
 [64.261]
 [77.886]
 [64.261]] [[0.817]
 [0.817]
 [0.817]
 [1.03 ]
 [0.817]]
printing an ep nov before normalisation:  94.94338745238367
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.79676442054013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.64212808112013
siam score:  -0.93145007
line 256 mcts: sample exp_bonus 50.929127343616756
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  18.586812019348145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  99.7407214973732
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.11777029196019
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.7927915973647
printing an ep nov before normalisation:  56.25926912933787
printing an ep nov before normalisation:  93.4118124351099
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.19988779503893
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[92.376]
 [92.376]
 [92.376]
 [92.376]
 [92.376]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
siam score:  -0.9213698
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.637]
 [87.637]
 [87.637]
 [87.637]
 [87.637]] [[0.848]
 [0.848]
 [0.848]
 [0.848]
 [0.848]]
printing an ep nov before normalisation:  45.79998146797592
siam score:  -0.92065454
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.16241455078125
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.683]
 [30.683]
 [30.683]
 [30.683]
 [30.683]] [[0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  73.90251585065512
printing an ep nov before normalisation:  40.054437856154706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.843]
 [68.843]
 [68.843]
 [68.843]
 [68.843]] [[1.005]
 [1.005]
 [1.005]
 [1.005]
 [1.005]]
printing an ep nov before normalisation:  35.48928496697505
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.242]
 [29.479]
 [29.479]
 [38.624]
 [29.479]] [[1.224]
 [0.361]
 [0.361]
 [0.554]
 [0.361]]
printing an ep nov before normalisation:  22.348039150238037
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 79.83824447773938
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.05742297870103
printing an ep nov before normalisation:  69.33565027307318
printing an ep nov before normalisation:  54.12226618474725
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([0.9406, 0.0129, 0.0043, 0.0257, 0.0166], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9951,     0.0001,     0.0003,     0.0043],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9588,     0.0347,     0.0065],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0001,     0.0074,     0.9207,     0.0716],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0001,     0.0028,     0.0090,     0.5320,     0.4562],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.637]
 [36.637]
 [44.8  ]
 [36.637]
 [36.637]] [[1.334]
 [1.334]
 [1.834]
 [1.334]
 [1.334]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.767710724973085
printing an ep nov before normalisation:  67.87089728914667
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.398733260196096
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  87.14867701787202
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  93.83759809829147
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.997]
 [47.997]
 [47.997]
 [63.247]
 [47.997]] [[0.908]
 [0.908]
 [0.908]
 [1.333]
 [0.908]]
line 256 mcts: sample exp_bonus 52.37872194940509
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.917]
 [36.917]
 [36.917]
 [36.917]
 [36.917]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
line 256 mcts: sample exp_bonus 40.80710296520131
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.756]
 [54.756]
 [57.772]
 [67.03 ]
 [54.756]] [[0.989]
 [0.989]
 [1.066]
 [1.301]
 [0.989]]
printing an ep nov before normalisation:  68.12217277819721
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.93101406097412
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.4347363755931
siam score:  -0.9268594
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.54835649498396
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  95.39417110105936
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  104.26471622590024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 60.88781911432228
printing an ep nov before normalisation:  42.42413256312388
printing an ep nov before normalisation:  52.38440565965277
printing an ep nov before normalisation:  29.27964855604702
printing an ep nov before normalisation:  96.44021034714324
printing an ep nov before normalisation:  57.212386007504975
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.23176247843823
siam score:  -0.928781
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.70284922989714
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.4978700691936
actions average: 
K:  4  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9962,     0.0009,     0.0000,     0.0028],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0004,     0.9204,     0.0658,     0.0133],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0001,     0.0199,     0.8805,     0.0990],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0398,     0.0271,     0.0004,     0.6816,     0.2512],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.168301582336426
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.798609420855144
line 256 mcts: sample exp_bonus 51.448788968812494
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.915]
 [54.915]
 [54.915]
 [82.08 ]
 [54.915]] [[0.867]
 [0.867]
 [0.867]
 [1.377]
 [0.867]]
printing an ep nov before normalisation:  92.44905596514249
printing an ep nov before normalisation:  88.33596444330607
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  91.66493892011694
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9247133
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.60397519917768
siam score:  -0.92227584
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.81268221050712
printing an ep nov before normalisation:  63.39206403315952
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 48.185636362010285
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.301]
 [48.301]
 [48.301]
 [91.06 ]
 [48.301]] [[0.4  ]
 [0.4  ]
 [0.4  ]
 [0.867]
 [0.4  ]]
siam score:  -0.92503846
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[100.507]
 [100.507]
 [100.507]
 [100.507]
 [100.507]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
printing an ep nov before normalisation:  28.617496490478516
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.043]
 [49.111]
 [58.814]
 [69.805]
 [49.043]] [[0.331]
 [0.332]
 [0.462]
 [0.609]
 [0.331]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.06144361791337
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.613101482391357
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  61.320386796082566
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92183787
using explorer policy with actor:  1
printing an ep nov before normalisation:  85.58558390712223
printing an ep nov before normalisation:  32.31228503318843
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.013]
 [69.172]
 [69.172]
 [69.172]
 [69.172]] [[1.531]
 [1.117]
 [1.117]
 [1.117]
 [1.117]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.58298465751607
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.38685002397817
printing an ep nov before normalisation:  75.20389785659188
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  28.37545871734619
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.74596744375377
printing an ep nov before normalisation:  99.80763276810816
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.266]
 [56.839]
 [29.144]
 [28.483]
 [25.002]] [[0.379]
 [0.994]
 [0.328]
 [0.312]
 [0.228]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  98.13374572302307
printing an ep nov before normalisation:  36.08624803762898
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 88.89006162903652
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.91982025
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.43187554299513
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[89.684]
 [89.684]
 [89.684]
 [87.317]
 [89.684]] [[0.987]
 [0.987]
 [0.987]
 [0.957]
 [0.987]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.848]
 [25.294]
 [35.366]
 [42.481]
 [19.836]] [[0.082]
 [0.189]
 [0.335]
 [0.437]
 [0.11 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.816335201263428
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.19024800205177
printing an ep nov before normalisation:  81.2983790028966
actions average: 
K:  0  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9995,     0.0000,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0002,     0.8933,     0.0899,     0.0165],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0002,     0.0212,     0.8808,     0.0977],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0018,     0.0001,     0.0004,     0.5475,     0.4503],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  89.86436570202986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.85307682179692
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.368]
 [49.818]
 [67.913]
 [68.815]
 [49.818]] [[0.517]
 [0.811]
 [1.277]
 [1.3  ]
 [0.811]]
printing an ep nov before normalisation:  26.09237773077829
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.256 0.128 0.513 0.077 0.026]
siam score:  -0.9281103
using explorer policy with actor:  1
printing an ep nov before normalisation:  25.040206909179688
using explorer policy with actor:  1
siam score:  -0.9273384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.763141433964336
printing an ep nov before normalisation:  21.22964382171631
printing an ep nov before normalisation:  81.42825746999947
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.752]
 [24.752]
 [24.752]
 [53.375]
 [24.752]] [[0.081]
 [0.081]
 [0.081]
 [0.334]
 [0.081]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.633247722517275
printing an ep nov before normalisation:  78.4846242717898
printing an ep nov before normalisation:  82.85853222279465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.33098757952941
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9229335
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.583]
 [23.583]
 [23.583]
 [50.95 ]
 [23.583]] [[0.205]
 [0.205]
 [0.205]
 [0.657]
 [0.205]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.273]
 [76.273]
 [76.273]
 [82.34 ]
 [76.273]] [[0.79 ]
 [0.79 ]
 [0.79 ]
 [0.864]
 [0.79 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.231 0.077 0.051 0.615 0.026]
siam score:  -0.9195409
siam score:  -0.92029107
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.065]
 [32.06 ]
 [40.554]
 [51.565]
 [28.93 ]] [[0.157]
 [0.226]
 [0.343]
 [0.495]
 [0.183]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.23 ]
 [24.435]
 [24.435]
 [25.22 ]
 [24.435]] [[0.312]
 [0.256]
 [0.256]
 [0.271]
 [0.256]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.468]
 [39.835]
 [39.835]
 [71.662]
 [39.835]] [[0.119]
 [0.236]
 [0.236]
 [0.596]
 [0.236]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9991,     0.0000,     0.0000,     0.0008,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9746,     0.0004,     0.0001,     0.0249],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0015,     0.9214,     0.0446,     0.0324],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0003,     0.0123,     0.8616,     0.1257],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0145,     0.0299,     0.0005,     0.6678,     0.2873],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.3419853402282
printing an ep nov before normalisation:  40.13058848568161
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.11558163003936
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9973,     0.0004,     0.0002,     0.0013,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9986,     0.0000,     0.0000,     0.0013],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0002,     0.0011,     0.8882,     0.0547,     0.0559],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0002,     0.0292,     0.8563,     0.1140],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0025, 0.0232, 0.0744, 0.5000, 0.3999], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9211107
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[89.416]
 [89.416]
 [89.416]
 [97.916]
 [89.416]] [[0.605]
 [0.605]
 [0.605]
 [0.667]
 [0.605]]
printing an ep nov before normalisation:  27.025254634992987
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.4464491573915
printing an ep nov before normalisation:  95.25824186859882
printing an ep nov before normalisation:  90.3772655937259
printing an ep nov before normalisation:  46.78873646771292
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.91821295
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.8971453373606
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.542]
 [54.542]
 [60.902]
 [69.302]
 [54.542]] [[1.204]
 [1.204]
 [1.405]
 [1.671]
 [1.204]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.6683382173037
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.39294767379761
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  65.27979375286682
printing an ep nov before normalisation:  97.39376656807075
actions average: 
K:  3  action  0 :  tensor([    0.9976,     0.0002,     0.0000,     0.0008,     0.0014],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9945,     0.0000,     0.0000,     0.0055],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0002,     0.9255,     0.0621,     0.0122],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0007,     0.0144,     0.8741,     0.1105],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0004,     0.0007,     0.0304,     0.6622,     0.3062],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  89.28662135990706
siam score:  -0.92474073
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9858,     0.0018,     0.0011,     0.0106,     0.0008],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9990,     0.0000,     0.0000,     0.0008],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0001,     0.9434,     0.0468,     0.0097],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0001,     0.0067,     0.8829,     0.1102],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0068,     0.0003,     0.0659,     0.6150,     0.3120],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.115]
 [43.753]
 [44.971]
 [17.608]
 [17.603]] [[0.081]
 [0.451]
 [0.467]
 [0.101]
 [0.101]]
printing an ep nov before normalisation:  29.531264305114746
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.62987549746094
printing an ep nov before normalisation:  77.17296495591641
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.45 ]
 [33.169]
 [30.285]
 [44.734]
 [34.681]] [[0.593]
 [0.665]
 [0.544]
 [1.152]
 [0.729]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([0.9629, 0.0098, 0.0089, 0.0090, 0.0094], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9995,     0.0001,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9719,     0.0241,     0.0040],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0001,     0.0213,     0.8564,     0.1218],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0017,     0.0003,     0.0265,     0.6559,     0.3155],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  75.95565455593204
printing an ep nov before normalisation:  65.0915365634886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.9202594
printing an ep nov before normalisation:  42.78334877406958
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  3.21282141158008e-05
printing an ep nov before normalisation:  31.853957360568895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.914]
 [39.914]
 [63.21 ]
 [70.005]
 [39.914]] [[0.491]
 [0.491]
 [0.882]
 [0.996]
 [0.491]]
printing an ep nov before normalisation:  43.377968395803975
siam score:  -0.9232755
printing an ep nov before normalisation:  44.605136740016675
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.920188
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.16807051949695
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.715]
 [40.976]
 [40.976]
 [57.606]
 [40.976]] [[0.756]
 [0.54 ]
 [0.54 ]
 [0.909]
 [0.54 ]]
printing an ep nov before normalisation:  41.856055437709756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.8675120765149
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0006,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0048, 0.9334, 0.0094, 0.0253, 0.0270], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0002,     0.9188,     0.0654,     0.0155],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0005,     0.0002,     0.0107,     0.8697,     0.1189],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0006,     0.0003,     0.0257,     0.8316,     0.1419],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 -1.4470118492196272e-11
0.0 -1.0547704423443988e-11
0.0 -1.7077853530531394e-11
0.0 -1.045688778062146e-11
0.0 -1.580209592442184e-11
0.0 0.0
0.0 0.0
0.0 -9.868741898221768e-12
0.0 -1.075528531985685e-11
0.0 -1.0063348989552796e-11
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  94.93702617628915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.56789704195683
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.9246937
using explorer policy with actor:  1
printing an ep nov before normalisation:  77.64105236493408
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.63314284277226
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.724]
 [23.697]
 [37.626]
 [60.18 ]
 [23.697]] [[0.182]
 [0.097]
 [0.295]
 [0.615]
 [0.097]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.90606844958786
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9221276
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.54965506930587
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.276]
 [31.276]
 [31.276]
 [31.276]
 [31.276]] [[0.232]
 [0.232]
 [0.232]
 [0.232]
 [0.232]]
actions average: 
K:  0  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0009,     0.0078,     0.9899,     0.0005,     0.0009],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0010,     0.0002,     0.0173,     0.8862,     0.0953],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0017,     0.0005,     0.0398,     0.7075,     0.2505],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9974,     0.0000,     0.0000,     0.0010,     0.0015],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9996,     0.0000,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0002,     0.9450,     0.0435,     0.0112],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0002,     0.0113,     0.8834,     0.1049],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0003,     0.0005,     0.0426,     0.8059,     0.1506],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
siam score:  -0.91848207
printing an ep nov before normalisation:  67.78488696121903
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.279]
 [60.689]
 [69.322]
 [75.997]
 [60.689]] [[1.251]
 [1.041]
 [1.252]
 [1.415]
 [1.041]]
printing an ep nov before normalisation:  67.94308590276924
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.692]
 [32.692]
 [49.286]
 [40.969]
 [32.692]] [[0.329]
 [0.329]
 [0.647]
 [0.487]
 [0.329]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.891]
 [49.891]
 [58.124]
 [49.891]
 [49.891]] [[1.564]
 [1.564]
 [2.   ]
 [1.564]
 [1.564]]
line 256 mcts: sample exp_bonus 53.752569035028294
line 256 mcts: sample exp_bonus 59.68094158687804
siam score:  -0.9241322
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.54040317086094
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.072750091552734
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.211]
 [43.211]
 [57.502]
 [64.805]
 [43.211]] [[0.523]
 [0.523]
 [0.814]
 [0.962]
 [0.523]]
printing an ep nov before normalisation:  39.30647925115018
printing an ep nov before normalisation:  64.80704832974034
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.915]
 [41.915]
 [73.51 ]
 [65.58 ]
 [41.915]] [[0.721]
 [0.721]
 [1.53 ]
 [1.327]
 [0.721]]
printing an ep nov before normalisation:  52.18528773111303
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.22236592776896
printing an ep nov before normalisation:  93.41827307972557
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.15260578916904
printing an ep nov before normalisation:  53.170163484012065
printing an ep nov before normalisation:  25.533189353366232
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92994505
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.63103498029013
printing an ep nov before normalisation:  40.651496883333394
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.04875469207764
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.220326385657316
printing an ep nov before normalisation:  41.928011780514495
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  40.834300487752
printing an ep nov before normalisation:  70.59005922000333
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.12107856361092
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.903607404486294
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.718959174539
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.92107576
line 256 mcts: sample exp_bonus 20.78293740749359
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.042675920128833
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  73.82308486066292
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.158]
 [57.158]
 [70.551]
 [79.325]
 [57.158]] [[0.961]
 [0.961]
 [1.224]
 [1.397]
 [0.961]]
printing an ep nov before normalisation:  84.00882542731237
actions average: 
K:  1  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9799,     0.0123,     0.0002,     0.0074],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0082, 0.0078, 0.9103, 0.0495, 0.0242], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0010,     0.0005,     0.0307,     0.8826,     0.0851],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0018,     0.0006,     0.0007,     0.8207,     0.1763],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9818,     0.0000,     0.0000,     0.0108,     0.0073],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9969,     0.0004,     0.0000,     0.0026],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.9003,     0.0860,     0.0135],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0003,     0.0109,     0.8859,     0.1026],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0002,     0.0001,     0.0103,     0.6679,     0.3214],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9280289
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.338]
 [51.338]
 [65.927]
 [71.605]
 [51.338]] [[0.794]
 [0.794]
 [1.142]
 [1.277]
 [0.794]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.866]
 [93.866]
 [93.866]
 [96.736]
 [93.866]] [[1.611]
 [1.611]
 [1.611]
 [1.667]
 [1.611]]
printing an ep nov before normalisation:  63.5032104139294
printing an ep nov before normalisation:  73.71825968186748
printing an ep nov before normalisation:  85.3387769619242
printing an ep nov before normalisation:  42.768200281286475
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9231322
printing an ep nov before normalisation:  26.0663376123837
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.13907600746705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9973,     0.0000,     0.0000,     0.0017,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9996,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9377,     0.0531,     0.0091],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0011,     0.0004,     0.0293,     0.8327,     0.1366],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0048, 0.0030, 0.0358, 0.5558, 0.4006], grad_fn=<DivBackward0>)
actions average: 
K:  1  action  0 :  tensor([    0.9896,     0.0000,     0.0000,     0.0084,     0.0020],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9990,     0.0002,     0.0001,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9622,     0.0327,     0.0050],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0005,     0.0005,     0.0061,     0.8368,     0.1561],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0012, 0.0010, 0.0062, 0.6765, 0.3150], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  67.71228322947529
printing an ep nov before normalisation:  92.20681831126197
printing an ep nov before normalisation:  90.25403287927305
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.479]
 [60.479]
 [74.315]
 [76.424]
 [60.479]] [[1.262]
 [1.262]
 [1.635]
 [1.692]
 [1.262]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.1]
 [79.1]
 [79.1]
 [79.1]
 [79.1]] [[1.617]
 [1.617]
 [1.617]
 [1.617]
 [1.617]]
actions average: 
K:  1  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9964,     0.0020,     0.0001,     0.0013],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0002,     0.9107,     0.0652,     0.0239],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0006,     0.0003,     0.0160,     0.8752,     0.1079],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0008, 0.0056, 0.0379, 0.6057, 0.3500], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[89.61 ]
 [88.915]
 [67.063]
 [89.324]
 [67.063]] [[1.644]
 [1.628]
 [1.13 ]
 [1.638]
 [1.13 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.637]
 [43.637]
 [43.637]
 [75.24 ]
 [43.637]] [[0.692]
 [0.692]
 [0.692]
 [1.475]
 [0.692]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.52357543180559
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.53856182098389
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9210172
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.25812593474978
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.32653244662376
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.51336097717285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.47 ]
 [34.262]
 [34.706]
 [42.45 ]
 [26.505]] [[0.537]
 [0.508]
 [0.519]
 [0.704]
 [0.323]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.883]
 [31.9  ]
 [31.9  ]
 [34.57 ]
 [31.9  ]] [[0.144]
 [0.134]
 [0.134]
 [0.159]
 [0.134]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  93.74229202556863
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.261]
 [59.261]
 [72.799]
 [73.787]
 [59.261]] [[0.899]
 [0.899]
 [1.169]
 [1.189]
 [0.899]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.178]
 [44.65 ]
 [38.198]
 [54.426]
 [32.168]] [[0.271]
 [0.464]
 [0.356]
 [0.628]
 [0.254]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.973]
 [37.45 ]
 [35.533]
 [47.616]
 [32.056]] [[0.414]
 [0.446]
 [0.404]
 [0.67 ]
 [0.327]]
printing an ep nov before normalisation:  32.36526240924961
printing an ep nov before normalisation:  49.03890428658607
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.874721499977795
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 37.00941775665441
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92497116
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9241908
line 256 mcts: sample exp_bonus 22.39144245783488
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.9  ]
 [37.101]
 [42.534]
 [47.119]
 [41.243]] [[0.385]
 [0.35 ]
 [0.457]
 [0.547]
 [0.431]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.076]
 [43.076]
 [43.076]
 [65.701]
 [43.076]] [[0.513]
 [0.513]
 [0.513]
 [0.912]
 [0.513]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.919]
 [18.94 ]
 [18.94 ]
 [20.754]
 [18.94 ]] [[0.799]
 [0.159]
 [0.159]
 [0.188]
 [0.159]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  26.58376693725586
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  95.34148311444254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.051 0.026 0.026 0.872 0.026]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9981,     0.0002,     0.0000,     0.0005,     0.0013],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9993,     0.0002,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0004,     0.0329,     0.8809,     0.0485,     0.0373],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0004,     0.0418,     0.7975,     0.1599],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0405, 0.0031, 0.0828, 0.5260, 0.3476], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.026 0.026 0.051 0.795 0.103]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9246068
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.948581218719482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.103236198425293
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  98.97287404311803
siam score:  -0.91780245
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.4656361981979
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.075]
 [93.075]
 [93.075]
 [98.833]
 [93.075]] [[0.553]
 [0.553]
 [0.553]
 [0.591]
 [0.553]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.821]
 [24.821]
 [24.821]
 [24.821]
 [24.821]] [[0.099]
 [0.099]
 [0.099]
 [0.099]
 [0.099]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.02]
 [50.02]
 [50.02]
 [60.91]
 [50.02]] [[0.502]
 [0.502]
 [0.502]
 [0.667]
 [0.502]]
printing an ep nov before normalisation:  105.65465735107158
printing an ep nov before normalisation:  94.69250296312775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.464]
 [39.464]
 [47.277]
 [51.214]
 [39.464]] [[0.687]
 [0.687]
 [0.947]
 [1.077]
 [0.687]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 55.972218735134156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.4705306371204
printing an ep nov before normalisation:  69.10465285778452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  36.113831996917725
actions average: 
K:  0  action  0 :  tensor([    0.9038,     0.0004,     0.0005,     0.0789,     0.0164],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9210,     0.0678,     0.0112],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0001,     0.0276,     0.8594,     0.1126],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0081, 0.0010, 0.0009, 0.6243, 0.3656], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0003,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9831,     0.0025,     0.0144],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0014, 0.0010, 0.0280, 0.8878, 0.0819], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0019, 0.0018, 0.0498, 0.5746, 0.3719], grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9982,     0.0001,     0.0000,     0.0017],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.9373,     0.0365,     0.0258],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0017,     0.0007,     0.0217,     0.8845,     0.0913],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0023,     0.0012,     0.0001,     0.6847,     0.3117],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  48.03131431687337
printing an ep nov before normalisation:  83.22279417582992
siam score:  -0.9280126
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.246520042419434
printing an ep nov before normalisation:  89.91512678949718
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.011]
 [26.701]
 [26.701]
 [26.701]
 [26.701]] [[1.344]
 [0.854]
 [0.854]
 [0.854]
 [0.854]]
printing an ep nov before normalisation:  50.45267963602366
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.528990745544434
siam score:  -0.92361474
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.63723396792335
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.23661184310913
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9246306
printing an ep nov before normalisation:  42.37537402824791
printing an ep nov before normalisation:  90.78529416461964
printing an ep nov before normalisation:  40.7232732026418
actions average: 
K:  4  action  0 :  tensor([    0.9827,     0.0000,     0.0000,     0.0144,     0.0028],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9808,     0.0027,     0.0001,     0.0165],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9994,     0.0006,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0001,     0.0110,     0.9090,     0.0798],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0006, 0.0218, 0.0779, 0.4697, 0.4300], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  18.853529691696167
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.885881423950195
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9298431
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.53517278035481
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  67.63992799673663
printing an ep nov before normalisation:  80.09298567102152
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[81.054]
 [81.054]
 [81.054]
 [81.054]
 [81.054]] [[1.314]
 [1.314]
 [1.314]
 [1.314]
 [1.314]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.49014753049591
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.75853705676337
printing an ep nov before normalisation:  94.32252909832913
siam score:  -0.9251667
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[80.919]
 [80.919]
 [80.919]
 [84.572]
 [80.919]] [[1.402]
 [1.402]
 [1.402]
 [1.491]
 [1.402]]
siam score:  -0.92635226
printing an ep nov before normalisation:  49.54104392097815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.39790596638734
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.99092245101929
printing an ep nov before normalisation:  21.449110507965088
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.94 ]
 [51.731]
 [57.95 ]
 [68.581]
 [33.521]] [[0.358]
 [0.348]
 [0.399]
 [0.487]
 [0.199]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([0.9930, 0.0015, 0.0016, 0.0024, 0.0016], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9998,     0.0002,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0002,     0.0049,     0.8704,     0.1242],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0069, 0.0012, 0.0760, 0.5019, 0.4139], grad_fn=<DivBackward0>)
siam score:  -0.92710763
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9251831
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.119402695102494
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.74698231887056
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.42909670994918
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.677]
 [73.677]
 [73.677]
 [73.677]
 [73.677]] [[1.632]
 [1.632]
 [1.632]
 [1.632]
 [1.632]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.003]
 [39.003]
 [39.003]
 [57.237]
 [39.003]] [[0.573]
 [0.573]
 [0.573]
 [1.004]
 [0.573]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
siam score:  -0.92888147
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.636]
 [41.636]
 [41.636]
 [55.166]
 [41.636]] [[0.851]
 [0.851]
 [0.851]
 [1.254]
 [0.851]]
printing an ep nov before normalisation:  48.558618137280355
printing an ep nov before normalisation:  42.87862689663985
printing an ep nov before normalisation:  42.28891189258772
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.15011002984843
printing an ep nov before normalisation:  62.94790341424993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [20.954]
 [18.587]
 [35.889]] [[-0.106]
 [-0.106]
 [ 0.102]
 [ 0.078]
 [ 0.25 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.302]
 [35.302]
 [69.558]
 [68.855]
 [35.302]] [[0.173]
 [0.173]
 [0.453]
 [0.448]
 [0.173]]
printing an ep nov before normalisation:  87.4479524160551
printing an ep nov before normalisation:  23.123083708614324
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.703]
 [35.703]
 [35.703]
 [45.07 ]
 [35.703]] [[0.537]
 [0.537]
 [0.537]
 [0.815]
 [0.537]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.409198813759094
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.139]
 [66.139]
 [66.139]
 [72.546]
 [66.139]] [[0.875]
 [0.875]
 [0.875]
 [1.   ]
 [0.875]]
printing an ep nov before normalisation:  83.02666194673222
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.92734870752258
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.38005017646563
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.497]
 [41.966]
 [31.811]
 [24.115]
 [24.288]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  94.35931719443765
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.964324951171875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9261933
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.65663395293969
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  95.85580702402474
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.31555461883545
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.25741086308186
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.446]
 [33.489]
 [25.931]
 [54.973]
 [26.904]] [[0.175]
 [0.199]
 [0.108]
 [0.46 ]
 [0.12 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 64.60223405044987
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.21659061481368
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.883]
 [29.139]
 [23.913]
 [45.871]
 [23.48 ]] [[0.145]
 [0.222]
 [0.157]
 [0.429]
 [0.152]]
siam score:  -0.92999697
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.29738739057835
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.93019485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.026 0.026 0.179 0.513 0.256]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.746]
 [32.322]
 [29.17 ]
 [30.232]
 [29.17 ]] [[0.314]
 [0.215]
 [0.179]
 [0.191]
 [0.179]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.476]
 [23.66 ]
 [23.66 ]
 [70.297]
 [23.66 ]] [[0.152]
 [0.092]
 [0.092]
 [0.447]
 [0.092]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[     0.0000],
        [    -0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000],
        [     0.0000]], dtype=torch.float64)
0.0 8.220203594531192e-11
0.0 -2.5776636952841954e-20
0.0 1.7990344569781205e-11
0.0 3.5980689236224797e-11
0.0 0.0
0.0 6.19974951449788e-11
0.0 7.306847642017742e-11
0.0 8.05519904776311e-21
0.0 0.0
0.0 4.843554309913198e-12
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.441]
 [36.441]
 [36.441]
 [36.441]
 [36.441]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.194]
 [31.033]
 [70.584]
 [26.362]
 [29.74 ]] [[0.16 ]
 [0.398]
 [1.267]
 [0.295]
 [0.37 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  87.37303245936143
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.9277162
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  81.51704300574409
printing an ep nov before normalisation:  40.44947624206543
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.593]
 [40.593]
 [38.82 ]
 [62.036]
 [40.593]] [[0.582]
 [0.582]
 [0.539]
 [1.104]
 [0.582]]
printing an ep nov before normalisation:  99.47159633151772
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 67.54105656687852
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.888]
 [21.957]
 [21.957]
 [21.957]
 [21.957]] [[0.918]
 [0.47 ]
 [0.47 ]
 [0.47 ]
 [0.47 ]]
printing an ep nov before normalisation:  31.775222385018285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.393]
 [50.393]
 [50.393]
 [70.082]
 [50.393]] [[0.925]
 [0.925]
 [0.925]
 [1.443]
 [0.925]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.442]
 [25.208]
 [50.46 ]
 [30.677]
 [32.724]] [[0.653]
 [0.541]
 [1.083]
 [0.658]
 [0.702]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0030,     0.9753,     0.0086,     0.0006,     0.0126],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9011,     0.0770,     0.0219],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0004,     0.0002,     0.0130,     0.8685,     0.1179],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0007,     0.0005,     0.0268,     0.5616,     0.4103],
       grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 51.1932975761386
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.69488525390625
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  44.704878760606135
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.772]
 [65.772]
 [79.39 ]
 [82.183]
 [65.772]] [[0.641]
 [0.641]
 [0.805]
 [0.839]
 [0.641]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  97.08737441962593
printing an ep nov before normalisation:  96.54670143478728
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.039]
 [28.225]
 [53.276]
 [54.3  ]
 [26.574]] [[0.131]
 [0.157]
 [0.451]
 [0.463]
 [0.137]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.69602917821658
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.60290518906112
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.41 ]
 [27.422]
 [30.789]
 [32.203]
 [27.15 ]] [[0.245]
 [0.2  ]
 [0.251]
 [0.272]
 [0.196]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  69.77515061075754
printing an ep nov before normalisation:  32.99505693514844
printing an ep nov before normalisation:  41.063165203354636
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.213]
 [73.213]
 [73.213]
 [90.958]
 [73.213]] [[0.677]
 [0.677]
 [0.677]
 [0.875]
 [0.677]]
printing an ep nov before normalisation:  26.31698243254411
printing an ep nov before normalisation:  101.15319617781222
printing an ep nov before normalisation:  81.00451924370653
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.325]
 [12.325]
 [12.325]
 [71.24 ]
 [12.325]] [[0.037]
 [0.037]
 [0.037]
 [0.68 ]
 [0.037]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  110.48984269877653
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  32.181057929992676
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.575]
 [37.575]
 [50.45 ]
 [61.002]
 [50.384]] [[0.173]
 [0.173]
 [0.352]
 [0.498]
 [0.351]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.36686737429197
actions average: 
K:  2  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0003,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0009,     0.9705,     0.0011,     0.0034,     0.0241],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0003,     0.9279,     0.0525,     0.0192],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0002,     0.0083,     0.8902,     0.1012],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0163,     0.0344,     0.0003,     0.6878,     0.2612],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.561]
 [41.561]
 [41.561]
 [70.474]
 [41.561]] [[0.333]
 [0.333]
 [0.333]
 [0.697]
 [0.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.9195441900267
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  92.24359355830865
printing an ep nov before normalisation:  95.23416888279581
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.946]
 [62.946]
 [62.946]
 [87.788]
 [62.946]] [[0.521]
 [0.521]
 [0.521]
 [0.834]
 [0.521]]
printing an ep nov before normalisation:  97.7714435094006
siam score:  -0.9261242
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  73.41100752501806
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9257995
printing an ep nov before normalisation:  91.61924164796078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.81060081987451
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.873]
 [33.094]
 [28.635]
 [66.204]
 [26.015]] [[0.258]
 [0.236]
 [0.183]
 [0.635]
 [0.151]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.3358038956908
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.02587060645598
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.79986178778974
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 70.45229531928403
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.858]
 [34.407]
 [34.407]
 [34.407]
 [34.407]] [[1.461]
 [1.183]
 [1.183]
 [1.183]
 [1.183]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.416]
 [51.416]
 [51.416]
 [60.36 ]
 [51.416]] [[0.834]
 [0.834]
 [0.834]
 [1.047]
 [0.834]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.60226003862427
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.023]
 [55.023]
 [55.023]
 [70.586]
 [55.023]] [[0.742]
 [0.742]
 [0.742]
 [0.995]
 [0.742]]
printing an ep nov before normalisation:  41.545951377781655
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  18.737445250913808
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  93.02167527384091
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.47]
 [71.47]
 [71.47]
 [71.47]
 [71.47]] [[1.179]
 [1.179]
 [1.179]
 [1.179]
 [1.179]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9277278
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  102.67884869553144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  106.13344916098713
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.09819431452941
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.074]
 [45.074]
 [45.074]
 [71.174]
 [45.074]] [[0.335]
 [0.335]
 [0.335]
 [0.665]
 [0.335]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.462]
 [33.659]
 [29.158]
 [61.752]
 [28.726]] [[0.254]
 [0.213]
 [0.165]
 [0.513]
 [0.161]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 97.157]
 [ 97.157]
 [ 97.157]
 [102.305]
 [ 97.157]] [[0.945]
 [0.945]
 [0.945]
 [1.   ]
 [0.945]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[90.035]
 [90.035]
 [90.035]
 [90.035]
 [90.035]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.06 ]
 [74.06 ]
 [74.06 ]
 [83.583]
 [74.06 ]] [[1.152]
 [1.152]
 [1.152]
 [1.333]
 [1.152]]
printing an ep nov before normalisation:  26.762185096740723
printing an ep nov before normalisation:  68.60510115600363
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  98.80203422711718
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.722609519958496
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.035]
 [30.035]
 [30.035]
 [30.035]
 [30.035]] [[0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.440893280597795
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.602]
 [29.611]
 [20.867]
 [25.395]
 [26.417]] [[0.409]
 [0.193]
 [0.081]
 [0.139]
 [0.152]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.02 ]
 [33.254]
 [22.563]
 [50.777]
 [27.334]] [[0.497]
 [0.262]
 [0.12 ]
 [0.493]
 [0.183]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  94.8922422802638
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.34594624574213
printing an ep nov before normalisation:  38.830318544237024
printing an ep nov before normalisation:  29.917516708374023
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.04844639102539
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.5122994958115
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.11367264959843
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92622465
printing an ep nov before normalisation:  28.418654374348723
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.241]
 [73.241]
 [73.241]
 [73.241]
 [73.241]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.90395632583031
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.92613786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.84578021837673
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.003]
 [64.41 ]
 [63.152]
 [66.544]
 [53.362]] [[0.819]
 [0.751]
 [0.733]
 [0.783]
 [0.589]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.37146641549049
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  22.574045260747276
printing an ep nov before normalisation:  73.83567338647524
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[92.556]
 [92.556]
 [92.556]
 [92.556]
 [92.556]] [[0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  97.9047167761922
printing an ep nov before normalisation:  85.06511832420783
printing an ep nov before normalisation:  37.762696324923645
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  38.0847837948332
printing an ep nov before normalisation:  33.12567587754715
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.804588451601685
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.29081076117257
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9984,     0.0000,     0.0000,     0.0010,     0.0006],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9982,     0.0009,     0.0000,     0.0009],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9836,     0.0005,     0.0157],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0005,     0.0017,     0.0202,     0.8895,     0.0880],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0003,     0.0008,     0.0044,     0.4831,     0.5115],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 75.89556446640171
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.127416090036895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.93241966
printing an ep nov before normalisation:  25.568981170654297
UNIT TEST: sample policy line 217 mcts : [0.026 0.026 0.026 0.846 0.077]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9289722
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.494970341099354
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.217]
 [21.217]
 [52.195]
 [21.217]
 [21.217]] [[0.05 ]
 [0.05 ]
 [0.191]
 [0.05 ]
 [0.05 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.9887,     0.0030,     0.0003,     0.0052,     0.0028],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0001,     0.8981,     0.0845,     0.0172],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0002,     0.0252,     0.8515,     0.1229],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0006, 0.0012, 0.0137, 0.5954, 0.3892], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.472]
 [26.301]
 [37.614]
 [19.948]
 [19.356]] [[0.154]
 [0.256]
 [0.426]
 [0.161]
 [0.152]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.305292748921488
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[96.88 ]
 [70.517]
 [83.833]
 [89.195]
 [70.517]] [[0.939]
 [0.644]
 [0.793]
 [0.853]
 [0.644]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.124234471993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.78241012707961
printing an ep nov before normalisation:  78.94071394451228
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9988,     0.0000,     0.0000,     0.0011],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0003,     0.9536,     0.0271,     0.0189],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0009,     0.0003,     0.0209,     0.8703,     0.1076],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0011,     0.0004,     0.0338,     0.7907,     0.1740],
       grad_fn=<DivBackward0>)
using explorer policy with actor:  1
actions average: 
K:  1  action  0 :  tensor([    0.9993,     0.0000,     0.0000,     0.0005,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9976,     0.0002,     0.0000,     0.0021],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9266,     0.0615,     0.0119],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0031,     0.0002,     0.0227,     0.8245,     0.1495],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0017, 0.0046, 0.0509, 0.6849, 0.2580], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.144]
 [34.907]
 [53.582]
 [49.069]
 [36.223]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.975]
 [76.975]
 [76.975]
 [83.573]
 [76.975]] [[0.718]
 [0.718]
 [0.718]
 [0.788]
 [0.718]]
printing an ep nov before normalisation:  97.49018436945497
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  67.57522233070415
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.414]
 [18.414]
 [18.414]
 [71.13 ]
 [18.414]] [[0.107]
 [0.107]
 [0.107]
 [0.692]
 [0.107]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.90663587120481
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[89.398]
 [89.398]
 [89.398]
 [99.766]
 [89.398]] [[0.56 ]
 [0.56 ]
 [0.56 ]
 [0.636]
 [0.56 ]]
actions average: 
K:  1  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0006,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9980,     0.0004,     0.0001,     0.0013],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0011,     0.9748,     0.0039,     0.0202],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0011,     0.0003,     0.0332,     0.8519,     0.1135],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0311, 0.0553, 0.0037, 0.6714, 0.2385], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  102.51716700168103
printing an ep nov before normalisation:  80.82219287974618
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9300414
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 59.44371190172765
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.63]
 [36.63]
 [36.63]
 [58.72]
 [36.63]] [[0.491]
 [0.491]
 [0.491]
 [1.03 ]
 [0.491]]
printing an ep nov before normalisation:  48.29073577889257
printing an ep nov before normalisation:  86.47686168598501
printing an ep nov before normalisation:  59.85198313678774
siam score:  -0.924863
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.685]
 [49.685]
 [68.67 ]
 [69.659]
 [49.685]] [[0.6  ]
 [0.6  ]
 [0.972]
 [0.991]
 [0.6  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.103]
 [44.103]
 [44.103]
 [71.354]
 [44.103]] [[0.574]
 [0.574]
 [0.574]
 [1.053]
 [0.574]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.70199637419672
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[91.321]
 [74.756]
 [80.666]
 [85.994]
 [74.756]] [[0.615]
 [0.485]
 [0.532]
 [0.573]
 [0.485]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9986,     0.0000,     0.0000,     0.0011,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9987,     0.0004,     0.0000,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9305,     0.0606,     0.0089],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0003,     0.0051,     0.8640,     0.1303],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0024, 0.0498, 0.0332, 0.5710, 0.3436], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.03]
 [85.03]
 [85.03]
 [85.03]
 [85.03]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
actions average: 
K:  2  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0006,     0.9973,     0.0002,     0.0000,     0.0019],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0002,     0.0011,     0.9347,     0.0359,     0.0281],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0012,     0.0001,     0.0283,     0.8444,     0.1260],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0021,     0.0004,     0.0002,     0.6864,     0.3109],
       grad_fn=<DivBackward0>)
siam score:  -0.9197363
printing an ep nov before normalisation:  74.24122802333915
printing an ep nov before normalisation:  97.17168852870898
printing an ep nov before normalisation:  45.59185981750488
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.736]
 [42.87 ]
 [43.396]
 [54.24 ]
 [44.861]] [[0.236]
 [0.181]
 [0.185]
 [0.273]
 [0.197]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9261618
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9289418
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.338]
 [38.873]
 [38.501]
 [53.587]
 [36.813]] [[0.544]
 [0.559]
 [0.549]
 [0.953]
 [0.503]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.649]
 [65.649]
 [65.649]
 [74.328]
 [65.649]] [[1.249]
 [1.249]
 [1.249]
 [1.463]
 [1.249]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.14471480165052
printing an ep nov before normalisation:  75.16132391258625
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.97600352179454
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.2270366943307
siam score:  -0.9353978
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.383]
 [22.219]
 [22.219]
 [23.944]
 [22.219]] [[0.674]
 [0.193]
 [0.193]
 [0.221]
 [0.193]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.890793068923436
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.19412980234014
printing an ep nov before normalisation:  37.696603082469224
printing an ep nov before normalisation:  21.318256567165875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.97272923674626
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.077]
 [22.077]
 [22.077]
 [70.182]
 [22.077]] [[0.113]
 [0.113]
 [0.113]
 [0.687]
 [0.113]]
printing an ep nov before normalisation:  32.370663783911695
printing an ep nov before normalisation:  86.2814044302825
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.325]
 [66.325]
 [66.325]
 [78.313]
 [66.325]] [[0.738]
 [0.738]
 [0.738]
 [0.903]
 [0.738]]
line 256 mcts: sample exp_bonus 86.18061114872168
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  41.04422033619386
siam score:  -0.92449784
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.666]
 [21.666]
 [21.666]
 [54.705]
 [21.666]] [[0.19 ]
 [0.19 ]
 [0.19 ]
 [0.677]
 [0.19 ]]
printing an ep nov before normalisation:  72.26981227636962
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.176707619262615
printing an ep nov before normalisation:  91.37741914537465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[89.096]
 [89.096]
 [89.096]
 [91.935]
 [89.096]] [[0.965]
 [0.965]
 [0.965]
 [1.   ]
 [0.965]]
printing an ep nov before normalisation:  24.116703710121374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  93.7027517194215
printing an ep nov before normalisation:  89.06056244146735
printing an ep nov before normalisation:  18.464031219482422
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.32 ]
 [30.283]
 [19.197]
 [65.494]
 [17.394]] [[0.144]
 [0.213]
 [0.085]
 [0.621]
 [0.064]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.50051196656162
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  97.29294791985166
printing an ep nov before normalisation:  41.17406822026754
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.631]
 [93.631]
 [93.631]
 [93.631]
 [93.631]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
printing an ep nov before normalisation:  71.44405113298706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  101.80720609317554
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.71828668948776
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  87.7200576657806
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.279]
 [68.273]
 [68.273]
 [81.068]
 [68.273]] [[1.658]
 [1.426]
 [1.426]
 [1.756]
 [1.426]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[81.802]
 [69.492]
 [69.492]
 [69.492]
 [69.492]] [[1.772]
 [1.455]
 [1.455]
 [1.455]
 [1.455]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.50412381479454
printing an ep nov before normalisation:  62.64136907629308
printing an ep nov before normalisation:  86.66411708327439
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[80.998]
 [80.998]
 [80.998]
 [80.998]
 [80.998]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.945890970853284
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  91.2196441662401
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.24688310949088
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.472923846310568
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.28309325531915
printing an ep nov before normalisation:  41.97937506389629
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.375]
 [27.433]
 [27.433]
 [51.229]
 [27.433]] [[0.39 ]
 [0.276]
 [0.276]
 [0.732]
 [0.276]]
printing an ep nov before normalisation:  25.802400769904033
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  64.31595385942461
printing an ep nov before normalisation:  100.25999133943782
printing an ep nov before normalisation:  72.62540452246074
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.579]
 [51.579]
 [51.579]
 [72.732]
 [51.579]] [[0.843]
 [0.843]
 [0.843]
 [1.318]
 [0.843]]
line 256 mcts: sample exp_bonus 71.30309924486122
siam score:  -0.9264584
siam score:  -0.92482895
actions average: 
K:  2  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9998,     0.0001,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9999,     0.0001,     0.0000],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0001,     0.0190,     0.9008,     0.0799],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0004,     0.0003,     0.0003,     0.7622,     0.2368],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.8]
 [69.8]
 [69.8]
 [69.8]
 [69.8]] [[1.245]
 [1.245]
 [1.245]
 [1.245]
 [1.245]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.4392665992052
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.84821809791495
printing an ep nov before normalisation:  73.54485644741162
line 256 mcts: sample exp_bonus 51.20603535079727
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  73.8225756597315
printing an ep nov before normalisation:  85.21937855752704
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  60.284012401307805
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.042]
 [66.042]
 [66.042]
 [84.454]
 [66.042]] [[0.825]
 [0.825]
 [0.825]
 [1.152]
 [0.825]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.04771471908423
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.20144834429725
siam score:  -0.9191434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.553]
 [26.796]
 [26.796]
 [30.611]
 [26.796]] [[0.859]
 [0.338]
 [0.338]
 [0.419]
 [0.338]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9258121
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.447]
 [31.447]
 [60.617]
 [63.806]
 [31.447]] [[0.342]
 [0.342]
 [0.865]
 [0.922]
 [0.342]]
printing an ep nov before normalisation:  78.00051122126719
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.92468809359786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.99764484598383
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.853]
 [34.853]
 [34.853]
 [34.853]
 [34.853]] [[0.891]
 [0.891]
 [0.891]
 [0.891]
 [0.891]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.091]
 [34.338]
 [27.233]
 [28.934]
 [29.885]] [[1.163]
 [1.061]
 [0.646]
 [0.746]
 [0.801]]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 4.2367261452394046e-10
0.0 1.6946904581086501e-09
0.0 8.880310852063649e-10
0.0 2.1596716715509976e-09
0.0 8.023693676814253e-10
0.0 2.6199477178262074e-09
0.0 3.4780179601759497e-10
0.0 0.0
0.0 9.765989353821771e-10
0.0 0.0
using explorer policy with actor:  1
siam score:  -0.9285625
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9292485
printing an ep nov before normalisation:  0.0006315953990565504
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  84.03905849826465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.228682860891816
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.381]
 [25.935]
 [24.427]
 [45.986]
 [24.434]] [[0.345]
 [0.388]
 [0.347]
 [0.944]
 [0.347]]
printing an ep nov before normalisation:  30.206522941589355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.49 ]
 [36.877]
 [36.877]
 [32.986]
 [36.877]] [[1.062]
 [0.58 ]
 [0.58 ]
 [0.489]
 [0.58 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.112]
 [75.112]
 [81.185]
 [82.309]
 [75.112]] [[0.808]
 [0.808]
 [0.888]
 [0.903]
 [0.808]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 74.68263061332094
printing an ep nov before normalisation:  28.805694580078125
printing an ep nov before normalisation:  85.71975960984749
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.177]
 [63.523]
 [63.523]
 [75.818]
 [63.523]] [[0.884]
 [0.606]
 [0.606]
 [0.757]
 [0.606]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0003,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9994,     0.0000,     0.0000,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9460,     0.0472,     0.0068],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0001,     0.0125,     0.8440,     0.1432],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0002,     0.0002,     0.0381,     0.8293,     0.1323],
       grad_fn=<DivBackward0>)
siam score:  -0.9291379
printing an ep nov before normalisation:  79.98190353590813
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9297728
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.462]
 [50.462]
 [50.462]
 [58.556]
 [50.462]] [[1.298]
 [1.298]
 [1.298]
 [1.648]
 [1.298]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 59.8702072122644
printing an ep nov before normalisation:  73.07470006725421
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.01286472115098
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.687]
 [30.911]
 [31.464]
 [29.732]
 [28.841]] [[1.109]
 [1.288]
 [1.333]
 [1.193]
 [1.121]]
printing an ep nov before normalisation:  77.48885060106767
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.476]
 [84.476]
 [84.476]
 [84.476]
 [84.476]] [[1.891]
 [1.891]
 [1.891]
 [1.891]
 [1.891]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.324705123901367
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.72285616043507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  82.15419051199106
siam score:  -0.92594343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.81751527438266
using explorer policy with actor:  1
printing an ep nov before normalisation:  96.98808607565286
printing an ep nov before normalisation:  77.3824634107904
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.17418846698317
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92382514
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  97.54779436529049
siam score:  -0.92512137
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9267254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.995]
 [37.628]
 [30.561]
 [51.419]
 [35.602]] [[1.004]
 [0.559]
 [0.355]
 [0.959]
 [0.501]]
printing an ep nov before normalisation:  74.38442423290576
printing an ep nov before normalisation:  47.16019580487376
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.497387409210205
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  90.97503931887944
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.814]
 [26.664]
 [21.236]
 [21.656]
 [21.21 ]] [[1.101]
 [1.333]
 [0.891]
 [0.925]
 [0.889]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.68480886232783
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.28786277770996
printing an ep nov before normalisation:  16.54697761744752
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.978]
 [17.145]
 [17.145]
 [19.684]
 [17.145]] [[0.326]
 [0.198]
 [0.198]
 [0.254]
 [0.198]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.217537770676365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  29.365982163193905
printing an ep nov before normalisation:  29.447849646150114
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  23.814917152091564
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.21976772935062
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.937]
 [44.937]
 [44.937]
 [44.937]
 [44.937]] [[0.243]
 [0.243]
 [0.243]
 [0.243]
 [0.243]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.96938546785587
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9988,     0.0000,     0.0000,     0.0009,     0.0004],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9981,     0.0006,     0.0002,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9978,     0.0011,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0009,     0.0004,     0.0325,     0.8383,     0.1279],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0180,     0.0007,     0.0004,     0.5352,     0.4458],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.31285362042598
printing an ep nov before normalisation:  92.19877670782517
printing an ep nov before normalisation:  74.63702512355454
printing an ep nov before normalisation:  84.08626516480318
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.92925566
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([0.9648, 0.0091, 0.0039, 0.0170, 0.0052], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9873,     0.0065,     0.0004,     0.0059],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9834,     0.0078,     0.0087],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0007,     0.0002,     0.0197,     0.9041,     0.0753],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0019, 0.0038, 0.0775, 0.3972, 0.5196], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  77.77080363124504
printing an ep nov before normalisation:  101.91640418765897
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.345]
 [28.345]
 [28.345]
 [75.343]
 [28.345]] [[0.199]
 [0.199]
 [0.199]
 [0.728]
 [0.199]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  92.18042391577404
printing an ep nov before normalisation:  50.13792433657027
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.138]
 [49.138]
 [49.138]
 [64.838]
 [49.138]] [[0.556]
 [0.556]
 [0.556]
 [0.859]
 [0.556]]
printing an ep nov before normalisation:  42.73795900898824
printing an ep nov before normalisation:  35.86087352809528
actions average: 
K:  1  action  0 :  tensor([    0.8849,     0.0419,     0.0001,     0.0025,     0.0706],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9997,     0.0001,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9097,     0.0848,     0.0055],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0398,     0.0001,     0.0437,     0.7889,     0.1275],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0513,     0.0002,     0.0548,     0.6167,     0.2770],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  63.69102328937011
printing an ep nov before normalisation:  103.27948032520746
printing an ep nov before normalisation:  97.69948460087952
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.046]
 [45.046]
 [45.046]
 [62.826]
 [45.046]] [[0.511]
 [0.511]
 [0.511]
 [0.837]
 [0.511]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.719420719030822
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.603]
 [33.603]
 [33.603]
 [17.043]
 [33.603]] [[2.851]
 [2.851]
 [2.851]
 [1.   ]
 [2.851]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.88355630573356
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.54844879150915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.380068603887885
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.853]
 [41.853]
 [42.12 ]
 [37.492]
 [41.853]] [[1.417]
 [1.417]
 [1.434]
 [1.143]
 [1.417]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.558]
 [67.558]
 [67.558]
 [67.558]
 [67.558]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.279]
 [51.279]
 [51.279]
 [62.602]
 [51.279]] [[0.93 ]
 [0.93 ]
 [0.93 ]
 [1.212]
 [0.93 ]]
printing an ep nov before normalisation:  28.042209148406982
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.26988754360597
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 56.90255571238606
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.727120506050774
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[89.151]
 [89.151]
 [89.151]
 [89.151]
 [89.151]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.90480427115727
siam score:  -0.92845476
printing an ep nov before normalisation:  78.20119007415484
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.182]
 [45.182]
 [47.77 ]
 [64.901]
 [45.182]] [[0.75 ]
 [0.75 ]
 [0.824]
 [1.313]
 [0.75 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.6364073989578
printing an ep nov before normalisation:  63.78054184452759
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.80434714026063
siam score:  -0.9316943
printing an ep nov before normalisation:  22.878910374900162
printing an ep nov before normalisation:  28.551579965355835
printing an ep nov before normalisation:  26.323851987055242
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.02309153042602
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 77.76574175731605
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.445]
 [46.776]
 [46.776]
 [76.182]
 [46.776]] [[1.283]
 [0.73 ]
 [0.73 ]
 [1.364]
 [0.73 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.233]
 [40.233]
 [54.581]
 [57.845]
 [40.233]] [[0.626]
 [0.626]
 [0.987]
 [1.07 ]
 [0.626]]
printing an ep nov before normalisation:  81.98983360201221
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9304448
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  31.987859307968304
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.442]
 [32.925]
 [31.301]
 [33.458]
 [33.258]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  46.91813815958512
printing an ep nov before normalisation:  72.5546101846791
printing an ep nov before normalisation:  84.9174856887891
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.92571485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.05679316641893
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.929]
 [50.929]
 [50.929]
 [67.815]
 [50.929]] [[0.591]
 [0.591]
 [0.591]
 [0.855]
 [0.591]]
printing an ep nov before normalisation:  26.18046760559082
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.59  0.026 0.051 0.282 0.051]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.75193989593055
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 74.57773443490674
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.93953763357639
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.26401021086394
actions average: 
K:  2  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0005,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9993,     0.0002,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0001,     0.9194,     0.0679,     0.0125],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0007,     0.0001,     0.0163,     0.8869,     0.0960],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0005,     0.0004,     0.0260,     0.6938,     0.2794],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  68.50632893632502
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.2929360444873
UNIT TEST: sample policy line 217 mcts : [0.026 0.897 0.026 0.026 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  96.00509999478263
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.355]
 [51.355]
 [78.14 ]
 [74.49 ]
 [51.355]] [[0.861]
 [0.861]
 [1.407]
 [1.332]
 [0.861]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.201]
 [27.201]
 [35.717]
 [60.349]
 [27.201]] [[0.352]
 [0.352]
 [0.525]
 [1.023]
 [0.352]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.48]
 [87.48]
 [87.51]
 [87.48]
 [87.48]] [[1.4  ]
 [1.4  ]
 [1.401]
 [1.4  ]
 [1.4  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9676,     0.0291,     0.0033],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0001,     0.0107,     0.8766,     0.1121],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0015, 0.0046, 0.0249, 0.6997, 0.2693], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.22]
 [87.22]
 [87.22]
 [87.22]
 [87.22]] [[0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.869481044745946
printing an ep nov before normalisation:  30.39200140990956
printing an ep nov before normalisation:  96.68212626483347
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.583807468414307
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.58733356788169
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.29334520989786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.83453383431076
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  18.29517533452165
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.08438501193772
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.845381483899033
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.92389375
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  77.61648877550019
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.16855727775428
printing an ep nov before normalisation:  51.284873045272064
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.94 ]
 [32.94 ]
 [32.94 ]
 [41.216]
 [32.94 ]] [[0.813]
 [0.813]
 [0.813]
 [1.16 ]
 [0.813]]
printing an ep nov before normalisation:  36.55512832372026
printing an ep nov before normalisation:  17.70766923205111
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.24436094930277
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9964,     0.0000,     0.0000,     0.0025,     0.0010],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9986,     0.0002,     0.0000,     0.0012],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9583,     0.0388,     0.0029],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0001,     0.0233,     0.8687,     0.1078],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0031, 0.0293, 0.0088, 0.4000, 0.5587], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  61.64282303326796
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.222]
 [63.222]
 [63.222]
 [76.846]
 [63.222]] [[0.612]
 [0.612]
 [0.612]
 [0.787]
 [0.612]]
printing an ep nov before normalisation:  73.46713010325362
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.92806596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.489]
 [45.489]
 [58.773]
 [65.34 ]
 [45.489]] [[0.652]
 [0.652]
 [0.908]
 [1.034]
 [0.652]]
printing an ep nov before normalisation:  83.54067447117494
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  16.06319785118103
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9302552
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9283853
printing an ep nov before normalisation:  64.63979467112385
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.69 ]
 [16.69 ]
 [16.69 ]
 [59.786]
 [16.69 ]] [[0.076]
 [0.076]
 [0.076]
 [0.452]
 [0.076]]
printing an ep nov before normalisation:  88.72675841654042
printing an ep nov before normalisation:  29.76317075874089
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.876]
 [51.891]
 [71.132]
 [68.342]
 [49.133]] [[0.279]
 [0.327]
 [0.48 ]
 [0.458]
 [0.305]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  18.594971451101348
printing an ep nov before normalisation:  80.84153439140229
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.58438686184954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.38458413413149
printing an ep nov before normalisation:  36.90611455845556
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.70089830710861
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.757]
 [83.757]
 [83.757]
 [83.757]
 [83.757]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0289, 0.9570, 0.0082, 0.0021, 0.0037], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9303,     0.0614,     0.0083],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0000,     0.0096,     0.9038,     0.0862],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0039, 0.0066, 0.0218, 0.8044, 0.1633], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.856574737940484
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  16.231126556132956
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.607120990753174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92133486
printing an ep nov before normalisation:  43.08145511746006
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9983,     0.0002,     0.0000,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9998,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0002,     0.0246,     0.8926,     0.0824],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0018,     0.0003,     0.0005,     0.7151,     0.2823],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.84926500340374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9208915
printing an ep nov before normalisation:  77.26667765928751
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  3.716484684446186e-05
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92339206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.037935911679185
printing an ep nov before normalisation:  45.85451204305911
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0004,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9996,     0.0001,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9650,     0.0317,     0.0033],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0000,     0.0128,     0.8845,     0.1024],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0005,     0.0060,     0.0077,     0.5771,     0.4087],
       grad_fn=<DivBackward0>)
siam score:  -0.9240703
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.052987885399965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.198]
 [25.891]
 [23.614]
 [33.024]
 [22.263]] [[0.506]
 [0.248]
 [0.215]
 [0.348]
 [0.196]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.178]
 [46.178]
 [55.326]
 [72.969]
 [46.178]] [[0.406]
 [0.406]
 [0.527]
 [0.76 ]
 [0.406]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  69.47413034005062
printing an ep nov before normalisation:  33.38130136863807
printing an ep nov before normalisation:  84.3154058632343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.218]
 [18.623]
 [15.523]
 [45.459]
 [10.505]] [[0.115]
 [0.189]
 [0.147]
 [0.559]
 [0.078]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.126]
 [66.442]
 [66.442]
 [66.911]
 [66.442]] [[0.971]
 [0.86 ]
 [0.86 ]
 [0.867]
 [0.86 ]]
printing an ep nov before normalisation:  18.589695692062378
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.457]
 [26.457]
 [26.457]
 [26.457]
 [26.457]] [[0.261]
 [0.261]
 [0.261]
 [0.261]
 [0.261]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.839]
 [60.869]
 [60.869]
 [66.218]
 [60.869]] [[0.594]
 [0.509]
 [0.509]
 [0.56 ]
 [0.509]]
printing an ep nov before normalisation:  55.66917961237699
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.56335046547458
printing an ep nov before normalisation:  90.07207899046576
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.897]
 [15.897]
 [15.897]
 [45.702]
 [15.897]] [[0.134]
 [0.134]
 [0.134]
 [0.614]
 [0.134]]
printing an ep nov before normalisation:  75.7984834003215
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.27114096300065
printing an ep nov before normalisation:  24.829931259155273
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.976]
 [49.976]
 [62.065]
 [67.02 ]
 [49.976]] [[0.361]
 [0.361]
 [0.47 ]
 [0.514]
 [0.361]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.003]
 [67.003]
 [77.036]
 [75.768]
 [67.003]] [[1.213]
 [1.213]
 [1.455]
 [1.424]
 [1.213]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.86 ]
 [24.86 ]
 [64.699]
 [24.826]
 [24.86 ]] [[0.236]
 [0.236]
 [0.888]
 [0.235]
 [0.236]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.086]
 [29.789]
 [21.436]
 [58.24 ]
 [26.973]] [[0.194]
 [0.142]
 [0.073]
 [0.377]
 [0.119]]
printing an ep nov before normalisation:  27.128727534425824
printing an ep nov before normalisation:  87.0346432728165
siam score:  -0.93157774
siam score:  -0.93102264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  41.88824649421489
printing an ep nov before normalisation:  60.26923556438193
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9955,     0.0000,     0.0000,     0.0034,     0.0011],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9889,     0.0051,     0.0008,     0.0052],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9976,     0.0022,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0003,     0.0204,     0.8805,     0.0981],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0007, 0.0016, 0.0215, 0.6327, 0.3435], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  62.75315455696776
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.19 ]
 [35.19 ]
 [65.42 ]
 [42.517]
 [35.19 ]] [[0.454]
 [0.454]
 [1.128]
 [0.617]
 [0.454]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.55343083413752
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.81670841141352
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.02371380173365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  65.57020056120551
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.12 ]
 [39.12 ]
 [45.671]
 [61.41 ]
 [39.12 ]] [[0.679]
 [0.679]
 [0.86 ]
 [1.295]
 [0.679]]
printing an ep nov before normalisation:  32.213132598859715
printing an ep nov before normalisation:  63.65154128956178
printing an ep nov before normalisation:  64.41667525361237
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.108]
 [44.108]
 [44.108]
 [66.619]
 [44.108]] [[0.386]
 [0.386]
 [0.386]
 [0.667]
 [0.386]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92598337
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.083]
 [41.083]
 [41.083]
 [41.083]
 [41.083]] [[82.165]
 [82.165]
 [82.165]
 [82.165]
 [82.165]]
UNIT TEST: sample policy line 217 mcts : [0.026 0.051 0.872 0.026 0.026]
printing an ep nov before normalisation:  47.103049575691536
printing an ep nov before normalisation:  93.02016656004004
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.44684151169201
printing an ep nov before normalisation:  43.47401754243379
printing an ep nov before normalisation:  71.80053700179269
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.224]
 [28.224]
 [28.224]
 [45.558]
 [28.224]] [[0.337]
 [0.337]
 [0.337]
 [0.701]
 [0.337]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.26811169338391
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.06 ]
 [21.954]
 [44.46 ]
 [22.154]
 [21.974]] [[0.201]
 [0.25 ]
 [0.842]
 [0.256]
 [0.251]]
printing an ep nov before normalisation:  31.839818954467773
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.71011972427368
printing an ep nov before normalisation:  37.1760583524918
siam score:  -0.93096185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.664118829195615
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.871]
 [23.596]
 [24.564]
 [22.925]
 [22.045]] [[0.939]
 [0.542]
 [0.564]
 [0.526]
 [0.506]]
printing an ep nov before normalisation:  39.85447883605957
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  19.286561012268066
printing an ep nov before normalisation:  47.64403794511367
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.252984758596575
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.25 ]
 [29.652]
 [28.446]
 [31.5  ]
 [21.906]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.482]
 [48.729]
 [55.242]
 [66.586]
 [48.729]] [[0.965]
 [0.769]
 [0.958]
 [1.286]
 [0.769]]
siam score:  -0.9295745
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.186]
 [31.211]
 [28.686]
 [26.355]
 [21.293]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.93108386
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.351661629288465
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.041]
 [38.009]
 [38.009]
 [58.455]
 [38.009]] [[0.812]
 [0.635]
 [0.635]
 [1.233]
 [0.635]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  63.03989087458994
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.300782506114047
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.392]
 [28.29 ]
 [28.29 ]
 [29.469]
 [28.29 ]] [[1.128]
 [0.57 ]
 [0.57 ]
 [0.609]
 [0.57 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.90174811332616
printing an ep nov before normalisation:  81.93701168538223
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.06060610495459
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 2.589502519314578e-09
0.0 2.1213383988729755e-09
0.0 4.15992121278811e-09
0.0 2.7800617845443025e-09
0.0 1.6487458858993832e-09
0.0 1.0314002927037544e-09
0.0 1.3625610199751303e-09
0.0 3.4477803424844102e-09
0.0 8.114337336170476e-10
0.0 2.0611399382474834e-09
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  67.99012807876692
printing an ep nov before normalisation:  43.94543268960547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.13905222907587
printing an ep nov before normalisation:  23.084301948547363
printing an ep nov before normalisation:  33.631815910339355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.784]
 [42.784]
 [69.332]
 [61.748]
 [42.784]] [[0.337]
 [0.337]
 [0.596]
 [0.522]
 [0.337]]
printing an ep nov before normalisation:  64.64868764410964
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9808,     0.0000,     0.0000,     0.0164,     0.0028],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0006,     0.9824,     0.0035,     0.0003,     0.0132],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.8375,     0.1468,     0.0156],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0007,     0.0001,     0.0443,     0.8676,     0.0874],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0005,     0.0017,     0.0843,     0.2637,     0.6498],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.823]
 [19.823]
 [19.823]
 [71.83 ]
 [19.823]] [[0.075]
 [0.075]
 [0.075]
 [0.452]
 [0.075]]
printing an ep nov before normalisation:  59.726797310013865
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.239]
 [26.239]
 [62.835]
 [64.313]
 [26.239]] [[0.241]
 [0.241]
 [0.879]
 [0.905]
 [0.241]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.594]
 [53.594]
 [53.594]
 [76.288]
 [53.594]] [[0.786]
 [0.786]
 [0.786]
 [1.195]
 [0.786]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.968]
 [36.062]
 [46.19 ]
 [31.467]
 [28.467]] [[0.38 ]
 [0.45 ]
 [0.678]
 [0.346]
 [0.279]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.374]
 [77.374]
 [77.374]
 [75.821]
 [77.374]] [[0.84 ]
 [0.84 ]
 [0.84 ]
 [0.821]
 [0.84 ]]
siam score:  -0.9276529
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.664]
 [34.664]
 [34.664]
 [53.31 ]
 [34.664]] [[0.253]
 [0.253]
 [0.253]
 [0.512]
 [0.253]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.409]
 [34.409]
 [34.586]
 [34.409]
 [34.409]] [[0.238]
 [0.238]
 [0.241]
 [0.238]
 [0.238]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.907]
 [86.907]
 [86.907]
 [86.907]
 [86.907]] [[0.968]
 [0.968]
 [0.968]
 [0.968]
 [0.968]]
printing an ep nov before normalisation:  82.56905840320763
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  87.99498508130334
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.69174312070106
printing an ep nov before normalisation:  60.435290458693096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.941]
 [25.332]
 [29.189]
 [65.218]
 [14.117]] [[0.157]
 [0.193]
 [0.234]
 [0.617]
 [0.074]]
printing an ep nov before normalisation:  83.53846454944467
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.673]
 [54.673]
 [54.673]
 [82.802]
 [54.673]] [[0.532]
 [0.532]
 [0.532]
 [0.843]
 [0.532]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.95626518450332
siam score:  -0.9375809
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9372499
printing an ep nov before normalisation:  105.59152026068088
printing an ep nov before normalisation:  101.81038786470734
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.8013520751438
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9992,     0.0002,     0.0000,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9162,     0.0745,     0.0092],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0003,     0.0325,     0.8799,     0.0870],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0003,     0.0117,     0.0549,     0.4922,     0.4410],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.694]
 [46.694]
 [46.694]
 [71.135]
 [46.694]] [[0.331]
 [0.331]
 [0.331]
 [0.556]
 [0.331]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.17881062850656
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.278]
 [25.028]
 [25.83 ]
 [62.261]
 [21.283]] [[0.197]
 [0.17 ]
 [0.18 ]
 [0.609]
 [0.126]]
line 256 mcts: sample exp_bonus 93.61574451238886
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0004,     0.9296,     0.0007,     0.0648,     0.0045],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9672,     0.0286,     0.0042],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0001,     0.0128,     0.8899,     0.0970],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0412, 0.0070, 0.0125, 0.7025, 0.2368], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00019498219785418772
printing an ep nov before normalisation:  40.03702893893233
printing an ep nov before normalisation:  69.36315212778459
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.25494300891137
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.946999919582264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  15.326840877532959
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.98 ]
 [87.42 ]
 [85.894]
 [90.377]
 [85.894]] [[1.695]
 [1.706]
 [1.667]
 [1.782]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.68162487703755
printing an ep nov before normalisation:  42.483819110884326
printing an ep nov before normalisation:  57.29806397202286
actions average: 
K:  4  action  0 :  tensor([    0.9986,     0.0000,     0.0000,     0.0008,     0.0007],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9888,     0.0015,     0.0006,     0.0090],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9976,     0.0020,     0.0005],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0009,     0.0003,     0.0138,     0.8583,     0.1267],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0018,     0.0277,     0.6966,     0.2736],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.915]
 [42.915]
 [42.915]
 [80.1  ]
 [42.915]] [[0.237]
 [0.237]
 [0.237]
 [0.486]
 [0.237]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9939,     0.0014,     0.0000,     0.0000,     0.0047],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9989,     0.0003,     0.0001,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9620,     0.0336,     0.0044],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0003,     0.0184,     0.8594,     0.1217],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0020,     0.0001,     0.0001,     0.6572,     0.3405],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  95.75248900417591
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.21798038482666
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
actions average: 
K:  2  action  0 :  tensor([    0.9575,     0.0007,     0.0000,     0.0006,     0.0411],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.8917,     0.0783,     0.0299],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0008,     0.0016,     0.0164,     0.8462,     0.1350],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0189, 0.0013, 0.0314, 0.7516, 0.1969], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.316]
 [56.801]
 [56.801]
 [56.801]
 [56.801]] [[1.226]
 [0.867]
 [0.867]
 [0.867]
 [0.867]]
printing an ep nov before normalisation:  40.45180320739746
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.15176827339128
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.29884004974798
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.193]
 [28.428]
 [30.641]
 [59.394]
 [20.455]] [[0.174]
 [0.212]
 [0.238]
 [0.576]
 [0.119]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.218]
 [26.218]
 [26.218]
 [71.88 ]
 [26.218]] [[0.168]
 [0.168]
 [0.168]
 [0.685]
 [0.168]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.92697392231072
printing an ep nov before normalisation:  91.40186358595709
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.50344467163086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.43408020818806
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  74.11471006052159
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.79826929799729
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.01739820966152
printing an ep nov before normalisation:  64.05078519148388
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9994,     0.0000,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9648,     0.0314,     0.0038],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0002,     0.0096,     0.8868,     0.1030],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0010,     0.0004,     0.0307,     0.5791,     0.3888],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.42472511539961
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.035]
 [26.035]
 [26.035]
 [61.995]
 [26.035]] [[0.218]
 [0.218]
 [0.218]
 [0.668]
 [0.218]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.483]
 [29.433]
 [33.29 ]
 [64.407]
 [23.567]] [[0.252]
 [0.176]
 [0.217]
 [0.553]
 [0.112]]
line 256 mcts: sample exp_bonus 95.56736675669583
siam score:  -0.92882216
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.69555125007915
siam score:  -0.92837125
printing an ep nov before normalisation:  20.80714464187622
printing an ep nov before normalisation:  28.1750745516592
printing an ep nov before normalisation:  61.376356561377534
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9943,     0.0000,     0.0000,     0.0050,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0118, 0.0309, 0.8782, 0.0630, 0.0161], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0002,     0.0306,     0.9059,     0.0632],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0008, 0.0128, 0.0376, 0.6765, 0.2724], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  46.29605864956807
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.781]
 [34.781]
 [34.781]
 [58.506]
 [34.781]] [[0.192]
 [0.192]
 [0.192]
 [0.42 ]
 [0.192]]
printing an ep nov before normalisation:  80.44766803191999
printing an ep nov before normalisation:  63.75361177668787
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.45144491335709
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.587]
 [28.587]
 [28.587]
 [69.518]
 [28.587]] [[0.11 ]
 [0.11 ]
 [0.11 ]
 [0.436]
 [0.11 ]]
using explorer policy with actor:  1
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9418,     0.0521,     0.0062],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0026,     0.0002,     0.0188,     0.8918,     0.0866],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0057,     0.0005,     0.0745,     0.7537,     0.1657],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  52.718317869365244
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  69.91590720906916
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.27237892150879
line 256 mcts: sample exp_bonus 61.93917504115689
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.57377455977749
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.22478652005627
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.454]
 [41.627]
 [44.566]
 [69.571]
 [41.627]] [[1.071]
 [0.651]
 [0.71 ]
 [1.215]
 [0.651]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.15016391612621
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.25864006525185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.23944348169374
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9198485
printing an ep nov before normalisation:  81.25396534239987
siam score:  -0.92089736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9199375
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.794]
 [41.794]
 [41.794]
 [52.333]
 [41.794]] [[0.827]
 [0.827]
 [0.827]
 [1.152]
 [0.827]]
printing an ep nov before normalisation:  51.379453147896754
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.024]
 [25.122]
 [45.173]
 [20.521]
 [19.958]] [[0.129]
 [0.245]
 [0.626]
 [0.157]
 [0.146]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.6541807482297
printing an ep nov before normalisation:  86.97529879275756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.81961114237142
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.497340625281932
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.10683575386352
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.49710345869667
printing an ep nov before normalisation:  58.27848069205061
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.43271806446172
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[104.456]
 [ 96.707]
 [ 96.707]
 [ 94.788]
 [ 96.707]] [[0.982]
 [0.89 ]
 [0.89 ]
 [0.867]
 [0.89 ]]
printing an ep nov before normalisation:  25.331106185913086
printing an ep nov before normalisation:  97.07774287157523
actions average: 
K:  4  action  0 :  tensor([    0.9991,     0.0001,     0.0000,     0.0005,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9993,     0.0006,     0.0001],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0007,     0.0028,     0.0288,     0.8613,     0.1064],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0008,     0.0004,     0.0004,     0.7005,     0.2979],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.335]
 [40.335]
 [40.335]
 [81.23 ]
 [40.335]] [[0.33 ]
 [0.33 ]
 [0.33 ]
 [0.761]
 [0.33 ]]
printing an ep nov before normalisation:  105.39204684733939
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 91.32367647239184
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.219]
 [26.219]
 [26.219]
 [72.112]
 [26.219]] [[0.155]
 [0.155]
 [0.155]
 [0.67 ]
 [0.155]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.411979952766316
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.703]
 [56.703]
 [56.703]
 [56.703]
 [56.703]] [[0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.00539476683475
siam score:  -0.9255551
siam score:  -0.92623574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92292756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  70.3087399715168
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9247168
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.211]
 [31.211]
 [31.211]
 [44.833]
 [31.211]] [[0.445]
 [0.445]
 [0.445]
 [0.762]
 [0.445]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  79.04181058750994
printing an ep nov before normalisation:  31.396517753601074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.28825910563861
printing an ep nov before normalisation:  66.11936119888796
line 256 mcts: sample exp_bonus 67.00805371755521
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.369]
 [43.888]
 [43.888]
 [44.045]
 [43.888]] [[0.55 ]
 [0.41 ]
 [0.41 ]
 [0.412]
 [0.41 ]]
printing an ep nov before normalisation:  91.3643829488491
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.637]
 [40.947]
 [35.475]
 [59.91 ]
 [47.077]] [[0.257]
 [0.291]
 [0.211]
 [0.571]
 [0.382]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.86566783930009
printing an ep nov before normalisation:  82.46760794933473
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.27662510342068
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 63.854900672461284
siam score:  -0.9324046
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.308]
 [17.48 ]
 [59.624]
 [20.504]
 [16.598]] [[0.135]
 [0.093]
 [0.55 ]
 [0.126]
 [0.084]]
line 256 mcts: sample exp_bonus 39.982263759236645
printing an ep nov before normalisation:  79.21387198590108
printing an ep nov before normalisation:  89.75946156645543
siam score:  -0.9261094
printing an ep nov before normalisation:  95.32458023035608
siam score:  -0.9239016
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.163]
 [28.163]
 [63.113]
 [61.582]
 [28.163]] [[0.408]
 [0.408]
 [1.14 ]
 [1.108]
 [0.408]]
printing an ep nov before normalisation:  28.359795980635447
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.53555071744317
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  87.71614521935405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.046]
 [68.032]
 [42.046]
 [64.876]
 [42.046]] [[0.627]
 [1.209]
 [0.627]
 [1.138]
 [0.627]]
actions average: 
K:  2  action  0 :  tensor([    0.9974,     0.0002,     0.0000,     0.0001,     0.0023],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9994,     0.0002,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0004,     0.9914,     0.0006,     0.0075],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0014,     0.0005,     0.0215,     0.8919,     0.0848],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0388,     0.0122,     0.0005,     0.5743,     0.3742],
       grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.927325
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.9511223186653
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.55821405389963
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[96.411]
 [96.411]
 [96.411]
 [96.113]
 [96.411]] [[1.   ]
 [1.   ]
 [1.   ]
 [0.997]
 [1.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  87.09670035425405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.67834999088667
printing an ep nov before normalisation:  19.347004890441895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.42829293145589
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.274]
 [74.274]
 [74.274]
 [74.274]
 [74.274]] [[0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.901]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.325]
 [31.325]
 [31.325]
 [31.325]
 [31.325]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  99.48832444525783
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.48 ]
 [83.817]
 [83.45 ]
 [71.305]
 [78.805]] [[0.913]
 [0.974]
 [0.968]
 [0.798]
 [0.903]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.0369820619392
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.64 ]
 [50.627]
 [50.627]
 [63.33 ]
 [50.627]] [[0.688]
 [0.55 ]
 [0.55 ]
 [0.725]
 [0.55 ]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  38.12510245584795
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.174049377441406
printing an ep nov before normalisation:  81.6766890336657
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.14637221796069
printing an ep nov before normalisation:  41.94879768443287
printing an ep nov before normalisation:  34.955062338040875
printing an ep nov before normalisation:  38.93569442785554
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.45212545568819
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.931275874055096
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.318]
 [68.318]
 [80.22 ]
 [68.318]
 [68.318]] [[0.935]
 [0.935]
 [1.193]
 [0.935]
 [0.935]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.748932361602783
printing an ep nov before normalisation:  65.31597710727155
printing an ep nov before normalisation:  58.64223924291943
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.522]
 [88.522]
 [88.522]
 [88.522]
 [88.522]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[78.641]
 [81.876]
 [80.098]
 [78.752]
 [78.641]] [[1.092]
 [1.159]
 [1.122]
 [1.095]
 [1.092]]
actions average: 
K:  0  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0007,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9993,     0.0004,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0004,     0.0206,     0.8712,     0.1074],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0001,     0.0004,     0.0685,     0.5180,     0.4131],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  39.39840355756168
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[94.537]
 [87.827]
 [87.827]
 [90.318]
 [87.827]] [[1.293]
 [1.189]
 [1.189]
 [1.228]
 [1.189]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9255578
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.145]
 [71.145]
 [71.145]
 [87.454]
 [71.145]] [[1.008]
 [1.008]
 [1.008]
 [1.327]
 [1.008]]
printing an ep nov before normalisation:  55.87883030310999
printing an ep nov before normalisation:  47.31502621435344
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.824]
 [44.824]
 [44.824]
 [71.44 ]
 [44.824]] [[0.641]
 [0.641]
 [0.641]
 [1.143]
 [0.641]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.4674291087819
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[105.125]
 [ 92.674]
 [ 92.674]
 [ 92.674]
 [ 92.674]] [[1.333]
 [1.16 ]
 [1.16 ]
 [1.16 ]
 [1.16 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.61472988128662
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.88588685450041
printing an ep nov before normalisation:  36.463234424591064
printing an ep nov before normalisation:  86.67003820533914
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.56679105758667
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9921,     0.0000,     0.0000,     0.0065,     0.0014],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9984,     0.0005,     0.0000,     0.0011],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     1.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0003,     0.0299,     0.8466,     0.1230],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0001,     0.0003,     0.0305,     0.5765,     0.3926],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.243]
 [40.87 ]
 [29.8  ]
 [51.094]
 [40.87 ]] [[0.309]
 [0.425]
 [0.197]
 [0.636]
 [0.425]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.394095082579522
printing an ep nov before normalisation:  90.91652437131617
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.167]
 [49.167]
 [28.337]
 [49.167]
 [49.167]] [[1.601]
 [1.601]
 [0.667]
 [1.601]
 [1.601]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
siam score:  -0.9259121
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.311]
 [37.808]
 [30.374]
 [40.836]
 [38.128]] [[0.372]
 [0.469]
 [0.308]
 [0.535]
 [0.476]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.33 ]
 [85.33 ]
 [85.33 ]
 [86.152]
 [85.33 ]] [[0.623]
 [0.623]
 [0.623]
 [0.63 ]
 [0.623]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.931]
 [21.931]
 [21.931]
 [70.227]
 [21.931]] [[0.09]
 [0.09]
 [0.09]
 [0.47]
 [0.09]]
printing an ep nov before normalisation:  0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.298]
 [25.109]
 [29.337]
 [62.154]
 [18.502]] [[0.073]
 [0.117]
 [0.149]
 [0.396]
 [0.067]]
printing an ep nov before normalisation:  94.37208562328316
printing an ep nov before normalisation:  64.9563093857204
using explorer policy with actor:  1
printing an ep nov before normalisation:  91.64630459230156
printing an ep nov before normalisation:  93.80833671337152
printing an ep nov before normalisation:  94.32579189236795
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.1534598644153
siam score:  -0.93099654
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9818,     0.0002,     0.0000,     0.0122,     0.0058],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9866,     0.0074,     0.0001,     0.0059],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9669,     0.0086,     0.0245],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0001,     0.0289,     0.8887,     0.0822],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0022, 0.0014, 0.1293, 0.4946, 0.3725], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  35.43225540741382
printing an ep nov before normalisation:  40.88167216609607
printing an ep nov before normalisation:  100.50594283600351
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  92.53319460430274
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.032146224730795
printing an ep nov before normalisation:  26.868955960369174
actions average: 
K:  4  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9992,     0.0002,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0013,     0.9384,     0.0301,     0.0302],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0005,     0.0183,     0.8982,     0.0828],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0002,     0.0001,     0.0171,     0.8870,     0.0957],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.316]
 [29.549]
 [25.13 ]
 [64.413]
 [24.988]] [[0.249]
 [0.102]
 [0.072]
 [0.337]
 [0.071]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.37258548312359
printing an ep nov before normalisation:  99.89505484794387
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  94.20315871415026
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.74 ]
 [16.74 ]
 [16.74 ]
 [24.314]
 [16.74 ]] [[0.29]
 [0.29]
 [0.29]
 [0.54]
 [0.29]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9295982
printing an ep nov before normalisation:  19.18115735054016
printing an ep nov before normalisation:  29.077911376953125
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  91.62983543596017
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92476034
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.68913000685598
printing an ep nov before normalisation:  72.79892791726965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.926]
 [19.926]
 [19.926]
 [52.174]
 [19.926]] [[0.195]
 [0.195]
 [0.195]
 [0.795]
 [0.195]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 87.16053392449474
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9281358
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.69901318164177
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.951]
 [29.951]
 [29.951]
 [44.936]
 [29.951]] [[0.283]
 [0.283]
 [0.283]
 [0.553]
 [0.283]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.494]
 [68.494]
 [68.494]
 [80.496]
 [68.494]] [[1.102]
 [1.102]
 [1.102]
 [1.333]
 [1.102]]
printing an ep nov before normalisation:  65.05721790788286
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.384]
 [33.391]
 [29.009]
 [59.841]
 [26.786]] [[0.213]
 [0.371]
 [0.294]
 [0.838]
 [0.255]]
printing an ep nov before normalisation:  85.22057923019989
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.06955924767259
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.91389876964246
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  92.76814202866731
printing an ep nov before normalisation:  88.31839211760115
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.127]
 [30.482]
 [30.482]
 [30.482]
 [30.482]] [[1.406]
 [0.994]
 [0.994]
 [0.994]
 [0.994]]
printing an ep nov before normalisation:  29.290266777332054
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  11.93580150604248
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  30.252611309483726
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  97.33104083625726
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.19346003958655
printing an ep nov before normalisation:  82.99947387995232
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.43341881629364
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.14414541921984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.157518928979684
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.539]
 [40.539]
 [40.539]
 [40.539]
 [40.539]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.922576
printing an ep nov before normalisation:  64.18227920889338
line 256 mcts: sample exp_bonus 72.86942758729644
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.737]
 [58.737]
 [73.348]
 [77.316]
 [58.737]] [[1.102]
 [1.102]
 [1.509]
 [1.62 ]
 [1.102]]
printing an ep nov before normalisation:  81.848432939788
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.056]
 [82.056]
 [83.961]
 [85.363]
 [82.056]] [[1.828]
 [1.828]
 [1.884]
 [1.926]
 [1.828]]
printing an ep nov before normalisation:  57.7963669145661
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.6  ]
 [20.6  ]
 [20.6  ]
 [56.943]
 [20.6  ]] [[0.149]
 [0.149]
 [0.149]
 [0.651]
 [0.149]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.47164144269357
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  92.03779160755174
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.2120774253377
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.537]
 [66.537]
 [66.537]
 [66.537]
 [66.537]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.86086322674952
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.065]
 [42.467]
 [42.467]
 [52.294]
 [42.467]] [[0.941]
 [0.681]
 [0.681]
 [0.948]
 [0.681]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.852]
 [58.852]
 [58.852]
 [62.887]
 [58.852]] [[1.603]
 [1.603]
 [1.603]
 [1.751]
 [1.603]]
siam score:  -0.92905706
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.97980928408156
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.037]
 [33.436]
 [33.436]
 [46.058]
 [33.436]] [[0.272]
 [0.19 ]
 [0.19 ]
 [0.326]
 [0.19 ]]
printing an ep nov before normalisation:  86.79783124237808
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.785]
 [14.785]
 [14.785]
 [14.785]
 [14.785]] [[0.34]
 [0.34]
 [0.34]
 [0.34]
 [0.34]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.324]
 [43.18 ]
 [42.389]
 [53.212]
 [38.636]] [[0.297]
 [0.247]
 [0.239]
 [0.345]
 [0.203]]
actions average: 
K:  3  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0005,     0.9289,     0.0299,     0.0406],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0004,     0.0003,     0.0256,     0.8691,     0.1046],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0011, 0.0015, 0.1279, 0.6198, 0.2497], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  41.10285149411595
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.020651337093057
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.694]
 [24.694]
 [20.892]
 [39.564]
 [24.694]] [[0.525]
 [0.525]
 [0.444]
 [0.841]
 [0.525]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.4640931490069
printing an ep nov before normalisation:  74.74240138265242
printing an ep nov before normalisation:  25.57913303375244
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.137052565624955
printing an ep nov before normalisation:  53.777757821569246
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.016280498880973937
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.77570617418537
printing an ep nov before normalisation:  82.32808819582546
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.922]
 [24.44 ]
 [30.756]
 [26.453]
 [27.185]] [[1.477]
 [1.207]
 [1.519]
 [1.306]
 [1.342]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.78076491117606
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 46.38173705604893
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.123195064843515
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.732]
 [39.238]
 [35.799]
 [40.327]
 [39.229]] [[1.004]
 [0.695]
 [0.554]
 [0.74 ]
 [0.695]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  68.89412338385253
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.570660099445604
printing an ep nov before normalisation:  48.33405506161128
printing an ep nov before normalisation:  65.28274788407154
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.76313754860553
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.116]
 [44.624]
 [44.624]
 [46.852]
 [44.624]] [[1.359]
 [1.135]
 [1.135]
 [1.226]
 [1.135]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.9953424264865
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.618]
 [60.618]
 [60.618]
 [60.618]
 [60.618]] [[1.805]
 [1.805]
 [1.805]
 [1.805]
 [1.805]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  43.25641652779256
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.79430403531569
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  64.35046822761244
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.55134636702941
printing an ep nov before normalisation:  49.95410411454664
printing an ep nov before normalisation:  34.97835522124018
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.425]
 [59.425]
 [59.425]
 [64.294]
 [59.425]] [[0.553]
 [0.553]
 [0.553]
 [0.618]
 [0.553]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.984471784466795
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.75883047247945
printing an ep nov before normalisation:  39.25637533953763
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.602]
 [36.602]
 [36.602]
 [51.295]
 [36.602]] [[0.744]
 [0.744]
 [0.744]
 [1.156]
 [0.744]]
Starting evaluation
printing an ep nov before normalisation:  62.55985210531878
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.23 ]
 [66.615]
 [66.615]
 [69.719]
 [66.615]] [[1.231]
 [1.156]
 [1.156]
 [1.221]
 [1.156]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  86.6767122788115
printing an ep nov before normalisation:  74.76114735372889
printing an ep nov before normalisation:  28.56081247329712
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.013255248592436
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.396]
 [45.396]
 [65.589]
 [58.792]
 [45.396]] [[0.369]
 [0.369]
 [0.669]
 [0.568]
 [0.369]]
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.562]
 [34.545]
 [36.519]
 [45.136]
 [42.261]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.30563838520737
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.974]
 [33.974]
 [33.974]
 [47.348]
 [33.974]] [[0.644]
 [0.644]
 [0.644]
 [1.127]
 [0.644]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  69.26550188838166
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.253]
 [61.253]
 [69.712]
 [63.283]
 [61.253]] [[1.181]
 [1.181]
 [1.411]
 [1.236]
 [1.181]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.24979904567829
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  57.08533099427626
printing an ep nov before normalisation:  37.61988288229081
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.19959796659884
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.24600142493871
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.86207628250122
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.36452626599453
printing an ep nov before normalisation:  62.205038817749156
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.191]
 [27.191]
 [27.191]
 [41.251]
 [27.191]] [[0.151]
 [0.151]
 [0.151]
 [0.255]
 [0.151]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.9878432721016
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.20217238085462
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.881]
 [62.881]
 [62.881]
 [62.881]
 [62.881]] [[0.842]
 [0.842]
 [0.842]
 [0.842]
 [0.842]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.466]
 [13.466]
 [13.466]
 [46.389]
 [13.466]] [[0.106]
 [0.106]
 [0.106]
 [0.599]
 [0.106]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.415]
 [57.415]
 [67.049]
 [65.803]
 [57.415]] [[1.389]
 [1.389]
 [1.671]
 [1.634]
 [1.389]]
siam score:  -0.92372787
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.3963090914294
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.435]
 [49.435]
 [52.894]
 [59.746]
 [49.435]] [[1.269]
 [1.269]
 [1.39 ]
 [1.63 ]
 [1.269]]
printing an ep nov before normalisation:  67.83046806572159
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.171]
 [29.171]
 [29.171]
 [46.938]
 [29.171]] [[0.457]
 [0.457]
 [0.457]
 [0.988]
 [0.457]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.5935192836538
printing an ep nov before normalisation:  18.947956660852345
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0025,     0.9970,     0.0000,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0010, 0.0275, 0.8508, 0.0900, 0.0308], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0084,     0.0005,     0.0283,     0.8568,     0.1060],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0040,     0.0005,     0.0187,     0.7320,     0.2448],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.717]
 [79.717]
 [79.717]
 [81.749]
 [79.717]] [[1.24 ]
 [1.24 ]
 [1.24 ]
 [1.277]
 [1.24 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.763]
 [32.763]
 [32.077]
 [53.642]
 [32.763]] [[0.347]
 [0.347]
 [0.335]
 [0.721]
 [0.347]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.565]
 [23.036]
 [20.986]
 [22.867]
 [21.789]] [[1.217]
 [0.704]
 [0.593]
 [0.695]
 [0.636]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.764]
 [32.963]
 [19.672]
 [23.515]
 [21.031]] [[1.315]
 [1.262]
 [0.374]
 [0.631]
 [0.465]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.549]
 [27.052]
 [48.019]
 [29.522]
 [26.152]] [[0.352]
 [0.365]
 [0.917]
 [0.43 ]
 [0.341]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0005,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9963,     0.0010,     0.0002,     0.0025],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9604,     0.0351,     0.0045],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0004,     0.0171,     0.8858,     0.0965],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0099, 0.0141, 0.0178, 0.6165, 0.3417], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.429]
 [58.732]
 [40.429]
 [60.596]
 [40.429]] [[0.607]
 [1.065]
 [0.607]
 [1.112]
 [0.607]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  42.85674762972326
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.64822768620369
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9974,     0.0000,     0.0000,     0.0016,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9924,     0.0021,     0.0005,     0.0050],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9205,     0.0729,     0.0067],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0001,     0.0104,     0.8859,     0.1035],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0010, 0.0007, 0.0092, 0.3915, 0.5976], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  80.85513920742483
printing an ep nov before normalisation:  54.41531185763129
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.733]
 [20.733]
 [20.733]
 [37.036]
 [20.733]] [[0.218]
 [0.218]
 [0.218]
 [0.486]
 [0.218]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.09 ]
 [30.47 ]
 [26.242]
 [28.195]
 [27.704]] [[0.39 ]
 [0.3  ]
 [0.219]
 [0.257]
 [0.247]]
printing an ep nov before normalisation:  78.16254466066303
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.763]
 [83.763]
 [83.763]
 [80.16 ]
 [83.763]] [[0.661]
 [0.661]
 [0.661]
 [0.629]
 [0.661]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.737063622450904
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.23864564798492
siam score:  -0.92373955
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.171]
 [36.349]
 [28.528]
 [48.682]
 [36.349]] [[0.654]
 [0.515]
 [0.289]
 [0.871]
 [0.515]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.26655539853146
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.07249689102173
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.041]
 [67.468]
 [58.041]
 [68.306]
 [58.041]] [[1.082]
 [1.321]
 [1.082]
 [1.343]
 [1.082]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.503945420812556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.446]
 [32.153]
 [32.437]
 [51.685]
 [28.342]] [[0.169]
 [0.234]
 [0.238]
 [0.503]
 [0.181]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.93749498549228
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.318]
 [42.318]
 [42.318]
 [64.658]
 [42.318]] [[0.659]
 [0.659]
 [0.659]
 [1.165]
 [0.659]]
siam score:  -0.92309844
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.931]
 [31.931]
 [31.931]
 [56.764]
 [31.931]] [[0.509]
 [0.509]
 [0.509]
 [1.122]
 [0.509]]
printing an ep nov before normalisation:  66.46117444875144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.034]
 [45.034]
 [45.034]
 [56.177]
 [45.034]] [[1.   ]
 [1.   ]
 [1.   ]
 [1.382]
 [1.   ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.869]
 [65.869]
 [65.869]
 [71.024]
 [65.869]] [[1.434]
 [1.434]
 [1.434]
 [1.598]
 [1.434]]
printing an ep nov before normalisation:  42.2386644683865
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.198538808612255
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.511]
 [31.819]
 [31.819]
 [48.831]
 [31.819]] [[0.105]
 [0.187]
 [0.187]
 [0.378]
 [0.187]]
siam score:  -0.9273737
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.924]
 [28.01 ]
 [42.683]
 [41.794]
 [22.84 ]] [[0.18 ]
 [0.193]
 [0.364]
 [0.353]
 [0.133]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9274675
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.422412847519944
printing an ep nov before normalisation:  57.58941237229345
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.91698418342022
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.040881060474455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.52002117791998
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.6023006439209
printing an ep nov before normalisation:  58.525159313672944
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.664193093259456
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.5254616169877
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.26011249723901
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.239]
 [23.239]
 [49.063]
 [25.379]
 [23.239]] [[0.307]
 [0.307]
 [0.896]
 [0.355]
 [0.307]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.901]
 [88.901]
 [88.901]
 [88.901]
 [88.901]] [[1.664]
 [1.664]
 [1.664]
 [1.664]
 [1.664]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.923694
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.99814439818871
printing an ep nov before normalisation:  27.354767322540283
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.873]
 [28.873]
 [28.873]
 [66.622]
 [28.873]] [[0.123]
 [0.123]
 [0.123]
 [0.455]
 [0.123]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9256391
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.308]
 [23.944]
 [22.621]
 [45.254]
 [21.283]] [[0.174]
 [0.125]
 [0.113]
 [0.32 ]
 [0.101]]
siam score:  -0.92616063
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.548]
 [64.106]
 [64.106]
 [72.445]
 [64.106]] [[0.59 ]
 [0.475]
 [0.475]
 [0.546]
 [0.475]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[81.449]
 [81.449]
 [81.449]
 [77.991]
 [81.449]] [[0.949]
 [0.949]
 [0.949]
 [0.9  ]
 [0.949]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.029]
 [52.029]
 [52.029]
 [70.039]
 [52.029]] [[0.497]
 [0.497]
 [0.497]
 [0.724]
 [0.497]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9840,     0.0001,     0.0000,     0.0134,     0.0024],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.8879,     0.0980,     0.0005,     0.0135],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9999,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0000,     0.0005,     0.0227,     0.8441,     0.1327],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0001,     0.0049,     0.0272,     0.6602,     0.3077],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.42840359673785
siam score:  -0.9290622
actions average: 
K:  2  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0004,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9116,     0.0817,     0.0067],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0002,     0.0121,     0.8721,     0.1156],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0001,     0.0071,     0.0463,     0.5788,     0.3677],
       grad_fn=<DivBackward0>)
siam score:  -0.92819047
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  57.17157250294935
printing an ep nov before normalisation:  58.10843993861841
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  76.47296302394159
UNIT TEST: sample policy line 217 mcts : [0.051 0.128 0.692 0.103 0.026]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.651]
 [22.275]
 [53.764]
 [20.76 ]
 [19.142]] [[0.164]
 [0.147]
 [0.536]
 [0.129]
 [0.109]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[105.391]
 [105.391]
 [105.391]
 [105.391]
 [105.391]] [[1.523]
 [1.523]
 [1.523]
 [1.523]
 [1.523]]
siam score:  -0.9296835
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.76826834265118
siam score:  -0.92731684
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.333]
 [38.019]
 [38.019]
 [33.261]
 [38.019]] [[1.478]
 [1.278]
 [1.278]
 [1.057]
 [1.278]]
printing an ep nov before normalisation:  65.86370302525924
siam score:  -0.92592096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9250145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.16649696025622
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.18192009597914
printing an ep nov before normalisation:  57.15911332818943
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.954]
 [37.239]
 [36.75 ]
 [37.239]
 [37.239]] [[0.954]
 [1.641]
 [1.601]
 [1.641]
 [1.641]]
printing an ep nov before normalisation:  43.1754008600318
printing an ep nov before normalisation:  58.93120928777863
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.398]
 [22.398]
 [48.726]
 [25.832]
 [22.398]] [[0.313]
 [0.313]
 [1.015]
 [0.405]
 [0.313]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.4  ]
 [37.885]
 [37.885]
 [41.787]
 [37.885]] [[1.098]
 [0.566]
 [0.566]
 [0.678]
 [0.566]]
line 256 mcts: sample exp_bonus 43.82753849029541
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.30908032915474
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9616,     0.0341,     0.0043],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0056, 0.0030, 0.0153, 0.8943, 0.0818], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0004,     0.0001,     0.0171,     0.8562,     0.1261],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.021]
 [42.021]
 [42.021]
 [66.193]
 [42.021]] [[0.599]
 [0.599]
 [0.599]
 [1.179]
 [0.599]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  93.4220937843484
line 256 mcts: sample exp_bonus 86.81968420534302
siam score:  -0.9248508
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.03996582799446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.318]
 [86.318]
 [86.318]
 [86.894]
 [86.318]] [[0.993]
 [0.993]
 [0.993]
 [1.   ]
 [0.993]]
printing an ep nov before normalisation:  37.82247691215302
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  72.08321640870949
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.37215675389591
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9232379
line 256 mcts: sample exp_bonus 61.09114096713605
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.747]
 [48.747]
 [48.747]
 [52.597]
 [48.747]] [[0.719]
 [0.719]
 [0.719]
 [0.814]
 [0.719]]
siam score:  -0.92514056
printing an ep nov before normalisation:  31.719530986954283
printing an ep nov before normalisation:  59.11735250898879
printing an ep nov before normalisation:  56.91073011304417
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.175]
 [36.175]
 [37.037]
 [44.24 ]
 [36.175]] [[0.752]
 [0.752]
 [0.784]
 [1.044]
 [0.752]]
printing an ep nov before normalisation:  56.20425320343365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9260963
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.336873531341553
using explorer policy with actor:  1
printing an ep nov before normalisation:  71.45492634806185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.555520787982076
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.538 0.026 0.026 0.359 0.051]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.993]
 [34.993]
 [44.242]
 [50.275]
 [34.993]] [[0.522]
 [0.522]
 [0.749]
 [0.898]
 [0.522]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.723]
 [18.723]
 [34.776]
 [18.723]
 [18.723]] [[0.376]
 [0.376]
 [0.897]
 [0.376]
 [0.376]]
line 256 mcts: sample exp_bonus 61.04971308747855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  61.147996590474456
UNIT TEST: sample policy line 217 mcts : [0.026 0.026 0.59  0.308 0.051]
printing an ep nov before normalisation:  85.86579430114206
printing an ep nov before normalisation:  26.276818157048467
printing an ep nov before normalisation:  85.64788884279879
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.73471690968302
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.994]
 [25.213]
 [27.648]
 [51.176]
 [19.082]] [[0.157]
 [0.208]
 [0.238]
 [0.524]
 [0.133]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.846]
 [25.935]
 [38.334]
 [58.708]
 [19.146]] [[0.176]
 [0.145]
 [0.242]
 [0.401]
 [0.092]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.851]
 [21.577]
 [54.515]
 [34.828]
 [14.851]] [[0.064]
 [0.119]
 [0.388]
 [0.227]
 [0.064]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  17.54173994064331
printing an ep nov before normalisation:  76.80000171931152
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.128 0.128 0.359 0.231 0.154]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.4271236359949
line 256 mcts: sample exp_bonus 48.85625976174208
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.505514298352374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  61.454862935371054
printing an ep nov before normalisation:  82.94282640531803
printing an ep nov before normalisation:  81.21261900310452
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.88509951352991
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
siam score:  -0.92483765
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  41.44191148037123
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.533]
 [22.844]
 [26.487]
 [25.137]
 [22.906]] [[1.137]
 [0.917]
 [1.216]
 [1.105]
 [0.922]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.485]
 [50.485]
 [50.485]
 [50.485]
 [50.485]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.977]
 [31.672]
 [29.48 ]
 [39.149]
 [29.48 ]] [[0.445]
 [0.521]
 [0.459]
 [0.732]
 [0.459]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.78261661529541
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.987]
 [50.987]
 [50.987]
 [54.897]
 [50.987]] [[1.028]
 [1.028]
 [1.028]
 [1.127]
 [1.028]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  21.901843547821045
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.981516605128895
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.59385120241001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.719]
 [35.013]
 [39.365]
 [54.448]
 [37.232]] [[0.562]
 [0.481]
 [0.612]
 [1.066]
 [0.547]]
siam score:  -0.9217533
printing an ep nov before normalisation:  62.534584202020625
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.219]
 [24.42 ]
 [28.251]
 [26.63 ]
 [31.219]] [[2.081]
 [1.269]
 [1.727]
 [1.533]
 [2.081]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.329]
 [34.511]
 [31.263]
 [44.947]
 [34.271]] [[0.75 ]
 [0.6  ]
 [0.473]
 [1.009]
 [0.591]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.28303740239819
printing an ep nov before normalisation:  49.928820858428864
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 44.97919986067984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.38]
 [30.38]
 [36.72]
 [30.38]
 [30.38]] [[0.971]
 [0.971]
 [1.366]
 [0.971]
 [0.971]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.68338635368448
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  13.252718448638916
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.758]
 [17.747]
 [14.107]
 [41.775]
 [13.253]] [[0.121]
 [0.274]
 [0.162]
 [1.012]
 [0.136]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.023477070873614
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9224728
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.9044271437501
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.5870167198623
printing an ep nov before normalisation:  85.14956779652202
siam score:  -0.9231805
printing an ep nov before normalisation:  87.6136432763792
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 38.895895923858305
printing an ep nov before normalisation:  24.407358169555664
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.72795535451775
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  29.49333667755127
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.256]
 [27.381]
 [28.782]
 [43.498]
 [25.992]] [[0.345]
 [0.408]
 [0.45 ]
 [0.89 ]
 [0.367]]
actions average: 
K:  4  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0000],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9956,     0.0011,     0.0001,     0.0032],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0058, 0.0148, 0.9002, 0.0465, 0.0326], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0001,     0.0208,     0.9049,     0.0740],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0002,     0.0000,     0.0001,     0.8530,     0.1466],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.28679517969868
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.859673481841405
printing an ep nov before normalisation:  44.16388931224665
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.181045439169615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  77.20283072625148
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  71.75418588501228
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.30489695919512
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.7545609547654
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.205591102266816
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  78.69034975912814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.97108536158541
printing an ep nov before normalisation:  82.4835849661684
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.46715605672034
printing an ep nov before normalisation:  58.931290192981706
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.444]
 [74.731]
 [74.731]
 [82.211]
 [74.731]] [[1.604]
 [1.612]
 [1.612]
 [1.816]
 [1.612]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.33444548012862
printing an ep nov before normalisation:  73.31408820488231
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  65.77652571437909
printing an ep nov before normalisation:  50.742356680095504
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.73 ]
 [25.888]
 [46.324]
 [22.397]
 [23.964]] [[0.28 ]
 [0.449]
 [1.009]
 [0.353]
 [0.396]]
printing an ep nov before normalisation:  71.35788032434134
using explorer policy with actor:  1
printing an ep nov before normalisation:  66.47263788875182
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.732]
 [38.732]
 [38.732]
 [47.529]
 [38.732]] [[1.017]
 [1.017]
 [1.017]
 [1.457]
 [1.017]]
printing an ep nov before normalisation:  77.59039378268417
siam score:  -0.9229941
printing an ep nov before normalisation:  29.279732994263874
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
actions average: 
K:  1  action  0 :  tensor([    0.9980,     0.0000,     0.0000,     0.0018,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9868,     0.0000,     0.0019,     0.0112],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9995,     0.0004,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0003,     0.0165,     0.9009,     0.0820],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0328,     0.0012,     0.0005,     0.3869,     0.5787],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92532086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.352]
 [40.993]
 [25.699]
 [30.449]
 [26.37 ]] [[1.326]
 [2.   ]
 [0.806]
 [1.177]
 [0.859]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.622]
 [36.622]
 [36.622]
 [57.618]
 [36.622]] [[0.632]
 [0.632]
 [0.632]
 [1.178]
 [0.632]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.033]
 [34.033]
 [34.033]
 [46.131]
 [34.033]] [[0.664]
 [0.664]
 [0.664]
 [1.   ]
 [0.664]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.092999534643372
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.422]
 [61.853]
 [62.422]
 [65.915]
 [62.422]] [[1.569]
 [1.547]
 [1.569]
 [1.702]
 [1.569]]
printing an ep nov before normalisation:  66.2502310662776
printing an ep nov before normalisation:  76.66926753666499
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.021]
 [39.021]
 [39.021]
 [37.723]
 [39.021]] [[0.711]
 [0.711]
 [0.711]
 [0.667]
 [0.711]]
actions average: 
K:  2  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0008,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0024,     0.9965,     0.0000,     0.0000,     0.0011],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9996,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0004,     0.0112,     0.8988,     0.0893],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0003,     0.0028,     0.1048,     0.6497,     0.2425],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.05778248357752
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 0.0
actions average: 
K:  4  action  0 :  tensor([    0.9947,     0.0000,     0.0000,     0.0017,     0.0035],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9981,     0.0007,     0.0002,     0.0010],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9975,     0.0023,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0002,     0.0215,     0.8973,     0.0808],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0030, 0.0006, 0.0693, 0.5147, 0.4125], grad_fn=<DivBackward0>)
siam score:  -0.9254715
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9797,     0.0106,     0.0000,     0.0097],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0005,     0.9489,     0.0322,     0.0184],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0019,     0.0125,     0.8767,     0.1085],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0015, 0.0665, 0.0007, 0.6792, 0.2520], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.806]
 [51.806]
 [41.738]
 [57.484]
 [51.806]] [[1.018]
 [1.018]
 [0.732]
 [1.179]
 [1.018]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.741]
 [33.741]
 [37.552]
 [33.741]
 [33.741]] [[0.519]
 [0.519]
 [0.641]
 [0.519]
 [0.519]]
siam score:  -0.92307425
printing an ep nov before normalisation:  30.796864441714114
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.355]
 [45.355]
 [45.355]
 [48.027]
 [45.355]] [[1.028]
 [1.028]
 [1.028]
 [1.109]
 [1.028]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.744]
 [29.606]
 [42.81 ]
 [52.183]
 [29.606]] [[0.584]
 [0.408]
 [0.861]
 [1.182]
 [0.408]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.207565201424906
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.17307522034405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 42.09995242177528
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.387335494529765
siam score:  -0.92504305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.99347464356299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  18.42237949371338
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  16.21381210189522
line 256 mcts: sample exp_bonus 72.56128868713331
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.41900935260048
UNIT TEST: sample policy line 217 mcts : [0.026 0.667 0.026 0.256 0.026]
printing an ep nov before normalisation:  86.21783380865237
printing an ep nov before normalisation:  81.37771298128297
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  89.89764700884083
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.882257360106024
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.42]
 [48.42]
 [48.42]
 [48.42]
 [48.42]] [[64.544]
 [64.544]
 [64.544]
 [64.544]
 [64.544]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.792273672304752
actions average: 
K:  3  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9986,     0.0006,     0.0000,     0.0007],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0004,     0.9742,     0.0026,     0.0228],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0006,     0.0002,     0.0284,     0.8902,     0.0807],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0025, 0.0025, 0.0294, 0.7298, 0.2357], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.55934939786582
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.476]
 [27.476]
 [27.476]
 [38.423]
 [27.476]] [[0.109]
 [0.109]
 [0.109]
 [0.188]
 [0.109]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.63]
 [38.63]
 [38.63]
 [52.86]
 [38.63]] [[0.27 ]
 [0.27 ]
 [0.27 ]
 [0.396]
 [0.27 ]]
actions average: 
K:  2  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9684,     0.0294,     0.0022],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0001,     0.0072,     0.9034,     0.0889],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0011, 0.0158, 0.1297, 0.6963, 0.1571], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.30681085586548
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9976,     0.0000,     0.0000,     0.0004,     0.0020],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9965,     0.0001,     0.0003,     0.0031],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9469,     0.0500,     0.0031],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0201,     0.0002,     0.0067,     0.8791,     0.0939],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0001,     0.0003,     0.0120,     0.6195,     0.3681],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.107637740243085
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.88466215874455
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.747]
 [54.891]
 [44.503]
 [51.822]
 [54.891]] [[0.819]
 [0.585]
 [0.395]
 [0.529]
 [0.585]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.53821864881095
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.49056843464896
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.611]
 [82.333]
 [85.292]
 [77.465]
 [82.333]] [[0.958]
 [0.908]
 [0.943]
 [0.85 ]
 [0.908]]
actions average: 
K:  3  action  0 :  tensor([    0.9371,     0.0001,     0.0000,     0.0555,     0.0073],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0412, 0.9321, 0.0069, 0.0147, 0.0051], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9996,     0.0003,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0042,     0.0002,     0.0323,     0.8710,     0.0922],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0003,     0.0007,     0.0025,     0.7225,     0.2740],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.384]
 [27.733]
 [14.107]
 [14.479]
 [14.061]] [[0.376]
 [0.939]
 [0.263]
 [0.282]
 [0.261]]
printing an ep nov before normalisation:  31.0339093208313
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.588012536366783
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.192]
 [56.192]
 [56.192]
 [61.003]
 [56.192]] [[0.84 ]
 [0.84 ]
 [0.84 ]
 [0.937]
 [0.84 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 42.212316394953206
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  74.50661157762907
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92321414
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9256169
printing an ep nov before normalisation:  30.071887969970703
Starting evaluation
printing an ep nov before normalisation:  21.13730602548502
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.882]
 [37.069]
 [45.547]
 [44.113]
 [42.286]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  16.618030360772526
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  42.05370107468532
siam score:  -0.92151487
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9972,     0.0000,     0.0000,     0.0001,     0.0027],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9981,     0.0001,     0.0000,     0.0018],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0002,     0.9657,     0.0034,     0.0307],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0003,     0.0128,     0.9127,     0.0739],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0002,     0.0003,     0.0005,     0.7658,     0.2332],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  35.79099065312816
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9195202
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.91758754600187
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.26400509436175
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.63057092498581
actions average: 
K:  1  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0003,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0004,     0.9976,     0.0002,     0.0000,     0.0018],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9098,     0.0786,     0.0115],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0004,     0.0001,     0.0210,     0.8655,     0.1129],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0376, 0.0120, 0.0502, 0.6400, 0.2602], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  11.553414304811005
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  16.041052577695787
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.314]
 [40.314]
 [46.672]
 [46.183]
 [40.314]] [[1.246]
 [1.246]
 [1.475]
 [1.458]
 [1.246]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.19183522385242
siam score:  -0.91952264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.59616489960902
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.536]
 [53.536]
 [53.536]
 [53.536]
 [53.536]] [[1.777]
 [1.777]
 [1.777]
 [1.777]
 [1.777]]
printing an ep nov before normalisation:  68.58747401468612
siam score:  -0.91954404
printing an ep nov before normalisation:  39.865811053573296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.696757049279704
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.87 ]
 [27.63 ]
 [27.63 ]
 [34.621]
 [27.63 ]] [[1.034]
 [0.475]
 [0.475]
 [0.716]
 [0.475]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.261]
 [21.261]
 [21.261]
 [21.261]
 [21.261]] [[0.111]
 [0.111]
 [0.111]
 [0.111]
 [0.111]]
printing an ep nov before normalisation:  79.28063777854551
printing an ep nov before normalisation:  75.89210418606426
printing an ep nov before normalisation:  33.46736410389109
printing an ep nov before normalisation:  81.87665341282772
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  84.43017583739447
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.098]
 [78.069]
 [78.069]
 [77.313]
 [78.069]] [[0.635]
 [0.564]
 [0.564]
 [0.558]
 [0.564]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.061]
 [24.061]
 [24.061]
 [63.673]
 [24.061]] [[0.143]
 [0.143]
 [0.143]
 [0.453]
 [0.143]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.53 ]
 [40.53 ]
 [24.994]
 [30.889]
 [40.53 ]] [[1.005]
 [1.005]
 [0.46 ]
 [0.667]
 [1.005]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 58.45732808515997
printing an ep nov before normalisation:  64.5046650086162
using explorer policy with actor:  1
siam score:  -0.9166522
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.323]
 [69.323]
 [69.323]
 [81.591]
 [69.323]] [[0.83]
 [0.83]
 [0.83]
 [1.  ]
 [0.83]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  89.0507945511799
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.512]
 [82.78 ]
 [81.691]
 [78.241]
 [79.267]] [[0.892]
 [0.86 ]
 [0.848]
 [0.808]
 [0.82 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  93.59369228537184
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.06 ]
 [20.442]
 [20.683]
 [25.388]
 [17.615]] [[0.091]
 [0.14 ]
 [0.143]
 [0.196]
 [0.108]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.26957601225244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.305]
 [33.305]
 [33.305]
 [43.805]
 [33.305]] [[0.637]
 [0.637]
 [0.637]
 [1.02 ]
 [0.637]]
siam score:  -0.918777
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.733]
 [42.733]
 [57.418]
 [42.733]
 [42.733]] [[0.58 ]
 [0.58 ]
 [0.915]
 [0.58 ]
 [0.58 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  15.241020917892456
printing an ep nov before normalisation:  79.55162773067684
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.856520151748054
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.92207018565486
printing an ep nov before normalisation:  32.38665819168091
printing an ep nov before normalisation:  75.77297409940273
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.5443058013916
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.46732731100953
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  25.12896458307902
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.18049619162989
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  21.224281701411645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.444]
 [44.444]
 [44.444]
 [56.735]
 [44.444]] [[0.823]
 [0.823]
 [0.823]
 [1.162]
 [0.823]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.63849854488527
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  88.69801482254078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.53 ]
 [20.53 ]
 [20.53 ]
 [33.902]
 [20.53 ]] [[0.211]
 [0.211]
 [0.211]
 [0.472]
 [0.211]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.8172845888169
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.815]
 [36.815]
 [55.016]
 [56.004]
 [36.815]] [[0.476]
 [0.476]
 [0.81 ]
 [0.828]
 [0.476]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  89.20509751121547
actions average: 
K:  4  action  0 :  tensor([    0.9993,     0.0000,     0.0000,     0.0004,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0023,     0.9283,     0.0536,     0.0159],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0077,     0.0004,     0.0306,     0.8315,     0.1297],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0099,     0.0027,     0.0000,     0.8175,     0.1699],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.72]
 [61.72]
 [61.72]
 [61.72]
 [61.72]] [[1.135]
 [1.135]
 [1.135]
 [1.135]
 [1.135]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.82016823025388
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.06243408159311
printing an ep nov before normalisation:  68.47399795954286
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  16.33514165878296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.14325555477577
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.43702600967259
actions average: 
K:  3  action  0 :  tensor([    0.9998,     0.0001,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9995,     0.0001,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9537,     0.0420,     0.0043],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0007,     0.0002,     0.0184,     0.8963,     0.0844],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0015, 0.0215, 0.0824, 0.4546, 0.4400], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.633]
 [49.633]
 [49.633]
 [53.622]
 [49.633]] [[0.981]
 [0.981]
 [0.981]
 [1.1  ]
 [0.981]]
actions average: 
K:  4  action  0 :  tensor([    0.9795,     0.0002,     0.0000,     0.0164,     0.0039],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9981,     0.0001,     0.0000,     0.0018],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9329,     0.0606,     0.0065],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0001,     0.0315,     0.8725,     0.0959],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0009, 0.0037, 0.0170, 0.5375, 0.4409], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92511255
printing an ep nov before normalisation:  84.3432544207019
printing an ep nov before normalisation:  38.68934154510498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.91701861026923
siam score:  -0.9277199
siam score:  -0.92717695
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9246352
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 38.383087464575276
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.638]
 [28.047]
 [26.599]
 [33.134]
 [27.096]] [[0.311]
 [0.376]
 [0.337]
 [0.512]
 [0.35 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.324]
 [17.324]
 [17.324]
 [54.905]
 [17.324]] [[0.164]
 [0.164]
 [0.164]
 [0.673]
 [0.164]]
printing an ep nov before normalisation:  74.68621591539703
printing an ep nov before normalisation:  30.29316907358004
printing an ep nov before normalisation:  75.26835584020309
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.179409503936768
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.21414703066201
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.672]
 [37.24 ]
 [25.558]
 [50.816]
 [22.624]] [[0.435]
 [0.332]
 [0.144]
 [0.55 ]
 [0.097]]
printing an ep nov before normalisation:  56.78664229750208
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.664]
 [26.664]
 [26.664]
 [50.526]
 [26.664]] [[0.319]
 [0.319]
 [0.319]
 [0.979]
 [0.319]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.801]
 [39.801]
 [47.069]
 [44.41 ]
 [39.801]] [[0.871]
 [0.871]
 [1.106]
 [1.02 ]
 [0.871]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.38458152393821
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9899,     0.0000,     0.0000,     0.0083,     0.0019],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9295,     0.0044,     0.0001,     0.0661],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9897,     0.0093,     0.0011],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0003,     0.0157,     0.9055,     0.0783],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0002,     0.0209,     0.0403,     0.8207,     0.1179],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  59.25876168764926
printing an ep nov before normalisation:  33.754217846926835
printing an ep nov before normalisation:  32.48233542247323
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.852]
 [47.852]
 [47.852]
 [47.852]
 [47.852]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.89727444605664
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9242619
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[74.91 ]
 [70.363]
 [70.363]
 [73.215]
 [70.363]] [[1.253]
 [1.155]
 [1.155]
 [1.216]
 [1.155]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 61.417823106671634
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 78.73297077635475
printing an ep nov before normalisation:  63.6169805600219
printing an ep nov before normalisation:  61.56187562523924
printing an ep nov before normalisation:  58.507307948832484
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.693]
 [65.693]
 [65.693]
 [75.951]
 [65.693]] [[0.626]
 [0.626]
 [0.626]
 [0.737]
 [0.626]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.683]
 [24.683]
 [24.683]
 [72.156]
 [24.683]] [[0.145]
 [0.145]
 [0.145]
 [0.677]
 [0.145]]
printing an ep nov before normalisation:  95.2620527951824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.197]
 [20.197]
 [20.197]
 [73.708]
 [20.197]] [[0.118]
 [0.118]
 [0.118]
 [0.711]
 [0.118]]
actions average: 
K:  0  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0006,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9985,     0.0002,     0.0001,     0.0010],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0002,     0.0066,     0.9738,     0.0029,     0.0165],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0004,     0.0126,     0.8877,     0.0992],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0025, 0.0090, 0.0476, 0.6162, 0.3247], grad_fn=<DivBackward0>)
siam score:  -0.92805696
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.079]
 [37.079]
 [37.079]
 [38.076]
 [37.079]] [[0.154]
 [0.154]
 [0.154]
 [0.162]
 [0.154]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  85.24986398728144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.194]
 [64.738]
 [55.958]
 [64.406]
 [65.194]] [[1.041]
 [1.03 ]
 [0.83 ]
 [1.023]
 [1.041]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.04454437846402
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9194386
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.52417113077612
siam score:  -0.9184856
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.499]
 [59.499]
 [59.499]
 [66.659]
 [59.499]] [[0.893]
 [0.893]
 [0.893]
 [1.057]
 [0.893]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.635]
 [47.635]
 [47.635]
 [47.635]
 [47.635]] [[0.92]
 [0.92]
 [0.92]
 [0.92]
 [0.92]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.465297836825364
printing an ep nov before normalisation:  55.63315412471143
siam score:  -0.9189883
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.826]
 [66.826]
 [66.826]
 [70.428]
 [66.826]] [[0.889]
 [0.889]
 [0.889]
 [0.944]
 [0.889]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0005,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9590,     0.0371,     0.0039],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0024,     0.0004,     0.0154,     0.8754,     0.1064],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0037, 0.0025, 0.0448, 0.6639, 0.2851], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  75.28739486599198
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.905]
 [26.905]
 [26.905]
 [68.84 ]
 [26.905]] [[0.217]
 [0.217]
 [0.217]
 [0.731]
 [0.217]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.80319293910246
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.506]
 [29.599]
 [30.156]
 [52.119]
 [18.382]] [[0.071]
 [0.228]
 [0.236]
 [0.521]
 [0.083]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  91.39752833650374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.064]
 [39.674]
 [33.064]
 [51.63 ]
 [33.064]] [[0.617]
 [0.823]
 [0.617]
 [1.195]
 [0.617]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9290091
using explorer policy with actor:  1
siam score:  -0.9275194
siam score:  -0.9283148
printing an ep nov before normalisation:  46.977796383370574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.02494668960571
printing an ep nov before normalisation:  62.76358336868594
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.186]
 [40.186]
 [40.186]
 [44.585]
 [40.186]] [[0.46 ]
 [0.46 ]
 [0.46 ]
 [0.534]
 [0.46 ]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.094399166314986
printing an ep nov before normalisation:  34.90653059751302
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.27078277928601
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.69823106554238
printing an ep nov before normalisation:  32.89666367965172
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.811]
 [47.106]
 [50.811]
 [48.142]
 [50.811]] [[1.18 ]
 [1.029]
 [1.18 ]
 [1.071]
 [1.18 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.336181640625
printing an ep nov before normalisation:  47.661618739341506
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.34879127526103
printing an ep nov before normalisation:  12.471301542606366
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.851]
 [41.851]
 [41.851]
 [47.359]
 [41.851]] [[0.642]
 [0.642]
 [0.642]
 [0.727]
 [0.642]]
siam score:  -0.9245276
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.03 ]
 [30.723]
 [30.723]
 [36.919]
 [30.723]] [[0.627]
 [0.332]
 [0.332]
 [0.46 ]
 [0.332]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.9240767
printing an ep nov before normalisation:  35.0024675675651
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.5668153864024
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.923]
 [55.923]
 [55.923]
 [55.923]
 [55.923]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
printing an ep nov before normalisation:  38.664173872744136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.120130297710055
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.89 ]
 [30.89 ]
 [43.363]
 [39.686]
 [30.89 ]] [[0.52 ]
 [0.52 ]
 [0.957]
 [0.828]
 [0.52 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.31680321278887
printing an ep nov before normalisation:  33.18507105682811
printing an ep nov before normalisation:  54.22902069266814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.013]
 [51.013]
 [51.013]
 [57.204]
 [51.013]] [[0.687]
 [0.687]
 [0.687]
 [0.803]
 [0.687]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.444]
 [34.444]
 [34.444]
 [37.505]
 [34.444]] [[0.737]
 [0.737]
 [0.737]
 [0.854]
 [0.737]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.497]
 [22.497]
 [22.497]
 [22.497]
 [22.497]] [[0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.545]
 [29.911]
 [29.436]
 [27.144]
 [29.549]] [[0.869]
 [0.88 ]
 [0.866]
 [0.798]
 [0.87 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.4654369300415
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.18457529053639
printing an ep nov before normalisation:  47.61131023545424
printing an ep nov before normalisation:  41.443145664105145
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.817180243835395
printing an ep nov before normalisation:  53.84591427250543
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.67873740536653
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.43196144818909
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.033]
 [25.033]
 [25.033]
 [25.033]
 [25.033]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.637618922215974
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.89719787322234
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.19793290045154
actions average: 
K:  2  action  0 :  tensor([    0.9111,     0.0001,     0.0000,     0.0114,     0.0774],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0008,     0.9459,     0.0034,     0.0201,     0.0298],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0198, 0.0108, 0.7823, 0.1370, 0.0500], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0016,     0.0001,     0.0098,     0.8903,     0.0981],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0002,     0.0003,     0.0552,     0.6014,     0.3430],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  44.31226793640525
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.10969495437098
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
main train batch thing paused
add a thread
Adding thread: now have 2 threads
printing an ep nov before normalisation:  27.551770732761263
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.067]
 [28.884]
 [24.324]
 [25.713]
 [25.013]] [[0.218]
 [0.27 ]
 [0.186]
 [0.212]
 [0.199]]
printing an ep nov before normalisation:  26.562411327053884
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.439]
 [66.439]
 [66.439]
 [65.878]
 [66.439]] [[1.589]
 [1.589]
 [1.589]
 [1.57 ]
 [1.589]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.384]
 [29.459]
 [35.631]
 [23.945]
 [24.13 ]] [[0.414]
 [0.646]
 [0.883]
 [0.435]
 [0.442]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.75360082312255
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.62516239008922
siam score:  -0.9199475
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.154 0.154 0.205 0.359 0.128]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.830905797745135
printing an ep nov before normalisation:  77.7202067514751
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.60344981050954
printing an ep nov before normalisation:  58.82224093215644
printing an ep nov before normalisation:  52.89338183807922
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.741]
 [32.074]
 [32.074]
 [37.656]
 [32.074]] [[0.959]
 [0.694]
 [0.694]
 [0.916]
 [0.694]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.475]
 [38.475]
 [38.475]
 [70.804]
 [38.475]] [[0.445]
 [0.445]
 [0.445]
 [1.057]
 [0.445]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.38887927501564
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.4093976020813
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.615615764073365
printing an ep nov before normalisation:  44.461996707759106
printing an ep nov before normalisation:  81.00499603840771
printing an ep nov before normalisation:  17.217504463444758
printing an ep nov before normalisation:  55.88961512449889
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.407]
 [58.98 ]
 [51.471]
 [60.053]
 [53.407]] [[0.656]
 [0.786]
 [0.611]
 [0.811]
 [0.656]]
line 256 mcts: sample exp_bonus 0.0
printing an ep nov before normalisation:  76.60573413819829
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.654]
 [65.918]
 [61.654]
 [64.513]
 [61.654]] [[1.008]
 [1.102]
 [1.008]
 [1.071]
 [1.008]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.144]
 [44.144]
 [60.266]
 [62.843]
 [44.144]] [[0.509]
 [0.509]
 [0.792]
 [0.837]
 [0.509]]
printing an ep nov before normalisation:  83.10382654099719
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.9199816
printing an ep nov before normalisation:  80.3890575369455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.025238037109375
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.499]
 [22.452]
 [18.277]
 [17.333]
 [15.76 ]] [[0.814]
 [1.253]
 [0.883]
 [0.799]
 [0.66 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  80.49240813734542
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  79.29662251652583
printing an ep nov before normalisation:  48.492520548446585
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.771]
 [25.771]
 [40.608]
 [25.771]
 [25.771]] [[0.503]
 [0.503]
 [1.054]
 [0.503]
 [0.503]]
printing an ep nov before normalisation:  49.17503985664422
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.559]
 [12.559]
 [12.559]
 [12.559]
 [12.559]] [[4.182]
 [4.182]
 [4.182]
 [4.182]
 [4.182]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 51.227470811739586
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.015]
 [59.05 ]
 [57.015]
 [45.247]
 [57.015]] [[1.581]
 [1.667]
 [1.581]
 [1.083]
 [1.581]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.539]
 [28.539]
 [28.539]
 [37.288]
 [28.539]] [[0.543]
 [0.543]
 [0.543]
 [0.807]
 [0.543]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.126]
 [34.749]
 [26.926]
 [46.927]
 [30.208]] [[0.473]
 [0.354]
 [0.226]
 [0.552]
 [0.28 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.662]
 [11.662]
 [11.662]
 [53.802]
 [11.662]] [[0.087]
 [0.087]
 [0.087]
 [0.687]
 [0.087]]
siam score:  -0.921512
line 256 mcts: sample exp_bonus 61.642973857498255
printing an ep nov before normalisation:  47.4159961490766
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.596]
 [34.641]
 [34.641]
 [28.032]
 [28.449]] [[0.719]
 [1.359]
 [1.359]
 [0.976]
 [1.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([0.9669, 0.0012, 0.0012, 0.0246, 0.0061], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0005,     0.9875,     0.0028,     0.0071,     0.0020],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.8249,     0.1581,     0.0168],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0001,     0.0115,     0.8885,     0.0997],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0002,     0.0006,     0.0021,     0.4262,     0.5709],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.978]
 [70.978]
 [70.978]
 [74.365]
 [70.978]] [[1.492]
 [1.492]
 [1.492]
 [1.583]
 [1.492]]
printing an ep nov before normalisation:  70.24434109019498
printing an ep nov before normalisation:  51.60867138849102
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.973151206970215
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.497]
 [53.497]
 [53.497]
 [65.869]
 [53.497]] [[1.006]
 [1.006]
 [1.006]
 [1.333]
 [1.006]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  90.486328426854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.767]
 [57.767]
 [67.795]
 [62.752]
 [57.767]] [[0.976]
 [0.976]
 [1.206]
 [1.091]
 [0.976]]
siam score:  -0.92297196
printing an ep nov before normalisation:  17.468349933624268
printing an ep nov before normalisation:  54.646514408547766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 61.946386706466406
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.349]
 [35.919]
 [24.539]
 [53.774]
 [35.172]] [[0.649]
 [0.548]
 [0.291]
 [0.952]
 [0.531]]
line 256 mcts: sample exp_bonus 75.20684098204543
printing an ep nov before normalisation:  28.944375525481856
line 256 mcts: sample exp_bonus 0.0
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.74697741065063
printing an ep nov before normalisation:  36.070411965865645
printing an ep nov before normalisation:  35.992931207062874
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  103.3243683730112
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.579]
 [33.579]
 [33.579]
 [45.683]
 [33.579]] [[0.84 ]
 [0.84 ]
 [0.84 ]
 [1.417]
 [0.84 ]]
printing an ep nov before normalisation:  68.69443401252693
printing an ep nov before normalisation:  72.06343103363821
using explorer policy with actor:  1
printing an ep nov before normalisation:  83.50194353586181
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.73559332215243
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.939743189423417
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.615]
 [22.615]
 [22.615]
 [51.792]
 [22.615]] [[0.198]
 [0.198]
 [0.198]
 [0.686]
 [0.198]]
printing an ep nov before normalisation:  60.2262138790442
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  92.88313535993275
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.01646200782175
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.197729761720645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.102]
 [30.43 ]
 [30.43 ]
 [30.43 ]
 [30.43 ]] [[0.435]
 [0.271]
 [0.271]
 [0.271]
 [0.271]]
printing an ep nov before normalisation:  34.251997605854406
printing an ep nov before normalisation:  88.33485250879399
printing an ep nov before normalisation:  47.694301299396614
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.381]
 [41.381]
 [41.381]
 [51.608]
 [41.381]] [[0.586]
 [0.586]
 [0.586]
 [0.767]
 [0.586]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  73.67068423619028
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.52116800612554
printing an ep nov before normalisation:  83.4874920985813
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9993,     0.0000,     0.0000,     0.0004,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9995,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9973,     0.0004,     0.0022],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0019,     0.0002,     0.0243,     0.8758,     0.0978],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0295, 0.0039, 0.0295, 0.5976, 0.3396], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  76.8172680357642
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.505]
 [37.505]
 [37.505]
 [55.788]
 [37.505]] [[0.556]
 [0.556]
 [0.556]
 [0.92 ]
 [0.556]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.173043850323154
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.064091223432754
maxi score, test score, baseline:  0.0001 0.0 0.0001
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 3.261234308011168e-09
0.0 1.6278494086755072e-09
0.0 4.070523039009731e-09
0.0 6.8703742025595266e-09
0.0 2.595176397256863e-09
0.0 5.717054728594788e-09
0.0 1.9386672079127504e-09
0.0 3.538977550653393e-09
0.0 3.3675157282311646e-09
0.0 2.0317326442519513e-09
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 55.135602765125256
printing an ep nov before normalisation:  48.272719383239746
siam score:  -0.92015094
printing an ep nov before normalisation:  69.00748374434038
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.92941761016846
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.491]
 [45.491]
 [45.491]
 [55.118]
 [45.491]] [[1.177]
 [1.177]
 [1.177]
 [1.596]
 [1.177]]
printing an ep nov before normalisation:  39.67288198244002
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.96985912322998
printing an ep nov before normalisation:  32.9671669625373
actions average: 
K:  3  action  0 :  tensor([    0.9286,     0.0003,     0.0000,     0.0586,     0.0125],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9997,     0.0001,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9585,     0.0366,     0.0049],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0010,     0.0002,     0.0303,     0.8613,     0.1072],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0014, 0.0036, 0.0166, 0.7286, 0.2497], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.92172134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  20.074532474413257
siam score:  -0.9210977
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.981165867522062
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.686]
 [41.686]
 [41.686]
 [51.86 ]
 [41.686]] [[0.853]
 [0.853]
 [0.853]
 [1.064]
 [0.853]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.40995803583792
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.487 0.128 0.128 0.154 0.103]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.428]
 [18.463]
 [18.281]
 [22.105]
 [17.632]] [[0.128]
 [0.143]
 [0.141]
 [0.195]
 [0.131]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.343]
 [52.343]
 [52.343]
 [80.402]
 [52.343]] [[0.459]
 [0.459]
 [0.459]
 [0.814]
 [0.459]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.619]
 [67.619]
 [67.619]
 [68.829]
 [67.619]] [[0.979]
 [0.979]
 [0.979]
 [1.   ]
 [0.979]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.11280434903489
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.526]
 [57.526]
 [57.526]
 [61.58 ]
 [57.526]] [[1.25 ]
 [1.25 ]
 [1.25 ]
 [1.384]
 [1.25 ]]
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.383]
 [41.383]
 [60.291]
 [44.082]
 [41.383]] [[0.778]
 [0.778]
 [1.22 ]
 [0.841]
 [0.778]]
printing an ep nov before normalisation:  66.75658917929634
line 256 mcts: sample exp_bonus 54.00351262826788
siam score:  -0.9278698
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00010152314246170135
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  82.56357735887954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.955]
 [33.435]
 [26.501]
 [28.299]
 [27.66 ]] [[0.809]
 [0.482]
 [0.315]
 [0.358]
 [0.343]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.27041811690832
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.34227446227892
printing an ep nov before normalisation:  36.601061881793825
printing an ep nov before normalisation:  83.02721224512291
printing an ep nov before normalisation:  46.641552325626975
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  69.93229171705254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  28.939890703223256
printing an ep nov before normalisation:  33.223245116639596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
siam score:  -0.9208058
printing an ep nov before normalisation:  53.79193090844903
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.849]
 [27.849]
 [27.849]
 [40.446]
 [27.849]] [[0.292]
 [0.292]
 [0.292]
 [0.511]
 [0.292]]
printing an ep nov before normalisation:  23.27700951023417
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.40059311677353
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  24.13960668508112
printing an ep nov before normalisation:  73.2232854954697
printing an ep nov before normalisation:  58.86411711476942
printing an ep nov before normalisation:  58.467093122425105
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.517228603363037
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.905]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[ 0.663]
 [-0.305]
 [-0.305]
 [-0.305]
 [-0.305]]
printing an ep nov before normalisation:  46.65760529600673
printing an ep nov before normalisation:  57.34486348158104
printing an ep nov before normalisation:  81.40369550497147
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.535905530659242
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  79.62178346603328
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91695434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.76601865820348
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.46]
 [44.46]
 [44.46]
 [44.46]
 [44.46]] [[1.014]
 [1.014]
 [1.014]
 [1.014]
 [1.014]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  45.63667893645705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.004]
 [20.208]
 [14.119]
 [48.992]
 [18.882]] [[0.232]
 [0.161]
 [0.087]
 [0.512]
 [0.145]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.61129888866444
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.58 ]
 [23.58 ]
 [23.58 ]
 [30.283]
 [23.58 ]] [[0.649]
 [0.649]
 [0.649]
 [1.   ]
 [0.649]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.4  ]
 [18.177]
 [15.643]
 [41.284]
 [13.253]] [[0.172]
 [0.169]
 [0.13 ]
 [0.52 ]
 [0.094]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  85.76650201997522
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[79.456]
 [79.456]
 [79.456]
 [82.884]
 [79.456]] [[0.889]
 [0.889]
 [0.889]
 [0.936]
 [0.889]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.238]
 [75.238]
 [75.238]
 [76.753]
 [75.238]] [[1.27 ]
 [1.27 ]
 [1.27 ]
 [1.303]
 [1.27 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.677]
 [24.677]
 [24.677]
 [58.617]
 [24.677]] [[0.222]
 [0.222]
 [0.222]
 [0.859]
 [0.222]]
printing an ep nov before normalisation:  58.44905729363901
actions average: 
K:  4  action  0 :  tensor([    0.9995,     0.0001,     0.0000,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0033, 0.9364, 0.0052, 0.0030, 0.0520], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0002,     0.9619,     0.0053,     0.0326],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0012,     0.0008,     0.0180,     0.8725,     0.1075],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0075, 0.0032, 0.0430, 0.5659, 0.3804], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.76245493539405
printing an ep nov before normalisation:  41.804146729803136
printing an ep nov before normalisation:  71.8247943457457
printing an ep nov before normalisation:  70.63090242151944
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9974,     0.0000,     0.0000,     0.0002,     0.0024],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9952,     0.0039,     0.0001,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.8180,     0.1689,     0.0131],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0002,     0.0202,     0.8885,     0.0908],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0001,     0.0024,     0.0197,     0.7604,     0.2174],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  17.492714021050364
printing an ep nov before normalisation:  73.28126147898448
siam score:  -0.92349046
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.95060893497856
printing an ep nov before normalisation:  17.056031227111816
printing an ep nov before normalisation:  90.72361826248081
maxi score, test score, baseline:  0.0001 0.0 0.0001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.975]
 [26.975]
 [28.72 ]
 [47.865]
 [26.975]] [[0.471]
 [0.471]
 [0.524]
 [1.101]
 [0.471]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.083]
 [50.083]
 [50.083]
 [50.083]
 [50.083]] [[33.405]
 [33.405]
 [33.405]
 [33.405]
 [33.405]]
printing an ep nov before normalisation:  23.26382875442505
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.411634625475386
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.391866957035624
printing an ep nov before normalisation:  55.963519231347234
printing an ep nov before normalisation:  32.16142654418945
printing an ep nov before normalisation:  62.08565650971796
printing an ep nov before normalisation:  20.30091572937935
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9219067
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  91.47338131404096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.26508030862813
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.484]
 [24.998]
 [23.171]
 [52.888]
 [22.034]] [[0.313]
 [0.236]
 [0.204]
 [0.719]
 [0.184]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.258]
 [27.712]
 [25.73 ]
 [59.56 ]
 [24.779]] [[0.275]
 [0.08 ]
 [0.063]
 [0.356]
 [0.055]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  85.6358744455589
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  86.08436679620723
printing an ep nov before normalisation:  98.24096742330592
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  74.0447909962233
printing an ep nov before normalisation:  66.0594664154012
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.03 ]
 [77.03 ]
 [77.03 ]
 [80.769]
 [77.03 ]] [[1.576]
 [1.576]
 [1.576]
 [1.667]
 [1.576]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  81.25969719680701
printing an ep nov before normalisation:  75.46170826719896
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.268]
 [32.268]
 [32.268]
 [66.53 ]
 [32.268]] [[0.266]
 [0.266]
 [0.266]
 [0.746]
 [0.266]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.241]
 [46.899]
 [40.241]
 [57.36 ]
 [40.241]] [[0.698]
 [0.886]
 [0.698]
 [1.181]
 [0.698]]
printing an ep nov before normalisation:  63.85335961298088
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.012154557336046
printing an ep nov before normalisation:  33.83116006851196
printing an ep nov before normalisation:  80.36615680867543
printing an ep nov before normalisation:  63.149640485798244
actions average: 
K:  3  action  0 :  tensor([    0.9992,     0.0004,     0.0000,     0.0003,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0874,     0.9099,     0.0002,     0.0000,     0.0024],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0001,     0.8507,     0.1365,     0.0125],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0019, 0.0094, 0.0185, 0.9022, 0.0679], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0023, 0.0040, 0.0134, 0.6305, 0.3498], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9206003
printing an ep nov before normalisation:  72.74643463931638
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.241]
 [41.241]
 [41.241]
 [41.904]
 [41.241]] [[1.3  ]
 [1.3  ]
 [1.3  ]
 [1.333]
 [1.3  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  83.66561020447104
printing an ep nov before normalisation:  62.573415730335924
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 74.05068077905051
printing an ep nov before normalisation:  85.51860405867963
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.098]
 [66.098]
 [66.098]
 [75.997]
 [66.098]] [[0.948]
 [0.948]
 [0.948]
 [1.108]
 [0.948]]
siam score:  -0.9130653
printing an ep nov before normalisation:  42.0649848115616
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.612]
 [18.049]
 [14.574]
 [12.588]
 [50.612]] [[4.437]
 [1.   ]
 [0.633]
 [0.424]
 [4.437]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.081]
 [67.081]
 [67.081]
 [74.142]
 [67.081]] [[0.692]
 [0.692]
 [0.692]
 [0.765]
 [0.692]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9943,     0.0000,     0.0000,     0.0034,     0.0023],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0184, 0.9473, 0.0182, 0.0085, 0.0077], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0002,     0.9325,     0.0412,     0.0261],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0001,     0.0224,     0.8749,     0.1024],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0028,     0.2082,     0.2517,     0.5370],
       grad_fn=<DivBackward0>)
actions average: 
K:  4  action  0 :  tensor([    0.9842,     0.0003,     0.0000,     0.0120,     0.0036],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9989,     0.0001,     0.0000,     0.0010],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.8175,     0.1679,     0.0146],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0008,     0.0003,     0.0350,     0.8611,     0.1029],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0019, 0.0109, 0.0059, 0.7048, 0.2764], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  38.36695194244385
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.30471611022949
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.143]
 [34.184]
 [33.03 ]
 [47.451]
 [28.808]] [[0.263]
 [0.433]
 [0.408]
 [0.714]
 [0.319]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.49791125567404
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.722641212289
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  72.8144493460805
printing an ep nov before normalisation:  66.2422604696059
siam score:  -0.9207993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([0.9661, 0.0158, 0.0105, 0.0042, 0.0035], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9793,     0.0007,     0.0000,     0.0199],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0003,     0.9983,     0.0003,     0.0011],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0000,     0.0063,     0.8944,     0.0991],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0001,     0.0012,     0.0701,     0.5527,     0.3758],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  45.799679070334975
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.661372757083214
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  46.75242420280397
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.203]
 [32.693]
 [29.956]
 [33.577]
 [27.192]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.853]
 [40.853]
 [40.853]
 [40.853]
 [40.853]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.327]
 [27.236]
 [27.559]
 [23.012]
 [25.782]] [[0.95 ]
 [0.334]
 [0.345]
 [0.198]
 [0.287]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.671708669268355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.489]
 [40.262]
 [40.262]
 [55.142]
 [40.262]] [[0.872]
 [0.673]
 [0.673]
 [1.082]
 [0.673]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.75965682713051
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  23.78566265106201
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.631]
 [20.631]
 [20.631]
 [42.407]
 [20.631]] [[0.355]
 [0.355]
 [0.355]
 [0.989]
 [0.355]]
printing an ep nov before normalisation:  32.99674034118652
printing an ep nov before normalisation:  42.95022469102234
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9803,     0.0038,     0.0000,     0.0002,     0.0156],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0070,     0.9907,     0.0004,     0.0000,     0.0019],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9134,     0.0779,     0.0086],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0002,     0.0123,     0.8901,     0.0972],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0010,     0.0003,     0.0007,     0.7386,     0.2595],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.99446256436542
actions average: 
K:  3  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0006,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0113, 0.9184, 0.0156, 0.0423, 0.0124], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0168, 0.0209, 0.9044, 0.0466, 0.0113], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0401,     0.0001,     0.0171,     0.8763,     0.0665],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0331, 0.0374, 0.0124, 0.5689, 0.3482], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.48]
 [34.48]
 [34.48]
 [34.48]
 [34.48]] [[0.758]
 [0.758]
 [0.758]
 [0.758]
 [0.758]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.618]
 [35.035]
 [35.035]
 [34.663]
 [35.035]] [[1.907]
 [1.526]
 [1.526]
 [1.496]
 [1.526]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.28773212432861
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  4  action  0 :  tensor([    0.9966,     0.0000,     0.0000,     0.0022,     0.0011],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0005,     0.9441,     0.0002,     0.0104,     0.0448],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9770,     0.0004,     0.0225],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0003,     0.0193,     0.8939,     0.0862],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0003,     0.0008,     0.1360,     0.6614,     0.2015],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  50.528536621905424
printing an ep nov before normalisation:  31.2901060088263
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.704091469943194
printing an ep nov before normalisation:  55.30311416777533
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  17.750493959203254
printing an ep nov before normalisation:  34.95603778372754
printing an ep nov before normalisation:  0.0001644144685997162
printing an ep nov before normalisation:  56.50563171850489
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.581260570001504
printing an ep nov before normalisation:  37.56969545161596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 44.52544881769314
printing an ep nov before normalisation:  34.79225158691406
siam score:  -0.91767466
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.123]
 [33.123]
 [40.537]
 [33.123]
 [33.123]] [[1.007]
 [1.007]
 [1.478]
 [1.007]
 [1.007]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.827]
 [65.827]
 [65.827]
 [65.827]
 [65.827]] [[1.934]
 [1.934]
 [1.934]
 [1.934]
 [1.934]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.317]
 [65.317]
 [65.317]
 [65.317]
 [65.317]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9151015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.691]
 [43.691]
 [43.691]
 [43.691]
 [43.691]] [[1.322]
 [1.322]
 [1.322]
 [1.322]
 [1.322]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 48.21926017380526
printing an ep nov before normalisation:  18.418501061190256
using explorer policy with actor:  1
UNIT TEST: sample policy line 217 mcts : [0.    0.103 0.436 0.308 0.154]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.38345089217104
printing an ep nov before normalisation:  58.496312748431905
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.509192943573
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.64771309074408
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.95117596167408
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.323]
 [60.323]
 [60.323]
 [62.392]
 [60.323]] [[1.364]
 [1.364]
 [1.364]
 [1.45 ]
 [1.364]]
actions average: 
K:  1  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0000],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0016,     0.9932,     0.0021,     0.0002,     0.0030],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9257,     0.0695,     0.0049],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0020,     0.0005,     0.0172,     0.8702,     0.1101],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0003,     0.0030,     0.1153,     0.7075,     0.1739],
       grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.703]
 [60.703]
 [60.703]
 [60.703]
 [60.703]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  0  action  0 :  tensor([0.9652, 0.0084, 0.0064, 0.0143, 0.0056], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0002,     0.9787,     0.0002,     0.0208],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0011,     0.0003,     0.0152,     0.8981,     0.0853],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0054, 0.0105, 0.0515, 0.3666, 0.5661], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.525]
 [40.525]
 [49.013]
 [40.525]
 [40.525]] [[1.158]
 [1.158]
 [1.533]
 [1.158]
 [1.158]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.08824113510225
printing an ep nov before normalisation:  43.33926391969353
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.2  ]
 [46.263]
 [46.263]
 [47.047]
 [46.263]] [[1.591]
 [1.447]
 [1.447]
 [1.486]
 [1.447]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.402753129211035
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.76850937026206
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.54671416406302
siam score:  -0.9201114
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.455750465393066
printing an ep nov before normalisation:  53.89733292995612
printing an ep nov before normalisation:  89.28436512906622
siam score:  -0.9202917
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.728]
 [34.728]
 [34.728]
 [37.774]
 [34.728]] [[0.925]
 [0.925]
 [0.925]
 [1.067]
 [0.925]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.395]
 [51.395]
 [51.395]
 [51.585]
 [51.395]] [[1.655]
 [1.655]
 [1.655]
 [1.667]
 [1.655]]
printing an ep nov before normalisation:  0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.955]
 [37.626]
 [29.969]
 [27.011]
 [33.557]] [[0.743]
 [1.075]
 [0.743]
 [0.615]
 [0.899]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  62.128431472070254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.9979829788208
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 25.65169314240314
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.027]
 [35.359]
 [31.24 ]
 [29.182]
 [31.392]] [[0.763]
 [1.021]
 [0.822]
 [0.722]
 [0.829]]
printing an ep nov before normalisation:  55.364987822086086
printing an ep nov before normalisation:  64.61491441338029
printing an ep nov before normalisation:  38.60455116212664
actions average: 
K:  3  action  0 :  tensor([0.9752, 0.0190, 0.0031, 0.0014, 0.0013], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9984,     0.0001,     0.0000,     0.0015],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9679,     0.0001,     0.0319],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0005,     0.0123,     0.8831,     0.1038],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0001,     0.0004,     0.0516,     0.6158,     0.3321],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.647]
 [59.647]
 [59.647]
 [62.459]
 [59.647]] [[1.247]
 [1.247]
 [1.247]
 [1.333]
 [1.247]]
printing an ep nov before normalisation:  42.69862643071574
printing an ep nov before normalisation:  57.854081621010415
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.563]
 [42.563]
 [42.563]
 [42.563]
 [42.563]] [[1.197]
 [1.197]
 [1.197]
 [1.197]
 [1.197]]
printing an ep nov before normalisation:  50.80552753381284
printing an ep nov before normalisation:  0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.512545831150916
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91811526
printing an ep nov before normalisation:  25.137767791748047
siam score:  -0.9171834
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.591255710031945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.935]
 [43.935]
 [43.935]
 [43.935]
 [43.935]] [[0.852]
 [0.852]
 [0.852]
 [0.852]
 [0.852]]
siam score:  -0.92251456
printing an ep nov before normalisation:  44.70821800618323
printing an ep nov before normalisation:  50.21972561032586
printing an ep nov before normalisation:  42.82135086668014
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.1385925908165
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([0.9644, 0.0076, 0.0056, 0.0170, 0.0055], grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0008,     0.9591,     0.0109,     0.0292],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0008,     0.0033,     0.0313,     0.8536,     0.1110],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0023,     0.0004,     0.0189,     0.5739,     0.4044],
       grad_fn=<DivBackward0>)
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 42.8101626523008
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.57 ]
 [35.456]
 [34.149]
 [39.235]
 [33.805]] [[0.97 ]
 [0.796]
 [0.741]
 [0.956]
 [0.727]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.76433173239418
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.06322927909123
printing an ep nov before normalisation:  27.13873863220215
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  71.44436728894553
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.93]
 [27.93]
 [27.93]
 [27.93]
 [27.93]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.57082716426341
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.099]
 [37.099]
 [37.099]
 [37.099]
 [37.099]] [[1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.91317964
printing an ep nov before normalisation:  46.25951413299356
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.493647804765395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.590206418718616
printing an ep nov before normalisation:  36.00724352155335
printing an ep nov before normalisation:  90.9420401069072
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9185022
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.67292668339021
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.723019678197886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.74522193770885
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.967]
 [27.967]
 [34.532]
 [29.971]
 [27.967]] [[0.35 ]
 [0.35 ]
 [0.506]
 [0.398]
 [0.35 ]]
printing an ep nov before normalisation:  48.74462178288666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.92 ]
 [37.487]
 [38.265]
 [46.263]
 [49.512]] [[0.405]
 [0.325]
 [0.336]
 [0.454]
 [0.502]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.703288256699025
printing an ep nov before normalisation:  36.333038355294995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  60.06793733334844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.53174004636507
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.672]
 [38.06 ]
 [34.497]
 [29.444]
 [34.497]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.996617126042334
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.256]
 [33.202]
 [31.869]
 [29.517]
 [29.684]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.92177284
printing an ep nov before normalisation:  47.86174218286847
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.7  ]
 [35.493]
 [29.7  ]
 [32.717]
 [29.7  ]] [[0.858]
 [1.196]
 [0.858]
 [1.034]
 [0.858]]
printing an ep nov before normalisation:  16.838853699820383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.351630658932805
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9626,     0.0003,     0.0000,     0.0303,     0.0069],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9986,     0.0001,     0.0005,     0.0008],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0015,     0.0006,     0.9590,     0.0332,     0.0056],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0001,     0.0114,     0.8827,     0.1058],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0004,     0.0019,     0.0693,     0.6837,     0.2446],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.007]
 [31.007]
 [41.929]
 [31.007]
 [31.007]] [[0.831]
 [0.831]
 [1.388]
 [0.831]
 [0.831]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.78938149750143
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.691]
 [52.691]
 [52.691]
 [51.993]
 [52.691]] [[1.689]
 [1.689]
 [1.689]
 [1.649]
 [1.689]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  60.426043714819414
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.582]
 [57.582]
 [47.918]
 [52.376]
 [57.582]] [[1.743]
 [1.743]
 [1.273]
 [1.49 ]
 [1.743]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  66.84119032055843
printing an ep nov before normalisation:  31.644177129615915
printing an ep nov before normalisation:  64.96018483708589
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.596]
 [43.102]
 [49.068]
 [49.549]
 [45.438]] [[0.611]
 [1.064]
 [1.424]
 [1.453]
 [1.205]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.16631540029752
printing an ep nov before normalisation:  51.82818169096828
printing an ep nov before normalisation:  64.65718896688473
siam score:  -0.9127153
printing an ep nov before normalisation:  72.39659174839831
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.1631514451975
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.259663105010986
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  0  action  0 :  tensor([    0.9986,     0.0000,     0.0000,     0.0002,     0.0011],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9962,     0.0002,     0.0000,     0.0036],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9663,     0.0303,     0.0034],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0007,     0.0006,     0.0198,     0.8811,     0.0978],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0011,     0.0002,     0.0002,     0.8248,     0.1738],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.098678161783376
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  51.22428027882211
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.618]
 [50.618]
 [50.618]
 [49.921]
 [50.618]] [[0.629]
 [0.629]
 [0.629]
 [0.615]
 [0.629]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.3878231048584
line 256 mcts: sample exp_bonus 27.44690710482184
siam score:  -0.9202698
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.972]
 [43.972]
 [43.972]
 [48.315]
 [50.9  ]] [[1.109]
 [1.109]
 [1.109]
 [1.275]
 [1.374]]
printing an ep nov before normalisation:  60.73954493598299
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.22045425982594
printing an ep nov before normalisation:  34.12778939716992
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.3470229284592
printing an ep nov before normalisation:  41.969762410094525
printing an ep nov before normalisation:  65.77028284683993
printing an ep nov before normalisation:  55.749949418897344
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.85668468475342
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.863473892211914
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.72653311521048
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.077 0.179 0.462 0.154 0.128]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.3402213385903
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.91877365
printing an ep nov before normalisation:  0.07570130159422206
printing an ep nov before normalisation:  31.51805531071306
siam score:  -0.9203467
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.314]
 [37.22 ]
 [30.314]
 [35.208]
 [33.764]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  39.55401420593262
using explorer policy with actor:  1
printing an ep nov before normalisation:  47.91888192259013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.7068067627612
siam score:  -0.9192929
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.36603576848725
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.295]
 [35.821]
 [40.824]
 [38.016]
 [39.107]] [[0.996]
 [0.931]
 [1.151]
 [1.028]
 [1.076]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.692]
 [33.835]
 [33.835]
 [38.7  ]
 [33.835]] [[1.2  ]
 [0.809]
 [0.809]
 [1.002]
 [0.809]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91607237
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.11132501231514
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  64.8768629986514
line 256 mcts: sample exp_bonus 30.776958650987478
siam score:  -0.91413045
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.754]
 [47.754]
 [47.754]
 [48.116]
 [47.754]] [[1.144]
 [1.144]
 [1.144]
 [1.159]
 [1.144]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.00599851113123
printing an ep nov before normalisation:  56.85611658999387
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  52.799660236994406
printing an ep nov before normalisation:  43.95562505025712
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.864]
 [47.286]
 [34.864]
 [34.864]
 [34.864]] [[0.951]
 [1.676]
 [0.951]
 [0.951]
 [0.951]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.468]
 [27.468]
 [48.685]
 [27.468]
 [27.468]] [[0.494]
 [0.494]
 [1.22 ]
 [0.494]
 [0.494]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 51.77420560156274
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  62.92618215807363
printing an ep nov before normalisation:  46.97831137776838
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  65.84955419326717
printing an ep nov before normalisation:  59.95220675413269
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.87310144815203
printing an ep nov before normalisation:  23.982882499694824
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.483]
 [57.483]
 [57.483]
 [57.483]
 [57.483]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.471]
 [32.471]
 [32.471]
 [44.569]
 [32.471]] [[0.217]
 [0.217]
 [0.217]
 [0.345]
 [0.217]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.53 ]
 [55.53 ]
 [70.301]
 [55.53 ]
 [55.53 ]] [[1.333]
 [1.333]
 [1.687]
 [1.333]
 [1.333]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.27989570858763
printing an ep nov before normalisation:  45.77962557474772
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.956]
 [36.085]
 [52.11 ]
 [38.615]
 [36.085]] [[0.849]
 [1.023]
 [1.477]
 [1.095]
 [1.023]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.031]
 [33.349]
 [42.364]
 [28.89 ]
 [35.582]] [[0.435]
 [0.495]
 [0.729]
 [0.379]
 [0.553]]
siam score:  -0.9144091
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  3.5160126117261825e-05
actions average: 
K:  3  action  0 :  tensor([    0.9931,     0.0002,     0.0000,     0.0047,     0.0020],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0313, 0.9382, 0.0100, 0.0142, 0.0063], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0010, 0.0024, 0.9601, 0.0214, 0.0151], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0001,     0.0184,     0.8948,     0.0866],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0002,     0.0244,     0.0447,     0.3488,     0.5820],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  37.32056894598559
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.828]
 [52.828]
 [52.828]
 [52.828]
 [52.828]] [[1.497]
 [1.497]
 [1.497]
 [1.497]
 [1.497]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  74.75047685495852
printing an ep nov before normalisation:  40.08949756854001
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  76.6947142029471
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.9471826569129
printing an ep nov before normalisation:  37.147444571755884
printing an ep nov before normalisation:  65.6514413308356
printing an ep nov before normalisation:  42.77631640434265
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91694504
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0001,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0017,     0.9576,     0.0002,     0.0403,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0002,     0.9488,     0.0300,     0.0211],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0004,     0.0147,     0.8936,     0.0911],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0017, 0.0016, 0.0655, 0.4175, 0.5137], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  60.64713715454307
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.791]
 [71.791]
 [71.791]
 [71.791]
 [71.791]] [[0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]]
siam score:  -0.9149033
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  81.42458232201638
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  26.836288188738216
siam score:  -0.90768766
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  78.96370099020395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.093911334164638
printing an ep nov before normalisation:  63.6347542543352
printing an ep nov before normalisation:  23.967048022487905
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.746576153485165
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.161]
 [26.461]
 [25.152]
 [24.132]
 [22.692]] [[0.19 ]
 [0.182]
 [0.167]
 [0.155]
 [0.139]]
printing an ep nov before normalisation:  67.15235947547858
printing an ep nov before normalisation:  44.937835298385714
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  88.83416478110396
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.005]
 [38.005]
 [38.005]
 [45.886]
 [38.005]] [[0.421]
 [0.421]
 [0.421]
 [0.57 ]
 [0.421]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.065620419864718
printing an ep nov before normalisation:  61.656703065747486
printing an ep nov before normalisation:  36.575574796007125
printing an ep nov before normalisation:  23.869905471801758
siam score:  -0.9111732
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.72305465311927
printing an ep nov before normalisation:  61.824058100424665
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.756]
 [44.756]
 [43.424]
 [47.885]
 [44.756]] [[1.093]
 [1.093]
 [1.043]
 [1.213]
 [1.093]]
printing an ep nov before normalisation:  59.766035524140705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.93898193466619
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  21.834096908569336
actions average: 
K:  2  action  0 :  tensor([0.9275, 0.0089, 0.0041, 0.0373, 0.0222], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9634,     0.0314,     0.0052],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0036, 0.0015, 0.0175, 0.8552, 0.1223], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0051,     0.0004,     0.0128,     0.7277,     0.2540],
       grad_fn=<DivBackward0>)
UNIT TEST: sample policy line 217 mcts : [0.128 0.026 0.256 0.051 0.538]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.82551374239388
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.0824089050293
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.44563366528373
printing an ep nov before normalisation:  57.589994439858394
printing an ep nov before normalisation:  55.8869882722319
printing an ep nov before normalisation:  25.814082887437607
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.063]
 [29.368]
 [28.221]
 [45.598]
 [31.007]] [[0.4  ]
 [0.255]
 [0.236]
 [0.526]
 [0.283]]
actions average: 
K:  3  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9925,     0.0039,     0.0001,     0.0034],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.8579,     0.1292,     0.0129],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0016, 0.0016, 0.0300, 0.8712, 0.0956], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0009, 0.0052, 0.0734, 0.3687, 0.5517], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.014]
 [29.147]
 [36.539]
 [29.301]
 [31.881]] [[0.89 ]
 [0.897]
 [1.333]
 [0.906]
 [1.059]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.18501018964032
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.8060914641539
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  45.45503855512582
printing an ep nov before normalisation:  0.0
siam score:  -0.91789156
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.994]
 [28.098]
 [29.76 ]
 [30.87 ]
 [27.235]] [[0.617]
 [0.456]
 [0.501]
 [0.532]
 [0.432]]
printing an ep nov before normalisation:  53.96123531365763
printing an ep nov before normalisation:  61.754350662231445
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.472]
 [39.472]
 [39.472]
 [39.472]
 [39.472]] [[0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]]
printing an ep nov before normalisation:  63.78602068501443
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.066]
 [28.066]
 [37.549]
 [29.348]
 [28.066]] [[0.702]
 [0.702]
 [1.154]
 [0.763]
 [0.702]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.79287018357254
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.077293497557434
printing an ep nov before normalisation:  64.17314313310251
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.15 ]
 [32.133]
 [32.133]
 [32.133]
 [32.133]] [[1.112]
 [0.649]
 [0.649]
 [0.649]
 [0.649]]
printing an ep nov before normalisation:  58.15594480501621
printing an ep nov before normalisation:  43.50280168458155
printing an ep nov before normalisation:  31.368389129638672
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.99168438235228
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.36838881559558
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.59955547221891
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.727]
 [29.727]
 [48.814]
 [42.609]
 [29.727]] [[0.54 ]
 [0.54 ]
 [1.2  ]
 [0.985]
 [0.54 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91077787
printing an ep nov before normalisation:  36.86820686941824
printing an ep nov before normalisation:  28.450349165824125
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  70.22385631339141
siam score:  -0.91131455
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.008]
 [63.008]
 [63.008]
 [65.317]
 [63.008]] [[0.589]
 [0.589]
 [0.589]
 [0.62 ]
 [0.589]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.9138443
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.933]
 [47.933]
 [47.933]
 [46.446]
 [47.933]] [[1.815]
 [1.815]
 [1.815]
 [1.732]
 [1.815]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.724]
 [31.131]
 [36.822]
 [31.556]
 [33.637]] [[0.869]
 [0.78 ]
 [1.098]
 [0.804]
 [0.92 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  24.931559562683105
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  67.57918129143232
using explorer policy with actor:  1
printing an ep nov before normalisation:  54.341763240665266
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.231 0.026 0.282 0.333 0.128]
printing an ep nov before normalisation:  43.76732659589305
printing an ep nov before normalisation:  41.29636255913612
printing an ep nov before normalisation:  0.05986429423643358
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  38.72362362831261
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.20413464956557
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.997158448836885
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.70837627271976
line 256 mcts: sample exp_bonus 30.79671754785387
printing an ep nov before normalisation:  30.21810207753126
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.579]
 [26.579]
 [38.771]
 [26.579]
 [26.579]] [[0.579]
 [0.579]
 [1.085]
 [0.579]
 [0.579]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.509]
 [27.078]
 [27.078]
 [29.255]
 [27.078]] [[0.286]
 [0.207]
 [0.207]
 [0.239]
 [0.207]]
printing an ep nov before normalisation:  37.99601824033432
printing an ep nov before normalisation:  75.50527943123133
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.273]
 [41.273]
 [41.273]
 [41.273]
 [41.273]] [[1.646]
 [1.646]
 [1.646]
 [1.646]
 [1.646]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  91.823586886008
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.67248315039837
printing an ep nov before normalisation:  54.77812214175927
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9951,     0.0001,     0.0000,     0.0002,     0.0046],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9967,     0.0009,     0.0003,     0.0020],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0009,     0.0019,     0.9183,     0.0626,     0.0164],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0011,     0.0002,     0.0165,     0.8674,     0.1149],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0022, 0.0278, 0.0401, 0.5848, 0.3453], grad_fn=<DivBackward0>)
actions average: 
K:  2  action  0 :  tensor([    0.9681,     0.0021,     0.0000,     0.0003,     0.0295],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0004,     0.0003,     0.9574,     0.0368,     0.0052],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0008,     0.0013,     0.0211,     0.8487,     0.1281],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0015, 0.1030, 0.0166, 0.5214, 0.3576], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.2722023701915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.028091286528735
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.107]
 [65.107]
 [65.107]
 [65.107]
 [65.107]] [[1.028]
 [1.028]
 [1.028]
 [1.028]
 [1.028]]
line 256 mcts: sample exp_bonus 28.719464911793278
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.00017720935034049035
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.352]
 [55.352]
 [60.982]
 [55.352]
 [55.352]] [[1.055]
 [1.055]
 [1.238]
 [1.055]
 [1.055]]
actions average: 
K:  4  action  0 :  tensor([    0.9987,     0.0004,     0.0000,     0.0001,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9989,     0.0003,     0.0000,     0.0008],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0007,     0.0145,     0.9641,     0.0054,     0.0153],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0053, 0.0064, 0.0207, 0.8731, 0.0945], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0018, 0.0011, 0.0139, 0.6514, 0.3319], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  44.449138359251904
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.56813907623291
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.575]
 [47.86 ]
 [43.575]
 [52.145]
 [48.527]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  63.29513342072532
UNIT TEST: sample policy line 217 mcts : [0.59  0.026 0.308 0.051 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.882322692288604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.731]
 [53.714]
 [34.348]
 [47.699]
 [34.348]] [[0.572]
 [0.662]
 [0.225]
 [0.526]
 [0.225]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.359 0.282 0.051 0.077 0.231]
line 256 mcts: sample exp_bonus 34.661716930287845
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.502237587881055
actions average: 
K:  3  action  0 :  tensor([    0.9961,     0.0000,     0.0000,     0.0031,     0.0008],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0072,     0.9829,     0.0002,     0.0003,     0.0094],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0007,     0.0140,     0.9704,     0.0015,     0.0135],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0022,     0.0008,     0.0208,     0.8407,     0.1356],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0006,     0.1646,     0.0005,     0.6726,     0.1617],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.927972038637215
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  34.34056043624878
printing an ep nov before normalisation:  43.83058334813484
printing an ep nov before normalisation:  51.85824080782876
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.94 ]
 [43.976]
 [37.866]
 [41.361]
 [45.127]] [[0.847]
 [0.821]
 [0.65 ]
 [0.748]
 [0.853]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.62427137231844
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.35 ]
 [25.747]
 [19.796]
 [20.55 ]
 [20.268]] [[0.692]
 [0.371]
 [0.22 ]
 [0.239]
 [0.232]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.34242201462634
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  1  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0001,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0328, 0.9170, 0.0251, 0.0101, 0.0149], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9988,     0.0010,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0002,     0.0131,     0.8941,     0.0923],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0004,     0.0015,     0.0100,     0.7116,     0.2765],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.946]
 [46.471]
 [34.091]
 [28.278]
 [33.819]] [[0.157]
 [0.26 ]
 [0.191]
 [0.158]
 [0.19 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.191]
 [37.494]
 [26.976]
 [30.768]
 [37.494]] [[1.103]
 [0.822]
 [0.481]
 [0.604]
 [0.822]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.272]
 [49.81 ]
 [41.272]
 [37.226]
 [41.919]] [[0.815]
 [1.171]
 [0.815]
 [0.646]
 [0.842]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.696]
 [66.696]
 [66.696]
 [67.133]
 [66.696]] [[1.401]
 [1.401]
 [1.401]
 [1.415]
 [1.401]]
printing an ep nov before normalisation:  58.51137775389106
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.855169812035875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.26028308962597
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.056]
 [29.259]
 [26.056]
 [26.056]
 [26.056]] [[0.193]
 [0.254]
 [0.193]
 [0.193]
 [0.193]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.85066053256633
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.909]
 [73.909]
 [73.909]
 [73.909]
 [73.909]] [[1.964]
 [1.964]
 [1.964]
 [1.964]
 [1.964]]
printing an ep nov before normalisation:  36.442845688181016
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.163]
 [20.479]
 [27.163]
 [35.696]
 [28.781]] [[0.401]
 [0.213]
 [0.401]
 [0.64 ]
 [0.446]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.482]
 [39.482]
 [46.914]
 [39.482]
 [39.482]] [[1.017]
 [1.017]
 [1.37 ]
 [1.017]
 [1.017]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.948375251195756
siam score:  -0.90677744
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.903]
 [30.654]
 [34.085]
 [22.362]
 [25.462]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.255]
 [33.144]
 [42.067]
 [26.972]
 [26.896]] [[0.265]
 [0.251]
 [0.365]
 [0.173]
 [0.172]]
printing an ep nov before normalisation:  44.165320436957884
actions average: 
K:  1  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0002,     0.0010],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9914,     0.0005,     0.0000,     0.0081],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9770,     0.0006,     0.0223],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0031,     0.0008,     0.0217,     0.8807,     0.0937],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0331, 0.0502, 0.0148, 0.3572, 0.5447], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  4.3843817820743425e-06
printing an ep nov before normalisation:  29.833740063102073
printing an ep nov before normalisation:  37.67997256765806
printing an ep nov before normalisation:  42.35370578268643
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.314]
 [35.314]
 [36.072]
 [35.896]
 [38.526]] [[0.69 ]
 [0.69 ]
 [0.717]
 [0.711]
 [0.806]]
printing an ep nov before normalisation:  41.08894406714135
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.740782676385386
printing an ep nov before normalisation:  40.631092107154224
printing an ep nov before normalisation:  62.1507180062459
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.543]
 [49.924]
 [49.521]
 [39.84 ]
 [38.573]] [[0.709]
 [1.743]
 [1.72 ]
 [1.176]
 [1.104]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.849690110745804
siam score:  -0.9094708
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.74 ]
 [40.74 ]
 [46.528]
 [45.605]
 [40.74 ]] [[1.4  ]
 [1.4  ]
 [1.687]
 [1.642]
 [1.4  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.781]
 [37.781]
 [62.794]
 [38.536]
 [37.781]] [[0.519]
 [0.519]
 [1.173]
 [0.538]
 [0.519]]
printing an ep nov before normalisation:  51.66367245660971
printing an ep nov before normalisation:  37.75042749543987
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.269]
 [32.269]
 [50.629]
 [32.269]
 [32.269]] [[0.586]
 [0.586]
 [1.221]
 [0.586]
 [0.586]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.789]
 [68.789]
 [67.918]
 [71.315]
 [68.789]] [[1.595]
 [1.595]
 [1.571]
 [1.667]
 [1.595]]
printing an ep nov before normalisation:  69.2152986669597
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.39420691531376
printing an ep nov before normalisation:  33.44303695984475
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.191]
 [22.191]
 [22.191]
 [22.191]
 [22.191]] [[0.082]
 [0.082]
 [0.082]
 [0.082]
 [0.082]]
printing an ep nov before normalisation:  52.7126037787246
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.535]
 [50.535]
 [50.535]
 [50.535]
 [50.535]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.494]
 [30.379]
 [33.668]
 [30.379]
 [30.379]] [[1.377]
 [1.367]
 [1.649]
 [1.367]
 [1.367]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.301]
 [34.301]
 [39.108]
 [34.301]
 [34.301]] [[0.943]
 [0.943]
 [1.186]
 [0.943]
 [0.943]]
printing an ep nov before normalisation:  36.78562871196662
printing an ep nov before normalisation:  54.72813507798484
printing an ep nov before normalisation:  51.72451800884555
line 256 mcts: sample exp_bonus 34.830954772478954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.13205060613006
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91104484
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.531]
 [53.531]
 [53.531]
 [53.531]
 [53.531]] [[1.404]
 [1.404]
 [1.404]
 [1.404]
 [1.404]]
printing an ep nov before normalisation:  53.378253918884305
using explorer policy with actor:  1
printing an ep nov before normalisation:  52.35615882536648
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.131650319889
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.91144896
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.8141695331532
using explorer policy with actor:  1
siam score:  -0.9122448
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.811]
 [50.572]
 [42.41 ]
 [40.431]
 [42.811]] [[0.699]
 [0.943]
 [0.686]
 [0.624]
 [0.699]]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[80.092]
 [56.557]
 [56.557]
 [56.557]
 [56.557]] [[1.511]
 [0.961]
 [0.961]
 [0.961]
 [0.961]]
printing an ep nov before normalisation:  64.50945542595261
printing an ep nov before normalisation:  55.226997479253754
printing an ep nov before normalisation:  29.13517968821862
printing an ep nov before normalisation:  54.18408954340822
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.72 ]
 [30.565]
 [30.565]
 [30.565]
 [30.565]] [[1.619]
 [0.997]
 [0.997]
 [0.997]
 [0.997]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.59369550965782
printing an ep nov before normalisation:  52.75107972930238
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.935]
 [49.935]
 [49.935]
 [50.768]
 [49.935]] [[1.3  ]
 [1.3  ]
 [1.3  ]
 [1.333]
 [1.3  ]]
printing an ep nov before normalisation:  36.061050405788926
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  36.90688262585028
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  19.94505008747044
siam score:  -0.90639055
printing an ep nov before normalisation:  70.16952179151725
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [ 0.   ]
 [44.812]
 [29.901]
 [ 0.   ]] [[-0.476]
 [-0.476]
 [ 0.824]
 [ 0.392]
 [-0.476]]
siam score:  -0.9070081
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.337]
 [13.337]
 [13.337]
 [14.577]
 [13.337]] [[1.032]
 [1.032]
 [1.032]
 [1.17 ]
 [1.032]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.533035705221245
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.851]
 [42.666]
 [42.666]
 [49.129]
 [42.666]] [[1.298]
 [0.94 ]
 [0.94 ]
 [1.115]
 [0.94 ]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.104561805725098
printing an ep nov before normalisation:  73.11563522042579
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  35.47497818134752
printing an ep nov before normalisation:  80.14387130809835
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.613]
 [41.278]
 [41.278]
 [58.408]
 [41.278]] [[0.543]
 [0.247]
 [0.247]
 [0.432]
 [0.247]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  27.273121265313872
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.269]
 [60.841]
 [60.841]
 [63.846]
 [60.841]] [[1.542]
 [1.468]
 [1.468]
 [1.559]
 [1.468]]
printing an ep nov before normalisation:  30.164306163787842
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.910683
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.14610028054514
line 256 mcts: sample exp_bonus 41.590633392333984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 62.91178055945305
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.364]
 [24.902]
 [27.282]
 [23.129]
 [24.067]] [[1.   ]
 [0.775]
 [0.93 ]
 [0.66 ]
 [0.721]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.282]
 [27.282]
 [27.282]
 [32.879]
 [27.282]] [[0.719]
 [0.719]
 [0.719]
 [1.   ]
 [0.719]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.738]
 [29.738]
 [29.738]
 [29.738]
 [29.738]] [[0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.37695014209828
siam score:  -0.90543365
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  50.209728883042814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.976159674988345
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.716]
 [31.335]
 [37.511]
 [32.162]
 [41.183]] [[0.747]
 [0.441]
 [0.623]
 [0.465]
 [0.731]]
line 256 mcts: sample exp_bonus 58.30152785677153
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  77.53245107272531
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[90.976]
 [90.976]
 [90.976]
 [93.958]
 [90.976]] [[1.603]
 [1.603]
 [1.603]
 [1.667]
 [1.603]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.23590927063767
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.174]
 [29.174]
 [29.174]
 [39.884]
 [29.174]] [[1.006]
 [1.006]
 [1.006]
 [1.492]
 [1.006]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.0665377439079
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.48888053538324
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.251]
 [54.251]
 [54.251]
 [54.251]
 [54.251]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.54502271747532
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.43739823702811
printing an ep nov before normalisation:  30.915993745323004
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  49.50247952046426
siam score:  -0.91501296
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000],
        [    -0.0000]], dtype=torch.float64)
0.0 -1.1391001825655931e-11
0.0 -9.583318162859936e-12
0.0 -2.1623010287515367e-12
0.0 -9.583318162859936e-12
0.0 -9.583318162859936e-12
0.0 -1.078123293304122e-11
0.0 -1.2238623825601348e-11
0.0 -7.568053600026237e-12
0.0 0.0
0.0 -3.9786338537867807e-13
printing an ep nov before normalisation:  29.250714778900146
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  26.61449203072056
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.677]
 [21.412]
 [25.357]
 [23.848]
 [21.957]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  36.361939907073975
printing an ep nov before normalisation:  35.69784753138161
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.276840970058544
printing an ep nov before normalisation:  23.953809246179663
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  36.92161473001782
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  2  action  0 :  tensor([    0.9854,     0.0025,     0.0003,     0.0074,     0.0045],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0009,     0.9969,     0.0003,     0.0001,     0.0018],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9481,     0.0465,     0.0054],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0001,     0.0163,     0.8748,     0.1087],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0002,     0.0003,     0.0018,     0.6615,     0.3363],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.73673201952676
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.593]
 [44.135]
 [35.716]
 [39.573]
 [37.593]] [[0.797]
 [1.061]
 [0.721]
 [0.877]
 [0.797]]
printing an ep nov before normalisation:  0.00017603706055524526
printing an ep nov before normalisation:  46.04747851933222
printing an ep nov before normalisation:  37.7091121673584
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.63126182556152
printing an ep nov before normalisation:  42.32416897569087
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.391]
 [35.391]
 [35.391]
 [35.391]
 [35.391]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9986,     0.0000,     0.0000,     0.0008,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9973,     0.0001,     0.0001,     0.0024],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0005,     0.0001,     0.9893,     0.0068,     0.0033],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0001,     0.0230,     0.8991,     0.0777],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0094, 0.0414, 0.0242, 0.4508, 0.4742], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  42.61545686922697
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  19.44005846977234
actions average: 
K:  4  action  0 :  tensor([    0.9959,     0.0005,     0.0000,     0.0005,     0.0031],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9998,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9449,     0.0299,     0.0251],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0021,     0.0006,     0.0206,     0.8695,     0.1072],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.1041, 0.0421, 0.0501, 0.4250, 0.3787], grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 32.48378649810992
printing an ep nov before normalisation:  24.118261337280273
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.528]
 [31.53 ]
 [31.53 ]
 [31.53 ]
 [31.53 ]] [[1.941]
 [1.365]
 [1.365]
 [1.365]
 [1.365]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  55.037806467301564
printing an ep nov before normalisation:  36.039149188031274
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.009]
 [26.009]
 [26.009]
 [27.736]
 [26.009]] [[1.291]
 [1.291]
 [1.291]
 [1.42 ]
 [1.291]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.15393867076861
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  39.706558832639274
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.765]
 [51.181]
 [51.765]
 [48.267]
 [52.482]] [[1.199]
 [1.179]
 [1.199]
 [1.082]
 [1.223]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.95555400848389
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
UNIT TEST: sample policy line 217 mcts : [0.59  0.026 0.026 0.333 0.026]
printing an ep nov before normalisation:  28.76243423452662
printing an ep nov before normalisation:  12.845209088721186
printing an ep nov before normalisation:  35.134515506278404
printing an ep nov before normalisation:  47.22505152588163
printing an ep nov before normalisation:  49.24677679190859
printing an ep nov before normalisation:  23.8475207331556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  79.62990119932566
printing an ep nov before normalisation:  70.68915738271004
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.435]
 [17.435]
 [17.435]
 [17.435]
 [17.435]] [[0.293]
 [0.293]
 [0.293]
 [0.293]
 [0.293]]
printing an ep nov before normalisation:  22.608277252432536
printing an ep nov before normalisation:  29.888420928762233
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  75.40775839833995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.955]
 [40.955]
 [40.955]
 [44.901]
 [40.955]] [[0.633]
 [0.633]
 [0.633]
 [0.719]
 [0.633]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  31.448582587743587
printing an ep nov before normalisation:  31.117826406528405
printing an ep nov before normalisation:  47.709092478945294
printing an ep nov before normalisation:  70.71274071579212
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 3.1586893439543936e-10
0.0 1.0340296507678108e-09
0.0 0.0
0.0 4.1253243962378676e-10
0.0 4.1253243962378676e-10
0.0 3.1586893439543936e-10
0.0 7.206516871687963e-10
0.0 0.0
0.0 1.0102962346469002e-09
0.0 2.778470331231556e-10
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.9070778
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  tensor([    0.9800,     0.0001,     0.0000,     0.0147,     0.0052],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0039, 0.9751, 0.0056, 0.0013, 0.0141], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.8344,     0.1436,     0.0219],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0009, 0.0025, 0.0197, 0.8657, 0.1112], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0010, 0.0022, 0.0033, 0.6312, 0.3623], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.634]
 [57.765]
 [54.634]
 [56.839]
 [54.634]] [[1.398]
 [1.523]
 [1.398]
 [1.486]
 [1.398]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.39 ]
 [45.071]
 [35.39 ]
 [41.8  ]
 [35.39 ]] [[0.754]
 [1.148]
 [0.754]
 [1.015]
 [0.754]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.906]
 [26.301]
 [62.154]
 [27.771]
 [31.221]] [[0.176]
 [0.212]
 [1.143]
 [0.25 ]
 [0.34 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.122]
 [32.122]
 [32.122]
 [33.312]
 [32.122]] [[0.879]
 [0.879]
 [0.879]
 [0.934]
 [0.879]]
printing an ep nov before normalisation:  39.09708502948139
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  40.151281729705524
siam score:  -0.9100573
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.30962902053904
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.967]
 [44.967]
 [44.967]
 [51.523]
 [44.967]] [[0.873]
 [0.873]
 [0.873]
 [1.   ]
 [0.873]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.66934379252865
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.97823946260516
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.32769014197845
printing an ep nov before normalisation:  60.50429342303723
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  37.18005050674708
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.373]
 [42.373]
 [50.422]
 [42.373]
 [42.373]] [[0.976]
 [0.976]
 [1.289]
 [0.976]
 [0.976]]
printing an ep nov before normalisation:  42.63710489894385
printing an ep nov before normalisation:  40.9763707265671
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.734]
 [47.734]
 [47.734]
 [51.251]
 [48.414]] [[1.487]
 [1.487]
 [1.487]
 [1.596]
 [1.508]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.24106079826943
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.621]
 [34.621]
 [34.621]
 [34.621]
 [34.621]] [[0.106]
 [0.106]
 [0.106]
 [0.106]
 [0.106]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.069]
 [46.257]
 [38.088]
 [34.042]
 [34.278]] [[0.098]
 [0.132]
 [0.099]
 [0.082]
 [0.083]]
printing an ep nov before normalisation:  39.81415690023793
siam score:  -0.9029487
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.967]
 [45.137]
 [35.613]
 [48.782]
 [49.442]] [[1.191]
 [0.963]
 [0.592]
 [1.106]
 [1.131]]
printing an ep nov before normalisation:  33.02386208236873
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  53.30770604096173
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.899774
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.00520671578606703
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
line 256 mcts: sample exp_bonus 65.34089723018784
siam score:  -0.89894944
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.868392371352655
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  0.015344141459081584
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.753672617586915
actions average: 
K:  2  action  0 :  tensor([    0.9769,     0.0010,     0.0003,     0.0140,     0.0078],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9598,     0.0143,     0.0004,     0.0252],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9103,     0.0776,     0.0120],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0003,     0.0067,     0.8924,     0.1004],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0184, 0.0154, 0.1396, 0.3520, 0.4745], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9014824
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.597]
 [83.597]
 [83.597]
 [83.597]
 [83.597]] [[1.854]
 [1.854]
 [1.854]
 [1.854]
 [1.854]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.988]
 [37.359]
 [31.65 ]
 [31.1  ]
 [33.908]] [[1.364]
 [0.934]
 [0.65 ]
 [0.622]
 [0.762]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  43.95146722125109
actions average: 
K:  1  action  0 :  tensor([    0.9992,     0.0003,     0.0000,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9928,     0.0011,     0.0010,     0.0050],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9996,     0.0002,     0.0002],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0010,     0.0001,     0.0323,     0.8206,     0.1459],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0073, 0.0026, 0.0883, 0.5184, 0.3834], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.267]
 [83.935]
 [99.605]
 [94.278]
 [93.167]] [[0.934]
 [0.957]
 [1.177]
 [1.102]
 [1.086]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.267]
 [43.885]
 [35.734]
 [38.267]
 [40.947]] [[1.464]
 [1.679]
 [1.367]
 [1.464]
 [1.566]]
printing an ep nov before normalisation:  46.25285922462859
printing an ep nov before normalisation:  46.22069832663493
using explorer policy with actor:  1
printing an ep nov before normalisation:  24.516873359680176
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  63.44577703079353
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  70.46932730341057
siam score:  -0.89837664
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  46.58465405922445
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.51472529219535
printing an ep nov before normalisation:  40.22463259615706
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.514]
 [47.473]
 [47.473]
 [47.586]
 [47.473]] [[1.066]
 [0.845]
 [0.845]
 [0.848]
 [0.845]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
actions average: 
K:  3  action  0 :  printing an ep nov before normalisation:  40.07160337834724
tensor([    0.9904,     0.0001,     0.0000,     0.0053,     0.0042],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0014,     0.9619,     0.0118,     0.0004,     0.0245],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0012, 0.0080, 0.8928, 0.0708, 0.0271], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0006,     0.0001,     0.0155,     0.8811,     0.1028],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0065, 0.0638, 0.1013, 0.2295, 0.5990], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.905237197875977
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.492]
 [41.79 ]
 [47.99 ]
 [48.755]
 [52.435]] [[1.26 ]
 [1.158]
 [1.329]
 [1.351]
 [1.452]]
printing an ep nov before normalisation:  58.99739765184222
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.171]
 [48.171]
 [48.171]
 [48.171]
 [48.171]] [[1.078]
 [1.078]
 [1.078]
 [1.078]
 [1.078]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.816]
 [40.816]
 [56.809]
 [40.816]
 [40.816]] [[0.608]
 [0.608]
 [1.061]
 [0.608]
 [0.608]]
printing an ep nov before normalisation:  58.21977281272304
printing an ep nov before normalisation:  47.52546335054723
printing an ep nov before normalisation:  59.31296368080352
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.721]
 [46.721]
 [51.973]
 [48.563]
 [46.721]] [[1.202]
 [1.202]
 [1.408]
 [1.274]
 [1.202]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  57.77045286075572
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.388]
 [61.027]
 [61.027]
 [63.614]
 [61.027]] [[1.243]
 [1.005]
 [1.005]
 [1.065]
 [1.005]]
printing an ep nov before normalisation:  39.804300053534625
siam score:  -0.8989058
printing an ep nov before normalisation:  74.68557446254141
printing an ep nov before normalisation:  44.84241531430762
printing an ep nov before normalisation:  62.10626395007969
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.24 ]
 [45.657]
 [40.825]
 [49.997]
 [43.402]] [[0.719]
 [0.393]
 [0.317]
 [0.462]
 [0.357]]
printing an ep nov before normalisation:  44.011238637602304
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.415]
 [47.415]
 [47.415]
 [47.415]
 [47.415]] [[0.852]
 [0.852]
 [0.852]
 [0.852]
 [0.852]]
printing an ep nov before normalisation:  29.034085273742676
printing an ep nov before normalisation:  57.02961612177231
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
siam score:  -0.9005243
printing an ep nov before normalisation:  28.63808147052488
printing an ep nov before normalisation:  54.83095108439763
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.55]
 [53.55]
 [53.55]
 [53.55]
 [53.55]] [[0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  41.047746594801545
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.834]
 [41.834]
 [41.834]
 [41.834]
 [41.834]] [[41.834]
 [41.834]
 [41.834]
 [41.834]
 [41.834]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.371]
 [51.371]
 [51.371]
 [54.929]
 [51.371]] [[0.558]
 [0.558]
 [0.558]
 [0.627]
 [0.558]]
printing an ep nov before normalisation:  37.86409911689691
printing an ep nov before normalisation:  46.13057931942025
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.02 ]
 [26.02 ]
 [26.02 ]
 [27.773]
 [26.02 ]] [[0.307]
 [0.307]
 [0.307]
 [0.346]
 [0.307]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.31 ]
 [29.374]
 [29.374]
 [29.374]
 [29.374]] [[1.392]
 [0.891]
 [0.891]
 [0.891]
 [0.891]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  86.98428946412939
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  33.61147081205263
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.353]
 [32.153]
 [39.303]
 [32.412]
 [27.571]] [[0.789]
 [0.393]
 [0.533]
 [0.398]
 [0.304]]
printing an ep nov before normalisation:  69.25131987128452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  63.91500917697923
siam score:  -0.904216
printing an ep nov before normalisation:  50.38737662843028
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  69.34060548798794
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
printing an ep nov before normalisation:  50.6757371904946
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  29.490540022715347
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  44.17495804649387
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  56.5807855912725
printing an ep nov before normalisation:  53.971400259790066
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.555]
 [21.248]
 [24.946]
 [18.582]
 [17.3  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  29.660593320807713
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  47.51856960529669
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.226]
 [33.743]
 [25.136]
 [37.636]
 [42.926]] [[0.884]
 [0.538]
 [0.279]
 [0.655]
 [0.814]]
printing an ep nov before normalisation:  0.024327155500145636
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9977,     0.0009,     0.0000,     0.0004,     0.0010],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0054, 0.9310, 0.0249, 0.0011, 0.0376], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0009,     0.9371,     0.0373,     0.0247],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0048, 0.0208, 0.0241, 0.8472, 0.1031], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0005,     0.0612,     0.0019,     0.5941,     0.3424],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  48.62966327001176
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  73.25448318443068
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.221]
 [33.953]
 [29.731]
 [36.124]
 [30.288]] [[0.461]
 [0.37 ]
 [0.279]
 [0.416]
 [0.291]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.712]
 [38.712]
 [38.012]
 [38.712]
 [38.712]] [[1.375]
 [1.375]
 [1.35 ]
 [1.375]
 [1.375]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.937]
 [37.937]
 [37.937]
 [37.937]
 [37.937]] [[0.166]
 [0.166]
 [0.166]
 [0.166]
 [0.166]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.89557695
printing an ep nov before normalisation:  36.08370542526245
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  12.759738007018202
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  54.438011155471926
printing an ep nov before normalisation:  26.03476047515869
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  48.36360605886313
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  58.76971421974621
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.622]
 [53.809]
 [53.809]
 [57.448]
 [53.809]] [[1.702]
 [1.667]
 [1.667]
 [1.822]
 [1.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  62.854743498092716
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  28.576485438832844
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.080628498013
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.553]
 [61.042]
 [61.042]
 [61.042]
 [61.042]] [[1.921]
 [1.645]
 [1.645]
 [1.645]
 [1.645]]
printing an ep nov before normalisation:  57.90932342449378
printing an ep nov before normalisation:  24.599151611328125
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.612]
 [55.355]
 [55.355]
 [55.355]
 [55.355]] [[1.569]
 [1.462]
 [1.462]
 [1.462]
 [1.462]]
using explorer policy with actor:  1
siam score:  -0.8998332
printing an ep nov before normalisation:  45.5438870500787
printing an ep nov before normalisation:  44.6711540222168
siam score:  -0.90023035
printing an ep nov before normalisation:  30.775293336187183
printing an ep nov before normalisation:  0.00023601123302796623
printing an ep nov before normalisation:  0.0006515457044997675
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  32.69969550105665
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.05569505691528
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.197]
 [27.154]
 [41.078]
 [27.367]
 [30.197]] [[0.329]
 [0.258]
 [0.584]
 [0.263]
 [0.329]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  71.13968514467886
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  68.92483906331276
printing an ep nov before normalisation:  50.88330479072828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  42.928283253266684
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
from probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  49.69734308614189
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.17956260696049
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.09569460307881
actions average: 
K:  3  action  0 :  tensor([    0.9841,     0.0081,     0.0004,     0.0021,     0.0053],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0014,     0.9813,     0.0053,     0.0002,     0.0118],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9586,     0.0334,     0.0080],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0121, 0.0129, 0.0241, 0.8035, 0.1473], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0026, 0.0018, 0.0517, 0.5881, 0.3558], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.211]
 [51.211]
 [51.211]
 [59.666]
 [51.211]] [[0.502]
 [0.502]
 [0.502]
 [0.613]
 [0.502]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.42 ]
 [24.513]
 [26.917]
 [29.635]
 [26.917]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  32.93005216939785
siam score:  -0.90038073
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.76229391318026
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.51 ]
 [35.235]
 [32.479]
 [36.663]
 [32.152]] [[1.148]
 [0.896]
 [0.8  ]
 [0.945]
 [0.789]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
printing an ep nov before normalisation:  61.24038046123268
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669, 0.16666666666666669]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.47 ]
 [41.385]
 [41.385]
 [49.04 ]
 [41.385]] [[0.831]
 [0.546]
 [0.546]
 [0.701]
 [0.546]]
actor:  1 policy actor:  1  step number:  105 total reward:  1.0  reward:  1.0 rdn_beta:  1.333
printing an ep nov before normalisation:  34.41259808305047
printing an ep nov before normalisation:  95.85385745940978
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  34.228383731513254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.269]
 [64.269]
 [64.269]
 [64.269]
 [64.269]] [[1.192]
 [1.192]
 [1.192]
 [1.192]
 [1.192]]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  39.517552114116434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.922]
 [82.922]
 [82.922]
 [86.284]
 [82.922]] [[1.095]
 [1.095]
 [1.095]
 [1.15 ]
 [1.095]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  52.456143930482654
line 256 mcts: sample exp_bonus 27.39160855410497
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.29]
 [28.29]
 [28.29]
 [28.29]
 [28.29]] [[0.57]
 [0.57]
 [0.57]
 [0.57]
 [0.57]]
printing an ep nov before normalisation:  40.57996020806754
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.23 ]
 [32.212]
 [39.201]
 [29.087]
 [30.653]] [[0.479]
 [0.992]
 [1.319]
 [0.846]
 [0.919]]
printing an ep nov before normalisation:  63.14224540741343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
actions average: 
K:  4  action  0 :  tensor([    0.9854,     0.0006,     0.0000,     0.0045,     0.0095],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9869,     0.0008,     0.0006,     0.0116],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0004,     0.8977,     0.0690,     0.0328],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0009,     0.0005,     0.0125,     0.8122,     0.1740],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0036, 0.0016, 0.0114, 0.4236, 0.5598], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.002]
 [35.192]
 [25.444]
 [20.197]
 [24.496]] [[0.329]
 [0.601]
 [0.364]
 [0.237]
 [0.341]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[68.3]
 [68.3]
 [68.3]
 [68.3]
 [68.3]] [[1.21]
 [1.21]
 [1.21]
 [1.21]
 [1.21]]
UNIT TEST: sample policy line 217 mcts : [0.615 0.026 0.308 0.026 0.026]
siam score:  -0.85662127
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  17.60273242019545
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  20.155512010909433
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.512]
 [34.333]
 [34.333]
 [41.257]
 [34.333]] [[0.512]
 [0.242]
 [0.242]
 [0.334]
 [0.242]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
line 256 mcts: sample exp_bonus 40.37904361673664
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  28.660636253707466
siam score:  -0.8576929
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
printing an ep nov before normalisation:  54.46016258077959
printing an ep nov before normalisation:  34.51242690930077
printing an ep nov before normalisation:  44.174150617075284
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.05 ]
 [33.695]
 [45.4  ]
 [25.476]
 [32.05 ]] [[0.228]
 [0.249]
 [0.398]
 [0.145]
 [0.228]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  68.7091979335496
printing an ep nov before normalisation:  6.873760298731213e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  38.98762946706664
printing an ep nov before normalisation:  32.48105589888662
using explorer policy with actor:  1
using explorer policy with actor:  1
siam score:  -0.85604185
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.859]
 [33.859]
 [40.138]
 [33.859]
 [33.859]] [[0.936]
 [0.936]
 [1.333]
 [0.936]
 [0.936]]
printing an ep nov before normalisation:  29.418860040099233
printing an ep nov before normalisation:  37.69171953201294
printing an ep nov before normalisation:  46.61821445391487
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  38.4133988170946
printing an ep nov before normalisation:  44.23900713486778
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  32.604593138837835
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  63.98142102301434
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  67.41742771314584
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.998700444173984
printing an ep nov before normalisation:  22.128569394622772
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
siam score:  -0.85778993
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  66.17013040310977
printing an ep nov before normalisation:  79.63343491373465
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.378]
 [55.378]
 [55.378]
 [60.936]
 [57.715]] [[1.111]
 [1.111]
 [1.111]
 [1.26 ]
 [1.173]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  31.393592583866926
printing an ep nov before normalisation:  39.939613342285156
printing an ep nov before normalisation:  48.429791962165076
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  51.88482637409498
printing an ep nov before normalisation:  35.59394192551099
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]] [[28.177]
 [25.196]
 [22.547]
 [22.627]
 [23.096]] [[0.612]
 [0.505]
 [0.41 ]
 [0.413]
 [0.43 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
siam score:  -0.8599157
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.549]
 [57.025]
 [54.077]
 [61.256]
 [54.077]] [[1.086]
 [0.92 ]
 [0.855]
 [1.013]
 [0.855]]
printing an ep nov before normalisation:  44.61094394868933
printing an ep nov before normalisation:  50.65908676168349
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  67.83970276642792
printing an ep nov before normalisation:  32.42050455774503
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  18.480343156619032
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  46.04199636007007
printing an ep nov before normalisation:  61.325952301230586
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.891]
 [39.251]
 [36.534]
 [41.474]
 [42.357]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  32.018121697251175
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  31.025081210666233
siam score:  -0.8574483
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  91.54198836980866
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.028]
 [40.802]
 [26.166]
 [27.241]
 [33.217]] [[0.094]
 [0.154]
 [0.072]
 [0.078]
 [0.111]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  53.21992182485119
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.265]
 [44.988]
 [44.255]
 [44.753]
 [50.855]] [[1.111]
 [0.961]
 [0.935]
 [0.952]
 [1.167]]
printing an ep nov before normalisation:  37.012604868367816
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  39.36585651233841
printing an ep nov before normalisation:  39.00792693234629
printing an ep nov before normalisation:  25.500386953353882
printing an ep nov before normalisation:  39.623700564623405
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  44.23292733555274
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.233]
 [44.233]
 [44.233]
 [43.261]
 [44.233]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.748]
 [24.748]
 [24.748]
 [30.196]
 [24.748]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  43.94735665015485
printing an ep nov before normalisation:  25.16543465915442
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.511]
 [20.926]
 [13.584]
 [21.217]
 [16.139]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  67.12536295269331
printing an ep nov before normalisation:  27.393493108020433
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.775866268360264
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.703]
 [16.34 ]
 [16.34 ]
 [16.34 ]
 [16.34 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.33386333554838
printing an ep nov before normalisation:  56.967413562454446
actions average: 
K:  0  action  0 :  tensor([    0.9850,     0.0021,     0.0005,     0.0050,     0.0074],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9992,     0.0004,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0028,     0.9925,     0.0027,     0.0020],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0003,     0.0279,     0.8122,     0.1590],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0023, 0.0081, 0.0148, 0.5081, 0.4667], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.179]
 [19.179]
 [19.179]
 [19.179]
 [19.179]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  31.126962361534623
printing an ep nov before normalisation:  12.707579135894775
using explorer policy with actor:  0
printing an ep nov before normalisation:  28.921503308263226
printing an ep nov before normalisation:  26.79232336651716
printing an ep nov before normalisation:  46.041985193098434
line 256 mcts: sample exp_bonus 75.77706431321948
line 256 mcts: sample exp_bonus 46.66763294499695
printing an ep nov before normalisation:  29.073404716281992
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  63.664955399363656
printing an ep nov before normalisation:  66.08027190024384
printing an ep nov before normalisation:  27.383246421813965
printing an ep nov before normalisation:  21.51800395612712
siam score:  -0.8594394
line 256 mcts: sample exp_bonus 48.73298911354911
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
line 256 mcts: sample exp_bonus 21.77671424043472
using explorer policy with actor:  0
printing an ep nov before normalisation:  68.20102899534389
printing an ep nov before normalisation:  15.163851108556576
printing an ep nov before normalisation:  20.814234987180342
printing an ep nov before normalisation:  86.90981547872076
printing an ep nov before normalisation:  15.855789659174796
printing an ep nov before normalisation:  63.668387868674934
printing an ep nov before normalisation:  30.637337961964665
printing an ep nov before normalisation:  15.815205574035645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  28.979112965992968
printing an ep nov before normalisation:  37.33034438903384
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.28267854883097
printing an ep nov before normalisation:  49.553998986849834
printing an ep nov before normalisation:  20.775570167729498
printing an ep nov before normalisation:  73.68532924441284
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  38.50173289108998
printing an ep nov before normalisation:  18.08051347732544
printing an ep nov before normalisation:  26.78219414470521
using explorer policy with actor:  0
siam score:  -0.86434466
printing an ep nov before normalisation:  15.871606346036305
using explorer policy with actor:  0
printing an ep nov before normalisation:  23.260191487031403
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  15.701392786030812
using explorer policy with actor:  0
printing an ep nov before normalisation:  89.75422304848419
printing an ep nov before normalisation:  34.5859559641753
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.263]
 [28.824]
 [15.172]
 [26.264]
 [15.172]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  90.05691976781253
printing an ep nov before normalisation:  0.0005045690159022342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  0
printing an ep nov before normalisation:  59.66319644903641
using explorer policy with actor:  0
printing an ep nov before normalisation:  24.355415924045737
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.747]
 [25.747]
 [25.747]
 [28.55 ]
 [25.747]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  46.993578507379176
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  28.687671880901107
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  19.06117501231881
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.106]
 [18.106]
 [18.106]
 [23.453]
 [18.106]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  30.123469679577454
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.177]
 [40.177]
 [40.177]
 [46.994]
 [40.177]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  21.004453592128314
printing an ep nov before normalisation:  72.1419425465791
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  99.5835581989465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  0
printing an ep nov before normalisation:  39.42174510681595
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  28.31367225134489
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.329]
 [35.329]
 [35.329]
 [35.329]
 [35.329]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  52.721336444343564
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.   ]
 [56.187]
 [56.187]
 [68.834]
 [56.187]] [[1.115]
 [0.812]
 [0.812]
 [1.089]
 [0.812]]
actions average: 
K:  2  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0026,     0.9623,     0.0031,     0.0003,     0.0316],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9612,     0.0336,     0.0052],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0004,     0.0222,     0.8690,     0.1081],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0069, 0.0502, 0.0343, 0.5650, 0.3437], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  70.02467742660428
siam score:  -0.86358047
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  64.06211258997017
printing an ep nov before normalisation:  28.366076155961135
using explorer policy with actor:  1
siam score:  -0.8623625
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
actions average: 
K:  4  action  0 :  tensor([    0.9947,     0.0001,     0.0000,     0.0021,     0.0030],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0501,     0.8788,     0.0057,     0.0005,     0.0649],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.8520,     0.1190,     0.0287],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0006,     0.0040,     0.0202,     0.8442,     0.1311],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0024, 0.0082, 0.0136, 0.5094, 0.4663], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.007]
 [32.007]
 [41.643]
 [32.007]
 [32.007]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
siam score:  -0.8661096
printing an ep nov before normalisation:  57.690293599739746
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]] [[32.751]
 [30.887]
 [34.201]
 [25.749]
 [30.887]] [[0.953]
 [0.898]
 [0.994]
 [0.749]
 [0.898]]
printing an ep nov before normalisation:  46.57752136804733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.49410580992736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
printing an ep nov before normalisation:  66.55465053353782
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  49.58349902325309
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  49.886498035016004
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.929]
 [23.032]
 [22.504]
 [24.825]
 [25.821]] [[0.762]
 [1.036]
 [1.012]
 [1.117]
 [1.162]]
printing an ep nov before normalisation:  25.35109043121338
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  43.54227022151827
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  33.71112531333766
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.326]
 [61.899]
 [42.326]
 [42.326]
 [42.326]] [[0.462]
 [1.011]
 [0.462]
 [0.462]
 [0.462]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.427]
 [54.165]
 [54.165]
 [63.359]
 [54.165]] [[1.025]
 [0.846]
 [0.846]
 [1.072]
 [0.846]]
line 256 mcts: sample exp_bonus 47.31920486119631
printing an ep nov before normalisation:  59.05300354508137
siam score:  -0.85800433
printing an ep nov before normalisation:  57.08435083911596
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 25.700850715585474
printing an ep nov before normalisation:  35.935278521614244
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  44.29340001364102
printing an ep nov before normalisation:  32.001397483263716
printing an ep nov before normalisation:  61.37506565112534
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.231]
 [31.586]
 [29.332]
 [44.511]
 [31.787]] [[0.665]
 [0.277]
 [0.238]
 [0.498]
 [0.28 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  43.07479166359408
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using another actor
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.227]
 [46.227]
 [46.227]
 [46.227]
 [46.227]] [[0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]]
siam score:  -0.8503827
printing an ep nov before normalisation:  55.22282968337486
printing an ep nov before normalisation:  18.913444876670837
printing an ep nov before normalisation:  23.370560251160306
printing an ep nov before normalisation:  30.169739959927384
line 256 mcts: sample exp_bonus 46.05303776932934
printing an ep nov before normalisation:  35.063780668733855
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
UNIT TEST: sample policy line 217 mcts : [0.487 0.205 0.231 0.051 0.026]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  88.29445967516342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  44.061764624975396
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
line 256 mcts: sample exp_bonus 28.489734499743633
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  66.15388390890385
line 256 mcts: sample exp_bonus 43.386485003909065
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.393]
 [38.494]
 [29.512]
 [32.54 ]
 [34.728]] [[0.959]
 [1.176]
 [0.901]
 [0.994]
 [1.061]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  56.72921339595012
printing an ep nov before normalisation:  58.20548102899645
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.001]] [[62.805]
 [62.805]
 [62.805]
 [62.805]
 [78.409]] [[0.985]
 [0.985]
 [0.985]
 [0.985]
 [1.334]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.843]
 [33.987]
 [39.275]
 [37.533]
 [41.139]] [[0.842]
 [0.476]
 [0.639]
 [0.586]
 [0.697]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.585]
 [32.032]
 [32.032]
 [32.032]
 [32.032]] [[1.261]
 [0.553]
 [0.553]
 [0.553]
 [0.553]]
printing an ep nov before normalisation:  88.27145052893837
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.82530400207932
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.36 ]
 [30.674]
 [38.935]
 [37.172]
 [30.674]] [[0.641]
 [0.746]
 [0.947]
 [0.904]
 [0.746]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.001]
 [0.001]
 [0.   ]] [[33.194]
 [33.876]
 [38.734]
 [35.636]
 [36.916]] [[0.843]
 [0.872]
 [1.073]
 [0.945]
 [0.998]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  45.110667557279015
printing an ep nov before normalisation:  23.4385347366333
using another actor
actions average: 
K:  1  action  0 :  tensor([    0.9775,     0.0001,     0.0000,     0.0070,     0.0154],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0132, 0.9752, 0.0019, 0.0032, 0.0065], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0315, 0.0042, 0.8858, 0.0659, 0.0125], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0035,     0.0003,     0.0198,     0.8464,     0.1299],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0004,     0.0026,     0.0493,     0.5952,     0.3524],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  33.26406002044678
using explorer policy with actor:  1
printing an ep nov before normalisation:  80.5610300659701
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.846]
 [41.844]
 [38.722]
 [36.53 ]
 [38.722]] [[0.853]
 [1.028]
 [0.891]
 [0.795]
 [0.891]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  78.62469466226199
printing an ep nov before normalisation:  36.88188927467544
printing an ep nov before normalisation:  24.439091682434082
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  29.6336170090374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
line 256 mcts: sample exp_bonus 62.61331349182369
printing an ep nov before normalisation:  65.52963785386763
printing an ep nov before normalisation:  71.50322560790102
printing an ep nov before normalisation:  33.50162752597184
printing an ep nov before normalisation:  35.265015653034865
printing an ep nov before normalisation:  54.024848406321226
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.801]
 [41.694]
 [43.016]
 [42.648]
 [45.1  ]] [[1.333]
 [0.965]
 [1.025]
 [1.008]
 [1.12 ]]
using explorer policy with actor:  1
siam score:  -0.8520041
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  67.63970106529133
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  43.78707650219398
actions average: 
K:  4  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0003,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0333,     0.9339,     0.0006,     0.0030,     0.0291],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0246,     0.8502,     0.0808,     0.0444],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0001,     0.0119,     0.8887,     0.0988],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0301, 0.0864, 0.0283, 0.2695, 0.5858], grad_fn=<DivBackward0>)
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
siam score:  -0.8477473
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  62.435364899545775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using another actor
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
siam score:  -0.8617929
UNIT TEST: sample policy line 217 mcts : [0.128 0.103 0.179 0.282 0.308]
printing an ep nov before normalisation:  39.176796319718434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  47.79220582003376
printing an ep nov before normalisation:  37.80555193998111
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.739]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[ 0.71]
 [-1.07]
 [-1.07]
 [-1.07]
 [-1.07]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  78.87093796173042
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  35.422677993774414
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
printing an ep nov before normalisation:  84.31077634326435
printing an ep nov before normalisation:  40.468959212565466
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  35.528119750911955
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.95]
 [69.95]
 [69.95]
 [69.95]
 [69.95]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
printing an ep nov before normalisation:  51.85707104869979
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  50.132512050504324
printing an ep nov before normalisation:  42.766618728637695
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.078]
 [40.494]
 [35.54 ]
 [30.942]
 [39.181]] [[0.835]
 [1.089]
 [0.856]
 [0.64 ]
 [1.028]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  58.757845619661786
printing an ep nov before normalisation:  62.974682963329734
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  62.18483453616578
printing an ep nov before normalisation:  44.251723186279136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  53.73908320391916
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
actions average: 
K:  1  action  0 :  tensor([    0.9973,     0.0023,     0.0001,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9959,     0.0001,     0.0000,     0.0037],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0020,     0.9279,     0.0322,     0.0378],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0006,     0.0009,     0.0210,     0.8530,     0.1245],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0025, 0.0203, 0.0620, 0.3899, 0.5254], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  60.47756002118618
printing an ep nov before normalisation:  45.48829596905055
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.267]
 [58.696]
 [43.267]
 [43.267]
 [43.267]] [[0.609]
 [0.929]
 [0.609]
 [0.609]
 [0.609]]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]] [[68.877]
 [46.973]
 [46.973]
 [52.497]
 [46.973]] [[0.991]
 [0.611]
 [0.611]
 [0.706]
 [0.611]]
printing an ep nov before normalisation:  39.80375826978319
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.177]
 [29.177]
 [60.461]
 [29.177]
 [29.177]] [[0.469]
 [0.469]
 [1.427]
 [0.469]
 [0.469]]
printing an ep nov before normalisation:  51.00921598884238
printing an ep nov before normalisation:  22.03533411026001
printing an ep nov before normalisation:  25.690741083640773
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  84.21378771329681
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  41.54676217943059
siam score:  -0.8661955
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.11276574135364
printing an ep nov before normalisation:  32.028354304052385
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  22.858943939208984
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  31.465470895210462
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  57.284906189355226
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.14 ]
 [30.882]
 [19.996]
 [27.187]
 [36.208]] [[1.333]
 [1.031]
 [0.506]
 [0.853]
 [1.288]]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  64.74239711645238
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  56.85484303434722
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.146]
 [38.818]
 [38.818]
 [48.6  ]
 [45.051]] [[0.79 ]
 [0.308]
 [0.308]
 [0.487]
 [0.422]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  33.684096681224155
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.19 ]
 [45.854]
 [56.822]
 [50.222]
 [46.19 ]] [[0.793]
 [0.785]
 [1.036]
 [0.885]
 [0.793]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.854079
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.656]
 [53.656]
 [53.656]
 [53.656]
 [63.148]] [[0.959]
 [0.959]
 [0.959]
 [0.959]
 [1.2  ]]
using another actor
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.031]
 [40.031]
 [52.76 ]
 [39.883]
 [40.031]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  57.988266944885254
printing an ep nov before normalisation:  46.20387077331543
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  49.26008971903438
line 256 mcts: sample exp_bonus 22.812507199693115
printing an ep nov before normalisation:  56.333433896343266
siam score:  -0.8534864
printing an ep nov before normalisation:  28.70607852935791
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.894]
 [53.894]
 [53.894]
 [53.894]
 [53.894]] [[0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.912]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.983]
 [44.983]
 [44.983]
 [44.983]
 [44.983]] [[1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.667]]
siam score:  -0.8514408
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.138]
 [18.082]
 [18.082]
 [25.509]
 [18.082]] [[0.617]
 [0.613]
 [0.613]
 [1.093]
 [0.613]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  21.498653888702393
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.768]
 [42.911]
 [47.618]
 [48.471]
 [48.589]] [[0.521]
 [0.625]
 [0.782]
 [0.811]
 [0.815]]
using explorer policy with actor:  1
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  73.20672436741404
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[80.839]
 [80.839]
 [80.839]
 [80.839]
 [80.839]] [[1.071]
 [1.071]
 [1.071]
 [1.071]
 [1.071]]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
line 256 mcts: sample exp_bonus 40.110986755430226
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.128]
 [41.176]
 [38.417]
 [34.802]
 [39.858]] [[1.12 ]
 [1.229]
 [1.082]
 [0.889]
 [1.159]]
printing an ep nov before normalisation:  45.30580612186862
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.273381062507966
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.   ]
 [0.001]
 [0.   ]] [[19.951]
 [17.406]
 [18.462]
 [30.937]
 [15.499]] [[0.441]
 [0.351]
 [0.388]
 [0.832]
 [0.283]]
actions average: 
K:  2  action  0 :  tensor([0.9573, 0.0188, 0.0094, 0.0034, 0.0111], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9994,     0.0001,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0004,     0.9396,     0.0360,     0.0240],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0281,     0.0001,     0.0086,     0.8395,     0.1237],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0086, 0.0191, 0.0033, 0.5705, 0.3985], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  72.90726635524896
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.71221438700231
printing an ep nov before normalisation:  38.96262089799287
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  30.076352585038254
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.948728561401367
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.214]
 [42.426]
 [42.426]
 [42.426]
 [42.426]] [[0.671]
 [0.628]
 [0.628]
 [0.628]
 [0.628]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  46.067190084658385
printing an ep nov before normalisation:  41.14037381253821
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  40.32230048480112
printing an ep nov before normalisation:  24.37268962515936
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  36.38309882297032
printing an ep nov before normalisation:  46.270781284471454
printing an ep nov before normalisation:  26.805195031223146
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.553]
 [28.553]
 [44.525]
 [30.166]
 [28.553]] [[0.525]
 [0.525]
 [1.084]
 [0.581]
 [0.525]]
printing an ep nov before normalisation:  55.96458310949689
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.31813611002949
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
printing an ep nov before normalisation:  63.14278816994668
printing an ep nov before normalisation:  75.84786209702594
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  54.97460853272092
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.708]
 [49.708]
 [49.708]
 [49.708]
 [49.708]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.095]
 [45.095]
 [45.095]
 [45.095]
 [45.095]] [[1.595]
 [1.595]
 [1.595]
 [1.595]
 [1.595]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.096134903389654
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  50.63556179237114
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
printing an ep nov before normalisation:  58.347086118618854
printing an ep nov before normalisation:  37.5414540766523
printing an ep nov before normalisation:  51.437844192714074
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.956]
 [38.956]
 [38.956]
 [38.956]
 [38.956]] [[1.657]
 [1.657]
 [1.657]
 [1.657]
 [1.657]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.996]
 [29.028]
 [31.645]
 [28.578]
 [33.324]] [[0.664]
 [0.626]
 [0.728]
 [0.608]
 [0.793]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  38.68434777618188
printing an ep nov before normalisation:  49.73300951577171
printing an ep nov before normalisation:  31.81723399572583
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  75.61676912791486
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  52.271853429743
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.426]
 [45.595]
 [45.832]
 [46.179]
 [47.907]] [[0.939]
 [0.993]
 [1.004]
 [1.02 ]
 [1.1  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  50.49827036471674
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[54.103]
 [54.103]
 [54.103]
 [54.103]
 [54.103]] [[1.005]
 [1.005]
 [1.005]
 [1.005]
 [1.005]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  77.63908724741853
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[38.273]
 [38.273]
 [38.273]
 [38.273]
 [38.273]] [[1.163]
 [1.163]
 [1.163]
 [1.163]
 [1.163]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8592041
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[37.342]
 [42.233]
 [42.226]
 [39.518]
 [37.342]] [[0.962]
 [1.163]
 [1.162]
 [1.051]
 [0.962]]
siam score:  -0.8603734
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  51.34101602799205
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]] [[67.348]
 [44.89 ]
 [44.89 ]
 [68.483]
 [44.89 ]] [[0.876]
 [0.448]
 [0.448]
 [0.897]
 [0.448]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  61.77352814818136
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9985,     0.0002,     0.0000,     0.0001,     0.0012],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0238, 0.9245, 0.0023, 0.0060, 0.0435], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9452,     0.0442,     0.0105],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0015,     0.0001,     0.0426,     0.7954,     0.1603],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0070, 0.0015, 0.0376, 0.4885, 0.4654], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  47.022833672489526
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.   ]
 [0.   ]
 [0.   ]] [[40.89 ]
 [52.834]
 [40.89 ]
 [40.89 ]
 [40.89 ]] [[0.993]
 [1.443]
 [0.993]
 [0.993]
 [0.993]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  65.5978129114582
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  56.00661410855053
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  55.64463572904312
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[54.555]
 [54.555]
 [54.555]
 [54.555]
 [54.555]] [[1.178]
 [1.178]
 [1.178]
 [1.178]
 [1.178]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.053]
 [31.053]
 [35.241]
 [31.053]
 [31.053]] [[0.514]
 [0.514]
 [0.646]
 [0.514]
 [0.514]]
line 256 mcts: sample exp_bonus 0.0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.315]
 [43.71 ]
 [43.71 ]
 [47.115]
 [43.71 ]] [[0.965]
 [0.466]
 [0.466]
 [0.535]
 [0.466]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  35.188064769497856
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  65.4222050582762
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.53 ]
 [41.06 ]
 [51.845]
 [39.275]
 [41.06 ]] [[0.495]
 [0.843]
 [1.417]
 [0.748]
 [0.843]]
printing an ep nov before normalisation:  78.32507782604846
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  29.10776442663363
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  61.90364661519712
printing an ep nov before normalisation:  53.12418775349903
printing an ep nov before normalisation:  44.894123734976674
printing an ep nov before normalisation:  52.09941001339377
printing an ep nov before normalisation:  24.569993019104004
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.98 ]
 [41.134]
 [40.131]
 [26.785]
 [30.307]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[63.181]
 [33.612]
 [33.612]
 [33.612]
 [33.612]] [[1.194]
 [0.446]
 [0.446]
 [0.446]
 [0.446]]
printing an ep nov before normalisation:  62.23885329721497
actions average: 
K:  4  action  0 :  tensor([    0.9721,     0.0001,     0.0000,     0.0158,     0.0119],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0009,     0.9988,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0132, 0.0134, 0.7967, 0.0628, 0.1139], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0027, 0.0022, 0.0356, 0.7859, 0.1737], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0386, 0.1285, 0.0115, 0.2452, 0.5762], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.124]
 [56.787]
 [54.132]
 [55.178]
 [38.681]] [[0.212]
 [0.216]
 [0.198]
 [0.205]
 [0.093]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.904]
 [52.904]
 [52.904]
 [52.904]
 [52.904]] [[1.88]
 [1.88]
 [1.88]
 [1.88]
 [1.88]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
line 256 mcts: sample exp_bonus 56.0513941281461
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  72.50145820089527
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  52.49406032497106
printing an ep nov before normalisation:  42.064715222810435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  61.3750727741872
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  52.08579950039529
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  57.473188759387334
printing an ep nov before normalisation:  74.07194329108826
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.   ]
 [0.001]] [[48.142]
 [33.089]
 [45.853]
 [34.123]
 [33.089]] [[0.75 ]
 [0.381]
 [0.694]
 [0.406]
 [0.381]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  45.399638099073826
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.88946533203125
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
line 256 mcts: sample exp_bonus 79.11146982267195
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.797]
 [37.303]
 [45.79 ]
 [47.504]
 [43.172]] [[0.537]
 [0.582]
 [0.84 ]
 [0.892]
 [0.761]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.597573172677535
siam score:  -0.8714178
printing an ep nov before normalisation:  36.722628871063655
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.448]
 [56.418]
 [41.448]
 [41.448]
 [41.448]] [[0.883]
 [1.35 ]
 [0.883]
 [0.883]
 [0.883]]
printing an ep nov before normalisation:  87.29925196937327
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  52.99385025259759
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  36.284141540527344
printing an ep nov before normalisation:  29.749258699041352
using explorer policy with actor:  1
printing an ep nov before normalisation:  39.7237616420908
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
siam score:  -0.87366545
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  59.33443610036728
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[77.024]
 [60.624]
 [60.624]
 [60.624]
 [60.624]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  32.28585569014594
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using another actor
printing an ep nov before normalisation:  66.90455215977074
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[50.92]
 [50.92]
 [50.92]
 [50.92]
 [50.92]] [[1.058]
 [1.058]
 [1.058]
 [1.058]
 [1.058]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[0.0002],
        [0.0002],
        [0.0001],
        [0.0001],
        [0.0002],
        [0.0001],
        [0.0002],
        [0.0002],
        [0.0000],
        [0.0001]], dtype=torch.float64)
0.0 0.00018205025222767246
0.0 0.00022409267925778943
0.0 0.00012078334859910309
0.0 0.00010250793546820477
0.0 0.00018149168664301557
0.0 0.00011734119435637653
0.0 0.00015958719459876005
0.0 0.00015451477118113676
0.0 0.0
0.0 0.00014560503278275604
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8693776
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.30315877562447
printing an ep nov before normalisation:  55.620900464927345
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Starting evaluation
from probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.146]
 [68.146]
 [68.146]
 [68.146]
 [68.146]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  39.53377794017766
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.175]
 [41.045]
 [48.039]
 [39.441]
 [29.175]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  0
printing an ep nov before normalisation:  28.015853738862138
printing an ep nov before normalisation:  37.87194934821901
printing an ep nov before normalisation:  30.04466559488454
using explorer policy with actor:  0
printing an ep nov before normalisation:  62.17863950294196
using explorer policy with actor:  0
printing an ep nov before normalisation:  55.59315713502862
printing an ep nov before normalisation:  55.52669468249378
printing an ep nov before normalisation:  31.044446621685136
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.214]
 [43.231]
 [37.166]
 [41.382]
 [42.793]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  19.24048900604248
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.37 ]
 [62.136]
 [38.069]
 [31.596]
 [30.519]] [[0.128]
 [0.759]
 [0.335]
 [0.221]
 [0.202]]
printing an ep nov before normalisation:  41.142133504321436
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.077]
 [37.544]
 [27.071]
 [24.694]
 [26.713]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  43.93514716472903
printing an ep nov before normalisation:  43.60972435728448
using explorer policy with actor:  1
printing an ep nov before normalisation:  30.809918701762733
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
actions average: 
K:  4  action  0 :  tensor([    0.9828,     0.0029,     0.0009,     0.0051,     0.0083],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0031,     0.9041,     0.0265,     0.0003,     0.0660],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0036,     0.9056,     0.0358,     0.0550],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0004,     0.0029,     0.8938,     0.1025],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0029, 0.0056, 0.0898, 0.3230, 0.5787], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  36.93479679421018
printing an ep nov before normalisation:  89.36919932911022
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  77.64223463381917
printing an ep nov before normalisation:  0.0053986092143532005
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  14.98825003162574
printing an ep nov before normalisation:  42.05816714856246
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  65.23354224250926
siam score:  -0.87159395
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  41.97545528411865
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.207]
 [50.71 ]
 [44.207]
 [57.09 ]
 [44.207]] [[0.53 ]
 [0.673]
 [0.53 ]
 [0.812]
 [0.53 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
printing an ep nov before normalisation:  25.197737216949463
printing an ep nov before normalisation:  41.51665838800185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
using explorer policy with actor:  1
printing an ep nov before normalisation:  68.4380505683218
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.08337664614326587, 0.08337664614326587, 0.08337664614326587, 0.5831167692836706, 0.08337664614326587, 0.08337664614326587]
siam score:  -0.86582583
printing an ep nov before normalisation:  33.71206472082803
actor:  1 policy actor:  1  step number:  55 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
deleting a thread, now have 1 threads
Frames:  200903 train batches done:  23534 episodes:  5213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
siam score:  -0.8608815
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
siam score:  -0.84556395
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  19.870862440151882
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  33.67090594064961
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  31.45803204770513
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  40.24548792001064
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.483]
 [50.483]
 [50.483]
 [52.21 ]
 [50.483]] [[1.896]
 [1.896]
 [1.896]
 [2.   ]
 [1.896]]
printing an ep nov before normalisation:  55.90970324634418
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
siam score:  -0.8405722
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
siam score:  -0.8420103
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.68 ]
 [49.361]
 [54.49 ]
 [49.756]
 [47.82 ]] [[1.265]
 [1.746]
 [2.   ]
 [1.765]
 [1.669]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[81.723]
 [81.723]
 [81.723]
 [81.723]
 [81.723]] [[1.929]
 [1.929]
 [1.929]
 [1.929]
 [1.929]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.021]
 [0.011]
 [0.011]
 [0.011]] [[43.729]
 [53.506]
 [43.729]
 [43.729]
 [43.729]] [[1.115]
 [1.539]
 [1.115]
 [1.115]
 [1.115]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [25.833]
 [23.164]
 [ 0.   ]
 [ 0.   ]] [[-0.083]
 [ 0.176]
 [ 0.149]
 [-0.083]
 [-0.083]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
from probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  85.95016489238648
printing an ep nov before normalisation:  34.950125217437744
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.005]
 [44.846]
 [38.085]
 [47.198]
 [44.005]] [[1.159]
 [1.201]
 [0.867]
 [1.317]
 [1.159]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.426]
 [40.318]
 [40.318]
 [40.318]
 [40.318]] [[1.251]
 [1.245]
 [1.245]
 [1.245]
 [1.245]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  38.924045262716774
siam score:  -0.8476799
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  31.559373562138468
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  62.11178659557544
printing an ep nov before normalisation:  32.7574845606603
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  36.05370067142456
printing an ep nov before normalisation:  40.519347190856934
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.021]
 [0.   ]
 [0.021]
 [0.   ]] [[16.522]
 [30.636]
 [17.333]
 [30.636]
 [16.083]] [[0.953]
 [1.788]
 [1.   ]
 [1.788]
 [0.928]]
printing an ep nov before normalisation:  52.90564152511514
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.955]
 [31.955]
 [54.11 ]
 [38.557]
 [31.955]] [[0.462]
 [0.462]
 [1.072]
 [0.644]
 [0.462]]
printing an ep nov before normalisation:  94.18470174283735
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  46.48907727837936
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  38.59570641108466
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  21.750653675744616
printing an ep nov before normalisation:  50.780095998515556
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  29.958883921305336
siam score:  -0.8451547
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.18779934505774
siam score:  -0.8413645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
UNIT TEST: sample policy line 217 mcts : [0.872 0.026 0.051 0.026 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  48.381464351766645
printing an ep nov before normalisation:  63.87509847064601
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  25.317101158526107
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  35.34040981994459
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  31.37822703658835
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  31.338186264038086
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  29.52177865164621
printing an ep nov before normalisation:  34.62814630968131
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  52.76823985007002
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.486]
 [19.914]
 [19.163]
 [19.652]
 [24.516]] [[1.194]
 [0.666]
 [0.62 ]
 [0.65 ]
 [0.949]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  47.8737512733332
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  34.143690268198654
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  53.11851501812757
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]]
siam score:  -0.8535922
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  24.573562145233154
printing an ep nov before normalisation:  45.14916960370104
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
siam score:  -0.8530377
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
printing an ep nov before normalisation:  39.15281015053006
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.23467726108783
using another actor
from probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
from probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.055623663707658325, 0.055623663707658325, 0.055623663707658325, 0.3887526725846833, 0.055623663707658325, 0.3887526725846833]
actor:  1 policy actor:  1  step number:  60 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  0
printing an ep nov before normalisation:  33.35987739595929
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.   ]
 [0.   ]
 [0.   ]] [[57.55 ]
 [76.091]
 [57.55 ]
 [56.776]
 [61.805]] [[0.604]
 [0.939]
 [0.604]
 [0.59 ]
 [0.681]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  48.926090850629606
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  24.22564022184468
siam score:  -0.84450513
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.41851548028528
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[51.721]
 [43.136]
 [43.136]
 [43.136]
 [43.136]] [[1.335]
 [1.018]
 [1.018]
 [1.018]
 [1.018]]
printing an ep nov before normalisation:  60.368381630887924
printing an ep nov before normalisation:  37.76149966418384
line 256 mcts: sample exp_bonus 40.2087922463734
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.864]
 [34.312]
 [34.312]
 [34.312]
 [34.312]] [[1.738]
 [1.122]
 [1.122]
 [1.122]
 [1.122]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]] [[58.066]
 [39.621]
 [39.621]
 [39.621]
 [39.621]] [[1.26 ]
 [0.622]
 [0.622]
 [0.622]
 [0.622]]
printing an ep nov before normalisation:  75.05707532885579
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  34.69764627292037
printing an ep nov before normalisation:  35.55719030069841
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  36.42301526239694
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  35.86234092712402
actions average: 
K:  3  action  0 :  tensor([    0.9954,     0.0003,     0.0000,     0.0003,     0.0039],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0019, 0.9577, 0.0073, 0.0015, 0.0315], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0003,     0.9044,     0.0721,     0.0232],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0008,     0.0197,     0.8649,     0.1144],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0031, 0.0244, 0.0184, 0.2322, 0.7220], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  30.673468112945557
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  68.5044824617625
printing an ep nov before normalisation:  37.77875608867141
printing an ep nov before normalisation:  68.80739127446414
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  79.66852216716829
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.83655137
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  27.80545949935913
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  18.18996548652649
siam score:  -0.8430148
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  48.82761670135062
printing an ep nov before normalisation:  61.16188533374761
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  92.16640139845275
printing an ep nov before normalisation:  22.97896241567155
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  40.69457685644144
printing an ep nov before normalisation:  51.78041398040214
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9686,     0.0012,     0.0001,     0.0019,     0.0282],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0039,     0.8531,     0.0209,     0.0003,     0.1217],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0026,     0.9942,     0.0010,     0.0023],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0013,     0.0532,     0.8088,     0.1367],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0011, 0.0043, 0.0022, 0.1084, 0.8839], grad_fn=<DivBackward0>)
siam score:  -0.83887506
printing an ep nov before normalisation:  100.72218817102667
printing an ep nov before normalisation:  44.46401791798908
printing an ep nov before normalisation:  59.95616766343231
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  46.82929515838623
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.001]
 [0.   ]
 [0.   ]] [[34.319]
 [34.319]
 [32.661]
 [34.319]
 [34.319]] [[0.868]
 [0.868]
 [0.774]
 [0.868]
 [0.868]]
line 256 mcts: sample exp_bonus 61.62562640757883
siam score:  -0.8548955
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.001]
 [0.   ]
 [0.   ]] [[29.453]
 [29.453]
 [57.611]
 [29.453]
 [29.453]] [[0.437]
 [0.437]
 [1.232]
 [0.437]
 [0.437]]
printing an ep nov before normalisation:  78.89885393573873
printing an ep nov before normalisation:  55.156455889312156
printing an ep nov before normalisation:  64.3219123069689
actions average: 
K:  2  action  0 :  tensor([    0.9710,     0.0022,     0.0000,     0.0167,     0.0102],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0020,     0.9665,     0.0008,     0.0012,     0.0294],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0009,     0.9448,     0.0292,     0.0252],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0009,     0.0082,     0.8995,     0.0910],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0061, 0.0095, 0.0113, 0.1212, 0.8518], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  37.99550771713257
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  79.08437160750962
printing an ep nov before normalisation:  53.65044647281438
printing an ep nov before normalisation:  74.62135665962377
siam score:  -0.85298264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  40.53013645910731
using explorer policy with actor:  0
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 59.98661854032929
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  42.88495176210266
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.234]
 [44.234]
 [44.234]
 [44.96 ]
 [44.234]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  4  action  0 :  tensor([    0.9957,     0.0003,     0.0000,     0.0001,     0.0040],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0008,     0.9683,     0.0004,     0.0003,     0.0302],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0003,     0.7293,     0.1168,     0.1536],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0007,     0.0001,     0.0199,     0.8474,     0.1320],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0022, 0.0070, 0.0450, 0.3526, 0.5931], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  45.602428483228984
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.297]
 [35.387]
 [35.387]
 [35.387]
 [35.387]] [[1.384]
 [0.694]
 [0.694]
 [0.694]
 [0.694]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.001]] [[41.627]
 [36.755]
 [36.863]
 [40.084]
 [38.269]] [[0.275]
 [0.242]
 [0.243]
 [0.264]
 [0.253]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  34.92807037431369
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
UNIT TEST: sample policy line 217 mcts : [0.128 0.692 0.    0.154 0.026]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.002]
 [0.002]
 [0.002]
 [0.003]] [[37.725]
 [57.998]
 [55.193]
 [46.009]
 [56.086]] [[1.119]
 [1.722]
 [1.639]
 [1.366]
 [1.666]]
printing an ep nov before normalisation:  49.76178649331017
printing an ep nov before normalisation:  52.41190216625087
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  0.0057722486826605746
printing an ep nov before normalisation:  36.13088921458342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  26.937781527252717
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 29.79976508809084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  47.64314005419221
printing an ep nov before normalisation:  37.175071239471436
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  56.64571560176824
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.85457873
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  39.278080166714034
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  52.537549243253785
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.847566
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  37.99717628377477
printing an ep nov before normalisation:  72.48107418735985
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  73.06461183089132
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  40.65346744933077
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  31.008512834047153
actions average: 
K:  0  action  0 :  tensor([    0.9988,     0.0000,     0.0000,     0.0005,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0004,     0.9741,     0.0003,     0.0000,     0.0251],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0003,     0.9895,     0.0007,     0.0095],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0012,     0.0211,     0.8587,     0.1189],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0414, 0.0468, 0.0345, 0.2893, 0.5880], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 54.214978053628336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  66.41916031755824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  62.956901530529
printing an ep nov before normalisation:  34.5888847857981
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.069]
 [48.069]
 [48.069]
 [48.069]
 [48.069]] [[1.492]
 [1.492]
 [1.492]
 [1.492]
 [1.492]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.456925649569957
printing an ep nov before normalisation:  30.353541177460933
printing an ep nov before normalisation:  56.08717712022428
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
line 256 mcts: sample exp_bonus 53.48379623787241
printing an ep nov before normalisation:  41.87683049963898
printing an ep nov before normalisation:  62.880388870829286
using another actor
siam score:  -0.8257608
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  29.016580362168522
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[49.461]
 [39.295]
 [54.064]
 [48.472]
 [49.461]] [[0.916]
 [0.632]
 [1.045]
 [0.889]
 [0.916]]
printing an ep nov before normalisation:  30.80699920654297
printing an ep nov before normalisation:  27.16911408994738
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  0  action  0 :  tensor([    0.9932,     0.0036,     0.0003,     0.0001,     0.0028],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9870,     0.0005,     0.0029,     0.0095],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0002,     0.9989,     0.0004,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0008,     0.0000,     0.0407,     0.8565,     0.1019],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0045, 0.0035, 0.0698, 0.2720, 0.6502], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  69.82463775158776
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  44.59829059555817
printing an ep nov before normalisation:  47.89140869264615
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[31.724]
 [31.724]
 [37.363]
 [34.758]
 [32.639]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  39.15978881189301
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.   ]
 [0.   ]
 [0.   ]] [[36.866]
 [21.045]
 [21.045]
 [21.045]
 [21.045]] [[0.974]
 [0.401]
 [0.401]
 [0.401]
 [0.401]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  70.56167953297307
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.   ]
 [0.   ]
 [0.001]] [[32.37 ]
 [42.098]
 [43.871]
 [37.563]
 [44.531]] [[0.577]
 [0.751]
 [0.782]
 [0.67 ]
 [0.794]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  0.0
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.8376637
printing an ep nov before normalisation:  27.27191460813344
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  63.68306196336917
printing an ep nov before normalisation:  66.71394403259028
printing an ep nov before normalisation:  55.44882871520422
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.241]
 [57.914]
 [34.41 ]
 [34.41 ]
 [34.41 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.165]
 [58.559]
 [41.37 ]
 [41.37 ]
 [50.993]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  30.916897069780134
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  27.77376189440441
printing an ep nov before normalisation:  74.96314328588949
printing an ep nov before normalisation:  72.74653044710008
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  25.132497660378824
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  32.17440075317746
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  85.10733341890936
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  24.631991386413574
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.   ]
 [0.   ]
 [0.001]
 [0.   ]] [[55.542]
 [72.067]
 [55.542]
 [62.95 ]
 [55.542]] [[1.411]
 [1.936]
 [1.411]
 [1.647]
 [1.411]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  35.330328941345215
actions average: 
K:  3  action  0 :  tensor([    0.9903,     0.0003,     0.0008,     0.0011,     0.0075],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0002,     0.9891,     0.0071,     0.0009,     0.0027],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9670,     0.0009,     0.0319],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0401, 0.0079, 0.0460, 0.7108, 0.1952], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0078, 0.0079, 0.1278, 0.1935, 0.6630], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
UNIT TEST: sample policy line 217 mcts : [0.154 0.41  0.231 0.128 0.077]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  4  action  0 :  tensor([    0.9854,     0.0007,     0.0001,     0.0029,     0.0109],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0037,     0.8762,     0.0027,     0.0005,     0.1169],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0026,     0.9297,     0.0544,     0.0132],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0025,     0.0003,     0.0039,     0.9001,     0.0932],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0018, 0.0092, 0.0068, 0.2378, 0.7444], grad_fn=<DivBackward0>)
siam score:  -0.8389514
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.629057686143206
printing an ep nov before normalisation:  30.7542085647583
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.8428923
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  29.5462191673215
printing an ep nov before normalisation:  44.11204595780953
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  43.40854979068508
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  68.86708562426107
using explorer policy with actor:  1
printing an ep nov before normalisation:  46.168856620788574
siam score:  -0.844956
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.001]
 [0.   ]
 [0.   ]] [[37.155]
 [47.512]
 [35.299]
 [37.155]
 [37.155]] [[0.673]
 [1.03 ]
 [0.61 ]
 [0.673]
 [0.673]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  50.52126220332449
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  59.22975277908561
printing an ep nov before normalisation:  53.57008588404975
printing an ep nov before normalisation:  32.48290538787842
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  27.08146095275879
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  59.42363754256346
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  58.34702850691631
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  84.32866706813954
printing an ep nov before normalisation:  71.93714630371613
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  60.69143130079286
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  1  action  0 :  tensor([    0.9991,     0.0002,     0.0000,     0.0000,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9585,     0.0036,     0.0000,     0.0377],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9090,     0.0461,     0.0448],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0005,     0.0106,     0.9406,     0.0481],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0071, 0.0112, 0.0020, 0.2244, 0.7553], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  75.51919258618855
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  36.67293811464508
printing an ep nov before normalisation:  59.58874283646878
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  76.97599052975244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  43.21676326273144
siam score:  -0.8538504
actions average: 
K:  1  action  0 :  tensor([    0.9772,     0.0019,     0.0000,     0.0081,     0.0127],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9480,     0.0032,     0.0013,     0.0473],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0325,     0.0001,     0.8941,     0.0505,     0.0228],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0004,     0.0082,     0.8786,     0.1126],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0046, 0.0289, 0.0456, 0.1360, 0.7849], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  55.972839463177664
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.158598986576806
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  4  action  0 :  tensor([    0.9905,     0.0026,     0.0000,     0.0001,     0.0067],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0004,     0.9986,     0.0001,     0.0002,     0.0006],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0477,     0.0046,     0.9421,     0.0003,     0.0053],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0004,     0.0541,     0.8307,     0.1145],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0199, 0.0602, 0.0341, 0.1853, 0.7005], grad_fn=<DivBackward0>)
using explorer policy with actor:  0
siam score:  -0.84696853
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.83603382110596
printing an ep nov before normalisation:  53.363980889956
line 256 mcts: sample exp_bonus 29.44147249705952
printing an ep nov before normalisation:  37.23124971959296
printing an ep nov before normalisation:  81.58786896618376
printing an ep nov before normalisation:  75.1162927208369
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.87609946727753
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  70.60548342473092
printing an ep nov before normalisation:  35.67529812885972
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.001]
 [0.001]
 [0.001]] [[35.259]
 [22.162]
 [35.93 ]
 [32.353]
 [27.78 ]] [[0.001]
 [0.   ]
 [0.001]
 [0.001]
 [0.001]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.84824157
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  58.4712754206759
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.003]
 [0.001]
 [0.003]
 [0.003]] [[53.257]
 [63.734]
 [63.583]
 [51.629]
 [66.517]] [[1.328]
 [1.657]
 [1.65 ]
 [1.275]
 [1.744]]
actions average: 
K:  0  action  0 :  tensor([    0.9898,     0.0006,     0.0000,     0.0028,     0.0068],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0367,     0.9536,     0.0005,     0.0003,     0.0089],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9994,     0.0002,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0001,     0.0052,     0.8285,     0.1661],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0026, 0.0307, 0.0425, 0.2939, 0.6303], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[34.293]
 [49.866]
 [33.564]
 [33.564]
 [33.564]] [[0.625]
 [1.152]
 [0.6  ]
 [0.6  ]
 [0.6  ]]
printing an ep nov before normalisation:  22.900623045419195
printing an ep nov before normalisation:  43.57169405077915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.85989934
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  35.00300407409668
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  41.64198875427246
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  84.93266707353835
printing an ep nov before normalisation:  62.94784411827913
printing an ep nov before normalisation:  47.742621103922524
printing an ep nov before normalisation:  87.28634593126785
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[59.187]
 [32.828]
 [38.274]
 [45.62 ]
 [43.136]] [[0.   ]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[50.695]
 [50.695]
 [50.695]
 [50.695]
 [63.144]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
printing an ep nov before normalisation:  27.703092098236084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  0
printing an ep nov before normalisation:  30.713791847229004
printing an ep nov before normalisation:  72.54861866395707
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[34.191]
 [34.191]
 [36.814]
 [34.191]
 [34.191]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[35.67 ]
 [33.489]
 [43.314]
 [40.905]
 [35.67 ]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
printing an ep nov before normalisation:  61.61764718389409
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.001]
 [0.   ]
 [0.   ]] [[33.205]
 [36.21 ]
 [39.141]
 [33.205]
 [33.205]] [[0.   ]
 [0.001]
 [0.001]
 [0.   ]
 [0.   ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[37.642]
 [37.642]
 [37.642]
 [39.081]
 [37.642]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
printing an ep nov before normalisation:  27.73762387372535
printing an ep nov before normalisation:  37.326881885528564
siam score:  -0.8636761
printing an ep nov before normalisation:  45.40358094344435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[31.47]
 [31.47]
 [31.47]
 [31.47]
 [31.47]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.002]
 [0.001]] [[43.074]
 [39.128]
 [38.626]
 [28.983]
 [36.528]] [[0.001]
 [0.001]
 [0.001]
 [0.002]
 [0.001]]
printing an ep nov before normalisation:  39.75449361626153
printing an ep nov before normalisation:  28.034934364696095
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.003]
 [0.002]] [[42.144]
 [42.144]
 [42.144]
 [42.742]
 [42.144]] [[0.958]
 [0.958]
 [0.958]
 [0.978]
 [0.958]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  75.20760871906255
printing an ep nov before normalisation:  35.73031932328504
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[27.504]
 [27.504]
 [27.504]
 [27.504]
 [27.504]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  60.92504433321375
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
UNIT TEST: sample policy line 217 mcts : [0.846 0.077 0.026 0.026 0.026]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.002]
 [0.001]] [[40.161]
 [38.053]
 [40.743]
 [27.271]
 [36.763]] [[0.001]
 [0.001]
 [0.001]
 [0.002]
 [0.001]]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[63.547]
 [55.221]
 [55.221]
 [55.221]
 [55.221]] [[0.002]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.014]
 [0.004]] [[30.863]
 [30.863]
 [30.863]
 [37.311]
 [30.863]] [[1.011]
 [1.011]
 [1.011]
 [1.342]
 [1.011]]
printing an ep nov before normalisation:  66.45120933041129
printing an ep nov before normalisation:  49.665670029731075
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.   ]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.   ]
 [0.001]
 [0.001]
 [0.001]]
printing an ep nov before normalisation:  51.08297571216604
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  82.62968843755237
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
siam score:  -0.8640888
printing an ep nov before normalisation:  42.77121579762222
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  77.65402153997805
printing an ep nov before normalisation:  74.95511277136005
printing an ep nov before normalisation:  65.10744197186025
printing an ep nov before normalisation:  62.421406281700406
Printing some Q and Qe and total Qs values:  [[0.02 ]
 [0.004]
 [0.007]
 [0.003]
 [0.004]] [[58.603]
 [17.041]
 [18.703]
 [15.579]
 [19.563]] [[1.323]
 [0.178]
 [0.226]
 [0.136]
 [0.246]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  99.4562779376009
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[57.108]
 [28.184]
 [28.184]
 [28.184]
 [28.184]] [[1.334]
 [0.452]
 [0.452]
 [0.452]
 [0.452]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[23.77 ]
 [23.77 ]
 [23.77 ]
 [29.378]
 [23.77 ]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  56.78616896449206
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.003]
 [0.004]] [[26.616]
 [26.616]
 [26.616]
 [50.413]
 [26.616]] [[0.367]
 [0.367]
 [0.367]
 [0.896]
 [0.367]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8589194
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[51.993]
 [44.477]
 [44.477]
 [50.525]
 [44.477]] [[1.694]
 [1.342]
 [1.342]
 [1.625]
 [1.342]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.002]
 [0.002]] [[34.796]
 [55.111]
 [30.985]
 [28.667]
 [32.637]] [[0.564]
 [1.297]
 [0.427]
 [0.344]
 [0.487]]
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  51.946538642583576
printing an ep nov before normalisation:  62.58703600367082
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  2  action  0 :  tensor([    0.9852,     0.0044,     0.0000,     0.0043,     0.0060],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9160,     0.0007,     0.0003,     0.0826],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9571,     0.0002,     0.0426],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0002,     0.0004,     0.0350,     0.8024,     0.1620],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0018, 0.0034, 0.0659, 0.1170, 0.8119], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.767]
 [0.036]
 [0.036]
 [0.036]
 [0.036]] [[42.596]
 [46.617]
 [46.617]
 [46.617]
 [46.617]] [[0.767]
 [0.036]
 [0.036]
 [0.036]
 [0.036]]
siam score:  -0.86037153
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  30.59008774099788
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  63.92539958781196
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9964,     0.0002,     0.0000,     0.0013,     0.0022],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0009,     0.9551,     0.0084,     0.0083,     0.0273],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.8786,     0.0990,     0.0225],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0000,     0.0354,     0.8250,     0.1393],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0030, 0.0037, 0.0195, 0.2256, 0.7482], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  40.251746158059035
line 256 mcts: sample exp_bonus 22.847366088386966
printing an ep nov before normalisation:  37.38752841949463
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[24.015]
 [27.504]
 [33.434]
 [20.994]
 [20.602]] [[0.606]
 [0.75 ]
 [0.993]
 [0.483]
 [0.467]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  40.367336467307254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[63.708]
 [63.708]
 [63.708]
 [63.708]
 [63.708]] [[1.802]
 [1.802]
 [1.802]
 [1.802]
 [1.802]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using another actor
actions average: 
K:  4  action  0 :  tensor([    0.9820,     0.0014,     0.0000,     0.0041,     0.0125],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9853,     0.0002,     0.0107,     0.0037],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0006,     0.9740,     0.0024,     0.0231],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0014, 0.0009, 0.0453, 0.8239, 0.1286], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([    0.0006,     0.0308,     0.0711,     0.2008,     0.6967],
       grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[74.243]
 [74.641]
 [67.437]
 [66.866]
 [76.191]] [[1.127]
 [1.137]
 [0.969]
 [0.955]
 [1.173]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[72.017]
 [72.017]
 [72.017]
 [72.017]
 [72.017]] [[2.001]
 [2.001]
 [2.001]
 [2.001]
 [2.001]]
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[89.283]
 [89.283]
 [89.283]
 [89.283]
 [89.283]] [[1.333]
 [1.333]
 [1.333]
 [1.333]
 [1.333]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[60.292]
 [48.421]
 [58.46 ]
 [34.999]
 [47.318]] [[0.876]
 [0.543]
 [0.824]
 [0.166]
 [0.512]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  35.7055202828138
printing an ep nov before normalisation:  48.10661602167528
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  0.0
printing an ep nov before normalisation:  43.742043915380165
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 6.999]
 [10.606]
 [ 7.143]
 [11.298]
 [14.225]] [[0.065]
 [0.099]
 [0.067]
 [0.105]
 [0.133]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[23.649]
 [33.455]
 [40.365]
 [28.159]
 [33.455]] [[0.253]
 [0.623]
 [0.884]
 [0.423]
 [0.623]]
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  0
UNIT TEST: sample policy line 217 mcts : [0.385 0.051 0.41  0.077 0.077]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
UNIT TEST: sample policy line 217 mcts : [0.026 0.051 0.051 0.821 0.051]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.002]
 [0.001]
 [0.001]] [[88.72 ]
 [88.72 ]
 [90.137]
 [88.72 ]
 [88.72 ]] [[0.926]
 [0.926]
 [0.941]
 [0.926]
 [0.926]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  27.824850366877826
printing an ep nov before normalisation:  48.77395153045654
printing an ep nov before normalisation:  76.38565371154179
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[25.748]
 [34.99 ]
 [39.447]
 [32.254]
 [32.583]] [[0.456]
 [0.621]
 [0.7  ]
 [0.572]
 [0.578]]
printing an ep nov before normalisation:  54.90541240876722
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  1  action  0 :  tensor([    0.9978,     0.0004,     0.0000,     0.0001,     0.0017],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9958,     0.0003,     0.0022,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9045,     0.0685,     0.0268],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0233,     0.0001,     0.0064,     0.8245,     0.1457],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0105, 0.0057, 0.0359, 0.2019, 0.7460], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  51.628479707694225
printing an ep nov before normalisation:  67.58111741015911
printing an ep nov before normalisation:  48.96194180855995
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.002]
 [0.003]
 [0.003]] [[80.69 ]
 [80.69 ]
 [65.652]
 [80.69 ]
 [80.69 ]] [[1.67]
 [1.67]
 [1.27]
 [1.67]
 [1.67]]
printing an ep nov before normalisation:  9.381134077557363e-05
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.38589089011469
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  53.9822133571621
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  43.968823188577176
printing an ep nov before normalisation:  43.18679287341254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  42.5262529994907
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.002]
 [0.001]] [[27.637]
 [27.637]
 [27.637]
 [38.696]
 [27.637]] [[0.748]
 [0.748]
 [0.748]
 [1.348]
 [0.748]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[40.343]
 [46.635]
 [41.606]
 [40.819]
 [39.243]] [[0.803]
 [1.041]
 [0.851]
 [0.821]
 [0.761]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  52.380590481626534
printing an ep nov before normalisation:  0.019219262175340646
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.45377255314125
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[67.784]
 [67.784]
 [67.784]
 [67.784]
 [67.784]] [[2.001]
 [2.001]
 [2.001]
 [2.001]
 [2.001]]
printing an ep nov before normalisation:  46.90076267950009
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.86699754
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.866552
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  74.73203346271393
printing an ep nov before normalisation:  30.040666035243444
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  49.89669744004508
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.82360657301656
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
printing an ep nov before normalisation:  55.13155118675754
printing an ep nov before normalisation:  34.20258201626612
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  22.73204216767753
printing an ep nov before normalisation:  51.259302374011696
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  69.02267785948246
printing an ep nov before normalisation:  115.53651661866428
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.005]
 [0.002]] [[52.945]
 [57.462]
 [50.291]
 [53.115]
 [57.153]] [[1.66 ]
 [1.801]
 [1.577]
 [1.668]
 [1.792]]
using explorer policy with actor:  1
siam score:  -0.8676479
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.002]
 [0.003]
 [0.003]] [[49.62 ]
 [49.62 ]
 [50.665]
 [49.62 ]
 [49.62 ]] [[1.849]
 [1.849]
 [1.911]
 [1.849]
 [1.849]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  25.955020200718266
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  7.427269679283199e-06
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  2  action  0 :  tensor([    0.9699,     0.0118,     0.0001,     0.0050,     0.0132],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0118,     0.9200,     0.0541,     0.0140],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0045, 0.0071, 0.0350, 0.7939, 0.1594], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0062, 0.0085, 0.0260, 0.4000, 0.5593], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  51.40727764802722
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[47.344]
 [47.344]
 [55.158]
 [42.422]
 [44.263]] [[0.839]
 [0.839]
 [1.078]
 [0.688]
 [0.744]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  56.3531810301753
printing an ep nov before normalisation:  51.1897039820624
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  40.11324269497696
printing an ep nov before normalisation:  25.224651863308
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[45.695]
 [45.695]
 [45.695]
 [45.695]
 [45.695]] [[91.392]
 [91.392]
 [91.392]
 [91.392]
 [91.392]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.28945297517772
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[56.064]
 [36.229]
 [42.095]
 [42.095]
 [42.095]] [[1.366]
 [0.642]
 [0.856]
 [0.856]
 [0.856]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  63.10861062299254
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.3832483291626
printing an ep nov before normalisation:  46.74488861273685
printing an ep nov before normalisation:  52.7209347589446
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[43.352]
 [37.675]
 [30.676]
 [43.143]
 [37.828]] [[0.836]
 [0.663]
 [0.449]
 [0.83 ]
 [0.667]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.88284796
actions average: 
K:  4  action  0 :  tensor([    0.9982,     0.0011,     0.0000,     0.0000,     0.0007],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0004,     0.9702,     0.0009,     0.0001,     0.0285],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0011,     0.9269,     0.0444,     0.0277],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0088,     0.0005,     0.0140,     0.8910,     0.0857],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0063, 0.0047, 0.0628, 0.3649, 0.5613], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[48.697]
 [48.697]
 [48.697]
 [48.697]
 [48.697]] [[81.18]
 [81.18]
 [81.18]
 [81.18]
 [81.18]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[41.864]
 [30.284]
 [33.907]
 [30.284]
 [30.284]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.003]
 [0.   ]
 [0.002]
 [0.002]] [[44.832]
 [36.655]
 [42.157]
 [48.381]
 [41.362]] [[0.   ]
 [0.003]
 [0.   ]
 [0.002]
 [0.002]]
printing an ep nov before normalisation:  82.39532939418854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  74.92123876375571
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[69.647]
 [61.23 ]
 [61.23 ]
 [61.23 ]
 [61.23 ]] [[1.818]
 [1.453]
 [1.453]
 [1.453]
 [1.453]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  55.182574231409106
printing an ep nov before normalisation:  74.57162074690517
printing an ep nov before normalisation:  86.2701186238693
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
actions average: 
K:  1  action  0 :  tensor([    0.9943,     0.0004,     0.0000,     0.0002,     0.0051],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9789,     0.0002,     0.0002,     0.0206],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([0.0870, 0.0026, 0.8447, 0.0319, 0.0339], grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0001,     0.0065,     0.8919,     0.1014],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0006, 0.0018, 0.0531, 0.3614, 0.5831], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  70.78624449577828
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  3  action  0 :  tensor([    0.9975,     0.0004,     0.0000,     0.0005,     0.0017],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9998,     0.0001,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9994,     0.0003,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0007,     0.0005,     0.0290,     0.8577,     0.1121],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0009, 0.0384, 0.0657, 0.1249, 0.7701], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.78746318618003
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.8784378
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  42.78440680559631
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.003]
 [0.004]
 [0.004]
 [0.004]] [[47.077]
 [77.71 ]
 [47.077]
 [47.077]
 [47.077]] [[0.529]
 [1.178]
 [0.529]
 [0.529]
 [0.529]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[70.057]
 [80.63 ]
 [84.326]
 [86.464]
 [80.63 ]] [[1.242]
 [1.479]
 [1.561]
 [1.609]
 [1.479]]
printing an ep nov before normalisation:  57.659667898191486
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  80.75899949456209
printing an ep nov before normalisation:  72.22344300225151
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[70.224]
 [70.224]
 [70.224]
 [70.224]
 [70.224]] [[1.971]
 [1.971]
 [1.971]
 [1.971]
 [1.971]]
printing an ep nov before normalisation:  46.631460189819336
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  49.40274671147598
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  48.05422888861762
printing an ep nov before normalisation:  57.11298420374787
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  59.83596008309558
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
using another actor
printing an ep nov before normalisation:  0.0001796368417217309
siam score:  -0.8883171
siam score:  -0.8893531
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  54.90340821169077
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.011]
 [0.011]
 [0.011]
 [0.011]] [[42.511]
 [42.511]
 [42.511]
 [42.511]
 [42.511]] [[85.032]
 [85.032]
 [85.032]
 [85.032]
 [85.032]]
siam score:  -0.8945298
printing an ep nov before normalisation:  73.94500497247351
printing an ep nov before normalisation:  54.79576053600328
printing an ep nov before normalisation:  46.984412051778556
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[67.535]
 [60.659]
 [60.659]
 [60.659]
 [60.659]] [[1.514]
 [1.283]
 [1.283]
 [1.283]
 [1.283]]
printing an ep nov before normalisation:  71.46368144838905
actions average: 
K:  1  action  0 :  tensor([0.9885, 0.0016, 0.0031, 0.0027, 0.0041], grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9763,     0.0003,     0.0006,     0.0225],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0002,     0.9659,     0.0271,     0.0068],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0003,     0.0132,     0.8952,     0.0910],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0102, 0.0058, 0.0173, 0.2897, 0.6770], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.006]
 [0.002]
 [0.005]
 [0.004]] [[57.104]
 [84.745]
 [43.943]
 [48.363]
 [47.986]] [[0.716]
 [1.339]
 [0.421]
 [0.523]
 [0.514]]
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.004]
 [0.002]
 [0.003]
 [0.003]] [[56.185]
 [36.198]
 [39.154]
 [55.621]
 [40.823]] [[1.34 ]
 [0.631]
 [0.734]
 [1.32 ]
 [0.794]]
printing an ep nov before normalisation:  58.97405227859884
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[55.475]
 [55.475]
 [55.475]
 [55.475]
 [55.475]] [[110.952]
 [110.952]
 [110.952]
 [110.952]
 [110.952]]
printing an ep nov before normalisation:  43.696045875549316
printing an ep nov before normalisation:  75.47135948263374
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  54.4686328347934
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  54.55986447066446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.005]
 [0.004]
 [0.003]
 [0.004]] [[87.859]
 [87.846]
 [92.632]
 [77.073]
 [93.554]] [[1.845]
 [1.842]
 [1.941]
 [1.614]
 [1.96 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  44.824882590872534
printing an ep nov before normalisation:  65.4681444136138
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.004]
 [0.003]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.004]
 [0.003]
 [0.004]
 [0.004]]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.003]
 [0.003]
 [0.004]
 [0.003]] [[44.794]
 [42.761]
 [44.78 ]
 [45.66 ]
 [44.121]] [[1.694]
 [1.578]
 [1.693]
 [1.743]
 [1.655]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.016]
 [0.016]
 [0.014]
 [0.014]] [[57.371]
 [58.906]
 [58.906]
 [59.31 ]
 [60.518]] [[1.827]
 [1.901]
 [1.901]
 [1.917]
 [1.97 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  60.99214286853403
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.33198090147583
printing an ep nov before normalisation:  48.67062489045112
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  39.12958606053339
siam score:  -0.8995613
printing an ep nov before normalisation:  70.4923118817759
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.8987544
siam score:  -0.8979456
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.8974249
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  40.60797960827469
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  1  action  0 :  tensor([    0.9654,     0.0144,     0.0004,     0.0027,     0.0171],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9765,     0.0001,     0.0001,     0.0230],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9969,     0.0017,     0.0013],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0012,     0.0006,     0.0154,     0.8774,     0.1054],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0019, 0.0379, 0.0213, 0.1040, 0.8350], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  44.76341736827624
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  64.9504334503026
printing an ep nov before normalisation:  31.221871376037598
printing an ep nov before normalisation:  47.56893892045749
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  47.319384578922524
printing an ep nov before normalisation:  22.39252124885261
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.019]
 [0.019]
 [0.019]
 [0.019]] [[32.269]
 [32.269]
 [32.269]
 [32.269]
 [32.269]] [[2.019]
 [2.019]
 [2.019]
 [2.019]
 [2.019]]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  29.26194190979004
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.90477586
printing an ep nov before normalisation:  51.81603282648353
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
printing an ep nov before normalisation:  75.69931109992977
maxi score, test score, baseline:  0.0001 0.0 0.0001
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  51.783203962427734
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]]
siam score:  -0.90453446
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.90182847
using another actor
printing an ep nov before normalisation:  87.50144142093596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.029]
 [0.004]
 [0.005]
 [0.012]] [[73.95 ]
 [76.872]
 [78.231]
 [59.583]
 [81.769]] [[1.676]
 [1.753]
 [1.759]
 [1.339]
 [1.846]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  73.02702847459412
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  43.66199334143811
printing an ep nov before normalisation:  40.79473000443977
printing an ep nov before normalisation:  42.4959253358503
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]]
printing an ep nov before normalisation:  47.179092679704944
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.011]
 [0.005]
 [0.007]
 [0.005]] [[42.011]
 [35.708]
 [42.011]
 [47.709]
 [42.011]] [[0.401]
 [0.279]
 [0.401]
 [0.519]
 [0.401]]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.008]
 [0.008]
 [0.008]
 [0.008]] [[54.269]
 [37.817]
 [37.817]
 [37.817]
 [37.817]] [[0.634]
 [0.356]
 [0.356]
 [0.356]
 [0.356]]
printing an ep nov before normalisation:  16.131163835525513
printing an ep nov before normalisation:  0.0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.849235372833206
line 256 mcts: sample exp_bonus 55.54153849800058
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  2  action  0 :  tensor([    0.9750,     0.0117,     0.0002,     0.0002,     0.0130],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0019,     0.9245,     0.0275,     0.0002,     0.0459],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9994,     0.0004,     0.0002],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0002,     0.0302,     0.8888,     0.0807],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0073, 0.0188, 0.0581, 0.2891, 0.6268], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.200901973595016
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.005]
 [0.004]] [[36.94 ]
 [41.348]
 [47.952]
 [40.029]
 [36.94 ]] [[0.635]
 [0.76 ]
 [0.949]
 [0.723]
 [0.635]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.004]
 [0.003]
 [0.003]
 [0.003]] [[75.839]
 [80.514]
 [75.839]
 [75.839]
 [75.839]] [[1.17]
 [1.27]
 [1.17]
 [1.17]
 [1.17]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  85.22031942997697
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  78.07376179050533
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  46.043182441750346
actions average: 
K:  2  action  0 :  tensor([    0.9923,     0.0003,     0.0000,     0.0012,     0.0063],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9873,     0.0005,     0.0039,     0.0082],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0298,     0.8591,     0.0511,     0.0600],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0017,     0.0002,     0.0278,     0.8448,     0.1255],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0132, 0.0780, 0.0604, 0.2038, 0.6446], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.88571763
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.3298064473852
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[46.921]
 [46.921]
 [46.921]
 [46.921]
 [46.921]] [[1.876]
 [1.876]
 [1.876]
 [1.876]
 [1.876]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.004]
 [0.004]
 [0.004]
 [0.004]]
using explorer policy with actor:  1
siam score:  -0.8930895
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.65860855279743
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.005]
 [0.004]] [[32.515]
 [35.659]
 [40.74 ]
 [40.266]
 [32.515]] [[0.434]
 [0.51 ]
 [0.635]
 [0.624]
 [0.434]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.78001435415857
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.689549922943115
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  37.86660671234131
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.005]
 [0.005]] [[57.512]
 [57.512]
 [59.61 ]
 [58.396]
 [57.416]] [[1.475]
 [1.475]
 [1.529]
 [1.499]
 [1.474]]
printing an ep nov before normalisation:  0.2373764317729865
printing an ep nov before normalisation:  22.54978815714518
actions average: 
K:  2  action  0 :  tensor([    0.9881,     0.0062,     0.0003,     0.0002,     0.0052],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0004,     0.9391,     0.0014,     0.0000,     0.0591],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9715,     0.0169,     0.0115],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0014, 0.0010, 0.0365, 0.8891, 0.0721], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0052, 0.0788, 0.0647, 0.2881, 0.5632], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  49.32022571563721
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  39.34748216290728
printing an ep nov before normalisation:  43.890395164489746
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[72.463]
 [56.474]
 [56.474]
 [56.474]
 [56.474]] [[1.924]
 [1.415]
 [1.415]
 [1.415]
 [1.415]]
printing an ep nov before normalisation:  32.919909093289796
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  69.07060559187497
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[58.595]
 [55.022]
 [60.849]
 [58.595]
 [58.595]] [[1.409]
 [1.217]
 [1.529]
 [1.409]
 [1.409]]
printing an ep nov before normalisation:  76.18732716532969
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.004]
 [0.004]
 [0.005]
 [0.004]] [[55.222]
 [54.13 ]
 [54.523]
 [51.585]
 [53.91 ]] [[1.736]
 [1.67 ]
 [1.695]
 [1.511]
 [1.656]]
printing an ep nov before normalisation:  38.71669835181883
printing an ep nov before normalisation:  42.644404903733744
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
printing an ep nov before normalisation:  27.84886360168457
printing an ep nov before normalisation:  64.58047124395091
printing an ep nov before normalisation:  55.86948500936315
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  41.790994820795646
printing an ep nov before normalisation:  70.33133484449617
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  36.23743109186205
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  60.56559166628556
printing an ep nov before normalisation:  53.26394852697911
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  57.83224237881388
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using another actor
printing an ep nov before normalisation:  45.34440597352393
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.014]
 [0.083]
 [0.026]
 [0.026]
 [0.026]] [[59.83 ]
 [46.27 ]
 [54.051]
 [54.051]
 [54.051]] [[1.937]
 [1.477]
 [1.724]
 [1.724]
 [1.724]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
from probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  42.22852200632733
printing an ep nov before normalisation:  73.09438635389242
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  75.46144440774098
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  47.929128138007336
printing an ep nov before normalisation:  76.2777550898617
printing an ep nov before normalisation:  48.91501645816021
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[31.483]
 [32.08 ]
 [36.284]
 [36.274]
 [33.332]] [[0.837]
 [0.868]
 [1.083]
 [1.083]
 [0.932]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  52.35547079524336
printing an ep nov before normalisation:  89.6070824802915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actions average: 
K:  0  action  0 :  tensor([    0.9954,     0.0021,     0.0004,     0.0001,     0.0020],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.8929,     0.0004,     0.0002,     0.1063],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0015,     0.9320,     0.0432,     0.0234],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0022,     0.0001,     0.0241,     0.8472,     0.1265],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0081, 0.0584, 0.0370, 0.2457, 0.6508], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[71.3  ]
 [70.356]
 [68.033]
 [71.3  ]
 [72.586]] [[1.088]
 [1.066]
 [1.011]
 [1.088]
 [1.119]]
printing an ep nov before normalisation:  48.211299093877145
actions average: 
K:  1  action  0 :  tensor([    0.9987,     0.0003,     0.0000,     0.0003,     0.0007],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0196,     0.9585,     0.0008,     0.0000,     0.0211],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0038,     0.9322,     0.0205,     0.0435],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0026, 0.0009, 0.0154, 0.8389, 0.1422], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0018, 0.1596, 0.0889, 0.0856, 0.6640], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[71.014]
 [71.014]
 [71.014]
 [71.014]
 [71.014]] [[1.322]
 [1.322]
 [1.322]
 [1.322]
 [1.322]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  58.07594636831191
using explorer policy with actor:  1
siam score:  -0.8876163
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using another actor
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[70.076]
 [78.295]
 [70.076]
 [70.076]
 [70.076]] [[1.101]
 [1.336]
 [1.101]
 [1.101]
 [1.101]]
printing an ep nov before normalisation:  85.87488656642044
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  33.25184011445516
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  75.71548604508126
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  26.113039920803004
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.8842656
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.012711429836826937
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  54.369874939599086
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  84.6799183258404
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  43.01736599406955
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.796]
 [20.871]
 [25.801]
 [18.886]
 [17.282]] [[0.581]
 [0.779]
 [0.971]
 [0.702]
 [0.639]]
line 256 mcts: sample exp_bonus 74.79615536188436
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.8832068
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[45.325]
 [45.325]
 [45.325]
 [45.325]
 [45.325]] [[1.365]
 [1.365]
 [1.365]
 [1.365]
 [1.365]]
printing an ep nov before normalisation:  39.114582386952264
printing an ep nov before normalisation:  53.30203056335449
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[50.43]
 [50.43]
 [50.43]
 [53.2 ]
 [50.43]] [[0.259]
 [0.259]
 [0.259]
 [0.287]
 [0.259]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.003]
 [0.005]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.004]
 [0.004]
 [0.004]
 [0.003]
 [0.005]]
printing an ep nov before normalisation:  40.862154960632324
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  37.757511138916016
siam score:  -0.89425004
printing an ep nov before normalisation:  51.07030551472376
printing an ep nov before normalisation:  26.77800953031202
actions average: 
K:  3  action  0 :  tensor([0.9883, 0.0011, 0.0029, 0.0035, 0.0041], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9974,     0.0002,     0.0009,     0.0015],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0028,     0.9926,     0.0017,     0.0028],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0001,     0.0001,     0.0072,     0.8885,     0.1041],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0016, 0.0529, 0.0052, 0.1289, 0.8114], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  53.01872656342077
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9689,     0.0203,     0.0003,     0.0004,     0.0101],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.8925,     0.0013,     0.0001,     0.1059],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0063,     0.9148,     0.0252,     0.0537],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0000,     0.0174,     0.0087,     0.9053,     0.0686],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0012, 0.0039, 0.0591, 0.1962, 0.7396], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  35.53413750554769
printing an ep nov before normalisation:  50.461870165006246
printing an ep nov before normalisation:  32.66387452428688
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  51.8748082465624
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  71.24318384213353
actions average: 
K:  0  action  0 :  tensor([    0.9991,     0.0001,     0.0000,     0.0000,     0.0009],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9987,     0.0001,     0.0002,     0.0010],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0035, 0.0030, 0.9456, 0.0212, 0.0266], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0054,     0.0003,     0.0295,     0.8319,     0.1329],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0452, 0.0017, 0.0423, 0.2792, 0.6316], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  36.80224011690729
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.468395437250926
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.013]
 [0.01 ]
 [0.022]
 [0.022]] [[38.048]
 [29.233]
 [34.529]
 [41.42 ]
 [38.954]] [[1.02 ]
 [0.546]
 [0.824]
 [1.201]
 [1.071]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  28.399002585706747
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
printing an ep nov before normalisation:  35.67233430735169
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
siam score:  -0.9065644
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.06671943976210959, 0.06671943976210959, 0.06671943976210959, 0.2666138935712237, 0.06671943976210959, 0.466508347380338]
actor:  1 policy actor:  1  step number:  57 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.001]
 [0.002]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.001]
 [0.002]
 [0.002]
 [0.002]]
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.001]
 [0.002]
 [0.002]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.002]
 [0.001]
 [0.002]
 [0.002]
 [0.002]]
printing an ep nov before normalisation:  43.05429713618606
printing an ep nov before normalisation:  33.70940994621921
printing an ep nov before normalisation:  56.19244629453676
printing an ep nov before normalisation:  89.49793892680876
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[45.351]
 [45.351]
 [45.351]
 [45.351]
 [45.351]] [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  41.2146587396337
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[38.46]
 [38.46]
 [38.46]
 [38.46]
 [38.46]] [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]]
printing an ep nov before normalisation:  49.78924494470668
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.05498386022310342
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  53.837693076692496
printing an ep nov before normalisation:  23.797875456115328
printing an ep nov before normalisation:  30.36323070526123
printing an ep nov before normalisation:  24.286019328731733
printing an ep nov before normalisation:  19.644204643096735
printing an ep nov before normalisation:  33.65832805633545
using explorer policy with actor:  0
printing an ep nov before normalisation:  41.50599146156018
printing an ep nov before normalisation:  38.76015441882947
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.008]
 [0.006]
 [0.006]] [[54.374]
 [54.374]
 [55.906]
 [52.649]
 [54.374]] [[1.904]
 [1.904]
 [2.008]
 [1.79 ]
 [1.904]]
printing an ep nov before normalisation:  49.54864085867056
printing an ep nov before normalisation:  50.38554668426514
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.005]
 [0.003]] [[36.132]
 [36.132]
 [36.132]
 [42.616]
 [36.132]] [[0.003]
 [0.003]
 [0.003]
 [0.005]
 [0.003]]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.9000485
printing an ep nov before normalisation:  47.415782182671244
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
actions average: 
K:  1  action  0 :  tensor([    0.9987,     0.0000,     0.0000,     0.0001,     0.0012],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0253,     0.9585,     0.0016,     0.0001,     0.0145],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0030,     0.9929,     0.0002,     0.0039],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0181,     0.0001,     0.0139,     0.8383,     0.1295],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0025, 0.0826, 0.0168, 0.2935, 0.6046], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  25.37494497789119
printing an ep nov before normalisation:  66.10804960525601
printing an ep nov before normalisation:  80.1522383484545
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.012]
 [0.012]
 [0.012]
 [0.012]] [[32.683]
 [32.683]
 [32.683]
 [32.683]
 [32.683]] [[1.413]
 [1.413]
 [1.413]
 [1.413]
 [1.413]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  67.23243482117044
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  33.17987619498567
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  62.06093715529738
printing an ep nov before normalisation:  40.54584680903084
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  32.0395487437213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.004]
 [0.005]
 [0.006]
 [0.005]] [[31.511]
 [41.374]
 [42.044]
 [37.412]
 [33.999]] [[0.163]
 [0.271]
 [0.279]
 [0.228]
 [0.19 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
line 256 mcts: sample exp_bonus 49.174040314002596
printing an ep nov before normalisation:  35.91860150311757
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  57.657380857107476
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.009]
 [0.011]
 [0.009]] [[32.361]
 [16.973]
 [18.317]
 [25.306]
 [18.503]] [[0.664]
 [0.233]
 [0.271]
 [0.468]
 [0.276]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.9121673
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.9147102
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.011]
 [0.014]
 [0.022]
 [0.013]] [[26.353]
 [22.715]
 [33.53 ]
 [35.048]
 [26.353]] [[0.744]
 [0.583]
 [1.061]
 [1.135]
 [0.744]]
siam score:  -0.91569
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[55.147]
 [55.147]
 [55.147]
 [59.866]
 [57.357]] [[1.105]
 [1.105]
 [1.105]
 [1.237]
 [1.167]]
actions average: 
K:  0  action  0 :  tensor([    0.9841,     0.0012,     0.0005,     0.0004,     0.0137],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9495,     0.0006,     0.0001,     0.0497],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0225, 0.0190, 0.8346, 0.0704, 0.0534], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0015, 0.0010, 0.0169, 0.8041, 0.1764], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0490, 0.0789, 0.0765, 0.1774, 0.6182], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  61.29393287499001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.024]
 [0.023]
 [0.023]
 [0.023]
 [0.023]] [[54.051]
 [53.779]
 [53.779]
 [51.155]
 [53.779]] [[1.887]
 [1.874]
 [1.874]
 [1.753]
 [1.874]]
printing an ep nov before normalisation:  52.64566695620749
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  46.1609989103138
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  26.932060718536377
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[42.879]
 [32.524]
 [32.524]
 [32.524]
 [32.524]] [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]]
printing an ep nov before normalisation:  55.52153722848288
printing an ep nov before normalisation:  52.97974109649658
printing an ep nov before normalisation:  40.73772539299233
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  39.66128985465525
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.009]
 [0.01 ]
 [0.01 ]
 [0.011]] [[64.461]
 [70.502]
 [61.215]
 [58.833]
 [60.502]] [[1.017]
 [1.15 ]
 [0.949]
 [0.896]
 [0.934]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
line 256 mcts: sample exp_bonus 58.162811338001916
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.011]
 [0.011]
 [0.011]
 [0.011]] [[40.081]
 [40.081]
 [40.081]
 [49.821]
 [40.081]] [[1.302]
 [1.302]
 [1.302]
 [1.798]
 [1.302]]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.009]] [[63.919]
 [63.919]
 [63.919]
 [63.919]
 [63.919]] [[1.989]
 [1.989]
 [1.989]
 [1.989]
 [1.989]]
printing an ep nov before normalisation:  50.20994545224142
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.283295081137304
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  67.47665030373263
printing an ep nov before normalisation:  43.602842015284615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  86.41945005261807
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  45.40867306588294
line 256 mcts: sample exp_bonus 0.0
line 256 mcts: sample exp_bonus 57.15692434812317
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  61.449527965040424
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[9.032]
 [5.142]
 [5.398]
 [3.999]
 [5.55 ]] [[0.218]
 [0.124]
 [0.131]
 [0.097]
 [0.134]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  49.77496372976724
printing an ep nov before normalisation:  56.92661808618264
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.013]
 [0.013]
 [0.015]
 [0.013]] [[41.539]
 [40.771]
 [40.771]
 [40.765]
 [43.266]] [[1.533]
 [1.481]
 [1.481]
 [1.482]
 [1.649]]
printing an ep nov before normalisation:  62.39860996733481
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  71.79312010898411
siam score:  -0.9231598
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[42.88 ]
 [33.905]
 [30.139]
 [45.297]
 [35.371]] [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]]
printing an ep nov before normalisation:  50.432980966113
printing an ep nov before normalisation:  55.218967902444575
printing an ep nov before normalisation:  38.03263779125409
actions average: 
K:  4  action  0 :  tensor([    0.9919,     0.0008,     0.0008,     0.0017,     0.0048],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0008,     0.9284,     0.0080,     0.0002,     0.0627],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9150,     0.0599,     0.0250],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0020,     0.0002,     0.0295,     0.8142,     0.1541],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0323, 0.1125, 0.0771, 0.2257, 0.5524], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  29.00535142395945
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.011]
 [0.009]
 [0.009]
 [0.01 ]] [[51.882]
 [38.421]
 [51.416]
 [45.516]
 [47.074]] [[1.221]
 [0.618]
 [1.201]
 [0.935]
 [1.006]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.011]
 [0.013]
 [0.013]
 [0.011]] [[53.333]
 [41.005]
 [42.347]
 [49.842]
 [41.005]] [[1.654]
 [0.945]
 [1.025]
 [1.46 ]
 [0.945]]
actions average: 
K:  2  action  0 :  tensor([    0.9667,     0.0292,     0.0001,     0.0008,     0.0032],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9754,     0.0001,     0.0002,     0.0242],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9438,     0.0457,     0.0104],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0042,     0.0017,     0.9150,     0.0790],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0010, 0.1548, 0.0700, 0.2075, 0.5667], grad_fn=<DivBackward0>)
siam score:  -0.92030066
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.009]
 [0.01 ]
 [0.009]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.009]
 [0.009]
 [0.009]
 [0.01 ]
 [0.009]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  67.70521854935666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  68.91944622216532
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  52.06530211803915
printing an ep nov before normalisation:  59.61206463251812
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  47.04632520866577
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.9208821
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  56.74900082620053
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.009]
 [0.009]
 [0.009]
 [0.01 ]] [[38.562]
 [35.485]
 [35.485]
 [35.485]
 [34.579]] [[1.577]
 [1.354]
 [1.354]
 [1.354]
 [1.29 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  97.95303169571706
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.009]
 [0.01 ]
 [0.009]
 [0.01 ]] [[44.8  ]
 [43.701]
 [39.706]
 [46.467]
 [45.203]] [[1.534]
 [1.461]
 [1.203]
 [1.64 ]
 [1.559]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  52.61478652457245
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.007]
 [0.008]
 [0.008]
 [0.008]] [[58.469]
 [51.982]
 [52.305]
 [59.381]
 [59.073]] [[1.681]
 [1.356]
 [1.374]
 [1.727]
 [1.711]]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.01 ]
 [0.011]
 [0.01 ]
 [0.009]] [[57.823]
 [58.261]
 [60.195]
 [57.484]
 [57.1  ]] [[1.891]
 [1.914]
 [2.011]
 [1.875]
 [1.856]]
printing an ep nov before normalisation:  51.54585202814887
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  56.55987268576103
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
from probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
printing an ep nov before normalisation:  22.316429615020752
printing an ep nov before normalisation:  57.99540162718357
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.009]] [[71.73]
 [71.73]
 [71.73]
 [71.73]
 [71.73]] [[2.009]
 [2.009]
 [2.009]
 [2.009]
 [2.009]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.013]
 [0.009]
 [0.008]
 [0.013]] [[34.233]
 [37.068]
 [38.471]
 [47.348]
 [37.068]] [[0.815]
 [0.953]
 [1.016]
 [1.445]
 [0.953]]
printing an ep nov before normalisation:  53.1088716017814
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
from probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  5.5011366839607945e-06
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  47.81031880897159
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.007]
 [0.006]
 [0.006]] [[38.462]
 [35.915]
 [32.341]
 [39.419]
 [38.053]] [[1.027]
 [0.899]
 [0.719]
 [1.076]
 [1.007]]
printing an ep nov before normalisation:  33.01784479310323
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
siam score:  -0.91340137
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.01 ]
 [0.009]
 [0.01 ]
 [0.01 ]] [[40.771]
 [37.744]
 [36.884]
 [37.744]
 [37.744]] [[1.315]
 [1.156]
 [1.109]
 [1.156]
 [1.156]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
actions average: 
K:  2  action  0 :  tensor([0.9482, 0.0039, 0.0063, 0.0374, 0.0042], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0207,     0.9312,     0.0029,     0.0007,     0.0445],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9908,     0.0048,     0.0044],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0020,     0.0007,     0.0217,     0.9077,     0.0680],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0044, 0.0851, 0.0532, 0.2901, 0.5672], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.008]
 [0.008]
 [0.008]
 [0.007]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.007]
 [0.008]
 [0.008]
 [0.008]
 [0.007]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  76.77861531658088
siam score:  -0.9185669
line 256 mcts: sample exp_bonus 40.79785240635842
printing an ep nov before normalisation:  41.63701249313003
from probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  33.20744037628174
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[31.691]
 [31.691]
 [31.691]
 [31.691]
 [31.691]] [[1.155]
 [1.155]
 [1.155]
 [1.155]
 [1.155]]
printing an ep nov before normalisation:  55.06172312074582
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  30.96175853469034
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.008]
 [0.009]
 [0.008]
 [0.008]] [[31.165]
 [26.642]
 [28.963]
 [30.02 ]
 [26.642]] [[0.939]
 [0.706]
 [0.825]
 [0.879]
 [0.706]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  42.27839469909668
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  17.919001092985564
using explorer policy with actor:  1
from probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  90.26436782052087
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  60.395508148085625
printing an ep nov before normalisation:  60.53231471588894
printing an ep nov before normalisation:  45.306518505779685
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  41.42991941241923
from probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.630238325332265
printing an ep nov before normalisation:  43.528996573554146
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.006]
 [0.007]
 [0.007]] [[48.834]
 [48.834]
 [52.285]
 [48.834]
 [48.834]] [[1.002]
 [1.002]
 [1.135]
 [1.002]
 [1.002]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  49.387615249656456
printing an ep nov before normalisation:  65.27193996535067
printing an ep nov before normalisation:  60.51162371503995
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.344578729092415
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.005]
 [0.006]
 [0.005]
 [0.005]] [[39.771]
 [38.148]
 [33.64 ]
 [41.904]
 [41.512]] [[1.719]
 [1.602]
 [1.277]
 [1.873]
 [1.845]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  36.68560704281784
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.9034474
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
printing an ep nov before normalisation:  59.263511401256956
printing an ep nov before normalisation:  37.766889108142905
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  60.77780947463919
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[54.19]
 [54.19]
 [54.19]
 [54.19]
 [56.51]] [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.004]
 [0.005]] [[63.258]
 [58.37 ]
 [63.258]
 [63.037]
 [63.258]] [[1.839]
 [1.644]
 [1.839]
 [1.83 ]
 [1.839]]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.005]
 [0.004]
 [0.004]
 [0.004]] [[44.363]
 [49.486]
 [44.363]
 [44.363]
 [44.363]] [[0.699]
 [0.852]
 [0.699]
 [0.699]
 [0.699]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.020206633093046
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  54.94691793072004
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[32.338]
 [32.338]
 [32.338]
 [32.338]
 [32.338]] [[1.886]
 [1.886]
 [1.886]
 [1.886]
 [1.886]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  45.76917210597378
using another actor
printing an ep nov before normalisation:  68.87495623553461
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  40.99843481460831
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  63.486138141997536
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  45.06078133661275
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  51.28567688321215
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
line 256 mcts: sample exp_bonus 60.35298289261718
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  34.194602035025426
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  47.134454214860284
siam score:  -0.90824735
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[50.806]
 [45.1  ]
 [45.1  ]
 [54.819]
 [45.1  ]] [[1.156]
 [0.946]
 [0.946]
 [1.305]
 [0.946]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.009]
 [0.007]
 [0.007]
 [0.007]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.007]
 [0.009]
 [0.007]
 [0.007]
 [0.007]]
siam score:  -0.9044615
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
line 256 mcts: sample exp_bonus 46.034577752454936
from probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.9023541
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.006]
 [0.006]
 [0.006]] [[46.411]
 [43.742]
 [40.021]
 [45.271]
 [43.858]] [[1.515]
 [1.348]
 [1.116]
 [1.444]
 [1.356]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  61.067779213793756
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.89489424
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  34.01970314288191
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.8943148
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[43.396]
 [41.689]
 [41.689]
 [41.689]
 [41.689]] [[1.323]
 [1.248]
 [1.248]
 [1.248]
 [1.248]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
printing an ep nov before normalisation:  55.12525117794365
printing an ep nov before normalisation:  47.49781593951755
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  40.923781394958496
printing an ep nov before normalisation:  58.53510272809098
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  50.04338260235015
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  59.82137544669301
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  75.87337879152264
printing an ep nov before normalisation:  44.55339411223438
printing an ep nov before normalisation:  44.92279600006989
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.004]
 [0.005]
 [0.004]
 [0.004]] [[47.511]
 [ 0.   ]
 [42.708]
 [ 0.   ]
 [41.396]] [[ 0.619]
 [-0.307]
 [ 0.526]
 [-0.307]
 [ 0.499]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
line 256 mcts: sample exp_bonus 40.79244704676964
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  36.507408618927
from probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[38.516]
 [38.516]
 [38.516]
 [38.516]
 [38.516]] [[77.037]
 [77.037]
 [77.037]
 [77.037]
 [77.037]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  58.876015928919394
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  74.14113568524203
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[33.879]
 [33.879]
 [33.879]
 [33.879]
 [33.879]] [[0.153]
 [0.153]
 [0.153]
 [0.153]
 [0.153]]
siam score:  -0.8915012
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.14017440711707
from probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  26.658716201782227
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  44.819019194107725
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  54.284595102559145
using another actor
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.002]
 [0.002]
 [0.003]
 [0.002]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.002]
 [0.002]
 [0.003]
 [0.002]]
printing an ep nov before normalisation:  47.811314312280956
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  54.63472119696361
printing an ep nov before normalisation:  92.5718158653232
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.004]
 [0.005]] [[59.045]
 [59.045]
 [59.045]
 [60.708]
 [59.045]] [[1.08 ]
 [1.08 ]
 [1.08 ]
 [1.118]
 [1.08 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
printing an ep nov before normalisation:  50.073140366553744
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
actions average: 
K:  0  action  0 :  tensor([    0.9681,     0.0002,     0.0001,     0.0133,     0.0183],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9300,     0.0008,     0.0032,     0.0657],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9510,     0.0197,     0.0293],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0002,     0.0028,     0.8899,     0.1069],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0694, 0.0966, 0.0412, 0.1403, 0.6525], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  75.9971179172976
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  60.12955193150393
printing an ep nov before normalisation:  32.85834550857544
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  53.51700120256223
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.8831078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.68488158968184
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.006]
 [0.005]
 [0.006]] [[38.474]
 [38.474]
 [38.474]
 [46.051]
 [38.474]] [[1.188]
 [1.188]
 [1.188]
 [1.546]
 [1.188]]
Printing some Q and Qe and total Qs values:  [[0.004]
 [0.005]
 [0.004]
 [0.004]
 [0.003]] [[30.615]
 [34.624]
 [30.615]
 [30.615]
 [40.271]] [[0.985]
 [1.213]
 [0.985]
 [0.985]
 [1.533]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.002]
 [0.003]
 [0.003]
 [0.003]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.003]
 [0.002]
 [0.003]
 [0.003]
 [0.003]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  73.72183010692815
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.004]
 [0.004]
 [0.005]
 [0.004]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.005]
 [0.004]
 [0.004]
 [0.005]
 [0.004]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  0.1232550226325202
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  43.862394468905464
siam score:  -0.8720703
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  62.90172360260993
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
printing an ep nov before normalisation:  50.08101156289118
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  44.95118168860362
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[52.068]
 [78.935]
 [52.068]
 [52.068]
 [52.068]] [[0.907]
 [1.566]
 [0.907]
 [0.907]
 [0.907]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  41.352644019016154
printing an ep nov before normalisation:  28.820571899414062
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  37.18229055404663
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9991,     0.0001,     0.0001,     0.0002,     0.0006],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9652,     0.0009,     0.0003,     0.0335],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9642,     0.0231,     0.0127],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0013,     0.0001,     0.0015,     0.8647,     0.1325],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0575, 0.0998, 0.0519, 0.2276, 0.5631], grad_fn=<DivBackward0>)
actions average: 
K:  1  action  0 :  tensor([    0.9857,     0.0046,     0.0017,     0.0005,     0.0074],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9575,     0.0006,     0.0002,     0.0416],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0011,     0.9691,     0.0025,     0.0272],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0003,     0.0004,     0.0187,     0.8893,     0.0914],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0013, 0.0947, 0.0492, 0.1929, 0.6619], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  66.17507045638803
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.236222406307576
printing an ep nov before normalisation:  41.14811269393322
printing an ep nov before normalisation:  47.284322252891315
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  51.45250203702096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.012]
 [0.006]
 [0.007]
 [0.007]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.006]
 [0.012]
 [0.006]
 [0.007]
 [0.007]]
siam score:  -0.8998881
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[37.411]
 [48.303]
 [37.411]
 [37.411]
 [37.411]] [[0.937]
 [1.34 ]
 [0.937]
 [0.937]
 [0.937]]
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.011]
 [0.011]
 [0.009]
 [0.012]] [[74.794]
 [79.304]
 [56.153]
 [68.056]
 [77.696]] [[0.984]
 [1.066]
 [0.639]
 [0.857]
 [1.037]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using another actor
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  104.25855017686001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
printing an ep nov before normalisation:  48.951154947280884
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.007]
 [0.007]
 [0.005]
 [0.005]] [[48.563]
 [47.869]
 [47.47 ]
 [58.416]
 [56.927]] [[1.014]
 [0.993]
 [0.977]
 [1.414]
 [1.354]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  30.691170692443848
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  51.518795501077655
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.014]
 [0.014]
 [0.01 ]
 [0.009]] [[53.81 ]
 [59.649]
 [52.464]
 [57.619]
 [55.847]] [[0.85 ]
 [1.014]
 [0.817]
 [0.954]
 [0.905]]
siam score:  -0.8933617
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  86.83214275085913
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
printing an ep nov before normalisation:  56.831274885678305
printing an ep nov before normalisation:  52.191786604887675
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.01 ]
 [0.01 ]
 [0.008]
 [0.007]] [[52.054]
 [54.276]
 [54.276]
 [52.641]
 [55.091]] [[1.687]
 [1.763]
 [1.763]
 [1.707]
 [1.786]]
printing an ep nov before normalisation:  76.70838374439082
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  73.92301867613452
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  90.21452865247439
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  30.446791648864746
siam score:  -0.90217817
from probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  35.10939598083496
using explorer policy with actor:  0
printing an ep nov before normalisation:  48.582058330331925
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.007]
 [0.01 ]
 [0.007]
 [0.008]] [[38.108]
 [36.133]
 [29.779]
 [36.416]
 [34.294]] [[0.009]
 [0.007]
 [0.01 ]
 [0.007]
 [0.008]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
actions average: 
K:  0  action  0 :  tensor([    0.9998,     0.0000,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0020,     0.8992,     0.0009,     0.0003,     0.0976],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0013,     0.9688,     0.0215,     0.0083],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0007,     0.0002,     0.0107,     0.9130,     0.0754],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0038, 0.1429, 0.0061, 0.2314, 0.6158], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  64.50987840681505
printing an ep nov before normalisation:  61.37174445761474
using explorer policy with actor:  1
siam score:  -0.912101
line 256 mcts: sample exp_bonus 63.84256774924031
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.77567815085747
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  60.51895581420692
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.01 ]
 [0.009]
 [0.01 ]
 [0.01 ]] [[53.659]
 [49.849]
 [49.381]
 [49.849]
 [49.849]] [[1.411]
 [1.252]
 [1.232]
 [1.252]
 [1.252]]
printing an ep nov before normalisation:  63.26581064550457
UNIT TEST: sample policy line 217 mcts : [0.231 0.385 0.282 0.026 0.077]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  48.73796548823517
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.9147838
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  33.837057298333434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  48.8479553305385
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  66.4258274447901
siam score:  -0.9166933
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  78.56636558013211
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
siam score:  -0.92030615
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  25.61921605987996
using explorer policy with actor:  0
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.009]] [[54.721]
 [43.476]
 [70.473]
 [54.721]
 [54.721]] [[0.841]
 [0.492]
 [1.332]
 [0.841]
 [0.841]]
printing an ep nov before normalisation:  80.9435355195285
using explorer policy with actor:  0
printing an ep nov before normalisation:  59.79140770954186
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.593661308288574
printing an ep nov before normalisation:  49.675274752679094
line 256 mcts: sample exp_bonus 49.730158967706714
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.011]
 [0.012]
 [0.012]
 [0.012]] [[56.433]
 [58.501]
 [56.433]
 [56.433]
 [56.433]] [[1.144]
 [1.207]
 [1.144]
 [1.144]
 [1.144]]
printing an ep nov before normalisation:  69.79216766015105
using explorer policy with actor:  1
printing an ep nov before normalisation:  84.66043949543298
printing an ep nov before normalisation:  57.03314269338041
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  53.06714527001301
Printing some Q and Qe and total Qs values:  [[0.   ]
 [0.009]
 [0.01 ]
 [0.007]
 [0.009]] [[20.708]
 [40.688]
 [37.878]
 [43.659]
 [36.394]] [[0.   ]
 [0.009]
 [0.01 ]
 [0.007]
 [0.009]]
printing an ep nov before normalisation:  48.00410423440279
using explorer policy with actor:  0
printing an ep nov before normalisation:  34.74797001375686
using explorer policy with actor:  0
printing an ep nov before normalisation:  34.59856418396984
printing an ep nov before normalisation:  35.98877496618972
printing an ep nov before normalisation:  43.193817238413494
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.008]
 [0.007]
 [0.007]
 [0.007]] [[36.204]
 [40.104]
 [42.178]
 [39.02 ]
 [36.78 ]] [[0.006]
 [0.008]
 [0.007]
 [0.007]
 [0.007]]
printing an ep nov before normalisation:  32.828158122673734
printing an ep nov before normalisation:  52.49859232454459
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.006]
 [0.006]
 [0.007]
 [0.006]
 [0.006]] [[51.509]
 [55.758]
 [48.525]
 [52.856]
 [57.511]] [[0.006]
 [0.006]
 [0.007]
 [0.006]
 [0.006]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  31.030335426330566
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  53.7915823910151
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
printing an ep nov before normalisation:  55.50400488517674
printing an ep nov before normalisation:  52.9430051894867
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.0714753518132806, 0.0714753518132806, 0.0714753518132806, 0.21426232409335966, 0.0714753518132806, 0.4998362686535179]
actor:  0 policy actor:  1  step number:  55 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0021 0.0 0.0021
probs:  [0.07147536490485612, 0.07147536490485612, 0.07147536490485612, 0.21426231754757197, 0.07147536490485612, 0.4998362228330037]
maxi score, test score, baseline:  0.0021 0.0 0.0021
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.011]
 [0.009]
 [0.008]
 [0.011]] [[26.935]
 [21.014]
 [36.916]
 [37.713]
 [26.935]] [[0.011]
 [0.011]
 [0.009]
 [0.008]
 [0.011]]
printing an ep nov before normalisation:  26.84885310299529
actions average: 
K:  4  action  0 :  tensor([    0.9836,     0.0001,     0.0004,     0.0142,     0.0017],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0247,     0.8996,     0.0175,     0.0005,     0.0578],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0005,     0.9571,     0.0287,     0.0136],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0002,     0.0001,     0.0399,     0.8506,     0.1092],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0007, 0.1315, 0.0837, 0.1716, 0.6125], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0021 0.0 0.0021
probs:  [0.07147536490485612, 0.07147536490485612, 0.07147536490485612, 0.21426231754757197, 0.07147536490485612, 0.4998362228330037]
maxi score, test score, baseline:  0.0021 0.0 0.0021
probs:  [0.07147536490485612, 0.07147536490485612, 0.07147536490485612, 0.21426231754757197, 0.07147536490485612, 0.4998362228330037]
printing an ep nov before normalisation:  45.41248483303155
actions average: 
K:  2  action  0 :  tensor([    0.9978,     0.0000,     0.0000,     0.0011,     0.0011],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0059, 0.9266, 0.0014, 0.0011, 0.0650], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0007,     0.9982,     0.0004,     0.0007],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0001,     0.0024,     0.9335,     0.0637],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0148, 0.0400, 0.0066, 0.0763, 0.8623], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.011]
 [0.009]
 [0.009]
 [0.01 ]] [[46.237]
 [42.242]
 [39.763]
 [39.508]
 [36.654]] [[1.458]
 [1.2  ]
 [1.037]
 [1.02 ]
 [0.836]]
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.01 ]] [[28.356]
 [29.586]
 [26.388]
 [32.536]
 [31.318]] [[0.011]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.01 ]]
printing an ep nov before normalisation:  30.66313690683765
maxi score, test score, baseline:  0.0021 0.0 0.0021
probs:  [0.07147536490485612, 0.07147536490485612, 0.07147536490485612, 0.21426231754757197, 0.07147536490485612, 0.4998362228330037]
printing an ep nov before normalisation:  33.06518591355568
maxi score, test score, baseline:  0.0021 0.0 0.0021
probs:  [0.07147536490485612, 0.07147536490485612, 0.07147536490485612, 0.21426231754757197, 0.07147536490485612, 0.4998362228330037]
printing an ep nov before normalisation:  73.21755182873267
printing an ep nov before normalisation:  27.44816483242403
using explorer policy with actor:  0
actor:  0 policy actor:  1  step number:  118 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  58.74878474573351
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  95.62353434383735
printing an ep nov before normalisation:  95.50273694427138
printing an ep nov before normalisation:  56.69739910411972
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  35.95964142063249
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
actions average: 
K:  3  action  0 :  tensor([    0.9710,     0.0003,     0.0002,     0.0250,     0.0034],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0279,     0.8757,     0.0205,     0.0002,     0.0757],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0433, 0.0017, 0.9176, 0.0332, 0.0042], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0006,     0.0023,     0.0168,     0.9157,     0.0647],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0246, 0.0833, 0.0048, 0.1536, 0.7338], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  60.54407088006437
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  55.19905993924476
printing an ep nov before normalisation:  41.224511976760574
printing an ep nov before normalisation:  23.05692444974909
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.009]
 [0.007]
 [0.007]] [[42.366]
 [42.366]
 [44.565]
 [42.366]
 [42.366]] [[0.007]
 [0.007]
 [0.009]
 [0.007]
 [0.007]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  55.70140945735588
line 256 mcts: sample exp_bonus 37.985511525459536
printing an ep nov before normalisation:  55.41783128041208
printing an ep nov before normalisation:  0.05446910237793645
printing an ep nov before normalisation:  61.36524720176151
printing an ep nov before normalisation:  43.20297193010046
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  52.27425569275774
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  45.15598196975856
printing an ep nov before normalisation:  55.318870144269226
UNIT TEST: sample policy line 217 mcts : [0.821 0.051 0.051 0.026 0.051]
from probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  74.73185270653754
printing an ep nov before normalisation:  39.25330143034063
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
Printing some Q and Qe and total Qs values:  [[0.023]
 [0.03 ]
 [0.021]
 [0.023]
 [0.03 ]] [[50.99 ]
 [63.827]
 [49.678]
 [50.99 ]
 [50.695]] [[0.91 ]
 [1.534]
 [0.846]
 [0.91 ]
 [0.903]]
Printing some Q and Qe and total Qs values:  [[0.021]
 [0.019]
 [0.023]
 [0.028]
 [0.029]] [[35.62 ]
 [38.995]
 [35.609]
 [31.446]
 [32.743]] [[0.893]
 [1.048]
 [0.895]
 [0.707]
 [0.768]]
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.016]
 [0.014]
 [0.016]
 [0.016]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.018]
 [0.016]
 [0.014]
 [0.016]
 [0.016]]
printing an ep nov before normalisation:  32.70697314116862
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  35.95102071762085
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.02 ]
 [0.018]
 [0.017]
 [0.021]] [[37.694]
 [31.134]
 [37.694]
 [44.677]
 [41.978]] [[0.752]
 [0.446]
 [0.752]
 [1.079]
 [0.956]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
Printing some Q and Qe and total Qs values:  [[0.015]
 [0.015]
 [0.015]
 [0.015]
 [0.015]] [[41.55]
 [41.55]
 [41.55]
 [41.55]
 [41.55]] [[1.348]
 [1.348]
 [1.348]
 [1.348]
 [1.348]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  58.096671810246406
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
using explorer policy with actor:  1
siam score:  -0.9241118
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
printing an ep nov before normalisation:  57.941161017195654
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07147611633836504, 0.07147611633836504, 0.07147611633836504, 0.2142619418308175, 0.07147611633836504, 0.4998335928157224]
actor:  1 policy actor:  1  step number:  58 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  27.810027599334717
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  44.91071801881034
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  55.14896868586349
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  39.93448976593634
printing an ep nov before normalisation:  40.19644814341743
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.014]
 [0.016]
 [0.019]
 [0.016]
 [0.016]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.014]
 [0.016]
 [0.019]
 [0.016]
 [0.016]]
siam score:  -0.9321727
siam score:  -0.9325595
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  62.95562444439205
using another actor
siam score:  -0.9328853
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
siam score:  -0.9335472
siam score:  -0.93217707
printing an ep nov before normalisation:  44.8400863087597
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  65.4799248270699
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
siam score:  -0.9312985
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.016]
 [0.016]
 [0.015]
 [0.016]] [[40.102]
 [48.304]
 [48.304]
 [52.967]
 [48.304]] [[0.35 ]
 [0.468]
 [0.468]
 [0.535]
 [0.468]]
printing an ep nov before normalisation:  72.92241670076503
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  55.40172379817465
printing an ep nov before normalisation:  59.246819025012414
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.017]
 [0.02 ]
 [0.019]
 [0.018]] [[55.694]
 [49.98 ]
 [34.307]
 [47.936]
 [49.804]] [[1.485]
 [1.239]
 [0.564]
 [1.152]
 [1.232]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[0.0122],
        [0.0105],
        [0.0161],
        [0.0155],
        [0.1841],
        [0.0364],
        [0.0107],
        [0.0000],
        [0.0146],
        [0.0000]], dtype=torch.float64)
0.0 0.012193919931642738
0.0 0.010452128593336545
0.0 0.016138449439276954
0.0 0.015490163946652289
0.0 0.18406444452891677
0.0 0.036428192130967915
0.0 0.010663579504532509
0.0 0.0
0.0 0.01456969980167785
0.99 0.99
siam score:  -0.93387556
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  52.4952571884722
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.027]
 [0.029]
 [0.023]
 [0.029]] [[39.803]
 [32.247]
 [32.4  ]
 [44.421]
 [41.084]] [[1.242]
 [0.874]
 [0.885]
 [1.505]
 [1.337]]
maxi score, test score, baseline:  0.0041 0.1 0.1
using explorer policy with actor:  1
siam score:  -0.9325466
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
using another actor
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  42.52486998726012
line 256 mcts: sample exp_bonus 40.96291303949278
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.036]
 [0.036]
 [0.036]
 [0.059]
 [0.036]] [[33.615]
 [33.615]
 [33.615]
 [46.192]
 [33.615]] [[0.955]
 [0.955]
 [0.955]
 [1.527]
 [0.955]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.001]
 [0.015]
 [0.015]
 [0.016]] [[49.695]
 [57.191]
 [60.887]
 [60.513]
 [63.181]] [[1.109]
 [1.403]
 [1.571]
 [1.555]
 [1.666]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
siam score:  -0.93374056
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  38.73532349049914
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  46.521336953675224
maxi score, test score, baseline:  0.0041 0.1 0.1
line 256 mcts: sample exp_bonus 46.63569472810687
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.021]
 [0.021]
 [0.021]
 [0.021]
 [0.021]] [[48.052]
 [62.061]
 [48.052]
 [48.052]
 [48.052]] [[1.377]
 [2.021]
 [1.377]
 [1.377]
 [1.377]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
using explorer policy with actor:  1
printing an ep nov before normalisation:  57.1904182434082
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  36.30800035071704
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  28.55087078980768
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.011]
 [0.013]
 [0.011]
 [0.011]] [[63.055]
 [46.251]
 [41.576]
 [46.251]
 [46.251]] [[1.145]
 [0.682]
 [0.555]
 [0.682]
 [0.682]]
printing an ep nov before normalisation:  52.01160248282788
printing an ep nov before normalisation:  36.752777262411485
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  47.933175033704686
using explorer policy with actor:  1
using explorer policy with actor:  0
printing an ep nov before normalisation:  44.04640197753906
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
siam score:  -0.9291387
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.017]
 [0.017]
 [0.017]
 [0.017]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.017]
 [0.017]
 [0.017]
 [0.017]
 [0.017]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  37.49929684651563
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
actions average: 
K:  3  action  0 :  tensor([    0.9955,     0.0000,     0.0003,     0.0005,     0.0037],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0028,     0.9763,     0.0003,     0.0002,     0.0203],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9710,     0.0198,     0.0091],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0057,     0.0001,     0.0232,     0.8866,     0.0844],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0687, 0.0529, 0.0395, 0.2177, 0.6213], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  72.17769257071245
printing an ep nov before normalisation:  46.25730300177131
printing an ep nov before normalisation:  37.89238920542074
maxi score, test score, baseline:  0.0041 0.1 0.1
using explorer policy with actor:  1
printing an ep nov before normalisation:  56.74017010723703
printing an ep nov before normalisation:  62.86456512624344
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.027]
 [0.029]
 [0.013]
 [0.028]
 [0.027]] [[58.389]
 [57.862]
 [63.123]
 [58.492]
 [58.803]] [[1.708]
 [1.688]
 [1.899]
 [1.714]
 [1.726]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  24.42298483949473
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.017]
 [0.015]
 [0.013]
 [0.015]] [[61.787]
 [63.296]
 [70.421]
 [69.598]
 [63.454]] [[0.018]
 [0.017]
 [0.015]
 [0.013]
 [0.015]]
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.014]
 [0.013]
 [0.014]
 [0.015]] [[40.645]
 [44.704]
 [40.032]
 [35.155]
 [30.991]] [[0.011]
 [0.014]
 [0.013]
 [0.014]
 [0.015]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  48.435285704908125
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
siam score:  -0.92978513
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  53.70862638577783
using explorer policy with actor:  1
printing an ep nov before normalisation:  73.13609256302342
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  77.41504761587044
printing an ep nov before normalisation:  72.08422364886846
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
line 256 mcts: sample exp_bonus 49.334263426505935
Printing some Q and Qe and total Qs values:  [[0.02 ]
 [0.021]
 [0.019]
 [0.02 ]
 [0.02 ]] [[38.84 ]
 [36.045]
 [42.296]
 [44.107]
 [38.84 ]] [[1.357]
 [1.206]
 [1.544]
 [1.644]
 [1.357]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  52.290583206506874
printing an ep nov before normalisation:  42.15888153554067
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.02 ]
 [0.021]
 [0.022]
 [0.022]] [[41.407]
 [32.637]
 [40.057]
 [35.874]
 [35.846]] [[1.306]
 [0.836]
 [1.234]
 [1.011]
 [1.009]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  72.79417830801094
Printing some Q and Qe and total Qs values:  [[0.05 ]
 [0.039]
 [0.05 ]
 [0.055]
 [0.05 ]] [[30.55 ]
 [31.671]
 [30.55 ]
 [35.622]
 [30.55 ]] [[0.967]
 [1.029]
 [0.967]
 [1.298]
 [0.967]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  33.450343749049125
printing an ep nov before normalisation:  47.32177734375
printing an ep nov before normalisation:  34.88192821082821
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  68.28072469047487
printing an ep nov before normalisation:  29.948935652509554
Printing some Q and Qe and total Qs values:  [[0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]] [[32.855]
 [32.855]
 [32.855]
 [32.855]
 [32.855]] [[1.402]
 [1.402]
 [1.402]
 [1.402]
 [1.402]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  39.78529190334279
Printing some Q and Qe and total Qs values:  [[0.027]
 [0.025]
 [0.027]
 [0.027]
 [0.027]] [[28.029]
 [35.469]
 [28.029]
 [28.029]
 [28.029]] [[1.098]
 [1.382]
 [1.098]
 [1.098]
 [1.098]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.027]
 [0.025]
 [0.032]
 [0.023]
 [0.026]] [[39.866]
 [36.806]
 [28.606]
 [36.084]
 [39.016]] [[2.027]
 [1.807]
 [1.231]
 [1.753]
 [1.965]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
siam score:  -0.93068147
printing an ep nov before normalisation:  60.13632061271863
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  50.387910114593
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  55.95976567431949
printing an ep nov before normalisation:  40.679037984469346
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.017]
 [0.017]
 [0.017]
 [0.017]] [[37.701]
 [37.701]
 [37.701]
 [43.908]
 [37.701]] [[1.151]
 [1.151]
 [1.151]
 [1.518]
 [1.151]]
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.029]
 [0.019]
 [0.018]
 [0.018]] [[46.671]
 [45.804]
 [48.936]
 [46.16 ]
 [47.729]] [[1.287]
 [1.258]
 [1.388]
 [1.263]
 [1.333]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  43.735630078705725
siam score:  -0.92946714
printing an ep nov before normalisation:  34.757301807403564
printing an ep nov before normalisation:  0.0004960303707927476
maxi score, test score, baseline:  0.0041 0.1 0.1
line 256 mcts: sample exp_bonus 28.725825002295533
printing an ep nov before normalisation:  45.08415495821779
printing an ep nov before normalisation:  39.340646266937256
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
siam score:  -0.9317502
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  48.858812414711366
using explorer policy with actor:  1
printing an ep nov before normalisation:  50.99399663489025
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.023]
 [0.019]
 [0.017]
 [0.019]] [[33.353]
 [39.911]
 [33.353]
 [24.727]
 [33.353]] [[1.127]
 [1.535]
 [1.127]
 [0.595]
 [1.127]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  39.274042422079184
printing an ep nov before normalisation:  45.112654736138
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  0.024057204153677958
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  37.18522580132433
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  37.65574650894924
printing an ep nov before normalisation:  34.52503743732214
printing an ep nov before normalisation:  63.529296592424764
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  54.63589852911647
printing an ep nov before normalisation:  20.88690596320791
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  64.34884555219337
actor:  1 policy actor:  1  step number:  60 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  37.37552457357812
printing an ep nov before normalisation:  90.05859502590546
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  40.82783809596526
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  60.3884642541738
printing an ep nov before normalisation:  42.96872525479756
printing an ep nov before normalisation:  80.9637010565347
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
siam score:  -0.93656754
printing an ep nov before normalisation:  38.317688929710705
printing an ep nov before normalisation:  57.76714323502473
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
Printing some Q and Qe and total Qs values:  [[0.04]
 [0.04]
 [0.04]
 [0.04]
 [0.04]] [[41.093]
 [41.093]
 [41.093]
 [41.093]
 [41.093]] [[1.107]
 [1.107]
 [1.107]
 [1.107]
 [1.107]]
printing an ep nov before normalisation:  56.62718006574386
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  31.23046875
printing an ep nov before normalisation:  30.733715597463092
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
from probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  56.960319946883565
Printing some Q and Qe and total Qs values:  [[0.035]
 [0.04 ]
 [0.035]
 [0.035]
 [0.03 ]] [[44.107]
 [48.002]
 [44.107]
 [44.107]
 [39.125]] [[0.777]
 [0.89 ]
 [0.777]
 [0.777]
 [0.634]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  51.7530113049415
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  24.682202339172363
siam score:  -0.94644946
printing an ep nov before normalisation:  40.63098682188185
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
siam score:  -0.9462172
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
siam score:  -0.9472721
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
Printing some Q and Qe and total Qs values:  [[0.105]
 [0.073]
 [0.082]
 [0.073]
 [0.073]] [[35.794]
 [37.426]
 [46.436]
 [37.426]
 [37.426]] [[1.033]
 [1.084]
 [1.552]
 [1.084]
 [1.084]]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
UNIT TEST: sample policy line 217 mcts : [0.128 0.179 0.205 0.231 0.256]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  64.42346408220057
Printing some Q and Qe and total Qs values:  [[0.07 ]
 [0.08 ]
 [0.103]
 [0.088]
 [0.101]] [[72.43 ]
 [70.316]
 [48.22 ]
 [66.534]
 [68.289]] [[1.903]
 [1.859]
 [1.323]
 [1.772]
 [1.829]]
printing an ep nov before normalisation:  42.63922691345215
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.455]] [[43.628]
 [43.628]
 [43.628]
 [43.628]
 [43.628]] [[2.455]
 [2.455]
 [2.455]
 [2.455]
 [2.455]]
Printing some Q and Qe and total Qs values:  [[0.029]
 [0.029]
 [0.029]
 [0.029]
 [0.029]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.029]
 [0.029]
 [0.029]
 [0.029]
 [0.029]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
siam score:  -0.9537302
printing an ep nov before normalisation:  41.370836044520196
printing an ep nov before normalisation:  33.11428342756093
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  50.234359695483235
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
Printing some Q and Qe and total Qs values:  [[0.074]
 [0.076]
 [0.094]
 [0.072]
 [0.093]] [[52.119]
 [25.289]
 [37.592]
 [45.25 ]
 [34.773]] [[0.648]
 [0.218]
 [0.434]
 [0.535]
 [0.388]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
Printing some Q and Qe and total Qs values:  [[0.076]
 [0.076]
 [0.076]
 [0.076]
 [0.076]] [[41.763]
 [41.763]
 [48.043]
 [41.763]
 [41.763]] [[1.488]
 [1.488]
 [1.893]
 [1.488]
 [1.488]]
Printing some Q and Qe and total Qs values:  [[0.069]
 [0.077]
 [0.069]
 [0.07 ]
 [0.066]] [[43.59 ]
 [37.024]
 [43.59 ]
 [45.952]
 [46.024]] [[1.221]
 [0.899]
 [1.221]
 [1.341]
 [1.341]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  43.737162690461226
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
siam score:  -0.95681703
printing an ep nov before normalisation:  47.626909838894285
Printing some Q and Qe and total Qs values:  [[0.08]
 [0.08]
 [0.08]
 [0.08]
 [0.08]] [[40.962]
 [40.962]
 [40.962]
 [40.962]
 [40.962]] [[0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  32.71050950608162
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  64.34604128631004
printing an ep nov before normalisation:  62.428181170390054
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
Printing some Q and Qe and total Qs values:  [[0.064]
 [0.062]
 [0.059]
 [0.058]
 [0.06 ]] [[41.231]
 [49.391]
 [50.532]
 [49.083]
 [48.027]] [[0.867]
 [1.269]
 [1.323]
 [1.25 ]
 [1.2  ]]
Printing some Q and Qe and total Qs values:  [[0.057]
 [0.057]
 [0.057]
 [0.058]
 [0.057]] [[59.323]
 [59.323]
 [59.323]
 [60.618]
 [59.323]] [[1.993]
 [1.993]
 [1.993]
 [2.058]
 [1.993]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  56.803104229842944
Printing some Q and Qe and total Qs values:  [[0.06 ]
 [0.06 ]
 [0.02 ]
 [0.061]
 [0.063]] [[47.546]
 [42.341]
 [43.062]
 [32.121]
 [37.147]] [[1.68 ]
 [1.502]
 [1.487]
 [1.152]
 [1.326]]
printing an ep nov before normalisation:  48.86627120054036
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
siam score:  -0.9595817
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.063]
 [0.075]
 [0.059]
 [0.063]
 [0.063]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.063]
 [0.075]
 [0.059]
 [0.063]
 [0.063]]
line 256 mcts: sample exp_bonus 61.314465773132696
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.082]
 [0.097]
 [0.083]
 [0.087]] [[51.262]
 [54.356]
 [47.639]
 [49.381]
 [53.419]] [[1.432]
 [1.666]
 [1.338]
 [1.413]
 [1.623]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
siam score:  -0.96172696
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  63.00587109970677
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  46.2102299331069
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  84.22804107978571
using another actor
printing an ep nov before normalisation:  60.93799764848227
siam score:  -0.9600358
printing an ep nov before normalisation:  40.61660519034556
printing an ep nov before normalisation:  0.01286623317014346
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  74.96654756136434
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.61342538208375
siam score:  -0.9593855
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
actions average: 
K:  0  action  0 :  tensor([    0.9810,     0.0111,     0.0004,     0.0001,     0.0075],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0164,     0.8589,     0.0007,     0.0001,     0.1239],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9679,     0.0202,     0.0119],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0015,     0.0001,     0.0223,     0.8247,     0.1515],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0417, 0.1113, 0.0649, 0.2050, 0.5772], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
Printing some Q and Qe and total Qs values:  [[0.055]
 [0.047]
 [0.047]
 [0.047]
 [0.043]] [[39.338]
 [40.685]
 [40.685]
 [40.685]
 [43.419]] [[1.128]
 [1.194]
 [1.194]
 [1.194]
 [1.339]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
actions average: 
K:  4  action  0 :  tensor([    0.9942,     0.0034,     0.0002,     0.0003,     0.0018],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.9245,     0.0029,     0.0026,     0.0698],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9279,     0.0516,     0.0205],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0028, 0.0012, 0.0147, 0.8586, 0.1227], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0458, 0.0877, 0.0661, 0.1450, 0.6554], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
Printing some Q and Qe and total Qs values:  [[0.044]
 [0.046]
 [0.046]
 [0.039]
 [0.046]] [[66.544]
 [68.196]
 [64.136]
 [64.824]
 [71.022]] [[1.815]
 [1.861]
 [1.754]
 [1.765]
 [1.937]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  29.557809829711914
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  70.11016767565776
Printing some Q and Qe and total Qs values:  [[0.036]
 [0.049]
 [0.049]
 [0.049]
 [0.049]] [[56.591]
 [51.122]
 [51.122]
 [51.122]
 [51.122]] [[1.443]
 [1.234]
 [1.234]
 [1.234]
 [1.234]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
Printing some Q and Qe and total Qs values:  [[0.042]
 [0.039]
 [0.041]
 [0.041]
 [0.042]] [[46.774]
 [46.575]
 [48.807]
 [49.505]
 [46.774]] [[1.739]
 [1.726]
 [1.849]
 [1.887]
 [1.739]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  37.16059684753418
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  31.53280237173677
from probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
Printing some Q and Qe and total Qs values:  [[0.035]
 [0.035]
 [0.035]
 [0.035]
 [0.035]] [[44.6]
 [44.6]
 [44.6]
 [44.6]
 [44.6]] [[0.035]
 [0.035]
 [0.035]
 [0.035]
 [0.035]]
siam score:  -0.95230466
siam score:  -0.9522621
printing an ep nov before normalisation:  29.356560268204664
printing an ep nov before normalisation:  74.04135622848368
printing an ep nov before normalisation:  59.08265857782904
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
using another actor
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  70.93922431373366
printing an ep nov before normalisation:  32.32339382171631
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.041]
 [0.047]
 [0.027]
 [0.044]] [[39.783]
 [32.089]
 [31.611]
 [40.86 ]
 [36.731]] [[1.513]
 [1.089]
 [1.067]
 [1.603]
 [1.372]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
Printing some Q and Qe and total Qs values:  [[0.038]
 [0.035]
 [0.04 ]
 [0.038]
 [0.038]] [[73.312]
 [75.608]
 [69.268]
 [73.312]
 [72.967]] [[1.295]
 [1.344]
 [1.205]
 [1.295]
 [1.287]]
actions average: 
K:  4  action  0 :  tensor([0.9272, 0.0253, 0.0059, 0.0052, 0.0364], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9511,     0.0004,     0.0001,     0.0483],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9567,     0.0215,     0.0218],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0005,     0.0340,     0.8577,     0.1074],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0383, 0.0011, 0.0701, 0.2526, 0.6379], grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 33.56039680806987
printing an ep nov before normalisation:  40.47204164281811
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  74.28140759965632
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  48.110449755983346
Printing some Q and Qe and total Qs values:  [[0.039]
 [0.042]
 [0.042]
 [0.042]
 [0.042]] [[48.037]
 [49.882]
 [49.882]
 [49.882]
 [49.882]] [[1.614]
 [1.738]
 [1.738]
 [1.738]
 [1.738]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
actions average: 
K:  2  action  0 :  tensor([    0.9964,     0.0005,     0.0000,     0.0002,     0.0028],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0027,     0.9159,     0.0007,     0.0003,     0.0804],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0014, 0.0063, 0.9334, 0.0171, 0.0418], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0001,     0.0001,     0.0531,     0.8579,     0.0889],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0021, 0.1865, 0.0952, 0.2668, 0.4494], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  54.61664668898567
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
siam score:  -0.9512956
maxi score, test score, baseline:  0.0041 0.1 0.1
actions average: 
K:  2  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0133,     0.8865,     0.0071,     0.0007,     0.0924],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9975,     0.0007,     0.0017],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0011,     0.0002,     0.0167,     0.7945,     0.1875],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0561, 0.1724, 0.0416, 0.1813, 0.5485], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  34.62942739740191
printing an ep nov before normalisation:  37.82580988690773
actions average: 
K:  4  action  0 :  tensor([    0.9925,     0.0000,     0.0001,     0.0002,     0.0072],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9769,     0.0000,     0.0001,     0.0230],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0003,     0.8779,     0.0677,     0.0539],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0005,     0.0005,     0.0074,     0.8769,     0.1147],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0134, 0.0425, 0.0460, 0.1702, 0.7279], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
siam score:  -0.9499469
siam score:  -0.9498735
printing an ep nov before normalisation:  50.26421227069809
Printing some Q and Qe and total Qs values:  [[0.035]
 [0.038]
 [0.038]
 [0.038]
 [0.038]] [[64.603]
 [59.406]
 [59.406]
 [59.406]
 [59.406]] [[1.555]
 [1.378]
 [1.378]
 [1.378]
 [1.378]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  74.207869468875
printing an ep nov before normalisation:  31.247217146607586
printing an ep nov before normalisation:  96.17856179708609
Printing some Q and Qe and total Qs values:  [[0.042]
 [0.042]
 [0.046]
 [0.046]
 [0.046]] [[88.115]
 [87.718]
 [65.945]
 [65.945]
 [65.945]] [[1.676]
 [1.666]
 [1.139]
 [1.139]
 [1.139]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  52.51259846377782
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.036]
 [0.034]
 [0.036]
 [0.036]
 [0.036]] [[68.913]
 [65.278]
 [68.913]
 [76.92 ]
 [68.913]] [[1.492]
 [1.395]
 [1.492]
 [1.703]
 [1.492]]
printing an ep nov before normalisation:  48.255973930829676
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
Printing some Q and Qe and total Qs values:  [[0.04 ]
 [0.039]
 [0.037]
 [0.036]
 [0.04 ]] [[32.841]
 [37.277]
 [44.212]
 [44.811]
 [39.447]] [[0.513]
 [0.723]
 [1.052]
 [1.08 ]
 [0.828]]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  70.28007130721798
maxi score, test score, baseline:  0.0041 0.1 0.1
using another actor
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
printing an ep nov before normalisation:  58.607799717426055
maxi score, test score, baseline:  0.0041 0.1 0.1
Printing some Q and Qe and total Qs values:  [[0.034]
 [0.035]
 [0.034]
 [0.034]
 [0.034]] [[90.08 ]
 [89.292]
 [90.08 ]
 [90.08 ]
 [90.08 ]] [[1.745]
 [1.725]
 [1.745]
 [1.745]
 [1.745]]
printing an ep nov before normalisation:  40.45305486740561
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
using another actor
actions average: 
K:  2  action  0 :  tensor([    0.9578,     0.0001,     0.0002,     0.0016,     0.0404],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0001,     0.9264,     0.0326,     0.0005,     0.0404],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0057,     0.0002,     0.9690,     0.0012,     0.0239],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0008,     0.0002,     0.0331,     0.8865,     0.0793],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0034, 0.0838, 0.0458, 0.2361, 0.6309], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
line 256 mcts: sample exp_bonus 56.5703498171167
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07579967440449586, 0.07579967440449586, 0.07579967440449586, 0.16666666666666666, 0.07579967440449586, 0.5301346357153499]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  62.090903786225994
maxi score, test score, baseline:  0.0041 0.1 0.1
actions average: 
K:  3  action  0 :  tensor([0.9530, 0.0084, 0.0011, 0.0124, 0.0251], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0104,     0.9472,     0.0006,     0.0009,     0.0408],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0005,     0.0074,     0.9603,     0.0209,     0.0109],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0002,     0.0004,     0.0270,     0.8504,     0.1220],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0135, 0.1535, 0.0416, 0.1747, 0.6166], grad_fn=<DivBackward0>)
siam score:  -0.94451416
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  57.7423174544985
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
using explorer policy with actor:  1
from probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  27.416820542570626
printing an ep nov before normalisation:  56.84811241110877
Printing some Q and Qe and total Qs values:  [[0.02 ]
 [0.019]
 [0.019]
 [0.019]
 [0.019]] [[26.591]
 [19.029]
 [23.277]
 [26.843]
 [23.277]] [[0.02 ]
 [0.019]
 [0.019]
 [0.019]
 [0.019]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.021]
 [0.018]
 [0.018]
 [0.018]
 [0.018]] [[31.912]
 [34.195]
 [35.039]
 [40.557]
 [34.195]] [[0.021]
 [0.018]
 [0.018]
 [0.018]
 [0.018]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  23.761562986903247
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  29.126664312151824
siam score:  -0.93922895
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  32.92097591332577
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  49.11582369205097
printing an ep nov before normalisation:  50.75235140823371
from probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.021]
 [0.017]
 [0.021]
 [0.02 ]
 [0.021]] [[29.671]
 [24.328]
 [21.948]
 [22.693]
 [21.652]] [[0.021]
 [0.017]
 [0.021]
 [0.02 ]
 [0.021]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.039]
 [0.055]
 [0.039]
 [0.039]
 [0.039]] [[39.504]
 [45.083]
 [39.504]
 [39.504]
 [39.504]] [[0.875]
 [1.148]
 [0.875]
 [0.875]
 [0.875]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  29.010790818794128
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.035]
 [0.054]
 [0.042]
 [0.044]
 [0.044]] [[35.725]
 [22.616]
 [25.671]
 [17.96 ]
 [17.197]] [[2.266]
 [1.115]
 [1.375]
 [0.689]
 [0.62 ]]
printing an ep nov before normalisation:  26.63900136947632
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  59.460249268250635
Printing some Q and Qe and total Qs values:  [[0.194]
 [0.219]
 [0.219]
 [0.213]
 [0.205]] [[52.38 ]
 [49.485]
 [49.485]
 [52.899]
 [52.661]] [[1.85 ]
 [1.75 ]
 [1.75 ]
 [1.892]
 [1.873]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  32.02314615249634
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  57.16538978020075
printing an ep nov before normalisation:  69.01537973080157
maxi score, test score, baseline:  0.0041 0.1 0.1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  30.854830205976857
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
actions average: 
K:  1  action  0 :  tensor([    0.9661,     0.0118,     0.0011,     0.0003,     0.0208],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0016,     0.9508,     0.0001,     0.0001,     0.0473],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0201,     0.9197,     0.0141,     0.0459],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0058,     0.0004,     0.0231,     0.7843,     0.1864],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0463, 0.0482, 0.1083, 0.2078, 0.5894], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  54.473220124430405
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.053]
 [0.053]
 [0.053]
 [0.053]
 [0.053]] [[43.409]
 [43.409]
 [43.409]
 [45.226]
 [43.409]] [[1.924]
 [1.924]
 [1.924]
 [2.053]
 [1.924]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  52.54105991909882
printing an ep nov before normalisation:  79.47781068334965
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.055]
 [0.055]
 [0.049]
 [0.055]
 [0.055]] [[16.24 ]
 [16.24 ]
 [42.483]
 [16.24 ]
 [16.24 ]] [[0.351]
 [0.351]
 [1.255]
 [0.351]
 [0.351]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  60.64366023378981
printing an ep nov before normalisation:  99.21030106702432
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.066]
 [0.059]
 [0.07 ]
 [0.062]
 [0.067]] [[40.411]
 [47.818]
 [39.294]
 [53.998]
 [48.208]] [[0.472]
 [0.607]
 [0.455]
 [0.729]
 [0.623]]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  32.17624786881136
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
using another actor
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
UNIT TEST: sample policy line 217 mcts : [0.872 0.026 0.051 0.026 0.026]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  20.760532082556626
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  33.35535952366745
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.087]
 [0.114]
 [0.087]
 [0.087]
 [0.087]] [[69.417]
 [74.073]
 [69.417]
 [69.417]
 [69.417]] [[1.661]
 [1.823]
 [1.661]
 [1.661]
 [1.661]]
using explorer policy with actor:  0
printing an ep nov before normalisation:  57.64354811077324
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.055]
 [0.055]
 [0.051]
 [0.05 ]
 [0.052]] [[38.026]
 [52.002]
 [54.981]
 [54.232]
 [49.885]] [[0.055]
 [0.055]
 [0.051]
 [0.05 ]
 [0.052]]
printing an ep nov before normalisation:  23.538267612457275
printing an ep nov before normalisation:  34.219363945684655
printing an ep nov before normalisation:  25.868569096711628
Printing some Q and Qe and total Qs values:  [[0.048]
 [0.043]
 [0.056]
 [0.052]
 [0.043]] [[32.328]
 [31.322]
 [24.386]
 [28.588]
 [31.322]] [[0.048]
 [0.043]
 [0.056]
 [0.052]
 [0.043]]
printing an ep nov before normalisation:  45.87803581644908
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  25.562245845794678
printing an ep nov before normalisation:  33.60836343524573
using another actor
from probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  32.76178540146519
from probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  39.741606819183744
printing an ep nov before normalisation:  36.61315958479095
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
maxi score, test score, baseline:  0.0041 0.1 0.1
printing an ep nov before normalisation:  55.076003000313214
maxi score, test score, baseline:  0.0041 0.1 0.1
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
printing an ep nov before normalisation:  29.94321166340119
maxi score, test score, baseline:  0.0041 0.1 0.1
probs:  [0.07411825356345668, 0.07411825356345668, 0.07411825356345668, 0.18517634928730867, 0.07411825356345668, 0.5183506364588647]
Printing some Q and Qe and total Qs values:  [[0.049]
 [0.001]
 [0.047]
 [0.048]
 [0.042]] [[37.559]
 [32.467]
 [30.162]
 [21.427]
 [29.148]] [[0.049]
 [0.001]
 [0.047]
 [0.048]
 [0.042]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  29.21172669591171
printing an ep nov before normalisation:  60.76469503100338
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  48.27653612806394
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  35.21141507369033
printing an ep nov before normalisation:  37.10562705993652
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
siam score:  -0.9548407
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  44.08908970673928
printing an ep nov before normalisation:  49.22866503542212
siam score:  -0.9548958
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
Printing some Q and Qe and total Qs values:  [[0.117]
 [0.123]
 [0.117]
 [0.117]
 [0.117]] [[34.408]
 [42.962]
 [34.408]
 [34.408]
 [34.408]] [[1.109]
 [1.566]
 [1.109]
 [1.109]
 [1.109]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
Printing some Q and Qe and total Qs values:  [[0.065]
 [0.065]
 [0.069]
 [0.065]
 [0.065]] [[67.652]
 [68.574]
 [63.205]
 [67.652]
 [70.264]] [[0.841]
 [0.859]
 [0.76 ]
 [0.841]
 [0.892]]
Printing some Q and Qe and total Qs values:  [[0.069]
 [0.069]
 [0.07 ]
 [0.069]
 [0.069]] [[70.021]
 [70.021]
 [74.802]
 [70.021]
 [70.021]] [[0.835]
 [0.835]
 [0.93 ]
 [0.835]
 [0.835]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  43.67594301438988
printing an ep nov before normalisation:  82.36321482491286
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
siam score:  -0.9569043
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
actions average: 
K:  3  action  0 :  tensor([    0.9504,     0.0164,     0.0009,     0.0004,     0.0319],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0205,     0.9491,     0.0010,     0.0008,     0.0287],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0026,     0.0145,     0.9547,     0.0003,     0.0279],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0005,     0.0002,     0.0112,     0.9202,     0.0678],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0668, 0.1204, 0.0607, 0.0927, 0.6594], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  39.28485046632734
printing an ep nov before normalisation:  68.18188433425037
printing an ep nov before normalisation:  29.454312324523926
printing an ep nov before normalisation:  51.5499449262802
printing an ep nov before normalisation:  54.090655164385865
printing an ep nov before normalisation:  59.227340020553434
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]] [[53.307]
 [53.307]
 [53.307]
 [53.307]
 [53.307]] [[1.728]
 [1.728]
 [1.728]
 [1.728]
 [1.728]]
printing an ep nov before normalisation:  47.924746228117534
using another actor
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  0.0041670732042575764
printing an ep nov before normalisation:  40.52191891493432
printing an ep nov before normalisation:  53.80130840122531
Printing some Q and Qe and total Qs values:  [[0.033]
 [0.033]
 [0.041]
 [0.033]
 [0.033]] [[35.155]
 [35.155]
 [43.082]
 [35.155]
 [35.155]] [[0.504]
 [0.504]
 [0.729]
 [0.504]
 [0.504]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
Printing some Q and Qe and total Qs values:  [[0.047]
 [0.044]
 [0.046]
 [0.048]
 [0.049]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.047]
 [0.044]
 [0.046]
 [0.048]
 [0.049]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
line 256 mcts: sample exp_bonus 45.59489690807355
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  44.453160722597524
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  38.87180443979417
printing an ep nov before normalisation:  46.69971285805812
printing an ep nov before normalisation:  41.186820133591596
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  89.26678711981971
siam score:  -0.95299315
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
Printing some Q and Qe and total Qs values:  [[0.039]
 [0.034]
 [0.042]
 [0.039]
 [0.04 ]] [[33.98 ]
 [30.171]
 [31.704]
 [30.708]
 [29.503]] [[0.223]
 [0.183]
 [0.206]
 [0.193]
 [0.184]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  61.778863422423825
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  57.14209868581866
line 256 mcts: sample exp_bonus 73.4652218782218
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  64.48968528627724
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  56.84185739147796
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.036]
 [0.04 ]
 [0.036]
 [0.036]] [[59.132]
 [59.249]
 [58.296]
 [59.249]
 [59.249]] [[1.876]
 [1.888]
 [1.838]
 [1.888]
 [1.888]]
printing an ep nov before normalisation:  40.11013984680176
using explorer policy with actor:  1
printing an ep nov before normalisation:  33.10732182887511
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  51.4144807869999
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
using explorer policy with actor:  1
printing an ep nov before normalisation:  71.70813742421765
from probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  46.93088560903515
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.038]
 [0.032]
 [0.032]
 [0.032]] [[45.416]
 [55.102]
 [34.891]
 [34.891]
 [34.891]] [[0.977]
 [1.302]
 [0.633]
 [0.633]
 [0.633]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  28.862841526229467
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  22.462704040912687
printing an ep nov before normalisation:  39.19602258811997
printing an ep nov before normalisation:  86.98578866632874
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  62.751235442956975
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  18.549057245254517
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
printing an ep nov before normalisation:  83.05634134910485
Printing some Q and Qe and total Qs values:  [[0.047]
 [0.052]
 [0.052]
 [0.052]
 [0.052]] [[55.775]
 [45.177]
 [45.378]
 [45.378]
 [45.378]] [[1.77 ]
 [1.365]
 [1.373]
 [1.373]
 [1.373]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  64.96693909243864
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
siam score:  -0.9463596
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[5.725]
 [4.252]
 [5.79 ]
 [4.422]
 [5.245]] [[0.321]
 [0.238]
 [0.324]
 [0.248]
 [0.294]]
from probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
siam score:  -0.9468391
printing an ep nov before normalisation:  72.05487620647604
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  40.086708068847656
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  53.18143059139567
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  29.91917371749878
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
Printing some Q and Qe and total Qs values:  [[0.022]
 [0.022]
 [0.024]
 [0.023]
 [0.022]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.022]
 [0.022]
 [0.024]
 [0.023]
 [0.022]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
using another actor
maxi score, test score, baseline:  0.0041 0.0 0.0041
Printing some Q and Qe and total Qs values:  [[0.052]
 [0.045]
 [0.052]
 [0.052]
 [0.052]] [[47.581]
 [64.512]
 [47.581]
 [47.581]
 [47.581]] [[0.706]
 [1.16 ]
 [0.706]
 [0.706]
 [0.706]]
Printing some Q and Qe and total Qs values:  [[0.047]
 [0.041]
 [0.047]
 [0.047]
 [0.047]] [[60.121]
 [70.539]
 [60.121]
 [60.121]
 [60.121]] [[1.017]
 [1.287]
 [1.017]
 [1.017]
 [1.017]]
Printing some Q and Qe and total Qs values:  [[0.045]
 [0.045]
 [0.045]
 [0.045]
 [0.045]] [[43.446]
 [43.446]
 [43.446]
 [43.446]
 [43.446]] [[1.378]
 [1.378]
 [1.378]
 [1.378]
 [1.378]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
from probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
line 256 mcts: sample exp_bonus 49.9579203417858
printing an ep nov before normalisation:  29.95483636856079
maxi score, test score, baseline:  0.0041 0.0 0.0041
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
siam score:  -0.9385405
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  68.33093818241858
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
using another actor
Printing some Q and Qe and total Qs values:  [[0.026]
 [0.026]
 [0.026]
 [0.026]
 [0.026]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.026]
 [0.026]
 [0.026]
 [0.026]
 [0.026]]
printing an ep nov before normalisation:  29.9954891204834
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
from probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
Printing some Q and Qe and total Qs values:  [[0.028]
 [0.028]
 [0.029]
 [0.028]
 [0.028]] [[45.965]
 [45.965]
 [69.141]
 [45.965]
 [45.965]] [[0.426]
 [0.426]
 [0.731]
 [0.426]
 [0.426]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
siam score:  -0.9352371
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  31.506291973221497
printing an ep nov before normalisation:  28.97428274154663
siam score:  -0.93571734
printing an ep nov before normalisation:  73.34996536137213
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
actions average: 
K:  0  action  0 :  tensor([    0.9947,     0.0000,     0.0000,     0.0031,     0.0022],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0001,     0.9804,     0.0012,     0.0003,     0.0179],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0005,     0.0002,     0.9480,     0.0211,     0.0302],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0001,     0.0287,     0.8023,     0.1687],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0615, 0.2055, 0.0349, 0.0733, 0.6248], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
Printing some Q and Qe and total Qs values:  [[0.034]
 [0.034]
 [0.036]
 [0.035]
 [0.037]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.034]
 [0.034]
 [0.036]
 [0.035]
 [0.037]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  41.1163281220577
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  44.54004705360347
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
actions average: 
K:  3  action  0 :  tensor([    1.0000,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0008,     0.9496,     0.0002,     0.0005,     0.0489],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0004,     0.0110,     0.9406,     0.0159,     0.0322],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0087,     0.0001,     0.0203,     0.8049,     0.1660],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0738, 0.0999, 0.0335, 0.2189, 0.5739], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  8.897685625711915
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.025]
 [0.025]
 [0.025]
 [0.027]
 [0.025]] [[52.016]
 [52.016]
 [52.016]
 [56.278]
 [52.016]] [[0.914]
 [0.914]
 [0.914]
 [1.027]
 [0.914]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
Printing some Q and Qe and total Qs values:  [[0.034]
 [0.024]
 [0.03 ]
 [0.033]
 [0.038]] [[29.281]
 [27.731]
 [36.591]
 [30.04 ]
 [30.312]] [[0.437]
 [0.38 ]
 [0.654]
 [0.459]
 [0.472]]
Printing some Q and Qe and total Qs values:  [[0.029]
 [0.029]
 [0.029]
 [0.029]
 [0.029]] [[36.981]
 [36.981]
 [57.972]
 [36.981]
 [36.981]] [[0.748]
 [0.748]
 [1.375]
 [0.748]
 [0.748]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
printing an ep nov before normalisation:  59.68765496297829
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
siam score:  -0.93593186
using explorer policy with actor:  1
using another actor
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
using explorer policy with actor:  0
printing an ep nov before normalisation:  0.001858202182347668
printing an ep nov before normalisation:  71.40459166428671
printing an ep nov before normalisation:  64.94073892206909
using another actor
using explorer policy with actor:  0
siam score:  -0.93569076
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
from probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07147537807537997, 0.07147537807537997, 0.07147537807537997, 0.21426231096231, 0.07147537807537997, 0.4998361767361701]
Printing some Q and Qe and total Qs values:  [[0.064]
 [0.064]
 [0.064]
 [0.064]
 [0.064]] [[74.865]
 [74.865]
 [74.865]
 [74.865]
 [74.865]] [[2.064]
 [2.064]
 [2.064]
 [2.064]
 [2.064]]
printing an ep nov before normalisation:  68.0730888042035
printing an ep nov before normalisation:  56.13019776508017
actor:  1 policy actor:  1  step number:  74 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
printing an ep nov before normalisation:  69.50870789718499
Printing some Q and Qe and total Qs values:  [[0.028]
 [0.028]
 [0.027]
 [0.028]
 [0.028]] [[22.209]
 [22.209]
 [39.247]
 [22.209]
 [22.209]] [[0.21 ]
 [0.21 ]
 [0.584]
 [0.21 ]
 [0.21 ]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  29.301269054412842
siam score:  -0.92879105
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
Printing some Q and Qe and total Qs values:  [[0.038]
 [0.039]
 [0.036]
 [0.042]
 [0.038]] [[39.456]
 [24.608]
 [38.3  ]
 [33.932]
 [36.806]] [[1.049]
 [0.669]
 [1.018]
 [0.912]
 [0.982]]
printing an ep nov before normalisation:  35.30446529388428
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  81.17826811124277
from probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  41.00167274475098
printing an ep nov before normalisation:  60.387477001394444
siam score:  -0.9289223
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  47.66312228610744
maxi score, test score, baseline:  0.0041 0.0 0.0041
using explorer policy with actor:  0
printing an ep nov before normalisation:  52.777604892558145
siam score:  -0.9305731
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
Printing some Q and Qe and total Qs values:  [[0.027]
 [0.027]
 [0.027]
 [0.027]
 [0.027]] [[47.023]
 [47.023]
 [47.023]
 [47.023]
 [47.023]] [[2.018]
 [2.018]
 [2.018]
 [2.018]
 [2.018]]
printing an ep nov before normalisation:  0.00013657573324129166
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
printing an ep nov before normalisation:  51.96560658505768
printing an ep nov before normalisation:  0.0020223269348207396
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
using another actor
printing an ep nov before normalisation:  50.343045502081345
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
using another actor
from probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  61.87376489703926
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.07411769528533255, 0.07411769528533255, 0.07411769528533255, 0.1851764609429335, 0.07411769528533255, 0.5183527579157364]
actions average: 
K:  3  action  0 :  tensor([    0.9891,     0.0001,     0.0001,     0.0003,     0.0104],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0004,     0.9628,     0.0001,     0.0022,     0.0344],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0044,     0.9285,     0.0250,     0.0422],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0014, 0.0011, 0.0332, 0.8534, 0.1109], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0006, 0.0643, 0.0026, 0.3604, 0.5722], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  34.45626497268677
maxi score, test score, baseline:  0.0041 0.0 0.0041
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  1
actor:  1 policy actor:  1  step number:  62 total reward:  1.0  reward:  1.0 rdn_beta:  1.333
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  38.70592668429432
maxi score, test score, baseline:  0.0041 0.0 0.0041
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.031]
 [0.034]
 [0.029]
 [0.031]] [[45.19 ]
 [48.71 ]
 [42.649]
 [53.639]
 [50.003]] [[1.12 ]
 [1.266]
 [1.066]
 [1.43 ]
 [1.31 ]]
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.021]
 [0.02 ]
 [0.019]
 [0.022]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.019]
 [0.021]
 [0.02 ]
 [0.019]
 [0.022]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  40.81143591858128
printing an ep nov before normalisation:  55.66651241461279
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  40.86107842986341
line 256 mcts: sample exp_bonus 45.21329485801688
printing an ep nov before normalisation:  76.8227953018905
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.023]
 [0.022]
 [0.021]
 [0.021]] [[35.802]
 [29.949]
 [22.792]
 [26.09 ]
 [23.072]] [[0.018]
 [0.023]
 [0.022]
 [0.021]
 [0.021]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0041 0.0 0.0041
using explorer policy with actor:  0
actions average: 
K:  1  action  0 :  tensor([    0.9802,     0.0090,     0.0004,     0.0001,     0.0103],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9418,     0.0068,     0.0001,     0.0512],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9969,     0.0019,     0.0012],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0010,     0.0001,     0.0125,     0.8891,     0.0972],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0699, 0.1461, 0.0537, 0.1851, 0.5451], grad_fn=<DivBackward0>)
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
from probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  28.545559761646306
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.029]
 [0.03 ]
 [0.031]
 [0.03 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.031]
 [0.029]
 [0.03 ]
 [0.031]
 [0.03 ]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.028]
 [0.026]
 [0.027]
 [0.027]
 [0.027]] [[51.226]
 [59.042]
 [52.929]
 [52.929]
 [52.929]] [[0.959]
 [1.236]
 [1.019]
 [1.019]
 [1.019]]
printing an ep nov before normalisation:  47.14161937656174
printing an ep nov before normalisation:  33.51160013945531
printing an ep nov before normalisation:  44.373312168490514
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  48.092498023560665
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.035]
 [0.   ]
 [0.023]
 [0.028]] [[42.15 ]
 [40.638]
 [44.42 ]
 [44.06 ]
 [45.7  ]] [[1.428]
 [1.354]
 [1.588]
 [1.585]
 [1.707]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
from probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.027]
 [0.025]
 [0.023]
 [0.034]
 [0.023]] [[37.654]
 [45.714]
 [34.723]
 [40.033]
 [34.723]] [[0.594]
 [0.81 ]
 [0.511]
 [0.665]
 [0.511]]
printing an ep nov before normalisation:  41.07314374543059
Printing some Q and Qe and total Qs values:  [[0.026]
 [0.03 ]
 [0.032]
 [0.026]
 [0.031]] [[29.707]
 [34.421]
 [36.94 ]
 [29.707]
 [34.088]] [[0.954]
 [1.337]
 [1.541]
 [0.954]
 [1.311]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.021]
 [0.021]
 [0.021]
 [0.021]
 [0.021]] [[28.97]
 [28.97]
 [28.97]
 [28.97]
 [28.97]] [[0.021]
 [0.021]
 [0.021]
 [0.021]
 [0.021]]
printing an ep nov before normalisation:  47.37085414521657
actions average: 
K:  4  action  0 :  tensor([    0.9947,     0.0000,     0.0039,     0.0000,     0.0014],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.8963,     0.0035,     0.0004,     0.0996],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0177,     0.9020,     0.0182,     0.0620],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0022,     0.0007,     0.0126,     0.8497,     0.1348],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0078, 0.0871, 0.0730, 0.2672, 0.5648], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  31.014293432235718
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  74.54956668780774
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
using explorer policy with actor:  1
printing an ep nov before normalisation:  63.25893698840108
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.032]
 [0.031]
 [0.029]
 [0.034]
 [0.029]] [[61.805]
 [61.695]
 [64.861]
 [62.572]
 [64.861]] [[1.869]
 [1.865]
 [1.958]
 [1.895]
 [1.958]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  97.87257830184195
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  58.03126021399294
printing an ep nov before normalisation:  35.72035710420334
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  113.92457175616788
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
line 256 mcts: sample exp_bonus 69.53367833889796
printing an ep nov before normalisation:  66.43160891747677
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  54.618643419941826
printing an ep nov before normalisation:  56.99891058790669
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
siam score:  -0.92297524
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.51259709358275
printing an ep nov before normalisation:  52.93350828764716
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  55.02364718972842
Printing some Q and Qe and total Qs values:  [[0.029]
 [0.   ]
 [0.028]
 [0.031]
 [0.031]] [[27.893]
 [27.724]
 [35.015]
 [26.996]
 [24.525]] [[0.627]
 [0.591]
 [0.912]
 [0.593]
 [0.493]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  29.6103298384539
printing an ep nov before normalisation:  42.96546488110454
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.022]
 [0.031]
 [0.027]
 [0.027]] [[36.404]
 [44.679]
 [32.113]
 [27.879]
 [27.879]] [[0.182]
 [0.245]
 [0.165]
 [0.131]
 [0.131]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.028]
 [0.   ]
 [0.027]
 [0.026]] [[39.084]
 [58.523]
 [31.035]
 [33.371]
 [41.501]] [[0.415]
 [0.783]
 [0.27 ]
 [0.337]
 [0.481]]
printing an ep nov before normalisation:  46.13416653766734
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.027]
 [0.027]
 [0.027]
 [0.026]
 [0.027]] [[24.82 ]
 [24.82 ]
 [24.82 ]
 [44.721]
 [24.82 ]] [[0.267]
 [0.267]
 [0.267]
 [0.7  ]
 [0.267]]
Printing some Q and Qe and total Qs values:  [[0.026]
 [0.026]
 [0.031]
 [0.026]
 [0.026]] [[48.024]
 [48.024]
 [48.405]
 [48.024]
 [48.024]] [[0.888]
 [0.888]
 [0.904]
 [0.888]
 [0.888]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
from probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  34.71491494810907
printing an ep nov before normalisation:  100.75594666045353
from probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.021]
 [0.015]
 [0.021]
 [0.019]
 [0.02 ]] [[29.021]
 [28.177]
 [28.459]
 [23.831]
 [23.997]] [[0.021]
 [0.015]
 [0.021]
 [0.019]
 [0.02 ]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
actions average: 
K:  1  action  0 :  tensor([    0.9416,     0.0181,     0.0004,     0.0003,     0.0396],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9417,     0.0003,     0.0026,     0.0553],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0005,     0.0000,     0.9691,     0.0182,     0.0122],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0012,     0.0003,     0.0348,     0.7982,     0.1655],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0831, 0.1118, 0.0344, 0.2071, 0.5636], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  72.65902079444616
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.032]
 [0.027]
 [0.032]
 [0.032]
 [0.032]] [[27.422]
 [37.673]
 [27.422]
 [27.422]
 [27.422]] [[0.474]
 [0.747]
 [0.474]
 [0.474]
 [0.474]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
Printing some Q and Qe and total Qs values:  [[0.027]
 [0.027]
 [0.027]
 [0.027]
 [0.027]] [[68.889]
 [68.889]
 [68.889]
 [68.889]
 [68.889]] [[1.805]
 [1.805]
 [1.805]
 [1.805]
 [1.805]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  40.550145914984505
printing an ep nov before normalisation:  30.60157299041748
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  37.97799489700362
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
printing an ep nov before normalisation:  69.7802021998345
Printing some Q and Qe and total Qs values:  [[0.025]
 [0.023]
 [0.029]
 [0.028]
 [0.027]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.025]
 [0.023]
 [0.029]
 [0.028]
 [0.027]]
actions average: 
K:  3  action  0 :  tensor([    0.9598,     0.0112,     0.0004,     0.0002,     0.0285],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9089,     0.0003,     0.0002,     0.0905],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0098,     0.0003,     0.9875,     0.0002,     0.0021],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0009,     0.0004,     0.0111,     0.8443,     0.1433],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0020, 0.0986, 0.0028, 0.2619, 0.6347], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06671706105961071, 0.06671706105961071, 0.06671706105961071, 0.2666162722737226, 0.06671706105961071, 0.46651548348783445]
maxi score, test score, baseline:  0.0041 0.0 0.0041
actor:  1 policy actor:  1  step number:  90 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
printing an ep nov before normalisation:  91.2459429964797
printing an ep nov before normalisation:  74.76110844280281
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  28.07167576688561
printing an ep nov before normalisation:  40.05474478962967
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
using explorer policy with actor:  1
printing an ep nov before normalisation:  37.78976042183533
Printing some Q and Qe and total Qs values:  [[0.287]
 [0.32 ]
 [0.169]
 [0.287]
 [0.287]] [[44.087]
 [52.696]
 [46.475]
 [44.087]
 [44.087]] [[1.272]
 [1.681]
 [1.258]
 [1.272]
 [1.272]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
Printing some Q and Qe and total Qs values:  [[0.027]
 [0.02 ]
 [0.024]
 [0.025]
 [0.027]] [[41.58 ]
 [50.043]
 [56.654]
 [47.914]
 [41.58 ]] [[0.697]
 [0.889]
 [1.049]
 [0.844]
 [0.697]]
siam score:  -0.9086334
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  65.2156983069874
printing an ep nov before normalisation:  43.124935360097915
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  32.7088737487793
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
printing an ep nov before normalisation:  40.220073611805596
printing an ep nov before normalisation:  57.579456223314004
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
printing an ep nov before normalisation:  71.5064798423348
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
printing an ep nov before normalisation:  30.530874130708273
printing an ep nov before normalisation:  68.65675868393055
actions average: 
K:  1  action  0 :  tensor([    0.9912,     0.0000,     0.0000,     0.0001,     0.0087],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0149, 0.9251, 0.0162, 0.0011, 0.0427], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0178,     0.9531,     0.0152,     0.0138],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0044,     0.0005,     0.0368,     0.7840,     0.1743],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0155, 0.1393, 0.0446, 0.2339, 0.5667], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
printing an ep nov before normalisation:  40.961809158325195
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
actions average: 
K:  4  action  0 :  tensor([    0.9459,     0.0253,     0.0012,     0.0002,     0.0274],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0127,     0.9062,     0.0007,     0.0028,     0.0775],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0007,     0.9399,     0.0202,     0.0391],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0023,     0.0004,     0.0110,     0.7633,     0.2230],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0025, 0.0396, 0.0579, 0.3213, 0.5787], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  36.29887930874161
printing an ep nov before normalisation:  54.9760922276733
printing an ep nov before normalisation:  55.72859652050124
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]]
printing an ep nov before normalisation:  68.7831704753186
printing an ep nov before normalisation:  72.51021320608072
printing an ep nov before normalisation:  26.689716981672664
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.019]
 [0.021]
 [0.02 ]
 [0.02 ]] [[33.337]
 [28.122]
 [30.964]
 [40.714]
 [27.002]] [[0.019]
 [0.019]
 [0.021]
 [0.02 ]
 [0.02 ]]
printing an ep nov before normalisation:  36.53486574034933
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
using explorer policy with actor:  1
from probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
printing an ep nov before normalisation:  43.56031701108754
maxi score, test score, baseline:  0.0041 0.0 0.0041
using explorer policy with actor:  0
printing an ep nov before normalisation:  28.03452491760254
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06949175227135196, 0.06949175227135196, 0.06949175227135196, 0.2360773198061772, 0.06949175227135196, 0.48595567110841503]
printing an ep nov before normalisation:  40.237399162764255
actor:  1 policy actor:  1  step number:  75 total reward:  1.0  reward:  1.0 rdn_beta:  1.0
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  63.14382834915482
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
siam score:  -0.904671
Printing some Q and Qe and total Qs values:  [[0.025]
 [0.027]
 [0.025]
 [0.027]
 [0.025]] [[53.133]
 [40.068]
 [41.374]
 [40.842]
 [41.374]] [[1.447]
 [0.889]
 [0.944]
 [0.923]
 [0.944]]
printing an ep nov before normalisation:  68.99746853305392
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
printing an ep nov before normalisation:  53.33463814623521
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
printing an ep nov before normalisation:  31.42198838543325
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  0.01083183081163952
printing an ep nov before normalisation:  60.34325321901891
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
printing an ep nov before normalisation:  52.14353116060858
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.06415493955322946, 0.06415493955322946, 0.14103873488830737, 0.21792253022338529, 0.06415493955322946, 0.448573916228619]
actor:  1 policy actor:  1  step number:  48 total reward:  1.0  reward:  1.0 rdn_beta:  1.667
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
siam score:  -0.89498717
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
printing an ep nov before normalisation:  35.51473417713863
printing an ep nov before normalisation:  64.00837145794142
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
printing an ep nov before normalisation:  73.7852610914301
printing an ep nov before normalisation:  0.061803968160916156
printing an ep nov before normalisation:  58.31023780554209
printing an ep nov before normalisation:  38.29138437664402
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  48.8328618937441
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.608681201934814
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
printing an ep nov before normalisation:  73.73316638846228
printing an ep nov before normalisation:  56.23020434838036
Printing some Q and Qe and total Qs values:  [[0.028]
 [0.039]
 [0.061]
 [0.028]
 [0.051]] [[45.699]
 [56.937]
 [40.074]
 [45.699]
 [41.182]] [[0.676]
 [1.042]
 [0.531]
 [0.676]
 [0.556]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
actions average: 
K:  0  action  0 :  tensor([    0.8843,     0.0175,     0.0008,     0.0319,     0.0655],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0156,     0.9229,     0.0008,     0.0001,     0.0606],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0007,     0.0000,     0.9990,     0.0001,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0001,     0.0001,     0.0298,     0.8175,     0.1525],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0240, 0.2310, 0.0601, 0.2115, 0.4734], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  49.995414648731355
printing an ep nov before normalisation:  50.82857393919685
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
printing an ep nov before normalisation:  51.91318384511952
Printing some Q and Qe and total Qs values:  [[0.025]
 [0.027]
 [0.023]
 [0.025]
 [0.026]] [[27.191]
 [29.103]
 [34.687]
 [24.943]
 [25.012]] [[0.638]
 [0.716]
 [0.936]
 [0.547]
 [0.551]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
printing an ep nov before normalisation:  49.18117589572318
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  41.71276381707246
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
Printing some Q and Qe and total Qs values:  [[0.038]
 [0.038]
 [0.037]
 [0.038]
 [0.037]] [[54.627]
 [54.627]
 [56.637]
 [54.627]
 [55.017]] [[1.806]
 [1.806]
 [1.898]
 [1.806]
 [1.823]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.05958073319476325, 0.05958073319476325, 0.13097135550936553, 0.2023619778239678, 0.13097135550936553, 0.4165338447677746]
UNIT TEST: sample policy line 217 mcts : [0.    0.231 0.103 0.667 0.   ]
siam score:  -0.89836824
actor:  1 policy actor:  1  step number:  74 total reward:  1.0  reward:  1.0 rdn_beta:  1.333
Printing some Q and Qe and total Qs values:  [[0.032]
 [0.03 ]
 [0.028]
 [0.028]
 [0.029]] [[47.094]
 [61.476]
 [62.733]
 [59.398]
 [59.991]] [[0.968]
 [1.591]
 [1.644]
 [1.499]
 [1.526]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  80.79240766357204
maxi score, test score, baseline:  0.0041 0.0 0.0041
Printing some Q and Qe and total Qs values:  [[0.002]
 [0.064]
 [0.065]
 [0.072]
 [0.064]] [[37.989]
 [40.557]
 [34.813]
 [40.559]
 [41.616]] [[1.325]
 [1.571]
 [1.162]
 [1.579]
 [1.646]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.031]
 [0.031]
 [0.031]
 [0.031]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.031]
 [0.031]
 [0.031]
 [0.031]
 [0.031]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[5.437]
 [5.186]
 [6.972]
 [5.114]
 [4.525]] [[0.388]
 [0.37 ]
 [0.5  ]
 [0.364]
 [0.321]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
using explorer policy with actor:  1
printing an ep nov before normalisation:  50.69230055335717
printing an ep nov before normalisation:  36.06851577758789
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  47.25815498337232
printing an ep nov before normalisation:  39.09382953397605
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
Printing some Q and Qe and total Qs values:  [[0.029]
 [0.025]
 [0.031]
 [0.025]
 [0.026]] [[37.121]
 [33.646]
 [30.831]
 [38.791]
 [38.719]] [[1.074]
 [0.884]
 [0.738]
 [1.159]
 [1.156]]
line 256 mcts: sample exp_bonus 53.46679884055243
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
siam score:  -0.896458
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  61.21677278129178
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 6.727]
 [ 9.674]
 [ 7.138]
 [11.224]
 [ 8.765]] [[0.238]
 [0.342]
 [0.253]
 [0.397]
 [0.31 ]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  98.37153599572586
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
siam score:  -0.90241194
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  42.86587138319415
Printing some Q and Qe and total Qs values:  [[0.039]
 [0.039]
 [0.043]
 [0.039]
 [0.041]] [[77.765]
 [75.922]
 [74.366]
 [77.765]
 [77.605]] [[1.59 ]
 [1.539]
 [1.5  ]
 [1.59 ]
 [1.587]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
Printing some Q and Qe and total Qs values:  [[0.033]
 [0.038]
 [0.037]
 [0.033]
 [0.033]] [[34.679]
 [42.334]
 [39.36 ]
 [34.679]
 [34.679]] [[0.761]
 [1.09 ]
 [0.964]
 [0.761]
 [0.761]]
printing an ep nov before normalisation:  51.01224505026344
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
siam score:  -0.9079265
printing an ep nov before normalisation:  0.0
Printing some Q and Qe and total Qs values:  [[0.036]
 [0.034]
 [0.037]
 [0.037]
 [0.037]] [[50.403]
 [64.579]
 [67.107]
 [64.585]
 [64.263]] [[1.008]
 [1.364]
 [1.43 ]
 [1.366]
 [1.358]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  55.49198568472708
using explorer policy with actor:  1
printing an ep nov before normalisation:  41.58577244917915
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  36.807115450833834
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  38.948915192882446
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  48.414201736450195
printing an ep nov before normalisation:  38.72993169044271
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  30.466408729553223
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
using another actor
from probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  30.53631762337756
Printing some Q and Qe and total Qs values:  [[0.042]
 [0.045]
 [0.038]
 [0.038]
 [0.039]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.042]
 [0.045]
 [0.038]
 [0.038]
 [0.039]]
printing an ep nov before normalisation:  44.52742357985058
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
Printing some Q and Qe and total Qs values:  [[0.04]
 [0.04]
 [0.04]
 [0.04]
 [0.04]] [[52.678]
 [52.678]
 [52.678]
 [52.678]
 [52.678]] [[1.707]
 [1.707]
 [1.707]
 [1.707]
 [1.707]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
printing an ep nov before normalisation:  69.96205134782949
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  43.147170551664225
printing an ep nov before normalisation:  40.2150711212298
Printing some Q and Qe and total Qs values:  [[0.089]
 [0.086]
 [0.082]
 [0.103]
 [0.085]] [[30.417]
 [27.803]
 [25.226]
 [33.78 ]
 [26.757]] [[0.757]
 [0.663]
 [0.569]
 [0.89 ]
 [0.625]]
printing an ep nov before normalisation:  36.937150955200195
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  46.12604915211408
printing an ep nov before normalisation:  50.657204966534955
printing an ep nov before normalisation:  55.999958588811765
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  40.78660948405059
Printing some Q and Qe and total Qs values:  [[0.143]
 [0.109]
 [0.135]
 [0.119]
 [0.129]] [[39.931]
 [38.593]
 [33.44 ]
 [41.609]
 [40.076]] [[1.269]
 [1.16 ]
 [0.895]
 [1.34 ]
 [1.264]]
printing an ep nov before normalisation:  53.52854079474381
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
actions average: 
K:  0  action  0 :  tensor([    0.9784,     0.0072,     0.0012,     0.0008,     0.0124],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0266,     0.9412,     0.0000,     0.0002,     0.0320],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0100,     0.9607,     0.0193,     0.0099],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0032, 0.0016, 0.0379, 0.8436, 0.1138], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0456, 0.0706, 0.0292, 0.2098, 0.6448], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  39.02132272720337
printing an ep nov before normalisation:  45.43929100036621
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  68.2811647975919
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
actions average: 
K:  4  action  0 :  tensor([    0.9715,     0.0098,     0.0005,     0.0003,     0.0180],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0193,     0.8077,     0.0008,     0.0002,     0.1721],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0068,     0.0376,     0.9244,     0.0005,     0.0307],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0003,     0.0086,     0.0249,     0.8967,     0.0695],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0513, 0.2025, 0.0020, 0.0020, 0.7422], grad_fn=<DivBackward0>)
Printing some Q and Qe and total Qs values:  [[0.043]
 [0.042]
 [0.046]
 [0.042]
 [0.043]] [[44.214]
 [57.85 ]
 [64.534]
 [59.421]
 [60.619]] [[0.569]
 [0.881]
 [1.04 ]
 [0.917]
 [0.946]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  39.888113763974836
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
printing an ep nov before normalisation:  41.393579648766135
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.055616573733142355, 0.055616573733142355, 0.12224662949325694, 0.2555067410134862, 0.12224662949325694, 0.3887668525337153]
actor:  1 policy actor:  1  step number:  72 total reward:  1.0  reward:  1.0 rdn_beta:  1.333
Printing some Q and Qe and total Qs values:  [[0.047]
 [0.104]
 [0.047]
 [0.047]
 [0.047]] [[35.229]
 [47.845]
 [35.229]
 [35.229]
 [35.229]] [[0.552]
 [0.897]
 [0.552]
 [0.552]
 [0.552]]
Printing some Q and Qe and total Qs values:  [[0.046]
 [0.047]
 [0.05 ]
 [0.05 ]
 [0.048]] [[45.05 ]
 [48.622]
 [49.398]
 [47.557]
 [49.563]] [[0.988]
 [1.148]
 [1.186]
 [1.103]
 [1.191]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.052148050524347137, 0.052148050524347137, 0.1146127502383396, 0.302006849380317, 0.1146127502383396, 0.36447154909430945]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.052148050524347137, 0.052148050524347137, 0.1146127502383396, 0.302006849380317, 0.1146127502383396, 0.36447154909430945]
printing an ep nov before normalisation:  77.9807754136284
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.052148050524347137, 0.052148050524347137, 0.1146127502383396, 0.302006849380317, 0.1146127502383396, 0.36447154909430945]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.052148050524347137, 0.052148050524347137, 0.1146127502383396, 0.302006849380317, 0.1146127502383396, 0.36447154909430945]
printing an ep nov before normalisation:  31.60607008405865
printing an ep nov before normalisation:  44.292895201826795
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.052148050524347137, 0.052148050524347137, 0.1146127502383396, 0.302006849380317, 0.1146127502383396, 0.36447154909430945]
Starting evaluation
using explorer policy with actor:  0
printing an ep nov before normalisation:  42.32854810486134
Printing some Q and Qe and total Qs values:  [[0.063]
 [0.063]
 [0.064]
 [0.063]
 [0.063]] [[49.143]
 [49.143]
 [45.659]
 [49.143]
 [49.143]] [[0.063]
 [0.063]
 [0.064]
 [0.063]
 [0.063]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.052148050524347137, 0.052148050524347137, 0.1146127502383396, 0.302006849380317, 0.1146127502383396, 0.36447154909430945]
Printing some Q and Qe and total Qs values:  [[0.032]
 [0.033]
 [0.032]
 [0.032]
 [0.032]] [[36.588]
 [34.499]
 [36.588]
 [48.917]
 [36.588]] [[0.032]
 [0.033]
 [0.032]
 [0.032]
 [0.032]]
printing an ep nov before normalisation:  49.72573280334473
printing an ep nov before normalisation:  45.71342719198765
maxi score, test score, baseline:  0.0041 0.0 0.0041
using explorer policy with actor:  0
printing an ep nov before normalisation:  41.1745161844514
printing an ep nov before normalisation:  49.2988490588401
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.052148050524347137, 0.052148050524347137, 0.1146127502383396, 0.302006849380317, 0.1146127502383396, 0.36447154909430945]
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.031]
 [0.031]
 [0.031]
 [0.031]] [[35.194]
 [35.194]
 [35.194]
 [35.194]
 [35.194]] [[0.031]
 [0.031]
 [0.031]
 [0.031]
 [0.031]]
printing an ep nov before normalisation:  37.441496716850395
Printing some Q and Qe and total Qs values:  [[0.03]
 [0.03]
 [0.03]
 [0.03]
 [0.03]] [[50.768]
 [48.418]
 [48.418]
 [48.418]
 [48.418]] [[0.03]
 [0.03]
 [0.03]
 [0.03]
 [0.03]]
printing an ep nov before normalisation:  37.437477111816406
Printing some Q and Qe and total Qs values:  [[0.029]
 [0.037]
 [0.037]
 [0.037]
 [0.037]] [[54.605]
 [58.723]
 [58.723]
 [58.723]
 [58.723]] [[0.029]
 [0.037]
 [0.037]
 [0.037]
 [0.037]]
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.052148050524347137, 0.052148050524347137, 0.1146127502383396, 0.302006849380317, 0.1146127502383396, 0.36447154909430945]
line 256 mcts: sample exp_bonus 55.35721892164348
maxi score, test score, baseline:  0.0041 0.0 0.0041
probs:  [0.052148050524347137, 0.052148050524347137, 0.1146127502383396, 0.302006849380317, 0.1146127502383396, 0.36447154909430945]
using explorer policy with actor:  0
using explorer policy with actor:  0
printing an ep nov before normalisation:  29.387265090371535
actor:  0 policy actor:  1  step number:  40 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
maxi score, test score, baseline:  0.0061 0.0 0.0061
Printing some Q and Qe and total Qs values:  [[0.101]
 [0.092]
 [0.091]
 [0.051]
 [0.086]] [[27.332]
 [28.406]
 [26.712]
 [33.103]
 [29.302]] [[0.101]
 [0.092]
 [0.091]
 [0.051]
 [0.086]]
line 256 mcts: sample exp_bonus 39.48873996734619
actor:  0 policy actor:  1  step number:  41 total reward:  1.0  reward:  1.0 rdn_beta:  2.0
Printing some Q and Qe and total Qs values:  [[0.121]
 [0.104]
 [0.121]
 [0.121]
 [0.121]] [[34.757]
 [49.396]
 [34.757]
 [34.757]
 [34.757]] [[0.121]
 [0.104]
 [0.121]
 [0.121]
 [0.121]]
Printing some Q and Qe and total Qs values:  [[0.098]
 [0.098]
 [0.098]
 [0.098]
 [0.098]] [[30.78]
 [30.78]
 [30.78]
 [30.78]
 [30.78]] [[0.098]
 [0.098]
 [0.098]
 [0.098]
 [0.098]]
printing an ep nov before normalisation:  52.92892134370758
actions average: 
K:  4  action  0 :  tensor([    0.9849,     0.0000,     0.0000,     0.0001,     0.0150],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9431,     0.0043,     0.0002,     0.0520],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0002,     0.9714,     0.0141,     0.0143],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0324, 0.0036, 0.0358, 0.7485, 0.1796], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0035, 0.1058, 0.0021, 0.1697, 0.7189], grad_fn=<DivBackward0>)
line 256 mcts: sample exp_bonus 58.62555303619861
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
printing an ep nov before normalisation:  42.67384488184672
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
printing an ep nov before normalisation:  19.20576067863879
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
Printing some Q and Qe and total Qs values:  [[0.119]
 [0.121]
 [0.153]
 [0.123]
 [0.138]] [[36.855]
 [27.887]
 [18.655]
 [33.013]
 [20.557]] [[0.119]
 [0.121]
 [0.153]
 [0.123]
 [0.138]]
maxi score, test score, baseline:  0.0081 0.0 0.0081
printing an ep nov before normalisation:  26.584239505460136
printing an ep nov before normalisation:  49.87044453288882
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
printing an ep nov before normalisation:  21.197552947406486
printing an ep nov before normalisation:  69.08785283817609
printing an ep nov before normalisation:  41.95887301088411
printing an ep nov before normalisation:  41.91983281484673
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
using explorer policy with actor:  1
printing an ep nov before normalisation:  54.99487387875327
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
printing an ep nov before normalisation:  20.65349578857422
printing an ep nov before normalisation:  26.67670279480446
printing an ep nov before normalisation:  38.28527094737922
using explorer policy with actor:  0
printing an ep nov before normalisation:  14.983541221067112
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
printing an ep nov before normalisation:  24.87233669514554
printing an ep nov before normalisation:  47.80918952223425
Printing some Q and Qe and total Qs values:  [[0.072]
 [0.028]
 [0.072]
 [0.072]
 [0.047]] [[18.337]
 [17.038]
 [18.337]
 [18.337]
 [22.407]] [[0.072]
 [0.028]
 [0.072]
 [0.072]
 [0.047]]
maxi score, test score, baseline:  0.0081 0.0 0.0081
maxi score, test score, baseline:  0.0081 0.0 0.0081
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
printing an ep nov before normalisation:  32.329019560756166
maxi score, test score, baseline:  0.0081 0.0 0.0081
using explorer policy with actor:  0
maxi score, test score, baseline:  0.0081 0.0 0.0081
probs:  [0.05214806451336964, 0.05214806451336964, 0.1146127565969862, 0.30200683284783586, 0.1146127565969862, 0.3644715249314524]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  38.40133833370988
using explorer policy with actor:  1
printing an ep nov before normalisation:  56.57438042948859
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  47.30917491194528
printing an ep nov before normalisation:  57.84966166600593
printing an ep nov before normalisation:  34.95848672759526
printing an ep nov before normalisation:  49.729177844258366
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
siam score:  -0.92058593
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  34.66838142424162
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
actions average: 
K:  1  action  0 :  tensor([    0.9674,     0.0088,     0.0028,     0.0004,     0.0205],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0207,     0.9090,     0.0026,     0.0001,     0.0676],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0047,     0.0004,     0.9171,     0.0163,     0.0614],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0008,     0.0030,     0.0123,     0.8794,     0.1045],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0735, 0.0491, 0.0110, 0.1349, 0.7314], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  62.0428491591483
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
actions average: 
K:  0  action  0 :  tensor([    0.8158,     0.0571,     0.0022,     0.0005,     0.1243],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0158,     0.8765,     0.0143,     0.0004,     0.0930],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0006,     0.0002,     0.9536,     0.0209,     0.0247],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0007,     0.0005,     0.0193,     0.8712,     0.1083],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0785, 0.1513, 0.0265, 0.2311, 0.5126], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
actions average: 
K:  4  action  0 :  tensor([    0.9137,     0.0162,     0.0020,     0.0002,     0.0679],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0167,     0.8908,     0.0058,     0.0002,     0.0865],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0041,     0.0000,     0.9527,     0.0236,     0.0196],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0059,     0.0002,     0.0289,     0.8731,     0.0919],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.1316, 0.1837, 0.0050, 0.0719, 0.6078], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  25.123941898345947
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  68.5213141105964
printing an ep nov before normalisation:  48.94991042084722
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
siam score:  -0.9294332
Printing some Q and Qe and total Qs values:  [[0.101]
 [0.085]
 [0.085]
 [0.085]
 [0.085]] [[89.478]
 [75.041]
 [75.041]
 [75.041]
 [75.041]] [[1.84 ]
 [1.463]
 [1.463]
 [1.463]
 [1.463]]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  43.58680725097656
printing an ep nov before normalisation:  29.292287826538086
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  52.96931254836511
printing an ep nov before normalisation:  50.38748528072474
Printing some Q and Qe and total Qs values:  [[0.06 ]
 [0.055]
 [0.06 ]
 [0.06 ]
 [0.06 ]] [[33.641]
 [41.06 ]
 [33.641]
 [33.641]
 [33.641]] [[0.605]
 [0.83 ]
 [0.605]
 [0.605]
 [0.605]]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
Printing some Q and Qe and total Qs values:  [[0.064]
 [0.064]
 [0.065]
 [0.064]
 [0.064]] [[41.54 ]
 [41.54 ]
 [50.679]
 [41.54 ]
 [41.54 ]] [[0.889]
 [0.889]
 [1.171]
 [0.889]
 [0.889]]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  46.806982821466995
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  42.244393640706384
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.9287964
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  87.44553827696834
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
siam score:  -0.92817503
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  8.272069749182265e-05
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  14482
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  38.1178290316774
line 256 mcts: sample exp_bonus 0.0
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  55.564592990425375
actions average: 
K:  0  action  0 :  tensor([    0.9977,     0.0000,     0.0008,     0.0001,     0.0014],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0301,     0.8919,     0.0003,     0.0004,     0.0773],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0004,     0.0139,     0.9112,     0.0248,     0.0497],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0112, 0.0073, 0.0085, 0.7736, 0.1993], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0318, 0.1693, 0.0010, 0.1680, 0.6298], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  43.72512348984352
printing an ep nov before normalisation:  28.28793102402383
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
siam score:  -0.91850877
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
siam score:  -0.9169197
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
actions average: 
K:  0  action  0 :  tensor([    0.9539,     0.0074,     0.0003,     0.0031,     0.0353],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0064,     0.9369,     0.0002,     0.0009,     0.0555],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0060,     0.0004,     0.9321,     0.0206,     0.0408],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0004,     0.0001,     0.0112,     0.8455,     0.1427],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0885, 0.1572, 0.0749, 0.0113, 0.6680], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
Printing some Q and Qe and total Qs values:  [[0.028]
 [0.03 ]
 [0.03 ]
 [0.03 ]
 [0.03 ]] [[42.883]
 [41.238]
 [41.238]
 [41.238]
 [41.238]] [[0.695]
 [0.659]
 [0.659]
 [0.659]
 [0.659]]
printing an ep nov before normalisation:  44.70978999123139
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  54.51119990185972
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  50.213957721608494
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  52.55883919932916
printing an ep nov before normalisation:  44.364271971383886
actions average: 
K:  4  action  0 :  tensor([    0.9784,     0.0010,     0.0009,     0.0104,     0.0093],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0002,     0.8815,     0.0010,     0.0000,     0.1173],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9938,     0.0025,     0.0036],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0279,     0.0006,     0.0217,     0.8773,     0.0725],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0868, 0.1248, 0.0501, 0.0270, 0.7114], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
using explorer policy with actor:  1
printing an ep nov before normalisation:  52.27820452326153
Printing some Q and Qe and total Qs values:  [[0.018]
 [0.   ]
 [0.017]
 [0.019]
 [0.016]] [[51.112]
 [33.242]
 [41.253]
 [35.218]
 [47.928]] [[0.018]
 [0.   ]
 [0.017]
 [0.019]
 [0.016]]
printing an ep nov before normalisation:  97.42010998884224
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
printing an ep nov before normalisation:  53.54955740852833
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  63.44568236230052
printing an ep nov before normalisation:  53.503002372875606
printing an ep nov before normalisation:  39.56560866870151
siam score:  -0.8958809
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  45.56095140284873
siam score:  -0.89643645
Printing some Q and Qe and total Qs values:  [[0.019]
 [0.026]
 [0.023]
 [0.002]
 [0.024]] [[36.82 ]
 [30.688]
 [32.593]
 [24.164]
 [32.99 ]] [[1.532]
 [1.286]
 [1.361]
 [0.993]
 [1.379]]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
siam score:  -0.89799887
printing an ep nov before normalisation:  31.667017350067677
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  50.89274816793994
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
using another actor
maxi score, test score, baseline:  0.0081 0.1 0.1
printing an ep nov before normalisation:  57.105144544393994
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
printing an ep nov before normalisation:  44.468927396281565
maxi score, test score, baseline:  0.0081 0.1 0.1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  25.708726750066923
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
Printing some Q and Qe and total Qs values:  [[0.028]
 [0.025]
 [0.026]
 [0.026]
 [0.026]] [[27.761]
 [29.09 ]
 [39.403]
 [31.89 ]
 [29.994]] [[0.028]
 [0.025]
 [0.026]
 [0.026]
 [0.026]]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  37.59987454231539
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  44.43215114506506
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
Printing some Q and Qe and total Qs values:  [[0.024]
 [0.023]
 [0.024]
 [0.024]
 [0.024]] [[88.587]
 [89.262]
 [96.532]
 [94.497]
 [88.587]] [[1.755]
 [1.77 ]
 [1.936]
 [1.891]
 [1.755]]
actions average: 
K:  4  action  0 :  tensor([    0.9107,     0.0448,     0.0003,     0.0002,     0.0441],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9228,     0.0001,     0.0002,     0.0768],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0014,     0.9389,     0.0289,     0.0308],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0028, 0.0035, 0.0018, 0.8595, 0.1323], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0906, 0.1388, 0.0032, 0.0858, 0.6815], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  38.40345859527588
maxi score, test score, baseline:  0.0081 0.1 0.1
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.032]
 [0.031]
 [0.031]
 [0.031]] [[59.8  ]
 [58.755]
 [59.8  ]
 [59.8  ]
 [59.8  ]] [[1.841]
 [1.803]
 [1.841]
 [1.841]
 [1.841]]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  48.725881576538086
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  85.95250563868613
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  35.616214187849195
siam score:  -0.8823398
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  42.22095720472268
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
Printing some Q and Qe and total Qs values:  [[0.051]
 [0.07 ]
 [0.07 ]
 [0.064]
 [0.07 ]] [[47.565]
 [41.052]
 [41.052]
 [41.433]
 [41.052]] [[1.067]
 [0.888]
 [0.888]
 [0.893]
 [0.888]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
actions average: 
K:  1  action  0 :  tensor([    0.9940,     0.0000,     0.0001,     0.0007,     0.0051],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0236,     0.8910,     0.0005,     0.0005,     0.0844],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0003,     0.0004,     0.9308,     0.0187,     0.0498],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0013,     0.0000,     0.0324,     0.8087,     0.1577],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0676, 0.1963, 0.0428, 0.0670, 0.6263], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  32.35615253448486
printing an ep nov before normalisation:  51.0165250695412
printing an ep nov before normalisation:  102.77149712428536
printing an ep nov before normalisation:  56.14365129925333
Printing some Q and Qe and total Qs values:  [[0.033]
 [0.031]
 [0.033]
 [0.033]
 [0.033]] [[35.574]
 [42.287]
 [35.574]
 [35.574]
 [35.574]] [[0.921]
 [1.238]
 [0.921]
 [0.921]
 [0.921]]
maxi score, test score, baseline:  0.0081 0.1 0.1
Printing some Q and Qe and total Qs values:  [[0.029]
 [0.029]
 [0.004]
 [0.029]
 [0.029]] [[44.625]
 [44.625]
 [48.42 ]
 [44.625]
 [44.625]] [[1.731]
 [1.731]
 [2.004]
 [1.731]
 [1.731]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.12083625793457
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.034]
 [0.031]
 [0.026]
 [0.027]] [[49.431]
 [43.158]
 [49.431]
 [49.786]
 [50.085]] [[0.809]
 [0.624]
 [0.809]
 [0.815]
 [0.825]]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
printing an ep nov before normalisation:  49.19278321520623
printing an ep nov before normalisation:  37.75925874710083
printing an ep nov before normalisation:  51.634234474010235
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
printing an ep nov before normalisation:  78.22083179136938
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
Printing some Q and Qe and total Qs values:  [[0.027]
 [0.03 ]
 [0.031]
 [0.034]
 [0.03 ]] [[32.814]
 [39.656]
 [40.818]
 [36.907]
 [40.836]] [[0.472]
 [0.702]
 [0.741]
 [0.615]
 [0.741]]
printing an ep nov before normalisation:  30.26275634765625
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
siam score:  -0.89220613
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.30200639019421677, 0.11461292684837818, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
printing an ep nov before normalisation:  56.75212512069486
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
from probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
using explorer policy with actor:  0
printing an ep nov before normalisation:  64.99761259403027
printing an ep nov before normalisation:  44.65634274900149
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
using explorer policy with actor:  1
printing an ep nov before normalisation:  53.1162389792341
from probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
printing an ep nov before normalisation:  34.738769670205144
printing an ep nov before normalisation:  69.76463869707088
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.026]
 [0.026]
 [0.027]
 [0.026]
 [0.022]] [[80.998]
 [80.998]
 [78.779]
 [80.998]
 [84.17 ]] [[1.297]
 [1.297]
 [1.255]
 [1.297]
 [1.355]]
Printing some Q and Qe and total Qs values:  [[0.022]
 [0.025]
 [0.022]
 [0.022]
 [0.022]] [[57.9  ]
 [66.951]
 [57.9  ]
 [57.9  ]
 [57.9  ]] [[1.178]
 [1.487]
 [1.178]
 [1.178]
 [1.178]]
printing an ep nov before normalisation:  102.79779444500954
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
printing an ep nov before normalisation:  29.687505131874694
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
actions average: 
K:  0  action  0 :  tensor([    0.9766,     0.0014,     0.0043,     0.0005,     0.0173],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.8908,     0.0202,     0.0004,     0.0884],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9617,     0.0319,     0.0063],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0016,     0.0002,     0.0017,     0.8905,     0.1059],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0661, 0.1217, 0.0266, 0.1497, 0.6359], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
printing an ep nov before normalisation:  44.35345649719238
printing an ep nov before normalisation:  32.17945588341969
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
printing an ep nov before normalisation:  36.829653732530446
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
siam score:  -0.8896327
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
Printing some Q and Qe and total Qs values:  [[0.029]
 [0.03 ]
 [0.029]
 [0.029]
 [0.029]] [[42.869]
 [50.64 ]
 [42.869]
 [42.869]
 [42.869]] [[0.41 ]
 [0.559]
 [0.41 ]
 [0.41 ]
 [0.41 ]]
maxi score, test score, baseline:  0.0081 0.1 0.1
printing an ep nov before normalisation:  41.38975983258597
printing an ep nov before normalisation:  62.30137841811188
actions average: 
K:  4  action  0 :  tensor([    0.8755,     0.0301,     0.0004,     0.0013,     0.0927],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0049,     0.8700,     0.0008,     0.0006,     0.1236],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0001,     0.0360,     0.9422,     0.0110,     0.0107],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0196, 0.0009, 0.0196, 0.8208, 0.1390], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0707, 0.2374, 0.0313, 0.0599, 0.6007], grad_fn=<DivBackward0>)
UNIT TEST: sample policy line 217 mcts : [0.026 0.051 0.538 0.333 0.051]
printing an ep nov before normalisation:  63.154455084507504
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05561697563158484, 0.05561697563158484, 0.12224679025263394, 0.25550641949473213, 0.12224679025263394, 0.38876604873683035]
actor:  1 policy actor:  1  step number:  40 total reward:  1.0  reward:  1.0 rdn_beta:  1.667
printing an ep nov before normalisation:  58.08657834917607
printing an ep nov before normalisation:  29.919238090515137
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
printing an ep nov before normalisation:  55.962612524417246
Printing some Q and Qe and total Qs values:  [[0.036]
 [0.036]
 [0.034]
 [0.036]
 [0.036]] [[35.339]
 [35.339]
 [49.594]
 [35.339]
 [35.339]] [[1.083]
 [1.083]
 [1.786]
 [1.083]
 [1.083]]
printing an ep nov before normalisation:  62.41584561180478
printing an ep nov before normalisation:  53.28490777995158
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
printing an ep nov before normalisation:  49.79430675506592
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
printing an ep nov before normalisation:  33.02716653029839
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
siam score:  -0.88453
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
printing an ep nov before normalisation:  67.87371870971033
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
Printing some Q and Qe and total Qs values:  [[0.021]
 [0.   ]
 [0.021]
 [0.023]
 [0.02 ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.021]
 [0.   ]
 [0.021]
 [0.023]
 [0.02 ]]
from probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
printing an ep nov before normalisation:  53.37397318096085
maxi score, test score, baseline:  0.0081 0.1 0.1
printing an ep nov before normalisation:  48.77564654582224
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0081 0.1 0.1
printing an ep nov before normalisation:  57.34578329012976
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
maxi score, test score, baseline:  0.0081 0.1 0.1
probs:  [0.05214843906643198, 0.05214843906643198, 0.11461292684837818, 0.23954190241227058, 0.17707741463032436, 0.36447087797616295]
printing an ep nov before normalisation:  38.800415042863
maxi score, test score, baseline:  0.0081 0.1 0.1
printing an ep nov before normalisation:  36.66763122421315
