dirichlet_alpha:0.3
noise:0.3
dirichlet_alpha:0.5
noise:0.5
sims:{-1: 6, 6000: 40}
c1:1
c2:19652
temperature_init:1
temperature_changes:{-1: 1, 3000000.0: 0.5}
manual_over_ride_play_limit:None
exponent_node_n:1
ucb_denom_k:1
use_policy:True
model_expV_on_dones:True
norm_Qs_OnMaxi:True
norm_Qs_OnAll:True
norm_each_turn:False
state_channels:64
res_block_kernel_size:3
res_block_channels:[32, 32, 64, 64, 64]
res_block_ds:[False, True, False, False, False]
conv1:{'channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1}
conv2:{'channels': 64, 'kernel_size': 3, 'stride': 2, 'padding': 1}
reward_support:[-1, 1, 51]
conv1:{'kernel_size': 3, 'stride': 1, 'padding': 1}
res_blocks:[64]
reward_conv_channels:32
reward_hidden_dim:128
terminal_conv_channels:32
terminal_hidden_dim:64
value_support:[-1, 1, 51]
res_block:[64]
value_conv_channels:32
value_hidden_dim:128
policy_conv_channels:32
policy_hidden_dim:128
expV_conv_channels:32
expV_hidden_dim:128
expV_support:[-10, 10, 51]
proj_l1:256
proj_out:128
pred_hid:256
replay_buffer_size:50000
replay_buffer_size_exploration:200000
all_time_buffer_size:200000
batch_size:128
play_workers:2
min_workers:1
max_workers:6
lr:0.001
lr_warmup:1000
lr_decay:1
lr_decay_step:100000
optimizer:<class 'torch.optim.rmsprop.RMSprop'>
momentum:0.9
l2:0.0001
rho:0.99
k:5
value:0.25
dones:2.0
siam:2
rdn:0.5
expV:0.5
train_start_batch_multiple:2
prioritised_replay:True
ep_to_batch_ratio:[15, 16]
main_to_rdn_ratio:2
train_to_RS_ratio:4
on_policy_expV:False
rgb_im:True
channels:3
state_size:[6, 6]
timesteps_in_obs:2
store_prev_actions:True
env:<class 'game_play.frozen_lake_KEY.gridWorld'>
same_env_each_time:True
env_size:[7, 7]
observable_size:[7, 7]
game_modes:2
env_map:[['H' 'H' 'H' 'H' 'H' 'F' 'G']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F']
 ['S' 'F' 'H' 'H' 'H' 'H' 'H']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'K' 'F']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']]
max_steps:100
actions_size:5
optimal_score:1
total_frames:305000
exp_gamma:0.95
atari_env:False
reward_clipping:False
memory_size:100
image_size:[48, 48]
deque_length:3
PRESET_CONFIG:6
VK:True
use_two_heads:True
follow_better_policy:0.5
use_siam:True
exploration_type:episodic
rdn_beta:[1, 3, 5]
explorer_percentage:0.8
reward_exploration:False
train_dones:True
contrast_vector:False
norm_state_vecs:False
RND_output_vector:256
RND_loss:cosine
prediction_bias:True
distance_measure:False
update_play_model:16
gamma:0.99
calc_n_step_rewards_after_frames:10000
N_steps_reward:5
start_frame_count:0
load_in_model:False
log_states:True
log_metrics:False
exploration_logger_dims:(2, 49)
device_train:cpu
device_selfplay:cpu
eval_x_frames:10000
eval_count:20
detach_expV_calc:True
use_new_episode_expV:False
start_training_expV_min:10000
start_training_expV_max:20000
start_training_expV_siam_override:0.8
value_only:False
[['H' 'H' 'H' 'H' 'H' 'F' 'G']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'F' 'F']
 ['S' 'F' 'H' 'H' 'H' 'H' 'H']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']
 ['F' 'F' 'F' 'F' 'F' 'K' 'F']
 ['F' 'F' 'H' 'H' 'F' 'F' 'F']]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  6.232033967971802
printing an ep nov before normalisation:  6.02347195148468
using explorer policy with actor:  1
from probs:  [0.2, 0.2, 0.2, 0.2, 0.2]
UNIT TEST: sample policy line 217 mcts : [0. 0. 0. 0. 1.]
printing an ep nov before normalisation:  6.17883563041687
Printing some Q and Qe and total Qs values:  [[ 1.5  ]
 [ 1.5  ]
 [ 1.5  ]
 [-0.002]
 [ 1.5  ]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 1.5  ]
 [ 1.5  ]
 [ 1.5  ]
 [-0.002]
 [ 1.5  ]]
Printing some Q and Qe and total Qs values:  [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[6.166]
 [4.657]
 [4.657]
 [4.657]
 [4.657]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]]
Starting evaluation
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  5.676863023212978
siam score:  0.011198296253992752
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
deleting a thread, now have 2 threads
Frames:  1385 train batches done:  25 episodes:  92
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
actions average: 
K:  2  action  0 :  tensor([0.3574, 0.1309, 0.1140, 0.1939, 0.2039], grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.1541, 0.5073, 0.1320, 0.0220, 0.1846], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.1371, 0.1836, 0.3077, 0.1532, 0.2184], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.1254, 0.0093, 0.2524, 0.4221, 0.1908], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.1611, 0.1111, 0.2594, 0.2180, 0.2505], grad_fn=<DivBackward0>)
deleting a thread, now have 1 threads
Frames:  1385 train batches done:  68 episodes:  92
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.38767257
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.5084311
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.59504545
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.5922881
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
siam score:  -0.5585961
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.55910563
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5440903
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  30.164010524749756
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.5475867
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.5243024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  35.92049598693848
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5032312
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.51159185
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([0.7115, 0.1423, 0.0056, 0.0513, 0.0893], grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0635, 0.7058, 0.0368, 0.0022, 0.1918], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([0.0285, 0.1045, 0.5012, 0.1849, 0.1809], grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.2181, 0.0213, 0.1039, 0.4362, 0.2205], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.1496, 0.2069, 0.1877, 0.2081, 0.2477], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  70.16515135765076
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  15.861191462820065
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.56248915
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
printing an ep nov before normalisation:  52.989952144769205
printing an ep nov before normalisation:  25.463877652406698
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.5704354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  51.588266718134335
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  42.82489779164853
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.9800,     0.0010,     0.0003,     0.0078,     0.0109],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0058,     0.9868,     0.0004,     0.0001,     0.0068],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0011,     0.9071,     0.0436,     0.0480],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0098, 0.0009, 0.0393, 0.6452, 0.3047], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0191, 0.0107, 0.0608, 0.4565, 0.4530], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  90.06009896596274
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  46.865620613098145
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9873,     0.0004,     0.0005,     0.0047,     0.0071],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0112, 0.9059, 0.0221, 0.0011, 0.0597], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([0.0020, 0.0013, 0.9147, 0.0431, 0.0390], grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0122, 0.0086, 0.0225, 0.5539, 0.4029], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0094, 0.0091, 0.0677, 0.3097, 0.6041], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.702211
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.8470,     0.0030,     0.0001,     0.0750,     0.0749],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0036,     0.9652,     0.0046,     0.0002,     0.0265],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0008,     0.8265,     0.0669,     0.1057],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0653, 0.0013, 0.0453, 0.6268, 0.2613], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.3474, 0.0238, 0.0255, 0.2338, 0.3696], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
siam score:  -0.69791013
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  1  action  0 :  tensor([    0.9837,     0.0003,     0.0000,     0.0061,     0.0099],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0082,     0.9857,     0.0026,     0.0001,     0.0033],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0007,     0.8652,     0.0674,     0.0667],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0083, 0.0007, 0.0235, 0.6941, 0.2734], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0612, 0.0183, 0.0923, 0.3453, 0.4829], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.8932,     0.0052,     0.0002,     0.0301,     0.0712],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0087,     0.9700,     0.0090,     0.0007,     0.0117],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0001,     0.0073,     0.8473,     0.0446,     0.1007],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.1510, 0.0040, 0.1110, 0.5054, 0.2286], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.2322, 0.0115, 0.0151, 0.2994, 0.4418], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[1.5]
 [1.5]
 [1.5]
 [1.5]
 [1.5]] [[0]
 [0]
 [0]
 [0]
 [0]] [[1.5]
 [1.5]
 [1.5]
 [1.5]
 [1.5]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.72264636
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.9910,     0.0050,     0.0000,     0.0017,     0.0022],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0021,     0.9947,     0.0008,     0.0000,     0.0023],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0025,     0.9602,     0.0045,     0.0328],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0029,     0.0004,     0.0205,     0.6189,     0.3574],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0503, 0.0151, 0.0466, 0.3078, 0.5802], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  17.066027094314475
siam score:  -0.74364614
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.72433203
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.71317893
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([    0.8813,     0.0099,     0.0000,     0.0492,     0.0596],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0024,     0.9814,     0.0005,     0.0019,     0.0139],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0007,     0.0065,     0.8549,     0.0713,     0.0666],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0084, 0.0019, 0.0602, 0.6356, 0.2938], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0429, 0.0676, 0.1019, 0.2790, 0.5085], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  17.749188308350483
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.608]
 [20.899]
 [28.417]
 [32.213]
 [28.184]] [[0.731]
 [0.751]
 [1.277]
 [1.543]
 [1.261]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.71107805
siam score:  -0.7139276
printing an ep nov before normalisation:  28.069227439426925
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  125.34346573491646
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.9935,     0.0048,     0.0000,     0.0003,     0.0014],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0004,     0.9662,     0.0143,     0.0001,     0.0190],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9482,     0.0171,     0.0346],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0212, 0.0007, 0.0321, 0.6208, 0.3252], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0290, 0.0122, 0.0417, 0.2871, 0.6300], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  59.341934462279674
printing an ep nov before normalisation:  60.61615126769112
printing an ep nov before normalisation:  28.42283009456705
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.191]
 [20.424]
 [23.605]
 [34.648]
 [38.442]] [[0.552]
 [0.605]
 [0.74 ]
 [1.211]
 [1.372]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.40611716076085
printing an ep nov before normalisation:  22.39908559861655
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[16.059]
 [47.117]
 [33.557]
 [22.738]
 [47.117]] [[0.548]
 [2.214]
 [1.487]
 [0.906]
 [2.214]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.612]
 [84.612]
 [84.612]
 [84.612]
 [84.612]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.356]
 [59.356]
 [60.834]
 [58.902]
 [59.216]] [[1.546]
 [1.546]
 [1.587]
 [1.533]
 [1.542]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  55.61436903572482
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.906]
 [19.906]
 [43.975]
 [35.913]
 [19.906]] [[0.646]
 [0.646]
 [1.629]
 [1.3  ]
 [0.646]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.153]
 [30.21 ]
 [19.403]
 [22.553]
 [22.824]] [[1.398]
 [0.984]
 [0.422]
 [0.586]
 [0.6  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  10.089811898114723
printing an ep nov before normalisation:  43.97744642805593
printing an ep nov before normalisation:  13.592027009088953
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
printing an ep nov before normalisation:  23.013267624092624
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  54.61590522814446
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.225]
 [40.225]
 [40.225]
 [40.225]
 [40.225]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  41.479505916359656
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.41665357567079
siam score:  -0.7264637
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  65.75422745550297
printing an ep nov before normalisation:  85.61928480146192
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.063]
 [24.139]
 [29.309]
 [48.984]
 [ 9.152]] [[0.143]
 [0.548]
 [0.736]
 [1.455]
 [0.   ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  57.194935243822584
siam score:  -0.72989386
printing an ep nov before normalisation:  43.502367318843554
printing an ep nov before normalisation:  4.103007849173611
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[112.823]
 [112.823]
 [112.823]
 [109.984]
 [112.823]] [[2.5  ]
 [2.5  ]
 [2.5  ]
 [2.425]
 [2.5  ]]
printing an ep nov before normalisation:  89.74275361718314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  32.952775955200195
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.247]
 [85.247]
 [85.247]
 [85.247]
 [85.247]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
actions average: 
K:  2  action  0 :  tensor([    0.9395,     0.0012,     0.0000,     0.0067,     0.0526],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0039,     0.9832,     0.0075,     0.0002,     0.0052],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0195,     0.9401,     0.0099,     0.0305],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0947, 0.0010, 0.0317, 0.6574, 0.2152], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.1846, 0.0166, 0.0941, 0.2815, 0.4233], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  35.56724463220483
printing an ep nov before normalisation:  116.51360624592567
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  18.23363695068577
printing an ep nov before normalisation:  47.56823331781925
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.7665318
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.    0.59  0.026 0.333 0.051]
printing an ep nov before normalisation:  35.901668071746826
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.053]
 [72.053]
 [72.053]
 [72.053]
 [72.053]] [[1.919]
 [1.919]
 [1.919]
 [1.919]
 [1.919]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.528]
 [38.528]
 [38.528]
 [43.411]
 [38.528]] [[2.32 ]
 [2.32 ]
 [2.32 ]
 [2.649]
 [2.32 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  60.33513298393115
siam score:  -0.77153
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.7710672
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  9.155575037002563
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.9483,     0.0082,     0.0000,     0.0187,     0.0248],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9920,     0.0042,     0.0000,     0.0036],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9989,     0.0001,     0.0009],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0015, 0.0008, 0.0386, 0.7118, 0.2474], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0043, 0.0121, 0.0810, 0.2759, 0.6268], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[ 0.]
 [ 0.]
 [-0.]
 [-0.]
 [-0.]] [[13.328]
 [23.551]
 [15.554]
 [38.479]
 [36.788]] [[0.294]
 [0.905]
 [0.427]
 [1.797]
 [1.696]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  92.9357523952698
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.669]
 [38.669]
 [38.669]
 [38.323]
 [39.47 ]] [[2.325]
 [2.325]
 [2.325]
 [2.285]
 [2.418]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.345]
 [16.563]
 [13.233]
 [16.078]
 [16.563]] [[1.32 ]
 [0.793]
 [0.489]
 [0.749]
 [0.793]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.805]
 [21.805]
 [25.069]
 [21.805]
 [21.805]] [[0.657]
 [0.657]
 [1.026]
 [0.657]
 [0.657]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.7891861
printing an ep nov before normalisation:  36.28297665397475
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  40.98596288873098
printing an ep nov before normalisation:  45.82858318663817
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.575291576851672
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  23.266753318603318
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  56.85038089752197
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.293]
 [69.293]
 [11.046]
 [61.847]
 [76.851]] [[1.523]
 [1.523]
 [0.104]
 [1.342]
 [1.707]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[88.978]
 [88.978]
 [88.978]
 [88.978]
 [88.978]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
printing an ep nov before normalisation:  16.79208931160626
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[86.487]
 [86.487]
 [86.487]
 [78.683]
 [86.487]] [[1.947]
 [1.947]
 [1.947]
 [1.763]
 [1.947]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 2.802]
 [31.718]
 [14.53 ]
 [37.651]
 [31.718]] [[0.056]
 [1.157]
 [0.502]
 [1.383]
 [1.157]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  31.078876125263278
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  12.708675722745049
UNIT TEST: sample policy line 217 mcts : [0.359 0.128 0.256 0.077 0.179]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  59.208578967257466
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 4.701]
 [17.1  ]
 [11.893]
 [30.168]
 [ 8.624]] [[0.092]
 [0.551]
 [0.358]
 [1.036]
 [0.237]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 9.371]
 [ 9.825]
 [ 9.825]
 [14.873]
 [ 9.825]] [[0.851]
 [0.929]
 [0.929]
 [1.803]
 [0.929]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  84.59803809850001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 83.141]
 [154.002]
 [150.017]
 [144.49 ]
 [152.893]] [[1.313]
 [2.443]
 [2.379]
 [2.291]
 [2.425]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[135.008]
 [135.008]
 [135.008]
 [135.008]
 [135.008]] [[2.31]
 [2.31]
 [2.31]
 [2.31]
 [2.31]]
printing an ep nov before normalisation:  144.20746475575064
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  66.27329095868863
siam score:  -0.7836052
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.408]
 [56.408]
 [24.011]
 [57.072]
 [56.408]] [[1.359]
 [1.359]
 [0.48 ]
 [1.377]
 [1.359]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.761588454246521
printing an ep nov before normalisation:  21.755204047715004
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.845876287248074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  22.167799988334416
printing an ep nov before normalisation:  27.04569106691859
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.7634906
printing an ep nov before normalisation:  104.54697785978314
printing an ep nov before normalisation:  15.532125845131477
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 8.417]
 [19.443]
 [16.083]
 [29.757]
 [22.321]] [[0.126]
 [0.371]
 [0.296]
 [0.599]
 [0.434]]
using explorer policy with actor:  1
using explorer policy with actor:  1
printing an ep nov before normalisation:  10.287547261077087
printing an ep nov before normalisation:  5.149881839752197
siam score:  -0.76738685
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 5.446]
 [24.931]
 [20.687]
 [ 7.83 ]
 [24.931]] [[0.137]
 [1.015]
 [0.823]
 [0.244]
 [1.015]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  14.194884802862303
Starting evaluation
Sims:  40 1 epoch:  10097 pick best:  True frame count:  10097
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 7.104]
 [15.192]
 [ 6.673]
 [26.887]
 [13.948]] [[0.208]
 [0.447]
 [0.195]
 [0.792]
 [0.41 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  10.835177657652409
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  9.738525748252869
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.753]
 [41.753]
 [37.585]
 [55.776]
 [41.753]] [[0.364]
 [0.364]
 [0.32 ]
 [0.514]
 [0.364]]
printing an ep nov before normalisation:  57.95517868178278
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  10.812828223238176
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  4.655602072758986
printing an ep nov before normalisation:  63.82752546798699
printing an ep nov before normalisation:  54.63804337178526
printing an ep nov before normalisation:  102.49272297231367
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  42.052042953993954
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  58.84836951972355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  56.28030469918477
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.661]
 [12.661]
 [12.661]
 [12.661]
 [12.661]] [[0.205]
 [0.205]
 [0.205]
 [0.205]
 [0.205]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.436]
 [26.436]
 [26.436]
 [71.088]
 [26.436]] [[0.65 ]
 [0.65 ]
 [0.65 ]
 [1.858]
 [0.65 ]]
STARTED EXPV TRAINING ON FRAME NO.  10507
printing an ep nov before normalisation:  23.259393146427726
printing an ep nov before normalisation:  22.365077652060368
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9722,     0.0002,     0.0000,     0.0158,     0.0118],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0021,     0.9794,     0.0007,     0.0003,     0.0174],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9355,     0.0330,     0.0315],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0064,     0.0002,     0.0136,     0.7320,     0.2478],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0825, 0.0034, 0.0532, 0.3585, 0.5024], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  91.05506896972656
printing an ep nov before normalisation:  68.460813439834
printing an ep nov before normalisation:  12.534262427395007
siam score:  -0.80783373
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9850,     0.0049,     0.0000,     0.0016,     0.0086],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0032,     0.9642,     0.0166,     0.0000,     0.0160],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0001,     0.9531,     0.0170,     0.0298],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0067, 0.0071, 0.0301, 0.7077, 0.2484], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0133, 0.0128, 0.0027, 0.5886, 0.3827], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  88.55091622627343
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  102.85935161730336
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  44.086629829246014
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 91.781]
 [ 91.781]
 [ 91.409]
 [105.948]
 [136.878]] [[1.12 ]
 [1.12 ]
 [1.113]
 [1.384]
 [1.961]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  43.44598100324942
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  3.410193920135498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  104.8439981001479
printing an ep nov before normalisation:  82.79186122790362
printing an ep nov before normalisation:  25.435458667274254
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  84.21147260483653
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  16.012952527376157
using explorer policy with actor:  1
printing an ep nov before normalisation:  58.82731914520264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.9964,     0.0004,     0.0000,     0.0005,     0.0026],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0190,     0.9676,     0.0008,     0.0004,     0.0122],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9523,     0.0074,     0.0403],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0070,     0.0004,     0.0625,     0.6767,     0.2534],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0106, 0.0020, 0.0425, 0.3394, 0.6055], grad_fn=<DivBackward0>)
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.609]
 [ 4.204]
 [19.808]
 [55.86 ]
 [58.5  ]] [[0.435]
 [0.038]
 [0.374]
 [1.151]
 [1.208]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.569]
 [69.569]
 [69.569]
 [82.041]
 [69.569]] [[1.68]
 [1.68]
 [1.68]
 [2.  ]
 [1.68]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.817145
printing an ep nov before normalisation:  102.68828844917282
printing an ep nov before normalisation:  104.82506041163103
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  26.16616328689049
printing an ep nov before normalisation:  31.71915311426164
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8052368
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  34.20127436382106
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  79.34596962666018
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 8.201]
 [14.448]
 [23.902]
 [46.133]
 [37.94 ]] [[0.065]
 [0.237]
 [0.496]
 [1.105]
 [0.88 ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.475]
 [16.789]
 [17.959]
 [44.306]
 [35.589]] [[0.765]
 [0.577]
 [0.659]
 [2.5  ]
 [1.891]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  80.580371520581
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.403]
 [51.021]
 [56.453]
 [66.395]
 [74.822]] [[1.075]
 [1.539]
 [1.776]
 [2.21 ]
 [2.578]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.254]
 [50.254]
 [44.977]
 [60.931]
 [50.254]] [[1.709]
 [1.709]
 [1.484]
 [2.163]
 [1.709]]
siam score:  -0.8113221
printing an ep nov before normalisation:  161.2950021627175
printing an ep nov before normalisation:  91.78513350481761
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.234]
 [68.234]
 [80.719]
 [68.234]
 [68.234]] [[0.785]
 [0.785]
 [0.947]
 [0.785]
 [0.785]]
printing an ep nov before normalisation:  69.14005394602654
siam score:  -0.812475
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.209545253491545
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[64.26 ]
 [64.26 ]
 [64.26 ]
 [60.785]
 [64.26 ]] [[3.   ]
 [3.   ]
 [3.   ]
 [2.779]
 [3.   ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.915]
 [30.686]
 [37.582]
 [43.37 ]
 [37.582]] [[0.823]
 [1.085]
 [1.397]
 [1.66 ]
 [1.397]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  32.02855609779476
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  38.39742089178031
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.589977448788237
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[  6.248]
 [  6.248]
 [  6.248]
 [107.767]
 [  6.248]] [[0.062]
 [0.062]
 [0.062]
 [1.975]
 [0.062]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  7.8052777975180625
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  131.30223823080723
printing an ep nov before normalisation:  72.2254861146763
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.215]
 [11.215]
 [11.215]
 [11.215]
 [11.215]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 62.485]
 [ 62.485]
 [122.897]
 [ 59.119]
 [ 62.485]] [[1.085]
 [1.085]
 [2.227]
 [1.021]
 [1.085]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  4  action  0 :  tensor([    0.9613,     0.0065,     0.0000,     0.0184,     0.0137],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9921,     0.0003,     0.0006,     0.0067],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0005,     0.0012,     0.8722,     0.0211,     0.1050],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0027,     0.0006,     0.0190,     0.7586,     0.2191],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0008, 0.0226, 0.0286, 0.3061, 0.6419], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8123738
actions average: 
K:  4  action  0 :  tensor([    0.9165,     0.0007,     0.0000,     0.0530,     0.0298],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0065, 0.9273, 0.0093, 0.0012, 0.0557], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0023,     0.9293,     0.0584,     0.0100],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([0.0048, 0.0019, 0.0742, 0.6976, 0.2215], grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0035, 0.0372, 0.1576, 0.2964, 0.5053], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9992,     0.0000,     0.0000,     0.0002,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0027,     0.9955,     0.0000,     0.0002,     0.0016],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0002,     0.9503,     0.0203,     0.0292],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0007,     0.0002,     0.0071,     0.7399,     0.2521],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0036, 0.0013, 0.0756, 0.4065, 0.5131], grad_fn=<DivBackward0>)
siam score:  -0.81047547
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
siam score:  -0.8144449
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.977]
 [39.409]
 [54.115]
 [61.557]
 [55.392]] [[1.119]
 [0.34 ]
 [0.645]
 [0.799]
 [0.672]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[105.949]
 [105.949]
 [105.949]
 [104.056]
 [105.949]] [[1.977]
 [1.977]
 [1.977]
 [1.937]
 [1.977]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 96.35783364151153
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  97.51799478579198
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  78.55058920418074
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.093]
 [26.219]
 [26.219]
 [34.734]
 [26.219]] [[1.471]
 [1.416]
 [1.416]
 [1.951]
 [1.416]]
printing an ep nov before normalisation:  103.25465388943789
line 256 mcts: sample exp_bonus 62.17930196098357
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.75757545
printing an ep nov before normalisation:  89.41389517188094
printing an ep nov before normalisation:  133.87495130661435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  28.115547274432654
printing an ep nov before normalisation:  82.11935828416394
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  13.918352945400423
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.561]
 [40.414]
 [40.414]
 [38.854]
 [40.414]] [[0.352]
 [1.301]
 [1.301]
 [1.248]
 [1.301]]
printing an ep nov before normalisation:  16.23365548766307
printing an ep nov before normalisation:  77.51232148639093
printing an ep nov before normalisation:  11.164474839780121
printing an ep nov before normalisation:  23.11544764061263
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  66.3619600134519
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  60.116506394824754
printing an ep nov before normalisation:  8.134969785749636
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  41.26974248867558
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.156]
 [52.156]
 [52.156]
 [52.156]
 [52.156]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  73.1536831248065
siam score:  -0.7712869
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  15.633989572525024
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.982]
 [15.982]
 [11.27 ]
 [26.128]
 [15.982]] [[0.338]
 [0.338]
 [0.148]
 [0.747]
 [0.338]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 39.4309663772583
printing an ep nov before normalisation:  55.13473637243471
printing an ep nov before normalisation:  34.20065955727002
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.658]
 [32.658]
 [32.658]
 [32.658]
 [32.658]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  28.461049355315726
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.8115434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.484]
 [20.995]
 [14.202]
 [19.007]
 [21.334]] [[1.402]
 [1.688]
 [1.135]
 [1.526]
 [1.715]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.368]
 [44.688]
 [44.688]
 [44.688]
 [44.688]] [[1.287]
 [0.847]
 [0.847]
 [0.847]
 [0.847]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  27.929028742757392
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  16.41958713531494
printing an ep nov before normalisation:  15.215573749674128
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  105.93292104983222
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  20.676005386702645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  66.40982595116384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
actions average: 
K:  3  action  0 :  tensor([    0.9703,     0.0089,     0.0052,     0.0008,     0.0148],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9975,     0.0000,     0.0008,     0.0017],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0005,     0.9347,     0.0308,     0.0341],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0021,     0.0006,     0.0115,     0.7273,     0.2585],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0289, 0.0152, 0.0471, 0.3730, 0.5357], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  75.37406812956382
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[76.954]
 [76.954]
 [76.954]
 [76.954]
 [76.954]] [[1.419]
 [1.419]
 [1.419]
 [1.419]
 [1.419]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  127.8647433663483
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 71.492]
 [ 71.492]
 [ 71.492]
 [102.461]
 [ 71.492]] [[1.457]
 [1.457]
 [1.457]
 [2.128]
 [1.457]]
printing an ep nov before normalisation:  32.703988552093506
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.1  ]
 [88.214]
 [26.82 ]
 [81.997]
 [66.416]] [[0.943]
 [2.085]
 [0.496]
 [1.924]
 [1.521]]
printing an ep nov before normalisation:  109.96191327710126
printing an ep nov before normalisation:  101.5139310366091
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.647]
 [12.905]
 [26.639]
 [55.456]
 [53.101]] [[0.541]
 [0.132]
 [0.489]
 [1.238]
 [1.177]]
printing an ep nov before normalisation:  91.45637648516924
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[101.548]
 [ 11.863]
 [ 26.632]
 [ 82.377]
 [101.548]] [[2.374]
 [0.04 ]
 [0.424]
 [1.875]
 [2.374]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.004]
 [21.004]
 [21.004]
 [38.042]
 [21.004]] [[0.488]
 [0.488]
 [0.488]
 [1.001]
 [0.488]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.837]
 [ 8.889]
 [38.852]
 [41.224]
 [13.562]] [[0.075]
 [0.   ]
 [0.758]
 [0.818]
 [0.118]]
siam score:  -0.83407927
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
printing an ep nov before normalisation:  23.30208778152253
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[58.526]
 [58.526]
 [21.115]
 [65.422]
 [58.526]] [[1.129]
 [1.129]
 [0.291]
 [1.284]
 [1.129]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  32.39558549851547
printing an ep nov before normalisation:  27.388831161506467
printing an ep nov before normalisation:  102.46083324495521
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  18.4560687743193
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.427]
 [48.734]
 [22.161]
 [68.521]
 [73.305]] [[0.162]
 [0.405]
 [0.15 ]
 [0.595]
 [0.64 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  18.888097368287617
printing an ep nov before normalisation:  46.31146641015454
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  33.032863145612616
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 1.3905636832224064e-07
0.0 3.583116861040204e-07
0.0 1.3905636832224064e-07
0.0 0.0
0.0 3.168245676623377e-07
0.0 3.654695598513332e-07
0.0 3.4388308379395664e-07
0.0 0.0
0.0 1.745255435225e-07
0.0 3.856547264543069e-07
printing an ep nov before normalisation:  136.2710719853181
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  30.686984062194824
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 83.61098741066648
printing an ep nov before normalisation:  41.813512342036944
siam score:  -0.8306097
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[82.328]
 [68.539]
 [68.539]
 [68.539]
 [68.539]] [[0.632]
 [0.476]
 [0.476]
 [0.476]
 [0.476]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  14.574465130409699
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  84.5543612667839
printing an ep nov before normalisation:  85.01038713499345
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  29.411036839550096
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.82834786
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[100.977]
 [100.977]
 [100.977]
 [100.977]
 [100.977]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.026 0.026 0.026 0.538 0.385]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.651]
 [21.651]
 [41.184]
 [49.994]
 [21.651]] [[0.225]
 [0.225]
 [0.612]
 [0.786]
 [0.225]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 47.17876946530891
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.9765,     0.0031,     0.0000,     0.0141,     0.0063],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0261,     0.9372,     0.0003,     0.0007,     0.0358],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9976,     0.0012,     0.0013],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0010,     0.0007,     0.0165,     0.8397,     0.1420],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0037, 0.0052, 0.0426, 0.4520, 0.4966], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  72.21936588026885
printing an ep nov before normalisation:  109.37579524300645
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.802]
 [53.802]
 [53.802]
 [80.529]
 [53.802]] [[0.665]
 [0.665]
 [0.665]
 [1.739]
 [0.665]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 9.314]
 [57.535]
 [47.774]
 [66.951]
 [57.359]] [[0.044]
 [1.358]
 [1.092]
 [1.614]
 [1.353]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[102.887]
 [102.887]
 [102.887]
 [107.093]
 [102.887]] [[2.169]
 [2.169]
 [2.169]
 [2.309]
 [2.169]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  75.46483039855957
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[107.62 ]
 [107.62 ]
 [107.62 ]
 [100.455]
 [107.62 ]] [[2.   ]
 [2.   ]
 [2.   ]
 [1.856]
 [2.   ]]
printing an ep nov before normalisation:  21.718287648141498
printing an ep nov before normalisation:  105.68460719999884
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  78.02380765597965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[49.548]
 [ 5.166]
 [85.87 ]
 [85.535]
 [63.886]] [[0.881]
 [0.   ]
 [1.601]
 [1.595]
 [1.165]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.83472824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.9045,     0.0351,     0.0002,     0.0220,     0.0382],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9966,     0.0000,     0.0009,     0.0025],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9980,     0.0016,     0.0004],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0016,     0.0006,     0.0190,     0.8107,     0.1681],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0181, 0.0944, 0.0177, 0.3402, 0.5297], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  51.16998987029106
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.068]
 [ 6.211]
 [40.462]
 [68.956]
 [18.117]] [[1.346]
 [0.   ]
 [0.872]
 [1.598]
 [0.303]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 93.483]
 [ 93.483]
 [ 93.483]
 [103.085]
 [ 93.483]] [[2.69]
 [2.69]
 [2.69]
 [3.  ]
 [2.69]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.82483935
actions average: 
K:  3  action  0 :  tensor([    0.9560,     0.0314,     0.0000,     0.0011,     0.0115],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     1.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0001,     0.9561,     0.0205,     0.0231],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0023, 0.0033, 0.0083, 0.7719, 0.2142], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0008, 0.0048, 0.0389, 0.3461, 0.6092], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  53.224197654767465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  19.523180276200947
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.9644,     0.0002,     0.0000,     0.0187,     0.0167],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0000,     0.9962,     0.0000,     0.0001,     0.0036],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9620,     0.0196,     0.0183],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0015,     0.0002,     0.0276,     0.7836,     0.1871],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0098, 0.0013, 0.0493, 0.3447, 0.5950], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  92.22683131322515
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  13.069268422270719
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.878]
 [10.852]
 [56.477]
 [35.004]
 [29.858]] [[0.94 ]
 [0.186]
 [1.68 ]
 [0.977]
 [0.809]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  100.7681226373378
using explorer policy with actor:  1
siam score:  -0.830985
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  82.71654249069043
printing an ep nov before normalisation:  27.35000834219465
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[78.382]
 [78.382]
 [78.382]
 [78.382]
 [78.382]] [[2.6]
 [2.6]
 [2.6]
 [2.6]
 [2.6]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.9968,     0.0001,     0.0000,     0.0010,     0.0022],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0011,     0.9316,     0.0221,     0.0452],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0057, 0.0027, 0.0060, 0.7712, 0.2144], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.1606, 0.0178, 0.0314, 0.2548, 0.5354], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.279]
 [ 3.777]
 [33.89 ]
 [71.63 ]
 [79.123]] [[2.889]
 [0.048]
 [1.111]
 [2.443]
 [2.707]]
printing an ep nov before normalisation:  5.100495563714827
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  40.06278366238152
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  144.17785107504187
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[102.574]
 [102.574]
 [112.154]
 [102.574]
 [102.574]] [[1.821]
 [1.821]
 [2.165]
 [1.821]
 [1.821]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  96.23624583231378
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  96.57229423522949
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.177]
 [60.177]
 [31.347]
 [53.684]
 [60.177]] [[1.393]
 [1.393]
 [0.645]
 [1.225]
 [1.393]]
printing an ep nov before normalisation:  20.44585800645865
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  14.27982816195827
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  112.41045720685834
printing an ep nov before normalisation:  61.408699700361396
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.159]
 [53.159]
 [53.159]
 [62.56 ]
 [53.159]] [[1.131]
 [1.131]
 [1.131]
 [1.377]
 [1.131]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  19.949329742709896
printing an ep nov before normalisation:  63.59530134107359
printing an ep nov before normalisation:  26.569479277290984
printing an ep nov before normalisation:  53.970080489893064
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  29.087585566208624
using explorer policy with actor:  1
printing an ep nov before normalisation:  32.4027033160252
printing an ep nov before normalisation:  100.5462424350099
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  16.659634113311768
printing an ep nov before normalisation:  21.866506670891024
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.104]
 [71.104]
 [22.688]
 [65.302]
 [71.104]] [[1.438]
 [1.438]
 [0.337]
 [1.306]
 [1.438]]
printing an ep nov before normalisation:  39.88564959410796
printing an ep nov before normalisation:  30.90609998649924
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.915]
 [13.564]
 [30.459]
 [58.7  ]
 [61.015]] [[0.439]
 [0.035]
 [0.48 ]
 [1.224]
 [1.284]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  81.39154302974337
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.3  ]
 [15.39 ]
 [39.581]
 [64.374]
 [19.046]] [[0.184]
 [0.023]
 [0.285]
 [0.553]
 [0.063]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8347835
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  11.330053170790567
siam score:  -0.8332541
printing an ep nov before normalisation:  26.721512806842853
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  93.52079780824184
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  122.673238085066
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  2.2336340206550176
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[9.657]
 [9.657]
 [9.657]
 [9.657]
 [4.673]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  117.87970271962297
printing an ep nov before normalisation:  51.66983127593994
printing an ep nov before normalisation:  133.31248195109367
printing an ep nov before normalisation:  94.54957984917965
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  80.34194946289062
printing an ep nov before normalisation:  27.195941785423035
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  75.65797660264661
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[39.218]
 [14.389]
 [13.402]
 [68.42 ]
 [61.156]] [[0.665]
 [0.025]
 [0.   ]
 [1.417]
 [1.229]]
printing an ep nov before normalisation:  91.27328889315424
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  38.524649461401744
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.829]
 [11.228]
 [21.677]
 [23.456]
 [19.221]] [[0.857]
 [0.522]
 [1.493]
 [1.658]
 [1.265]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  55.443179992746124
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.037]
 [23.037]
 [30.172]
 [46.614]
 [23.037]] [[0.136]
 [0.136]
 [0.216]
 [0.4  ]
 [0.136]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([    0.9905,     0.0003,     0.0000,     0.0012,     0.0079],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0000,     0.9994,     0.0000,     0.0000,     0.0005],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0014,     0.9400,     0.0450,     0.0136],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([0.0047, 0.0026, 0.0056, 0.7523, 0.2347], grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0580, 0.0823, 0.0023, 0.2136, 0.6439], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
actions average: 
K:  0  action  0 :  tensor([    0.9966,     0.0002,     0.0000,     0.0002,     0.0030],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0003,     0.9993,     0.0000,     0.0000,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0214,     0.0002,     0.9380,     0.0164,     0.0241],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0022, 0.0013, 0.0098, 0.7744, 0.2124], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0196, 0.0018, 0.0226, 0.4078, 0.5482], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  13.83585326874464
printing an ep nov before normalisation:  54.4084713807633
printing an ep nov before normalisation:  32.226714349113564
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  119.66717642856639
printing an ep nov before normalisation:  62.61637910870579
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  47.576248548128554
actions average: 
K:  1  action  0 :  tensor([    0.9994,     0.0000,     0.0000,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9944,     0.0001,     0.0002,     0.0052],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9992,     0.0002,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0020, 0.0031, 0.0009, 0.8331, 0.1609], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0148, 0.0023, 0.0595, 0.3835, 0.5399], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  10.386536064258822
printing an ep nov before normalisation:  32.84463882446289
siam score:  -0.834469
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  65.70668973856112
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  54.35462063055514
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  124.12069043678198
printing an ep nov before normalisation:  69.82047183355667
printing an ep nov before normalisation:  43.972485876541555
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  53.54406993617282
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.226]
 [47.226]
 [47.226]
 [49.213]
 [47.226]] [[2.373]
 [2.373]
 [2.373]
 [2.5  ]
 [2.373]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.415]
 [44.415]
 [44.415]
 [52.59 ]
 [44.415]] [[1.732]
 [1.732]
 [1.732]
 [2.106]
 [1.732]]
siam score:  -0.80915815
printing an ep nov before normalisation:  103.82329023612529
using explorer policy with actor:  1
printing an ep nov before normalisation:  19.1864013671875
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  74.82956636493944
printing an ep nov before normalisation:  31.992654798120714
printing an ep nov before normalisation:  30.033729016204802
using explorer policy with actor:  1
siam score:  -0.8405468
printing an ep nov before normalisation:  110.23680487592901
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  70.6954079938211
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  87.24665790004362
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  18.281901036476274
line 256 mcts: sample exp_bonus 34.3548679944635
printing an ep nov before normalisation:  12.574889547402673
printing an ep nov before normalisation:  9.887589547699225
printing an ep nov before normalisation:  65.02513494989337
siam score:  -0.8564527
line 256 mcts: sample exp_bonus 12.670909508796843
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  133.35753318166317
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  46.41844157013419
printing an ep nov before normalisation:  121.49011391970433
printing an ep nov before normalisation:  144.58009445643174
printing an ep nov before normalisation:  15.334309914267928
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.26 ]
 [22.16 ]
 [19.201]
 [66.611]
 [52.26 ]] [[1.084]
 [0.097]
 [0.   ]
 [1.555]
 [1.084]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  14.22335147857666
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  36.39351428114827
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 42.377]
 [ 30.869]
 [103.787]
 [ 44.291]
 [ 43.014]] [[0.338]
 [0.122]
 [1.488]
 [0.373]
 [0.349]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  84.53919287791307
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  95.8166145026692
siam score:  -0.8615969
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  55.348381041357364
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8580058
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.9997,     0.0000,     0.0000,     0.0002,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0024,     0.9442,     0.0000,     0.0474,     0.0060],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0001,     0.0001,     0.8974,     0.0302,     0.0722],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0001,     0.0054,     0.8307,     0.1632],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0023, 0.0058, 0.0394, 0.4233, 0.5292], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8568857
actions average: 
K:  3  action  0 :  tensor([    0.9217,     0.0003,     0.0000,     0.0072,     0.0708],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0007,     0.9934,     0.0026,     0.0001,     0.0033],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0002,     0.0001,     0.9045,     0.0265,     0.0687],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0007,     0.0007,     0.0007,     0.7887,     0.2092],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0004,     0.0015,     0.1194,     0.3860,     0.4925],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  80.60988992889975
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.828]
 [13.399]
 [20.977]
 [60.19 ]
 [20.505]] [[0.   ]
 [0.039]
 [0.225]
 [1.189]
 [0.213]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  76.39687794000646
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.05]
 [50.05]
 [50.05]
 [50.05]
 [50.05]] [[150.151]
 [150.151]
 [150.151]
 [150.151]
 [150.151]]
printing an ep nov before normalisation:  26.39026615631111
printing an ep nov before normalisation:  107.29855120519704
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.662]
 [42.53 ]
 [15.297]
 [49.619]
 [42.53 ]] [[0.159]
 [1.157]
 [0.276]
 [1.386]
 [1.157]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  17.198519706726074
siam score:  -0.85049826
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.979]
 [48.979]
 [25.357]
 [63.303]
 [48.979]] [[1.287]
 [1.287]
 [0.566]
 [1.724]
 [1.287]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  29.756697492699658
siam score:  -0.8497957
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[71.566]
 [71.399]
 [30.732]
 [78.294]
 [58.905]] [[0.568]
 [0.566]
 [0.165]
 [0.634]
 [0.443]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  98.38665184738886
printing an ep nov before normalisation:  51.76248518220583
printing an ep nov before normalisation:  54.08067226409912
printing an ep nov before normalisation:  8.624367117881775
printing an ep nov before normalisation:  28.151935491365144
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[29.339]
 [29.339]
 [29.339]
 [46.524]
 [29.339]] [[0.296]
 [0.296]
 [0.296]
 [1.   ]
 [0.296]]
siam score:  -0.8608429
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.86391604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[41.573]
 [41.573]
 [41.573]
 [41.573]
 [41.573]] [[0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]]
line 256 mcts: sample exp_bonus 35.20681435121025
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  24.89028914765042
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.9735,     0.0001,     0.0000,     0.0155,     0.0109],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9915,     0.0021,     0.0003,     0.0059],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0002,     0.9424,     0.0328,     0.0246],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0008,     0.0064,     0.7785,     0.2139],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0337, 0.0020, 0.0669, 0.5051, 0.3923], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  125.47485551547841
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  17.799841922857393
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  5.092424750328064
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.616]
 [28.616]
 [28.616]
 [57.935]
 [28.616]] [[0.385]
 [0.385]
 [0.385]
 [0.93 ]
 [0.385]]
siam score:  -0.8535677
line 256 mcts: sample exp_bonus 58.587792563657004
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  75.10860225342432
printing an ep nov before normalisation:  84.54831730121055
siam score:  -0.85511565
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  81.7694928851706
printing an ep nov before normalisation:  43.55363580300785
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 16.583]
 [109.104]
 [ 26.329]
 [ 99.041]
 [111.222]] [[0.119]
 [0.98 ]
 [0.21 ]
 [0.887]
 [1.   ]]
printing an ep nov before normalisation:  5.064095989605004
printing an ep nov before normalisation:  7.932272040203209
printing an ep nov before normalisation:  105.1067687204264
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  24.58240640763265
printing an ep nov before normalisation:  65.63264284506641
siam score:  -0.851763
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  24.910851205280707
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
printing an ep nov before normalisation:  157.8817877534033
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.314]
 [16.235]
 [42.046]
 [65.64 ]
 [15.58 ]] [[0.853]
 [0.013]
 [0.516]
 [0.977]
 [0.   ]]
printing an ep nov before normalisation:  100.78187590822503
printing an ep nov before normalisation:  96.88169412952516
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.517624526692454
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.736296958701397
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[85.233]
 [85.233]
 [85.233]
 [77.78 ]
 [85.233]] [[1.678]
 [1.678]
 [1.678]
 [1.46 ]
 [1.678]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8389244
printing an ep nov before normalisation:  88.5558894792722
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
printing an ep nov before normalisation:  88.83276454400502
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[129.246]
 [129.246]
 [129.246]
 [160.161]
 [129.246]] [[0.768]
 [0.768]
 [0.768]
 [0.97 ]
 [0.768]]
printing an ep nov before normalisation:  99.3332562371667
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.124]
 [72.124]
 [72.124]
 [88.298]
 [72.124]] [[0.706]
 [0.706]
 [0.706]
 [0.896]
 [0.706]]
using explorer policy with actor:  1
siam score:  -0.84682214
printing an ep nov before normalisation:  57.57742223810134
printing an ep nov before normalisation:  100.10030326108989
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.084]
 [87.084]
 [87.084]
 [94.123]
 [87.084]] [[1.383]
 [1.383]
 [1.383]
 [1.5  ]
 [1.383]]
printing an ep nov before normalisation:  99.44085050904101
siam score:  -0.84458894
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 42.59129422871544
printing an ep nov before normalisation:  94.57704102920219
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[42.503]
 [42.503]
 [42.503]
 [73.973]
 [42.503]] [[0.529]
 [0.529]
 [0.529]
 [0.968]
 [0.529]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  105.54085447965646
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[93.871]
 [93.871]
 [93.871]
 [87.689]
 [93.871]] [[1.396]
 [1.396]
 [1.396]
 [1.297]
 [1.396]]
siam score:  -0.8449454
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8521109
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 21.424]
 [ 94.795]
 [ 94.795]
 [123.849]
 [ 94.795]] [[0.251]
 [1.888]
 [1.888]
 [2.536]
 [1.888]]
printing an ep nov before normalisation:  120.11210572454601
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  87.87823778634728
printing an ep nov before normalisation:  30.088476971475792
printing an ep nov before normalisation:  86.2716047836408
printing an ep nov before normalisation:  79.13302898406982
printing an ep nov before normalisation:  96.11928702443254
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 97.56 ]
 [ 97.56 ]
 [ 26.471]
 [ 93.636]
 [106.734]] [[1.362]
 [1.362]
 [0.289]
 [1.302]
 [1.5  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 71.925]
 [ 48.487]
 [ 71.925]
 [116.726]
 [ 71.925]] [[1.206]
 [0.782]
 [1.206]
 [2.017]
 [1.206]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.824]
 [23.824]
 [23.824]
 [23.824]
 [23.824]] [[2.666]
 [2.666]
 [2.666]
 [2.666]
 [2.666]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  12.058525986237365
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  64.49552570929846
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.442]
 [ 6.508]
 [ 6.508]
 [ 6.508]
 [ 6.508]] [[0.467]
 [0.031]
 [0.031]
 [0.031]
 [0.031]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 19.87766146659851
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  33.42765808105469
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  11.586748727769605
printing an ep nov before normalisation:  100.34780777603984
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.068]
 [43.068]
 [43.068]
 [69.105]
 [43.068]] [[0.501]
 [0.501]
 [0.501]
 [1.348]
 [0.501]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.519622400935385
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  2  action  0 :  tensor([    0.9894,     0.0002,     0.0000,     0.0007,     0.0097],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0003,     0.9500,     0.0004,     0.0199,     0.0294],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9735,     0.0130,     0.0135],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0004,     0.0185,     0.0265,     0.7520,     0.2026],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([    0.0011,     0.0003,     0.0190,     0.4878,     0.4919],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  91.84565124027432
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  17.497374236694107
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.277]
 [27.277]
 [27.277]
 [59.117]
 [27.277]] [[0.448]
 [0.448]
 [0.448]
 [1.362]
 [0.448]]
printing an ep nov before normalisation:  108.04015371736213
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.535]
 [50.078]
 [11.205]
 [62.916]
 [ 8.245]] [[0.136]
 [0.661]
 [0.087]
 [0.85 ]
 [0.043]]
printing an ep nov before normalisation:  32.50603183902967
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  33.244853019714355
printing an ep nov before normalisation:  118.06800668524542
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  66.28572147087709
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  10.445108413696289
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  89.9327405267458
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  20.42811462677433
printing an ep nov before normalisation:  109.72570414183897
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.883]
 [17.447]
 [ 4.983]
 [ 6.728]
 [16.431]] [[1.968]
 [2.891]
 [0.823]
 [1.113]
 [2.722]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9983,     0.0006,     0.0000,     0.0005,     0.0006],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([0.0303, 0.9365, 0.0060, 0.0205, 0.0067], grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9702,     0.0142,     0.0156],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0003,     0.0001,     0.0066,     0.8332,     0.1597],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0040,     0.0013,     0.0005,     0.4438,     0.5504],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 99.654]
 [ 99.654]
 [ 41.071]
 [100.77 ]
 [107.002]] [[0.837]
 [0.837]
 [0.292]
 [0.848]
 [0.906]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.458]
 [63.593]
 [35.719]
 [69.446]
 [69.729]] [[0.403]
 [0.646]
 [0.31 ]
 [0.716]
 [0.72 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  74.77841162230634
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  64.05541258174149
printing an ep nov before normalisation:  72.57071681716813
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  13.219342231750488
line 256 mcts: sample exp_bonus 40.83453335249738
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  100.27402956964262
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  22.352601127681815
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  19.9854024131248
siam score:  -0.85098875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[143.669]
 [143.669]
 [143.669]
 [138.046]
 [143.669]] [[1.4  ]
 [1.4  ]
 [1.4  ]
 [1.302]
 [1.4  ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.457]
 [87.457]
 [87.457]
 [71.241]
 [87.457]] [[1.307]
 [1.307]
 [1.307]
 [1.048]
 [1.307]]
printing an ep nov before normalisation:  30.074245787576874
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  18.941390022318704
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[23.443]
 [21.144]
 [20.506]
 [56.573]
 [60.408]] [[0.33 ]
 [0.29 ]
 [0.278]
 [0.91 ]
 [0.978]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  26.84378973953492
printing an ep nov before normalisation:  85.5804846776249
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.095]
 [ 9.193]
 [16.776]
 [42.942]
 [14.143]] [[0.246]
 [0.04 ]
 [0.183]
 [0.677]
 [0.133]]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
line 256 mcts: sample exp_bonus 95.13469003494633
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  109.7855079158725
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[119.197]
 [119.197]
 [119.197]
 [119.197]
 [119.197]] [[3.]
 [3.]
 [3.]
 [3.]
 [3.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  105.2800954249761
printing an ep nov before normalisation:  39.772532028704575
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.86884856
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8686267
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8682272
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.9918,     0.0011,     0.0000,     0.0028,     0.0042],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0002,     0.9651,     0.0275,     0.0002,     0.0070],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9635,     0.0133,     0.0231],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([0.0023, 0.0011, 0.0089, 0.8142, 0.1735], grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0114, 0.0252, 0.0294, 0.4588, 0.4751], grad_fn=<DivBackward0>)
siam score:  -0.8630358
printing an ep nov before normalisation:  79.18062331505736
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.783]
 [11.161]
 [37.438]
 [49.381]
 [56.783]] [[2.432]
 [0.165]
 [1.471]
 [2.064]
 [2.432]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.428]
 [17.074]
 [27.906]
 [35.298]
 [10.205]] [[0.485]
 [0.372]
 [0.891]
 [1.244]
 [0.043]]
printing an ep nov before normalisation:  113.88516355952247
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.006]
 [45.006]
 [45.006]
 [54.388]
 [45.006]] [[1.173]
 [1.173]
 [1.173]
 [1.549]
 [1.173]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8314533
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  24.372823238372803
printing an ep nov before normalisation:  35.61517861675239
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  130.97064943852155
printing an ep nov before normalisation:  73.35637728325548
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  112.04444569795113
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.791]
 [34.791]
 [34.791]
 [34.791]
 [34.791]] [[1.]
 [1.]
 [1.]
 [1.]
 [1.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  28.985818840479585
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  102.0037414063788
printing an ep nov before normalisation:  114.71363409029814
printing an ep nov before normalisation:  74.08154576239379
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  118.75697198779598
printing an ep nov before normalisation:  120.00422412669057
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  7.898455859319526
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[45.932]
 [45.932]
 [23.86 ]
 [51.282]
 [12.795]] [[0.674]
 [0.674]
 [0.31 ]
 [0.762]
 [0.128]]
printing an ep nov before normalisation:  31.970518789959755
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  95.2286134696644
printing an ep nov before normalisation:  63.41122887323441
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.837]
 [12.966]
 [15.1  ]
 [52.697]
 [13.398]] [[0.352]
 [0.356]
 [0.414]
 [1.445]
 [0.367]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  106.70503825224564
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  65.67888871721999
line 256 mcts: sample exp_bonus 84.33800309989113
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8500092
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[69.887]
 [69.887]
 [69.887]
 [62.331]
 [69.887]] [[1.933]
 [1.933]
 [1.933]
 [1.637]
 [1.933]]
printing an ep nov before normalisation:  85.2184893871576
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 7.094]
 [22.784]
 [12.373]
 [51.814]
 [ 4.375]] [[0.037]
 [0.25 ]
 [0.108]
 [0.643]
 [0.   ]]
printing an ep nov before normalisation:  57.22166913490285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.84805536
printing an ep nov before normalisation:  53.45037663554339
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.479]
 [36.479]
 [36.479]
 [32.6  ]
 [36.479]] [[2.5  ]
 [2.5  ]
 [2.5  ]
 [2.145]
 [2.5  ]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[67.891]
 [67.891]
 [67.891]
 [65.952]
 [67.891]] [[2.479]
 [2.479]
 [2.479]
 [2.4  ]
 [2.479]]
printing an ep nov before normalisation:  58.37568759918213
printing an ep nov before normalisation:  49.92552560852143
actions average: 
K:  0  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0006,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9993,     0.0000,     0.0001,     0.0005],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9936,     0.0037,     0.0027],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0010,     0.0004,     0.0012,     0.8309,     0.1665],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0021, 0.0010, 0.0031, 0.5852, 0.4086], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  19.22810221937226
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.86092865
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  14.697835445404053
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  102.76922225952148
printing an ep nov before normalisation:  15.38996159315301
printing an ep nov before normalisation:  99.7869103020247
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  107.90465280875023
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
siam score:  -0.86826754
printing an ep nov before normalisation:  108.37858909665444
using explorer policy with actor:  1
printing an ep nov before normalisation:  95.27841717918373
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  77.34138537990488
printing an ep nov before normalisation:  12.994529545834961
printing an ep nov before normalisation:  8.729166291003711
printing an ep nov before normalisation:  143.19866797420693
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.202]
 [17.263]
 [74.544]
 [66.842]
 [33.667]] [[0.623]
 [0.044]
 [1.322]
 [1.15 ]
 [0.41 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  7.321769412050284
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[35.812]
 [ 7.486]
 [11.804]
 [77.31 ]
 [17.892]] [[0.588]
 [0.072]
 [0.15 ]
 [1.345]
 [0.261]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 44.998]
 [ 44.998]
 [ 44.998]
 [100.438]
 [ 44.998]] [[0.76 ]
 [0.76 ]
 [0.76 ]
 [1.834]
 [0.76 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 12.425872878992012
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  107.23240254137676
printing an ep nov before normalisation:  50.913685457478344
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[102.96 ]
 [102.96 ]
 [102.96 ]
 [116.283]
 [102.96 ]] [[1.863]
 [1.863]
 [1.863]
 [2.128]
 [1.863]]
printing an ep nov before normalisation:  110.88574618436695
printing an ep nov before normalisation:  86.55921320832371
printing an ep nov before normalisation:  12.138173457496793
line 256 mcts: sample exp_bonus 109.18204894023094
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[156.598]
 [156.598]
 [156.598]
 [156.598]
 [156.598]] [[2.5]
 [2.5]
 [2.5]
 [2.5]
 [2.5]]
printing an ep nov before normalisation:  33.71557736196521
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[59.637]
 [59.637]
 [59.637]
 [70.847]
 [59.637]] [[2.091]
 [2.091]
 [2.091]
 [2.5  ]
 [2.091]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.699]
 [27.273]
 [14.655]
 [45.879]
 [42.736]] [[0.297]
 [0.832]
 [0.369]
 [1.515]
 [1.4  ]]
printing an ep nov before normalisation:  74.11576434054814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  59.42311331186238
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  91.30578872253224
siam score:  -0.8640114
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  96.49833425438798
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  94.86346373570528
printing an ep nov before normalisation:  19.974985783223968
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[90.346]
 [90.346]
 [90.346]
 [90.346]
 [90.346]] [[2.326]
 [2.326]
 [2.326]
 [2.326]
 [2.326]]
printing an ep nov before normalisation:  45.275083998424805
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[91.331]
 [91.331]
 [91.331]
 [91.331]
 [91.331]] [[2.345]
 [2.345]
 [2.345]
 [2.345]
 [2.345]]
printing an ep nov before normalisation:  12.233295440673828
printing an ep nov before normalisation:  99.964567067977
printing an ep nov before normalisation:  57.28102072786413
printing an ep nov before normalisation:  99.05103684527674
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.86901945
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  112.8852653503418
printing an ep nov before normalisation:  105.39436718039148
printing an ep nov before normalisation:  93.63814353942871
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[48.621]
 [11.987]
 [11.61 ]
 [60.136]
 [10.483]] [[0.837]
 [0.033]
 [0.025]
 [1.09 ]
 [0.   ]]
Training Flag: True
Self play flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 6.439]
 [10.066]
 [20.12 ]
 [41.267]
 [22.195]] [[0.038]
 [0.078]
 [0.19 ]
 [0.426]
 [0.214]]
printing an ep nov before normalisation:  69.70338097111151
printing an ep nov before normalisation:  4.9435151489165365
printing an ep nov before normalisation:  9.333939022488064
siam score:  -0.85974723
using explorer policy with actor:  1
printing an ep nov before normalisation:  44.10553455352783
printing an ep nov before normalisation:  62.06876754760742
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  50.7004282984759
printing an ep nov before normalisation:  14.08725960358954
printing an ep nov before normalisation:  88.58958813241844
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.034]
 [34.034]
 [34.034]
 [34.034]
 [34.034]] [[0.576]
 [0.576]
 [0.576]
 [0.576]
 [0.576]]
printing an ep nov before normalisation:  88.02590222021651
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8606713
printing an ep nov before normalisation:  23.266371135522537
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  31.475214207003656
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  20.76817043702997
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  57.25465673901604
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  24.98948335647583
printing an ep nov before normalisation:  101.47474226373674
using explorer policy with actor:  1
actions average: 
K:  4  action  0 :  tensor([    0.9777,     0.0010,     0.0002,     0.0012,     0.0198],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9964,     0.0000,     0.0003,     0.0031],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0001,     0.9870,     0.0021,     0.0108],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0009,     0.0005,     0.0012,     0.8269,     0.1705],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0016, 0.0007, 0.0056, 0.3790, 0.6131], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  25.246103469884417
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  17.206488670428186
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  115.3344769943036
printing an ep nov before normalisation:  72.39817913865579
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[65.277]
 [65.277]
 [65.277]
 [65.277]
 [65.277]] [[1.5]
 [1.5]
 [1.5]
 [1.5]
 [1.5]]
siam score:  -0.86391085
printing an ep nov before normalisation:  109.1871242383464
printing an ep nov before normalisation:  24.493916056008
printing an ep nov before normalisation:  57.77647997289815
printing an ep nov before normalisation:  54.220776126945445
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000],
        [    0.0000]], dtype=torch.float64)
0.0 0.0
0.0 4.0275995238815554e-22
0.0 1.2454853925737733e-11
0.0 2.2141962666392116e-11
0.0 2.2141962666392116e-11
0.0 0.0
0.0 2.2141962666392116e-11
0.0 6.4441592382104886e-21
0.0 6.0413992858223335e-22
0.0 4.0275995238815554e-22
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.84585816
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8449948
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  104.4613664310437
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[109.552]
 [109.552]
 [109.552]
 [ 83.956]
 [109.552]] [[1. ]
 [1. ]
 [1. ]
 [0.7]
 [1. ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  42.746562768097355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  49.81905937194824
printing an ep nov before normalisation:  29.949698773155998
printing an ep nov before normalisation:  82.64885730693878
printing an ep nov before normalisation:  6.812326853649653
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  12.001368999481201
printing an ep nov before normalisation:  30.785220558723825
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  56.10984989904476
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  15.413826540576688
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
printing an ep nov before normalisation:  58.35047070022135
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  39.938648614813296
printing an ep nov before normalisation:  92.52365747064944
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  32.42809245984124
printing an ep nov before normalisation:  34.084993807878575
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[24.123]
 [10.436]
 [10.436]
 [14.671]
 [10.436]] [[1.359]
 [0.588]
 [0.588]
 [0.826]
 [0.588]]
printing an ep nov before normalisation:  33.43424038983285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[145.823]
 [145.823]
 [145.823]
 [145.823]
 [145.823]] [[1.984]
 [1.984]
 [1.984]
 [1.984]
 [1.984]]
printing an ep nov before normalisation:  82.44580155810355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.86183435
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  45.324048878081314
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.896]
 [15.49 ]
 [15.49 ]
 [52.177]
 [15.49 ]] [[0.806]
 [0.166]
 [0.166]
 [0.914]
 [0.166]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.499]
 [60.499]
 [60.499]
 [63.501]
 [60.499]] [[1.425]
 [1.425]
 [1.425]
 [1.5  ]
 [1.425]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.713]
 [40.713]
 [14.701]
 [37.457]
 [40.713]] [[1.234]
 [1.234]
 [0.387]
 [1.128]
 [1.234]]
printing an ep nov before normalisation:  16.483020782470703
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  10.462031685411489
printing an ep nov before normalisation:  30.449607147893598
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  78.98343119652685
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  12.52680878686871
siam score:  -0.864738
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  9.970464646407533
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
printing an ep nov before normalisation:  18.584395932065497
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  31.672652148152505
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  76.02852914614382
printing an ep nov before normalisation:  26.103659873404062
printing an ep nov before normalisation:  24.005235130681008
printing an ep nov before normalisation:  35.904854973759356
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  23.369529833709425
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  81.66186318949954
maxi score, test score, baseline:  0.0001 0.0 0.0001
Starting evaluation
Sims:  40 1 epoch:  30063 pick best:  True frame count:  30063
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  32.52708315849304
printing an ep nov before normalisation:  13.46559150790154
printing an ep nov before normalisation:  76.01992646147903
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.8727275
printing an ep nov before normalisation:  102.99304090062915
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.053]
 [13.456]
 [14.165]
 [16.759]
 [13.345]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
rdn beta is 0 so we're just using the maxi policy
printing an ep nov before normalisation:  17.9818335673522
printing an ep nov before normalisation:  34.9003943772374
printing an ep nov before normalisation:  33.14486005307032
printing an ep nov before normalisation:  55.56260108947754
using explorer policy with actor:  1
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  30.71867237213759
printing an ep nov before normalisation:  25.570971965789795
printing an ep nov before normalisation:  5.462400570040252
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[87.904]
 [82.698]
 [86.004]
 [86.908]
 [86.61 ]] [[2.056]
 [1.808]
 [1.966]
 [2.009]
 [1.995]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  84.56038438534078
using explorer policy with actor:  1
siam score:  -0.86767656
printing an ep nov before normalisation:  111.53464868804261
printing an ep nov before normalisation:  35.44834182627547
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  33.36061482743289
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 6.261]
 [22.293]
 [15.626]
 [31.666]
 [27.743]] [[0.071]
 [0.691]
 [0.433]
 [1.054]
 [0.902]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.86587584
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.9993,     0.0000,     0.0000,     0.0003,     0.0003],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([0.0019, 0.9336, 0.0023, 0.0307, 0.0315], grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0028,     0.9353,     0.0299,     0.0321],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0023,     0.0002,     0.0018,     0.8359,     0.1598],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0292, 0.0034, 0.0498, 0.3255, 0.5921], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  63.58349144695327
line 256 mcts: sample exp_bonus 8.69862707218171
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[50.251]
 [50.251]
 [50.251]
 [51.442]
 [50.251]] [[1.284]
 [1.284]
 [1.284]
 [1.321]
 [1.284]]
actions average: 
K:  3  action  0 :  tensor([    0.9996,     0.0000,     0.0000,     0.0003,     0.0001],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9920,     0.0004,     0.0004,     0.0071],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0068,     0.9906,     0.0010,     0.0016],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0012,     0.0006,     0.0259,     0.8105,     0.1618],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0025,     0.0003,     0.0005,     0.6726,     0.3242],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  67.94888417897263
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.604]
 [36.604]
 [ 6.906]
 [49.569]
 [36.604]] [[0.838]
 [0.838]
 [0.   ]
 [1.204]
 [0.838]]
printing an ep nov before normalisation:  5.960460540401684
printing an ep nov before normalisation:  6.926177144050598
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[72.019]
 [72.019]
 [72.019]
 [75.522]
 [72.019]] [[1.76 ]
 [1.76 ]
 [1.76 ]
 [1.885]
 [1.76 ]]
printing an ep nov before normalisation:  64.95297588652824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  80.54643411441032
printing an ep nov before normalisation:  71.22531963123402
printing an ep nov before normalisation:  12.180858465079671
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  95.1480627774105
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[68.991]
 [61.285]
 [78.139]
 [77.801]
 [72.774]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  0.034987470812097854
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 60.502]
 [ 97.986]
 [118.345]
 [108.001]
 [106.797]] [[0.515]
 [1.441]
 [1.945]
 [1.689]
 [1.659]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
printing an ep nov before normalisation:  32.34665840436677
printing an ep nov before normalisation:  19.481304168913223
line 256 mcts: sample exp_bonus 38.75805130322438
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  77.58329805398743
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  23.217068027038298
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[73.251]
 [73.251]
 [73.251]
 [73.251]
 [73.251]] [[1.986]
 [1.986]
 [1.986]
 [1.986]
 [1.986]]
printing an ep nov before normalisation:  8.5498177419171
printing an ep nov before normalisation:  28.517741100944093
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
actions average: 
K:  0  action  0 :  tensor([    0.9822,     0.0128,     0.0000,     0.0028,     0.0022],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9939,     0.0001,     0.0004,     0.0054],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0001,     0.9380,     0.0416,     0.0203],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0002,     0.0003,     0.0058,     0.8789,     0.1148],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0365, 0.0006, 0.0126, 0.4310, 0.5193], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  38.460569453078264
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[84.892]
 [84.892]
 [84.892]
 [84.892]
 [84.892]] [[3.]
 [3.]
 [3.]
 [3.]
 [3.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  35.26241984910354
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  86.04372992634494
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[36.769]
 [36.769]
 [36.769]
 [42.933]
 [36.769]] [[1.063]
 [1.063]
 [1.063]
 [1.328]
 [1.063]]
printing an ep nov before normalisation:  18.208735150257983
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  51.320168909588304
printing an ep nov before normalisation:  33.69877815246582
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  27.379819523275543
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[56.603]
 [56.603]
 [47.958]
 [69.605]
 [56.603]] [[0.666]
 [0.666]
 [0.534]
 [0.864]
 [0.666]]
printing an ep nov before normalisation:  57.74311340797167
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.958]
 [25.37 ]
 [25.37 ]
 [13.803]
 [25.37 ]] [[0.606]
 [0.541]
 [0.541]
 [0.071]
 [0.541]]
printing an ep nov before normalisation:  13.93301723527802
printing an ep nov before normalisation:  8.988354157576719
siam score:  -0.8680298
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  33.26392046645195
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  35.60976359153483
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  56.27754305995467
siam score:  -0.8493359
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.985]
 [35.755]
 [24.806]
 [11.448]
 [24.443]] [[1.411]
 [1.943]
 [1.347]
 [0.62 ]
 [1.327]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[114.386]
 [114.386]
 [108.197]
 [114.386]
 [114.386]] [[1.   ]
 [1.   ]
 [0.921]
 [1.   ]
 [1.   ]]
siam score:  -0.8524033
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  71.45424385417802
siam score:  -0.854205
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8539987
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  45.735955238342285
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.   ]
 [26.472]
 [30.257]
 [30.105]
 [27.19 ]] [[0.74 ]
 [0.769]
 [1.003]
 [0.994]
 [0.813]]
printing an ep nov before normalisation:  0.000266258194301372
printing an ep nov before normalisation:  47.497666918806146
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.945]
 [49.978]
 [29.852]
 [49.51 ]
 [52.156]] [[1.335]
 [1.154]
 [0.541]
 [1.139]
 [1.22 ]]
siam score:  -0.86046374
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9767,     0.0020,     0.0001,     0.0090,     0.0122],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0008,     0.9790,     0.0027,     0.0028,     0.0147],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9987,     0.0003,     0.0010],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0003,     0.0002,     0.0001,     0.8419,     0.1574],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0012, 0.0009, 0.1169, 0.4536, 0.4274], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  67.58122757290775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
UNIT TEST: sample policy line 217 mcts : [0.179 0.308 0.179 0.128 0.205]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  55.44966203597679
printing an ep nov before normalisation:  37.30722665786743
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  41.03989716776823
UNIT TEST: sample policy line 217 mcts : [0.462 0.205 0.103 0.128 0.103]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[55.898]
 [55.634]
 [62.078]
 [59.78 ]
 [57.262]] [[1.979]
 [1.96 ]
 [2.431]
 [2.263]
 [2.079]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.9740,     0.0001,     0.0000,     0.0144,     0.0115],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0001,     0.9139,     0.0035,     0.0562,     0.0264],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9907,     0.0070,     0.0022],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0036,     0.0008,     0.0180,     0.8467,     0.1310],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0046, 0.0081, 0.0591, 0.5037, 0.4244], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  34.677337202522736
printing an ep nov before normalisation:  74.26718463004268
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  50.56902973927481
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.314]
 [38.299]
 [21.643]
 [40.188]
 [39.917]] [[0.724]
 [1.024]
 [0.022]
 [1.138]
 [1.122]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.85039514
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  132.09398877602194
line 256 mcts: sample exp_bonus 31.7240173102096
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[33.044]
 [33.044]
 [48.228]
 [44.169]
 [33.044]] [[0.586]
 [0.586]
 [1.021]
 [0.904]
 [0.586]]
printing an ep nov before normalisation:  50.458189083257054
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  14.13740643909499
printing an ep nov before normalisation:  61.65094191404539
printing an ep nov before normalisation:  14.859982247800687
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  110.81300058034361
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  87.10862474366925
printing an ep nov before normalisation:  22.860317088018416
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.982]
 [24.011]
 [13.085]
 [12.856]
 [24.011]] [[1.365]
 [1.449]
 [0.559]
 [0.541]
 [1.449]]
printing an ep nov before normalisation:  39.39399038611624
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  131.28366827192153
printing an ep nov before normalisation:  168.9776806301645
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  135.84616024023578
actions average: 
K:  1  action  0 :  tensor([    0.9989,     0.0000,     0.0000,     0.0006,     0.0005],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9834,     0.0002,     0.0062,     0.0102],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9591,     0.0174,     0.0235],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0002,     0.0061,     0.8139,     0.1795],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0018, 0.0322, 0.0177, 0.3708, 0.5775], grad_fn=<DivBackward0>)
siam score:  -0.8469467
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  30.396580472810836
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.9980,     0.0003,     0.0000,     0.0001,     0.0016],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0017, 0.8874, 0.0556, 0.0036, 0.0518], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0002,     0.9956,     0.0003,     0.0039],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0017, 0.0017, 0.0104, 0.8473, 0.1389], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0036, 0.0026, 0.0292, 0.4464, 0.5182], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  43.21906359340219
printing an ep nov before normalisation:  89.93323113248807
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.14927134034943
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[99.322]
 [83.256]
 [91.627]
 [96.296]
 [97.479]] [[1.852]
 [1.268]
 [1.572]
 [1.742]
 [1.785]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8714934
printing an ep nov before normalisation:  53.627372414770264
printing an ep nov before normalisation:  49.65120505798261
printing an ep nov before normalisation:  18.764210479153263
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.9985,     0.0000,     0.0000,     0.0004,     0.0011],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0214, 0.9551, 0.0039, 0.0012, 0.0184], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0001,     0.0018,     0.9567,     0.0218,     0.0196],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0002,     0.0009,     0.0109,     0.8163,     0.1716],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0005,     0.0004,     0.0009,     0.5467,     0.4515],
       grad_fn=<DivBackward0>)
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.9977,     0.0014,     0.0000,     0.0003,     0.0006],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0000,     0.9997,     0.0001,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0017,     0.9836,     0.0010,     0.0137],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0003,     0.0005,     0.8151,     0.1837],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0015, 0.0092, 0.0181, 0.4923, 0.4791], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  106.77021980285645
printing an ep nov before normalisation:  67.35877990722656
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  8.06668451809485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  90.1171465900344
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  10.651721954345703
printing an ep nov before normalisation:  54.36232709764797
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  2.4129326448019128e-05
siam score:  -0.87289214
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.9939,     0.0002,     0.0000,     0.0005,     0.0055],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0009,     0.9929,     0.0039,     0.0001,     0.0021],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9998,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0001,     0.0002,     0.0109,     0.7881,     0.2007],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0754, 0.0007, 0.0769, 0.2694, 0.5776], grad_fn=<DivBackward0>)
siam score:  -0.87094694
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  13.174388329494775
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.9965,     0.0013,     0.0000,     0.0002,     0.0020],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0001,     0.9983,     0.0000,     0.0001,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0011,     0.0001,     0.9540,     0.0046,     0.0401],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0007,     0.0002,     0.0001,     0.8522,     0.1468],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([    0.0026,     0.0009,     0.0004,     0.5902,     0.4060],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  20.222947597503662
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([0.8916, 0.0112, 0.0129, 0.0364, 0.0479], grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0000,     0.9997,     0.0000,     0.0000,     0.0002],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0001,     0.9670,     0.0044,     0.0285],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([0.0019, 0.0147, 0.0065, 0.8292, 0.1477], grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0007, 0.0260, 0.0572, 0.4260, 0.4902], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  73.31783302651208
actions average: 
K:  2  action  0 :  tensor([    0.9972,     0.0002,     0.0000,     0.0014,     0.0012],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0002,     0.9727,     0.0007,     0.0014,     0.0251],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0000,     0.9966,     0.0005,     0.0029],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0005,     0.0004,     0.0104,     0.8109,     0.1778],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0011, 0.0006, 0.0597, 0.4430, 0.4956], grad_fn=<DivBackward0>)
using explorer policy with actor:  1
printing an ep nov before normalisation:  40.70577191178045
printing an ep nov before normalisation:  74.22467401006047
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 45.99 ]
 [ 71.967]
 [114.07 ]
 [108.02 ]
 [ 90.25 ]] [[0.059]
 [0.27 ]
 [0.613]
 [0.564]
 [0.419]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  21.036595083797035
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0003,     0.0002],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0026,     0.9952,     0.0001,     0.0001,     0.0019],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0003,     0.0065,     0.9506,     0.0182,     0.0243],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0026,     0.0003,     0.0020,     0.8585,     0.1367],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([    0.0007,     0.0003,     0.0109,     0.4371,     0.5510],
       grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  28.093485832214355
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  7.256743737629482
printing an ep nov before normalisation:  68.51050937240949
printing an ep nov before normalisation:  64.83224545191432
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 8.305]
 [ 0.   ]
 [ 0.   ]
 [46.243]
 [ 0.   ]] [[ 0.293]
 [-0.   ]
 [-0.   ]
 [ 1.63 ]
 [-0.   ]]
line 256 mcts: sample exp_bonus 69.54038375772548
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.85056
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  73.72282854300437
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
siam score:  -0.8530513
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[70.028]
 [70.028]
 [70.028]
 [74.233]
 [70.028]] [[1.35 ]
 [1.35 ]
 [1.35 ]
 [1.431]
 [1.35 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  33.09950838645235
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[46.299]
 [36.397]
 [38.023]
 [38.745]
 [34.889]] [[0.541]
 [0.358]
 [0.388]
 [0.401]
 [0.33 ]]
printing an ep nov before normalisation:  13.855050460404351
printing an ep nov before normalisation:  28.451442942924416
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.9993,     0.0001,     0.0000,     0.0002,     0.0004],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0000,     0.9999,     0.0000,     0.0000,     0.0001],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0014,     0.9663,     0.0010,     0.0313],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0006,     0.0006,     0.0082,     0.8276,     0.1630],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0013, 0.0037, 0.1079, 0.4834, 0.4037], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  38.372067926964874
printing an ep nov before normalisation:  12.923469436002506
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  81.87894759679625
printing an ep nov before normalisation:  75.58986444076956
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 7.065]
 [ 4.922]
 [19.433]
 [ 9.664]
 [ 5.224]] [[0.462]
 [0.246]
 [1.708]
 [0.724]
 [0.276]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[22.405]
 [22.984]
 [22.984]
 [22.107]
 [22.984]] [[2.672]
 [2.757]
 [2.757]
 [2.628]
 [2.757]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  6.8594735860824585
using explorer policy with actor:  1
printing an ep nov before normalisation:  18.229122176146845
printing an ep nov before normalisation:  48.827414748881814
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8794101
line 256 mcts: sample exp_bonus 33.104669013280095
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.068284393299673
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8580295
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  49.61466176339038
siam score:  -0.8461355
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  9.506229724529192
printing an ep nov before normalisation:  12.494825275994776
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  2  action  0 :  tensor([    0.9146,     0.0002,     0.0000,     0.0504,     0.0348],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0731, 0.8141, 0.0252, 0.0028, 0.0848], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0005,     0.9567,     0.0250,     0.0178],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0056,     0.0006,     0.0203,     0.8065,     0.1670],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0099, 0.0149, 0.0010, 0.4355, 0.5386], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  104.70862816301346
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[130.55 ]
 [130.55 ]
 [130.55 ]
 [132.277]
 [130.55 ]] [[1.95 ]
 [1.95 ]
 [1.95 ]
 [1.982]
 [1.95 ]]
printing an ep nov before normalisation:  40.15889569599498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[18.608]
 [18.608]
 [18.608]
 [18.608]
 [18.608]] [[1.248]
 [1.248]
 [1.248]
 [1.248]
 [1.248]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  66.86371145423288
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  43.994717597961426
printing an ep nov before normalisation:  45.37626547764745
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  44.26411661235448
printing an ep nov before normalisation:  51.370790801243956
printing an ep nov before normalisation:  30.307103495121865
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[43.52 ]
 [43.52 ]
 [43.52 ]
 [68.002]
 [43.52 ]] [[0.29 ]
 [0.29 ]
 [0.29 ]
 [0.795]
 [0.29 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
printing an ep nov before normalisation:  28.267657232149972
printing an ep nov before normalisation:  23.1351043116566
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  12.770626293330057
printing an ep nov before normalisation:  21.813309688573963
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  76.73427104949951
printing an ep nov before normalisation:  8.111579830398785
printing an ep nov before normalisation:  24.75532453884308
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.88079697
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  146.94451103018525
printing an ep nov before normalisation:  65.38556372345057
printing an ep nov before normalisation:  72.83828541054643
printing an ep nov before normalisation:  151.85793407861124
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8825406
siam score:  -0.8807458
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  84.65879615365257
printing an ep nov before normalisation:  55.440164220104535
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.435]
 [66.435]
 [66.435]
 [66.435]
 [66.435]] [[0.896]
 [0.896]
 [0.896]
 [0.896]
 [0.896]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.521]
 [15.521]
 [15.521]
 [21.978]
 [15.521]] [[0.507]
 [0.507]
 [0.507]
 [0.889]
 [0.507]]
printing an ep nov before normalisation:  18.36695952625007
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  169.80032675830384
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  27.539321414355864
line 256 mcts: sample exp_bonus 21.32749790875644
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.843416219581233
printing an ep nov before normalisation:  3.4673309326171875
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  7.458852092781864
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  4  action  0 :  tensor([    0.9456,     0.0001,     0.0000,     0.0336,     0.0206],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0778,     0.9198,     0.0001,     0.0003,     0.0020],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0011,     0.9543,     0.0238,     0.0208],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0006,     0.0246,     0.8115,     0.1632],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0099, 0.0071, 0.0483, 0.4448, 0.4900], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  11.174792662841632
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[38.977]
 [38.977]
 [19.688]
 [32.7  ]
 [38.977]] [[2.395]
 [2.395]
 [0.943]
 [1.923]
 [2.395]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.341]
 [10.756]
 [17.183]
 [24.519]
 [21.738]] [[0.538]
 [0.501]
 [0.907]
 [1.371]
 [1.195]]
using explorer policy with actor:  1
printing an ep nov before normalisation:  47.82294341331456
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[144.101]
 [119.651]
 [134.22 ]
 [146.257]
 [146.103]] [[2.271]
 [1.73 ]
 [2.052]
 [2.319]
 [2.315]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.047]
 [25.047]
 [25.047]
 [25.047]
 [25.047]] [[2.5]
 [2.5]
 [2.5]
 [2.5]
 [2.5]]
using explorer policy with actor:  1
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  17.182847159389368
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[83.562]
 [83.562]
 [83.562]
 [83.562]
 [83.562]] [[1.806]
 [1.806]
 [1.806]
 [1.806]
 [1.806]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  33.436099326618375
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[32.524]
 [32.524]
 [32.524]
 [44.51 ]
 [32.524]] [[1.696]
 [1.696]
 [1.696]
 [2.555]
 [1.696]]
actions average: 
K:  4  action  0 :  tensor([    0.8851,     0.0027,     0.0000,     0.0471,     0.0651],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0003,     0.9980,     0.0003,     0.0000,     0.0014],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9981,     0.0010,     0.0009],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0001,     0.0003,     0.0166,     0.7258,     0.2573],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0200, 0.0146, 0.0658, 0.4066, 0.4930], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  11.88949480285271
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  52.23998483527132
printing an ep nov before normalisation:  23.27177301441317
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  46.201208149170064
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[66.85 ]
 [81.093]
 [78.495]
 [70.735]
 [73.212]] [[1.969]
 [2.782]
 [2.634]
 [2.191]
 [2.332]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  18.814963279087358
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[53.946]
 [53.946]
 [53.946]
 [66.64 ]
 [53.946]] [[1.317]
 [1.317]
 [1.317]
 [1.647]
 [1.317]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  20.91437836941924
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  73.73373773362901
printing an ep nov before normalisation:  41.893212933138486
printing an ep nov before normalisation:  38.70911819388834
printing an ep nov before normalisation:  99.07577623608303
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[52.854]
 [52.854]
 [52.854]
 [52.854]
 [52.854]] [[0.76]
 [0.76]
 [0.76]
 [0.76]
 [0.76]]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[13.757]
 [13.757]
 [13.757]
 [13.757]
 [13.757]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  49.88534851578414
printing an ep nov before normalisation:  66.61241760231638
actions average: 
K:  2  action  0 :  tensor([    0.9985,     0.0000,     0.0000,     0.0009,     0.0006],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0117,     0.9659,     0.0003,     0.0014,     0.0207],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([0.0014, 0.0188, 0.8962, 0.0476, 0.0359], grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0005,     0.0002,     0.0059,     0.9021,     0.0913],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0052, 0.0808, 0.0270, 0.4928, 0.3943], grad_fn=<DivBackward0>)
actions average: 
K:  3  action  0 :  tensor([    0.9522,     0.0466,     0.0000,     0.0002,     0.0010],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([0.0065, 0.9711, 0.0011, 0.0015, 0.0198], grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([0.0022, 0.0223, 0.9013, 0.0413, 0.0328], grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0010,     0.0006,     0.0096,     0.8315,     0.1573],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0099, 0.0091, 0.0319, 0.4491, 0.5000], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  31.21401595154568
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.102]
 [37.553]
 [37.553]
 [37.665]
 [37.553]] [[1.039]
 [2.819]
 [2.819]
 [2.835]
 [2.819]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[12.66]
 [12.66]
 [12.66]
 [12.66]
 [12.66]] [[3.]
 [3.]
 [3.]
 [3.]
 [3.]]
line 256 mcts: sample exp_bonus 42.64511726364108
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.606]
 [20.556]
 [17.495]
 [29.14 ]
 [18.221]] [[0.   ]
 [0.261]
 [0.1  ]
 [0.713]
 [0.138]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8888843
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[95.673]
 [76.197]
 [76.197]
 [76.431]
 [76.197]] [[1.29 ]
 [0.868]
 [0.868]
 [0.873]
 [0.868]]
printing an ep nov before normalisation:  49.089907543021155
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  109.65545022956587
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  100.56838147438059
printing an ep nov before normalisation:  37.962196677854195
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[6.077]
 [3.824]
 [8.047]
 [8.957]
 [8.608]] [[0.491]
 [0.289]
 [0.667]
 [0.749]
 [0.718]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  21.410532423280596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[44.466]
 [44.466]
 [44.466]
 [43.09 ]
 [44.466]] [[1.88 ]
 [1.88 ]
 [1.88 ]
 [1.808]
 [1.88 ]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  7.602776885032654
siam score:  -0.87614465
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[11.544]
 [39.512]
 [25.155]
 [19.519]
 [19.59 ]] [[0.182]
 [1.02 ]
 [0.589]
 [0.42 ]
 [0.423]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  3.2716691578820845
printing an ep nov before normalisation:  122.10260093308457
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  56.86455018654305
printing an ep nov before normalisation:  25.03066750038453
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  42.552248276502525
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  58.38319991684046
printing an ep nov before normalisation:  85.2237329409133
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.84685236
printing an ep nov before normalisation:  42.25338858284071
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.014]
 [34.014]
 [16.121]
 [34.827]
 [ 9.252]] [[0.73 ]
 [0.73 ]
 [0.313]
 [0.749]
 [0.153]]
Starting evaluation
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[61.306]
 [60.767]
 [39.171]
 [37.111]
 [43.418]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[75.785]
 [58.402]
 [24.089]
 [49.478]
 [51.296]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  26.165499687194824
printing an ep nov before normalisation:  19.497070107701692
printing an ep nov before normalisation:  60.4811676524596
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  17.591114855653245
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.918]
 [47.918]
 [47.918]
 [47.918]
 [47.918]] [[2.5]
 [2.5]
 [2.5]
 [2.5]
 [2.5]]
printing an ep nov before normalisation:  4.8906480274446835
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  41.66639191763742
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[40.136]
 [46.432]
 [40.136]
 [35.179]
 [35.962]] [[0.974]
 [1.265]
 [0.974]
 [0.745]
 [0.781]]
printing an ep nov before normalisation:  68.69460738173197
line 256 mcts: sample exp_bonus 41.86293509629974
siam score:  -0.8670824
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.9987043241225
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  2.0029609336933163
printing an ep nov before normalisation:  66.07590329271159
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  35.052526535368685
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 0.0010716282943263877
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[133.123]
 [133.123]
 [133.123]
 [133.123]
 [133.123]] [[2.432]
 [2.432]
 [2.432]
 [2.432]
 [2.432]]
siam score:  -0.8752122
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.87555665
printing an ep nov before normalisation:  26.44976763926505
printing an ep nov before normalisation:  71.0080768835072
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  54.22163963317871
printing an ep nov before normalisation:  14.22452449798584
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.87740934
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  31.339543369425055
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[20.305]
 [20.305]
 [20.305]
 [56.821]
 [20.305]] [[0.219]
 [0.219]
 [0.219]
 [0.971]
 [0.219]]
printing an ep nov before normalisation:  55.021935241625485
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  47.938909474992066
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.5  ]
 [17.475]
 [21.883]
 [36.188]
 [30.457]] [[0.458]
 [0.265]
 [0.35 ]
 [0.625]
 [0.515]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[25.56 ]
 [25.56 ]
 [25.56 ]
 [28.499]
 [25.56 ]] [[1.006]
 [1.006]
 [1.006]
 [1.137]
 [1.006]]
printing an ep nov before normalisation:  9.295561405464941
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  82.84956976473111
actions average: 
K:  4  action  0 :  tensor([    0.9906,     0.0001,     0.0000,     0.0041,     0.0053],
       grad_fn=<DivBackward0>)
K:  4  action  1 :  tensor([    0.0367,     0.9343,     0.0222,     0.0005,     0.0062],
       grad_fn=<DivBackward0>)
K:  4  action  2 :  tensor([    0.0000,     0.0000,     0.9980,     0.0002,     0.0017],
       grad_fn=<DivBackward0>)
K:  4  action  3 :  tensor([    0.0004,     0.0022,     0.0289,     0.8107,     0.1577],
       grad_fn=<DivBackward0>)
K:  4  action  4 :  tensor([0.0468, 0.0713, 0.0607, 0.4017, 0.4196], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.877818
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  71.28477096557617
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  3  action  0 :  tensor([    0.9992,     0.0003,     0.0000,     0.0002,     0.0004],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0001,     0.9885,     0.0000,     0.0014,     0.0100],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0000,     0.9870,     0.0071,     0.0059],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0007,     0.0006,     0.0203,     0.8464,     0.1320],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([0.0024, 0.0064, 0.0051, 0.5646, 0.4216], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  174.00300316629122
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.9679,     0.0184,     0.0004,     0.0061,     0.0072],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([0.0113, 0.9684, 0.0049, 0.0028, 0.0126], grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0001,     0.9619,     0.0207,     0.0173],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0046,     0.0002,     0.0087,     0.8386,     0.1480],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0007, 0.0005, 0.0379, 0.4807, 0.4803], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  16.196692718080797
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  78.15680066327617
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.24]
 [19.24]
 [19.24]
 [19.24]
 [19.24]] [[1.5]
 [1.5]
 [1.5]
 [1.5]
 [1.5]]
siam score:  -0.8793951
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.536]
 [21.536]
 [21.536]
 [21.536]
 [21.536]] [[0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  81.88936159871517
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  37.27619419679919
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  6.316170994555129
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  13.555781818712848
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.3  ]
 [13.874]
 [48.399]
 [47.383]
 [22.875]] [[2.095]
 [0.011]
 [2.164]
 [2.1  ]
 [0.572]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  28.611616194399332
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[130.066]
 [130.066]
 [130.066]
 [130.066]
 [130.066]] [[1.5]
 [1.5]
 [1.5]
 [1.5]
 [1.5]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  16.7968241414057
printing an ep nov before normalisation:  72.46960322846351
siam score:  -0.8529344
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  69.654072674948
printing an ep nov before normalisation:  11.933899557804377
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 6.564]
 [13.676]
 [ 7.964]
 [15.34 ]
 [ 8.398]] [[0.622]
 [1.296]
 [0.755]
 [1.454]
 [0.796]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  13.950207134752713
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  129.7767556589504
siam score:  -0.8611497
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  28.92392873764038
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  9.57953729245078
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  13.836405348203598
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  114.9011162896655
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[47.909]
 [55.31 ]
 [51.92 ]
 [50.909]
 [48.341]] [[1.091]
 [1.44 ]
 [1.28 ]
 [1.232]
 [1.112]]
printing an ep nov before normalisation:  75.68183053539082
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 9.581]
 [19.064]
 [28.072]
 [15.297]
 [23.135]] [[0.149]
 [0.629]
 [1.086]
 [0.438]
 [0.836]]
printing an ep nov before normalisation:  33.10028553009033
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[34.698]
 [29.638]
 [13.594]
 [41.458]
 [28.284]] [[0.899]
 [0.688]
 [0.02 ]
 [1.18 ]
 [0.632]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  66.25477258510399
actions average: 
K:  0  action  0 :  tensor([    0.9987,     0.0001,     0.0000,     0.0004,     0.0007],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0585,     0.9343,     0.0000,     0.0002,     0.0070],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0013,     0.9655,     0.0201,     0.0130],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0011, 0.0021, 0.0240, 0.7386, 0.2342], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0021, 0.0071, 0.0378, 0.4943, 0.4588], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  101.05990143645475
printing an ep nov before normalisation:  149.7299163422246
using explorer policy with actor:  1
printing an ep nov before normalisation:  9.373666486919747
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[26.656]
 [26.656]
 [26.656]
 [26.656]
 [26.656]] [[2.218]
 [2.218]
 [2.218]
 [2.218]
 [2.218]]
printing an ep nov before normalisation:  15.593265295028687
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  32.03972816467285
printing an ep nov before normalisation:  32.15768176100225
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  37.16423810767084
printing an ep nov before normalisation:  19.15820998123868
printing an ep nov before normalisation:  22.33061665833098
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[14.223]
 [27.522]
 [11.302]
 [17.709]
 [11.458]] [[0.178]
 [0.74 ]
 [0.055]
 [0.325]
 [0.061]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  130.1587587966644
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  104.89780672366959
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 78.327]
 [ 77.552]
 [105.404]
 [103.768]
 [105.607]] [[1.123]
 [1.103]
 [1.82 ]
 [1.778]
 [1.825]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  97.16492164910049
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  34.06254289024466
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  40.85451365845205
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
using explorer policy with actor:  1
printing an ep nov before normalisation:  11.64029836654663
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  29.415590661579728
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  25.09511006175602
printing an ep nov before normalisation:  22.779181556863808
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  109.86519795933954
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  10.109314736505958
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  104.32175217483237
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.403]
 [16.67 ]
 [17.403]
 [26.38 ]
 [28.91 ]] [[0.529]
 [0.477]
 [0.529]
 [1.161]
 [1.339]]
printing an ep nov before normalisation:  14.64580720076683
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  10.529339074755473
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[60.726]
 [60.726]
 [60.726]
 [70.022]
 [60.726]] [[2.133]
 [2.133]
 [2.133]
 [2.5  ]
 [2.133]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.022]
 [25.086]
 [54.696]
 [32.074]
 [25.103]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
printing an ep nov before normalisation:  54.815402030944824
printing an ep nov before normalisation:  13.336396217346191
printing an ep nov before normalisation:  114.50691570984262
printing an ep nov before normalisation:  28.240489959716797
printing an ep nov before normalisation:  8.26345881370122
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  11.852448845295621
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8798065
printing an ep nov before normalisation:  4.871059063647681
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  13.746595195371858
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[57.351]
 [60.114]
 [61.01 ]
 [64.811]
 [60.114]] [[1.113]
 [1.196]
 [1.223]
 [1.337]
 [1.196]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.9995,     0.0000,     0.0000,     0.0001,     0.0003],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0003,     0.9328,     0.0006,     0.0208,     0.0455],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0002,     0.9824,     0.0119,     0.0054],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0006,     0.0002,     0.0002,     0.8665,     0.1325],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0011, 0.0231, 0.0631, 0.4104, 0.5023], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  32.92947053909302
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 0.   ]
 [49.528]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[-1.227]
 [ 1.36 ]
 [-1.227]
 [-1.227]
 [-1.227]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  1  action  0 :  tensor([    0.9957,     0.0012,     0.0000,     0.0017,     0.0014],
       grad_fn=<DivBackward0>)
K:  1  action  1 :  tensor([    0.0005,     0.9978,     0.0001,     0.0001,     0.0015],
       grad_fn=<DivBackward0>)
K:  1  action  2 :  tensor([    0.0000,     0.0000,     0.9927,     0.0037,     0.0035],
       grad_fn=<DivBackward0>)
K:  1  action  3 :  tensor([    0.0004,     0.0004,     0.0048,     0.8448,     0.1496],
       grad_fn=<DivBackward0>)
K:  1  action  4 :  tensor([0.0007, 0.0064, 0.0453, 0.5720, 0.3755], grad_fn=<DivBackward0>)
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  27.774627952501515
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.746]
 [25.568]
 [61.66 ]
 [47.777]
 [24.623]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  26.254918192462586
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[27.833]
 [35.175]
 [34.442]
 [33.805]
 [41.329]] [[1.151]
 [1.455]
 [1.424]
 [1.398]
 [1.709]]
printing an ep nov before normalisation:  28.48825393578859
siam score:  -0.8702023
printing an ep nov before normalisation:  15.125226024281563
printing an ep nov before normalisation:  44.495278878290264
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[62.194]
 [49.425]
 [49.425]
 [49.425]
 [54.677]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  34.70107883985228
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8733412
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  38.921752759600466
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[15.013]
 [16.64 ]
 [15.653]
 [16.364]
 [16.514]] [[1.497]
 [1.843]
 [1.633]
 [1.784]
 [1.816]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  16.361552476882935
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  15.907860878018278
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 14.582690299354736
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  4.233408822460498
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  13.502502962541344
printing an ep nov before normalisation:  19.298781048557686
UNIT TEST: sample policy line 217 mcts : [0.231 0.051 0.692 0.026 0.   ]
using explorer policy with actor:  1
printing an ep nov before normalisation:  29.894981012170383
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
from probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  3  action  0 :  tensor([    0.9680,     0.0235,     0.0006,     0.0013,     0.0066],
       grad_fn=<DivBackward0>)
K:  3  action  1 :  tensor([    0.0005,     0.9468,     0.0318,     0.0013,     0.0197],
       grad_fn=<DivBackward0>)
K:  3  action  2 :  tensor([    0.0000,     0.0017,     0.9323,     0.0216,     0.0443],
       grad_fn=<DivBackward0>)
K:  3  action  3 :  tensor([    0.0006,     0.0007,     0.0179,     0.7848,     0.1961],
       grad_fn=<DivBackward0>)
K:  3  action  4 :  tensor([    0.0011,     0.0005,     0.0008,     0.5263,     0.4713],
       grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  68.72847462414498
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 17.560318947063823
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[28.997]
 [43.784]
 [28.997]
 [28.997]
 [28.997]] [[0.589]
 [0.892]
 [0.589]
 [0.589]
 [0.589]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  20.156021118164062
printing an ep nov before normalisation:  20.162856848977352
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  29.893887071775055
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.87233233
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  101.8902656124724
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  13.743774890899658
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  75.5947780621658
Training Flag: True
Self play flag: True
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10507
using explorer policy with actor:  1
actions average: 
K:  2  action  0 :  tensor([    0.9959,     0.0030,     0.0000,     0.0004,     0.0007],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([0.0032, 0.9148, 0.0418, 0.0024, 0.0377], grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0000,     0.0002,     0.9640,     0.0264,     0.0094],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0006,     0.0006,     0.0122,     0.8728,     0.1138],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0039, 0.0197, 0.0524, 0.6438, 0.2803], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  16.486599170513692
printing an ep nov before normalisation:  7.626262718222223
printing an ep nov before normalisation:  15.426928764567975
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[51.491]
 [51.491]
 [51.491]
 [51.491]
 [51.491]] [[2.]
 [2.]
 [2.]
 [2.]
 [2.]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  33.60657842895732
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
line 256 mcts: sample exp_bonus 24.38823139668114
siam score:  -0.862121
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  46.79747862346878
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  172.6398594091446
printing an ep nov before normalisation:  20.63113368412318
siam score:  -0.87672454
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
actions average: 
K:  0  action  0 :  tensor([    0.9939,     0.0033,     0.0000,     0.0004,     0.0024],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0002,     0.9995,     0.0000,     0.0000,     0.0003],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0002,     0.9693,     0.0163,     0.0142],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([0.0023, 0.0013, 0.0086, 0.8540, 0.1338], grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0041, 0.0043, 0.0389, 0.3935, 0.5592], grad_fn=<DivBackward0>)
printing an ep nov before normalisation:  28.13836097717285
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.8795924
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[ 91.787]
 [107.051]
 [111.561]
 [135.47 ]
 [111.561]] [[1.252]
 [1.648]
 [1.766]
 [2.387]
 [1.766]]
printing an ep nov before normalisation:  49.73357381298088
maxi score, test score, baseline:  0.0001 0.0 0.0001
printing an ep nov before normalisation:  34.60517108595848
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.382]
 [34.992]
 [42.397]
 [39.423]
 [41.967]] [[1.328]
 [1.672]
 [2.225]
 [2.003]
 [2.193]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  9.82288424669856
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]]
siam score:  -0.8802997
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  34.85963586742784
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
siam score:  -0.87698656
printing an ep nov before normalisation:  31.460083267049434
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  166.9296660803769
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[81.838]
 [81.838]
 [81.838]
 [81.838]
 [81.838]] [[1.979]
 [1.979]
 [1.979]
 [1.979]
 [1.979]]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.119]
 [24.364]
 [30.119]
 [30.119]
 [30.119]] [[1.755]
 [1.205]
 [1.755]
 [1.755]
 [1.755]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[21.671]
 [30.675]
 [25.415]
 [31.765]
 [32.115]] [[0.794]
 [2.03 ]
 [1.308]
 [2.18 ]
 [2.228]]
printing an ep nov before normalisation:  86.95410467390127
actions average: 
K:  2  action  0 :  tensor([    0.9560,     0.0057,     0.0000,     0.0045,     0.0338],
       grad_fn=<DivBackward0>)
K:  2  action  1 :  tensor([    0.0007,     0.9481,     0.0001,     0.0010,     0.0501],
       grad_fn=<DivBackward0>)
K:  2  action  2 :  tensor([    0.0001,     0.0001,     0.9139,     0.0440,     0.0419],
       grad_fn=<DivBackward0>)
K:  2  action  3 :  tensor([    0.0010,     0.0008,     0.0072,     0.8291,     0.1619],
       grad_fn=<DivBackward0>)
K:  2  action  4 :  tensor([0.0020, 0.0014, 0.0444, 0.4825, 0.4698], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[19.499]
 [19.499]
 [19.499]
 [19.499]
 [19.499]] [[29.248]
 [29.248]
 [29.248]
 [29.248]
 [29.248]]
using explorer policy with actor:  1
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  0.34260607031910695
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  56.454943176879155
printing an ep nov before normalisation:  6.468984540037304
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
printing an ep nov before normalisation:  18.873140811920166
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[17.909]
 [19.609]
 [19.609]
 [18.843]
 [19.609]] [[1.525]
 [1.826]
 [1.826]
 [1.69 ]
 [1.826]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
actions average: 
K:  0  action  0 :  tensor([    0.9999,     0.0000,     0.0000,     0.0000,     0.0000],
       grad_fn=<DivBackward0>)
K:  0  action  1 :  tensor([    0.0462,     0.9429,     0.0012,     0.0002,     0.0095],
       grad_fn=<DivBackward0>)
K:  0  action  2 :  tensor([    0.0000,     0.0000,     0.9974,     0.0017,     0.0009],
       grad_fn=<DivBackward0>)
K:  0  action  3 :  tensor([    0.0026,     0.0003,     0.0131,     0.8111,     0.1730],
       grad_fn=<DivBackward0>)
K:  0  action  4 :  tensor([0.0026, 0.0102, 0.0357, 0.4685, 0.4831], grad_fn=<DivBackward0>)
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
printing an ep nov before normalisation:  23.26750825114836
maxi score, test score, baseline:  0.0001 0.0 0.0001
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
Printing some Q and Qe and total Qs values:  [[0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[30.695]
 [26.181]
 [18.553]
 [18.609]
 [18.978]] [[1.08 ]
 [0.921]
 [0.653]
 [0.655]
 [0.668]]
maxi score, test score, baseline:  0.0001 0.0 0.0001
probs:  [0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998, 0.19999999999999998]
maxi score, test score, baseline:  0.0001 0.0 0.0001
