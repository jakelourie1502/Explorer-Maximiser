dirichlet_alpha:0.3
noise:0.3
dirichlet_alpha:0.5
noise:0.5
sims:{-1: 6, 6000: 50}
c1:1
c2:19652
temperature_init:1
temperature_changes:{-1: 1, 3000000.0: 0.5}
manual_over_ride_play_limit:None
exponent_node_n:1
ucb_denom_k:1
use_policy:True
model_expV_on_dones:True
norm_Qs_OnMaxi:True
norm_Qs_OnAll:True
norm_each_turn:False
state_channels:64
res_block_kernel_size:3
conv1:{'channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1}
conv2:{'channels': 64, 'kernel_size': 3, 'stride': 2, 'padding': 1}
res_block_channels:[32, 64, 64]
res_block_ds:[False, False, False]
reward_support:[-1, 1, 41]
conv1:{'kernel_size': 3, 'stride': 1, 'padding': 1}
res_blocks:[64, 64]
reward_conv_channels:32
reward_hidden_dim:128
terminal_conv_channels:32
terminal_hidden_dim:64
value_support:[-1, 1, 41]
res_block:[64]
value_conv_channels:32
value_hidden_dim:128
policy_conv_channels:32
policy_hidden_dim:128
expV_conv_channels:32
expV_hidden_dim:128
expV_support:[-10, 10, 51]
proj_l1:256
proj_out:128
pred_hid:256
replay_buffer_size:50000
replay_buffer_size_exploration:200000
all_time_buffer_size:200000
batch_size:128
play_workers:2
min_workers:2
max_workers:6
lr:0.001
lr_warmup:1000
lr_decay:1
lr_decay_step:100000
optimizer:<class 'torch.optim.rmsprop.RMSprop'>
momentum:0.9
l2:0.0001
rho:0.99
k:5
value:0.25
dones:2.0
siam:2
rdn:0.5
expV:0.5
train_start_batch_multiple:2
prioritised_replay:True
resampling:False
resampling_use_max:False
resampling_assess_best_child:False
rs_start:1000
ep_to_batch_ratio:[15, 16]
main_to_rdn_ratio:2
train_to_RS_ratio:4
on_policy_expV:False
env:<class 'game_play.Car_Driving_Env.RaceWorld'>
same_env_each_time:True
channels:3
env_size:[8, 60]
observable_size:[8, 10]
game_modes:1
env_map:[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.
  0. 0. 0. 0. 0. 0. 2. 2. 2. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.
  1. 1. 1. 1. 2. 1. 1. 1. 0. 0. 2. 2. 2. 1. 1. 0. 0. 0. 2. 1. 1. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 2. 1. 1. 1. 2. 2. 2. 2. 2.
  1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 0. 1. 1. 1. 1. 1. 1. 1. 2. 0. 0.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1.
  1. 1. 1. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 0. 2. 2. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 1. 2. 2. 2. 2. 1. 1. 2. 2. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.
  1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 2. 2. 1. 2. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 1. 1. 2. 1. 1. 2. 2. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 2. 2.
  2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
max_steps:200
actions_size:7
optimal_score:0.86
total_frames:305000
exp_gamma:0.975
atari_env:False
reward_clipping:False
memory_size:100
image_size:[48, 48]
timesteps_in_obs:2
store_prev_actions:True
running_reward_in_obs:False
deque_length:3
PRESET_CONFIG:1
VK:True
use_two_heads:True
follow_better_policy:0.5
use_siam:True
exploration_type:rdn
rdn_beta:[0.16666666666666666, 0.6666666666666666, 4]
explorer_percentage:0.8
reward_exploration:False
train_dones:True
state_size:[6, 6]
norm_state_vecs:False
RND_output_vector:256
RND_loss:cosine
prediction_bias:True
distance_measure:False
update_play_model:16
gamma:0.99
calc_n_step_rewards_after_frames:10000
N_steps_reward:5
start_frame_count:0
load_in_model:False
log_states:True
log_metrics:False
exploration_logger_dims:(1, 480)
device_train:cpu
device_selfplay:cpu
eval_x_frames:10000
eval_count:20
detach_expV_calc:True
use_new_episode_expV:True
start_training_expV_min:10000
start_training_expV_max:20000
start_training_expV_siam_override:0.8
value_only:False
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.
  0. 0. 0. 0. 0. 0. 2. 2. 2. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.
  1. 1. 1. 1. 2. 1. 1. 1. 0. 0. 2. 2. 2. 1. 1. 0. 0. 0. 2. 1. 1. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 2. 1. 1. 1. 2. 2. 2. 2. 2.
  1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 0. 1. 1. 1. 1. 1. 1. 1. 2. 0. 0.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1.
  1. 1. 1. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 0. 2. 2. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 1. 2. 2. 2. 2. 1. 1. 2. 2. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.
  1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 2. 2. 1. 2. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 1. 1. 2. 1. 1. 2. 2. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 2. 2.
  2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Starting evaluation
Printing some Q and Qe and total Qs values:  [[-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]]
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  0.001438379991503263
first move QE:  0
maxi score, test score, baseline:  -0.9544454545454546 0.0 0.0
probs:  [0.25, 0.25, 0.25, 0.25]
rdn probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  0.004202971872963155
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.002312469617140373, 0.002312469617140373, 0.4976875303828596, 0.4976875303828596]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
deleting a thread, now have 3 threads
Frames:  579 train batches done:  8 episodes:  14
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
deleting a thread, now have 2 threads
Frames:  579 train batches done:  29 episodes:  14
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
siam score:  -0.13147707
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.0028150990058544126, 0.0028150990058544126, 0.3070426694601875, 0.6873271325281036]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
from probs:  [0.0032443033739495567, 0.0032443033739495567, 0.14424755858883553, 0.8492638346632654]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
Printing some Q and Qe and total Qs values:  [[0.864]
 [0.864]
 [0.864]
 [0.864]
 [0.846]
 [0.864]
 [0.847]] [[ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-1.484]
 [ 0.   ]
 [-1.483]] [[3.688]
 [3.688]
 [3.688]
 [3.688]
 [1.674]
 [3.688]
 [1.678]]
deleting a thread, now have 2 threads
Frames:  801 train batches done:  77 episodes:  22
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.2804092316334613, 0.2804092316334613, 0.43679956574840534, 0.002381970984671934]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.28541059068121927, 0.28541059068121927, 0.4270529534060966, 0.002125865231464843]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.28541059068121927, 0.28541059068121927, 0.4270529534060966, 0.002125865231464843]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.28541059068121927, 0.28541059068121927, 0.4270529534060966, 0.002125865231464843]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.28541059068121927, 0.28541059068121927, 0.4270529534060966, 0.002125865231464843]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.28541059068121927, 0.28541059068121927, 0.4270529534060966, 0.002125865231464843]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.28541059068121927, 0.28541059068121927, 0.4270529534060966, 0.002125865231464843]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.28541059068121927, 0.28541059068121927, 0.4270529534060966, 0.002125865231464843]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.28541059068121927, 0.28541059068121927, 0.4270529534060966, 0.002125865231464843]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.28541059068121927, 0.28541059068121927, 0.4270529534060966, 0.002125865231464843]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.28541059068121927, 0.28541059068121927, 0.4270529534060966, 0.002125865231464843]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
deleting a thread, now have 2 threads
Frames:  1042 train batches done:  120 episodes:  30
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.2992507893433684, 0.0037460532831576003, 0.6932571040903164, 0.0037460532831576003]
siam score:  -0.34872276
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.2992507893433684, 0.0037460532831576003, 0.6932571040903164, 0.0037460532831576003]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.2992507893433684, 0.0037460532831576003, 0.6932571040903164, 0.0037460532831576003]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.2992507893433684, 0.0037460532831576003, 0.6932571040903164, 0.0037460532831576003]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.2992507893433684, 0.0037460532831576003, 0.6932571040903164, 0.0037460532831576003]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.2992507893433684, 0.0037460532831576003, 0.6932571040903164, 0.0037460532831576003]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.2992507893433684, 0.0037460532831576003, 0.6932571040903164, 0.0037460532831576003]
siam score:  -0.3557878
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
siam score:  -0.35715842
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.2992507893433684, 0.0037460532831576003, 0.6932571040903164, 0.0037460532831576003]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.2992507893433684, 0.0037460532831576003, 0.6932571040903164, 0.0037460532831576003]
Printing some Q and Qe and total Qs values:  [[0.156]
 [0.156]
 [0.015]
 [0.053]
 [0.095]
 [0.156]
 [0.182]] [[ 0.   ]
 [ 0.   ]
 [-0.283]
 [-0.286]
 [-0.294]
 [ 0.   ]
 [-0.29 ]] [[0.156]
 [0.156]
 [0.015]
 [0.053]
 [0.095]
 [0.156]
 [0.182]]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.29925079122905707, 0.0037460438547145297, 0.6932571210615139, 0.0037460438547145297]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.6213286228620938, 0.006715729848973074, 0.3652399174399601, 0.006715729848973074]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.9702025406820238, 0.009932486439325393, 0.009932486439325393, 0.009932486439325393]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
siam score:  -0.37774453
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.9702025406820238, 0.009932486439325393, 0.009932486439325393, 0.009932486439325393]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.9702025406820238, 0.009932486439325393, 0.009932486439325393, 0.009932486439325393]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.9702025406820238, 0.009932486439325393, 0.009932486439325393, 0.009932486439325393]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.9702025406820238, 0.009932486439325393, 0.009932486439325393, 0.009932486439325393]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.9702025406820238, 0.009932486439325393, 0.009932486439325393, 0.009932486439325393]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.9032214628316696, 0.03225951238944341, 0.03225951238944341, 0.03225951238944341]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.03525839018023365, 0.03525839018023365, 0.03525839018023365, 0.8942248294592992]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.03525839018023365, 0.03525839018023365, 0.03525839018023365, 0.8942248294592992]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.2733164000629254, 0.2733164000629254, 0.006843256486633439, 0.4465239433875156]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.2733164000629254, 0.2733164000629254, 0.006843256486633439, 0.4465239433875156]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.2733164000629254, 0.2733164000629254, 0.006843256486633439, 0.4465239433875156]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.2733164000629254, 0.2733164000629254, 0.006843256486633439, 0.4465239433875156]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.2733164000629254, 0.2733164000629254, 0.006843256486633439, 0.4465239433875156]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.18887625546409378, 0.40077190318856837, 0.009579938158769548, 0.40077190318856837]
siam score:  -0.47859618
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.021088066947369807, 0.9367357991578905, 0.021088066947369807, 0.021088066947369807]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.041016813762674346, 0.8769495587119768, 0.041016813762674346, 0.041016813762674346]
siam score:  -0.48360956
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.041016813762674346, 0.8769495587119768, 0.041016813762674346, 0.041016813762674346]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.041016813762674346, 0.8769495587119768, 0.041016813762674346, 0.041016813762674346]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.041016813762674346, 0.8769495587119768, 0.041016813762674346, 0.041016813762674346]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.041016813762674346, 0.8769495587119768, 0.041016813762674346, 0.041016813762674346]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.041016813762674346, 0.8769495587119768, 0.041016813762674346, 0.041016813762674346]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.041016813762674346, 0.8769495587119768, 0.041016813762674346, 0.041016813762674346]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.3123855982226971, 0.017471861169944813, 0.017471861169944813, 0.6526706794374132]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.39807800914751224, 0.1920564312031475, 0.011787550501828108, 0.39807800914751224]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.39807800914751224, 0.1920564312031475, 0.011787550501828108, 0.39807800914751224]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.39807800914751224, 0.1920564312031475, 0.011787550501828108, 0.39807800914751224]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.39807800914751224, 0.1920564312031475, 0.011787550501828108, 0.39807800914751224]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.39807800914751224, 0.1920564312031475, 0.011787550501828108, 0.39807800914751224]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.39807800914751224, 0.1920564312031475, 0.011787550501828108, 0.39807800914751224]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.39807800914751224, 0.1920564312031475, 0.011787550501828108, 0.39807800914751224]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.24243513171550254, 0.4996406533884136, 0.24243513171550254, 0.015489083180581386]
using another actor
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.27671905595071294, 0.43703339165498956, 0.27671905595071294, 0.009528496443584668]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.27671905595071294, 0.43703339165498956, 0.27671905595071294, 0.009528496443584668]
40 31
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.29101883410187895, 0.4109200414766026, 0.29101883410187895, 0.007042290319639396]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.3759927952690254, 0.23920061754836913, 0.3759927952690254, 0.008813791913580239]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.3759927952690254, 0.23920061754836913, 0.3759927952690254, 0.008813791913580239]
siam score:  -0.5458643
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.1943041350378176, 0.39587012252000087, 0.39587012252000087, 0.013955619922180617]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.1943041350378176, 0.39587012252000087, 0.39587012252000087, 0.013955619922180617]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.1943041350378176, 0.39587012252000087, 0.39587012252000087, 0.013955619922180617]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.1943041350378176, 0.39587012252000087, 0.39587012252000087, 0.013955619922180617]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.1943041350378176, 0.39587012252000087, 0.39587012252000087, 0.013955619922180617]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.1943041350378176, 0.39587012252000087, 0.39587012252000087, 0.013955619922180617]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.1943041350378176, 0.39587012252000087, 0.39587012252000087, 0.013955619922180617]
from probs:  [0.1943041350378176, 0.39587012252000087, 0.39587012252000087, 0.013955619922180617]
using another actor
maxi score, test score, baseline:  -0.96865 -1.0 -0.96865
probs:  [0.19430412282607218, 0.3958701545031438, 0.3958701545031438, 0.013955568167640245]
maxi score, test score, baseline:  -0.96865 -1.0 -0.96865
probs:  [0.016820996609042415, 0.4831790033909576, 0.4831790033909576, 0.016820996609042415]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.05658868104690218, 0.05658868104690218, 0.8302339568592934, 0.05658868104690218]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.05658868104690218, 0.05658868104690218, 0.8302339568592934, 0.05658868104690218]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.05658868104690218, 0.05658868104690218, 0.8302339568592934, 0.05658868104690218]
first move QE:  -0.2215435042535926
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.05658868104690218, 0.05658868104690218, 0.8302339568592934, 0.05658868104690218]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.05658868104690218, 0.05658868104690218, 0.8302339568592934, 0.05658868104690218]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.05658868104690218, 0.05658868104690218, 0.8302339568592934, 0.05658868104690218]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.05658868104690218, 0.05658868104690218, 0.8302339568592934, 0.05658868104690218]
siam score:  -0.5551191
from probs:  [0.018111265635897343, 0.24373273690907843, 0.49442326054594576, 0.24373273690907843]
rdn beta is 0 so we're just using the maxi policy
in main func line 156:  54
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
probs:  [0.0337973907400612, 0.4662026092599388, 0.0337973907400612, 0.4662026092599388]
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
probs:  [0.0337973907400612, 0.4662026092599388, 0.0337973907400612, 0.4662026092599388]
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
probs:  [0.0337973907400612, 0.4662026092599388, 0.0337973907400612, 0.4662026092599388]
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
probs:  [0.0337973907400612, 0.4662026092599388, 0.0337973907400612, 0.4662026092599388]
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
probs:  [0.0337973907400612, 0.4662026092599388, 0.0337973907400612, 0.4662026092599388]
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
probs:  [0.0337973907400612, 0.4662026092599388, 0.0337973907400612, 0.4662026092599388]
maxi score, test score, baseline:  -0.9713285714285714 -1.0 -0.9713285714285714
probs:  [0.03379728636324063, 0.46620271363675936, 0.03379728636324063, 0.46620271363675936]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.3250140029799167, 0.024957991060249825, 0.3250140029799167, 0.3250140029799167]
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.8161611825535687, 0.06127960581547706, 0.06127960581547706, 0.06127960581547706]
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.8161611825535687, 0.06127960581547706, 0.06127960581547706, 0.06127960581547706]
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.8161611825535687, 0.06127960581547706, 0.06127960581547706, 0.06127960581547706]
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.8161611825535687, 0.06127960581547706, 0.06127960581547706, 0.06127960581547706]
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.8161611825535687, 0.06127960581547706, 0.06127960581547706, 0.06127960581547706]
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.8161611825535687, 0.06127960581547706, 0.06127960581547706, 0.06127960581547706]
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.8161611825535687, 0.06127960581547706, 0.06127960581547706, 0.06127960581547706]
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.8161611825535687, 0.06127960581547706, 0.06127960581547706, 0.06127960581547706]
maxi score, test score, baseline:  -0.9721222222222222 -1.0 -0.9721222222222222
probs:  [0.25, 0.25, 0.25, 0.25]
61 35
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.32465403087918265, 0.32465403087918265, 0.32465403087918265, 0.026037907362452158]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.02710780533408167, 0.32429739822197273, 0.32429739822197273, 0.32429739822197273]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.02710780533408167, 0.32429739822197273, 0.32429739822197273, 0.32429739822197273]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.02710780533408167, 0.32429739822197273, 0.32429739822197273, 0.32429739822197273]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.02710780533408167, 0.32429739822197273, 0.32429739822197273, 0.32429739822197273]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.02710780533408167, 0.32429739822197273, 0.32429739822197273, 0.32429739822197273]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.02710780533408167, 0.32429739822197273, 0.32429739822197273, 0.32429739822197273]
using another actor
from probs:  [0.02710780533408167, 0.32429739822197273, 0.32429739822197273, 0.32429739822197273]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9735842105263158 -1.0 -0.9735842105263158
maxi score, test score, baseline:  -0.9735842105263158 -1.0 -0.9735842105263158
probs:  [0.19697016012589325, 0.3927726458149032, 0.3927726458149032, 0.017484548244300416]
maxi score, test score, baseline:  -0.9735842105263158 -1.0 -0.9735842105263158
probs:  [0.4603552171014984, 0.4603552171014984, 0.03964478289850165, 0.03964478289850165]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.06790775104915923, 0.7962767468525223, 0.06790775104915923, 0.06790775104915923]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.06790775104915923, 0.7962767468525223, 0.06790775104915923, 0.06790775104915923]
siam score:  -0.6180091
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.06790775104915923, 0.7962767468525223, 0.06790775104915923, 0.06790775104915923]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.06790775104915923, 0.7962767468525223, 0.06790775104915923, 0.06790775104915923]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.06790775104915923, 0.7962767468525223, 0.06790775104915923, 0.06790775104915923]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.5825944
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.39166175583528945, 0.1978088267975249, 0.018867661531896184, 0.39166175583528945]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.39166175583528945, 0.1978088267975249, 0.018867661531896184, 0.39166175583528945]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.39166175583528945, 0.1978088267975249, 0.018867661531896184, 0.39166175583528945]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.39166175583528945, 0.1978088267975249, 0.018867661531896184, 0.39166175583528945]
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
probs:  [0.3916617923485003, 0.19780881334528938, 0.018867601957710034, 0.3916617923485003]
first move QE:  -0.11466703362038981
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.4575470005289021, 0.04245299947109787, 0.04245299947109787, 0.4575470005289021]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.4575470005289021, 0.04245299947109787, 0.04245299947109787, 0.4575470005289021]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.4575470005289021, 0.04245299947109787, 0.04245299947109787, 0.4575470005289021]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.4575470005289021, 0.04245299947109787, 0.04245299947109787, 0.4575470005289021]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.4575470005289021, 0.04245299947109787, 0.04245299947109787, 0.4575470005289021]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.4575470005289021, 0.04245299947109787, 0.04245299947109787, 0.4575470005289021]
maxi score, test score, baseline:  -0.975509756097561 -1.0 -0.975509756097561
probs:  [0.07207581817465489, 0.07207581817465489, 0.07207581817465489, 0.7837725454760354]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.04382964283038932, 0.4561703571696107, 0.4561703571696107, 0.04382964283038932]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.04382964283038932, 0.4561703571696107, 0.4561703571696107, 0.04382964283038932]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.04382964283038932, 0.4561703571696107, 0.4561703571696107, 0.04382964283038932]
siam score:  -0.60217875
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.04382964283038932, 0.4561703571696107, 0.4561703571696107, 0.04382964283038932]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.04382964283038932, 0.4561703571696107, 0.4561703571696107, 0.04382964283038932]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.04382964283038932, 0.4561703571696107, 0.4561703571696107, 0.04382964283038932]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.04382964283038932, 0.4561703571696107, 0.4561703571696107, 0.04382964283038932]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
UNIT TEST: sample policy line 217 mcts : [0.2 0.2 0.  0.2 0.2 0.2 0. ]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
in main func line 156:  85
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.3274315827989978, 0.3274315827989978, 0.01770525160300649, 0.3274315827989978]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
from probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
siam score:  -0.655757
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
maxi score, test score, baseline:  -0.9766441860465116 -1.0 -0.9766441860465116
probs:  [0.39008946825296514, 0.39008946825296514, 0.020912516621621607, 0.19890854687244805]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
using explorer policy with actor:  1
main train batch thing paused
add a thread
Adding thread: now have 4 threads
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.39008950498451495, 0.39008950498451495, 0.0209124565547348, 0.19890853347623524]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.39008950498451495, 0.39008950498451495, 0.0209124565547348, 0.19890853347623524]
main train batch thing paused
add a thread
Adding thread: now have 5 threads
using explorer policy with actor:  1
main train batch thing paused
add a thread
Adding thread: now have 6 threads
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.202]
 [1.202]
 [1.202]
 [1.202]
 [1.192]
 [1.202]
 [1.202]] [[-0.18 ]
 [-0.18 ]
 [-0.18 ]
 [-0.18 ]
 [-0.003]
 [-0.18 ]
 [-0.18 ]] [[0.837]
 [0.837]
 [0.837]
 [0.837]
 [0.935]
 [0.837]
 [0.837]]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.24592078944706197, 0.4825150015174637, 0.025643419588412507, 0.24592078944706197]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.24592078944706197, 0.4825150015174637, 0.025643419588412507, 0.24592078944706197]
Printing some Q and Qe and total Qs values:  [[0.958]
 [0.958]
 [0.958]
 [0.948]
 [0.955]
 [0.958]
 [0.947]] [[0.014]
 [0.014]
 [0.014]
 [0.166]
 [0.208]
 [0.014]
 [0.662]] [[0.428]
 [0.428]
 [0.428]
 [0.509]
 [0.551]
 [0.428]
 [0.837]]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.24592078944706197, 0.4825150015174637, 0.025643419588412507, 0.24592078944706197]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.24592078944706197, 0.4825150015174637, 0.025643419588412507, 0.24592078944706197]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.24592078944706197, 0.4825150015174637, 0.025643419588412507, 0.24592078944706197]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.24592078944706197, 0.4825150015174637, 0.025643419588412507, 0.24592078944706197]
main train batch thing paused
using explorer policy with actor:  1
main train batch thing paused
main train batch thing paused
main train batch thing paused
main train batch thing paused
Printing some Q and Qe and total Qs values:  [[0.568]
 [0.446]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.572]] [[0.014]
 [0.005]
 [0.159]
 [0.159]
 [0.159]
 [0.159]
 [0.394]] [[-0.352]
 [-0.603]
 [-0.253]
 [-0.253]
 [-0.253]
 [-0.253]
 [-0.091]]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.04652965943615044, 0.45347034056384955, 0.04652965943615044, 0.45347034056384955]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.04652965943615044, 0.45347034056384955, 0.04652965943615044, 0.45347034056384955]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.04652965943615044, 0.45347034056384955, 0.04652965943615044, 0.45347034056384955]
main train batch thing paused
using another actor
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.3218915986081326, 0.03432520417560232, 0.3218915986081326, 0.3218915986081326]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.3218915986081326, 0.03432520417560232, 0.3218915986081326, 0.3218915986081326]
using another actor
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.38909167431275404, 0.1995601620624079, 0.38909167431275404, 0.022256489312084057]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.38909167431275404, 0.1995601620624079, 0.38909167431275404, 0.022256489312084057]
line 256 mcts: sample exp_bonus -0.04800956913624562
siam score:  -0.6735315
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.4731392557109493, 0.0268607442890507, 0.4731392557109493, 0.0268607442890507]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.4731392557109493, 0.0268607442890507, 0.4731392557109493, 0.0268607442890507]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.4731392557109493, 0.0268607442890507, 0.4731392557109493, 0.0268607442890507]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.6153655111310015, 0.03465211595590005, 0.31533025695719846, 0.03465211595590005]
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.557]
 [0.563]
 [0.563]
 [0.565]
 [0.563]
 [0.571]] [[ 0.109]
 [ 0.368]
 [ 0.109]
 [ 0.109]
 [-0.002]
 [ 0.109]
 [ 0.038]] [[0.563]
 [0.557]
 [0.563]
 [0.563]
 [0.565]
 [0.563]
 [0.571]]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.4910872091247774, 0.16636785344636765, 0.32331554202426643, 0.019229395404588605]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.4910872091247774, 0.16636785344636765, 0.32331554202426643, 0.019229395404588605]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.4910872091247774, 0.16636785344636765, 0.32331554202426643, 0.019229395404588605]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.4910872091247774, 0.16636785344636765, 0.32331554202426643, 0.019229395404588605]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.4910872091247774, 0.16636785344636765, 0.32331554202426643, 0.019229395404588605]
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
probs:  [0.4910872091247774, 0.16636785344636765, 0.32331554202426643, 0.019229395404588605]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
from probs:  [0.4910872091247774, 0.16636785344636765, 0.32331554202426643, 0.019229395404588605]
Printing some Q and Qe and total Qs values:  [[0.211]
 [0.202]
 [0.205]
 [0.202]
 [0.206]
 [0.21 ]
 [0.215]] [[-0.026]
 [-0.222]
 [-0.019]
 [-0.066]
 [-0.058]
 [-0.038]
 [-0.013]] [[-0.727]
 [-1.007]
 [-0.728]
 [-0.798]
 [-0.779]
 [-0.744]
 [-0.702]]
siam score:  -0.67985
first move QE:  -0.09264364836915101
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.5827588507388378, 0.1973006344983738, 0.1973006344983738, 0.022639880264414602]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.5827588507388378, 0.1973006344983738, 0.1973006344983738, 0.022639880264414602]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.5827588507388378, 0.1973006344983738, 0.1973006344983738, 0.022639880264414602]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.5827588507388378, 0.1973006344983738, 0.1973006344983738, 0.022639880264414602]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
from probs:  [0.5827589460420071, 0.19730061940511193, 0.19730061940511193, 0.02263981514776913]
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
probs:  [0.5005935833349352, 0.2421689505207831, 0.2421689505207831, 0.015068515623498691]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.5005936293382478, 0.24216894908317954, 0.24216894908317954, 0.015068472495393082]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.5005936293382478, 0.24216894908317954, 0.24216894908317954, 0.015068472495393082]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.5005936293382478, 0.24216894908317954, 0.24216894908317954, 0.015068472495393082]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.5005936293382478, 0.24216894908317954, 0.24216894908317954, 0.015068472495393082]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.5005936293382478, 0.24216894908317954, 0.24216894908317954, 0.015068472495393082]
Printing some Q and Qe and total Qs values:  [[1.116]
 [0.946]
 [1.117]
 [1.137]
 [1.136]
 [1.131]
 [1.122]] [[ 0.289]
 [ 0.113]
 [-0.007]
 [-0.008]
 [ 0.   ]
 [ 0.021]
 [ 0.121]] [[1.922]
 [1.524]
 [1.826]
 [1.864]
 [1.866]
 [1.864]
 [1.878]]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.5005936293382478, 0.24216894908317954, 0.24216894908317954, 0.015068472495393082]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.5005936293382478, 0.24216894908317954, 0.24216894908317954, 0.015068472495393082]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.4237452198379785, 0.2795039052555056, 0.2795039052555056, 0.01724696965101007]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.4237452198379785, 0.2795039052555056, 0.2795039052555056, 0.01724696965101007]
Printing some Q and Qe and total Qs values:  [[0.719]
 [0.711]
 [0.725]
 [0.725]
 [0.728]
 [0.726]
 [0.725]] [[ 0.024]
 [ 0.048]
 [-0.015]
 [-0.028]
 [-0.043]
 [-0.046]
 [-0.016]] [[0.719]
 [0.711]
 [0.725]
 [0.725]
 [0.728]
 [0.726]
 [0.725]]
first move QE:  -0.09212385519626003
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.4237452198379785, 0.2795039052555056, 0.2795039052555056, 0.01724696965101007]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.5748424824106662, 0.3790470135604004, 0.023055252014466752, 0.023055252014466752]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
siam score:  -0.6840488
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.4715473623320272, 0.4715473623320272, 0.028452637667972833, 0.028452637667972833]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.4715473623320272, 0.4715473623320272, 0.028452637667972833, 0.028452637667972833]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.4715473623320272, 0.4715473623320272, 0.028452637667972833, 0.028452637667972833]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.4715473623320272, 0.4715473623320272, 0.028452637667972833, 0.028452637667972833]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.3151353766045049, 0.611613642528457, 0.03662549043351905, 0.03662549043351905]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.3151353766045049, 0.611613642528457, 0.03662549043351905, 0.03662549043351905]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.3151353766045049, 0.611613642528457, 0.03662549043351905, 0.03662549043351905]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.023965366122177433, 0.5799263289521019, 0.19805415246286032, 0.19805415246286032]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.015955066148555786, 0.4986727422171601, 0.24268609581714207, 0.24268609581714207]
siam score:  -0.6921291
in main func line 156:  111
Printing some Q and Qe and total Qs values:  [[0.825]
 [0.83 ]
 [0.832]
 [0.833]
 [0.838]
 [0.841]
 [0.84 ]] [[-0.053]
 [-0.04 ]
 [-0.036]
 [-0.173]
 [-0.175]
 [-0.099]
 [-0.118]] [[0.938]
 [0.956]
 [0.965]
 [0.876]
 [0.883]
 [0.94 ]
 [0.925]]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.013334670188083741, 0.39901150395565094, 0.29382691292813273, 0.29382691292813273]
Printing some Q and Qe and total Qs values:  [[0.945]
 [0.945]
 [0.945]
 [0.945]
 [0.945]
 [0.945]
 [0.945]] [[0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]
 [0.]] [[0.945]
 [0.945]
 [0.945]
 [0.945]
 [0.945]
 [0.945]
 [0.945]]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.014696353406721874, 0.4429375399073839, 0.2162216176423276, 0.32614448904356663]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.332]
 [1.342]
 [1.342]
 [1.342]
 [1.342]
 [1.342]
 [1.342]] [[ 0.001]
 [-0.109]
 [-0.109]
 [-0.109]
 [-0.109]
 [-0.109]
 [-0.109]] [[2.908]
 [2.819]
 [2.819]
 [2.819]
 [2.819]
 [2.819]
 [2.819]]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.01469631309608229, 0.44293757296014685, 0.2162216118556419, 0.3261445020881289]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.01469631309608229, 0.44293757296014685, 0.2162216118556419, 0.3261445020881289]
Printing some Q and Qe and total Qs values:  [[0.293]
 [0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.289]] [[-0.   ]
 [-0.024]
 [-0.024]
 [-0.024]
 [-0.024]
 [-0.024]
 [ 0.105]] [[-0.25 ]
 [-0.284]
 [-0.284]
 [-0.284]
 [-0.284]
 [-0.284]
 [-0.187]]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.01469631309608229, 0.44293757296014685, 0.2162216118556419, 0.3261445020881289]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.01469631309608229, 0.44293757296014685, 0.2162216118556419, 0.3261445020881289]
Printing some Q and Qe and total Qs values:  [[0.749]
 [0.748]
 [0.761]
 [0.761]
 [0.76 ]
 [0.75 ]
 [0.753]] [[-0.049]
 [ 0.104]
 [-0.312]
 [-0.29 ]
 [-0.281]
 [-0.136]
 [-0.106]] [[0.367]
 [0.57 ]
 [0.041]
 [0.07 ]
 [0.081]
 [0.253]
 [0.299]]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.01469631309608229, 0.44293757296014685, 0.2162216118556419, 0.3261445020881289]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.01469631309608229, 0.44293757296014685, 0.2162216118556419, 0.3261445020881289]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.01469631309608229, 0.44293757296014685, 0.2162216118556419, 0.3261445020881289]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.523]
 [0.527]
 [0.501]
 [0.527]
 [0.506]
 [0.507]
 [0.496]] [[0.372]
 [0.101]
 [0.042]
 [0.101]
 [0.146]
 [0.117]
 [0.311]] [[ 0.074]
 [-0.279]
 [-0.411]
 [-0.279]
 [-0.26 ]
 [-0.299]
 [-0.063]]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.01469631309608229, 0.44293757296014685, 0.2162216118556419, 0.3261445020881289]
using another actor
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.018733848697718047, 0.4219671381478501, 0.27964950657721593, 0.27964950657721593]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.018733848697718047, 0.4219671381478501, 0.27964950657721593, 0.27964950657721593]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.018733848697718047, 0.4219671381478501, 0.27964950657721593, 0.27964950657721593]
maxi score, test score, baseline:  -0.9799 -1.0 -0.9799
probs:  [0.021495591165115232, 0.4875114378035264, 0.16795771439433033, 0.32303525663702803]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.0214955349575931, 0.48751149622659756, 0.16795769421356607, 0.3230352746022433]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.02502963003298652, 0.5713862428100193, 0.02502963003298652, 0.3785544971240077]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.12598704378875814, 0.4934977597221914, 0.016727101213953915, 0.36378809527509665]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.12598704378875814, 0.4934977597221914, 0.016727101213953915, 0.36378809527509665]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.12598704378875814, 0.4934977597221914, 0.016727101213953915, 0.36378809527509665]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.12598704378875814, 0.4934977597221914, 0.016727101213953915, 0.36378809527509665]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.17509385832146768, 0.45561193092629054, 0.012688658392359727, 0.35660555235988206]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.17509385832146768, 0.45561193092629054, 0.012688658392359727, 0.35660555235988206]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.539]
 [0.502]
 [0.52 ]
 [0.531]
 [0.53 ]
 [0.531]
 [0.53 ]] [[-0.083]
 [ 0.305]
 [-0.07 ]
 [-0.046]
 [-0.075]
 [-0.01 ]
 [-0.019]] [[0.389]
 [0.832]
 [0.369]
 [0.42 ]
 [0.381]
 [0.47 ]
 [0.455]]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.19430969482526547, 0.39585556117192405, 0.013979182830886465, 0.39585556117192405]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
using another actor
from probs:  [0.21676396837609674, 0.44172031473635776, 0.015487237422178633, 0.3260284794653668]
Printing some Q and Qe and total Qs values:  [[1.193]
 [1.193]
 [1.193]
 [1.193]
 [1.193]
 [1.193]
 [1.193]] [[0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]
 [0.001]] [[2.181]
 [2.181]
 [2.181]
 [2.181]
 [2.181]
 [2.181]
 [2.181]]
siam score:  -0.67824876
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
siam score:  -0.67617655
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
Printing some Q and Qe and total Qs values:  [[0.723]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]] [[-0.02 ]
 [ 0.036]
 [ 0.036]
 [ 0.036]
 [ 0.036]
 [ 0.036]
 [ 0.036]] [[1.143]
 [1.156]
 [1.156]
 [1.156]
 [1.156]
 [1.156]
 [1.156]]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.24335065226856042, 0.49602586606327576, 0.017272829399603302, 0.24335065226856042]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.1439150478383476, 0.5613384837649258, 0.019420338877789226, 0.27532612951893737]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.1439150478383476, 0.5613384837649258, 0.019420338877789226, 0.27532612951893737]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.1439150478383476, 0.5613384837649258, 0.019420338877789226, 0.27532612951893737]
siam score:  -0.678526
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.1439150478383476, 0.5613384837649258, 0.019420338877789226, 0.27532612951893737]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.026327573931193112, 0.5691730124802072, 0.026327573931193112, 0.37817183965740664]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.026327573931193112, 0.5691730124802072, 0.026327573931193112, 0.37817183965740664]
Printing some Q and Qe and total Qs values:  [[1.295]
 [1.061]
 [1.256]
 [1.274]
 [1.285]
 [1.256]
 [1.267]] [[ 0.007]
 [-0.102]
 [ 0.076]
 [ 0.011]
 [-0.008]
 [ 0.076]
 [ 0.019]] [[2.357]
 [1.817]
 [2.325]
 [2.317]
 [2.327]
 [2.325]
 [2.31 ]]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.03233784542712651, 0.46766215457287347, 0.03233784542712651, 0.46766215457287347]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.03233776568014713, 0.4676622343198529, 0.03233776568014713, 0.4676622343198529]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.03233776568014713, 0.4676622343198529, 0.03233776568014713, 0.4676622343198529]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.03233776568014713, 0.4676622343198529, 0.03233776568014713, 0.4676622343198529]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.03233776568014713, 0.4676622343198529, 0.03233776568014713, 0.4676622343198529]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.03233776568014713, 0.4676622343198529, 0.03233776568014713, 0.4676622343198529]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
UNIT TEST: sample policy line 217 mcts : [0.184 0.041 0.122 0.245 0.163 0.082 0.163]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.09358730805835427, 0.7192380758249372, 0.09358730805835427, 0.09358730805835427]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.09358730805835427, 0.7192380758249372, 0.09358730805835427, 0.09358730805835427]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.09358730805835427, 0.7192380758249372, 0.09358730805835427, 0.09358730805835427]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.3190138359686222, 0.3190138359686222, 0.3190138359686222, 0.0429584920941334]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.3190138359686222, 0.3190138359686222, 0.3190138359686222, 0.0429584920941334]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
Starting evaluation
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
using explorer policy with actor:  0
first move QE:  -0.07044216721776517
Printing some Q and Qe and total Qs values:  [[0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]] [[1.469]
 [1.469]
 [1.469]
 [1.469]
 [1.469]
 [1.469]
 [1.469]] [[0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]]
siam score:  -0.66543937
Printing some Q and Qe and total Qs values:  [[0.492]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]] [[0.006]
 [0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.008]] [[0.492]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9817181818181818 -1.0 -0.9817181818181818
probs:  [0.4192816722083054, 0.27977315842859624, 0.27977315842859624, 0.021172010934502213]
Printing some Q and Qe and total Qs values:  [[0.482]
 [0.436]
 [0.495]
 [0.515]
 [0.518]
 [0.513]
 [0.524]] [[-0.]
 [ 0.]
 [ 0.]
 [-0.]
 [-0.]
 [ 0.]
 [ 0.]] [[0.482]
 [0.436]
 [0.495]
 [0.515]
 [0.518]
 [0.513]
 [0.524]]
maxi score, test score, baseline:  -0.9817181818181818 -1.0 -0.9817181818181818
probs:  [0.4192816722083054, 0.27977315842859624, 0.27977315842859624, 0.021172010934502213]
maxi score, test score, baseline:  -0.9820428571428571 -1.0 -0.9820428571428571
Printing some Q and Qe and total Qs values:  [[0.471]
 [0.414]
 [0.471]
 [0.475]
 [0.473]
 [0.474]
 [0.484]] [[0.005]
 [0.007]
 [0.005]
 [0.006]
 [0.005]
 [0.005]
 [0.005]] [[0.471]
 [0.414]
 [0.471]
 [0.475]
 [0.473]
 [0.474]
 [0.484]]
maxi score, test score, baseline:  -0.9820428571428571 -1.0 -0.9820428571428571
probs:  [0.3845268868575663, 0.20219292450516235, 0.3845268868575663, 0.028753301779705056]
siam score:  -0.6240945
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9820428571428571 -1.0 -0.9820428571428571
probs:  [0.3845268868575663, 0.20219292450516235, 0.3845268868575663, 0.028753301779705056]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.544]
 [0.586]
 [0.589]
 [0.589]
 [0.591]
 [0.595]] [[0.005]
 [0.005]
 [0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.005]] [[0.582]
 [0.544]
 [0.586]
 [0.589]
 [0.589]
 [0.591]
 [0.595]]
maxi score, test score, baseline:  -0.9820428571428571 -1.0 -0.9820428571428571
Printing some Q and Qe and total Qs values:  [[0.457]
 [0.458]
 [0.458]
 [0.458]
 [0.458]
 [0.458]
 [0.458]] [[-0.011]
 [-0.011]
 [-0.011]
 [-0.011]
 [-0.011]
 [-0.011]
 [-0.011]] [[0.457]
 [0.458]
 [0.458]
 [0.458]
 [0.458]
 [0.458]
 [0.458]]
Printing some Q and Qe and total Qs values:  [[0.447]
 [0.371]
 [0.448]
 [0.45 ]
 [0.447]
 [0.445]
 [0.445]] [[-0.011]
 [-0.009]
 [-0.011]
 [-0.011]
 [-0.011]
 [-0.011]
 [-0.011]] [[0.447]
 [0.371]
 [0.448]
 [0.45 ]
 [0.447]
 [0.445]
 [0.445]]
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]] [[-0.012]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.012]] [[0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]]
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.24727814006429233, 0.24727814006429233, 0.4704706547923156, 0.034973065079099724]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.24727814006429233, 0.24727814006429233, 0.4704706547923156, 0.034973065079099724]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9829508474576272 -1.0 -0.9829508474576272
probs:  [0.24727814006429233, 0.24727814006429233, 0.4704706547923156, 0.034973065079099724]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.409]
 [0.334]
 [0.416]
 [0.417]
 [0.416]
 [0.413]
 [0.413]] [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[0.409]
 [0.334]
 [0.416]
 [0.417]
 [0.416]
 [0.413]
 [0.413]]
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.2472781391626508, 0.2472781391626508, 0.47047072782533905, 0.03497299384935942]
using explorer policy with actor:  0
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 0.00256752020276778
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
Printing some Q and Qe and total Qs values:  [[-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]] [[-0.067]
 [-0.067]
 [-0.067]
 [-0.067]
 [-0.067]
 [-0.067]
 [-0.067]] [[-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]]
siam score:  -0.73869246
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.24727813829130824, 0.24727813829130824, 0.4704707984040251, 0.03497292501335848]
first move QE:  -0.06725222168036267
using explorer policy with actor:  1
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 0.0030095032388075074
maxi score, test score, baseline:  -0.9840269841269841 -1.0 -0.9840269841269841
probs:  [0.3139953794874691, 0.044177022729494995, 0.5976505750535409, 0.044177022729494995]
maxi score, test score, baseline:  -0.9840269841269841 -1.0 -0.9840269841269841
probs:  [0.3139953794874691, 0.044177022729494995, 0.5976505750535409, 0.044177022729494995]
using explorer policy with actor:  1
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.02911982433959076, 0.2005492144043857, 0.5697817468516377, 0.2005492144043857]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.02911982433959076, 0.2005492144043857, 0.5697817468516377, 0.2005492144043857]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.02911982433959076, 0.2005492144043857, 0.5697817468516377, 0.2005492144043857]
Printing some Q and Qe and total Qs values:  [[0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]] [[0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
Printing some Q and Qe and total Qs values:  [[0.476]
 [0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]] [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.476]
 [0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]]
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.543]
 [0.541]
 [0.542]
 [0.542]
 [0.542]
 [0.541]] [[0.003]
 [0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.005]
 [0.005]] [[0.537]
 [0.543]
 [0.541]
 [0.542]
 [0.542]
 [0.542]
 [0.541]]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.02911982433959076, 0.2005492144043857, 0.5697817468516377, 0.2005492144043857]
Printing some Q and Qe and total Qs values:  [[0.337]
 [0.341]
 [0.341]
 [0.341]
 [0.341]
 [0.341]
 [0.341]] [[0.01 ]
 [0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]
 [0.005]] [[0.337]
 [0.341]
 [0.341]
 [0.341]
 [0.341]
 [0.341]
 [0.341]]
Printing some Q and Qe and total Qs values:  [[0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]] [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]] [[0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]
 [0.478]]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.019437535702399856, 0.24423593839255958, 0.4920905875124809, 0.24423593839255958]
STARTED EXPV TRAINING ON FRAME NO.  10723
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.014715312760951189, 0.26554272421396874, 0.4541992388111112, 0.26554272421396874]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.014715312760951189, 0.26554272421396874, 0.4541992388111112, 0.26554272421396874]
using explorer policy with actor:  0
from probs:  [0.014715312760951189, 0.26554272421396874, 0.4541992388111112, 0.26554272421396874]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.01603812957245613, 0.19501434333331877, 0.4978971666209318, 0.2910503604732933]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
Printing some Q and Qe and total Qs values:  [[0.292]
 [0.294]
 [0.294]
 [0.294]
 [0.294]
 [0.294]
 [0.285]] [[0.012]
 [0.011]
 [0.011]
 [0.011]
 [0.011]
 [0.011]
 [0.012]] [[0.292]
 [0.294]
 [0.294]
 [0.294]
 [0.294]
 [0.294]
 [0.285]]
Printing some Q and Qe and total Qs values:  [[0.809]
 [0.691]
 [0.691]
 [0.691]
 [0.691]
 [0.691]
 [0.691]] [[-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]] [[1.607]
 [1.371]
 [1.371]
 [1.371]
 [1.371]
 [1.371]
 [1.371]]
maxi score, test score, baseline:  -0.9847484848484849 -1.0 -0.9847484848484849
probs:  [0.01603806813886547, 0.19501432889521242, 0.49789723171364586, 0.2910503712522761]
maxi score, test score, baseline:  -0.9849746268656716 -1.0 -0.9849746268656716
maxi score, test score, baseline:  -0.9851941176470589 -1.0 -0.9851941176470589
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.836]
 [0.807]
 [0.844]
 [0.837]
 [0.835]
 [0.839]
 [0.832]] [[0.012]
 [0.012]
 [0.012]
 [0.012]
 [0.012]
 [0.012]
 [0.012]] [[1.614]
 [1.555]
 [1.629]
 [1.615]
 [1.612]
 [1.619]
 [1.606]]
maxi score, test score, baseline:  -0.9858154929577465 -1.0 -0.9858154929577465
maxi score, test score, baseline:  -0.9858154929577465 -1.0 -0.9858154929577465
probs:  [0.01646919287006305, 0.19627695047245575, 0.3936269283287406, 0.3936269283287406]
rdn probs:  [0.01646919287006305, 0.19627695047245575, 0.3936269283287406, 0.3936269283287406]
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.016469044192880457, 0.19627691626972354, 0.393627019768698, 0.393627019768698]
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.016469044192880457, 0.19627691626972354, 0.393627019768698, 0.393627019768698]
using explorer policy with actor:  1
siam score:  -0.82423997
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.016469044192880457, 0.19627691626972354, 0.393627019768698, 0.393627019768698]
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.016469044192880457, 0.19627691626972354, 0.393627019768698, 0.393627019768698]
Printing some Q and Qe and total Qs values:  [[-0.072]
 [-0.072]
 [-0.072]
 [-0.072]
 [-0.072]
 [-0.072]
 [-0.072]] [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[-0.141]
 [-0.141]
 [-0.141]
 [-0.141]
 [-0.141]
 [-0.141]
 [-0.141]]
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.016469044192880457, 0.19627691626972354, 0.393627019768698, 0.393627019768698]
Printing some Q and Qe and total Qs values:  [[0.224]
 [0.224]
 [0.224]
 [0.224]
 [0.224]
 [0.224]
 [0.224]] [[0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]]
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.016469044192880457, 0.19627691626972354, 0.393627019768698, 0.393627019768698]
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.020187215323935002, 0.12916081169242882, 0.362675661053486, 0.48797631193015023]
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.020187215323935002, 0.12916081169242882, 0.362675661053486, 0.48797631193015023]
siam score:  -0.8546307
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.84 ]
 [0.874]
 [0.875]
 [0.878]
 [0.874]
 [0.874]] [[-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]] [[1.671]
 [1.594]
 [1.663]
 [1.664]
 [1.671]
 [1.662]
 [1.662]]
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.022544863794433045, 0.022544863794433045, 0.4071081868636391, 0.5478020855474949]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.005691957098598512
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.02589895603709725, 0.02589895603709725, 0.31528928052462474, 0.6329128074011807]
maxi score, test score, baseline:  -0.986912987012987 -1.0 -0.986912987012987
probs:  [0.03718262932130398, 0.03718262932130398, 0.2426614699765975, 0.6829732713807947]
Printing some Q and Qe and total Qs values:  [[0.109]
 [0.104]
 [0.107]
 [0.109]
 [0.107]
 [0.106]
 [0.106]] [[-0.006]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.007]
 [-0.007]] [[0.109]
 [0.104]
 [0.107]
 [0.109]
 [0.107]
 [0.106]
 [0.106]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9870794871794872 -1.0 -0.9870794871794872
probs:  [0.04658830772716943, 0.04658830772716943, 0.04658830772716943, 0.8602350768184919]
maxi score, test score, baseline:  -0.9870794871794872 -1.0 -0.9870794871794872
probs:  [0.04658830772716943, 0.04658830772716943, 0.04658830772716943, 0.8602350768184919]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9872417721518988 -1.0 -0.9872417721518988
probs:  [0.046588251438977664, 0.046588251438977664, 0.046588251438977664, 0.8602352456830671]
siam score:  -0.87249374
maxi score, test score, baseline:  -0.9872417721518988 -1.0 -0.9872417721518988
probs:  [0.06475831863438186, 0.06475831863438186, 0.06475831863438186, 0.8057250440968544]
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.537]
 [0.537]
 [0.537]
 [0.537]
 [0.537]
 [0.537]] [[-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]] [[0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.801]]
from probs:  [0.06475831863438186, 0.06475831863438186, 0.06475831863438186, 0.8057250440968544]
using explorer policy with actor:  0
siam score:  -0.8726337
maxi score, test score, baseline:  -0.9872417721518988 -1.0 -0.9872417721518988
probs:  [0.201579136899864, 0.201579136899864, 0.03161202560958961, 0.5652297005906824]
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.201579136899864, 0.201579136899864, 0.03161202560958961, 0.5652297005906824]
maxi score, test score, baseline:  -0.9874 -1.0 -0.9874
probs:  [0.2015791279374338, 0.2015791279374338, 0.03161198518720106, 0.5652297589379313]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.382]
 [0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.38 ]] [[0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.008]] [[0.332]
 [0.327]
 [0.327]
 [0.327]
 [0.327]
 [0.327]
 [0.329]]
maxi score, test score, baseline:  -0.9874 -1.0 -0.9874
probs:  [0.2015791279374338, 0.2015791279374338, 0.03161198518720106, 0.5652297589379313]
maxi score, test score, baseline:  -0.9875543209876543 -1.0 -0.9875543209876543
Printing some Q and Qe and total Qs values:  [[0.047]
 [0.117]
 [0.044]
 [0.043]
 [0.044]
 [0.047]
 [0.046]] [[0.01 ]
 [0.009]
 [0.009]
 [0.01 ]
 [0.01 ]
 [0.009]
 [0.009]] [[-0.337]
 [-0.196]
 [-0.342]
 [-0.343]
 [-0.343]
 [-0.337]
 [-0.339]]
maxi score, test score, baseline:  -0.9878518072289156 -1.0 -0.9878518072289156
probs:  [0.24762516941485246, 0.24762516941485246, 0.03864007792187264, 0.46610958324842244]
Printing some Q and Qe and total Qs values:  [[0.177]
 [0.177]
 [0.177]
 [0.177]
 [0.177]
 [0.177]
 [0.178]] [[0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.009]] [[0.177]
 [0.177]
 [0.177]
 [0.177]
 [0.177]
 [0.177]
 [0.178]]
Printing some Q and Qe and total Qs values:  [[0.306]
 [0.371]
 [0.371]
 [0.371]
 [0.371]
 [0.371]
 [0.389]] [[-0.004]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.011]] [[0.415]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.572]]
maxi score, test score, baseline:  -0.9878518072289156 -1.0 -0.9878518072289156
probs:  [0.24762516941485246, 0.24762516941485246, 0.03864007792187264, 0.46610958324842244]
maxi score, test score, baseline:  -0.9878518072289156 -1.0 -0.9878518072289156
probs:  [0.24762516941485246, 0.24762516941485246, 0.03864007792187264, 0.46610958324842244]
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]] [[-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]] [[1.091]
 [1.091]
 [1.091]
 [1.091]
 [1.091]
 [1.091]
 [1.091]]
maxi score, test score, baseline:  -0.9878518072289156 -1.0 -0.9878518072289156
probs:  [0.31692734492566904, 0.31692734492566904, 0.049217965222992884, 0.31692734492566904]
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.559]] [[-0.001]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.008]] [[0.407]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.338]]
deleting a thread, now have 5 threads
Frames:  12332 train batches done:  1439 episodes:  220
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9878518072289156 -1.0 -0.9878518072289156
probs:  [0.4330567129115576, 0.4330567129115576, 0.0669432870884424, 0.0669432870884424]
maxi score, test score, baseline:  -0.9878518072289156 -1.0 -0.9878518072289156
probs:  [0.6841800523386373, 0.10527331588712094, 0.10527331588712094, 0.10527331588712094]
Printing some Q and Qe and total Qs values:  [[0.236]
 [0.239]
 [0.242]
 [0.244]
 [0.248]
 [0.242]
 [0.242]] [[-0.]
 [-0.]
 [-0.]
 [-0.]
 [-0.]
 [-0.]
 [-0.]] [[0.236]
 [0.239]
 [0.242]
 [0.244]
 [0.248]
 [0.242]
 [0.242]]
siam score:  -0.888767
maxi score, test score, baseline:  -0.9878518072289156 -1.0 -0.9878518072289156
probs:  [0.6841800523386373, 0.10527331588712094, 0.10527331588712094, 0.10527331588712094]
siam score:  -0.8894152
line 256 mcts: sample exp_bonus 0.0016027690294213239
maxi score, test score, baseline:  -0.9878518072289156 -1.0 -0.9878518072289156
probs:  [0.6841800523386373, 0.10527331588712094, 0.10527331588712094, 0.10527331588712094]
Printing some Q and Qe and total Qs values:  [[0.276]
 [0.272]
 [0.268]
 [0.269]
 [0.269]
 [0.273]
 [0.278]] [[0.003]
 [0.003]
 [0.004]
 [0.003]
 [0.003]
 [0.003]
 [0.003]] [[0.019]
 [0.009]
 [0.002]
 [0.003]
 [0.005]
 [0.011]
 [0.022]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9879952380952381 -1.0 -0.9879952380952381
probs:  [0.050082300711467055, 0.3166392330961777, 0.3166392330961777, 0.3166392330961777]
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9879952380952381 -1.0 -0.9879952380952381
probs:  [0.050082300711467055, 0.3166392330961777, 0.3166392330961777, 0.3166392330961777]
deleting a thread, now have 4 threads
Frames:  12575 train batches done:  1471 episodes:  225
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.0024636498998328606
Printing some Q and Qe and total Qs values:  [[0.634]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]] [[-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]] [[0.894]
 [0.892]
 [0.892]
 [0.892]
 [0.892]
 [0.892]
 [0.892]]
maxi score, test score, baseline:  -0.9881352941176471 -1.0 -0.9881352941176471
probs:  [0.03309075884216724, 0.3816286848051801, 0.3816286848051801, 0.20365187154747255]
Printing some Q and Qe and total Qs values:  [[0.593]
 [0.609]
 [0.609]
 [0.609]
 [0.613]
 [0.609]
 [0.602]] [[-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]] [[1.191]
 [1.224]
 [1.224]
 [1.224]
 [1.231]
 [1.224]
 [1.21 ]]
maxi score, test score, baseline:  -0.9881352941176471 -1.0 -0.9881352941176471
probs:  [0.04007345674027104, 0.24774272534129319, 0.4644410925771426, 0.24774272534129319]
siam score:  -0.8855014
maxi score, test score, baseline:  -0.9881352941176471 -1.0 -0.9881352941176471
probs:  [0.024971636814144722, 0.27977298343689794, 0.4154823963120596, 0.27977298343689794]
deleting a thread, now have 3 threads
Frames:  12832 train batches done:  1489 episodes:  229
first move QE:  -0.05659829994198244
maxi score, test score, baseline:  -0.9881352941176471 -1.0 -0.9881352941176471
from probs:  [0.024971636814144722, 0.27977298343689794, 0.4154823963120596, 0.27977298343689794]
maxi score, test score, baseline:  -0.9881352941176471 -1.0 -0.9881352941176471
probs:  [0.024971636814144722, 0.27977298343689794, 0.4154823963120596, 0.27977298343689794]
siam score:  -0.8795265
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.02875364708021054, 0.32374878430659654, 0.32374878430659654, 0.32374878430659654]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.02875364708021054, 0.32374878430659654, 0.32374878430659654, 0.32374878430659654]
Printing some Q and Qe and total Qs values:  [[0.818]
 [0.633]
 [0.819]
 [0.818]
 [0.814]
 [0.817]
 [0.819]] [[ 0.039]
 [ 1.908]
 [-0.027]
 [ 0.002]
 [-0.009]
 [ 0.022]
 [ 0.06 ]] [[1.667]
 [2.268]
 [1.638]
 [1.65 ]
 [1.64 ]
 [1.657]
 [1.678]]
maxi score, test score, baseline:  -0.9884057471264368 -1.0 -0.9884057471264368
probs:  [0.02251545494171208, 0.24642694431845594, 0.36552880036991603, 0.36552880036991603]
Printing some Q and Qe and total Qs values:  [[0.704]
 [0.729]
 [0.7  ]
 [0.701]
 [0.701]
 [0.715]
 [0.72 ]] [[1.402]
 [1.487]
 [1.547]
 [1.569]
 [1.647]
 [1.677]
 [1.68 ]] [[0.661]
 [0.766]
 [0.748]
 [0.766]
 [0.818]
 [0.866]
 [0.877]]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]] [[1.354]
 [1.05 ]
 [1.05 ]
 [1.05 ]
 [1.05 ]
 [1.05 ]
 [1.05 ]] [[0.875]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]]
maxi score, test score, baseline:  -0.9884057471264368 -1.0 -0.9884057471264368
probs:  [0.11692952901909476, 0.02033783579743383, 0.4313663175917357, 0.4313663175917357]
first move QE:  -0.03474840071569078
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.13120222025174919, 0.02271900182954634, 0.48434971851977277, 0.36172905939893174]
start point for exploration sampling:  10723
Printing some Q and Qe and total Qs values:  [[0.747]
 [0.969]
 [0.867]
 [0.844]
 [0.89 ]
 [0.92 ]
 [0.937]] [[1.893]
 [1.784]
 [1.379]
 [1.034]
 [0.972]
 [1.676]
 [1.799]] [[2.36 ]
 [2.551]
 [2.202]
 [1.977]
 [1.995]
 [2.433]
 [2.523]]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.14894959403824803, 0.02609195761058677, 0.5482369124281496, 0.2767215359230155]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.24794934983660805, 0.04288433349740718, 0.24794934983660805, 0.46121696682937674]
first move QE:  0.0021222741564290927
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.24799588061872227, 0.24799588061872227, 0.04357570372835047, 0.460432535034205]
siam score:  -0.8510879
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
Printing some Q and Qe and total Qs values:  [[0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.778]] [[2.829]
 [2.829]
 [2.829]
 [2.829]
 [2.829]
 [2.829]
 [2.829]] [[2.314]
 [2.314]
 [2.314]
 [2.314]
 [2.314]
 [2.314]
 [2.314]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.37928429022384125, 0.37928429022384125, 0.03668092113066097, 0.20475049842165643]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45965619769810184, 0.24804059628319616, 0.044262609735505755, 0.24804059628319616]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45965619769810184, 0.24804059628319616, 0.044262609735505755, 0.24804059628319616]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45965619769810184, 0.24804059628319616, 0.044262609735505755, 0.24804059628319616]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.47381083635489435, 0.32087900983377804, 0.17361132503566332, 0.03169882877566443]
first move QE:  0.039696393763191236
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.47381083635489435, 0.32087900983377804, 0.17361132503566332, 0.03169882877566443]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.47381083635489435, 0.32087900983377804, 0.17361132503566332, 0.03169882877566443]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.37890440725851904, 0.37890440725851904, 0.20492299868873762, 0.03726818679422444]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
from probs:  [0.37890440725851904, 0.37890440725851904, 0.20492299868873762, 0.03726818679422444]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45888770725168593, 0.24808359901603916, 0.24808359901603916, 0.04494509471623579]
using explorer policy with actor:  0
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45888770725168593, 0.24808359901603916, 0.24808359901603916, 0.04494509471623579]
siam score:  -0.86265945
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45888770725168593, 0.24808359901603916, 0.24808359901603916, 0.04494509471623579]
UNIT TEST: sample policy line 217 mcts : [0.102 0.122 0.102 0.265 0.143 0.102 0.163]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45888770725168593, 0.24808359901603916, 0.24808359901603916, 0.04494509471623579]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45888770725168593, 0.24808359901603916, 0.24808359901603916, 0.04494509471623579]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45888770725168593, 0.24808359901603916, 0.24808359901603916, 0.04494509471623579]
siam score:  -0.8631927
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45888770725168593, 0.24808359901603916, 0.24808359901603916, 0.04494509471623579]
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
maxi score, test score, baseline:  -0.9885363636363637 -1.0 -0.9885363636363637
probs:  [0.45888770725168593, 0.24808359901603916, 0.24808359901603916, 0.04494509471623579]
Printing some Q and Qe and total Qs values:  [[0.815]
 [0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.81 ]
 [0.812]] [[1.442]
 [1.135]
 [1.135]
 [1.135]
 [1.135]
 [0.985]
 [0.986]] [[1.37 ]
 [1.264]
 [1.264]
 [1.264]
 [1.264]
 [1.208]
 [1.212]]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.31441870518507187, 0.31441870518507187, 0.31441870518507187, 0.056743884444784586]
Printing some Q and Qe and total Qs values:  [[0.911]
 [0.917]
 [0.926]
 [0.926]
 [0.939]
 [0.941]
 [0.939]] [[0.432]
 [0.729]
 [0.474]
 [0.474]
 [0.357]
 [0.362]
 [0.378]] [[1.156]
 [1.365]
 [1.213]
 [1.213]
 [1.164]
 [1.171]
 [1.177]]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.31441870518507187, 0.31441870518507187, 0.31441870518507187, 0.056743884444784586]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.31441870518507187, 0.31441870518507187, 0.31441870518507187, 0.056743884444784586]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.31441870518507187, 0.31441870518507187, 0.31441870518507187, 0.056743884444784586]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.4238005797293729, 0.07619942027062712, 0.4238005797293729, 0.07619942027062712]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.4238005797293729, 0.07619942027062712, 0.4238005797293729, 0.07619942027062712]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.11651434133246988, 0.11651434133246988, 0.6504569760025904, 0.11651434133246988]
line 256 mcts: sample exp_bonus 1.5724296841568293
191 75
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.31415124695298974, 0.31415124695298974, 0.05754625914103073, 0.31415124695298974]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.31415124695298974, 0.31415124695298974, 0.05754625914103073, 0.31415124695298974]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.07717144118476496, 0.422828558815235, 0.07717144118476496, 0.422828558815235]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.05781208372969875, 0.5733820627063154, 0.05781208372969875, 0.31099376983428717]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.033230448225629566, 0.47194654836118244, 0.1743379658130883, 0.3204850376000998]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.033230448225629566, 0.47194654836118244, 0.1743379658130883, 0.3204850376000998]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.033230448225629566, 0.47194654836118244, 0.1743379658130883, 0.3204850376000998]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.033230448225629566, 0.47194654836118244, 0.1743379658130883, 0.3204850376000998]
Printing some Q and Qe and total Qs values:  [[-0.043]
 [-0.045]
 [-0.043]
 [-0.024]
 [-0.026]
 [-0.043]
 [-0.033]] [[3.006]
 [3.009]
 [3.006]
 [2.966]
 [3.112]
 [3.006]
 [3.009]] [[-0.019]
 [-0.022]
 [-0.019]
 [-0.008]
 [ 0.084]
 [-0.019]
 [ 0.003]]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.033230448225629566, 0.47194654836118244, 0.1743379658130883, 0.3204850376000998]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.033230448225629566, 0.47194654836118244, 0.1743379658130883, 0.3204850376000998]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.210623261540464
Printing some Q and Qe and total Qs values:  [[-0.042]
 [-0.042]
 [-0.042]
 [-0.042]
 [-0.042]
 [-0.042]
 [-0.048]] [[1.305]
 [1.305]
 [1.305]
 [1.305]
 [1.305]
 [1.305]
 [1.01 ]] [[-0.273]
 [-0.273]
 [-0.273]
 [-0.273]
 [-0.273]
 [-0.273]
 [-0.483]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.033230448225629566, 0.47194654836118244, 0.1743379658130883, 0.3204850376000998]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
Printing some Q and Qe and total Qs values:  [[0.903]
 [0.894]
 [0.903]
 [0.894]
 [0.903]
 [0.903]
 [0.903]] [[1.469]
 [1.894]
 [1.469]
 [0.619]
 [1.469]
 [1.469]
 [1.469]] [[1.255]
 [1.522]
 [1.255]
 [0.672]
 [1.255]
 [1.255]
 [1.255]]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.20433461753759075, 0.03935000993146967, 0.20433461753759075, 0.5519807549933489]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.20433461753759075, 0.03935000993146967, 0.20433461753759075, 0.5519807549933489]
siam score:  -0.8698327
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.31336174059441874, 0.05991477821674384, 0.31336174059441874, 0.31336174059441874]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.31336174059441874, 0.05991477821674384, 0.31336174059441874, 0.31336174059441874]
first move QE:  0.14934611594286173
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.047967291218399835, 0.047967291218399835, 0.4520327087816002, 0.4520327087816002]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.047967291218399835, 0.047967291218399835, 0.4520327087816002, 0.4520327087816002]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.047967291218399835, 0.047967291218399835, 0.4520327087816002, 0.4520327087816002]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.047967291218399835, 0.047967291218399835, 0.4520327087816002, 0.4520327087816002]
Printing some Q and Qe and total Qs values:  [[0.384]
 [0.384]
 [0.366]
 [0.353]
 [0.384]
 [0.384]
 [0.367]] [[1.879]
 [1.879]
 [1.867]
 [1.977]
 [1.879]
 [1.879]
 [1.999]] [[0.732]
 [0.732]
 [0.681]
 [0.801]
 [0.732]
 [0.732]
 [0.857]]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.0601745079866529, 0.0601745079866529, 0.5692519638406305, 0.3103990201860638]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.0601745079866529, 0.0601745079866529, 0.5692519638406305, 0.3103990201860638]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.0601745079866529, 0.0601745079866529, 0.5692519638406305, 0.3103990201860638]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.08095488766122994, 0.08095488766122994, 0.41904511233877006, 0.41904511233877006]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.08095488766122994, 0.08095488766122994, 0.41904511233877006, 0.41904511233877006]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
probs:  [0.12204358875735206, 0.12204358875735206, 0.12204358875735206, 0.6338692337279439]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
maxi score, test score, baseline:  -0.989147311827957 -1.0 -0.989147311827957
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.989147311827957 -1.0 -0.989147311827957
Printing some Q and Qe and total Qs values:  [[0.72 ]
 [0.703]
 [0.713]
 [0.715]
 [0.714]
 [0.718]
 [0.805]] [[0.614]
 [0.721]
 [0.606]
 [0.604]
 [0.604]
 [0.614]
 [0.699]] [[1.172]
 [1.211]
 [1.153]
 [1.155]
 [1.155]
 [1.169]
 [1.399]]
maxi score, test score, baseline:  -0.989147311827957 -1.0 -0.989147311827957
probs:  [0.0614623456042389, 0.31284588479858705, 0.31284588479858705, 0.31284588479858705]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.604]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.653]] [[1.973]
 [1.316]
 [1.316]
 [1.316]
 [1.316]
 [1.316]
 [1.584]] [[1.239]
 [1.18 ]
 [1.18 ]
 [1.18 ]
 [1.18 ]
 [1.18 ]
 [1.208]]
line 256 mcts: sample exp_bonus 0.5138931401025437
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.989147311827957 -1.0 -0.989147311827957
probs:  [0.0614623456042389, 0.31284588479858705, 0.31284588479858705, 0.31284588479858705]
maxi score, test score, baseline:  -0.989147311827957 -1.0 -0.989147311827957
probs:  [0.0614623456042389, 0.31284588479858705, 0.31284588479858705, 0.31284588479858705]
maxi score, test score, baseline:  -0.9892617021276596 -1.0 -0.9892617021276596
probs:  [0.12309540454503007, 0.12309540454503007, 0.6307137863649098, 0.12309540454503007]
maxi score, test score, baseline:  -0.9892617021276596 -1.0 -0.9892617021276596
probs:  [0.12309540454503007, 0.12309540454503007, 0.6307137863649098, 0.12309540454503007]
maxi score, test score, baseline:  -0.9892617021276596 -1.0 -0.9892617021276596
probs:  [0.2062156937792721, 0.37596408097347733, 0.37596408097347733, 0.041856144273773294]
maxi score, test score, baseline:  -0.9892617021276596 -1.0 -0.9892617021276596
probs:  [0.2062156937792721, 0.37596408097347733, 0.37596408097347733, 0.041856144273773294]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.2062156833767913, 0.3759641109006161, 0.3759641109006161, 0.041856094821976525]
first move QE:  0.2195269045276642
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.2483760194385202, 0.4529975701849447, 0.2483760194385202, 0.05025039093801499]
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]] [[1.449]
 [1.449]
 [1.449]
 [1.449]
 [1.449]
 [1.449]
 [1.449]] [[1.137]
 [1.137]
 [1.137]
 [1.137]
 [1.137]
 [1.137]
 [1.137]]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.2483760194385202, 0.4529975701849447, 0.2483760194385202, 0.05025039093801499]
Printing some Q and Qe and total Qs values:  [[0.672]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]] [[1.221]
 [1.146]
 [1.146]
 [1.146]
 [1.146]
 [1.146]
 [1.146]] [[1.12 ]
 [1.062]
 [1.062]
 [1.062]
 [1.062]
 [1.062]
 [1.062]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
Printing some Q and Qe and total Qs values:  [[0.403]
 [0.403]
 [0.446]
 [0.403]
 [0.403]
 [0.403]
 [0.403]] [[1.74 ]
 [1.74 ]
 [2.281]
 [1.74 ]
 [1.74 ]
 [1.74 ]
 [1.74 ]] [[0.681]
 [0.681]
 [1.31 ]
 [0.681]
 [0.681]
 [0.681]
 [0.681]]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.3098034088879302, 0.5652349180363779, 0.06248083653784593, 0.06248083653784593]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.3098034088879302, 0.5652349180363779, 0.06248083653784593, 0.06248083653784593]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.3098034088879302, 0.5652349180363779, 0.06248083653784593, 0.06248083653784593]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.3196822983315996, 0.4683772053826792, 0.03623263176548261, 0.17570786452023854]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.3196822983315996, 0.4683772053826792, 0.03623263176548261, 0.17570786452023854]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.3236494374112528, 0.4294813336123504, 0.025691945029699507, 0.22117728394669733]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.3620089472137473, 0.3620089472137473, 0.028627986215350152, 0.24735411935715512]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.3620089472137473, 0.3620089472137473, 0.028627986215350152, 0.24735411935715512]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.31954726012408313, 0.4678007072756002, 0.03672529940426566, 0.1759267331960509]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
siam score:  -0.88888735
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.4515899767686592, 0.24843728700179346, 0.051535449227753806, 0.24843728700179346]
216 91
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.4515900365842041, 0.2484372865381061, 0.05153539033958377, 0.2484372865381061]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.4515900365842041, 0.2484372865381061, 0.05153539033958377, 0.2484372865381061]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.5626165142006266, 0.06398830463451904, 0.06398830463451904, 0.3094068765303352]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.5626166273946995, 0.06398823728228169, 0.06398823728228169, 0.30940689804073707]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.5626166273946995, 0.06398823728228169, 0.06398823728228169, 0.30940689804073707]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.5626166273946995, 0.06398823728228169, 0.06398823728228169, 0.30940689804073707]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.41453880897790424, 0.08546119102209573, 0.08546119102209573, 0.41453880897790424]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
start point for exploration sampling:  10723
siam score:  -0.88885343
Printing some Q and Qe and total Qs values:  [[0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]] [[0.938]
 [0.938]
 [0.938]
 [0.938]
 [0.938]
 [0.938]
 [0.938]] [[0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]]
maxi score, test score, baseline:  -0.9895907216494846 -1.0 -0.9895907216494846
probs:  [0.25, 0.25, 0.25, 0.25]
UNIT TEST: sample policy line 217 mcts : [0.245 0.041 0.143 0.184 0.102 0.163 0.122]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.08633428985670508, 0.4136657101432949, 0.4136657101432949, 0.08633428985670508]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.08633428985670508, 0.4136657101432949, 0.4136657101432949, 0.08633428985670508]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.1281086090518988, 0.1281086090518988, 0.6156741728443035, 0.1281086090518988]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.1281086090518988, 0.1281086090518988, 0.6156741728443035, 0.1281086090518988]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.24849468920509488, 0.05280428586735758, 0.4502063357224526, 0.24849468920509488]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.31134637657595143, 0.06596087027214573, 0.31134637657595143, 0.31134637657595143]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.31110319454998975, 0.06669041635003083, 0.31110319454998975, 0.31110319454998975]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.4119465135973335, 0.0880534864026665, 0.4119465135973335, 0.0880534864026665]
Printing some Q and Qe and total Qs values:  [[0.943]
 [0.943]
 [0.943]
 [0.943]
 [0.943]
 [0.943]
 [0.943]] [[1.967]
 [1.967]
 [1.967]
 [1.967]
 [1.967]
 [1.967]
 [1.967]] [[2.442]
 [2.442]
 [2.442]
 [2.442]
 [2.442]
 [2.442]
 [2.442]]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.088]
 [0.088]
 [0.088]
 [0.088]
 [0.088]
 [0.088]
 [0.088]] [[0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]] [[0.088]
 [0.088]
 [0.088]
 [0.088]
 [0.088]
 [0.088]
 [0.088]]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.4488450737487389, 0.05405777404321151, 0.24854857610402478, 0.24854857610402478]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.4488450737487389, 0.05405777404321151, 0.24854857610402478, 0.24854857610402478]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.4488450737487389, 0.05405777404321151, 0.24854857610402478, 0.24854857610402478]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.4488450737487389, 0.05405777404321151, 0.24854857610402478, 0.24854857610402478]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
probs:  [0.4488450737487389, 0.05405777404321151, 0.24854857610402478, 0.24854857610402478]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9899990099009901 -1.0 -0.9899990099009901
from probs:  [0.44884513300872275, 0.05405771564833896, 0.24854857567146915, 0.24854857567146915]
maxi score, test score, baseline:  -0.9899990099009901 -1.0 -0.9899990099009901
probs:  [0.5575161684172624, 0.06693319006245077, 0.30861745145783603, 0.06693319006245077]
maxi score, test score, baseline:  -0.9899990099009901 -1.0 -0.9899990099009901
maxi score, test score, baseline:  -0.9899990099009901 -1.0 -0.9899990099009901
probs:  [0.5395084322399175, 0.04528483243286192, 0.3699219028943586, 0.04528483243286192]
maxi score, test score, baseline:  -0.9899990099009901 -1.0 -0.9899990099009901
maxi score, test score, baseline:  -0.9899990099009901 -1.0 -0.9899990099009901
probs:  [0.6461757852191456, 0.05405746362807624, 0.24570928752470184, 0.05405746362807624]
maxi score, test score, baseline:  -0.9899990099009901 -1.0 -0.9899990099009901
maxi score, test score, baseline:  -0.9899990099009901 -1.0 -0.9899990099009901
probs:  [0.5412078459468971, 0.20637777206463548, 0.04603660992383197, 0.20637777206463548]
maxi score, test score, baseline:  -0.9900960784313726 -1.0 -0.9900960784313726
maxi score, test score, baseline:  -0.9900960784313726 -1.0 -0.9900960784313726
probs:  [0.4750655228070421, 0.24683006305905592, 0.031274351074846135, 0.24683006305905592]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9900960784313726 -1.0 -0.9900960784313726
probs:  [0.4750655228070421, 0.24683006305905592, 0.031274351074846135, 0.24683006305905592]
maxi score, test score, baseline:  -0.9900960784313726 -1.0 -0.9900960784313726
probs:  [0.4750655228070421, 0.24683006305905592, 0.031274351074846135, 0.24683006305905592]
maxi score, test score, baseline:  -0.9900960784313726 -1.0 -0.9900960784313726
probs:  [0.4750655228070421, 0.24683006305905592, 0.031274351074846135, 0.24683006305905592]
maxi score, test score, baseline:  -0.9901912621359223 -1.0 -0.9901912621359223
probs:  [0.4750655611677902, 0.24683006251876322, 0.03127431379468324, 0.24683006251876322]
maxi score, test score, baseline:  -0.9902846153846154 -1.0 -0.9902846153846154
probs:  [0.4750655987800994, 0.2468300619890126, 0.03127427724187546, 0.2468300619890126]
maxi score, test score, baseline:  -0.9902846153846154 -1.0 -0.9902846153846154
probs:  [0.4750655987800994, 0.2468300619890126, 0.03127427724187546, 0.2468300619890126]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.775]
 [0.745]
 [0.775]
 [0.775]
 [0.775]
 [0.775]
 [0.775]] [[1.597]
 [1.982]
 [1.597]
 [1.597]
 [1.597]
 [1.597]
 [1.597]] [[1.741]
 [1.937]
 [1.741]
 [1.741]
 [1.741]
 [1.741]
 [1.741]]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.2075220158190613, 0.37284173803676685, 0.04679450810740492, 0.37284173803676685]
Printing some Q and Qe and total Qs values:  [[0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]] [[1.774]
 [1.774]
 [1.774]
 [1.774]
 [1.774]
 [1.774]
 [1.774]] [[0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]]
siam score:  -0.87369
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.2075220158190613, 0.37284173803676685, 0.04679450810740492, 0.37284173803676685]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.2075220158190613, 0.37284173803676685, 0.04679450810740492, 0.37284173803676685]
from probs:  [0.2075220158190613, 0.37284173803676685, 0.04679450810740492, 0.37284173803676685]
Printing some Q and Qe and total Qs values:  [[0.042]
 [0.042]
 [0.042]
 [0.042]
 [0.042]
 [0.042]
 [0.042]] [[1.005]
 [1.005]
 [1.005]
 [1.005]
 [1.005]
 [1.005]
 [1.124]] [[0.042]
 [0.042]
 [0.042]
 [0.042]
 [0.042]
 [0.042]
 [0.042]]
line 256 mcts: sample exp_bonus 1.7750551786763769
first move QE:  0.35064333352340743
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.2486234682566765, 0.2486234682566765, 0.055909024191361, 0.446844039295286]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.2486234682566765, 0.2486234682566765, 0.055909024191361, 0.446844039295286]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.2486234682566765, 0.2486234682566765, 0.055909024191361, 0.446844039295286]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.31014908891565013, 0.31014908891565013, 0.06955273325304948, 0.31014908891565013]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.31014908891565013, 0.31014908891565013, 0.06955273325304948, 0.31014908891565013]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
probs:  [0.31014911080859836, 0.31014911080859836, 0.06955266757420488, 0.31014911080859836]
siam score:  -0.86052185
maxi score, test score, baseline:  -0.9905542056074766 -1.0 -0.9905542056074766
probs:  [0.3101491322865567, 0.3101491322865567, 0.06955260314032992, 0.3101491322865567]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9905542056074766 -1.0 -0.9905542056074766
probs:  [0.3101491322865567, 0.3101491322865567, 0.06955260314032992, 0.3101491322865567]
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Printing some Q and Qe and total Qs values:  [[0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]] [[2.064]
 [1.987]
 [1.987]
 [1.987]
 [1.987]
 [1.987]
 [1.987]] [[1.739]
 [1.689]
 [1.689]
 [1.689]
 [1.689]
 [1.689]
 [1.689]]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.4086126102180004, 0.0913873897819996, 0.0913873897819996, 0.4086126102180004]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.4086126102180004, 0.0913873897819996, 0.0913873897819996, 0.4086126102180004]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.4086126102180004, 0.0913873897819996, 0.0913873897819996, 0.4086126102180004]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.4086126102180004, 0.0913873897819996, 0.0913873897819996, 0.4086126102180004]
Printing some Q and Qe and total Qs values:  [[0.304]
 [0.32 ]
 [0.321]
 [0.329]
 [0.322]
 [0.319]
 [0.324]] [[2.817]
 [3.217]
 [3.614]
 [3.616]
 [3.531]
 [3.584]
 [3.495]] [[0.703]
 [1.088]
 [1.451]
 [1.464]
 [1.376]
 [1.42 ]
 [1.346]]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.1336307835490058, 0.1336307835490058, 0.1336307835490058, 0.5991076493529828]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
siam score:  -0.8699377
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.1336307835490058, 0.1336307835490058, 0.1336307835490058, 0.5991076493529828]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.1336307835490058, 0.1336307835490058, 0.1336307835490058, 0.5991076493529828]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.1336307835490058, 0.1336307835490058, 0.1336307835490058, 0.5991076493529828]
main train batch thing paused
add a thread
Adding thread: now have 5 threads
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.455]
 [0.317]
 [0.458]
 [0.445]
 [0.445]
 [0.445]
 [0.443]] [[2.166]
 [1.558]
 [2.092]
 [2.189]
 [2.193]
 [2.185]
 [2.201]] [[1.684]
 [0.884]
 [1.617]
 [1.693]
 [1.695]
 [1.688]
 [1.701]]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
251 103
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.3721716907270872, 0.2077952341124605, 0.3721716907270872, 0.047861384433365135]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.3721716907270872, 0.2077952341124605, 0.3721716907270872, 0.047861384433365135]
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.234]
 [0.234]
 [0.234]
 [0.228]
 [0.234]
 [0.234]
 [0.235]] [[3.836]
 [3.836]
 [3.836]
 [3.946]
 [3.836]
 [3.836]
 [4.101]] [[1.404]
 [1.404]
 [1.404]
 [1.486]
 [1.404]
 [1.404]
 [1.62 ]]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
Printing some Q and Qe and total Qs values:  [[-0.071]
 [-0.071]
 [-0.071]
 [-0.071]
 [-0.071]
 [-0.071]
 [-0.071]] [[2.152]
 [2.152]
 [2.152]
 [2.152]
 [2.152]
 [2.152]
 [2.152]] [[0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.219]]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.35985453732479267, 0.24775807066684022, 0.35985453732479267, 0.0325328546835745]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.46228218703054536, 0.17799307212998086, 0.318190443861765, 0.04153429697770873]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.46228218703054536, 0.17799307212998086, 0.318190443861765, 0.04153429697770873]
using another actor
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.44256976226757583, 0.05743023773242422, 0.44256976226757583, 0.05743023773242422]
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.44256976226757583, 0.05743023773242422, 0.44256976226757583, 0.05743023773242422]
Printing some Q and Qe and total Qs values:  [[0.055]
 [0.051]
 [0.051]
 [0.054]
 [0.051]
 [0.051]
 [0.053]] [[2.   ]
 [1.869]
 [1.869]
 [1.901]
 [1.869]
 [1.869]
 [1.913]] [[0.055]
 [0.051]
 [0.051]
 [0.054]
 [0.051]
 [0.051]
 [0.053]]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.32243152835603284, 0.22234238303263285, 0.4252628420444562, 0.0299632465668783]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.526]] [[4.735]
 [4.735]
 [4.735]
 [4.735]
 [4.735]
 [4.735]
 [5.054]] [[1.403]
 [1.403]
 [1.403]
 [1.403]
 [1.403]
 [1.403]
 [1.534]]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.17838304208744257, 0.3179191768748426, 0.4612265585483885, 0.042471222489326166]
siam score:  -0.87964445
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.17838304208744257, 0.3179191768748426, 0.4612265585483885, 0.042471222489326166]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.049025046243531704, 0.3679986993905272, 0.5339512081224094, 0.049025046243531704]
using explorer policy with actor:  1
using explorer policy with actor:  1
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.4088561088416496
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.049025046243531704, 0.3679986993905272, 0.5339512081224094, 0.049025046243531704]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
Printing some Q and Qe and total Qs values:  [[-0.023]
 [-0.023]
 [-0.023]
 [-0.038]
 [-0.023]
 [-0.023]
 [-0.037]] [[4.086]
 [4.086]
 [4.086]
 [5.1  ]
 [4.086]
 [4.086]
 [4.054]] [[-0.298]
 [-0.298]
 [-0.298]
 [ 0.01 ]
 [-0.298]
 [-0.298]
 [-0.338]]
siam score:  -0.88074636
from probs:  [0.03348646318051456, 0.35712081071394375, 0.47083017606352506, 0.13856255004201667]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.03754973686519801, 0.2770949232394136, 0.5295884980662899, 0.1557668418290986]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.4316],
        [-0.4596],
        [-0.2856],
        [-0.4149],
        [-0.4118],
        [-0.4149],
        [-0.4199],
        [-0.2854],
        [-0.4593],
        [-0.4661]], dtype=torch.float64)
-0.024259925299500003 -0.45581394578805695
-0.024259925299500003 -0.48386950510686666
-0.0727797758985 -0.35840635811484745
-0.0727797758985 -0.487685294728541
-0.0727797758985 -0.4845324653103059
-0.0727797758985 -0.487685294728541
-0.0727797758985 -0.49269292168988443
-0.0727797758985 -0.3582101494123881
-0.024259925299500003 -0.4835724628099649
-0.024259925299500003 -0.4903243928571987
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.03754973686519801, 0.2770949232394136, 0.5295884980662899, 0.1557668418290986]
Printing some Q and Qe and total Qs values:  [[0.087]
 [0.138]
 [0.092]
 [0.092]
 [0.091]
 [0.095]
 [0.092]] [[0.515]
 [0.609]
 [0.241]
 [0.254]
 [0.335]
 [0.295]
 [0.457]] [[0.087]
 [0.138]
 [0.092]
 [0.092]
 [0.091]
 [0.095]
 [0.092]]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.027827967103391957, 0.2915555272807898, 0.4792535205601993, 0.20136298505561895]
Printing some Q and Qe and total Qs values:  [[0.143]
 [0.172]
 [0.143]
 [0.143]
 [0.143]
 [0.143]
 [0.143]] [[0.506]
 [1.058]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.506]] [[0.143]
 [0.172]
 [0.143]
 [0.143]
 [0.143]
 [0.143]
 [0.143]]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.027827967103391957, 0.2915555272807898, 0.4792535205601993, 0.20136298505561895]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.027827967103391957, 0.2915555272807898, 0.4792535205601993, 0.20136298505561895]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.027827967103391957, 0.2915555272807898, 0.4792535205601993, 0.20136298505561895]
Printing some Q and Qe and total Qs values:  [[0.334]
 [0.38 ]
 [0.368]
 [0.352]
 [0.349]
 [0.354]
 [0.358]] [[-0.093]
 [ 0.441]
 [ 0.126]
 [-0.537]
 [-0.648]
 [-0.391]
 [-0.316]] [[0.334]
 [0.38 ]
 [0.368]
 [0.352]
 [0.349]
 [0.354]
 [0.358]]
maxi score, test score, baseline:  -0.9912793103448276 -1.0 -0.9912793103448276
probs:  [0.02219186177787004, 0.29993889753045283, 0.45007243036968697, 0.22779681032199006]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9912793103448276 -1.0 -0.9912793103448276
probs:  [0.02219186177787004, 0.29993889753045283, 0.45007243036968697, 0.22779681032199006]
siam score:  -0.8781201
from probs:  [0.02219186177787004, 0.29993889753045283, 0.45007243036968697, 0.22779681032199006]
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
probs:  [0.022191838500608636, 0.2999389026331712, 0.4500724508129351, 0.22779680805328503]
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
probs:  [0.022191838500608636, 0.2999389026331712, 0.4500724508129351, 0.22779680805328503]
Printing some Q and Qe and total Qs values:  [[0.469]
 [0.278]
 [0.278]
 [0.27 ]
 [0.278]
 [0.278]
 [0.278]] [[3.489]
 [3.377]
 [3.377]
 [3.005]
 [3.377]
 [3.377]
 [3.377]] [[1.42 ]
 [1.046]
 [1.046]
 [0.751]
 [1.046]
 [1.046]
 [1.046]]
Printing some Q and Qe and total Qs values:  [[0.517]
 [0.484]
 [0.506]
 [0.516]
 [0.529]
 [0.522]
 [0.546]] [[1.784]
 [3.243]
 [1.186]
 [1.044]
 [1.108]
 [1.057]
 [1.355]] [[0.517]
 [0.484]
 [0.506]
 [0.516]
 [0.529]
 [0.522]
 [0.546]]
maxi score, test score, baseline:  -0.9913529914529915 -1.0 -0.9913529914529915
probs:  [0.01851309731813475, 0.30541083989154805, 0.4310255271804481, 0.24505053560986909]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9914254237288136 -1.0 -0.9914254237288136
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]] [[2.163]
 [2.151]
 [2.151]
 [2.151]
 [2.151]
 [2.151]
 [2.151]] [[0.83 ]
 [0.843]
 [0.843]
 [0.843]
 [0.843]
 [0.843]
 [0.843]]
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
probs:  [0.019708793334485775, 0.32619057482096314, 0.39239063962204174, 0.26170999222250935]
Printing some Q and Qe and total Qs values:  [[0.51 ]
 [0.567]
 [0.567]
 [0.524]
 [0.567]
 [0.536]
 [0.567]] [[1.914]
 [2.03 ]
 [2.03 ]
 [1.667]
 [2.03 ]
 [1.622]
 [2.03 ]] [[0.461]
 [0.692]
 [0.692]
 [0.242]
 [0.692]
 [0.222]
 [0.692]]
Printing some Q and Qe and total Qs values:  [[0.611]
 [0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]] [[2.33 ]
 [2.139]
 [2.139]
 [2.139]
 [2.139]
 [2.139]
 [2.139]] [[1.079]
 [0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]]
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
probs:  [0.019708793334485775, 0.32619057482096314, 0.39239063962204174, 0.26170999222250935]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
probs:  [0.019708793334485775, 0.32619057482096314, 0.39239063962204174, 0.26170999222250935]
Printing some Q and Qe and total Qs values:  [[0.396]
 [0.449]
 [0.449]
 [0.483]
 [0.496]
 [0.498]
 [0.494]] [[2.264]
 [2.194]
 [2.117]
 [2.259]
 [2.266]
 [2.28 ]
 [2.269]] [[0.245]
 [0.281]
 [0.204]
 [0.415]
 [0.448]
 [0.466]
 [0.447]]
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
probs:  [0.02625012260450942, 0.352846434873015, 0.352846434873015, 0.2680570076494607]
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.026250096411107447, 0.3528464469127892, 0.3528464469127892, 0.268057009763314]
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.026250096411107447, 0.3528464469127892, 0.3528464469127892, 0.268057009763314]
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.03135320101468833, 0.42394503851964843, 0.22267960283672542, 0.3220221576289378]
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.034716477302729705, 0.47080361302284085, 0.24723995483721473, 0.24723995483721473]
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.038800087075227106, 0.5276981754609388, 0.15644118959303913, 0.27706054787079487]
maxi score, test score, baseline:  -0.9915666666666667 -1.0 -0.9915666666666667
probs:  [0.050686791561340046, 0.6933087230512268, 0.050686791561340046, 0.20531769382609308]
Starting evaluation
maxi score, test score, baseline:  -0.9916355371900827 -1.0 -0.9916355371900827
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.13 ]
 [0.143]
 [0.143]
 [0.143]
 [0.126]
 [0.143]
 [0.129]] [[1.716]
 [0.906]
 [0.906]
 [0.906]
 [1.538]
 [0.906]
 [1.244]] [[0.13 ]
 [0.143]
 [0.143]
 [0.143]
 [0.126]
 [0.143]
 [0.129]]
siam score:  -0.88579714
Printing some Q and Qe and total Qs values:  [[0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]] [[1.489]
 [1.489]
 [1.489]
 [1.489]
 [1.489]
 [1.489]
 [1.489]] [[0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]]
line 256 mcts: sample exp_bonus 2.0971058707520687
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.1387043857975736, 0.5812893546043748, 0.03480486568134254, 0.24520139391670914]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.1387043857975736, 0.5812893546043748, 0.03480486568134254, 0.24520139391670914]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.1387043857975736, 0.5812893546043748, 0.03480486568134254, 0.24520139391670914]
Printing some Q and Qe and total Qs values:  [[0.139]
 [0.094]
 [0.133]
 [0.133]
 [0.133]
 [0.135]
 [0.134]] [[1.403]
 [2.818]
 [1.534]
 [1.455]
 [1.451]
 [1.133]
 [1.407]] [[0.139]
 [0.094]
 [0.133]
 [0.133]
 [0.133]
 [0.135]
 [0.134]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.1387043857975736, 0.5812893546043748, 0.03480486568134254, 0.24520139391670914]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.1387043857975736, 0.5812893546043748, 0.03480486568134254, 0.24520139391670914]
281 116
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.162]
 [0.162]
 [0.162]
 [0.162]
 [0.162]
 [0.162]
 [0.162]] [[1.568]
 [2.089]
 [2.089]
 [2.089]
 [2.089]
 [2.089]
 [1.876]] [[0.162]
 [0.162]
 [0.162]
 [0.162]
 [0.162]
 [0.162]
 [0.162]]
line 256 mcts: sample exp_bonus 0.7254750644451438
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.2079907969139856, 0.5322029995542841, 0.05181540661774464, 0.2079907969139856]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
probs:  [0.20799078754261044, 0.532203062507876, 0.051815362406903195, 0.20799078754261044]
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
using another actor
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.281]
 [0.28 ]
 [0.28 ]
 [0.28 ]
 [0.28 ]
 [0.28 ]
 [0.28 ]] [[1.465]
 [1.581]
 [1.581]
 [1.581]
 [1.581]
 [1.581]
 [1.581]] [[0.281]
 [0.28 ]
 [0.28 ]
 [0.28 ]
 [0.28 ]
 [0.28 ]
 [0.28 ]]
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
probs:  [0.2464832108402289, 0.6309854923085554, 0.06126564842560794, 0.06126564842560794]
Printing some Q and Qe and total Qs values:  [[0.283]
 [0.281]
 [0.281]
 [0.281]
 [0.281]
 [0.281]
 [0.281]] [[1.908]
 [2.239]
 [2.239]
 [2.239]
 [2.239]
 [2.239]
 [2.239]] [[0.283]
 [0.281]
 [0.281]
 [0.281]
 [0.281]
 [0.281]
 [0.281]]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
Printing some Q and Qe and total Qs values:  [[0.528]
 [0.52 ]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]] [[2.215]
 [2.522]
 [2.101]
 [2.101]
 [2.101]
 [2.101]
 [2.101]] [[0.528]
 [0.52 ]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]]
Printing some Q and Qe and total Qs values:  [[0.291]
 [0.279]
 [0.279]
 [0.291]
 [0.29 ]
 [0.279]
 [0.29 ]] [[2.991]
 [2.969]
 [2.969]
 [2.748]
 [2.743]
 [2.969]
 [2.719]] [[0.291]
 [0.279]
 [0.279]
 [0.291]
 [0.29 ]
 [0.279]
 [0.29 ]]
maxi score, test score, baseline:  -0.9922664122137405 -1.0 -0.9922664122137405
probs:  [0.24648320472966495, 0.6309861542862834, 0.061265320492025856, 0.061265320492025856]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.246483202308484, 0.6309864165808892, 0.06126519055531338, 0.06126519055531338]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.246483202308484, 0.6309864165808892, 0.06126519055531338, 0.06126519055531338]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
line 256 mcts: sample exp_bonus 3.2644716951515105
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.07503303129048254, 0.7749009061285524, 0.07503303129048254, 0.07503303129048254]
286 117
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.17826585794985636, 0.5985435372554035, 0.04492474684488363, 0.17826585794985636]
using explorer policy with actor:  1
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9926007299270073 -1.0 -0.9926007299270073
probs:  [0.06184269229730414, 0.6297776333385708, 0.06184269229730414, 0.24653698206682073]
maxi score, test score, baseline:  -0.9926007299270073 -1.0 -0.9926007299270073
probs:  [0.06184269229730414, 0.6297776333385708, 0.06184269229730414, 0.24653698206682073]
Printing some Q and Qe and total Qs values:  [[0.805]
 [0.837]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[3.172]
 [4.378]
 [3.172]
 [3.172]
 [3.172]
 [3.172]
 [3.172]] [[1.503]
 [2.05 ]
 [1.503]
 [1.503]
 [1.503]
 [1.503]
 [1.503]]
maxi score, test score, baseline:  -0.9926007299270073 -1.0 -0.9926007299270073
probs:  [0.06184269229730414, 0.6297776333385708, 0.06184269229730414, 0.24653698206682073]
Printing some Q and Qe and total Qs values:  [[1.258]
 [1.258]
 [1.258]
 [1.258]
 [1.258]
 [1.258]
 [1.258]] [[0.55]
 [0.55]
 [0.55]
 [0.55]
 [0.55]
 [0.55]
 [0.55]] [[1.479]
 [1.479]
 [1.479]
 [1.479]
 [1.479]
 [1.479]
 [1.479]]
Printing some Q and Qe and total Qs values:  [[0.49 ]
 [0.314]
 [0.485]
 [0.485]
 [0.485]
 [0.484]
 [0.484]] [[2.217]
 [1.555]
 [2.314]
 [2.257]
 [2.284]
 [2.365]
 [2.356]] [[1.918]
 [1.123]
 [1.971]
 [1.934]
 [1.95 ]
 [2.004]
 [1.998]]
maxi score, test score, baseline:  -0.9927571428571429 -1.0 -0.9927571428571429
Printing some Q and Qe and total Qs values:  [[0.893]
 [0.898]
 [0.893]
 [0.893]
 [0.893]
 [0.893]
 [0.893]] [[2.958]
 [4.465]
 [2.958]
 [2.958]
 [2.958]
 [2.958]
 [2.958]] [[1.467]
 [2.066]
 [1.467]
 [1.467]
 [1.467]
 [1.467]
 [1.467]]
maxi score, test score, baseline:  -0.9927571428571429 -1.0 -0.9927571428571429
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.862]
 [0.891]
 [0.827]
 [0.861]
 [0.827]
 [0.873]
 [0.876]] [[4.238]
 [4.207]
 [3.945]
 [3.945]
 [3.945]
 [4.286]
 [4.281]] [[1.837]
 [1.844]
 [1.649]
 [1.676]
 [1.649]
 [1.872]
 [1.871]]
maxi score, test score, baseline:  -0.9928078014184397 -1.0 -0.9928078014184397
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.202]
 [0.204]
 [0.204]
 [0.204]
 [0.204]
 [0.204]
 [0.202]] [[3.063]
 [3.44 ]
 [3.44 ]
 [3.44 ]
 [3.44 ]
 [3.44 ]
 [3.659]] [[0.202]
 [0.204]
 [0.204]
 [0.204]
 [0.204]
 [0.204]
 [0.202]]
maxi score, test score, baseline:  -0.9928577464788733 -1.0 -0.9928577464788733
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.992906993006993 -1.0 -0.992906993006993
probs:  [0.3074538941725977, 0.07763831748220694, 0.3074538941725977, 0.3074538941725977]
maxi score, test score, baseline:  -0.992906993006993 -1.0 -0.992906993006993
Printing some Q and Qe and total Qs values:  [[0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]] [[0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.287]] [[0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]]
maxi score, test score, baseline:  -0.992906993006993 -1.0 -0.992906993006993
probs:  [0.39937344646597167, 0.10062655353402836, 0.39937344646597167, 0.10062655353402836]
maxi score, test score, baseline:  -0.992906993006993 -1.0 -0.992906993006993
maxi score, test score, baseline:  -0.992906993006993 -1.0 -0.992906993006993
rdn probs:  [0.570059382869757, 0.1433135390434144, 0.1433135390434144, 0.1433135390434144]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9929555555555556 -1.0 -0.9929555555555556
probs:  [0.5700595340347846, 0.14331348865507174, 0.14331348865507174, 0.14331348865507174]
Printing some Q and Qe and total Qs values:  [[0.122]
 [0.04 ]
 [0.131]
 [0.131]
 [0.133]
 [0.138]
 [0.145]] [[8.786]
 [7.473]
 [8.756]
 [8.724]
 [8.722]
 [8.897]
 [8.598]] [[1.457]
 [0.857]
 [1.456]
 [1.443]
 [1.445]
 [1.518]
 [1.411]]
maxi score, test score, baseline:  -0.9929555555555556 -1.0 -0.9929555555555556
maxi score, test score, baseline:  -0.9929555555555556 -1.0 -0.9929555555555556
probs:  [0.5700595340347846, 0.14331348865507174, 0.14331348865507174, 0.14331348865507174]
maxi score, test score, baseline:  -0.9929555555555556 -1.0 -0.9929555555555556
probs:  [0.5700595340347846, 0.14331348865507174, 0.14331348865507174, 0.14331348865507174]
maxi score, test score, baseline:  -0.9930034482758621 -1.0 -0.9930034482758621
probs:  [0.43867941350571277, 0.06355347896181225, 0.2488835537662375, 0.2488835537662375]
Printing some Q and Qe and total Qs values:  [[0.867]
 [1.002]
 [0.867]
 [0.867]
 [0.867]
 [0.867]
 [0.867]] [[2.656]
 [3.204]
 [2.656]
 [2.656]
 [2.656]
 [2.656]
 [2.656]] [[1.7  ]
 [2.152]
 [1.7  ]
 [1.7  ]
 [1.7  ]
 [1.7  ]
 [1.7  ]]
Printing some Q and Qe and total Qs values:  [[0.824]
 [0.826]
 [0.824]
 [0.824]
 [0.824]
 [0.824]
 [0.824]] [[2.965]
 [3.439]
 [2.965]
 [2.965]
 [2.965]
 [2.965]
 [2.965]] [[1.611]
 [1.857]
 [1.611]
 [1.611]
 [1.611]
 [1.611]
 [1.611]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.9148526
maxi score, test score, baseline:  -0.9930506849315068 -1.0 -0.9930506849315068
maxi score, test score, baseline:  -0.9930972789115646 -1.0 -0.9930972789115646
maxi score, test score, baseline:  -0.9930972789115646 -1.0 -0.9930972789115646
probs:  [0.45664625811057363, 0.04658902074631599, 0.18005863133938732, 0.31670608980372306]
siam score:  -0.90875596
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.785]
 [0.702]
 [0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.785]] [[3.395]
 [4.463]
 [3.395]
 [3.395]
 [3.395]
 [3.395]
 [3.395]] [[1.529]
 [1.981]
 [1.529]
 [1.529]
 [1.529]
 [1.529]
 [1.529]]
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.535]
 [0.517]
 [0.535]
 [0.535]
 [0.535]
 [0.535]] [[2.7  ]
 [2.7  ]
 [2.742]
 [2.7  ]
 [2.7  ]
 [2.7  ]
 [2.7  ]] [[1.544]
 [1.544]
 [1.565]
 [1.544]
 [1.544]
 [1.544]
 [1.544]]
maxi score, test score, baseline:  -0.9930972789115646 -1.0 -0.9930972789115646
probs:  [0.45664625811057363, 0.04658902074631599, 0.18005863133938732, 0.31670608980372306]
maxi score, test score, baseline:  -0.9931432432432432 -1.0 -0.9931432432432432
probs:  [0.43808236367796705, 0.06411743004926189, 0.24890010313638555, 0.24890010313638555]
maxi score, test score, baseline:  -0.9931432432432432 -1.0 -0.9931432432432432
probs:  [0.43808236367796705, 0.06411743004926189, 0.24890010313638555, 0.24890010313638555]
maxi score, test score, baseline:  -0.9931432432432432 -1.0 -0.9931432432432432
probs:  [0.43808236367796705, 0.06411743004926189, 0.24890010313638555, 0.24890010313638555]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.009]] [[3.418]
 [3.78 ]
 [3.78 ]
 [3.78 ]
 [3.78 ]
 [3.78 ]
 [3.78 ]] [[0.923]
 [1.319]
 [1.319]
 [1.319]
 [1.319]
 [1.319]
 [1.319]]
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.259]
 [0.251]
 [0.251]
 [0.251]
 [0.251]
 [0.251]
 [0.251]] [[1.931]
 [1.559]
 [1.559]
 [1.559]
 [1.559]
 [1.559]
 [1.559]] [[0.259]
 [0.251]
 [0.251]
 [0.251]
 [0.251]
 [0.251]
 [0.251]]
maxi score, test score, baseline:  -0.9931432432432432 -1.0 -0.9931432432432432
probs:  [0.3972260952688095, 0.3972260952688095, 0.10277390473119052, 0.10277390473119052]
siam score:  -0.89574724
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9931432432432432 -1.0 -0.9931432432432432
probs:  [0.3972260952688095, 0.3972260952688095, 0.10277390473119052, 0.10277390473119052]
Printing some Q and Qe and total Qs values:  [[0.419]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]] [[2.773]
 [2.868]
 [2.868]
 [2.868]
 [2.868]
 [2.868]
 [2.868]] [[2.079]
 [2.214]
 [2.214]
 [2.214]
 [2.214]
 [2.214]
 [2.214]]
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.549]
 [0.554]
 [0.546]
 [0.545]
 [0.546]
 [0.547]] [[2.796]
 [1.651]
 [1.714]
 [2.614]
 [2.651]
 [2.638]
 [2.692]] [[2.063]
 [0.564]
 [0.657]
 [1.842]
 [1.889]
 [1.873]
 [1.947]]
maxi score, test score, baseline:  -0.9931885906040269 -1.0 -0.9931885906040269
probs:  [0.39722614331445094, 0.39722614331445094, 0.10277385668554907, 0.10277385668554907]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.383]
 [0.385]
 [0.382]
 [0.385]
 [0.381]
 [0.385]
 [0.385]] [[2.703]
 [2.478]
 [2.791]
 [2.478]
 [3.017]
 [2.478]
 [2.722]] [[1.682]
 [1.453]
 [1.772]
 [1.453]
 [2.003]
 [1.453]
 [1.705]]
maxi score, test score, baseline:  -0.9932333333333333 -1.0 -0.9932333333333333
maxi score, test score, baseline:  -0.9932333333333333 -1.0 -0.9932333333333333
maxi score, test score, baseline:  -0.9932333333333333 -1.0 -0.9932333333333333
probs:  [0.39722619071306653, 0.39722619071306653, 0.10277380928693353, 0.10277380928693353]
deleting a thread, now have 4 threads
Frames:  21953 train batches done:  2559 episodes:  432
Printing some Q and Qe and total Qs values:  [[0.383]
 [0.407]
 [0.407]
 [0.395]
 [0.394]
 [0.396]
 [0.394]] [[2.849]
 [2.534]
 [2.534]
 [2.68 ]
 [2.711]
 [2.641]
 [2.765]] [[1.756]
 [1.399]
 [1.399]
 [1.563]
 [1.601]
 [1.515]
 [1.672]]
siam score:  -0.88495374
maxi score, test score, baseline:  -0.9932333333333333 -1.0 -0.9932333333333333
probs:  [0.14549084243686017, 0.5635274726894195, 0.14549084243686017, 0.14549084243686017]
maxi score, test score, baseline:  -0.9932333333333333 -1.0 -0.9932333333333333
probs:  [0.14549084243686017, 0.5635274726894195, 0.14549084243686017, 0.14549084243686017]
maxi score, test score, baseline:  -0.9932333333333333 -1.0 -0.9932333333333333
probs:  [0.14549084243686017, 0.5635274726894195, 0.14549084243686017, 0.14549084243686017]
first move QE:  0.7232579310070992
deleting a thread, now have 3 threads
Frames:  22212 train batches done:  2576 episodes:  436
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.18059154953480502, 0.45517559958053283, 0.31630550530453216, 0.047927345580129975]
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.18059154953480502, 0.45517559958053283, 0.31630550530453216, 0.047927345580129975]
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.18059154953480502, 0.45517559958053283, 0.31630550530453216, 0.047927345580129975]
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.18059154953480502, 0.45517559958053283, 0.31630550530453216, 0.047927345580129975]
deleting a thread, now have 2 threads
Frames:  22212 train batches done:  2597 episodes:  436
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.18059154953480502, 0.45517559958053283, 0.31630550530453216, 0.047927345580129975]
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.18059154953480502, 0.45517559958053283, 0.31630550530453216, 0.047927345580129975]
313 125
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.24683263801347793, 0.6226929270807386, 0.06523721745289177, 0.06523721745289177]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.3048170764432371, 0.5344038907231338, 0.08038951641681454, 0.08038951641681454]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.3048170764432371, 0.5344038907231338, 0.08038951641681454, 0.08038951641681454]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.3048170764432371, 0.5344038907231338, 0.08038951641681454, 0.08038951641681454]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.5593165804506163, 0.14689447318312795, 0.14689447318312795, 0.14689447318312795]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.43573434649052095, 0.06634089760434568, 0.24896237795256673, 0.24896237795256673]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
Printing some Q and Qe and total Qs values:  [[0.923]
 [0.915]
 [0.915]
 [0.915]
 [0.935]
 [0.933]
 [0.925]] [[5.06 ]
 [5.863]
 [5.863]
 [5.863]
 [5.417]
 [5.33 ]
 [5.17 ]] [[1.739]
 [2.051]
 [2.051]
 [2.051]
 [1.897]
 [1.859]
 [1.787]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.43573434649052095, 0.06634089760434568, 0.24896237795256673, 0.24896237795256673]
from probs:  [0.43573434649052095, 0.06634089760434568, 0.24896237795256673, 0.24896237795256673]
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.40007813574991147, 0.043099407507361985, 0.2784112283713633, 0.2784112283713633]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.993321052631579 -1.0 -0.993321052631579
probs:  [0.40007813574991147, 0.043099407507361985, 0.2784112283713633, 0.2784112283713633]
siam score:  -0.88356215
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9933640522875817 -1.0 -0.9933640522875817
probs:  [0.31701395882666605, 0.048958123520001826, 0.31701395882666605, 0.31701395882666605]
Printing some Q and Qe and total Qs values:  [[0.78 ]
 [0.725]
 [0.791]
 [0.791]
 [0.791]
 [0.79 ]
 [0.791]] [[4.148]
 [2.426]
 [3.695]
 [3.695]
 [3.695]
 [4.98 ]
 [3.695]] [[1.808]
 [0.838]
 [1.574]
 [1.574]
 [1.574]
 [2.264]
 [1.574]]
maxi score, test score, baseline:  -0.9933640522875817 -1.0 -0.9933640522875817
probs:  [0.20992332097964403, 0.0565115174178528, 0.36678258080125153, 0.36678258080125153]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.06661911253078172, 0.06661911253078172, 0.43338088746921827, 0.43338088746921827]
319 131
Printing some Q and Qe and total Qs values:  [[0.681]
 [0.689]
 [0.674]
 [0.689]
 [0.671]
 [0.671]
 [0.687]] [[3.125]
 [2.137]
 [3.141]
 [2.137]
 [3.196]
 [3.288]
 [2.656]] [[1.998]
 [1.791]
 [1.999]
 [1.791]
 [2.01 ]
 [2.03 ]
 [1.901]]
line 256 mcts: sample exp_bonus 9.814172386919129
320 132
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.20930404264238855, 0.20930404264238855, 0.5245906175392507, 0.05680129717597212]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.20930404264238855, 0.20930404264238855, 0.5245906175392507, 0.05680129717597212]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.24899134498238476, 0.24899134498238476, 0.434583868223499, 0.06743344181173148]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.36618146109285393, 0.05748270526491007, 0.36618146109285393, 0.21015437254938207]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.4340142923756386, 0.06797505132571925, 0.24900532814932105, 0.24900532814932105]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.4340142923756386, 0.06797505132571925, 0.24900532814932105, 0.24900532814932105]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.4340142923756386, 0.06797505132571925, 0.24900532814932105, 0.24900532814932105]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.5301993203529315, 0.08285290000638496, 0.30409487963429865, 0.08285290000638496]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.6813169278735663, 0.10622769070881122, 0.10622769070881122, 0.10622769070881122]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.43344845225043127, 0.06851356328166062, 0.24901899223395413, 0.24901899223395413]
324 138
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.30538112360197567, 0.08385662919407297, 0.30538112360197567, 0.30538112360197567]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.30538112360197567, 0.08385662919407297, 0.30538112360197567, 0.30538112360197567]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.30538112360197567, 0.08385662919407297, 0.30538112360197567, 0.30538112360197567]
using explorer policy with actor:  1
using explorer policy with actor:  1
first move QE:  0.8627702522608375
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.30518181164631386, 0.08445456506105833, 0.30518181164631386, 0.30518181164631386]
Printing some Q and Qe and total Qs values:  [[0.692]
 [0.692]
 [0.692]
 [0.692]
 [0.692]
 [0.692]
 [0.692]] [[3.6]
 [3.6]
 [3.6]
 [3.6]
 [3.6]
 [3.6]
 [3.6]] [[1.317]
 [1.317]
 [1.317]
 [1.317]
 [1.317]
 [1.317]
 [1.317]]
Printing some Q and Qe and total Qs values:  [[1.148]
 [1.144]
 [1.145]
 [1.145]
 [1.145]
 [1.144]
 [1.144]] [[0.876]
 [0.885]
 [0.888]
 [0.889]
 [0.888]
 [0.889]
 [0.886]] [[1.41 ]
 [1.415]
 [1.421]
 [1.422]
 [1.421]
 [1.422]
 [1.417]]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.3917845107854295, 0.10821548921457055, 0.3917845107854295, 0.10821548921457055]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.3652917277568576, 0.2104944429364614, 0.3652917277568576, 0.058922101549823504]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.3652917277568576, 0.2104944429364614, 0.3652917277568576, 0.058922101549823504]
siam score:  -0.89228576
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.4323277914073415, 0.24904540423346927, 0.24904540423346927, 0.06958140012571991]
using another actor
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.10886814746241497, 0.39113185253758503, 0.39113185253758503, 0.10886814746241497]
line 256 mcts: sample exp_bonus 7.653714002263498
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.10886814746241497, 0.39113185253758503, 0.39113185253758503, 0.10886814746241497]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.10886814746241497, 0.39113185253758503, 0.39113185253758503, 0.10886814746241497]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.10886814746241497, 0.39113185253758503, 0.39113185253758503, 0.10886814746241497]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.10886814746241497, 0.39113185253758503, 0.39113185253758503, 0.10886814746241497]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.10886814746241497, 0.39113185253758503, 0.39113185253758503, 0.10886814746241497]
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
probs:  [0.10886809778440644, 0.3911319022155936, 0.3911319022155936, 0.10886809778440644]
siam score:  -0.8917819
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
probs:  [0.10886809778440644, 0.3911319022155936, 0.3911319022155936, 0.10886809778440644]
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
probs:  [0.10886809778440644, 0.3911319022155936, 0.3911319022155936, 0.10886809778440644]
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
probs:  [0.10886809778440644, 0.3911319022155936, 0.3911319022155936, 0.10886809778440644]
from probs:  [0.10886809778440644, 0.3911319022155936, 0.3911319022155936, 0.10886809778440644]
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
probs:  [0.05939728054245478, 0.3649983004660346, 0.3649983004660346, 0.21060611852547598]
using explorer policy with actor:  1
from probs:  [0.05939728054245478, 0.3649983004660346, 0.3649983004660346, 0.21060611852547598]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
probs:  [0.07011073607934595, 0.4317729211344808, 0.24905817139308664, 0.24905817139308664]
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
probs:  [0.07011073607934595, 0.4317729211344808, 0.24905817139308664, 0.24905817139308664]
maxi score, test score, baseline:  -0.9934897435897436 -1.0 -0.9934897435897436
probs:  [0.07011069562134487, 0.43177296201612886, 0.24905817118126314, 0.24905817118126314]
maxi score, test score, baseline:  -0.9934897435897436 -1.0 -0.9934897435897436
maxi score, test score, baseline:  -0.9934897435897436 -1.0 -0.9934897435897436
probs:  [0.07011069562134487, 0.43177296201612886, 0.24905817118126314, 0.24905817118126314]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.07011065568367063, 0.43177300237199745, 0.24905817097216593, 0.24905817097216593]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.07011065568367063, 0.43177300237199745, 0.24905817097216593, 0.24905817097216593]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.07011065568367063, 0.43177300237199745, 0.24905817097216593, 0.24905817097216593]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.08563783211724751, 0.3047873892942508, 0.3047873892942508, 0.3047873892942508]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.08563783211724751, 0.3047873892942508, 0.3047873892942508, 0.3047873892942508]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.08563783211724751, 0.3047873892942508, 0.3047873892942508, 0.3047873892942508]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.08563783211724751, 0.3047873892942508, 0.3047873892942508, 0.3047873892942508]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.08563783211724751, 0.3047873892942508, 0.3047873892942508, 0.3047873892942508]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.08563783211724751, 0.3047873892942508, 0.3047873892942508, 0.3047873892942508]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.08563783211724751, 0.3047873892942508, 0.3047873892942508, 0.3047873892942508]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.10951480380025076, 0.39048519619974925, 0.10951480380025076, 0.39048519619974925]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
Printing some Q and Qe and total Qs values:  [[0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]] [[4.538]
 [4.538]
 [4.538]
 [4.538]
 [4.538]
 [4.538]
 [4.538]] [[2.109]
 [2.109]
 [2.109]
 [2.109]
 [2.109]
 [2.109]
 [2.109]]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.2490706582247304, 0.4312216461775019, 0.07063703737303721, 0.2490706582247304]
Printing some Q and Qe and total Qs values:  [[-0.032]
 [-0.038]
 [-0.033]
 [-0.033]
 [-0.034]
 [-0.034]
 [-0.03 ]] [[6.424]
 [6.87 ]
 [6.611]
 [6.618]
 [7.202]
 [7.05 ]
 [6.466]] [[0.696]
 [0.944]
 [0.803]
 [0.807]
 [1.142]
 [1.054]
 [0.724]]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.2490706582247304, 0.4312216461775019, 0.07063703737303721, 0.2490706582247304]
Printing some Q and Qe and total Qs values:  [[0.606]
 [0.642]
 [0.606]
 [0.593]
 [0.606]
 [0.606]
 [0.64 ]] [[8.268]
 [7.217]
 [8.268]
 [8.95 ]
 [8.268]
 [8.268]
 [8.314]] [[1.689]
 [1.281]
 [1.689]
 [1.967]
 [1.689]
 [1.689]
 [1.752]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.30459220547054844, 0.30459220547054844, 0.08622338358835482, 0.30459220547054844]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.537]
 [0.707]
 [0.753]
 [0.7  ]
 [0.736]
 [0.681]] [[3.603]
 [4.382]
 [4.082]
 [3.827]
 [3.685]
 [3.74 ]
 [4.354]] [[2.089]
 [2.317]
 [2.454]
 [2.378]
 [2.179]
 [2.287]
 [2.583]]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.11015583253895646, 0.38984416746104356, 0.11015583253895646, 0.38984416746104356]
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.15277701213499692, 0.15277701213499692, 0.15277701213499692, 0.5416689635950093]
using another actor
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
maxi score, test score, baseline:  -0.9935305732484077 -1.0 -0.9935305732484077
probs:  [0.2780307559428572, 0.04662791964862918, 0.2780307559428572, 0.3973105684656565]
Printing some Q and Qe and total Qs values:  [[0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]] [[3.85]
 [3.85]
 [3.85]
 [3.85]
 [3.85]
 [3.85]
 [3.85]] [[0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9935708860759493 -1.0 -0.9935708860759493
probs:  [0.2780307601233048, 0.04662788931815115, 0.2780307601233048, 0.39731059043523914]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
start point for exploration sampling:  10723
siam score:  -0.87610126
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.06043790536054993, 0.06043790536054993, 0.36187271159049605, 0.5172514776884041]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.04192345056152957, 0.1436110159915539, 0.3532119161636416, 0.46125361728327496]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.05311669764138658, 0.18261480275533326, 0.3147290312049135, 0.44953946839836667]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.05311669764138658, 0.18261480275533326, 0.3147290312049135, 0.44953946839836667]
siam score:  -0.87581056
siam score:  -0.87655175
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.05311669764138658, 0.18261480275533326, 0.3147290312049135, 0.44953946839836667]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.05311669764138658, 0.18261480275533326, 0.3147290312049135, 0.44953946839836667]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.05311669764138658, 0.18261480275533326, 0.3147290312049135, 0.44953946839836667]
line 256 mcts: sample exp_bonus 3.910278227207322
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.05311669764138658, 0.18261480275533326, 0.3147290312049135, 0.44953946839836667]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.05311669764138658, 0.18261480275533326, 0.3147290312049135, 0.44953946839836667]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.05311669764138658, 0.18261480275533326, 0.3147290312049135, 0.44953946839836667]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.05311669764138658, 0.18261480275533326, 0.3147290312049135, 0.44953946839836667]
Printing some Q and Qe and total Qs values:  [[0.255]
 [0.255]
 [0.255]
 [0.255]
 [0.276]
 [0.255]
 [0.196]] [[3.895]
 [3.895]
 [3.895]
 [3.895]
 [3.291]
 [3.895]
 [4.645]] [[0.255]
 [0.255]
 [0.255]
 [0.255]
 [0.276]
 [0.255]
 [0.196]]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.07219839028811383, 0.24910652457431284, 0.24910652457431284, 0.4295885605632605]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.07219839028811383, 0.24910652457431284, 0.24910652457431284, 0.4295885605632605]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.07219839028811383, 0.24910652457431284, 0.24910652457431284, 0.4295885605632605]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.07219839028811383, 0.24910652457431284, 0.24910652457431284, 0.4295885605632605]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.07219834955352857, 0.2491065243696155, 0.2491065243696155, 0.4295886017072405]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.07219834955352857, 0.2491065243696155, 0.2491065243696155, 0.4295886017072405]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.07219834955352857, 0.2491065243696155, 0.2491065243696155, 0.4295886017072405]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.07219834955352857, 0.2491065243696155, 0.2491065243696155, 0.4295886017072405]
349 147
siam score:  -0.88569105
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.08795581313645251, 0.3040147289545158, 0.3040147289545158, 0.3040147289545158]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.08795581313645251, 0.3040147289545158, 0.3040147289545158, 0.3040147289545158]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.05367852148319237, 0.3154404928389359, 0.3154404928389359, 0.3154404928389359]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.05367852148319237, 0.3154404928389359, 0.3154404928389359, 0.3154404928389359]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.05367852148319237, 0.3154404928389359, 0.3154404928389359, 0.3154404928389359]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.04280414917208135, 0.35436912585128433, 0.2484575991253499, 0.35436912585128433]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.04280414917208135, 0.35436912585128433, 0.2484575991253499, 0.35436912585128433]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.04280414917208135, 0.35436912585128433, 0.2484575991253499, 0.35436912585128433]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.047778805148575645, 0.3964161994016705, 0.2779024977248769, 0.2779024977248769]
siam score:  -0.8853032
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.88640475
main train batch thing paused
add a thread
Adding thread: now have 3 threads
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Printing some Q and Qe and total Qs values:  [[0.067]
 [0.066]
 [0.066]
 [0.067]
 [0.066]
 [0.066]
 [0.068]] [[1.679]
 [1.431]
 [1.431]
 [1.603]
 [1.431]
 [1.431]
 [1.684]] [[0.067]
 [0.066]
 [0.066]
 [0.067]
 [0.066]
 [0.066]
 [0.068]]
355 151
maxi score, test score, baseline:  -0.9937271604938271 -1.0 -0.9937271604938271
in main func line 156:  356
maxi score, test score, baseline:  -0.9937650306748467 -1.0 -0.9937650306748467
maxi score, test score, baseline:  -0.9937650306748467 -1.0 -0.9937650306748467
probs:  [0.21136588107421161, 0.3629865742169237, 0.06266097049194089, 0.3629865742169237]
maxi score, test score, baseline:  -0.9937650306748467 -1.0 -0.9937650306748467
probs:  [0.21136588107421161, 0.3629865742169237, 0.06266097049194089, 0.3629865742169237]
maxi score, test score, baseline:  -0.9937650306748467 -1.0 -0.9937650306748467
probs:  [0.21136588107421161, 0.3629865742169237, 0.06266097049194089, 0.3629865742169237]
using another actor
siam score:  -0.88723433
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.3034490268578941, 0.3034490268578941, 0.08965291942631777, 0.3034490268578941]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.3034490268578941, 0.3034490268578941, 0.08965291942631777, 0.3034490268578941]
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.3034490268578941, 0.3034490268578941, 0.08965291942631777, 0.3034490268578941]
Printing some Q and Qe and total Qs values:  [[0.5  ]
 [0.497]
 [0.487]
 [0.49 ]
 [0.491]
 [0.491]
 [0.487]] [[5.602]
 [5.516]
 [6.039]
 [5.933]
 [5.968]
 [5.918]
 [5.984]] [[1.412]
 [1.357]
 [1.667]
 [1.604]
 [1.627]
 [1.596]
 [1.633]]
Printing some Q and Qe and total Qs values:  [[0.708]
 [0.77 ]
 [0.715]
 [0.702]
 [0.7  ]
 [0.701]
 [0.717]] [[3.942]
 [3.904]
 [3.647]
 [3.655]
 [4.115]
 [4.433]
 [3.721]] [[2.513]
 [2.611]
 [2.329]
 [2.31 ]
 [2.611]
 [2.824]
 [2.382]]
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.38611540021392543, 0.38611540021392543, 0.11388459978607456, 0.11388459978607456]
maxi score, test score, baseline:  -0.9938393939393939 -1.0 -0.9938393939393939
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9938393939393939 -1.0 -0.9938393939393939
maxi score, test score, baseline:  -0.9938393939393939 -1.0 -0.9938393939393939
probs:  [0.25, 0.25, 0.25, 0.25]
UNIT TEST: sample policy line 217 mcts : [0.612 0.041 0.041 0.02  0.204 0.061 0.02 ]
maxi score, test score, baseline:  -0.9938393939393939 -1.0 -0.9938393939393939
probs:  [0.15691402699768406, 0.15691402699768406, 0.5292579190069477, 0.15691402699768406]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.24916144938100454, 0.24916144938100454, 0.4269341806080555, 0.07474292062993541]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.816]
 [0.824]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]] [[7.29]
 [6.94]
 [7.29]
 [7.29]
 [7.29]
 [7.29]
 [7.29]] [[1.715]
 [1.621]
 [1.715]
 [1.715]
 [1.715]
 [1.715]
 [1.715]]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.11508467241514506, 0.38491532758485497, 0.38491532758485497, 0.11508467241514506]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.11508467241514506, 0.38491532758485497, 0.38491532758485497, 0.11508467241514506]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.11508467241514506, 0.38491532758485497, 0.38491532758485497, 0.11508467241514506]
Printing some Q and Qe and total Qs values:  [[0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.689]] [[6.186]
 [6.186]
 [6.186]
 [6.117]
 [6.186]
 [6.186]
 [6.509]] [[1.799]
 [1.799]
 [1.799]
 [1.771]
 [1.799]
 [1.799]
 [1.947]]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.11508467241514506, 0.38491532758485497, 0.38491532758485497, 0.11508467241514506]
Printing some Q and Qe and total Qs values:  [[0.326]
 [0.336]
 [0.319]
 [0.324]
 [0.326]
 [0.321]
 [0.323]] [[1.655]
 [1.719]
 [1.57 ]
 [1.434]
 [1.474]
 [1.53 ]
 [1.669]] [[0.326]
 [0.336]
 [0.319]
 [0.324]
 [0.326]
 [0.321]
 [0.323]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.3028946991292105, 0.09131590261236845, 0.3028946991292105, 0.3028946991292105]
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.455]
 [0.425]
 [0.422]
 [0.423]
 [0.425]
 [0.431]] [[2.762]
 [3.359]
 [2.954]
 [3.114]
 [3.204]
 [3.017]
 [2.944]] [[0.427]
 [0.455]
 [0.425]
 [0.422]
 [0.423]
 [0.425]
 [0.431]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.3028946991292105, 0.09131590261236845, 0.3028946991292105, 0.3028946991292105]
using explorer policy with actor:  1
siam score:  -0.8748749
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.36186897301577514, 0.21178389120579041, 0.36186897301577514, 0.06447816276265927]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.36186897301577514, 0.21178389120579041, 0.36186897301577514, 0.06447816276265927]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.35327698272531544, 0.24855892582243722, 0.35327698272531544, 0.04488710872693195]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.35327698272531544, 0.24855892582243722, 0.35327698272531544, 0.04488710872693195]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.35327698272531544, 0.24855892582243722, 0.35327698272531544, 0.04488710872693195]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.35327698272531544, 0.24855892582243722, 0.35327698272531544, 0.04488710872693195]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.35327698272531544, 0.24855892582243722, 0.35327698272531544, 0.04488710872693195]
Printing some Q and Qe and total Qs values:  [[-0.02 ]
 [-0.022]
 [-0.022]
 [-0.022]
 [-0.027]
 [-0.026]
 [-0.026]] [[6.957]
 [6.002]
 [6.002]
 [6.002]
 [6.273]
 [6.104]
 [6.269]] [[0.924]
 [0.427]
 [0.427]
 [0.427]
 [0.56 ]
 [0.473]
 [0.558]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.35327698272531544, 0.24855892582243722, 0.35327698272531544, 0.04488710872693195]
UNIT TEST: sample policy line 217 mcts : [0.102 0.041 0.163 0.082 0.082 0.143 0.388]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.35327698272531544, 0.24855892582243722, 0.35327698272531544, 0.04488710872693195]
372 165
from probs:  [0.5112697631764124, 0.06457152626760543, 0.35958718428837666, 0.06457152626760543]
using explorer policy with actor:  0
372 166
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
siam score:  -0.88436013
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
probs:  [0.3013469831812096, 0.09204689935685481, 0.5145592181050809, 0.09204689935685481]
Printing some Q and Qe and total Qs values:  [[0.361]
 [0.374]
 [0.374]
 [0.359]
 [0.354]
 [0.363]
 [0.359]] [[3.771]
 [4.208]
 [3.723]
 [3.407]
 [3.284]
 [3.552]
 [3.598]] [[0.361]
 [0.374]
 [0.374]
 [0.359]
 [0.354]
 [0.363]
 [0.359]]
line 256 mcts: sample exp_bonus 6.0683691494563385
maxi score, test score, baseline:  -0.9940176470588236 -1.0 -0.9940176470588236
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.3831536193796519, 0.11684638062034809, 0.3831536193796519, 0.11684638062034809]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.3831536193796519, 0.11684638062034809, 0.3831536193796519, 0.11684638062034809]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]] [[3.774]
 [3.774]
 [3.774]
 [3.774]
 [3.774]
 [3.774]
 [3.774]] [[2.153]
 [2.153]
 [2.153]
 [2.153]
 [2.153]
 [2.153]
 [2.153]]
Printing some Q and Qe and total Qs values:  [[0.7  ]
 [0.697]
 [0.697]
 [0.695]
 [0.697]
 [0.697]
 [0.697]] [[2.576]
 [2.41 ]
 [2.41 ]
 [2.549]
 [2.41 ]
 [2.41 ]
 [2.587]] [[1.479]
 [1.418]
 [1.418]
 [1.46 ]
 [1.418]
 [1.418]
 [1.477]]
maxi score, test score, baseline:  -0.9940860465116279 -1.0 -0.9940860465116279
probs:  [0.07672841121414692, 0.2492015134157344, 0.42486856195438427, 0.2492015134157344]
376 169
maxi score, test score, baseline:  -0.9940860465116279 -1.0 -0.9940860465116279
maxi score, test score, baseline:  -0.9940860465116279 -1.0 -0.9940860465116279
probs:  [0.05738583921863882, 0.3142047202604537, 0.3142047202604537, 0.3142047202604537]
maxi score, test score, baseline:  -0.9940860465116279 -1.0 -0.9940860465116279
probs:  [0.05738583921863882, 0.3142047202604537, 0.3142047202604537, 0.3142047202604537]
in main func line 156:  377
377 169
Printing some Q and Qe and total Qs values:  [[-0.057]
 [-0.061]
 [-0.061]
 [-0.062]
 [-0.061]
 [-0.061]
 [-0.062]] [[3.713]
 [3.772]
 [3.772]
 [3.24 ]
 [3.772]
 [3.772]
 [3.14 ]] [[0.532]
 [0.57 ]
 [0.57 ]
 [0.187]
 [0.57 ]
 [0.57 ]
 [0.114]]
maxi score, test score, baseline:  -0.9941196531791907 -1.0 -0.9941196531791907
probs:  [0.07721803253128645, 0.2492110412444356, 0.4243598849798423, 0.2492110412444356]
Printing some Q and Qe and total Qs values:  [[0.35 ]
 [0.512]
 [0.707]
 [0.718]
 [0.525]
 [0.42 ]
 [0.508]] [[3.282]
 [2.708]
 [2.246]
 [3.073]
 [3.054]
 [2.928]
 [2.95 ]] [[1.472]
 [1.194]
 [1.053]
 [1.76 ]
 [1.501]
 [1.264]
 [1.393]]
maxi score, test score, baseline:  -0.9941528735632184 -1.0 -0.9941528735632184
probs:  [0.07721799327204995, 0.24921104106516812, 0.4243599245976139, 0.24921104106516812]
maxi score, test score, baseline:  -0.9941528735632184 -1.0 -0.9941528735632184
probs:  [0.09348152119258529, 0.3021728262691382, 0.3021728262691382, 0.3021728262691382]
maxi score, test score, baseline:  -0.9941528735632184 -1.0 -0.9941528735632184
probs:  [0.11799608612334235, 0.38200391387665766, 0.38200391387665766, 0.11799608612334235]
maxi score, test score, baseline:  -0.9941528735632184 -1.0 -0.9941528735632184
probs:  [0.11799608612334235, 0.38200391387665766, 0.38200391387665766, 0.11799608612334235]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]
 [0.441]] [[2.791]
 [2.791]
 [2.791]
 [2.791]
 [2.791]
 [2.791]
 [2.791]] [[0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]]
line 256 mcts: sample exp_bonus 2.570699869718603
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
siam score:  -0.8719215
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.06626175029441131, 0.36077360180806306, 0.36077360180806306, 0.21219104608946252]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.06626175029441131, 0.36077360180806306, 0.36077360180806306, 0.21219104608946252]
siam score:  -0.8748708
Printing some Q and Qe and total Qs values:  [[-0.021]
 [-0.018]
 [-0.018]
 [-0.015]
 [-0.015]
 [-0.016]
 [-0.015]] [[5.514]
 [7.009]
 [5.858]
 [6.144]
 [6.177]
 [6.199]
 [5.761]] [[0.391]
 [1.022]
 [0.538]
 [0.66 ]
 [0.674]
 [0.683]
 [0.499]]
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.093662206947927, 0.5118187136655208, 0.30085687243862524, 0.093662206947927]
Printing some Q and Qe and total Qs values:  [[1.144]
 [1.144]
 [1.144]
 [1.144]
 [1.144]
 [1.144]
 [1.314]] [[1.421]
 [1.421]
 [1.421]
 [1.421]
 [1.421]
 [1.421]
 [1.383]] [[1.775]
 [1.775]
 [1.775]
 [1.775]
 [1.775]
 [1.775]
 [2.049]]
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.093662206947927, 0.5118187136655208, 0.30085687243862524, 0.093662206947927]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.11800220050141173, 0.645993398495765, 0.11800220050141173, 0.11800220050141173]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.11800220050141173, 0.645993398495765, 0.11800220050141173, 0.11800220050141173]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.16071821490833002, 0.51784535527501, 0.16071821490833002, 0.16071821490833002]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.16071821490833002, 0.51784535527501, 0.16071821490833002, 0.16071821490833002]
siam score:  -0.8709434
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.86987895
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.05885777691243292, 0.4434009640564039, 0.184790048725663, 0.3129512103055002]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.05885777691243292, 0.4434009640564039, 0.184790048725663, 0.3129512103055002]
Printing some Q and Qe and total Qs values:  [[0.873]
 [0.876]
 [0.873]
 [0.874]
 [0.874]
 [0.876]
 [0.868]] [[8.389]
 [8.828]
 [8.608]
 [8.462]
 [8.386]
 [8.828]
 [8.112]] [[2.231]
 [2.44 ]
 [2.334]
 [2.267]
 [2.233]
 [2.44 ]
 [2.096]]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.06757814125141375, 0.3599660765391302, 0.21248970567032585, 0.3599660765391302]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.06757814125141375, 0.3599660765391302, 0.21248970567032585, 0.3599660765391302]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.06757814125141375, 0.3599660765391302, 0.21248970567032585, 0.3599660765391302]
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.727]
 [0.722]
 [0.737]
 [0.732]
 [0.726]
 [0.728]] [[8.661]
 [7.572]
 [8.92 ]
 [8.147]
 [8.56 ]
 [8.81 ]
 [8.767]] [[1.963]
 [1.492]
 [2.085]
 [1.76 ]
 [1.938]
 [2.04 ]
 [2.024]]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.06757814125141375, 0.3599660765391302, 0.21248970567032585, 0.3599660765391302]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.06757814125141375, 0.3599660765391302, 0.21248970567032585, 0.3599660765391302]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.06757814125141375, 0.3599660765391302, 0.21248970567032585, 0.3599660765391302]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.06757814125141375, 0.3599660765391302, 0.21248970567032585, 0.3599660765391302]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.06757814125141375, 0.3599660765391302, 0.21248970567032585, 0.3599660765391302]
Printing some Q and Qe and total Qs values:  [[0.318]
 [0.385]
 [0.328]
 [0.325]
 [0.33 ]
 [0.324]
 [0.327]] [[9.231]
 [7.75 ]
 [9.405]
 [8.957]
 [9.41 ]
 [9.346]
 [8.648]] [[1.529]
 [1.077]
 [1.6  ]
 [1.44 ]
 [1.605]
 [1.576]
 [1.333]]
Printing some Q and Qe and total Qs values:  [[0.454]
 [0.503]
 [0.461]
 [0.461]
 [0.461]
 [0.461]
 [0.461]] [[2.158]
 [3.286]
 [2.301]
 [2.301]
 [2.301]
 [2.301]
 [2.301]] [[0.454]
 [0.503]
 [0.461]
 [0.461]
 [0.461]
 [0.461]
 [0.461]]
line 256 mcts: sample exp_bonus 0.570815878109986
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.06757814125141375, 0.3599660765391302, 0.21248970567032585, 0.3599660765391302]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.06757814125141375, 0.3599660765391302, 0.21248970567032585, 0.3599660765391302]
Printing some Q and Qe and total Qs values:  [[0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]] [[2.609]
 [2.609]
 [2.609]
 [2.609]
 [2.609]
 [2.609]
 [2.609]] [[0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]]
Printing some Q and Qe and total Qs values:  [[0.056]
 [0.068]
 [0.068]
 [0.076]
 [0.077]
 [0.068]
 [0.072]] [[9.23 ]
 [9.41 ]
 [9.41 ]
 [9.292]
 [9.303]
 [9.41 ]
 [9.291]] [[1.453]
 [1.539]
 [1.539]
 [1.502]
 [1.507]
 [1.539]
 [1.497]]
Printing some Q and Qe and total Qs values:  [[0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]] [[2.458]
 [2.458]
 [2.458]
 [2.458]
 [2.458]
 [2.458]
 [2.458]] [[0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]
 [0.526]]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.07915012988548815, 0.24924735740037635, 0.24924735740037635, 0.42235515531375917]
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.529]
 [0.913]
 [0.823]
 [0.768]
 [0.804]
 [0.701]] [[3.227]
 [3.335]
 [4.608]
 [2.563]
 [2.316]
 [2.399]
 [3.528]] [[1.272]
 [1.509]
 [2.9  ]
 [1.571]
 [1.336]
 [1.445]
 [1.916]]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.07915012988548815, 0.24924735740037635, 0.24924735740037635, 0.42235515531375917]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.07915009006444917, 0.24924735722495378, 0.24924735722495378, 0.4223551954856433]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.933]
 [0.916]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]] [[4.26 ]
 [5.374]
 [4.021]
 [4.021]
 [4.021]
 [4.021]
 [4.021]] [[1.371]
 [1.691]
 [1.296]
 [1.296]
 [1.296]
 [1.296]
 [1.296]]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.09524585702566828, 0.09524585702566828, 0.3003745157482465, 0.5091337702004171]
line 256 mcts: sample exp_bonus 1.1212128350356105
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.1849388169774978, 0.05925565589241745, 0.3128269458009163, 0.4429785813291685]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.1849388169774978, 0.05925565589241745, 0.3128269458009163, 0.4429785813291685]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.099]
 [0.085]
 [0.056]
 [0.063]
 [0.073]
 [0.07 ]
 [0.07 ]] [[4.105]
 [5.087]
 [5.433]
 [5.644]
 [5.51 ]
 [5.379]
 [5.411]] [[0.554]
 [0.991]
 [1.127]
 [1.228]
 [1.175]
 [1.113]
 [1.127]]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.212036325471438, 0.06783816675791243, 0.212036325471438, 0.5080891822992116]
Printing some Q and Qe and total Qs values:  [[-0.065]
 [-0.047]
 [-0.059]
 [-0.059]
 [-0.066]
 [-0.059]
 [-0.066]] [[7.671]
 [5.213]
 [7.32 ]
 [7.32 ]
 [7.361]
 [7.32 ]
 [7.325]] [[ 0.985]
 [-0.238]
 [ 0.815]
 [ 0.815]
 [ 0.826]
 [ 0.815]
 [ 0.807]]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [0.12078735102874505, 0.12078735102874505, 0.37921264897125495, 0.37921264897125495]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.86859775
Printing some Q and Qe and total Qs values:  [[0.813]
 [0.979]
 [0.833]
 [0.879]
 [0.814]
 [0.823]
 [0.827]] [[1.777]
 [4.652]
 [1.57 ]
 [1.912]
 [1.655]
 [1.677]
 [1.836]] [[0.411]
 [1.298]
 [0.361]
 [0.478]
 [0.377]
 [0.387]
 [0.434]]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [0.12079356569507499, 0.12079356569507499, 0.6376193029147751, 0.12079356569507499]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [0.3130126287472564, 0.3130126287472564, 0.3130126287472564, 0.06096211375823105]
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [0.3130126287472564, 0.3130126287472564, 0.3130126287472564, 0.06096211375823105]
using another actor
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [0.39130852691866536, 0.2771293499092593, 0.2771293499092593, 0.05443277326281614]
siam score:  -0.8646832
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
line 256 mcts: sample exp_bonus 2.537063000475094
from probs:  [0.39130855006658577, 0.27712935435334934, 0.27712935435334934, 0.054432741226715535]
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
probs:  [0.35838597340443235, 0.21307070712258896, 0.35838597340443235, 0.07015734606854632]
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
probs:  [0.35838597340443235, 0.21307070712258896, 0.35838597340443235, 0.07015734606854632]
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
probs:  [0.2994328054013341, 0.09832156291385398, 0.503924068770958, 0.09832156291385398]
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
probs:  [0.2994328054013341, 0.09832156291385398, 0.503924068770958, 0.09832156291385398]
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
probs:  [0.2994328054013341, 0.09832156291385398, 0.503924068770958, 0.09832156291385398]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.0000],
        [-0.3381],
        [-0.4679],
        [-0.2681],
        [-0.3962],
        [-0.4248],
        [-0.3433],
        [-0.4613],
        [-0.3597],
        [-0.0000]], dtype=torch.float64)
-0.9360449999999999 -0.9360449999999999
-0.0727797758985 -0.410862458139393
-0.024259925299500003 -0.49216864396351206
-0.024259925299500003 -0.29233966412852885
-0.024259925299500003 -0.42046049191127205
-0.024259925299500003 -0.4490170061585833
-0.0727797758985 -0.41612019283884255
-0.024259925299500003 -0.48560852127678805
-0.0727797758985 -0.4324792210394079
-0.9652499999999999 -0.9652499999999999
maxi score, test score, baseline:  -0.9943444444444445 -1.0 -0.9943444444444445
probs:  [0.29943281998452775, 0.09832151816713854, 0.5039241436811953, 0.09832151816713854]
maxi score, test score, baseline:  -0.9943444444444445 -1.0 -0.9943444444444445
probs:  [0.29943281998452775, 0.09832151816713854, 0.5039241436811953, 0.09832151816713854]
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.12294487635178859, 0.12294487635178859, 0.6311653709446342, 0.12294487635178859]
Printing some Q and Qe and total Qs values:  [[0.452]
 [0.46 ]
 [0.455]
 [0.445]
 [0.446]
 [0.447]
 [0.448]] [[0.108]
 [0.807]
 [0.245]
 [0.007]
 [0.016]
 [0.004]
 [0.179]] [[0.452]
 [0.46 ]
 [0.455]
 [0.445]
 [0.446]
 [0.447]
 [0.448]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.526085734870644
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.12294487635178859, 0.12294487635178859, 0.6311653709446342, 0.12294487635178859]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.21264779102320783, 0.07041057923958427, 0.504293838714, 0.21264779102320783]
maxi score, test score, baseline:  -0.994375138121547 -1.0 -0.994375138121547
probs:  [0.24930470039517144, 0.08243279523592609, 0.4189578039737311, 0.24930470039517144]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9944054945054945 -1.0 -0.9944054945054945
probs:  [0.3002827326668072, 0.09915180199957828, 0.3002827326668072, 0.3002827326668072]
line 256 mcts: sample exp_bonus 3.246730138666222
Printing some Q and Qe and total Qs values:  [[0.985]
 [0.866]
 [0.823]
 [0.814]
 [0.812]
 [0.89 ]
 [0.901]] [[3.187]
 [2.569]
 [2.821]
 [3.012]
 [2.983]
 [3.504]
 [3.208]] [[1.529]
 [1.074]
 [1.182]
 [1.282]
 [1.264]
 [1.628]
 [1.468]]
maxi score, test score, baseline:  -0.9944054945054945 -1.0 -0.9944054945054945
probs:  [0.376011694024992, 0.12398830597500798, 0.12398830597500798, 0.376011694024992]
Printing some Q and Qe and total Qs values:  [[0.958]
 [0.958]
 [0.958]
 [0.958]
 [0.958]
 [0.958]
 [0.958]] [[4.868]
 [4.868]
 [4.868]
 [4.868]
 [4.868]
 [4.868]
 [4.868]] [[2.026]
 [2.026]
 [2.026]
 [2.026]
 [2.026]
 [2.026]
 [2.026]]
first move QE:  1.3224732992720751
maxi score, test score, baseline:  -0.9944355191256831 -1.0 -0.9944355191256831
probs:  [0.5030463177016125, 0.16565122743279587, 0.16565122743279587, 0.16565122743279587]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
Printing some Q and Qe and total Qs values:  [[1.452]
 [1.452]
 [1.452]
 [1.452]
 [1.452]
 [1.452]
 [1.452]] [[1.341]
 [1.341]
 [1.341]
 [1.341]
 [1.341]
 [1.341]
 [1.341]] [[2.791]
 [2.792]
 [2.791]
 [2.792]
 [2.792]
 [2.792]
 [2.792]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.3573576217112936, 0.21344660065057805, 0.3573576217112936, 0.07183815592683471]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.3573576217112936, 0.21344660065057805, 0.3573576217112936, 0.07183815592683471]
siam score:  -0.84774476
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.38996090808381045, 0.2769155592468873, 0.2769155592468873, 0.056207973422414965]
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.38996090808381045, 0.2769155592468873, 0.2769155592468873, 0.056207973422414965]
siam score:  -0.84652156
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.38996090808381045, 0.2769155592468873, 0.2769155592468873, 0.056207973422414965]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.3761690460498874, 0.290710545525432, 0.290710545525432, 0.04240986289924864]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.41076481312957674, 0.317425942371075, 0.2255804935447093, 0.04622875095463888]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.3896947826806929, 0.276872923218385, 0.276872923218385, 0.05655937088253687]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.37598442362877693, 0.2906616393722512, 0.2906616393722512, 0.04269229762672057]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
siam score:  -0.8559662
from probs:  [0.37598442362877693, 0.2906616393722512, 0.2906616393722512, 0.04269229762672057]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.3499774579414681, 0.24881449654614768, 0.3499774579414681, 0.05123058757091609]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.2768303294162534, 0.2768303294162534, 0.38942974467135705, 0.056909596496136125]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.2768303294162534, 0.2768303294162534, 0.38942974467135705, 0.056909596496136125]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.2768303294162534, 0.2768303294162534, 0.38942974467135705, 0.056909596496136125]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.2768303294162534, 0.2768303294162534, 0.38942974467135705, 0.056909596496136125]
maxi score, test score, baseline:  -0.9945524064171123 -1.0 -0.9945524064171123
probs:  [0.27683033386639816, 0.27683033386639816, 0.3894297677975105, 0.05690956446969329]
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
probs:  [0.27683033826882125, 0.27683033826882125, 0.3894297906756766, 0.05690953278668087]
Printing some Q and Qe and total Qs values:  [[0.208]
 [0.149]
 [0.206]
 [0.2  ]
 [0.205]
 [0.203]
 [0.2  ]] [[1.194]
 [2.449]
 [1.006]
 [1.33 ]
 [1.238]
 [1.333]
 [1.516]] [[0.208]
 [0.149]
 [0.206]
 [0.2  ]
 [0.205]
 [0.203]
 [0.2  ]]
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
probs:  [0.27683033826882125, 0.27683033826882125, 0.3894297906756766, 0.05690953278668087]
first move QE:  1.3650998475333274
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
probs:  [0.31723419504073397, 0.2256808861943353, 0.4102523568286733, 0.0468325619362575]
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
probs:  [0.31723419504073397, 0.2256808861943353, 0.4102523568286733, 0.0468325619362575]
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
probs:  [0.24842438348928633, 0.24842438348928633, 0.45167891337133914, 0.05147231965008822]
maxi score, test score, baseline:  -0.9946089947089947 -1.0 -0.9946089947089947
probs:  [0.24842438325660277, 0.24842438325660277, 0.4516789431548666, 0.051472290331927795]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9946089947089947 -1.0 -0.9946089947089947
probs:  [0.27580722390901624, 0.1655783687251562, 0.5015559193255562, 0.05705848804027141]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9946089947089947 -1.0 -0.9946089947089947
probs:  [0.2480606449333379, 0.08515481933362765, 0.5816297163994066, 0.08515481933362765]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9946089947089947 -1.0 -0.9946089947089947
probs:  [0.10161117867146967, 0.10161117867146967, 0.6951664639855908, 0.10161117867146967]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.719]
 [0.768]
 [0.757]
 [0.762]
 [0.763]
 [0.773]] [[6.87 ]
 [6.862]
 [6.369]
 [6.943]
 [6.897]
 [6.865]
 [6.552]] [[2.037]
 [1.997]
 [1.776]
 [2.085]
 [2.064]
 [2.048]
 [1.884]]
425 214
using explorer policy with actor:  1
Starting evaluation
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.21342683462080242, 0.21342683462080242, 0.4994124887137757, 0.07373384204461943]
maxi score, test score, baseline:  -0.9946916666666666 -1.0 -0.9946916666666666
probs:  [0.21342681934633706, 0.21342681934633706, 0.4994125928787403, 0.0737337684285856]
maxi score, test score, baseline:  -0.9946916666666666 -1.0 -0.9946916666666666
maxi score, test score, baseline:  -0.9946916666666666 -1.0 -0.9946916666666666
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
line 256 mcts: sample exp_bonus 3.078681911495147
from probs:  [0.2134267825273731, 0.2134267825273731, 0.4994128439674615, 0.07373359097779228]
Printing some Q and Qe and total Qs values:  [[0.355]
 [0.412]
 [0.353]
 [0.33 ]
 [0.353]
 [0.387]
 [0.39 ]] [[1.464]
 [2.251]
 [1.504]
 [1.405]
 [1.67 ]
 [1.919]
 [2.137]] [[0.355]
 [0.412]
 [0.353]
 [0.33 ]
 [0.353]
 [0.387]
 [0.39 ]]
Printing some Q and Qe and total Qs values:  [[0.082]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]] [[1.53 ]
 [1.381]
 [1.381]
 [1.381]
 [1.381]
 [1.381]
 [1.381]] [[0.082]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]]
maxi score, test score, baseline:  -0.9948748743718593 -1.0 -0.9948748743718593
probs:  [0.31100799691570064, 0.06503959939259592, 0.4368746378357223, 0.1870777658559812]
maxi score, test score, baseline:  -0.9948748743718593 -1.0 -0.9948748743718593
probs:  [0.31100799691570064, 0.06503959939259592, 0.4368746378357223, 0.1870777658559812]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9949 -1.0 -0.9949
probs:  [0.24846851084940633, 0.052437899573415485, 0.45062507872777186, 0.24846851084940633]
Printing some Q and Qe and total Qs values:  [[0.34 ]
 [0.368]
 [0.358]
 [0.321]
 [0.318]
 [0.337]
 [0.358]] [[2.781]
 [2.933]
 [2.554]
 [2.189]
 [2.337]
 [2.571]
 [3.116]] [[0.34 ]
 [0.368]
 [0.358]
 [0.321]
 [0.318]
 [0.337]
 [0.358]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9949980392156863 -1.0 -0.9949980392156863
probs:  [0.24846851002891848, 0.052437793730359096, 0.45062518621180403, 0.24846851002891848]
maxi score, test score, baseline:  -0.9951153110047847 -1.0 -0.9951153110047847
probs:  [0.24846850904778905, 0.05243766716477115, 0.4506253147396507, 0.24846850904778905]
rdn probs:  [0.27570865988252835, 0.05809997290107778, 0.5001176183321534, 0.1660737488842405]
from probs:  [0.2757086633665474, 0.058099946894929505, 0.5001176522279048, 0.16607373751061816]
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.30910996759379994, 0.06504300462585069, 0.5608040231544987, 0.06504300462585069]
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.30910998530915235, 0.06504294919394726, 0.560804116302953, 0.06504294919394726]
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.30910998530915235, 0.06504294919394726, 0.560804116302953, 0.06504294919394726]
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.30910998530915235, 0.06504294919394726, 0.560804116302953, 0.06504294919394726]
from probs:  [0.21222225738868536, 0.07406365583872897, 0.6396504309338567, 0.07406365583872897]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.170075019717732, 0.170075019717732, 0.48977494084680384, 0.170075019717732]
Printing some Q and Qe and total Qs values:  [[0.208]
 [0.156]
 [0.207]
 [0.206]
 [0.206]
 [0.205]
 [0.205]] [[1.076]
 [2.61 ]
 [1.508]
 [1.448]
 [1.366]
 [1.355]
 [1.403]] [[0.208]
 [0.156]
 [0.207]
 [0.206]
 [0.206]
 [0.205]
 [0.205]]
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.2493815640151542, 0.2493815640151542, 0.41388553598404093, 0.08735133598565059]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.2493815640151542, 0.2493815640151542, 0.41388553598404093, 0.08735133598565059]
maxi score, test score, baseline:  -0.9952488372093024 -1.0 -0.9952488372093024
probs:  [0.2976389575416518, 0.10412877341897647, 0.4941034956203953, 0.10412877341897647]
maxi score, test score, baseline:  -0.9952703703703704 -1.0 -0.9952703703703704
probs:  [0.29763896885367574, 0.10412873878137828, 0.4941035535835677, 0.10412873878137828]
maxi score, test score, baseline:  -0.9952703703703704 -1.0 -0.9952703703703704
probs:  [0.29763896885367574, 0.10412873878137828, 0.4941035535835677, 0.10412873878137828]
Printing some Q and Qe and total Qs values:  [[0.101]
 [0.282]
 [0.153]
 [0.081]
 [0.101]
 [0.081]
 [0.085]] [[4.843]
 [2.144]
 [5.05 ]
 [5.188]
 [5.254]
 [5.104]
 [5.18 ]] [[ 1.313]
 [-0.312]
 [ 1.529]
 [ 1.525]
 [ 1.599]
 [ 1.467]
 [ 1.526]]
Printing some Q and Qe and total Qs values:  [[0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]] [[1.424]
 [1.412]
 [1.434]
 [1.428]
 [1.431]
 [1.425]
 [1.427]] [[0.084]
 [0.073]
 [0.093]
 [0.089]
 [0.091]
 [0.085]
 [0.088]]
line 256 mcts: sample exp_bonus 1.194933480561982
maxi score, test score, baseline:  -0.9952703703703704 -1.0 -0.9952703703703704
probs:  [0.17049249376084274, 0.17049249376084274, 0.48852251871747177, 0.17049249376084274]
maxi score, test score, baseline:  -0.9952703703703704 -1.0 -0.9952703703703704
probs:  [0.17049249376084274, 0.17049249376084274, 0.48852251871747177, 0.17049249376084274]
maxi score, test score, baseline:  -0.9952703703703704 -1.0 -0.9952703703703704
probs:  [0.17049249376084274, 0.17049249376084274, 0.48852251871747177, 0.17049249376084274]
maxi score, test score, baseline:  -0.9952703703703704 -1.0 -0.9952703703703704
probs:  [0.17049249376084274, 0.17049249376084274, 0.48852251871747177, 0.17049249376084274]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9952917050691245 -1.0 -0.9952917050691245
probs:  [0.17049246302102328, 0.17049246302102328, 0.48852261093693017, 0.17049246302102328]
maxi score, test score, baseline:  -0.9952917050691245 -1.0 -0.9952917050691245
probs:  [0.17049246302102328, 0.17049246302102328, 0.48852261093693017, 0.17049246302102328]
Printing some Q and Qe and total Qs values:  [[0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.313]] [[1.354]
 [1.354]
 [1.354]
 [1.354]
 [1.354]
 [1.354]
 [1.354]] [[0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.313]]
Printing some Q and Qe and total Qs values:  [[-0.014]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.013]
 [-0.013]
 [-0.006]] [[6.996]
 [7.575]
 [7.575]
 [7.575]
 [6.927]
 [6.632]
 [7.575]] [[ 0.037]
 [ 0.246]
 [ 0.246]
 [ 0.246]
 [ 0.016]
 [-0.082]
 [ 0.246]]
Printing some Q and Qe and total Qs values:  [[0.709]
 [0.818]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.714]] [[3.236]
 [3.671]
 [4.989]
 [4.989]
 [4.989]
 [4.989]
 [3.494]] [[1.539]
 [2.015]
 [2.684]
 [2.684]
 [2.684]
 [2.684]
 [1.734]]
from probs:  [0.17049243256514685, 0.17049243256514685, 0.4885227023045594, 0.17049243256514685]
Printing some Q and Qe and total Qs values:  [[0.643]
 [0.775]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]] [[4.027]
 [3.346]
 [4.027]
 [4.027]
 [4.027]
 [4.027]
 [4.027]] [[2.708]
 [2.544]
 [2.708]
 [2.708]
 [2.708]
 [2.708]
 [2.708]]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.104898184615627, 0.29836727179479106, 0.29836727179479106, 0.29836727179479106]
siam score:  -0.8580698
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.104898184615627, 0.29836727179479106, 0.29836727179479106, 0.29836727179479106]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.104898184615627, 0.29836727179479106, 0.29836727179479106, 0.29836727179479106]
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
probs:  [0.10489815060631796, 0.2983672831312273, 0.2983672831312273, 0.2983672831312273]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
probs:  [0.06664828645272816, 0.3111172378490906, 0.3111172378490906, 0.3111172378490906]
from probs:  [0.06664828645272816, 0.3111172378490906, 0.3111172378490906, 0.3111172378490906]
Printing some Q and Qe and total Qs values:  [[0.42 ]
 [0.42 ]
 [0.342]
 [0.42 ]
 [0.42 ]
 [0.409]
 [0.42 ]] [[5.846]
 [5.846]
 [5.492]
 [5.846]
 [5.846]
 [6.375]
 [5.846]] [[1.389]
 [1.389]
 [1.061]
 [1.389]
 [1.389]
 [1.667]
 [1.389]]
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
probs:  [0.07591068008963825, 0.3548699490640898, 0.2143494217821821, 0.3548699490640898]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.10505498143929219, 0.2973511157891585, 0.10505498143929219, 0.49253892133225713]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.10505498143929219, 0.2973511157891585, 0.10505498143929219, 0.49253892133225713]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.10505498143929219, 0.2973511157891585, 0.10505498143929219, 0.49253892133225713]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.06689358089731548, 0.3104206085441138, 0.18775514276646954, 0.43493066779210116]
siam score:  -0.8556737
Printing some Q and Qe and total Qs values:  [[0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [0.871]] [[6.081]
 [6.081]
 [6.081]
 [6.081]
 [6.081]
 [6.081]
 [6.081]] [[9.855]
 [9.855]
 [9.855]
 [9.855]
 [9.855]
 [9.855]
 [9.855]]
Printing some Q and Qe and total Qs values:  [[0.437]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.456]] [[4.375]
 [4.361]
 [4.361]
 [4.361]
 [4.361]
 [4.361]
 [4.484]] [[1.263]
 [1.258]
 [1.258]
 [1.258]
 [1.258]
 [1.258]
 [1.373]]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.07630818648191698, 0.35462741289071426, 0.2144369877366545, 0.35462741289071426]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.07630818648191698, 0.35462741289071426, 0.2144369877366545, 0.35462741289071426]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]] [[4.887]
 [4.887]
 [4.887]
 [4.887]
 [4.887]
 [4.887]
 [4.887]] [[2.204]
 [2.204]
 [2.204]
 [2.204]
 [2.204]
 [2.204]
 [2.204]]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.07630818648191698, 0.35462741289071426, 0.2144369877366545, 0.35462741289071426]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.07630818648191698, 0.35462741289071426, 0.2144369877366545, 0.35462741289071426]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.07630818648191698, 0.35462741289071426, 0.2144369877366545, 0.35462741289071426]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.07630818648191698, 0.35462741289071426, 0.2144369877366545, 0.35462741289071426]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.07630818648191698, 0.35462741289071426, 0.2144369877366545, 0.35462741289071426]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.08843423361906382, 0.41156576638093617, 0.08843423361906382, 0.41156576638093617]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
using another actor
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.10551387289216782, 0.2972083385599845, 0.10551387289216782, 0.49176391565567995]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.10551387289216782, 0.2972083385599845, 0.10551387289216782, 0.49176391565567995]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.834]
 [0.823]
 [0.834]
 [0.834]
 [0.834]
 [0.834]
 [0.834]] [[3.051]
 [3.241]
 [3.051]
 [3.051]
 [3.051]
 [3.051]
 [3.051]] [[2.246]
 [2.337]
 [2.246]
 [2.246]
 [2.246]
 [2.246]
 [2.246]]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.29791026104546253, 0.29791026104546253, 0.29791026104546253, 0.10626921686361221]
Printing some Q and Qe and total Qs values:  [[0.632]
 [0.605]
 [0.577]
 [0.607]
 [0.603]
 [0.608]
 [0.61 ]] [[4.596]
 [4.394]
 [4.627]
 [4.814]
 [4.827]
 [4.788]
 [4.797]] [[1.73 ]
 [1.543]
 [1.671]
 [1.85 ]
 [1.855]
 [1.834]
 [1.843]]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.29791026104546253, 0.29791026104546253, 0.29791026104546253, 0.10626921686361221]
Printing some Q and Qe and total Qs values:  [[0.817]
 [0.83 ]
 [0.817]
 [0.815]
 [0.813]
 [0.814]
 [0.828]] [[4.885]
 [5.66 ]
 [5.769]
 [5.589]
 [5.65 ]
 [5.704]
 [5.689]] [[1.896]
 [2.18 ]
 [2.19 ]
 [2.126]
 [2.143]
 [2.162]
 [2.186]]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.36864964442608417, 0.13135035557391586, 0.36864964442608417, 0.13135035557391586]
Printing some Q and Qe and total Qs values:  [[0.697]
 [0.729]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]] [[5.933]
 [6.27 ]
 [5.933]
 [5.933]
 [5.933]
 [5.933]
 [5.933]] [[1.277]
 [1.454]
 [1.277]
 [1.277]
 [1.277]
 [1.277]
 [1.277]]
siam score:  -0.86500305
Printing some Q and Qe and total Qs values:  [[0.176]
 [0.224]
 [0.224]
 [0.224]
 [0.18 ]
 [0.224]
 [0.196]] [[8.32 ]
 [6.625]
 [6.625]
 [6.625]
 [7.958]
 [6.625]
 [7.634]] [[1.464]
 [0.782]
 [0.782]
 [0.782]
 [1.313]
 [0.782]
 [1.189]]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.29775977881457927, 0.29775977881457927, 0.10672066355626217, 0.29775977881457927]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.29775977881457927, 0.29775977881457927, 0.10672066355626217, 0.29775977881457927]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.29775977881457927, 0.29775977881457927, 0.10672066355626217, 0.29775977881457927]
Printing some Q and Qe and total Qs values:  [[0.64 ]
 [0.691]
 [0.649]
 [0.65 ]
 [0.649]
 [0.649]
 [0.648]] [[6.38 ]
 [6.272]
 [6.432]
 [6.278]
 [6.313]
 [6.432]
 [6.318]] [[1.018]
 [1.083]
 [1.054]
 [1.004]
 [1.014]
 [1.054]
 [1.014]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.29775977881457927, 0.29775977881457927, 0.10672066355626217, 0.29775977881457927]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.29775977881457927, 0.29775977881457927, 0.10672066355626217, 0.29775977881457927]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.31062993529758615, 0.31062993529758615, 0.06811019410724155, 0.31062993529758615]
siam score:  -0.86121446
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.24893856274853454, 0.34800603955188586, 0.0550493581476937, 0.34800603955188586]
Printing some Q and Qe and total Qs values:  [[0.452]
 [0.452]
 [0.452]
 [0.463]
 [0.452]
 [0.452]
 [0.474]] [[6.938]
 [6.938]
 [6.938]
 [7.033]
 [6.938]
 [6.938]
 [6.958]] [[1.899]
 [1.899]
 [1.899]
 [1.967]
 [1.899]
 [1.899]
 [1.946]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.82532592363821
siam score:  -0.86523485
siam score:  -0.86723083
Printing some Q and Qe and total Qs values:  [[0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.328]
 [0.328]] [[0.186]
 [0.186]
 [0.186]
 [0.186]
 [0.186]
 [0.784]
 [0.766]] [[0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.328]
 [0.328]]
UNIT TEST: sample policy line 217 mcts : [0.02  0.653 0.02  0.041 0.02  0.02  0.224]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.24894789970420364, 0.34784532750902997, 0.05536144527773645, 0.34784532750902997]
Printing some Q and Qe and total Qs values:  [[0.823]
 [0.899]
 [0.823]
 [0.823]
 [0.823]
 [0.823]
 [0.823]] [[5.791]
 [6.946]
 [5.791]
 [5.791]
 [5.791]
 [5.791]
 [5.791]] [[1.506]
 [1.992]
 [1.506]
 [1.506]
 [1.506]
 [1.506]
 [1.506]]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.2762818620436672, 0.38608164124831623, 0.06135463466434932, 0.2762818620436672]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.2762818620436672, 0.38608164124831623, 0.06135463466434932, 0.2762818620436672]
line 256 mcts: sample exp_bonus 1.6166886271447252
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.2762818620436672, 0.38608164124831623, 0.06135463466434932, 0.2762818620436672]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.3103890320385853, 0.3103890320385853, 0.06883290388424423, 0.3103890320385853]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.35343097128578355, 0.21486786486017234, 0.07827019256826045, 0.35343097128578355]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.35343097128578355, 0.21486786486017234, 0.07827019256826045, 0.35343097128578355]
first move QE:  1.4925907610411893
Printing some Q and Qe and total Qs values:  [[0.192]
 [0.269]
 [0.25 ]
 [0.33 ]
 [0.274]
 [0.248]
 [0.229]] [[7.329]
 [7.557]
 [8.02 ]
 [9.071]
 [7.338]
 [8.171]
 [8.133]] [[1.116]
 [1.252]
 [1.425]
 [1.89 ]
 [1.168]
 [1.483]
 [1.457]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
probs:  [0.4103839706313406, 0.2494292385386788, 0.09075755229130192, 0.2494292385386788]
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
probs:  [0.4879605194644427, 0.10776682217460383, 0.10776682217460383, 0.2965058361863496]
Printing some Q and Qe and total Qs values:  [[0.826]
 [0.818]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]] [[4.008]
 [3.95 ]
 [4.008]
 [4.008]
 [4.008]
 [4.008]
 [4.008]] [[1.494]
 [1.461]
 [1.494]
 [1.494]
 [1.494]
 [1.494]
 [1.494]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
probs:  [0.6018114146433063, 0.13272952845223127, 0.13272952845223127, 0.13272952845223127]
siam score:  -0.86452055
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
line 256 mcts: sample exp_bonus 4.750859986005499
from probs:  [0.6018114146433063, 0.13272952845223127, 0.13272952845223127, 0.13272952845223127]
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
probs:  [0.4789464238064683, 0.1736845253978439, 0.1736845253978439, 0.1736845253978439]
Printing some Q and Qe and total Qs values:  [[0.474]
 [0.481]
 [0.488]
 [0.542]
 [0.478]
 [0.475]
 [0.475]] [[5.182]
 [4.873]
 [5.113]
 [5.909]
 [5.14 ]
 [5.258]
 [5.243]] [[1.23 ]
 [1.089]
 [1.211]
 [1.645]
 [1.214]
 [1.268]
 [1.261]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.4099567448021549, 0.09117369155687186, 0.2494347818204866, 0.2494347818204866]
Printing some Q and Qe and total Qs values:  [[0.826]
 [0.782]
 [0.823]
 [0.821]
 [0.837]
 [0.819]
 [0.843]] [[2.77 ]
 [3.895]
 [2.809]
 [2.817]
 [3.118]
 [2.876]
 [3.151]] [[0.784]
 [1.149]
 [0.795]
 [0.797]
 [0.914]
 [0.816]
 [0.93 ]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.732]
 [0.756]
 [0.774]
 [0.774]
 [0.74 ]
 [0.774]
 [0.774]] [[5.055]
 [5.133]
 [6.206]
 [6.206]
 [4.946]
 [6.206]
 [6.206]] [[2.103]
 [2.206]
 [3.109]
 [3.109]
 [2.028]
 [3.109]
 [3.109]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.09158777457087176, 0.24944023948611593, 0.24944023948611593, 0.4095317464568964]
Printing some Q and Qe and total Qs values:  [[0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]] [[3.467]
 [3.467]
 [3.467]
 [3.467]
 [3.467]
 [3.467]
 [3.467]] [[2.751]
 [2.751]
 [2.751]
 [2.751]
 [2.751]
 [2.751]
 [2.751]]
line 256 mcts: sample exp_bonus 2.77248503781409
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.13406571949997043, 0.3659342805000296, 0.13406571949997043, 0.3659342805000296]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.17444363831141682, 0.4766690850657494, 0.17444363831141682, 0.17444363831141682]
Printing some Q and Qe and total Qs values:  [[0.998]
 [0.977]
 [0.998]
 [0.998]
 [0.998]
 [0.998]
 [0.998]] [[3.813]
 [3.978]
 [3.813]
 [3.813]
 [3.813]
 [3.813]
 [3.813]] [[1.978]
 [2.016]
 [1.978]
 [1.978]
 [1.978]
 [1.978]
 [1.978]]
Printing some Q and Qe and total Qs values:  [[0.122]
 [0.208]
 [0.122]
 [0.142]
 [0.122]
 [0.122]
 [0.178]] [[4.753]
 [4.796]
 [4.753]
 [4.73 ]
 [4.753]
 [5.054]
 [5.227]] [[0.823]
 [0.979]
 [0.823]
 [0.836]
 [0.823]
 [1.039]
 [1.245]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.35249304220452615, 0.35249304220452615, 0.21520444063726196, 0.07980947495368564]
Printing some Q and Qe and total Qs values:  [[0.875]
 [0.88 ]
 [0.872]
 [0.87 ]
 [0.866]
 [0.861]
 [0.852]] [[4.007]
 [3.083]
 [2.774]
 [2.814]
 [2.838]
 [2.847]
 [2.798]] [[2.421]
 [1.606]
 [1.315]
 [1.346]
 [1.361]
 [1.36 ]
 [1.301]]
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.626]
 [0.697]
 [0.698]
 [0.652]
 [0.706]
 [0.705]] [[1.497]
 [2.03 ]
 [1.225]
 [1.177]
 [1.705]
 [1.393]
 [1.455]] [[2.377]
 [2.554]
 [2.194]
 [2.166]
 [2.403]
 [2.312]
 [2.348]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.38426163176404027, 0.38426163176404027, 0.06292017472218286, 0.1685565617497365]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.38426163176404027, 0.38426163176404027, 0.06292017472218286, 0.1685565617497365]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.38426163176404027, 0.38426163176404027, 0.06292017472218286, 0.1685565617497365]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.38426163176404027, 0.38426163176404027, 0.06292017472218286, 0.1685565617497365]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.38426163176404027, 0.38426163176404027, 0.06292017472218286, 0.1685565617497365]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.739]
 [0.778]
 [0.706]
 [0.673]
 [0.739]
 [0.709]] [[3.205]
 [3.287]
 [2.874]
 [3.469]
 [3.193]
 [3.091]
 [3.367]] [[1.671]
 [1.889]
 [1.544]
 [2.016]
 [1.701]
 [1.698]
 [1.922]]
first move QE:  1.534419629717599
from probs:  [0.4449445436082213, 0.34595364571467513, 0.05706184165800285, 0.1520399690191007]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.49318715427061555, 0.27520501059120395, 0.06315435381463376, 0.1684534813235467]
Printing some Q and Qe and total Qs values:  [[0.781]
 [0.783]
 [0.781]
 [0.781]
 [0.781]
 [0.781]
 [0.781]] [[3.69 ]
 [4.668]
 [3.69 ]
 [3.69 ]
 [3.69 ]
 [3.69 ]
 [3.69 ]] [[1.35 ]
 [1.681]
 [1.35 ]
 [1.35 ]
 [1.35 ]
 [1.35 ]
 [1.35 ]]
Printing some Q and Qe and total Qs values:  [[0.454]
 [0.454]
 [0.454]
 [0.451]
 [0.451]
 [0.451]
 [0.454]] [[6.463]
 [6.463]
 [6.463]
 [6.333]
 [6.369]
 [6.29 ]
 [6.463]] [[0.877]
 [0.877]
 [0.877]
 [0.827]
 [0.839]
 [0.813]
 [0.877]]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.49318715427061555, 0.27520501059120395, 0.06315435381463376, 0.1684534813235467]
Printing some Q and Qe and total Qs values:  [[-0.037]
 [-0.039]
 [-0.043]
 [-0.043]
 [-0.043]
 [-0.048]
 [-0.044]] [[4.481]
 [3.401]
 [3.722]
 [3.633]
 [3.858]
 [3.657]
 [3.496]] [[0.765]
 [0.023]
 [0.239]
 [0.177]
 [0.332]
 [0.189]
 [0.083]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.49318715427061555, 0.27520501059120395, 0.06315435381463376, 0.1684534813235467]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.5513732095076194, 0.3076215627531767, 0.07050261386960197, 0.07050261386960197]
from probs:  [0.5513732095076194, 0.3076215627531767, 0.07050261386960197, 0.07050261386960197]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954752212389381 -1.0 -0.9954752212389381
probs:  [0.48874859752144617, 0.350711060311408, 0.08027017108357283, 0.08027017108357283]
from probs:  [0.48874859752144617, 0.350711060311408, 0.08027017108357283, 0.08027017108357283]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.726559293367305
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.40744008921979397, 0.2494663047823067, 0.2494663047823067, 0.0936273012155926]
siam score:  -0.8542445
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.4711655171759103, 0.17627816094136325, 0.17627816094136325, 0.17627816094136325]
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.4711655171759103, 0.17627816094136325, 0.17627816094136325, 0.17627816094136325]
maxi score, test score, baseline:  -0.9955140350877193 -1.0 -0.9955140350877193
probs:  [0.11151123851656461, 0.2961629204944785, 0.2961629204944785, 0.2961629204944785]
from probs:  [0.11151123851656461, 0.2961629204944785, 0.2961629204944785, 0.2961629204944785]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.1366624490512746, 0.1366624490512746, 0.3633375509487254, 0.3633375509487254]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.2494761919167574, 0.09442899927715757, 0.2494761919167574, 0.40661861688932754]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.3087136749460945, 0.18969392732077642, 0.07225060019380349, 0.4293417975393256]
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]] [[6.413]
 [6.413]
 [6.413]
 [6.413]
 [6.413]
 [6.413]
 [6.413]] [[1.98]
 [1.98]
 [1.98]
 [1.98]
 [1.98]
 [1.98]
 [1.98]]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.31508773520538585, 0.22674372101566995, 0.05354295635425149, 0.40462558742469273]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.31508773520538585, 0.22674372101566995, 0.05354295635425149, 0.40462558742469273]
Printing some Q and Qe and total Qs values:  [[0.485]
 [0.397]
 [0.417]
 [0.405]
 [0.415]
 [0.426]
 [0.464]] [[2.31 ]
 [2.444]
 [2.559]
 [2.485]
 [2.376]
 [2.581]
 [2.684]] [[0.485]
 [0.397]
 [0.417]
 [0.405]
 [0.415]
 [0.426]
 [0.464]]
first move QE:  1.579351047901106
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
probs:  [0.38337878854008195, 0.27582666197195127, 0.06496788751601543, 0.27582666197195127]
Printing some Q and Qe and total Qs values:  [[0.802]
 [0.741]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]] [[4.207]
 [5.451]
 [4.497]
 [4.497]
 [4.497]
 [4.497]
 [4.497]] [[2.182]
 [2.452]
 [2.408]
 [2.408]
 [2.408]
 [2.408]
 [2.408]]
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.776]
 [0.779]
 [0.719]
 [0.46 ]
 [0.703]
 [0.752]] [[3.578]
 [2.772]
 [2.064]
 [2.547]
 [2.645]
 [2.584]
 [2.62 ]] [[1.484]
 [1.753]
 [1.523]
 [1.564]
 [1.08 ]
 [1.545]
 [1.654]]
maxi score, test score, baseline:  -0.9955709956709957 -1.0 -0.9955709956709957
probs:  [0.42898157749636223, 0.18981849024975508, 0.07259710867164883, 0.30860282358223395]
488 261
first move QE:  1.581864400823131
maxi score, test score, baseline:  -0.9955709956709957 -1.0 -0.9955709956709957
probs:  [0.4049713579686668, 0.09502864203133322, 0.09502864203133322, 0.4049713579686668]
using another actor
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.47999264979470047, 0.11249116705396253, 0.11249116705396253, 0.2950250160973744]
from probs:  [0.47999264979470047, 0.11249116705396253, 0.11249116705396253, 0.2950250160973744]
siam score:  -0.85704345
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.587472704526726, 0.13750909849109133, 0.13750909849109133, 0.13750909849109133]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.587472704526726, 0.13750909849109133, 0.13750909849109133, 0.13750909849109133]
UNIT TEST: sample policy line 217 mcts : [0.041 0.082 0.143 0.245 0.122 0.184 0.184]
from probs:  [0.587472704526726, 0.13750909849109133, 0.13750909849109133, 0.13750909849109133]
maxi score, test score, baseline:  -0.9956081545064378 -1.0 -0.9956081545064378
maxi score, test score, baseline:  -0.9956081545064378 -1.0 -0.9956081545064378
probs:  [0.5874728083689192, 0.13750906387702688, 0.13750906387702688, 0.13750906387702688]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9956264957264958 -1.0 -0.9956264957264958
probs:  [0.5874729113179243, 0.13750902956069186, 0.13750902956069186, 0.13750902956069186]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9956264957264958 -1.0 -0.9956264957264958
probs:  [0.5874729113179243, 0.13750902956069186, 0.13750902956069186, 0.13750902956069186]
maxi score, test score, baseline:  -0.9956264957264958 -1.0 -0.9956264957264958
probs:  [0.5874729113179243, 0.13750902956069186, 0.13750902956069186, 0.13750902956069186]
maxi score, test score, baseline:  -0.9956264957264958 -1.0 -0.9956264957264958
probs:  [0.5874729113179243, 0.13750902956069186, 0.13750902956069186, 0.13750902956069186]
maxi score, test score, baseline:  -0.9956264957264958 -1.0 -0.9956264957264958
probs:  [0.46694819314843583, 0.17768393561718804, 0.17768393561718804, 0.17768393561718804]
siam score:  -0.8527017
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.29560765575157116, 0.11317703274528655, 0.29560765575157116, 0.29560765575157116]
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.815]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]] [[6.695]
 [7.512]
 [6.695]
 [6.695]
 [6.695]
 [6.695]
 [6.695]] [[1.416]
 [1.749]
 [1.416]
 [1.416]
 [1.416]
 [1.416]
 [1.416]]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.29560767827828605, 0.1131769651651419, 0.29560767827828605, 0.29560767827828605]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.29560767827828605, 0.1131769651651419, 0.29560767827828605, 0.29560767827828605]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
Printing some Q and Qe and total Qs values:  [[0.766]
 [0.763]
 [0.766]
 [0.766]
 [0.766]
 [0.766]
 [0.766]] [[4.425]
 [5.915]
 [4.425]
 [4.425]
 [4.425]
 [4.425]
 [4.425]] [[0.902]
 [1.394]
 [0.902]
 [0.902]
 [0.902]
 [0.902]
 [0.902]]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.3616686318498781, 0.13833136815012192, 0.3616686318498781, 0.13833136815012192]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.3616686318498781, 0.13833136815012192, 0.3616686318498781, 0.13833136815012192]
Printing some Q and Qe and total Qs values:  [[0.425]
 [0.462]
 [0.425]
 [0.425]
 [0.425]
 [0.423]
 [0.421]] [[6.078]
 [6.138]
 [6.078]
 [6.078]
 [6.078]
 [6.165]
 [6.197]] [[0.513]
 [0.607]
 [0.513]
 [0.513]
 [0.513]
 [0.54 ]
 [0.546]]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.269]
 [0.314]
 [0.269]
 [0.269]
 [0.269]
 [0.269]
 [0.301]] [[7.125]
 [7.02 ]
 [7.125]
 [7.125]
 [7.125]
 [7.125]
 [7.072]] [[0.408]
 [0.462]
 [0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.455]]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.3616686318498781, 0.13833136815012192, 0.3616686318498781, 0.13833136815012192]
siam score:  -0.8465991
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.3616686318498781, 0.13833136815012192, 0.3616686318498781, 0.13833136815012192]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.3616686318498781, 0.13833136815012192, 0.3616686318498781, 0.13833136815012192]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.3616686318498781, 0.13833136815012192, 0.3616686318498781, 0.13833136815012192]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.3616686318498781, 0.13833136815012192, 0.3616686318498781, 0.13833136815012192]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.3616686318498781, 0.13833136815012192, 0.3616686318498781, 0.13833136815012192]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.1780271729679977, 0.1780271729679977, 0.4659184810960069, 0.1780271729679977]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.1780271729679977, 0.1780271729679977, 0.4659184810960069, 0.1780271729679977]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.0736289732808933, 0.308272431894449, 0.42790972164806845, 0.19018887317658922]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.0736289732808933, 0.308272431894449, 0.42790972164806845, 0.19018887317658922]
Printing some Q and Qe and total Qs values:  [[1.047]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.676]] [[2.134]
 [3.388]
 [3.388]
 [3.388]
 [3.388]
 [3.388]
 [2.191]] [[2.   ]
 [1.565]
 [1.565]
 [1.565]
 [1.565]
 [1.565]
 [1.276]]
deleting a thread, now have 3 threads
Frames:  35358 train batches done:  4142 episodes:  768
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.04355891499278677, 0.31850634462040106, 0.3895042828630582, 0.24843045752375398]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.036261194086760234, 0.32099001918248865, 0.3801836433471254, 0.2625651433836257]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.0384894434298851, 0.3412090132421309, 0.3412090132421309, 0.27909253008585316]
in main func line 156:  501
using explorer policy with actor:  1
siam score:  -0.84913284
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
siam score:  -0.8437881
Printing some Q and Qe and total Qs values:  [[0.725]
 [0.713]
 [0.725]
 [0.718]
 [0.725]
 [0.725]
 [0.72 ]] [[3.047]
 [3.443]
 [3.047]
 [4.529]
 [3.047]
 [3.047]
 [3.224]] [[1.682]
 [1.883]
 [1.682]
 [2.467]
 [1.682]
 [1.682]
 [1.772]]
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
probs:  [0.04707314021208255, 0.3427597514189191, 0.3427597514189191, 0.2674073569500792]
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
probs:  [0.04707314021208255, 0.3427597514189191, 0.3427597514189191, 0.2674073569500792]
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.576]
 [0.592]
 [0.592]
 [0.529]
 [0.578]
 [0.582]] [[7.124]
 [6.8  ]
 [6.981]
 [7.114]
 [7.093]
 [7.299]
 [7.275]] [[1.959]
 [1.85 ]
 [1.964]
 [2.032]
 [1.926]
 [2.103]
 [2.097]]
Printing some Q and Qe and total Qs values:  [[0.763]
 [0.756]
 [0.797]
 [0.802]
 [0.797]
 [0.798]
 [0.78 ]] [[6.784]
 [6.78 ]
 [6.109]
 [6.529]
 [6.109]
 [6.313]
 [6.549]] [[1.936]
 [1.931]
 [1.708]
 [1.865]
 [1.708]
 [1.783]
 [1.86 ]]
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
Printing some Q and Qe and total Qs values:  [[0.358]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.43 ]] [[5.681]
 [5.906]
 [5.906]
 [5.906]
 [5.906]
 [5.906]
 [5.817]] [[1.814]
 [2.026]
 [2.026]
 [2.026]
 [2.026]
 [2.026]
 [1.983]]
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
probs:  [0.05084433474128274, 0.37073167272160484, 0.28921199626855626, 0.28921199626855626]
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
probs:  [0.055225918375020076, 0.4032308169538535, 0.31454569763860357, 0.22699756703252288]
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
probs:  [0.055225918375020076, 0.4032308169538535, 0.31454569763860357, 0.22699756703252288]
siam score:  -0.83955324
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
probs:  [0.055225918375020076, 0.4032308169538535, 0.31454569763860357, 0.22699756703252288]
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
probs:  [0.055225918375020076, 0.4032308169538535, 0.31454569763860357, 0.22699756703252288]
maxi score, test score, baseline:  -0.99571589958159 -1.0 -0.99571589958159
probs:  [0.055225918375020076, 0.4032308169538535, 0.31454569763860357, 0.22699756703252288]
Printing some Q and Qe and total Qs values:  [[-0.038]
 [-0.04 ]
 [-0.04 ]
 [-0.04 ]
 [-0.04 ]
 [-0.04 ]
 [-0.024]] [[5.616]
 [5.557]
 [5.557]
 [5.557]
 [5.557]
 [5.557]
 [6.102]] [[1.149]
 [1.112]
 [1.112]
 [1.112]
 [1.112]
 [1.112]
 [1.445]]
siam score:  -0.8411893
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.055225895074935624, 0.40323083528427583, 0.31454570535995996, 0.2269975642808286]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.060526479871172566, 0.345192956340807, 0.345192956340807, 0.24908760744721342]
Printing some Q and Qe and total Qs values:  [[-0.103]
 [-0.087]
 [-0.102]
 [-0.088]
 [-0.092]
 [-0.085]
 [-0.093]] [[6.45 ]
 [5.509]
 [6.414]
 [6.763]
 [6.389]
 [6.168]
 [6.768]] [[1.249]
 [0.771]
 [1.231]
 [1.424]
 [1.226]
 [1.116]
 [1.423]]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.06688399592511499, 0.2755823829222267, 0.3819512382304315, 0.2755823829222267]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.06688399592511499, 0.2755823829222267, 0.3819512382304315, 0.2755823829222267]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.06688399592511499, 0.2755823829222267, 0.3819512382304315, 0.2755823829222267]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.06688399592511499, 0.2755823829222267, 0.3819512382304315, 0.2755823829222267]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
Printing some Q and Qe and total Qs values:  [[0.876]
 [0.9  ]
 [0.88 ]
 [0.876]
 [0.888]
 [0.881]
 [0.892]] [[4.887]
 [6.375]
 [4.648]
 [4.789]
 [4.822]
 [5.008]
 [5.141]] [[1.418]
 [2.238]
 [1.299]
 [1.367]
 [1.404]
 [1.491]
 [1.577]]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.08449023767242607, 0.21588083004514785, 0.4837481022372781, 0.21588083004514785]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.09717822482343524, 0.09717822482343524, 0.5571082958021053, 0.24853525455102415]
siam score:  -0.8521255
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.14035160973476624, 0.14035160973476624, 0.35964839026523376, 0.35964839026523376]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.14035160973476624, 0.14035160973476624, 0.35964839026523376, 0.35964839026523376]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.14035160973476624, 0.14035160973476624, 0.35964839026523376, 0.35964839026523376]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.21632973660481863, 0.08499479615653596, 0.3493377336193227, 0.3493377336193227]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.09775322944171184, 0.09775322944171184, 0.40224677055828817, 0.40224677055828817]
Printing some Q and Qe and total Qs values:  [[0.23 ]
 [0.267]
 [0.199]
 [0.201]
 [0.246]
 [0.197]
 [0.278]] [[4.733]
 [4.961]
 [4.662]
 [4.641]
 [4.896]
 [4.76 ]
 [4.628]] [[0.17 ]
 [0.32 ]
 [0.085]
 [0.081]
 [0.256]
 [0.113]
 [0.23 ]]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.08507093144178693, 0.08507093144178693, 0.34795279706249277, 0.48190534005393343]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.11574038287963434, 0.11574038287963434, 0.2940010509890297, 0.4745181832517016]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.1411399591420543, 0.1411399591420543, 0.3588600408579457, 0.3588600408579457]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
from probs:  [0.09851491968137516, 0.09851491968137516, 0.40148508031862484, 0.40148508031862484]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.17091349772611594, 0.06805252544352057, 0.38051698841518167, 0.38051698841518167]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.08578655048912563, 0.08578655048912563, 0.4808865793874717, 0.34754031963427706]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.09870533953416813, 0.09870533953416813, 0.5540032897210652, 0.2485860312105985]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.09870533953416813, 0.09870533953416813, 0.5540032897210652, 0.2485860312105985]
siam score:  -0.86997515
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.11652959569626509, 0.11652959569626509, 0.4731890993128839, 0.2937517092945859]
Printing some Q and Qe and total Qs values:  [[0.787]
 [1.058]
 [0.787]
 [0.787]
 [0.787]
 [0.787]
 [0.787]] [[7.051]
 [9.254]
 [7.051]
 [7.051]
 [7.051]
 [7.051]
 [7.051]] [[1.426]
 [2.211]
 [1.426]
 [1.426]
 [1.426]
 [1.426]
 [1.426]]
from probs:  [0.11652959569626509, 0.11652959569626509, 0.4731890993128839, 0.2937517092945859]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.18097901249217535, 0.18097901249217535, 0.18097901249217535, 0.457062962523474]
Printing some Q and Qe and total Qs values:  [[0.816]
 [0.867]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]] [[4.454]
 [5.32 ]
 [4.454]
 [4.454]
 [4.454]
 [4.454]
 [4.454]] [[1.156]
 [1.554]
 [1.156]
 [1.156]
 [1.156]
 [1.156]
 [1.156]]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.18097901249217535, 0.18097901249217535, 0.18097901249217535, 0.457062962523474]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.18097901249217535, 0.18097901249217535, 0.18097901249217535, 0.457062962523474]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.2495339108432952, 0.2495339108432952, 0.09945320238420274, 0.40147897592920684]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.2495339108432952, 0.2495339108432952, 0.09945320238420274, 0.40147897592920684]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.2495339108432952, 0.2495339108432952, 0.09945320238420274, 0.40147897592920684]
first move QE:  1.6691515134789974
from probs:  [0.2495339108432952, 0.2495339108432952, 0.09945320238420274, 0.40147897592920684]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.24953391074149742, 0.24953391074149742, 0.09945316950342202, 0.40147900901358313]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.24953391074149742, 0.24953391074149742, 0.09945316950342202, 0.40147900901358313]
line 256 mcts: sample exp_bonus 2.9958801277614047
first move QE:  1.669118453125309
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.24953391074149742, 0.24953391074149742, 0.09945316950342202, 0.40147900901358313]
Printing some Q and Qe and total Qs values:  [[-0.003]
 [ 0.002]
 [-0.001]
 [ 0.   ]
 [-0.001]
 [ 0.036]
 [ 0.056]] [[5.243]
 [5.335]
 [5.379]
 [5.37 ]
 [5.287]
 [5.372]
 [5.353]] [[0.824]
 [0.897]
 [0.924]
 [0.92 ]
 [0.858]
 [0.974]
 [0.988]]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.29427436752681346, 0.29427436752681346, 0.11717689741955954, 0.29427436752681346]
using another actor
Printing some Q and Qe and total Qs values:  [[0.474]
 [0.487]
 [0.465]
 [0.466]
 [0.47 ]
 [0.48 ]
 [0.486]] [[3.284]
 [4.231]
 [3.342]
 [3.587]
 [3.722]
 [3.073]
 [2.889]] [[0.474]
 [0.487]
 [0.465]
 [0.466]
 [0.47 ]
 [0.48 ]
 [0.486]]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
Printing some Q and Qe and total Qs values:  [[0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]] [[3.073]
 [3.073]
 [3.073]
 [3.073]
 [3.073]
 [3.073]
 [3.073]] [[0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.34825627438218765, 0.21671318051542268, 0.08677427072020202, 0.34825627438218765]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.34825627438218765, 0.21671318051542268, 0.08677427072020202, 0.34825627438218765]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.34825627438218765, 0.21671318051542268, 0.08677427072020202, 0.34825627438218765]
maxi score, test score, baseline:  -0.9958016393442624 -1.0 -0.9958016393442624
probs:  [0.24953792844288897, 0.24953792844288897, 0.09982674393887737, 0.40109739917534465]
maxi score, test score, baseline:  -0.9958183673469387 -1.0 -0.9958183673469387
probs:  [0.24953792834264396, 0.24953792834264396, 0.0998267113594839, 0.4010974319552281]
maxi score, test score, baseline:  -0.9958183673469387 -1.0 -0.9958183673469387
probs:  [0.24953792834264396, 0.24953792834264396, 0.0998267113594839, 0.4010974319552281]
maxi score, test score, baseline:  -0.9958183673469387 -1.0 -0.9958183673469387
probs:  [0.24953792834264396, 0.24953792834264396, 0.0998267113594839, 0.4010974319552281]
maxi score, test score, baseline:  -0.9958183673469387 -1.0 -0.9958183673469387
probs:  [0.24953792834264396, 0.24953792834264396, 0.0998267113594839, 0.4010974319552281]
maxi score, test score, baseline:  -0.9958183673469387 -1.0 -0.9958183673469387
probs:  [0.11730985112010599, 0.29350496684586785, 0.11730985112010599, 0.47187533091392014]
maxi score, test score, baseline:  -0.9958183673469387 -1.0 -0.9958183673469387
probs:  [0.11730985112010599, 0.29350496684586785, 0.11730985112010599, 0.47187533091392014]
maxi score, test score, baseline:  -0.9958183673469387 -1.0 -0.9958183673469387
probs:  [0.11730985112010599, 0.29350496684586785, 0.11730985112010599, 0.47187533091392014]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.21643825356724206, 0.08698580304088661, 0.21643825356724206, 0.4801376898246292]
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.21643825356724206, 0.08698580304088661, 0.21643825356724206, 0.4801376898246292]
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.21643825356724206, 0.08698580304088661, 0.21643825356724206, 0.4801376898246292]
Printing some Q and Qe and total Qs values:  [[0.534]
 [0.526]
 [0.52 ]
 [0.541]
 [0.535]
 [0.52 ]
 [0.535]] [[6.443]
 [6.62 ]
 [6.696]
 [6.478]
 [6.558]
 [6.696]
 [6.602]] [[1.569]
 [1.656]
 [1.691]
 [1.593]
 [1.631]
 [1.691]
 [1.654]]
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.21643825356724206, 0.08698580304088661, 0.21643825356724206, 0.4801376898246292]
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.069]
 [0.045]
 [0.049]
 [0.046]
 [0.069]
 [0.04 ]] [[4.762]
 [5.627]
 [5.   ]
 [4.838]
 [4.837]
 [5.093]
 [4.79 ]] [[0.768]
 [1.242]
 [0.902]
 [0.821]
 [0.818]
 [0.967]
 [0.789]]
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.24954189146253303, 0.10019850824811936, 0.24954189146253303, 0.4007177088268147]
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.24954189146253303, 0.10019850824811936, 0.24954189146253303, 0.4007177088268147]
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.24954189146253303, 0.10019850824811936, 0.24954189146253303, 0.4007177088268147]
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.24954189146253303, 0.10019850824811936, 0.24954189146253303, 0.4007177088268147]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.8455503963347537
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.45426733945504927, 0.18191088684831688, 0.18191088684831688, 0.18191088684831688]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.40033982502197757, 0.24954580113286287, 0.24954580113286287, 0.1005685727122967]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.47057649911992466, 0.29326076617121855, 0.11808136735442833, 0.11808136735442833]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.47057649911992466, 0.29326076617121855, 0.11808136735442833, 0.11808136735442833]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.5707923435521781, 0.14306921881594067, 0.14306921881594067, 0.14306921881594067]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.215]
 [0.215]
 [0.215]
 [0.248]
 [0.248]
 [0.215]
 [0.215]] [[5.19 ]
 [5.19 ]
 [5.19 ]
 [4.873]
 [4.801]
 [5.19 ]
 [5.19 ]] [[0.274]
 [0.274]
 [0.274]
 [0.235]
 [0.21 ]
 [0.274]
 [0.274]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.5707923435521781, 0.14306921881594067, 0.14306921881594067, 0.14306921881594067]
Printing some Q and Qe and total Qs values:  [[0.692]
 [0.705]
 [0.677]
 [0.666]
 [0.668]
 [0.662]
 [0.657]] [[6.11 ]
 [6.526]
 [6.732]
 [6.397]
 [6.466]
 [6.437]
 [6.377]] [[1.246]
 [1.41 ]
 [1.424]
 [1.291]
 [1.316]
 [1.295]
 [1.265]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [0.861]
 [0.88 ]
 [0.876]
 [0.88 ]
 [0.88 ]
 [0.849]] [[6.631]
 [6.344]
 [6.631]
 [6.926]
 [6.631]
 [6.631]
 [6.66 ]] [[2.415]
 [2.281]
 [2.415]
 [2.506]
 [2.415]
 [2.415]
 [2.362]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.05830280852959534, 0.3138990638234682, 0.3138990638234682, 0.3138990638234682]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
Printing some Q and Qe and total Qs values:  [[0.05]
 [0.05]
 [0.05]
 [0.05]
 [0.05]
 [0.05]
 [0.05]] [[3.631]
 [3.631]
 [3.631]
 [3.631]
 [3.631]
 [3.631]
 [3.631]] [[1.14]
 [1.14]
 [1.14]
 [1.14]
 [1.14]
 [1.14]
 [1.14]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.07030152970256502, 0.3794137481369502, 0.2751423610802424, 0.2751423610802424]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.07030152970256502, 0.3794137481369502, 0.2751423610802424, 0.2751423610802424]
siam score:  -0.85641694
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.07030152970256502, 0.3794137481369502, 0.2751423610802424, 0.2751423610802424]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.07030152970256502, 0.3794137481369502, 0.2751423610802424, 0.2751423610802424]
siam score:  -0.855748
Printing some Q and Qe and total Qs values:  [[0.216]
 [0.233]
 [0.294]
 [0.294]
 [0.241]
 [0.27 ]
 [0.272]] [[3.913]
 [3.327]
 [3.597]
 [3.597]
 [3.775]
 [3.765]
 [3.842]] [[0.829]
 [0.471]
 [0.774]
 [0.774]
 [0.785]
 [0.837]
 [0.893]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.07030152970256502, 0.3794137481369502, 0.2751423610802424, 0.2751423610802424]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.07030152970256502, 0.3794137481369502, 0.2751423610802424, 0.2751423610802424]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.07030152970256502, 0.3794137481369502, 0.2751423610802424, 0.2751423610802424]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.07030152970256502, 0.3794137481369502, 0.2751423610802424, 0.2751423610802424]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.07030152970256502, 0.3794137481369502, 0.2751423610802424, 0.2751423610802424]
from probs:  [0.07030152970256502, 0.3794137481369502, 0.2751423610802424, 0.2751423610802424]
maxi score, test score, baseline:  -0.9958677419354839 -1.0 -0.9958677419354839
probs:  [0.08851738472629547, 0.3471975217082489, 0.3471975217082489, 0.21708757185720673]
maxi score, test score, baseline:  -0.9958677419354839 -1.0 -0.9958677419354839
probs:  [0.14455492101367928, 0.3554450789863207, 0.3554450789863207, 0.14455492101367928]
maxi score, test score, baseline:  -0.9958677419354839 -1.0 -0.9958677419354839
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.1831157988751859, 0.1831157988751859, 0.4506526033744423, 0.1831157988751859]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.2495609238343573, 0.10203133217802896, 0.39884682015325656, 0.2495609238343573]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.27506348815791637, 0.07090998461707122, 0.37896303906709605, 0.27506348815791637]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.27506348815791637, 0.07090998461707122, 0.37896303906709605, 0.27506348815791637]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.27506348815791637, 0.07090998461707122, 0.37896303906709605, 0.27506348815791637]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.3467801828909443, 0.08920474505986167, 0.21723488915824976, 0.3467801828909443]
555 289
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.39847808155934517, 0.10239275762869042, 0.2495645804059822, 0.2495645804059822]
siam score:  -0.84553576
Printing some Q and Qe and total Qs values:  [[0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]] [[5.372]
 [5.372]
 [5.372]
 [5.372]
 [5.372]
 [5.372]
 [5.372]] [[1.717]
 [1.717]
 [1.717]
 [1.717]
 [1.717]
 [1.717]
 [1.717]]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.4673931617138917, 0.11997283277042188, 0.29266117274526454, 0.11997283277042188]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.4673931617138917, 0.11997283277042188, 0.29266117274526454, 0.11997283277042188]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.3547142947263706, 0.14528570527362938, 0.3547142947263706, 0.14528570527362938]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
first move QE:  1.7614046476368015
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.3547142947263706, 0.14528570527362938, 0.3547142947263706, 0.14528570527362938]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.3547142947263706, 0.14528570527362938, 0.3547142947263706, 0.14528570527362938]
Printing some Q and Qe and total Qs values:  [[-0.043]
 [-0.043]
 [-0.043]
 [-0.043]
 [-0.043]
 [-0.043]
 [-0.043]] [[4.814]
 [4.814]
 [4.814]
 [4.814]
 [4.814]
 [4.814]
 [4.814]] [[-0.438]
 [-0.438]
 [-0.438]
 [-0.438]
 [-0.438]
 [-0.438]
 [-0.438]]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.44889165531044734, 0.1837027815631842, 0.1837027815631842, 0.1837027815631842]
Printing some Q and Qe and total Qs values:  [[0.823]
 [0.842]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]] [[3.002]
 [2.871]
 [2.603]
 [2.603]
 [2.603]
 [2.603]
 [2.603]] [[1.937]
 [1.865]
 [1.609]
 [1.609]
 [1.609]
 [1.609]
 [1.609]]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.44889165531044734, 0.1837027815631842, 0.1837027815631842, 0.1837027815631842]
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.619]
 [0.563]
 [0.563]
 [0.563]
 [0.563]
 [0.563]] [[5.379]
 [5.562]
 [5.379]
 [5.379]
 [5.379]
 [5.379]
 [5.379]] [[2.004]
 [2.211]
 [2.004]
 [2.004]
 [2.004]
 [2.004]
 [2.004]]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.3067683490860322, 0.3067683490860322, 0.07969495274190348, 0.3067683490860322]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.3067683490860322, 0.3067683490860322, 0.07969495274190348, 0.3067683490860322]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.412861254644269
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.3067683490860322, 0.3067683490860322, 0.07969495274190348, 0.3067683490860322]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.3067683490860322, 0.3067683490860322, 0.07969495274190348, 0.3067683490860322]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.21738085027298432, 0.3463662880506657, 0.08988657362568424, 0.3463662880506657]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.21738085027298432, 0.3463662880506657, 0.08988657362568424, 0.3463662880506657]
Printing some Q and Qe and total Qs values:  [[0.461]
 [0.497]
 [0.449]
 [0.488]
 [0.451]
 [0.483]
 [0.479]] [[4.122]
 [5.148]
 [3.963]
 [4.183]
 [3.863]
 [4.194]
 [4.05 ]] [[0.461]
 [0.497]
 [0.449]
 [0.488]
 [0.451]
 [0.483]
 [0.479]]
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
maxi score, test score, baseline:  -0.9958839357429718 -1.0 -0.9958839357429718
probs:  [0.10293522615843559, 0.3970647738415644, 0.10293522615843559, 0.3970647738415644]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.12071481266749957, 0.4661447500840471, 0.12071481266749957, 0.29242562458095384]
UNIT TEST: sample policy line 217 mcts : [0.    0.918 0.    0.    0.    0.082 0.   ]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.12071481266749957, 0.4661447500840471, 0.12071481266749957, 0.29242562458095384]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.12071481266749957, 0.4661447500840471, 0.12071481266749957, 0.29242562458095384]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.12071481266749957, 0.4661447500840471, 0.12071481266749957, 0.29242562458095384]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.12071481266749957, 0.4661447500840471, 0.12071481266749957, 0.29242562458095384]
first move QE:  1.7780477780495534
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.1463636186836526, 0.3536363813163474, 0.3536363813163474, 0.1463636186836526]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.1463636186836526, 0.3536363813163474, 0.3536363813163474, 0.1463636186836526]
siam score:  -0.8591721
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.1463636186836526, 0.3536363813163474, 0.3536363813163474, 0.1463636186836526]
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
maxi score, test score, baseline:  -0.9959 -1.0 -0.9959
probs:  [0.1463636186836526, 0.3536363813163474, 0.3536363813163474, 0.1463636186836526]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.14636358530040366, 0.35363641469959634, 0.35363641469959634, 0.14636358530040366]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.21752545817854865, 0.34595584956281683, 0.34595584956281683, 0.0905628426958176]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.21752545817854865, 0.34595584956281683, 0.34595584956281683, 0.0905628426958176]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.21752545817854865, 0.34595584956281683, 0.34595584956281683, 0.0905628426958176]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.21752545817854865, 0.34595584956281683, 0.34595584956281683, 0.0905628426958176]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.21752545817854865, 0.34595584956281683, 0.34595584956281683, 0.0905628426958176]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.24957873658758267, 0.24957873658758267, 0.397020930933109, 0.10382159589172571]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.24957873658758267, 0.24957873658758267, 0.397020930933109, 0.10382159589172571]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.24957873658758267, 0.24957873658758267, 0.397020930933109, 0.10382159589172571]
Printing some Q and Qe and total Qs values:  [[0.532]
 [0.603]
 [0.54 ]
 [0.536]
 [0.537]
 [0.582]
 [0.577]] [[5.143]
 [5.726]
 [5.382]
 [5.659]
 [5.835]
 [5.975]
 [6.003]] [[1.465]
 [1.949]
 [1.625]
 [1.786]
 [1.895]
 [2.063]
 [2.071]]
Printing some Q and Qe and total Qs values:  [[0.577]
 [0.693]
 [0.598]
 [0.601]
 [0.608]
 [0.608]
 [0.592]] [[5.111]
 [5.318]
 [5.194]
 [5.163]
 [5.471]
 [5.471]
 [5.029]] [[1.522]
 [1.785]
 [1.592]
 [1.581]
 [1.737]
 [1.737]
 [1.505]]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
Printing some Q and Qe and total Qs values:  [[0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]] [[2.341]
 [2.341]
 [2.341]
 [2.341]
 [2.341]
 [2.341]
 [2.341]] [[0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.34575189847935445, 0.09089893674723348, 0.34575189847935445, 0.2175972662940576]
Starting evaluation
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
probs:  [0.3776296918117158, 0.07271233936051835, 0.274828984413883, 0.274828984413883]
Printing some Q and Qe and total Qs values:  [[0.198]
 [0.198]
 [0.198]
 [0.182]
 [0.198]
 [0.201]
 [0.198]] [[4.267]
 [4.267]
 [4.267]
 [3.59 ]
 [4.267]
 [3.702]
 [4.267]] [[0.198]
 [0.198]
 [0.198]
 [0.182]
 [0.198]
 [0.201]
 [0.198]]
maxi score, test score, baseline:  -0.9959317460317461 -1.0 -0.9959317460317461
maxi score, test score, baseline:  -0.9959474308300396 -1.0 -0.9959474308300396
probs:  [0.3776297121102707, 0.07271231116423234, 0.27482898836274855, 0.27482898836274855]
maxi score, test score, baseline:  -0.9959474308300396 -1.0 -0.9959474308300396
probs:  [0.3776297121102707, 0.07271231116423234, 0.27482898836274855, 0.27482898836274855]
maxi score, test score, baseline:  -0.9959474308300396 -1.0 -0.9959474308300396
probs:  [0.3776297121102707, 0.07271231116423234, 0.27482898836274855, 0.27482898836274855]
Printing some Q and Qe and total Qs values:  [[0.78 ]
 [0.771]
 [0.78 ]
 [0.78 ]
 [0.78 ]
 [0.78 ]
 [0.771]] [[4.519]
 [4.717]
 [4.519]
 [4.519]
 [4.519]
 [4.519]
 [5.239]] [[1.498]
 [1.591]
 [1.498]
 [1.498]
 [1.498]
 [1.498]
 [1.862]]
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.607]
 [0.609]
 [0.629]
 [0.635]
 [0.63 ]
 [0.634]] [[5.938]
 [6.176]
 [4.518]
 [5.831]
 [6.109]
 [5.825]
 [6.007]] [[0.631]
 [0.607]
 [0.609]
 [0.629]
 [0.635]
 [0.63 ]
 [0.634]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9960832061068703 -1.0 -0.9960832061068703
probs:  [0.3776298877846712, 0.0727120671386992, 0.27482902253831476, 0.27482902253831476]
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [0.921]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.883]] [[4.617]
 [5.296]
 [4.617]
 [4.617]
 [4.617]
 [4.617]
 [4.82 ]] [[1.242]
 [1.551]
 [1.242]
 [1.242]
 [1.242]
 [1.242]
 [1.315]]
Printing some Q and Qe and total Qs values:  [[0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]] [[5.381]
 [5.381]
 [5.381]
 [5.381]
 [5.381]
 [5.381]
 [5.381]] [[2.052]
 [2.052]
 [2.052]
 [2.052]
 [2.052]
 [2.052]
 [2.052]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9961121212121212 -1.0 -0.9961121212121212
probs:  [0.3776299251875954, 0.0727120151830992, 0.27482902981465274, 0.27482902981465274]
siam score:  -0.8606853
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.696]
 [0.614]
 [0.687]
 [0.614]
 [0.614]
 [0.643]] [[6.656]
 [4.84 ]
 [6.656]
 [4.369]
 [6.656]
 [6.656]
 [5.122]] [[0.614]
 [0.696]
 [0.614]
 [0.687]
 [0.614]
 [0.614]
 [0.643]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]] [[4.911]
 [4.911]
 [4.911]
 [4.911]
 [4.911]
 [4.911]
 [4.911]] [[0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]
 [0.632]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9961546816479401 -1.0 -0.9961546816479401
siam score:  -0.864626
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
siam score:  -0.86623794
Printing some Q and Qe and total Qs values:  [[0.695]
 [0.857]
 [0.845]
 [0.814]
 [0.646]
 [0.835]
 [0.849]] [[3.601]
 [3.138]
 [3.376]
 [3.685]
 [3.405]
 [3.527]
 [3.562]] [[2.108]
 [2.014]
 [2.159]
 [2.328]
 [1.909]
 [2.248]
 [2.291]]
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.42042868222255675, 0.08086123308746851, 0.1927641424615332, 0.3059459422284415]
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.42042868222255675, 0.08086123308746851, 0.1927641424615332, 0.3059459422284415]
Printing some Q and Qe and total Qs values:  [[0.516]
 [0.516]
 [0.544]
 [0.539]
 [0.516]
 [0.516]
 [0.472]] [[5.081]
 [5.081]
 [4.086]
 [4.48 ]
 [5.081]
 [5.081]
 [4.037]] [[0.516]
 [0.516]
 [0.544]
 [0.539]
 [0.516]
 [0.516]
 [0.472]]
maxi score, test score, baseline:  -0.9962235294117647 -1.0 -0.9962235294117647
probs:  [0.42042870830933055, 0.08086120719813879, 0.19276413370068848, 0.3059459507918421]
siam score:  -0.865864
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.579]
 [0.602]
 [0.599]
 [0.602]
 [0.602]
 [0.599]] [[4.777]
 [5.171]
 [4.867]
 [4.711]
 [4.378]
 [4.702]
 [4.789]] [[0.582]
 [0.579]
 [0.602]
 [0.599]
 [0.602]
 [0.602]
 [0.599]]
Printing some Q and Qe and total Qs values:  [[0.589]
 [0.598]
 [0.598]
 [0.606]
 [0.612]
 [0.613]
 [0.625]] [[4.912]
 [5.313]
 [4.695]
 [4.359]
 [4.306]
 [4.378]
 [4.41 ]] [[0.589]
 [0.598]
 [0.598]
 [0.606]
 [0.612]
 [0.613]
 [0.625]]
Printing some Q and Qe and total Qs values:  [[0.589]
 [0.589]
 [0.589]
 [0.586]
 [0.589]
 [0.589]
 [0.589]] [[4.888]
 [4.888]
 [4.888]
 [4.527]
 [4.888]
 [4.888]
 [4.56 ]] [[1.622]
 [1.622]
 [1.622]
 [1.366]
 [1.622]
 [1.622]
 [1.393]]
maxi score, test score, baseline:  -0.9962369963369964 -1.0 -0.9962369963369964
probs:  [0.42042873420394306, 0.08086118149951338, 0.19276412500438028, 0.3059459592921632]
rdn probs:  [0.4742011975785059, 0.0911001221045542, 0.21734934015846996, 0.21734934015846996]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.474201235728342, 0.09110009506632115, 0.2173493346026684, 0.2173493346026684]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.115]
 [0.115]
 [0.115]
 [0.115]
 [0.115]
 [0.115]
 [0.115]] [[2.118]
 [2.118]
 [2.118]
 [2.118]
 [2.118]
 [2.118]
 [2.118]] [[0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.5587732506544776, 0.1470755831151741, 0.1470755831151741, 0.1470755831151741]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.5587732506544776, 0.1470755831151741, 0.1470755831151741, 0.1470755831151741]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.44 ]
 [0.409]
 [0.44 ]
 [0.44 ]
 [0.44 ]
 [0.44 ]
 [0.444]] [[5.179]
 [5.323]
 [5.179]
 [5.179]
 [5.179]
 [5.179]
 [5.319]] [[0.226]
 [0.212]
 [0.226]
 [0.226]
 [0.226]
 [0.226]
 [0.282]]
Printing some Q and Qe and total Qs values:  [[0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]] [[5.555]
 [5.555]
 [5.555]
 [5.555]
 [5.555]
 [5.555]
 [5.555]] [[1.467]
 [1.467]
 [1.467]
 [1.467]
 [1.467]
 [1.467]
 [1.467]]
from probs:  [0.47372013560103654, 0.09143407927231413, 0.21742289256332467, 0.21742289256332467]
Printing some Q and Qe and total Qs values:  [[0.137]
 [0.137]
 [0.137]
 [0.137]
 [0.137]
 [0.137]
 [0.137]] [[3.761]
 [3.761]
 [3.761]
 [3.761]
 [3.761]
 [3.761]
 [3.761]] [[0.384]
 [0.384]
 [0.384]
 [0.384]
 [0.384]
 [0.384]
 [0.384]]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.4355935466072049, 0.06649177414119009, 0.24895733962580255, 0.24895733962580255]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.4355935466072049, 0.06649177414119009, 0.24895733962580255, 0.24895733962580255]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.4139543155918203, 0.052335451295841565, 0.26685511655616906, 0.26685511655616906]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.44628171900558955, 0.05635443006267777, 0.20969662234359876, 0.28766722858813387]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.44628171900558955, 0.05635443006267777, 0.20969662234359876, 0.28766722858813387]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.44628171900558955, 0.05635443006267777, 0.20969662234359876, 0.28766722858813387]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.34196640437550646, 0.0668400181765116, 0.24922717307247555, 0.34196640437550646]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.34196640437550646, 0.0668400181765116, 0.24922717307247555, 0.34196640437550646]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.3419664159163773, 0.06683999519175159, 0.24922717297549388, 0.3419664159163773]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.37654297256969954, 0.07351699143289338, 0.1733970634277076, 0.37654297256969954]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.3056414297060741, 0.081804027886872, 0.19309748465731486, 0.419457057749739]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
line 256 mcts: sample exp_bonus 3.703837035367001
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.2175689533113585, 0.09209801858153277, 0.2175689533113585, 0.47276407479575017]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.24959543430259273, 0.10557004602570487, 0.24959543430259273, 0.3952390853691096]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.24959543430259273, 0.10557004602570487, 0.24959543430259273, 0.3952390853691096]
Printing some Q and Qe and total Qs values:  [[0.278]
 [0.246]
 [0.278]
 [0.273]
 [0.278]
 [0.278]
 [0.278]] [[4.229]
 [4.958]
 [4.229]
 [4.664]
 [4.229]
 [4.229]
 [4.229]] [[0.686]
 [1.205]
 [0.686]
 [1.011]
 [0.686]
 [0.686]
 [0.686]]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.2921731706358763, 0.12348048809237125, 0.2921731706358763, 0.2921731706358763]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.2921731706358763, 0.12348048809237125, 0.2921731706358763, 0.2921731706358763]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.2921731706358763, 0.12348048809237125, 0.2921731706358763, 0.2921731706358763]
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.2921731706358763, 0.12348048809237125, 0.2921731706358763, 0.2921731706358763]
UNIT TEST: sample policy line 217 mcts : [0.143 0.224 0.102 0.163 0.204 0.082 0.082]
Printing some Q and Qe and total Qs values:  [[0.397]
 [0.392]
 [0.411]
 [0.411]
 [0.407]
 [0.404]
 [0.407]] [[5.055]
 [5.276]
 [5.157]
 [5.158]
 [5.196]
 [5.292]
 [5.249]] [[0.413]
 [0.477]
 [0.474]
 [0.476]
 [0.48 ]
 [0.505]
 [0.498]]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2921731901112471, 0.12348042966625891, 0.2921731901112471, 0.2921731901112471]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2921731901112471, 0.12348042966625891, 0.2921731901112471, 0.2921731901112471]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2921731901112471, 0.12348042966625891, 0.2921731901112471, 0.2921731901112471]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2921731901112471, 0.12348042966625891, 0.2921731901112471, 0.2921731901112471]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2921731901112471, 0.12348042966625891, 0.2921731901112471, 0.2921731901112471]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.14845523330737537, 0.14845523330737537, 0.35154476669262463, 0.35154476669262463]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.14845523330737537, 0.14845523330737537, 0.35154476669262463, 0.35154476669262463]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.10591501415882583, 0.24959864906450913, 0.394887687712156, 0.24959864906450913]
Printing some Q and Qe and total Qs values:  [[0.366]
 [0.405]
 [0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.382]] [[4.402]
 [4.526]
 [4.402]
 [4.402]
 [4.402]
 [4.402]
 [4.478]] [[0.967]
 [1.128]
 [0.967]
 [0.967]
 [0.967]
 [0.967]
 [1.051]]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.10591501415882583, 0.24959864906450913, 0.394887687712156, 0.24959864906450913]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.10591501415882583, 0.24959864906450913, 0.394887687712156, 0.24959864906450913]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.10591501415882583, 0.24959864906450913, 0.394887687712156, 0.24959864906450913]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.10591501415882583, 0.24959864906450913, 0.394887687712156, 0.24959864906450913]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.10591501415882583, 0.24959864906450913, 0.394887687712156, 0.24959864906450913]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.10591501415882583, 0.24959864906450913, 0.394887687712156, 0.24959864906450913]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.14879601596211636, 0.14879601596211636, 0.3512039840378836, 0.3512039840378836]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2180212247305624, 0.09288688671971823, 0.34454594427485974, 0.34454594427485974]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2496018239925307, 0.10625846130392438, 0.2496018239925307, 0.39453789071101425]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2496018239925307, 0.10625846130392438, 0.2496018239925307, 0.39453789071101425]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2496018239925307, 0.10625846130392438, 0.2496018239925307, 0.39453789071101425]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2496018239925307, 0.10625846130392438, 0.2496018239925307, 0.39453789071101425]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2496018239925307, 0.10625846130392438, 0.2496018239925307, 0.39453789071101425]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.2496018239925307, 0.10625846130392438, 0.2496018239925307, 0.39453789071101425]
Printing some Q and Qe and total Qs values:  [[0.61 ]
 [0.621]
 [0.61 ]
 [0.649]
 [0.61 ]
 [0.61 ]
 [0.609]] [[4.421]
 [4.304]
 [4.421]
 [3.957]
 [4.421]
 [4.421]
 [4.227]] [[1.47 ]
 [1.402]
 [1.47 ]
 [1.195]
 [1.47 ]
 [1.47 ]
 [1.331]]
siam score:  -0.83809876
Printing some Q and Qe and total Qs values:  [[0.804]
 [0.824]
 [0.804]
 [0.804]
 [0.804]
 [0.804]
 [0.804]] [[3.947]
 [4.79 ]
 [3.947]
 [3.947]
 [3.947]
 [3.947]
 [3.947]] [[1.338]
 [1.661]
 [1.338]
 [1.338]
 [1.338]
 [1.338]
 [1.338]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.4397245630977733, 0.1867584789674089, 0.1867584789674089, 0.1867584789674089]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.4397245630977733, 0.1867584789674089, 0.1867584789674089, 0.1867584789674089]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.4397245630977733, 0.1867584789674089, 0.1867584789674089, 0.1867584789674089]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]] [[5.243]
 [5.243]
 [5.243]
 [5.243]
 [5.243]
 [5.243]
 [5.243]] [[1.991]
 [1.991]
 [1.991]
 [1.991]
 [1.991]
 [1.991]
 [1.991]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.756]
 [0.734]
 [0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.681]] [[3.408]
 [3.566]
 [3.408]
 [3.408]
 [3.408]
 [3.408]
 [3.827]] [[1.991]
 [2.089]
 [1.991]
 [1.991]
 [1.991]
 [1.991]
 [2.234]]
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.291822214335226, 0.1245333569943221, 0.291822214335226, 0.291822214335226]
siam score:  -0.8489516
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.291822214335226, 0.1245333569943221, 0.291822214335226, 0.291822214335226]
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.291822214335226, 0.1245333569943221, 0.291822214335226, 0.291822214335226]
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.291822214335226, 0.1245333569943221, 0.291822214335226, 0.291822214335226]
using explorer policy with actor:  1
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.3755],
        [-0.4231],
        [-0.5062],
        [-0.3801],
        [-0.3636],
        [-0.4856],
        [-0.4711],
        [-0.4912],
        [-0.5051],
        [-0.5405]], dtype=torch.float64)
-0.0727797758985 -0.4482644159591181
-0.024259925299500003 -0.44739672759667715
-0.024259925299500003 -0.5304979621163445
-0.0727797758985 -0.45284539111110145
-0.0727797758985 -0.436386368737268
-0.024259925299500003 -0.5098927973796868
-0.024259925299500003 -0.4953792398024573
-0.024259925299500003 -0.5154502953741374
-0.024259925299500003 -0.5294011182475876
-0.024259925299500003 -0.5647323937479887
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.18702270203212398, 0.18702270203212398, 0.43893189390362797, 0.18702270203212398]
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.18702270203212398, 0.18702270203212398, 0.43893189390362797, 0.18702270203212398]
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.18702270203212398, 0.18702270203212398, 0.43893189390362797, 0.18702270203212398]
Printing some Q and Qe and total Qs values:  [[0.596]
 [0.624]
 [0.613]
 [0.612]
 [0.624]
 [0.616]
 [0.608]] [[6.228]
 [5.776]
 [6.112]
 [6.121]
 [5.776]
 [6.191]
 [6.466]] [[1.563]
 [1.307]
 [1.51 ]
 [1.515]
 [1.307]
 [1.566]
 [1.734]]
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.18702270203212398, 0.18702270203212398, 0.43893189390362797, 0.18702270203212398]
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.8461393
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.273]
 [0.273]
 [0.273]
 [0.273]
 [0.273]
 [0.273]
 [0.273]] [[1.63]
 [1.63]
 [1.63]
 [1.63]
 [1.63]
 [1.63]
 [1.63]] [[0.273]
 [0.273]
 [0.273]
 [0.273]
 [0.273]
 [0.273]
 [0.273]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.29170648522038756, 0.29170648522038756, 0.12488054433883747, 0.29170648522038756]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.2476],
        [-0.3026],
        [-0.0000],
        [-0.4663],
        [-0.3300],
        [-0.4781],
        [-0.4281],
        [-0.5678],
        [-0.0000],
        [-0.4782]], dtype=torch.float64)
-0.0632698753995 -0.3108258885676768
-0.0337698257985 -0.33637424479721434
-0.45044999999999963 -0.45044999999999963
-0.024259925299500003 -0.4905864744088715
-0.0727797758985 -0.4028144268806127
-0.024259925299500003 -0.5023532206428309
-0.024259925299500003 -0.45232601287724405
-0.024259925299500003 -0.5920896672562662
-0.7276499999999999 -0.7276499999999999
-0.024259925299500003 -0.5024578232843454
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.29170648522038756, 0.29170648522038756, 0.12488054433883747, 0.29170648522038756]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
start point for exploration sampling:  10723
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.1872847550482551, 0.43814573485523456, 0.1872847550482551, 0.1872847550482551]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.1872847550482551, 0.43814573485523456, 0.1872847550482551, 0.1872847550482551]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.1872847550482551, 0.43814573485523456, 0.1872847550482551, 0.1872847550482551]
siam score:  -0.83963203
in main func line 156:  611
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.24961111518045773, 0.39349849841052115, 0.10727927122856344, 0.24961111518045773]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.24961111518045773, 0.39349849841052115, 0.10727927122856344, 0.24961111518045773]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
using another actor
Printing some Q and Qe and total Qs values:  [[0.162]
 [0.162]
 [0.162]
 [0.162]
 [0.162]
 [0.162]
 [0.18 ]] [[3.576]
 [3.958]
 [3.958]
 [3.958]
 [3.958]
 [3.958]
 [3.507]] [[0.681]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.659]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2179989243244018, 0.4699439010719746, 0.09405825027922196, 0.2179989243244018]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2490146673810506, 0.4332718671245139, 0.06869879811338496, 0.2490146673810506]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2490146673810506, 0.4332718671245139, 0.06869879811338496, 0.2490146673810506]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.2490146673810506, 0.4332718671245139, 0.06869879811338496, 0.2490146673810506]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9963788732394366 -1.0 -0.9963788732394366
probs:  [0.24901466725734867, 0.43327189013325823, 0.06869877535204459, 0.24901466725734867]
in main func line 156:  617
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.27444541752472223, 0.3754684689528476, 0.0756406959977079, 0.27444541752472223]
maxi score, test score, baseline:  -0.9964034965034965 -1.0 -0.9964034965034965
maxi score, test score, baseline:  -0.9964034965034965 -1.0 -0.9964034965034965
probs:  [0.27444542086089607, 0.37546848607609573, 0.07564067220211215, 0.27444542086089607]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.6337606870132768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964034965034965 -1.0 -0.9964034965034965
probs:  [0.27444542086089607, 0.37546848607609573, 0.07564067220211215, 0.27444542086089607]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.3435630198747811, 0.3435630198747811, 0.09450796875908439, 0.21836599149135336]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.3435630198747811, 0.3435630198747811, 0.09450796875908439, 0.21836599149135336]
Printing some Q and Qe and total Qs values:  [[0.283]
 [0.273]
 [0.287]
 [0.287]
 [0.293]
 [0.295]
 [0.285]] [[1.585]
 [2.909]
 [1.803]
 [1.722]
 [1.922]
 [1.666]
 [1.625]] [[0.283]
 [0.273]
 [0.287]
 [0.287]
 [0.293]
 [0.295]
 [0.285]]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.39281363963927957, 0.2496171216095463, 0.10795211714162797, 0.2496171216095463]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.3928136671773155, 0.2496171215357166, 0.10795208975125137, 0.2496171215357166]
using another actor
from probs:  [0.3928136671773155, 0.2496171215357166, 0.10795208975125137, 0.2496171215357166]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.4577832946761931, 0.29084247360444826, 0.12568711585967934, 0.12568711585967934]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964397923875432 -1.0 -0.9964397923875432
probs:  [0.45778334106062785, 0.29084248272190555, 0.12568708810873327, 0.12568708810873327]
Printing some Q and Qe and total Qs values:  [[0.856]
 [0.744]
 [0.856]
 [0.856]
 [0.856]
 [0.856]
 [0.856]] [[4.012]
 [5.522]
 [4.012]
 [4.012]
 [4.012]
 [4.012]
 [4.012]] [[1.678]
 [2.168]
 [1.678]
 [1.678]
 [1.678]
 [1.678]
 [1.678]]
maxi score, test score, baseline:  -0.9964397923875432 -1.0 -0.9964397923875432
probs:  [0.5485818411147251, 0.150472719628425, 0.150472719628425, 0.150472719628425]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9964397923875432 -1.0 -0.9964397923875432
probs:  [0.46901954815136887, 0.09470129525596069, 0.21813957829633523, 0.21813957829633523]
maxi score, test score, baseline:  -0.9964397923875432 -1.0 -0.9964397923875432
probs:  [0.3924735961047028, 0.1082862630745201, 0.2496200704103886, 0.2496200704103886]
maxi score, test score, baseline:  -0.9964397923875432 -1.0 -0.9964397923875432
probs:  [0.3924735961047028, 0.1082862630745201, 0.2496200704103886, 0.2496200704103886]
maxi score, test score, baseline:  -0.9964397923875432 -1.0 -0.9964397923875432
line 256 mcts: sample exp_bonus 4.537061359350912
Printing some Q and Qe and total Qs values:  [[0.136]
 [0.09 ]
 [0.132]
 [0.132]
 [0.132]
 [0.133]
 [0.132]] [[1.353]
 [2.623]
 [1.521]
 [1.275]
 [1.391]
 [1.421]
 [1.484]] [[0.136]
 [0.09 ]
 [0.132]
 [0.132]
 [0.132]
 [0.133]
 [0.132]]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.4572100104911088, 0.12602819885147287, 0.12602819885147287, 0.2907335918059454]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.4572100104911088, 0.12602819885147287, 0.12602819885147287, 0.2907335918059454]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.547598501109982, 0.15080049963000597, 0.15080049963000597, 0.15080049963000597]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.547598501109982, 0.15080049963000597, 0.15080049963000597, 0.15080049963000597]
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.5475985802367791, 0.15080047325440699, 0.15080047325440699, 0.15080047325440699]
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.5475985802367791, 0.15080047325440699, 0.15080047325440699, 0.15080047325440699]
Printing some Q and Qe and total Qs values:  [[0.129]
 [0.129]
 [0.129]
 [0.129]
 [0.129]
 [0.129]
 [0.129]] [[1.815]
 [1.815]
 [1.815]
 [1.815]
 [1.815]
 [1.815]
 [1.815]] [[0.129]
 [0.129]
 [0.129]
 [0.129]
 [0.129]
 [0.129]
 [0.129]]
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.5475985802367791, 0.15080047325440699, 0.15080047325440699, 0.15080047325440699]
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.5475985802367791, 0.15080047325440699, 0.15080047325440699, 0.15080047325440699]
first move QE:  1.8812844855535804
siam score:  -0.8476886
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.5475986588188574, 0.15080044706038087, 0.15080044706038087, 0.15080044706038087]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.5475986588188574, 0.15080044706038087, 0.15080044706038087, 0.15080044706038087]
UNIT TEST: sample policy line 217 mcts : [0.102 0.061 0.041 0.102 0.204 0.163 0.327]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.46856026904016923, 0.2182094154123391, 0.2182094154123391, 0.09502090013515259]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.34298268685127103, 0.34298268685127103, 0.21856923261365388, 0.09546539368380409]
line 256 mcts: sample exp_bonus 4.756237010694826
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.34298268685127103, 0.34298268685127103, 0.21856923261365388, 0.09546539368380409]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.2496258622067368, 0.39179822364653216, 0.2496258622067368, 0.1089500519399943]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.2496258622067368, 0.39179822364653216, 0.2496258622067368, 0.1089500519399943]
Printing some Q and Qe and total Qs values:  [[0.053]
 [0.047]
 [0.066]
 [0.068]
 [0.074]
 [0.063]
 [0.065]] [[5.838]
 [5.621]
 [5.597]
 [5.9  ]
 [6.   ]
 [5.959]
 [5.936]] [[-0.065]
 [-0.149]
 [-0.121]
 [-0.015]
 [ 0.032]
 [-0.004]
 [-0.008]]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.12670500230999468, 0.45607255797657975, 0.29051743740343083, 0.12670500230999468]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.08517719748046278, 0.41598660802027687, 0.3045499282793506, 0.19428626621990966]
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.579]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]] [[4.593]
 [5.493]
 [4.593]
 [4.593]
 [4.593]
 [4.593]
 [4.593]] [[0.707]
 [1.034]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.08517719748046278, 0.41598660802027687, 0.3045499282793506, 0.19428626621990966]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.08517719748046278, 0.41598660802027687, 0.3045499282793506, 0.19428626621990966]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.08517719748046278, 0.41598660802027687, 0.3045499282793506, 0.19428626621990966]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.08517719748046278, 0.41598660802027687, 0.3045499282793506, 0.19428626621990966]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.08517719748046278, 0.41598660802027687, 0.3045499282793506, 0.19428626621990966]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.08517719748046278, 0.41598660802027687, 0.3045499282793506, 0.19428626621990966]
Printing some Q and Qe and total Qs values:  [[0.174]
 [0.174]
 [0.174]
 [0.174]
 [0.174]
 [0.174]
 [0.174]] [[5.69]
 [5.69]
 [5.69]
 [5.69]
 [5.69]
 [5.69]
 [5.69]] [[0.989]
 [0.989]
 [0.989]
 [0.989]
 [0.989]
 [0.989]
 [0.989]]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.08517719748046278, 0.41598660802027687, 0.3045499282793506, 0.19428626621990966]
first move QE:  1.8929298485501826
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.067]
 [-0.071]
 [-0.067]
 [-0.056]
 [-0.067]
 [-0.067]
 [-0.067]] [[5.747]
 [5.392]
 [5.747]
 [6.077]
 [5.747]
 [5.747]
 [5.734]] [[1.268]
 [1.033]
 [1.268]
 [1.493]
 [1.268]
 [1.268]
 [1.259]]
siam score:  -0.8544469
Printing some Q and Qe and total Qs values:  [[0.805]
 [0.777]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[3.39 ]
 [4.018]
 [3.39 ]
 [3.39 ]
 [3.39 ]
 [3.39 ]
 [3.39 ]] [[1.561]
 [1.838]
 [1.561]
 [1.561]
 [1.561]
 [1.561]
 [1.561]]
Printing some Q and Qe and total Qs values:  [[-0.037]
 [-0.044]
 [-0.037]
 [-0.038]
 [-0.038]
 [-0.038]
 [-0.037]] [[4.188]
 [4.121]
 [4.406]
 [4.438]
 [4.43 ]
 [4.369]
 [4.388]] [[-0.099]
 [-0.157]
 [ 0.046]
 [ 0.067]
 [ 0.061]
 [ 0.021]
 [ 0.035]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.06998707119446887, 0.4314397552405182, 0.3396422481812027, 0.15893092538381026]
siam score:  -0.8572306
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.08547753901544466, 0.30445259894157567, 0.4156780262056393, 0.19439183583734032]
640 311
using another actor
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.10960801096125754, 0.39112895486046756, 0.24963151708913744, 0.24963151708913744]
siam score:  -0.8550262
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.12737479465663049, 0.4549470215179398, 0.12737479465663049, 0.2903033891687993]
Printing some Q and Qe and total Qs values:  [[0.164]
 [0.24 ]
 [0.298]
 [0.267]
 [0.21 ]
 [0.293]
 [0.245]] [[2.924]
 [3.909]
 [2.495]
 [3.11 ]
 [2.235]
 [2.333]
 [3.055]] [[0.164]
 [0.24 ]
 [0.298]
 [0.267]
 [0.21 ]
 [0.293]
 [0.245]]
Printing some Q and Qe and total Qs values:  [[0.943]
 [0.954]
 [0.924]
 [0.903]
 [0.907]
 [0.926]
 [0.911]] [[5.617]
 [4.882]
 [5.06 ]
 [4.859]
 [5.062]
 [4.988]
 [4.988]] [[2.897]
 [2.519]
 [2.567]
 [2.423]
 [2.54 ]
 [2.53 ]
 [2.506]]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.15240264449311855, 0.3475973555068815, 0.15240264449311855, 0.3475973555068815]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.15240264449311855, 0.3475973555068815, 0.15240264449311855, 0.3475973555068815]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.15240264449311855, 0.3475973555068815, 0.15240264449311855, 0.3475973555068815]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.15240264449311855, 0.3475973555068815, 0.15240264449311855, 0.3475973555068815]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.15240264449311855, 0.3475973555068815, 0.15240264449311855, 0.3475973555068815]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
Printing some Q and Qe and total Qs values:  [[0.411]
 [0.375]
 [0.42 ]
 [0.417]
 [0.418]
 [0.415]
 [0.413]] [[5.381]
 [6.038]
 [5.073]
 [5.22 ]
 [5.041]
 [5.243]
 [5.128]] [[0.411]
 [0.375]
 [0.42 ]
 [0.417]
 [0.418]
 [0.415]
 [0.413]]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.15240264449311855, 0.3475973555068815, 0.15240264449311855, 0.3475973555068815]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.15240264449311855, 0.3475973555068815, 0.15240264449311855, 0.3475973555068815]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.15240261826583656, 0.34759738173416344, 0.15240261826583656, 0.34759738173416344]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.1893069571289371, 0.1893069571289371, 0.1893069571289371, 0.43207912861318865]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.24963429441647128, 0.10993476150862123, 0.24963429441647128, 0.3907966496584362]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.24963429441647128, 0.10993476150862123, 0.24963429441647128, 0.3907966496584362]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.24963429441647128, 0.10993476150862123, 0.24963429441647128, 0.3907966496584362]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.453]
 [0.409]
 [0.44 ]
 [0.439]
 [0.453]
 [0.453]
 [0.439]] [[6.732]
 [6.718]
 [7.093]
 [7.272]
 [6.732]
 [6.732]
 [7.151]] [[0.851]
 [0.758]
 [0.945]
 [1.003]
 [0.851]
 [0.851]
 [0.963]]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.1277070379855648, 0.1277070379855648, 0.29019716490561126, 0.4543887591232592]
start point for exploration sampling:  10723
Printing some Q and Qe and total Qs values:  [[0.632]
 [0.558]
 [0.632]
 [0.669]
 [0.632]
 [0.749]
 [0.651]] [[4.312]
 [4.405]
 [4.312]
 [4.542]
 [4.312]
 [5.677]
 [4.395]] [[1.346]
 [1.323]
 [1.346]
 [1.477]
 [1.346]
 [2.035]
 [1.398]]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.15240845454849872, 0.15240845454849872, 0.15240845454849872, 0.5427746363545038]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.15240845454849872, 0.15240845454849872, 0.15240845454849872, 0.5427746363545038]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.15240845454849872, 0.15240845454849872, 0.15240845454849872, 0.5427746363545038]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.21855395221737056, 0.09660075167965733, 0.21855395221737056, 0.4662913438856015]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.1099399583910644, 0.1099399583910644, 0.24890862305239791, 0.5312114601654734]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.1099399583910644, 0.1099399583910644, 0.24890862305239791, 0.5312114601654734]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.1947060988366008, 0.08637232658340316, 0.3041625008540821, 0.414759073725914]
Printing some Q and Qe and total Qs values:  [[0.326]
 [0.326]
 [0.326]
 [0.326]
 [0.326]
 [0.326]
 [0.326]] [[6.009]
 [6.009]
 [6.009]
 [6.009]
 [6.009]
 [6.009]
 [6.009]] [[1.457]
 [1.457]
 [1.457]
 [1.457]
 [1.457]
 [1.457]
 [1.457]]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.1947060988366008, 0.08637232658340316, 0.3041625008540821, 0.414759073725914]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.66 ]
 [0.751]
 [0.741]
 [0.761]
 [0.764]
 [0.765]] [[6.983]
 [7.514]
 [6.983]
 [7.385]
 [7.359]
 [7.321]
 [7.288]] [[1.529]
 [1.705]
 [1.529]
 [1.722]
 [1.729]
 [1.713]
 [1.697]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.21890217155138522, 0.09703656971214722, 0.34203062936823375, 0.34203062936823375]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
651 316
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.24963975169910313, 0.1105839075525997, 0.24963975169910313, 0.390136589049194]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.24963975169910313, 0.1105839075525997, 0.24963975169910313, 0.390136589049194]
using explorer policy with actor:  1
from probs:  [0.24963975169910313, 0.1105839075525997, 0.24963975169910313, 0.390136589049194]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.28998627995244425, 0.12836634213418377, 0.12836634213418377, 0.4532810357791882]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
Printing some Q and Qe and total Qs values:  [[-0.046]
 [-0.057]
 [-0.046]
 [-0.046]
 [-0.046]
 [-0.046]
 [-0.046]] [[6.273]
 [4.854]
 [6.273]
 [6.273]
 [6.273]
 [6.273]
 [6.273]] [[1.254]
 [0.361]
 [1.254]
 [1.254]
 [1.254]
 [1.254]
 [1.254]]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.28998627995244425, 0.12836634213418377, 0.12836634213418377, 0.4532810357791882]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.28998627995244425, 0.12836634213418377, 0.12836634213418377, 0.4532810357791882]
siam score:  -0.8445442
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.28998627995244425, 0.12836634213418377, 0.12836634213418377, 0.4532810357791882]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.30406643280586043, 0.19481004133279253, 0.08666851099720019, 0.41445501486414676]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.30406643280586043, 0.19481004133279253, 0.08666851099720019, 0.41445501486414676]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.30406643280586043, 0.19481004133279253, 0.08666851099720019, 0.41445501486414676]
siam score:  -0.83767056
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.30406643280586043, 0.19481004133279253, 0.08666851099720019, 0.41445501486414676]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.8115944172274636
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.30406643280586043, 0.19481004133279253, 0.08666851099720019, 0.41445501486414676]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.30406643280586043, 0.19481004133279253, 0.08666851099720019, 0.41445501486414676]
Printing some Q and Qe and total Qs values:  [[0.36]
 [0.36]
 [0.36]
 [0.36]
 [0.36]
 [0.36]
 [0.36]] [[4.739]
 [4.739]
 [4.739]
 [4.739]
 [4.739]
 [4.739]
 [4.739]] [[1.055]
 [1.055]
 [1.055]
 [1.055]
 [1.055]
 [1.055]
 [1.055]]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.31120025383206495, 0.22847430344680883, 0.0655419747692392, 0.3947834679518871]
line 256 mcts: sample exp_bonus 9.260175593803508
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.31120025383206495, 0.22847430344680883, 0.0655419747692392, 0.3947834679518871]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.032]
 [-0.044]
 [-0.032]
 [-0.032]
 [-0.032]
 [-0.032]
 [-0.014]] [[4.414]
 [3.726]
 [4.414]
 [4.414]
 [4.414]
 [4.414]
 [3.487]] [[ 0.56 ]
 [ 0.079]
 [ 0.56 ]
 [ 0.56 ]
 [ 0.56 ]
 [ 0.56 ]
 [-0.021]]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.339616450016096, 0.24931240575435348, 0.07145469421345442, 0.339616450016096]
maxi score, test score, baseline:  -0.9965329966329967 -1.0 -0.9965329966329967
probs:  [0.3730001389737653, 0.17559869394051245, 0.07840102811195694, 0.3730001389737653]
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.3730001725897943, 0.17559867360658188, 0.07840098121382952, 0.3730001725897943]
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.4141520573765792, 0.19491358803267883, 0.08696368180750735, 0.30397067278323464]
Printing some Q and Qe and total Qs values:  [[0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]] [[5.182]
 [5.182]
 [5.182]
 [5.182]
 [5.182]
 [5.182]
 [5.182]] [[1.797]
 [1.797]
 [1.797]
 [1.797]
 [1.797]
 [1.797]
 [1.797]]
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.46495215182305516, 0.21875695467688197, 0.09753393882318082, 0.21875695467688197]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.4521849385211783, 0.12901879825491272, 0.12901879825491272, 0.28977746496899637]
from probs:  [0.4521849385211783, 0.12901879825491272, 0.12901879825491272, 0.28977746496899637]
Printing some Q and Qe and total Qs values:  [[0.199]
 [0.266]
 [0.267]
 [0.267]
 [0.267]
 [0.267]
 [0.275]] [[5.319]
 [5.629]
 [5.689]
 [5.689]
 [5.689]
 [5.689]
 [6.837]] [[0.603]
 [0.839]
 [0.868]
 [0.868]
 [0.868]
 [0.868]
 [1.41 ]]
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.34603920851474007, 0.1539607914852599, 0.1539607914852599, 0.34603920851474007]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.69877292503777
maxi score, test score, baseline:  -0.9965666666666667 -1.0 -0.9965666666666667
probs:  [0.19050743274201226, 0.19050743274201226, 0.19050743274201226, 0.4284777017739632]
maxi score, test score, baseline:  -0.9965666666666667 -1.0 -0.9965666666666667
probs:  [0.2901487729607396, 0.12955368111778118, 0.2901487729607396, 0.2901487729607396]
Printing some Q and Qe and total Qs values:  [[0.203]
 [0.202]
 [0.202]
 [0.202]
 [0.202]
 [0.202]
 [0.202]] [[1.484]
 [1.569]
 [1.569]
 [1.569]
 [1.569]
 [1.569]
 [1.569]] [[0.203]
 [0.202]
 [0.202]
 [0.202]
 [0.202]
 [0.202]
 [0.202]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.8487938
maxi score, test score, baseline:  -0.9965666666666667 -1.0 -0.9965666666666667
probs:  [0.30411748712855025, 0.08764753861434917, 0.30411748712855025, 0.30411748712855025]
Printing some Q and Qe and total Qs values:  [[0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.709]] [[5.516]
 [5.516]
 [5.516]
 [5.516]
 [5.516]
 [5.516]
 [5.516]] [[1.508]
 [1.508]
 [1.508]
 [1.508]
 [1.508]
 [1.508]
 [1.508]]
Printing some Q and Qe and total Qs values:  [[0.619]
 [0.619]
 [0.619]
 [0.653]
 [0.619]
 [0.619]
 [0.619]] [[3.934]
 [3.934]
 [3.934]
 [3.642]
 [3.934]
 [3.934]
 [3.934]] [[2.059]
 [2.059]
 [2.059]
 [1.8  ]
 [2.059]
 [2.059]
 [2.059]]
Printing some Q and Qe and total Qs values:  [[0.557]
 [0.543]
 [0.59 ]
 [0.57 ]
 [0.59 ]
 [0.571]
 [0.589]] [[5.102]
 [5.462]
 [4.475]
 [4.635]
 [4.475]
 [5.153]
 [4.541]] [[0.944]
 [1.036]
 [0.8  ]
 [0.814]
 [0.8  ]
 [0.988]
 [0.82 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965777408637874 -1.0 -0.9965777408637874
probs:  [0.30411749535022936, 0.08764751394931199, 0.30411749535022936, 0.30411749535022936]
siam score:  -0.8505072
maxi score, test score, baseline:  -0.9965777408637874 -1.0 -0.9965777408637874
probs:  [0.34128247994312155, 0.0982716425819386, 0.34128247994312155, 0.2191633975318183]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.38829049552922185, 0.11170950447077818, 0.38829049552922185, 0.11170950447077818]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.38829049552922185, 0.11170950447077818, 0.38829049552922185, 0.11170950447077818]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.38829049552922185, 0.11170950447077818, 0.38829049552922185, 0.11170950447077818]
Printing some Q and Qe and total Qs values:  [[0.647]
 [0.577]
 [0.647]
 [0.647]
 [0.647]
 [0.647]
 [0.647]] [[3.886]
 [4.73 ]
 [3.886]
 [3.886]
 [3.886]
 [3.886]
 [3.886]] [[0.952]
 [1.345]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.45110023896765267, 0.12966453914448497, 0.28957068274337744, 0.12966453914448497]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.41324965443912687, 0.19522190418696153, 0.30368520418614203, 0.0878432371877697]
from probs:  [0.34109726229853304, 0.2192280150764156, 0.34109726229853304, 0.09857746032651836]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.3390803725308549, 0.2493302227629275, 0.3390803725308549, 0.07250903217536292]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
Printing some Q and Qe and total Qs values:  [[1.472]
 [1.472]
 [1.472]
 [1.472]
 [1.472]
 [1.472]
 [1.472]] [[1.915]
 [1.964]
 [1.964]
 [1.964]
 [1.94 ]
 [1.94 ]
 [1.94 ]] [[2.914]
 [2.963]
 [2.963]
 [2.963]
 [2.939]
 [2.939]
 [2.939]]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.34091276689974176, 0.34091276689974176, 0.2192923599323669, 0.0988821062681496]
in main func line 156:  672
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.3881920994050917, 0.24965538129824363, 0.24965538129824363, 0.11249713799842108]
Printing some Q and Qe and total Qs values:  [[0.91 ]
 [0.753]
 [0.945]
 [0.947]
 [1.066]
 [0.998]
 [0.94 ]] [[3.094]
 [3.307]
 [3.093]
 [3.128]
 [3.079]
 [3.203]
 [3.072]] [[1.454]
 [1.299]
 [1.517]
 [1.541]
 [1.725]
 [1.678]
 [1.494]]
from probs:  [0.45002671421587054, 0.28936589680372377, 0.13030369449020296, 0.13030369449020296]
Printing some Q and Qe and total Qs values:  [[-0.034]
 [-0.038]
 [-0.035]
 [-0.035]
 [-0.037]
 [-0.035]
 [-0.037]] [[5.113]
 [5.113]
 [4.543]
 [4.698]
 [4.802]
 [4.715]
 [4.753]] [[-0.397]
 [-0.405]
 [-0.589]
 [-0.537]
 [-0.506]
 [-0.531]
 [-0.522]]
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
maxi score, test score, baseline:  -0.9966213114754099 -1.0 -0.9966213114754099
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.13082759059232282, 0.28972413646922573, 0.28972413646922573, 0.28972413646922573]
siam score:  -0.84346664
maxi score, test score, baseline:  -0.996642671009772 -1.0 -0.996642671009772
probs:  [0.1308275641367978, 0.2897241452877341, 0.2897241452877341, 0.2897241452877341]
using another actor
from probs:  [0.19166241052320374, 0.19166241052320374, 0.42501276843038877, 0.19166241052320374]
maxi score, test score, baseline:  -0.996642671009772 -1.0 -0.996642671009772
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.362]
 [0.409]
 [0.362]
 [0.362]
 [0.362]
 [0.362]
 [0.362]] [[4.332]
 [5.324]
 [4.332]
 [4.332]
 [4.332]
 [4.332]
 [4.332]] [[0.362]
 [0.409]
 [0.362]
 [0.362]
 [0.362]
 [0.362]
 [0.362]]
maxi score, test score, baseline:  -0.996642671009772 -1.0 -0.996642671009772
probs:  [0.15576798631031843, 0.3442320136896816, 0.15576798631031843, 0.3442320136896816]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
Printing some Q and Qe and total Qs values:  [[0.44 ]
 [0.442]
 [0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.441]] [[6.454]
 [6.506]
 [6.526]
 [6.526]
 [6.526]
 [6.526]
 [6.546]] [[1.618]
 [1.647]
 [1.653]
 [1.653]
 [1.653]
 [1.653]
 [1.668]]
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.09978900371044867, 0.3403636170972651, 0.2194837620950211, 0.3403636170972651]
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.11328291792858808, 0.3867170820714119, 0.11328291792858808, 0.3867170820714119]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.15577371464591208, 0.5326788560622636, 0.15577371464591208, 0.15577371464591208]
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.15577371464591208, 0.5326788560622636, 0.15577371464591208, 0.15577371464591208]
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.21928527177521187, 0.46145909047065137, 0.21928527177521187, 0.09997036597892493]
Printing some Q and Qe and total Qs values:  [[0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]] [[5.2]
 [5.2]
 [5.2]
 [5.2]
 [5.2]
 [5.2]
 [5.2]] [[0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]]
Printing some Q and Qe and total Qs values:  [[0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]] [[5.477]
 [5.477]
 [5.477]
 [5.477]
 [5.477]
 [5.477]
 [5.477]] [[0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]]
siam score:  -0.8491785
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.249131754982825, 0.42799022852080465, 0.249131754982825, 0.07374626151354535]
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.249131754982825, 0.42799022852080465, 0.249131754982825, 0.07374626151354535]
686 336
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.2737413675366115, 0.3715558017874343, 0.2737413675366115, 0.08096146313934272]
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.2737413675366115, 0.3715558017874343, 0.2737413675366115, 0.08096146313934272]
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.2737413675366115, 0.3715558017874343, 0.2737413675366115, 0.08096146313934272]
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.2737413675366115, 0.3715558017874343, 0.2737413675366115, 0.08096146313934272]
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.2737413675366115, 0.3715558017874343, 0.2737413675366115, 0.08096146313934272]
Printing some Q and Qe and total Qs values:  [[0.515]
 [0.502]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.521]
 [0.523]] [[5.364]
 [5.979]
 [5.518]
 [5.2  ]
 [5.02 ]
 [5.185]
 [5.115]] [[0.515]
 [0.502]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.521]
 [0.523]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.2737413675366115, 0.3715558017874343, 0.2737413675366115, 0.08096146313934272]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.841]
 [0.841]
 [0.841]
 [0.841]
 [0.841]
 [0.841]
 [0.843]] [[2.048]
 [2.048]
 [2.048]
 [2.048]
 [2.048]
 [2.048]
 [2.07 ]] [[0.841]
 [0.841]
 [0.841]
 [0.841]
 [0.841]
 [0.841]
 [0.843]]
Printing some Q and Qe and total Qs values:  [[0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]
 [0.786]] [[4.649]
 [4.649]
 [4.649]
 [4.649]
 [4.649]
 [4.649]
 [4.649]] [[2.707]
 [2.707]
 [2.707]
 [2.707]
 [2.707]
 [2.707]
 [2.707]]
Printing some Q and Qe and total Qs values:  [[0.564]
 [0.813]
 [0.751]
 [0.772]
 [0.676]
 [0.751]
 [0.729]] [[4.754]
 [4.428]
 [4.383]
 [5.186]
 [4.062]
 [4.383]
 [4.536]] [[2.027]
 [2.307]
 [2.153]
 [2.73 ]
 [1.789]
 [2.153]
 [2.211]]
Printing some Q and Qe and total Qs values:  [[0.642]
 [0.617]
 [0.634]
 [0.642]
 [0.64 ]
 [0.642]
 [0.642]] [[5.389]
 [6.459]
 [6.234]
 [5.389]
 [5.994]
 [5.389]
 [5.389]] [[1.312]
 [1.772]
 [1.692]
 [1.312]
 [1.59 ]
 [1.312]
 [1.312]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
line 256 mcts: sample exp_bonus 6.305757325183131
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.30344343264155044, 0.30344343264155044, 0.30344343264155044, 0.08966970207534862]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.30344343264155044, 0.30344343264155044, 0.30344343264155044, 0.08966970207534862]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.30344343264155044, 0.30344343264155044, 0.30344343264155044, 0.08966970207534862]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.34000101953404616, 0.21961004535213813, 0.34000101953404616, 0.10038791557976946]
Printing some Q and Qe and total Qs values:  [[0.678]
 [0.701]
 [0.678]
 [0.66 ]
 [0.678]
 [0.671]
 [0.674]] [[7.334]
 [6.917]
 [7.334]
 [7.292]
 [7.334]
 [7.422]
 [7.441]] [[2.157]
 [1.967]
 [2.157]
 [2.117]
 [2.157]
 [2.194]
 [2.208]]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
Printing some Q and Qe and total Qs values:  [[0.082]
 [0.092]
 [0.082]
 [0.104]
 [0.082]
 [0.082]
 [0.082]] [[6.308]
 [6.02 ]
 [6.308]
 [5.782]
 [6.308]
 [6.308]
 [6.308]] [[0.988]
 [0.829]
 [0.988]
 [0.701]
 [0.988]
 [0.988]
 [0.988]]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.34000101953404616, 0.21961004535213813, 0.34000101953404616, 0.10038791557976946]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.34000101953404616, 0.21961004535213813, 0.34000101953404616, 0.10038791557976946]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.34000101953404616, 0.21961004535213813, 0.34000101953404616, 0.10038791557976946]
using explorer policy with actor:  1
siam score:  -0.85417634
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.34000101953404616, 0.21961004535213813, 0.34000101953404616, 0.10038791557976946]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.38609726044450166, 0.11390273955549836, 0.38609726044450166, 0.11390273955549836]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.4473909415429659, 0.13187325720528348, 0.2888625440464671, 0.13187325720528348]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.4473909415429659, 0.13187325720528348, 0.2888625440464671, 0.13187325720528348]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.4473909415429659, 0.13187325720528348, 0.2888625440464671, 0.13187325720528348]
siam score:  -0.8533418
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.46060308151885726, 0.10056793800944033, 0.2194144902358512, 0.2194144902358512]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.46060308151885726, 0.10056793800944033, 0.2194144902358512, 0.2194144902358512]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.46060308151885726, 0.10056793800944033, 0.2194144902358512, 0.2194144902358512]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.46060308151885726, 0.10056793800944033, 0.2194144902358512, 0.2194144902358512]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.5228746520022276, 0.11405880972979893, 0.11405880972979893, 0.24900772853817463]
siam score:  -0.8532623
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.5228746520022276, 0.11405880972979893, 0.11405880972979893, 0.24900772853817463]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.44687177698340047, 0.13218245742118345, 0.13218245742118345, 0.2887633081742327]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.5300415267362099, 0.15665282442126333, 0.15665282442126333, 0.15665282442126333]
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.625]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.678]] [[4.609]
 [4.894]
 [4.609]
 [4.609]
 [4.609]
 [4.609]
 [4.503]] [[1.238]
 [1.185]
 [1.238]
 [1.238]
 [1.238]
 [1.238]
 [1.16 ]]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.5300415267362099, 0.15665282442126333, 0.15665282442126333, 0.15665282442126333]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.5300415267362099, 0.15665282442126333, 0.15665282442126333, 0.15665282442126333]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.4601775729070909, 0.21947868693503314, 0.10086505322284288, 0.21947868693503314]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.4601775729070909, 0.21947868693503314, 0.10086505322284288, 0.21947868693503314]
Printing some Q and Qe and total Qs values:  [[0.329]
 [0.285]
 [0.329]
 [0.33 ]
 [0.277]
 [0.329]
 [0.299]] [[6.139]
 [5.92 ]
 [6.139]
 [5.911]
 [5.454]
 [6.139]
 [5.801]] [[1.532]
 [1.335]
 [1.532]
 [1.388]
 [1.025]
 [1.532]
 [1.277]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.4601775729070909, 0.21947868693503314, 0.10086505322284288, 0.21947868693503314]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.4601775729070909, 0.21947868693503314, 0.10086505322284288, 0.21947868693503314]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.4601775729070909, 0.21947868693503314, 0.10086505322284288, 0.21947868693503314]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.38598872203946394, 0.24967231633243403, 0.114666645295668, 0.24967231633243403]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.38598872203946394, 0.24967231633243403, 0.114666645295668, 0.24967231633243403]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.38598872203946394, 0.24967231633243403, 0.114666645295668, 0.24967231633243403]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.38598872203946394, 0.24967231633243403, 0.114666645295668, 0.24967231633243403]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.28910313867209786, 0.28910313867209786, 0.1326905839837065, 0.28910313867209786]
Printing some Q and Qe and total Qs values:  [[0.717]
 [0.856]
 [0.743]
 [0.738]
 [0.733]
 [0.739]
 [0.746]] [[2.771]
 [3.102]
 [1.943]
 [1.936]
 [2.031]
 [2.102]
 [2.238]] [[1.214]
 [1.515]
 [0.775]
 [0.767]
 [0.816]
 [0.86 ]
 [0.942]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.3031593557369811, 0.3031593557369811, 0.09052193278905667, 0.3031593557369811]
Printing some Q and Qe and total Qs values:  [[0.86 ]
 [0.852]
 [0.864]
 [0.852]
 [0.864]
 [0.865]
 [0.884]] [[2.569]
 [2.475]
 [2.491]
 [2.475]
 [2.555]
 [2.61 ]
 [2.537]] [[1.995]
 [1.857]
 [1.9  ]
 [1.857]
 [1.986]
 [2.061]
 [2.001]]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.24967462953909395, 0.3856794821982296, 0.11497125872358252, 0.24967462953909395]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.24967462953909395, 0.3856794821982296, 0.11497125872358252, 0.24967462953909395]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.24967462953909395, 0.3856794821982296, 0.11497125872358252, 0.24967462953909395]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.19320787434732906, 0.42037637695801283, 0.19320787434732906, 0.19320787434732906]
Printing some Q and Qe and total Qs values:  [[0.384]
 [0.46 ]
 [0.426]
 [0.437]
 [0.438]
 [0.432]
 [0.413]] [[5.086]
 [5.794]
 [5.555]
 [5.503]
 [5.281]
 [5.458]
 [5.601]] [[1.413]
 [2.021]
 [1.8  ]
 [1.787]
 [1.646]
 [1.748]
 [1.805]]
Printing some Q and Qe and total Qs values:  [[0.418]
 [0.33 ]
 [0.417]
 [0.417]
 [0.413]
 [0.414]
 [0.418]] [[1.119]
 [2.113]
 [1.131]
 [1.162]
 [1.258]
 [1.2  ]
 [1.185]] [[0.418]
 [0.33 ]
 [0.417]
 [0.417]
 [0.413]
 [0.414]
 [0.418]]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.24967691741586037, 0.38537160275417737, 0.24967691741586037, 0.11527456241410187]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 5.56699810910943
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.24967691741586037, 0.38537160275417737, 0.24967691741586037, 0.11527456241410187]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.2889002617653918, 0.2889002617653918, 0.2889002617653918, 0.13329921470382466]
Printing some Q and Qe and total Qs values:  [[0.454]
 [0.454]
 [0.454]
 [0.454]
 [0.454]
 [0.423]
 [0.437]] [[0.91 ]
 [0.91 ]
 [0.91 ]
 [0.91 ]
 [0.91 ]
 [1.065]
 [1.161]] [[0.454]
 [0.454]
 [0.454]
 [0.454]
 [0.454]
 [0.423]
 [0.437]]
Printing some Q and Qe and total Qs values:  [[0.786]
 [0.796]
 [0.786]
 [0.837]
 [0.786]
 [0.786]
 [0.786]] [[4.244]
 [4.205]
 [4.244]
 [5.099]
 [4.244]
 [4.244]
 [4.244]] [[1.937]
 [1.923]
 [1.937]
 [2.579]
 [1.937]
 [1.937]
 [1.937]]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.30297156084262833, 0.30297156084262833, 0.30297156084262833, 0.09108531747211511]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.30297156084262833, 0.30297156084262833, 0.30297156084262833, 0.09108531747211511]
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.556]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]] [[3.596]
 [3.968]
 [3.596]
 [3.596]
 [3.596]
 [3.596]
 [3.596]] [[1.132]
 [1.217]
 [1.132]
 [1.132]
 [1.132]
 [1.132]
 [1.132]]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.33910658837422425, 0.33910658837422425, 0.21992123086575094, 0.10186559238580044]
Printing some Q and Qe and total Qs values:  [[ 0.021]
 [ 0.268]
 [ 0.043]
 [ 0.042]
 [ 0.034]
 [ 0.032]
 [-0.001]] [[3.901]
 [3.637]
 [4.051]
 [4.057]
 [4.081]
 [3.952]
 [4.086]] [[-0.6  ]
 [-0.194]
 [-0.506]
 [-0.506]
 [-0.512]
 [-0.56 ]
 [-0.582]]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.33910658837422425, 0.33910658837422425, 0.21992123086575094, 0.10186559238580044]
705 343
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.13370533628657882, 0.13370533628657882, 0.4443151343059685, 0.2882741931208738]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.21979556985545676, 0.10233389707112245, 0.458074963217964, 0.21979556985545676]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.2490488131398119, 0.11588265271371524, 0.5191858814327577, 0.11588265271371524]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.2490488131398119, 0.11588265271371524, 0.5191858814327577, 0.11588265271371524]
709 348
from probs:  [0.28817775734434836, 0.13400537840353305, 0.44381148584858565, 0.13400537840353305]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
Printing some Q and Qe and total Qs values:  [[0.763]
 [0.714]
 [0.784]
 [0.75 ]
 [0.735]
 [0.763]
 [0.763]] [[4.103]
 [4.142]
 [4.053]
 [4.578]
 [3.81 ]
 [4.103]
 [4.103]] [[2.274]
 [2.221]
 [2.267]
 [2.67 ]
 [1.966]
 [2.274]
 [2.274]]
Printing some Q and Qe and total Qs values:  [[0.141]
 [0.168]
 [0.141]
 [0.152]
 [0.168]
 [0.203]
 [0.159]] [[3.829]
 [4.126]
 [4.415]
 [4.511]
 [4.126]
 [3.996]
 [4.232]] [[0.752]
 [1.004]
 [1.189]
 [1.274]
 [1.004]
 [0.946]
 [1.073]]
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
probs:  [0.15836423775000513, 0.15836423775000513, 0.5249072867499845, 0.15836423775000513]
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
probs:  [0.11618205833148956, 0.2490554027646943, 0.5185804805723266, 0.11618205833148956]
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
probs:  [0.11618205833148956, 0.2490554027646943, 0.5185804805723266, 0.11618205833148956]
siam score:  -0.8417917
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
probs:  [0.15891559954256257, 0.34108440045743743, 0.34108440045743743, 0.15891559954256257]
siam score:  -0.8451544
Printing some Q and Qe and total Qs values:  [[0.838]
 [0.849]
 [0.838]
 [0.838]
 [0.838]
 [0.838]
 [0.838]] [[3.852]
 [3.737]
 [3.852]
 [3.852]
 [3.852]
 [3.852]
 [3.852]] [[1.582]
 [1.523]
 [1.582]
 [1.582]
 [1.582]
 [1.582]
 [1.582]]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.15919165695530607, 0.34080834304469393, 0.15919165695530607, 0.34080834304469393]
Printing some Q and Qe and total Qs values:  [[0.435]
 [0.604]
 [0.384]
 [0.365]
 [0.161]
 [0.323]
 [0.3  ]] [[3.16 ]
 [3.726]
 [3.256]
 [3.264]
 [4.543]
 [3.219]
 [3.344]] [[0.454]
 [1.048]
 [0.449]
 [0.43 ]
 [1.003]
 [0.344]
 [0.397]]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.15919165695530607, 0.34080834304469393, 0.15919165695530607, 0.34080834304469393]
Printing some Q and Qe and total Qs values:  [[0.557]
 [0.503]
 [0.555]
 [0.56 ]
 [0.582]
 [0.548]
 [0.549]] [[4.716]
 [5.72 ]
 [4.892]
 [5.353]
 [6.209]
 [5.799]
 [5.118]] [[1.085]
 [1.559]
 [1.174]
 [1.415]
 [1.872]
 [1.635]
 [1.285]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.1643667660666974
Printing some Q and Qe and total Qs values:  [[0.156]
 [0.102]
 [0.19 ]
 [0.159]
 [0.159]
 [0.166]
 [0.164]] [[3.376]
 [3.085]
 [3.983]
 [3.538]
 [3.743]
 [3.592]
 [3.323]] [[ 0.196]
 [-0.106]
 [ 0.668]
 [ 0.309]
 [ 0.448]
 [ 0.36 ]
 [ 0.176]]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9967253968253968 -1.0 -0.9967253968253968
probs:  [0.28830365061922725, 0.28830365061922725, 0.1350890481423183, 0.28830365061922725]
maxi score, test score, baseline:  -0.9967253968253968 -1.0 -0.9967253968253968
probs:  [0.28830365061922725, 0.28830365061922725, 0.1350890481423183, 0.28830365061922725]
maxi score, test score, baseline:  -0.9967253968253968 -1.0 -0.9967253968253968
probs:  [0.28830365061922725, 0.28830365061922725, 0.1350890481423183, 0.28830365061922725]
maxi score, test score, baseline:  -0.9967253968253968 -1.0 -0.9967253968253968
probs:  [0.34053390141771955, 0.34053390141771955, 0.15946609858228047, 0.15946609858228047]
Printing some Q and Qe and total Qs values:  [[1.06 ]
 [1.013]
 [0.808]
 [1.055]
 [0.808]
 [0.808]
 [0.808]] [[3.09 ]
 [2.704]
 [4.144]
 [3.339]
 [4.144]
 [4.144]
 [4.144]] [[2.195]
 [1.953]
 [2.331]
 [2.303]
 [2.331]
 [2.331]
 [2.331]]
maxi score, test score, baseline:  -0.9967253968253968 -1.0 -0.9967253968253968
probs:  [0.34053390141771955, 0.34053390141771955, 0.15946609858228047, 0.15946609858228047]
maxi score, test score, baseline:  -0.9967253968253968 -1.0 -0.9967253968253968
maxi score, test score, baseline:  -0.9967253968253968 -1.0 -0.9967253968253968
probs:  [0.34053390141771955, 0.34053390141771955, 0.15946609858228047, 0.15946609858228047]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.34053392613291134, 0.34053392613291134, 0.15946607386708866, 0.15946607386708866]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.34053392613291134, 0.34053392613291134, 0.15946607386708866, 0.15946607386708866]
siam score:  -0.8419201
Printing some Q and Qe and total Qs values:  [[0.768]
 [0.845]
 [0.764]
 [0.817]
 [0.764]
 [0.764]
 [0.813]] [[3.835]
 [3.522]
 [3.798]
 [3.869]
 [3.798]
 [3.798]
 [3.886]] [[2.119]
 [2.072]
 [2.092]
 [2.22 ]
 [2.092]
 [2.092]
 [2.223]]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.34053392613291134, 0.34053392613291134, 0.15946607386708866, 0.15946607386708866]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.41597357851075706, 0.19467547382974762, 0.19467547382974762, 0.19467547382974762]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.41597357851075706, 0.19467547382974762, 0.19467547382974762, 0.19467547382974762]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.41597357851075706, 0.19467547382974762, 0.19467547382974762, 0.19467547382974762]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.3832539135091016, 0.2496922542413186, 0.11736157800826107, 0.2496922542413186]
Printing some Q and Qe and total Qs values:  [[0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]] [[5.245]
 [5.245]
 [5.245]
 [5.245]
 [5.245]
 [5.245]
 [5.245]] [[1.219]
 [1.219]
 [1.219]
 [1.219]
 [1.219]
 [1.219]
 [1.219]]
from probs:  [0.44182206144757397, 0.1351906810762438, 0.1351906810762438, 0.2877965763999385]
maxi score, test score, baseline:  -0.9967454258675079 -1.0 -0.9967454258675079
probs:  [0.44182210571057384, 0.1351906545839577, 0.1351906545839577, 0.28779658512151074]
maxi score, test score, baseline:  -0.9967454258675079 -1.0 -0.9967454258675079
probs:  [0.44182210571057384, 0.1351906545839577, 0.1351906545839577, 0.28779658512151074]
Printing some Q and Qe and total Qs values:  [[0.264]
 [0.275]
 [0.26 ]
 [0.265]
 [0.262]
 [0.263]
 [0.262]] [[1.325]
 [1.884]
 [1.331]
 [1.369]
 [1.508]
 [1.333]
 [1.159]] [[0.264]
 [0.275]
 [0.26 ]
 [0.265]
 [0.262]
 [0.263]
 [0.262]]
maxi score, test score, baseline:  -0.9967454258675079 -1.0 -0.9967454258675079
probs:  [0.44182210571057384, 0.1351906545839577, 0.1351906545839577, 0.28779658512151074]
Printing some Q and Qe and total Qs values:  [[0.087]
 [0.102]
 [0.132]
 [0.202]
 [0.162]
 [0.252]
 [0.092]] [[4.465]
 [3.922]
 [4.536]
 [4.552]
 [4.546]
 [4.619]
 [4.62 ]] [[ 0.288]
 [-0.042]
 [ 0.425]
 [ 0.577]
 [ 0.493]
 [ 0.722]
 [ 0.402]]
maxi score, test score, baseline:  -0.9967454258675079 -1.0 -0.9967454258675079
probs:  [0.34026108608505445, 0.15973891391494557, 0.15973891391494557, 0.34026108608505445]
maxi score, test score, baseline:  -0.9967454258675079 -1.0 -0.9967454258675079
probs:  [0.34026108608505445, 0.15973891391494557, 0.15973891391494557, 0.34026108608505445]
maxi score, test score, baseline:  -0.9967454258675079 -1.0 -0.9967454258675079
probs:  [0.34026108608505445, 0.15973891391494557, 0.15973891391494557, 0.34026108608505445]
Printing some Q and Qe and total Qs values:  [[0.36 ]
 [0.365]
 [0.369]
 [0.374]
 [0.371]
 [0.372]
 [0.378]] [[3.143]
 [3.483]
 [3.257]
 [3.236]
 [3.263]
 [3.208]
 [3.068]] [[0.36 ]
 [0.365]
 [0.369]
 [0.374]
 [0.371]
 [0.372]
 [0.378]]
maxi score, test score, baseline:  -0.9967454258675079 -1.0 -0.9967454258675079
probs:  [0.41536266270279093, 0.19487911243240302, 0.19487911243240302, 0.19487911243240302]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9967454258675079 -1.0 -0.9967454258675079
probs:  [0.41536266270279093, 0.19487911243240302, 0.19487911243240302, 0.19487911243240302]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.3829566480488247, 0.24969435253322192, 0.24969435253322192, 0.11765464688473157]
Printing some Q and Qe and total Qs values:  [[0.477]
 [0.823]
 [0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.477]] [[3.495]
 [3.823]
 [3.495]
 [3.495]
 [3.495]
 [3.495]
 [3.495]] [[0.843]
 [1.644]
 [0.843]
 [0.843]
 [0.843]
 [0.843]
 [0.843]]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.33998983372881264, 0.16001016627118733, 0.33998983372881264, 0.16001016627118733]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.19508129606363442, 0.19508129606363442, 0.4147561118090966, 0.19508129606363442]
maxi score, test score, baseline:  -0.9967553459119497 -1.0 -0.9967553459119497
probs:  [0.11794653212495337, 0.24969642880948206, 0.3826606102560825, 0.24969642880948206]
729 359
Printing some Q and Qe and total Qs values:  [[0.255]
 [0.239]
 [0.255]
 [0.268]
 [0.255]
 [0.255]
 [0.227]] [[4.071]
 [4.303]
 [4.071]
 [4.269]
 [4.071]
 [4.071]
 [4.27 ]] [[0.316]
 [0.438]
 [0.316]
 [0.474]
 [0.316]
 [0.316]
 [0.392]]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.1952820402500463, 0.1952820402500463, 0.1952820402500463, 0.4141538792498611]
Printing some Q and Qe and total Qs values:  [[0.512]
 [0.464]
 [0.511]
 [0.51 ]
 [0.509]
 [0.514]
 [0.499]] [[4.119]
 [4.943]
 [4.   ]
 [4.028]
 [3.933]
 [3.812]
 [3.899]] [[1.251]
 [1.719]
 [1.174]
 [1.19 ]
 [1.128]
 [1.056]
 [1.093]]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.38207237031172503, 0.2497005161670945, 0.2497005161670945, 0.1185265973540861]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.43987168829382295, 0.2874224853403794, 0.13635291318289883, 0.13635291318289883]
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.911]
 [0.722]
 [0.722]
 [0.722]
 [0.722]
 [0.722]] [[3.402]
 [4.442]
 [3.402]
 [3.402]
 [3.402]
 [3.402]
 [3.402]] [[1.285]
 [2.087]
 [1.285]
 [1.285]
 [1.285]
 [1.285]
 [1.285]]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.43987168829382295, 0.2874224853403794, 0.13635291318289883, 0.13635291318289883]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.43987168829382295, 0.2874224853403794, 0.13635291318289883, 0.13635291318289883]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]] [[4.422]
 [4.422]
 [4.422]
 [4.422]
 [4.422]
 [4.422]
 [4.422]] [[1.221]
 [1.221]
 [1.221]
 [1.221]
 [1.221]
 [1.221]
 [1.221]]
Starting evaluation
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.147]
 [0.147]
 [0.147]
 [0.147]
 [0.147]
 [0.147]
 [0.147]] [[1.659]
 [1.659]
 [1.659]
 [1.659]
 [1.659]
 [1.659]
 [1.659]] [[0.147]
 [0.147]
 [0.147]
 [0.147]
 [0.147]
 [0.147]
 [0.147]]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
Printing some Q and Qe and total Qs values:  [[0.144]
 [0.079]
 [0.131]
 [0.131]
 [0.13 ]
 [0.141]
 [0.139]] [[0.782]
 [1.897]
 [0.991]
 [1.011]
 [0.797]
 [0.966]
 [0.986]] [[0.144]
 [0.079]
 [0.131]
 [0.131]
 [0.13 ]
 [0.141]
 [0.139]]
Printing some Q and Qe and total Qs values:  [[0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]] [[2.086]
 [2.086]
 [2.086]
 [2.086]
 [2.086]
 [2.086]
 [2.086]] [[0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9968604863221885 -1.0 -0.9968604863221885
probs:  [0.33918565486029306, 0.33918565486029306, 0.160814345139707, 0.160814345139707]
maxi score, test score, baseline:  -0.9968604863221885 -1.0 -0.9968604863221885
probs:  [0.33918565486029306, 0.33918565486029306, 0.160814345139707, 0.160814345139707]
Printing some Q and Qe and total Qs values:  [[0.206]
 [0.107]
 [0.158]
 [0.153]
 [0.158]
 [0.156]
 [0.171]] [[-0.028]
 [ 1.73 ]
 [ 0.84 ]
 [ 1.017]
 [ 0.991]
 [ 1.082]
 [ 0.983]] [[0.206]
 [0.107]
 [0.158]
 [0.153]
 [0.158]
 [0.156]
 [0.171]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9968604863221885 -1.0 -0.9968604863221885
probs:  [0.33918565486029306, 0.33918565486029306, 0.160814345139707, 0.160814345139707]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.996869696969697 -1.0 -0.996869696969697
maxi score, test score, baseline:  -0.9968879518072289 -1.0 -0.9968879518072289
Printing some Q and Qe and total Qs values:  [[0.22 ]
 [0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.219]] [[0.937]
 [1.361]
 [1.361]
 [1.361]
 [1.361]
 [1.361]
 [1.361]] [[0.22 ]
 [0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.219]
 [0.219]]
734 365
Printing some Q and Qe and total Qs values:  [[0.793]
 [0.816]
 [0.793]
 [0.824]
 [0.793]
 [0.793]
 [0.842]] [[3.47 ]
 [2.977]
 [3.47 ]
 [2.872]
 [3.47 ]
 [3.47 ]
 [2.991]] [[2.029]
 [1.909]
 [2.029]
 [1.891]
 [2.029]
 [2.029]
 [1.966]]
maxi score, test score, baseline:  -0.9969149253731343 -1.0 -0.9969149253731343
probs:  [0.4063655651398905, 0.09456866250707209, 0.1975688351256868, 0.3014969372273506]
734 372
maxi score, test score, baseline:  -0.9969326409495549 -1.0 -0.9969326409495549
probs:  [0.4384345363635036, 0.13720943522328202, 0.28714659318993235, 0.13720943522328202]
Printing some Q and Qe and total Qs values:  [[1.448]
 [0.129]
 [0.129]
 [0.129]
 [0.129]
 [0.129]
 [0.129]] [[2.033]
 [3.167]
 [3.167]
 [3.167]
 [3.167]
 [3.167]
 [3.167]] [[2.823]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]]
using explorer policy with actor:  1
from probs:  [0.19626447585952284, 0.19626447585952284, 0.4112065724214315, 0.19626447585952284]
siam score:  -0.8504748
maxi score, test score, baseline:  -0.9969414201183432 -1.0 -0.9969414201183432
maxi score, test score, baseline:  -0.9969414201183432 -1.0 -0.9969414201183432
probs:  [0.1977553809963858, 0.30132193589811923, 0.4058173388258714, 0.09510534427962339]
maxi score, test score, baseline:  -0.9969414201183432 -1.0 -0.9969414201183432
maxi score, test score, baseline:  -0.9969414201183432 -1.0 -0.9969414201183432
probs:  [0.220588821200055, 0.220588821200055, 0.45279585731491423, 0.10602650028497579]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9969414201183432 -1.0 -0.9969414201183432
probs:  [0.24971036800908017, 0.24971036800908017, 0.38062402790489785, 0.11995523607694188]
rdn probs:  [0.24971036800908017, 0.24971036800908017, 0.38062402790489785, 0.11995523607694188]
maxi score, test score, baseline:  -0.9969501474926253 -1.0 -0.9969501474926253
probs:  [0.24971036795521742, 0.24971036795521742, 0.3806240521965819, 0.11995521189298328]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.456]
 [0.457]
 [0.441]
 [0.451]
 [0.441]
 [0.452]
 [0.455]] [[3.457]
 [4.423]
 [3.171]
 [3.27 ]
 [3.078]
 [3.401]
 [3.332]] [[0.456]
 [0.457]
 [0.441]
 [0.451]
 [0.441]
 [0.452]
 [0.455]]
maxi score, test score, baseline:  -0.9969501474926253 -1.0 -0.9969501474926253
probs:  [0.24971036795521742, 0.24971036795521742, 0.3806240521965819, 0.11995521189298328]
siam score:  -0.8432644
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9969588235294118 -1.0 -0.9969588235294118
probs:  [0.13777380500605305, 0.2869647111107675, 0.43748767887712636, 0.13777380500605305]
siam score:  -0.838978
siam score:  -0.84028184
maxi score, test score, baseline:  -0.9969588235294118 -1.0 -0.9969588235294118
probs:  [0.16212433127016873, 0.3378756687298313, 0.3378756687298313, 0.16212433127016873]
maxi score, test score, baseline:  -0.9969588235294118 -1.0 -0.9969588235294118
probs:  [0.16212433127016873, 0.3378756687298313, 0.3378756687298313, 0.16212433127016873]
maxi score, test score, baseline:  -0.9969588235294118 -1.0 -0.9969588235294118
probs:  [0.16212433127016873, 0.3378756687298313, 0.3378756687298313, 0.16212433127016873]
siam score:  -0.84314376
maxi score, test score, baseline:  -0.9969588235294118 -1.0 -0.9969588235294118
probs:  [0.16212433127016873, 0.3378756687298313, 0.3378756687298313, 0.16212433127016873]
maxi score, test score, baseline:  -0.9969588235294118 -1.0 -0.9969588235294118
probs:  [0.249712278166893, 0.12023745326895885, 0.380337990397255, 0.249712278166893]
maxi score, test score, baseline:  -0.9969674486803519 -1.0 -0.9969674486803519
probs:  [0.24971227811366087, 0.12023742926137428, 0.3803380145113039, 0.24971227811366087]
Printing some Q and Qe and total Qs values:  [[0.468]
 [0.436]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.465]] [[4.398]
 [5.116]
 [4.212]
 [4.212]
 [4.212]
 [4.212]
 [4.346]] [[0.468]
 [0.436]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.465]]
maxi score, test score, baseline:  -0.9969674486803519 -1.0 -0.9969674486803519
probs:  [0.24971227811366087, 0.12023742926137428, 0.3803380145113039, 0.24971227811366087]
maxi score, test score, baseline:  -0.9969674486803519 -1.0 -0.9969674486803519
maxi score, test score, baseline:  -0.9969674486803519 -1.0 -0.9969674486803519
probs:  [0.24971227811366087, 0.12023742926137428, 0.3803380145113039, 0.24971227811366087]
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.24971227806074214, 0.1202374053947952, 0.3803380384837206, 0.24971227806074214]
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.24971227806074214, 0.1202374053947952, 0.3803380384837206, 0.24971227806074214]
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.24971227806074214, 0.1202374053947952, 0.3803380384837206, 0.24971227806074214]
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
first move QE:  2.0848961676406255
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.33761816720386345, 0.16238183279613658, 0.33761816720386345, 0.16238183279613658]
Printing some Q and Qe and total Qs values:  [[1.051]
 [1.242]
 [1.051]
 [1.051]
 [1.051]
 [1.051]
 [1.051]] [[2.795]
 [3.028]
 [2.795]
 [2.795]
 [2.795]
 [2.795]
 [2.795]] [[1.327]
 [1.786]
 [1.327]
 [1.327]
 [1.327]
 [1.327]
 [1.327]]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.33761816720386345, 0.16238183279613658, 0.33761816720386345, 0.16238183279613658]
UNIT TEST: sample policy line 217 mcts : [0.143 0.163 0.082 0.102 0.102 0.102 0.306]
line 256 mcts: sample exp_bonus 2.416317758056612
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.1205184543605902, 0.249714168773422, 0.3800532080925658, 0.249714168773422]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.08700677283522316, 0.2729321701310694, 0.367128886902638, 0.2729321701310694]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.08700677283522316, 0.2729321701310694, 0.367128886902638, 0.2729321701310694]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.08700677283522316, 0.2729321701310694, 0.367128886902638, 0.2729321701310694]
using explorer policy with actor:  1
siam score:  -0.83511615
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.09590379971894863, 0.1980327329069683, 0.4050019868897716, 0.3010614804843114]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.16289263034585189, 0.16289263034585189, 0.3371073696541481, 0.3371073696541481]
Printing some Q and Qe and total Qs values:  [[0.78]
 [1.04]
 [0.78]
 [0.78]
 [0.78]
 [0.78]
 [0.78]] [[3.054]
 [2.855]
 [3.054]
 [3.054]
 [3.054]
 [3.054]
 [3.054]] [[2.019]
 [2.473]
 [2.019]
 [2.019]
 [2.019]
 [2.019]
 [2.019]]
line 256 mcts: sample exp_bonus 3.4737430201823982
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.1631458856058961, 0.3368541143941039, 0.3368541143941039, 0.1631458856058961]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.1631458856058961, 0.3368541143941039, 0.3368541143941039, 0.1631458856058961]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.22110471898332287, 0.3356937303971042, 0.3356937303971042, 0.10750782022246877]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.22110471898332287, 0.3356937303971042, 0.3356937303971042, 0.10750782022246877]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.2494460326653967, 0.3351263137509401, 0.3351263137509401, 0.08030133983272317]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.2494460326653967, 0.3351263137509401, 0.3351263137509401, 0.08030133983272317]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.2494460326653967, 0.3351263137509401, 0.3351263137509401, 0.08030133983272317]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.2494460326653967, 0.3351263137509401, 0.3351263137509401, 0.08030133983272317]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.2494460326653967, 0.3351263137509401, 0.3351263137509401, 0.08030133983272317]
maxi score, test score, baseline:  -0.9970098265895954 -1.0 -0.9970098265895954
probs:  [0.2494460325977729, 0.33512632414224397, 0.33512632414224397, 0.08030131911773915]
Printing some Q and Qe and total Qs values:  [[ 0.049]
 [-0.004]
 [ 0.101]
 [ 0.061]
 [ 0.07 ]
 [ 0.066]
 [ 0.049]] [[4.529]
 [4.532]
 [5.077]
 [5.024]
 [4.617]
 [4.607]
 [4.564]] [[-0.333]
 [-0.44 ]
 [-0.046]
 [-0.144]
 [-0.262]
 [-0.275]
 [-0.322]]
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.24944603253054448, 0.3351263344733969, 0.3351263344733969, 0.08030129852266166]
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.24944603253054448, 0.3351263344733969, 0.3351263344733969, 0.08030129852266166]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 4.264371082980128
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
Printing some Q and Qe and total Qs values:  [[0.478]
 [0.48 ]
 [0.442]
 [0.478]
 [0.478]
 [0.478]
 [0.433]] [[4.591]
 [4.855]
 [4.291]
 [4.591]
 [4.591]
 [4.591]
 [4.282]] [[1.557]
 [1.738]
 [1.285]
 [1.557]
 [1.557]
 [1.557]
 [1.262]]
Printing some Q and Qe and total Qs values:  [[0.763]
 [0.691]
 [0.763]
 [0.748]
 [0.763]
 [0.763]
 [0.797]] [[2.489]
 [2.619]
 [2.489]
 [2.753]
 [2.489]
 [2.489]
 [2.742]] [[2.163]
 [2.185]
 [2.163]
 [2.402]
 [2.163]
 [2.163]
 [2.463]]
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
probs:  [0.22963794641774793, 0.3877918245593793, 0.308371072709992, 0.07419915631288071]
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
probs:  [0.17986338783255046, 0.3660950759808776, 0.3660950759808776, 0.08794646020569408]
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
probs:  [0.1983980618262419, 0.3007179281327062, 0.40392753240705204, 0.0969564776339998]
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
probs:  [0.10783805637811643, 0.33470533848069284, 0.4496185487630742, 0.10783805637811643]
Printing some Q and Qe and total Qs values:  [[0.573]
 [0.584]
 [0.573]
 [0.694]
 [0.658]
 [0.502]
 [0.572]] [[2.5  ]
 [2.548]
 [2.473]
 [2.646]
 [3.088]
 [2.455]
 [2.532]] [[1.122]
 [1.19 ]
 [1.094]
 [1.509]
 [1.881]
 [0.934]
 [1.152]]
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
probs:  [0.08066407313517182, 0.33438862496333877, 0.4204343425398424, 0.16451295936164698]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
in main func line 156:  751
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
using another actor
maxi score, test score, baseline:  -0.997034670487106 -1.0 -0.997034670487106
Printing some Q and Qe and total Qs values:  [[0.768]
 [0.718]
 [0.8  ]
 [0.768]
 [0.8  ]
 [0.759]
 [0.75 ]] [[3.135]
 [3.048]
 [3.257]
 [2.826]
 [3.257]
 [2.656]
 [2.796]] [[1.312]
 [1.154]
 [1.457]
 [1.106]
 [1.457]
 [0.975]
 [1.049]]
maxi score, test score, baseline:  -0.997034670487106 -1.0 -0.997034670487106
probs:  [0.12204713975367612, 0.3779528602463239, 0.3779528602463239, 0.12204713975367612]
maxi score, test score, baseline:  -0.997034670487106 -1.0 -0.997034670487106
probs:  [0.1399780487912254, 0.4337902508731148, 0.28625365154443444, 0.1399780487912254]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.3356090108974405, 0.1643909891025595, 0.3356090108974405, 0.1643909891025595]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.33487929154973534, 0.10885511575157228, 0.33487929154973534, 0.22138630114895705]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.33487929154973534, 0.10885511575157228, 0.33487929154973534, 0.22138630114895705]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.33487929154973534, 0.10885511575157228, 0.33487929154973534, 0.22138630114895705]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.24972862657128253, 0.12272586193158042, 0.37781688492585447, 0.24972862657128253]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.30037858215721003, 0.097995704673465, 0.4028673470367947, 0.19875836613253023]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.24973035404986949, 0.12299675748959361, 0.3775425344106673, 0.24973035404986949]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.24973035404986949, 0.12299675748959361, 0.3775425344106673, 0.24973035404986949]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.24973035404986949, 0.12299675748959361, 0.3775425344106673, 0.24973035404986949]
Printing some Q and Qe and total Qs values:  [[1.289]
 [0.861]
 [0.861]
 [0.861]
 [0.861]
 [0.861]
 [0.861]] [[0.961]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.754]] [[1.863]
 [0.938]
 [0.938]
 [0.938]
 [0.938]
 [0.938]
 [0.938]]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.24973035404986949, 0.12299675748959361, 0.3775425344106673, 0.24973035404986949]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.24973035404986949, 0.12299675748959361, 0.3775425344106673, 0.24973035404986949]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.24973035404986949, 0.12299675748959361, 0.3775425344106673, 0.24973035404986949]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.10917962114763509, 0.10917962114763509, 0.44772233159746494, 0.33391842610726497]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.10917962114763509, 0.10917962114763509, 0.44772233159746494, 0.33391842610726497]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.08185677734268465, 0.16513219697891432, 0.4192108177413644, 0.33380020793703663]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.08944114648742123, 0.18052741915321288, 0.36501571717968295, 0.36501571717968295]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.10965200819246967, 0.22155267785902963, 0.3343976569742504, 0.3343976569742504]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.10965200819246967, 0.22155267785902963, 0.3343976569742504, 0.3343976569742504]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.10965200819246967, 0.22155267785902963, 0.3343976569742504, 0.3343976569742504]
siam score:  -0.81820005
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.12353525817682787, 0.24973375843826753, 0.24973375843826753, 0.37699722494663707]
Printing some Q and Qe and total Qs values:  [[0.314]
 [0.303]
 [0.374]
 [0.33 ]
 [0.391]
 [0.342]
 [0.44 ]] [[3.46 ]
 [3.824]
 [3.575]
 [3.573]
 [3.582]
 [3.412]
 [3.743]] [[0.898]
 [1.187]
 [1.097]
 [1.021]
 [1.132]
 [0.905]
 [1.351]]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.19901654821438466, 0.19901654821438466, 0.19901654821438466, 0.4029503553568459]
Printing some Q and Qe and total Qs values:  [[0.263]
 [0.199]
 [0.237]
 [0.235]
 [0.234]
 [0.263]
 [0.263]] [[5.074]
 [5.545]
 [4.934]
 [5.282]
 [4.943]
 [5.074]
 [5.074]] [[0.289]
 [0.318]
 [0.191]
 [0.303]
 [0.187]
 [0.289]
 [0.289]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.14174866787676932, 0.2860837773744102, 0.2860837773744102, 0.2860837773744102]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
maxi score, test score, baseline:  -0.9970509971509972 -1.0 -0.9970509971509972
probs:  [0.16560212389215126, 0.16560212389215126, 0.33439787610784877, 0.33439787610784877]
maxi score, test score, baseline:  -0.9970509971509972 -1.0 -0.9970509971509972
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.496]
 [0.564]
 [0.569]
 [0.58 ]
 [0.577]
 [0.578]] [[3.038]
 [4.588]
 [2.916]
 [3.058]
 [2.806]
 [2.947]
 [2.938]] [[0.563]
 [0.496]
 [0.564]
 [0.569]
 [0.58 ]
 [0.577]
 [0.578]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.22166252571142547, 0.1101784704855798, 0.3340795019014973, 0.3340795019014973]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.12393953784078873, 0.12393953784078873, 0.3760604621592113, 0.3760604621592113]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.12393953784078873, 0.12393953784078873, 0.3760604621592113, 0.3760604621592113]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.938399292809512
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.12393953784078873, 0.12393953784078873, 0.3760604621592113, 0.3760604621592113]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.12393953784078873, 0.12393953784078873, 0.3760604621592113, 0.3760604621592113]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.12393953784078873, 0.12393953784078873, 0.3760604621592113, 0.3760604621592113]
siam score:  -0.81615907
Printing some Q and Qe and total Qs values:  [[0.851]
 [1.347]
 [0.851]
 [0.851]
 [0.851]
 [0.851]
 [0.851]] [[2.919]
 [2.018]
 [2.919]
 [2.919]
 [2.919]
 [2.919]
 [2.919]] [[1.803]
 [2.196]
 [1.803]
 [1.803]
 [1.803]
 [1.803]
 [1.803]]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.12447044316748383, 0.12447044316748383, 0.37552955683251615, 0.37552955683251615]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.12447044316748383, 0.12447044316748383, 0.37552955683251615, 0.37552955683251615]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.12447044316748383, 0.12447044316748383, 0.37552955683251615, 0.37552955683251615]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.12447044316748383, 0.12447044316748383, 0.37552955683251615, 0.37552955683251615]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.12447044316748383, 0.12447044316748383, 0.37552955683251615, 0.37552955683251615]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.1423604626615856, 0.1423604626615856, 0.28548393023983715, 0.42979514443699174]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.1423604626615856, 0.1423604626615856, 0.28548393023983715, 0.42979514443699174]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.1423604626615856, 0.1423604626615856, 0.28548393023983715, 0.42979514443699174]
siam score:  -0.8134484
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.1423604626615856, 0.1423604626615856, 0.28548393023983715, 0.42979514443699174]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.1423604626615856, 0.1423604626615856, 0.28548393023983715, 0.42979514443699174]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.1423604626615856, 0.1423604626615856, 0.28548393023983715, 0.42979514443699174]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.1423604626615856, 0.1423604626615856, 0.28548393023983715, 0.42979514443699174]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.1423604626615856, 0.1423604626615856, 0.28548393023983715, 0.42979514443699174]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.1423604626615856, 0.1423604626615856, 0.28548393023983715, 0.42979514443699174]
769 430
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.16608276125217, 0.16608276125217, 0.16608276125217, 0.5017517162434901]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.5249],
        [-0.0000],
        [-0.5249],
        [-0.5099],
        [-0.0000],
        [-0.0000],
        [-0.4808],
        [-0.5345],
        [-0.5249],
        [-0.3452]], dtype=torch.float64)
-0.024259925299500003 -0.5491281014507555
-0.004949999999999235 -0.004949999999999235
-0.024259925299500003 -0.5491281014507555
-0.024259925299500003 -0.534201197712628
-0.9514752239519999 -0.9514752239519999
-0.9652499999999999 -0.9652499999999999
-0.0727797758985 -0.5535546222503811
-0.024259925299500003 -0.5587459057522416
-0.024259925299500003 -0.5491281014507555
-0.06307678589849999 -0.4083014308129198
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.16608276125217, 0.16608276125217, 0.16608276125217, 0.5017517162434901]
maxi score, test score, baseline:  -0.9970830985915493 -1.0 -0.9970830985915493
probs:  [0.221620272750462, 0.221620272750462, 0.11085890810044506, 0.4459005463986309]
Printing some Q and Qe and total Qs values:  [[1.107]
 [1.09 ]
 [1.118]
 [0.954]
 [1.073]
 [1.084]
 [1.106]] [[2.447]
 [2.432]
 [2.444]
 [3.447]
 [2.588]
 [2.437]
 [2.265]] [[1.01 ]
 [0.977]
 [1.02 ]
 [1.634]
 [1.083]
 [0.973]
 [0.861]]
maxi score, test score, baseline:  -0.9970830985915493 -1.0 -0.9970830985915493
maxi score, test score, baseline:  -0.9970830985915493 -1.0 -0.9970830985915493
probs:  [0.221620272750462, 0.221620272750462, 0.11085890810044506, 0.4459005463986309]
siam score:  -0.80418724
Printing some Q and Qe and total Qs values:  [[0.295]
 [0.224]
 [0.371]
 [0.345]
 [0.357]
 [0.359]
 [0.36 ]] [[0.528]
 [2.521]
 [0.974]
 [0.947]
 [0.882]
 [1.005]
 [0.952]] [[0.295]
 [0.224]
 [0.371]
 [0.345]
 [0.357]
 [0.359]
 [0.36 ]]
maxi score, test score, baseline:  -0.9970830985915493 -1.0 -0.9970830985915493
probs:  [0.221620272750462, 0.221620272750462, 0.11085890810044506, 0.4459005463986309]
first move QE:  2.111943576547893
maxi score, test score, baseline:  -0.9970830985915493 -1.0 -0.9970830985915493
Printing some Q and Qe and total Qs values:  [[0.385]
 [0.413]
 [0.385]
 [0.385]
 [0.385]
 [0.385]
 [0.385]] [[2.935]
 [3.542]
 [2.935]
 [2.935]
 [2.935]
 [2.935]
 [2.935]] [[0.385]
 [0.413]
 [0.385]
 [0.385]
 [0.385]
 [0.385]
 [0.385]]
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.22162026798982584, 0.22162026798982584, 0.11085888475982962, 0.4459005792605187]
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.22162026798982584, 0.22162026798982584, 0.11085888475982962, 0.4459005792605187]
maxi score, test score, baseline:  -0.9970910112359551 -1.0 -0.9970910112359551
probs:  [0.24974198449227805, 0.24974198449227805, 0.12486247875480141, 0.3756535522606424]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.24974198444375337, 0.24974198444375337, 0.12486245522073045, 0.37565357589176285]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.24974198444375337, 0.24974198444375337, 0.12486245522073045, 0.37565357589176285]
Printing some Q and Qe and total Qs values:  [[0.017]
 [0.004]
 [0.033]
 [0.005]
 [0.009]
 [0.019]
 [0.017]] [[3.365]
 [3.025]
 [2.984]
 [3.453]
 [3.467]
 [3.401]
 [2.942]] [[1.145]
 [0.719]
 [0.722]
 [1.228]
 [1.251]
 [1.19 ]
 [0.643]]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.28573766812006457, 0.28573766812006457, 0.1427869956398063, 0.28573766812006457]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.333452669997767, 0.333452669997767, 0.16654733000223299, 0.16654733000223299]
Printing some Q and Qe and total Qs values:  [[0.706]
 [0.742]
 [0.706]
 [0.706]
 [0.706]
 [0.706]
 [0.706]] [[3.801]
 [3.321]
 [3.801]
 [3.801]
 [3.801]
 [3.801]
 [3.801]] [[2.838]
 [2.749]
 [2.838]
 [2.838]
 [2.838]
 [2.838]
 [2.838]]
line 256 mcts: sample exp_bonus 2.0074178476561206
Printing some Q and Qe and total Qs values:  [[0.738]
 [0.77 ]
 [0.769]
 [0.756]
 [0.764]
 [0.76 ]
 [0.747]] [[4.188]
 [3.831]
 [4.656]
 [5.165]
 [4.847]
 [5.223]
 [4.967]] [[1.26 ]
 [1.205]
 [1.477]
 [1.621]
 [1.531]
 [1.649]
 [1.538]]
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
probs:  [0.4289300900724476, 0.1428764161810346, 0.1428764161810346, 0.28531707756548325]
Printing some Q and Qe and total Qs values:  [[0.826]
 [0.869]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]] [[4.655]
 [4.207]
 [4.655]
 [4.655]
 [4.655]
 [4.655]
 [4.655]] [[1.389]
 [1.326]
 [1.389]
 [1.389]
 [1.389]
 [1.389]
 [1.389]]
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
probs:  [0.3332195460368633, 0.16678045396313668, 0.16678045396313668, 0.3332195460368633]
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
probs:  [0.3332195460368633, 0.16678045396313668, 0.16678045396313668, 0.3332195460368633]
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
from probs:  [0.3332195460368633, 0.16678045396313668, 0.16678045396313668, 0.3332195460368633]
using explorer policy with actor:  1
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
probs:  [0.2000420035575935, 0.2000420035575935, 0.2000420035575935, 0.3998739893272195]
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
probs:  [0.2000420035575935, 0.2000420035575935, 0.2000420035575935, 0.3998739893272195]
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
probs:  [0.2000420035575935, 0.2000420035575935, 0.2000420035575935, 0.3998739893272195]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
probs:  [0.2000420035575935, 0.2000420035575935, 0.2000420035575935, 0.3998739893272195]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.09146168739878423, 0.2723306448491465, 0.2723306448491465, 0.36387702290292284]
first move QE:  2.112375822976258
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.09146168739878423, 0.2723306448491465, 0.2723306448491465, 0.36387702290292284]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.09146168739878423, 0.2723306448491465, 0.2723306448491465, 0.36387702290292284]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.09146168739878423, 0.2723306448491465, 0.2723306448491465, 0.36387702290292284]
Printing some Q and Qe and total Qs values:  [[0.402]
 [0.376]
 [0.381]
 [0.397]
 [0.405]
 [0.397]
 [0.407]] [[5.388]
 [5.573]
 [3.957]
 [4.682]
 [5.045]
 [4.716]
 [4.651]] [[0.402]
 [0.376]
 [0.381]
 [0.397]
 [0.405]
 [0.397]
 [0.407]]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.09146168739878423, 0.2723306448491465, 0.2723306448491465, 0.36387702290292284]
line 256 mcts: sample exp_bonus 6.838092324266389
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.09146168739878423, 0.2723306448491465, 0.2723306448491465, 0.36387702290292284]
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.09146166572951364, 0.2723306479013377, 0.2723306479013377, 0.36387703846781083]
Printing some Q and Qe and total Qs values:  [[0.156]
 [0.122]
 [0.166]
 [0.167]
 [0.167]
 [0.166]
 [0.169]] [[5.531]
 [5.79 ]
 [5.548]
 [5.644]
 [5.749]
 [5.867]
 [5.762]] [[0.281]
 [0.363]
 [0.306]
 [0.358]
 [0.412]
 [0.473]
 [0.423]]
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.10053628626875787, 0.29954825845148086, 0.199637776481698, 0.40027767879806336]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.709]
 [0.685]
 [0.813]
 [0.702]
 [0.813]
 [0.813]
 [0.813]] [[6.354]
 [7.006]
 [7.183]
 [6.235]
 [7.183]
 [7.183]
 [7.183]] [[1.915]
 [2.253]
 [2.455]
 [1.844]
 [2.455]
 [2.455]
 [2.455]]
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.12539150205621277, 0.24923864461541373, 0.12539150205621277, 0.49997835127216067]
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.12539150205621277, 0.24923864461541373, 0.12539150205621277, 0.49997835127216067]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
probs:  [0.20037497832763312, 0.20037497832763312, 0.20037497832763312, 0.3988750650171006]
siam score:  -0.801483
Printing some Q and Qe and total Qs values:  [[0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]] [[3.558]
 [3.558]
 [3.558]
 [3.558]
 [3.558]
 [3.558]
 [3.558]] [[0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]]
siam score:  -0.80250907
maxi score, test score, baseline:  -0.9971222222222222 -1.0 -0.9971222222222222
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.24974828650534225, 0.12590524713252618, 0.24974828650534225, 0.37459817985678934]
using explorer policy with actor:  1
788 440
maxi score, test score, baseline:  -0.9971375690607734 -1.0 -0.9971375690607734
probs:  [0.20053983895962402, 0.20053983895962402, 0.39838048312112784, 0.20053983895962402]
maxi score, test score, baseline:  -0.9971375690607734 -1.0 -0.9971375690607734
probs:  [0.20053983895962402, 0.20053983895962402, 0.39838048312112784, 0.20053983895962402]
maxi score, test score, baseline:  -0.9971375690607734 -1.0 -0.9971375690607734
probs:  [0.24974982496558087, 0.24974982496558087, 0.37433699210703403, 0.12616335796180428]
maxi score, test score, baseline:  -0.9971375690607734 -1.0 -0.9971375690607734
probs:  [0.24974982496558087, 0.24974982496558087, 0.37433699210703403, 0.12616335796180428]
maxi score, test score, baseline:  -0.9971375690607734 -1.0 -0.9971375690607734
probs:  [0.24974982496558087, 0.24974982496558087, 0.37433699210703403, 0.12616335796180428]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.424]] [[5.291]
 [5.291]
 [5.291]
 [5.291]
 [5.291]
 [5.291]
 [5.291]] [[1.174]
 [1.174]
 [1.174]
 [1.174]
 [1.174]
 [1.174]
 [1.174]]
maxi score, test score, baseline:  -0.9971375690607734 -1.0 -0.9971375690607734
probs:  [0.24974982496558087, 0.24974982496558087, 0.37433699210703403, 0.12616335796180428]
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
probs:  [0.2853138780176341, 0.2853138780176341, 0.2853138780176341, 0.14405836594709778]
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
probs:  [0.2853138780176341, 0.2853138780176341, 0.2853138780176341, 0.14405836594709778]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.235707296805566
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
probs:  [0.2853138780176341, 0.2853138780176341, 0.2853138780176341, 0.14405836594709778]
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
probs:  [0.2853138780176341, 0.2853138780176341, 0.2853138780176341, 0.14405836594709778]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.543]
 [0.543]
 [0.543]
 [0.752]
 [0.543]
 [0.763]
 [0.609]] [[3.091]
 [3.091]
 [3.091]
 [2.459]
 [3.091]
 [2.408]
 [3.035]] [[1.239]
 [1.239]
 [1.239]
 [1.445]
 [1.239]
 [1.45 ]
 [1.353]]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.2008664177018363, 0.2008664177018363, 0.2008664177018363, 0.39740074689449106]
siam score:  -0.7978706
Printing some Q and Qe and total Qs values:  [[1.074]
 [1.421]
 [1.074]
 [1.074]
 [1.074]
 [1.074]
 [1.074]] [[2.066]
 [2.937]
 [2.066]
 [2.066]
 [2.066]
 [2.066]
 [2.066]] [[2.129]
 [3.112]
 [2.129]
 [2.129]
 [2.129]
 [2.129]
 [2.129]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.14439629643372812, 0.28482525337899883, 0.14439629643372812, 0.42638215375354493]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.16793283018528907, 0.16793283018528907, 0.16793283018528907, 0.49620150944413277]
Printing some Q and Qe and total Qs values:  [[0.527]
 [0.468]
 [0.564]
 [0.531]
 [0.508]
 [0.539]
 [0.576]] [[4.267]
 [4.534]
 [4.392]
 [4.209]
 [4.211]
 [4.397]
 [4.189]] [[1.287]
 [1.381]
 [1.412]
 [1.255]
 [1.226]
 [1.384]
 [1.299]]
Printing some Q and Qe and total Qs values:  [[0.086]
 [0.065]
 [0.086]
 [0.086]
 [0.086]
 [0.086]
 [0.086]] [[5.632]
 [5.986]
 [5.632]
 [5.632]
 [5.632]
 [5.632]
 [5.632]] [[1.555]
 [1.732]
 [1.555]
 [1.555]
 [1.555]
 [1.555]
 [1.555]]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.16793283018528907, 0.16793283018528907, 0.16793283018528907, 0.49620150944413277]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.16793283018528907, 0.16793283018528907, 0.16793283018528907, 0.49620150944413277]
Printing some Q and Qe and total Qs values:  [[0.114]
 [0.061]
 [0.067]
 [0.068]
 [0.058]
 [0.057]
 [0.065]] [[3.188]
 [4.951]
 [3.391]
 [3.378]
 [3.348]
 [3.349]
 [3.276]] [[0.126]
 [1.148]
 [0.194]
 [0.188]
 [0.157]
 [0.156]
 [0.121]]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.16793283018528907, 0.16793283018528907, 0.16793283018528907, 0.49620150944413277]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.16793283018528907, 0.16793283018528907, 0.16793283018528907, 0.49620150944413277]
siam score:  -0.79520726
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.24934067997843168, 0.24934067997843168, 0.08516999460816872, 0.41614864543496805]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
probs:  [0.2493406798949429, 0.2493406798949429, 0.08516997373627161, 0.41614866647384247]
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
probs:  [0.2493406798949429, 0.2493406798949429, 0.08516997373627161, 0.41614866647384247]
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
probs:  [0.2493406798949429, 0.2493406798949429, 0.08516997373627161, 0.41614866647384247]
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
probs:  [0.2493406798949429, 0.2493406798949429, 0.08516997373627161, 0.41614866647384247]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
probs:  [0.2493406798949429, 0.2493406798949429, 0.08516997373627161, 0.41614866647384247]
siam score:  -0.79909164
Printing some Q and Qe and total Qs values:  [[0.358]
 [0.352]
 [0.358]
 [0.358]
 [0.358]
 [0.358]
 [0.357]] [[3.757]
 [4.708]
 [3.757]
 [3.757]
 [3.757]
 [3.757]
 [3.711]] [[0.358]
 [0.352]
 [0.358]
 [0.358]
 [0.358]
 [0.358]
 [0.357]]
line 256 mcts: sample exp_bonus 6.789565840800418
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
probs:  [0.2493406798949429, 0.2493406798949429, 0.08516997373627161, 0.41614866647384247]
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
maxi score, test score, baseline:  -0.9971602739726028 -1.0 -0.9971602739726028
probs:  [0.30701432744183293, 0.30701432744183293, 0.07895701767450133, 0.30701432744183293]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.24914319139490756, 0.31163478473062683, 0.06459770482536632, 0.3746243190490994]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.19950004359980342, 0.3322548281373425, 0.06881955257065571, 0.3994255756921985]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.19950004359980342, 0.3322548281373425, 0.06881955257065571, 0.3994255756921985]
from probs:  [0.22121380979278135, 0.3324477010213621, 0.057609098180311145, 0.3887293910055454]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.24914745811830707, 0.31157145181657625, 0.06479021602885265, 0.37449087403626413]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.24914745811830707, 0.31157145181657625, 0.06479021602885265, 0.37449087403626413]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.2845509410965888, 0.21378043809425257, 0.07389166173165267, 0.4277769590775059]
from probs:  [0.2845509410965888, 0.21378043809425257, 0.07389166173165267, 0.4277769590775059]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.30661137261584365, 0.2303349598354162, 0.0795629065573671, 0.38349076099137297]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.30661137261584365, 0.2303349598354162, 0.0795629065573671, 0.38349076099137297]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.30661137261584365, 0.2303349598354162, 0.0795629065573671, 0.38349076099137297]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.30661137261584365, 0.2303349598354162, 0.0795629065573671, 0.38349076099137297]
Printing some Q and Qe and total Qs values:  [[0.46 ]
 [0.493]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]] [[1.266]
 [2.251]
 [1.266]
 [1.266]
 [1.266]
 [1.266]
 [1.266]] [[0.46 ]
 [0.493]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.33217397455339426, 0.24951756962101798, 0.08613448127219349, 0.33217397455339426]
maxi score, test score, baseline:  -0.997175204359673 -1.0 -0.997175204359673
probs:  [0.3621446409570599, 0.27200805698218994, 0.09383924507856038, 0.27200805698218994]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.39777114896714266, 0.20048807431895177, 0.10299799462899172, 0.2987427820849139]
siam score:  -0.7953917
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.39777114896714266, 0.20048807431895177, 0.10299799462899172, 0.2987427820849139]
Printing some Q and Qe and total Qs values:  [[0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]] [[2.328]
 [2.328]
 [2.328]
 [2.328]
 [2.328]
 [2.328]
 [2.328]] [[1.809]
 [1.809]
 [1.809]
 [1.809]
 [1.809]
 [1.809]
 [1.809]]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.4408212616105908, 0.11406521207035077, 0.11406521207035077, 0.33104831424870756]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
maxi score, test score, baseline:  -0.997189972899729 -1.0 -0.997189972899729
probs:  [0.4408212938541544, 0.11406518910109965, 0.11406518910109965, 0.33104832794364625]
807 461
Printing some Q and Qe and total Qs values:  [[1.048]
 [1.327]
 [1.048]
 [1.048]
 [1.048]
 [1.048]
 [1.048]] [[2.452]
 [3.438]
 [2.452]
 [2.452]
 [2.452]
 [2.452]
 [2.452]] [[1.906]
 [2.794]
 [1.906]
 [1.906]
 [1.906]
 [1.906]
 [1.906]]
Printing some Q and Qe and total Qs values:  [[0.55 ]
 [0.731]
 [0.551]
 [0.55 ]
 [0.535]
 [0.539]
 [0.54 ]] [[3.79 ]
 [5.259]
 [4.129]
 [4.211]
 [4.303]
 [4.528]
 [4.173]] [[0.595]
 [1.449]
 [0.712]
 [0.737]
 [0.738]
 [0.82 ]
 [0.704]]
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
probs:  [0.4147129512865258, 0.08624935907746313, 0.16740670579060063, 0.33163098384541034]
Printing some Q and Qe and total Qs values:  [[0.756]
 [0.704]
 [0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.729]] [[3.649]
 [3.304]
 [3.649]
 [3.325]
 [3.649]
 [3.649]
 [3.139]] [[0.888]
 [0.668]
 [0.888]
 [0.778]
 [0.888]
 [0.888]
 [0.662]]
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
probs:  [0.4147129512865258, 0.08624935907746313, 0.16740670579060063, 0.33163098384541034]
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
probs:  [0.22237380909674564, 0.11440938487712041, 0.22237380909674564, 0.44084299692938833]
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
probs:  [0.2497630430373579, 0.1284410781629158, 0.2497630430373579, 0.37203283576236834]
siam score:  -0.7783465
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.37143145240138187, 0.12856854759861816, 0.37143145240138187, 0.12856854759861816]
from probs:  [0.37143145240138187, 0.12856854759861816, 0.37143145240138187, 0.12856854759861816]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.36138410202902976, 0.09447447280295276, 0.36138410202902976, 0.18275732313898774]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.36138410202902976, 0.09447447280295276, 0.36138410202902976, 0.18275732313898774]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.29850583624365506, 0.10372164983361741, 0.3970348021319909, 0.2007377117907367]
Printing some Q and Qe and total Qs values:  [[0.098]
 [0.096]
 [0.108]
 [0.113]
 [0.123]
 [0.123]
 [0.124]] [[4.245]
 [4.434]
 [4.278]
 [4.327]
 [4.186]
 [4.106]
 [4.222]] [[-0.556]
 [-0.498]
 [-0.525]
 [-0.499]
 [-0.526]
 [-0.552]
 [-0.512]]
Printing some Q and Qe and total Qs values:  [[0.369]
 [0.394]
 [0.369]
 [0.369]
 [0.369]
 [0.369]
 [0.369]] [[3.02 ]
 [3.338]
 [3.02 ]
 [3.02 ]
 [3.02 ]
 [3.02 ]
 [3.02 ]] [[0.369]
 [0.394]
 [0.369]
 [0.369]
 [0.369]
 [0.369]
 [0.369]]
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.3711837860887604, 0.12881621391123962, 0.3711837860887604, 0.12881621391123962]
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.2841113271854324, 0.14660003946914835, 0.42268859387627084, 0.14660003946914835]
Printing some Q and Qe and total Qs values:  [[0.973]
 [0.989]
 [0.973]
 [0.973]
 [0.973]
 [0.973]
 [0.973]] [[3.104]
 [3.618]
 [3.104]
 [3.104]
 [3.104]
 [3.104]
 [3.104]] [[1.159]
 [1.363]
 [1.159]
 [1.159]
 [1.159]
 [1.159]
 [1.159]]
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.2841113271854324, 0.14660003946914835, 0.42268859387627084, 0.14660003946914835]
from probs:  [0.2841113271854324, 0.14660003946914835, 0.42268859387627084, 0.14660003946914835]
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.16992221577507835, 0.16992221577507835, 0.4902333526747649, 0.16992221577507835]
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.16992219576823836, 0.16992219576823836, 0.4902334126952851, 0.16992219576823836]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.86775251298297
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.16992219576823836, 0.16992219576823836, 0.4902334126952851, 0.16992219576823836]
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.16992219576823836, 0.16992219576823836, 0.4902334126952851, 0.16992219576823836]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.16992219576823836, 0.16992219576823836, 0.4902334126952851, 0.16992219576823836]
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.16992219576823836, 0.16992219576823836, 0.4902334126952851, 0.16992219576823836]
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.16992219576823836, 0.16992219576823836, 0.4902334126952851, 0.16992219576823836]
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.16992217586880773, 0.16992217586880773, 0.49023347239357695, 0.16992217586880773]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.12942792180130608, 0.37103492686740114, 0.24976857566564636, 0.24976857566564636]
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.12942792180130608, 0.37103492686740114, 0.24976857566564636, 0.24976857566564636]
Printing some Q and Qe and total Qs values:  [[0.765]
 [0.906]
 [0.765]
 [0.765]
 [0.765]
 [0.765]
 [0.765]] [[2.773]
 [3.339]
 [2.773]
 [2.773]
 [2.773]
 [2.773]
 [2.773]] [[1.922]
 [2.469]
 [1.922]
 [1.922]
 [1.922]
 [1.922]
 [1.922]]
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.10443862214234521, 0.39630546430560865, 0.29827100774246806, 0.20098490580957812]
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.11563612282302582, 0.4390970951388074, 0.2226333910190834, 0.2226333910190834]
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.11563610003148031, 0.43909712721450084, 0.2226333863770094, 0.2226333863770094]
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.11563610003148031, 0.43909712721450084, 0.2226333863770094, 0.2226333863770094]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.11563610003148031, 0.43909712721450084, 0.2226333863770094, 0.2226333863770094]
maxi score, test score, baseline:  -0.9972474801061008 -1.0 -0.9972474801061008
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.546]
 [0.548]
 [0.55 ]
 [0.546]
 [0.554]
 [0.551]
 [0.551]] [[2.783]
 [3.86 ]
 [2.832]
 [2.746]
 [2.751]
 [2.806]
 [2.865]] [[0.546]
 [0.548]
 [0.55 ]
 [0.546]
 [0.554]
 [0.551]
 [0.551]]
maxi score, test score, baseline:  -0.9972474801061008 -1.0 -0.9972474801061008
probs:  [0.08764643038383847, 0.41359765827222356, 0.24937795567196894, 0.24937795567196894]
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
probs:  [0.0954640094993592, 0.36096190793324673, 0.2717870412836971, 0.2717870412836971]
Printing some Q and Qe and total Qs values:  [[0.486]
 [0.492]
 [0.496]
 [0.498]
 [0.501]
 [0.51 ]
 [0.497]] [[4.711]
 [5.189]
 [5.457]
 [5.233]
 [5.357]
 [5.694]
 [5.602]] [[1.109]
 [1.411]
 [1.58 ]
 [1.444]
 [1.523]
 [1.74 ]
 [1.671]]
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
maxi score, test score, baseline:  -0.9972614775725593 -1.0 -0.9972614775725593
probs:  [0.10475358736585998, 0.29841547087804665, 0.29841547087804665, 0.29841547087804665]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
probs:  [0.11597403234665547, 0.33057877811730835, 0.33057877811730835, 0.22286841141872774]
from probs:  [0.12991554609402903, 0.24977126770684466, 0.37054191849228174, 0.24977126770684466]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
probs:  [0.14770449716247802, 0.28409850094584066, 0.28409850094584066, 0.28409850094584066]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
probs:  [0.22291857063550816, 0.3304328594982854, 0.3304328594982854, 0.11621571036792111]
Printing some Q and Qe and total Qs values:  [[1.45 ]
 [0.165]
 [0.165]
 [0.165]
 [0.165]
 [0.165]
 [0.165]] [[2.128]
 [3.294]
 [3.294]
 [3.294]
 [3.294]
 [3.294]
 [3.294]] [[2.603]
 [1.198]
 [1.198]
 [1.198]
 [1.198]
 [1.198]
 [1.198]]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
probs:  [0.2306097546267212, 0.38177501705151523, 0.3059060879936195, 0.0817091403281442]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.2491921565144244, 0.37304165227062525, 0.31088234095359235, 0.06688385026135812]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.28443653812771147, 0.28443653812771147, 0.3548868604042506, 0.07624006334032642]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.33146795959390934, 0.22161884446579613, 0.3870166598575568, 0.05989653608273785]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.33146795959390934, 0.22161884446579613, 0.3870166598575568, 0.05989653608273785]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.37278169936302746, 0.24919986700015728, 0.310758486504217, 0.06725994713259816]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.37278169936302746, 0.24919986700015728, 0.310758486504217, 0.06725994713259816]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.39707885607372745, 0.20032841165907844, 0.33100226571893443, 0.07159046654825962]
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.673]
 [0.645]
 [0.645]
 [0.645]
 [0.645]
 [0.645]] [[1.291]
 [2.448]
 [1.77 ]
 [1.77 ]
 [1.77 ]
 [1.77 ]
 [1.77 ]] [[0.527]
 [0.919]
 [0.679]
 [0.679]
 [0.679]
 [0.679]
 [0.679]]
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.521]
 [0.563]
 [0.638]
 [0.563]
 [0.563]
 [0.633]] [[5.553]
 [5.71 ]
 [4.946]
 [4.36 ]
 [4.946]
 [4.946]
 [4.411]] [[1.827]
 [1.845]
 [1.482]
 [1.278]
 [1.482]
 [1.482]
 [1.297]]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.39707885607372745, 0.20032841165907844, 0.33100226571893443, 0.07159046654825962]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.3808407830095918, 0.15606658526246828, 0.3808407830095918, 0.08225184871834802]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.3808407830095918, 0.15606658526246828, 0.3808407830095918, 0.08225184871834802]
line 256 mcts: sample exp_bonus 3.550820657909602
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.4119890892230554, 0.16878279461105128, 0.3303130676866865, 0.08891504847920685]
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
using explorer policy with actor:  1
siam score:  -0.78636855
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.4119890892230554, 0.16878279461105128, 0.3303130676866865, 0.08891504847920685]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
probs:  [0.3597302528910972, 0.18377082731962854, 0.3597302528910972, 0.09676866689817708]
siam score:  -0.7847635
maxi score, test score, baseline:  -0.9972753280839896 -1.0 -0.9972753280839896
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972821989528796 -1.0 -0.9972821989528796
probs:  [0.3587049323117391, 0.09703198147749262, 0.4472311047332757, 0.09703198147749262]
maxi score, test score, baseline:  -0.9972821989528796 -1.0 -0.9972821989528796
maxi score, test score, baseline:  -0.9972821989528796 -1.0 -0.9972821989528796
probs:  [0.36828516808664613, 0.13171483191335384, 0.36828516808664613, 0.13171483191335384]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972821989528796 -1.0 -0.9972821989528796
probs:  [0.1320646699714945, 0.24978280786366924, 0.368369714301167, 0.24978280786366924]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.251]
 [0.284]
 [0.266]
 [0.266]
 [0.266]
 [0.266]
 [0.266]] [[-0.276]
 [ 0.606]
 [-0.368]
 [-0.368]
 [-0.368]
 [-0.368]
 [-0.368]] [[0.251]
 [0.284]
 [0.266]
 [0.266]
 [0.266]
 [0.266]
 [0.266]]
maxi score, test score, baseline:  -0.9972821989528796 -1.0 -0.9972821989528796
probs:  [0.1497789530471288, 0.28340701565095705, 0.28340701565095705, 0.28340701565095705]
maxi score, test score, baseline:  -0.9972821989528796 -1.0 -0.9972821989528796
probs:  [0.1497789530471288, 0.28340701565095705, 0.28340701565095705, 0.28340701565095705]
836 511
maxi score, test score, baseline:  -0.9972890339425587 -1.0 -0.9972890339425587
probs:  [0.1322989272666494, 0.24978403472892802, 0.24978403472892802, 0.36813300327549453]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.771926
maxi score, test score, baseline:  -0.9972890339425587 -1.0 -0.9972890339425587
probs:  [0.20448201706395927, 0.38655394880812216, 0.20448201706395927, 0.20448201706395927]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.20448200346543502, 0.3865539896036949, 0.20448200346543502, 0.20448200346543502]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.28325699884087346, 0.15022900347737966, 0.28325699884087346, 0.28325699884087346]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.28325699884087346, 0.15022900347737966, 0.28325699884087346, 0.28325699884087346]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.22345860619178234, 0.11882059319249376, 0.32886040030786196, 0.32886040030786196]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.24978645685933615, 0.1327648157757446, 0.3676622705055832, 0.24978645685933615]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.24978645685933615, 0.1327648157757446, 0.3676622705055832, 0.24978645685933615]
Printing some Q and Qe and total Qs values:  [[1.289]
 [1.289]
 [1.289]
 [1.289]
 [1.289]
 [1.289]
 [1.289]] [[2.209]
 [2.209]
 [2.209]
 [2.209]
 [2.209]
 [2.209]
 [2.209]] [[2.67]
 [2.67]
 [2.67]
 [2.67]
 [2.67]
 [2.67]
 [2.67]]
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
maxi score, test score, baseline:  -0.9972958333333334 -1.0 -0.9972958333333334
probs:  [0.1734314878464066, 0.1734314878464066, 0.3265685121535934, 0.3265685121535934]
line 256 mcts: sample exp_bonus 3.2468042723949084
Printing some Q and Qe and total Qs values:  [[0.603]
 [0.436]
 [0.412]
 [0.536]
 [0.466]
 [0.516]
 [0.466]] [[4.48 ]
 [4.885]
 [3.54 ]
 [4.724]
 [4.336]
 [4.188]
 [5.263]] [[0.603]
 [0.436]
 [0.412]
 [0.536]
 [0.466]
 [0.516]
 [0.466]]
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 0.4521175052868891
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
probs:  [0.28310826717397164, 0.28310826717397164, 0.15067519847808514, 0.28310826717397164]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
probs:  [0.17362895799387662, 0.3263710420061234, 0.17362895799387662, 0.3263710420061234]
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
probs:  [0.17362895799387662, 0.3263710420061234, 0.17362895799387662, 0.3263710420061234]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.436]
 [0.436]
 [0.436]
 [0.637]
 [0.436]
 [0.436]
 [0.436]] [[2.766]
 [2.766]
 [2.766]
 [3.183]
 [2.766]
 [2.766]
 [2.766]] [[1.799]
 [1.799]
 [1.799]
 [2.121]
 [1.799]
 [1.799]
 [1.799]]
maxi score, test score, baseline:  -0.9973160206718347 -1.0 -0.9973160206718347
maxi score, test score, baseline:  -0.9973160206718347 -1.0 -0.9973160206718347
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.802]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]] [[2.045]
 [2.678]
 [2.045]
 [2.045]
 [2.045]
 [2.045]
 [2.045]] [[0.65 ]
 [0.802]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]]
siam score:  -0.77188873
maxi score, test score, baseline:  -0.9973160206718347 -1.0 -0.9973160206718347
maxi score, test score, baseline:  -0.9973160206718347 -1.0 -0.9973160206718347
probs:  [0.17402102670546837, 0.17402102670546837, 0.3259789732945316, 0.3259789732945316]
using another actor
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
probs:  [0.2051711542573213, 0.2051711542573213, 0.38448653722803605, 0.2051711542573213]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
probs:  [0.2051711542573213, 0.2051711542573213, 0.38448653722803605, 0.2051711542573213]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
probs:  [0.2051711542573213, 0.2051711542573213, 0.38448653722803605, 0.2051711542573213]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
maxi score, test score, baseline:  -0.9973293059125964 -1.0 -0.9973293059125964
probs:  [0.20517114093188568, 0.20517114093188568, 0.3844865772043431, 0.20517114093188568]
line 256 mcts: sample exp_bonus 1.8238852614364147
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
probs:  [0.24979117781931864, 0.24979117781931864, 0.36673159900191526, 0.13368604535944756]
maxi score, test score, baseline:  -0.9973424552429667 -1.0 -0.9973424552429667
probs:  [0.2712660920963948, 0.2712660920963948, 0.3581864103376593, 0.09928140546955115]
Printing some Q and Qe and total Qs values:  [[0.209]
 [0.133]
 [0.133]
 [0.133]
 [0.133]
 [0.133]
 [0.133]] [[1.751]
 [2.312]
 [2.312]
 [2.312]
 [2.312]
 [2.312]
 [2.312]] [[0.209]
 [0.133]
 [0.133]
 [0.133]
 [0.133]
 [0.133]
 [0.133]]
maxi score, test score, baseline:  -0.9973489795918368 -1.0 -0.9973489795918368
probs:  [0.29683123497144087, 0.3918425826065837, 0.20249612468602218, 0.10883005773595318]
850 540
siam score:  -0.7766991
maxi score, test score, baseline:  -0.9973489795918368 -1.0 -0.9973489795918368
probs:  [0.28274196064136065, 0.28274196064136065, 0.28274196064136065, 0.1517741180759182]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.690167923940865
Printing some Q and Qe and total Qs values:  [[0.728]
 [0.622]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.668]] [[4.24 ]
 [4.86 ]
 [4.24 ]
 [4.24 ]
 [4.24 ]
 [4.24 ]
 [5.599]] [[1.353]
 [1.599]
 [1.353]
 [1.353]
 [1.353]
 [1.353]
 [2.104]]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.2826696274351788, 0.2826696274351788, 0.15199111769446347, 0.2826696274351788]
from probs:  [0.2826696274351788, 0.2826696274351788, 0.15199111769446347, 0.2826696274351788]
855 544
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.32775315868500915, 0.22383834896010307, 0.12065533366987856, 0.32775315868500915]
from probs:  [0.32775315868500915, 0.22383834896010307, 0.12065533366987856, 0.32775315868500915]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.36551586485852516, 0.13448413514147484, 0.13448413514147484, 0.36551586485852516]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.36551586485852516, 0.13448413514147484, 0.13448413514147484, 0.36551586485852516]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.36551586485852516, 0.13448413514147484, 0.13448413514147484, 0.36551586485852516]
siam score:  -0.7816611
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.36551586485852516, 0.13448413514147484, 0.13448413514147484, 0.36551586485852516]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.36551586485852516, 0.13448413514147484, 0.13448413514147484, 0.36551586485852516]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.36551586485852516, 0.13448413514147484, 0.13448413514147484, 0.36551586485852516]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.36551586485852516, 0.13448413514147484, 0.13448413514147484, 0.36551586485852516]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.36551586485852516, 0.13448413514147484, 0.13448413514147484, 0.36551586485852516]
maxi score, test score, baseline:  -0.9973683544303797 -1.0 -0.9973683544303797
probs:  [0.39116162157305395, 0.10950072240175512, 0.20272651297253705, 0.2966111430526539]
859 546
Printing some Q and Qe and total Qs values:  [[0.776]
 [0.696]
 [0.776]
 [0.778]
 [0.776]
 [0.776]
 [0.776]] [[3.28 ]
 [3.354]
 [3.28 ]
 [2.512]
 [3.28 ]
 [3.28 ]
 [3.28 ]] [[1.688]
 [1.621]
 [1.688]
 [1.091]
 [1.688]
 [1.688]
 [1.688]]
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
probs:  [0.3276168388508912, 0.12088124932073456, 0.22388507297748303, 0.3276168388508912]
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
probs:  [0.24979685786419698, 0.13481840899913589, 0.24979685786419698, 0.36558787527247016]
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
probs:  [0.24979685786419698, 0.13481840899913589, 0.24979685786419698, 0.36558787527247016]
using another actor
Printing some Q and Qe and total Qs values:  [[0.478]
 [0.501]
 [0.478]
 [0.534]
 [0.478]
 [0.478]
 [0.501]] [[4.603]
 [4.505]
 [4.603]
 [5.3  ]
 [4.603]
 [4.603]
 [3.941]] [[1.356]
 [1.319]
 [1.356]
 [1.928]
 [1.356]
 [1.356]
 [0.92 ]]
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
probs:  [0.15228269559080346, 0.15228269559080346, 0.28226623095062614, 0.4131683778677669]
Printing some Q and Qe and total Qs values:  [[0.256]
 [0.256]
 [0.256]
 [0.256]
 [0.256]
 [0.256]
 [0.256]] [[3.864]
 [3.864]
 [3.864]
 [3.864]
 [3.864]
 [3.864]
 [3.864]] [[0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]]
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
probs:  [0.17498944126685645, 0.17498944126685645, 0.17498944126685645, 0.4750316761994306]
siam score:  -0.7798394
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.7830462
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
using explorer policy with actor:  0
siam score:  -0.7762075
actor:  1 policy actor:  1  step number:  120 total reward:  0.12499999999999933  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.9973811083123426 -1.0 -0.9973811083123426
probs:  [0.0041506585610374324, 0.9848570756913608, 0.006841607186564488, 0.0041506585610374324]
siam score:  -0.7765355
maxi score, test score, baseline:  -0.9973811083123426 -1.0 -0.9973811083123426
probs:  [0.006801341964492629, 0.9795773220856546, 0.009487232969426523, 0.004134102980426293]
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9973937343358396 -1.0 -0.9973937343358396
probs:  [0.006872438383270176, 0.9793638043952793, 0.009591223890337846, 0.004172533331112764]
maxi score, test score, baseline:  -0.9973937343358396 -1.0 -0.9973937343358396
probs:  [0.006908259736300007, 0.9792562252451716, 0.009643618349937055, 0.004191896668591094]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973937343358396 -1.0 -0.9973937343358396
probs:  [0.006944269752978671, 0.9791480794979572, 0.00969628876030559, 0.004211361988758291]
siam score:  -0.7751034
maxi score, test score, baseline:  -0.9974000000000001 -1.0 -0.9974000000000001
probs:  [0.006944276857973832, 0.9791480581564924, 0.009696299678371146, 0.0042113653071626685]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007016876206730178, 0.9789300268508518, 0.009802488376605278, 0.004250608565812595]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007090241285496794, 0.9787096958985867, 0.009909796554376854, 0.004290266261539481]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007127217491405572, 0.9785986484793513, 0.00996388017758958, 0.004310253851653517]
Printing some Q and Qe and total Qs values:  [[0.581]
 [1.007]
 [0.581]
 [0.644]
 [0.581]
 [0.581]
 [0.5  ]] [[1.65 ]
 [2.126]
 [1.65 ]
 [2.355]
 [1.65 ]
 [1.65 ]
 [2.269]] [[1.529]
 [2.16 ]
 [1.529]
 [1.851]
 [1.529]
 [1.529]
 [1.665]]
siam score:  -0.7710277
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007164391570352541, 0.9784870068052515, 0.010018253221811744, 0.004330348402584126]
UNIT TEST: sample policy line 217 mcts : [0.02  0.061 0.02  0.204 0.592 0.082 0.02 ]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007239339734882967, 0.9782619215093706, 0.010127876916058303, 0.004370861839688089]
siam score:  -0.7716822
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007239339734882967, 0.9782619215093706, 0.010127876916058303, 0.004370861839688089]
line 256 mcts: sample exp_bonus 2.740065307247441
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.00735328640620166, 0.9779197153941291, 0.010294542172443395, 0.0044324560272255556]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.00735328640620166, 0.9779197153941291, 0.010294542172443395, 0.0044324560272255556]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.00735328640620166, 0.9779197153941291, 0.010294542172443395, 0.0044324560272255556]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.00735328640620166, 0.9779197153941291, 0.010294542172443395, 0.0044324560272255556]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.00735328640620166, 0.9779197153941291, 0.010294542172443395, 0.0044324560272255556]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.00735328640620166, 0.9779197153941291, 0.010294542172443395, 0.0044324560272255556]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.397]
 [0.397]
 [0.397]
 [0.478]
 [0.397]
 [0.418]
 [0.397]] [[3.952]
 [3.952]
 [3.952]
 [4.432]
 [3.952]
 [4.317]
 [3.952]] [[1.107]
 [1.107]
 [1.107]
 [1.589]
 [1.107]
 [1.39 ]
 [1.107]]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.00735328640620166, 0.9779197153941291, 0.010294542172443395, 0.0044324560272255556]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007430286534825709, 0.9776884676131758, 0.01040716719281738, 0.004474078659181249]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007430286534825709, 0.9776884676131758, 0.01040716719281738, 0.004474078659181249]
Starting evaluation
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007469102400641875, 0.977571895303542, 0.010463941613282644, 0.0044950606825334095]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[-0.046]
 [-0.051]
 [-0.048]
 [-0.046]
 [-0.045]
 [-0.043]
 [-0.041]] [[3.032]
 [3.621]
 [3.188]
 [3.232]
 [3.156]
 [3.192]
 [3.188]] [[-0.512]
 [-0.131]
 [-0.413]
 [-0.38 ]
 [-0.428]
 [-0.399]
 [-0.399]]
Printing some Q and Qe and total Qs values:  [[0.326]
 [0.352]
 [0.341]
 [0.341]
 [0.341]
 [0.332]
 [0.336]] [[0.373]
 [0.663]
 [0.582]
 [0.582]
 [0.582]
 [0.312]
 [0.26 ]] [[0.326]
 [0.352]
 [0.341]
 [0.341]
 [0.341]
 [0.332]
 [0.336]]
Printing some Q and Qe and total Qs values:  [[0.338]
 [0.354]
 [0.389]
 [0.369]
 [0.389]
 [0.389]
 [0.386]] [[2.782]
 [2.949]
 [2.55 ]
 [2.635]
 [2.55 ]
 [2.55 ]
 [2.518]] [[0.338]
 [0.354]
 [0.389]
 [0.369]
 [0.389]
 [0.389]
 [0.386]]
using explorer policy with actor:  0
using explorer policy with actor:  1
868 576
line 256 mcts: sample exp_bonus 1.8815588626168733
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.5001901417673964
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.808]
 [0.739]
 [0.774]
 [0.825]
 [0.848]
 [0.847]
 [0.761]] [[2.749]
 [2.681]
 [3.32 ]
 [3.205]
 [3.187]
 [3.187]
 [3.34 ]] [[1.373]
 [1.188]
 [1.684]
 [1.709]
 [1.743]
 [1.741]
 [1.671]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.87890480611134
maxi score, test score, baseline:  -0.9975190476190476 -1.0 -0.9975190476190476
probs:  [0.007910681478163935, 0.9762457392372904, 0.011109832741528936, 0.004733746543016739]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997524703087886 -1.0 -0.997524703087886
probs:  [0.008163209819049147, 0.9754873428550793, 0.011479196858363506, 0.004870250467508064]
Printing some Q and Qe and total Qs values:  [[1.099]
 [1.417]
 [1.099]
 [1.099]
 [1.099]
 [1.099]
 [1.099]] [[1.989]
 [2.006]
 [1.989]
 [1.989]
 [1.989]
 [1.989]
 [1.989]] [[2.112]
 [2.76 ]
 [2.112]
 [2.112]
 [2.112]
 [2.112]
 [2.112]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.49 ]
 [0.732]
 [0.49 ]
 [0.49 ]
 [0.49 ]
 [0.49 ]
 [0.49 ]] [[1.54 ]
 [2.067]
 [1.54 ]
 [1.54 ]
 [1.54 ]
 [1.54 ]
 [1.54 ]] [[0.414]
 [1.247]
 [0.414]
 [0.414]
 [0.414]
 [0.414]
 [0.414]]
rdn probs:  [0.008249325371641414, 0.9752287195141139, 0.011605154790127904, 0.0049168003241167125]
maxi score, test score, baseline:  -0.9975303317535545 -1.0 -0.9975303317535545
probs:  [0.008292765501056868, 0.9750982595517769, 0.011668693588607976, 0.004940281358558375]
maxi score, test score, baseline:  -0.9975303317535545 -1.0 -0.9975303317535545
Printing some Q and Qe and total Qs values:  [[1.265]
 [0.775]
 [0.775]
 [0.775]
 [0.775]
 [0.775]
 [0.775]] [[2.041]
 [1.787]
 [1.787]
 [1.787]
 [1.787]
 [1.787]
 [1.787]] [[1.585]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]]
rdn beta is 0 so we're just using the maxi policy
first move QE:  2.059553842702061
maxi score, test score, baseline:  -0.9975303317535545 -1.0 -0.9975303317535545
probs:  [0.008336448963146403, 0.9749670688136055, 0.01173258772468594, 0.00496389449856214]
maxi score, test score, baseline:  -0.9975303317535545 -1.0 -0.9975303317535545
probs:  [0.008336448963146403, 0.9749670688136055, 0.01173258772468594, 0.00496389449856214]
Printing some Q and Qe and total Qs values:  [[0.363]
 [0.371]
 [0.375]
 [0.467]
 [0.357]
 [0.525]
 [0.648]] [[2.267]
 [2.707]
 [2.403]
 [2.3  ]
 [2.99 ]
 [1.995]
 [3.711]] [[0.685]
 [0.995]
 [0.801]
 [0.915]
 [1.156]
 [0.828]
 [2.217]]
maxi score, test score, baseline:  -0.9975359338061466 -1.0 -0.9975359338061466
probs:  [0.011818982047998108, 0.9679143695011475, 0.015261774349927187, 0.005004874100927364]
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
probs:  [0.011947543895973106, 0.9675687309165899, 0.01543123220941207, 0.005052492978024998]
siam score:  -0.7607427
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
probs:  [0.011947543895973106, 0.9675687309165899, 0.01543123220941207, 0.005052492978024998]
from probs:  [0.012209152221548485, 0.9668653960170639, 0.015776058317004384, 0.0051493934443832615]
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
probs:  [0.012342265247090057, 0.9665075211817006, 0.0159515146843292, 0.005198698886880088]
874 607
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
probs:  [0.012476953955022699, 0.966145410118711, 0.01612904795965925, 0.005248587966607008]
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
maxi score, test score, baseline:  -0.9975415094339622 -1.0 -0.9975415094339622
probs:  [0.012682003170266824, 0.9655941345853942, 0.01639932346638107, 0.0053245387779577305]
Printing some Q and Qe and total Qs values:  [[0.426]
 [0.386]
 [0.405]
 [0.403]
 [0.402]
 [0.401]
 [0.397]] [[3.439]
 [4.436]
 [3.749]
 [3.991]
 [4.28 ]
 [4.282]
 [3.527]] [[0.426]
 [0.386]
 [0.405]
 [0.403]
 [0.402]
 [0.401]
 [0.397]]
Printing some Q and Qe and total Qs values:  [[0.714]
 [0.694]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]] [[3.577]
 [3.94 ]
 [3.577]
 [3.577]
 [3.577]
 [3.577]
 [3.577]] [[1.968]
 [2.088]
 [1.968]
 [1.968]
 [1.968]
 [1.968]
 [1.968]]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.01296121661442497, 0.9648434691278623, 0.016767355775762383, 0.005427958481950463]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
Printing some Q and Qe and total Qs values:  [[0.243]
 [0.568]
 [0.616]
 [0.616]
 [0.616]
 [0.654]
 [0.616]] [[ 2.578]
 [ 0.965]
 [ 0.063]
 [ 0.063]
 [ 0.063]
 [-0.619]
 [ 0.063]] [[1.349]
 [1.049]
 [0.692]
 [0.692]
 [0.692]
 [0.423]
 [0.692]]
Printing some Q and Qe and total Qs values:  [[0.837]
 [0.851]
 [0.837]
 [0.837]
 [0.837]
 [0.837]
 [0.837]] [[2.686]
 [3.285]
 [2.686]
 [2.686]
 [2.686]
 [2.686]
 [2.686]] [[2.039]
 [2.316]
 [2.039]
 [2.039]
 [2.039]
 [2.039]
 [2.039]]
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.013614746267362293, 0.9630864524143622, 0.017628773693346915, 0.005670027624928696]
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.013689623385981191, 0.96288514502413, 0.017727469278628387, 0.0056977623112605055]
line 256 mcts: sample exp_bonus 3.8082164311785287
Printing some Q and Qe and total Qs values:  [[0.51 ]
 [0.254]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]] [[1.924]
 [2.347]
 [1.924]
 [1.924]
 [1.924]
 [1.924]
 [1.924]] [[1.668]
 [1.439]
 [1.668]
 [1.668]
 [1.668]
 [1.668]
 [1.668]]
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
probs:  [0.013689623385981191, 0.96288514502413, 0.017727469278628387, 0.0056977623112605055]
maxi score, test score, baseline:  -0.9975525821596244 -1.0 -0.9975525821596244
Printing some Q and Qe and total Qs values:  [[0.402]
 [0.39 ]
 [0.415]
 [0.418]
 [0.416]
 [0.416]
 [0.418]] [[3.669]
 [3.912]
 [3.752]
 [3.808]
 [3.876]
 [4.071]
 [3.501]] [[0.553]
 [0.691]
 [0.633]
 [0.678]
 [0.718]
 [0.848]
 [0.473]]
Printing some Q and Qe and total Qs values:  [[0.482]
 [0.494]
 [0.481]
 [0.486]
 [0.481]
 [0.481]
 [0.481]] [[5.526]
 [5.559]
 [5.955]
 [5.628]
 [5.955]
 [5.955]
 [5.955]] [[0.482]
 [0.494]
 [0.481]
 [0.486]
 [0.481]
 [0.481]
 [0.481]]
maxi score, test score, baseline:  -0.9975580796252927 -1.0 -0.9975580796252927
probs:  [0.01399387484658428, 0.9620671643952227, 0.018128503829651088, 0.005810456928541953]
maxi score, test score, baseline:  -0.9975580796252927 -1.0 -0.9975580796252927
878 632
siam score:  -0.7555039
maxi score, test score, baseline:  -0.9975580796252927 -1.0 -0.9975580796252927
probs:  [0.014707302564945759, 0.9601491115529869, 0.019068873457600426, 0.00607471242446707]
start point for exploration sampling:  10723
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.7603749
siam score:  -0.75960726
line 256 mcts: sample exp_bonus 5.2489540657266
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.015151758150351479, 0.9589485122113165, 0.01964858255911077, 0.0062511470792212245]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.015151758150351479, 0.9589485122113165, 0.01964858255911077, 0.0062511470792212245]
using another actor
maxi score, test score, baseline:  -0.9975798143851509 -1.0 -0.9975798143851509
probs:  [0.015236290069238203, 0.9587212144517888, 0.019759968066618446, 0.006282527412354717]
883 649
maxi score, test score, baseline:  -0.9975798143851509 -1.0 -0.9975798143851509
probs:  [0.015580006104113687, 0.957796994845807, 0.020212871652926626, 0.006410127397152706]
maxi score, test score, baseline:  -0.9975798143851509 -1.0 -0.9975798143851509
probs:  [0.015755345151685987, 0.9573255248850898, 0.020443910287752567, 0.0064752196754715025]
using another actor
maxi score, test score, baseline:  -0.9975905311778291 -1.0 -0.9975905311778291
maxi score, test score, baseline:  -0.9975958525345622 -1.0 -0.9975958525345622
probs:  [0.016022903533386645, 0.9566060875183766, 0.02079646499245593, 0.0065745439557809695]
siam score:  -0.758876
siam score:  -0.75862664
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
Printing some Q and Qe and total Qs values:  [[0.798]
 [0.696]
 [0.696]
 [0.696]
 [0.696]
 [0.696]
 [0.696]] [[2.774]
 [2.4  ]
 [2.4  ]
 [2.4  ]
 [2.4  ]
 [2.4  ]
 [2.4  ]] [[1.271]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.817]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.016558051303133682, 0.9601106914323224, 0.016558051303133682, 0.0067732059614103255]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.016558051303133682, 0.9601106914323224, 0.016558051303133682, 0.0067732059614103255]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.0166525404057115, 0.9598866354569374, 0.0166525404057115, 0.006808283731639535]
Printing some Q and Qe and total Qs values:  [[0.712]
 [0.584]
 [0.584]
 [0.642]
 [0.584]
 [0.584]
 [0.584]] [[4.431]
 [4.464]
 [4.464]
 [3.277]
 [4.464]
 [4.464]
 [4.464]] [[2.285]
 [2.051]
 [2.051]
 [1.375]
 [2.051]
 [2.051]
 [2.051]]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.01694003202296777, 0.9592049249425819, 0.01694003202296777, 0.0069150110114825445]
888 669
Printing some Q and Qe and total Qs values:  [[0.343]
 [0.498]
 [0.256]
 [0.256]
 [0.256]
 [0.256]
 [0.263]] [[2.273]
 [2.104]
 [1.811]
 [1.811]
 [1.811]
 [1.811]
 [2.187]] [[0.343]
 [0.498]
 [0.256]
 [0.256]
 [0.256]
 [0.256]
 [0.263]]
line 256 mcts: sample exp_bonus 2.0034227006222047
line 256 mcts: sample exp_bonus 3.9232993565523757
first move QE:  1.9827907845610495
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
first move QE:  1.9824863004036266
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
probs:  [0.017433084061053504, 0.9580357843883465, 0.017433084061053504, 0.007098047489546721]
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
probs:  [0.017433084061053504, 0.9580357843883465, 0.017433084061053504, 0.007098047489546721]
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
890 674
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
probs:  [0.01237625942674644, 0.9628350516975284, 0.01762091265046412, 0.007167776225261071]
line 256 mcts: sample exp_bonus 3.2600178307628087
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.8  ]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]] [[0.862]
 [1.711]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]] [[1.955]
 [2.554]
 [1.955]
 [1.955]
 [1.955]
 [1.955]
 [1.955]]
using another actor
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9976324263038548 -1.0 -0.9976324263038548
probs:  [0.012805365894531455, 0.961546368451804, 0.018247776261756637, 0.007400489391907861]
maxi score, test score, baseline:  -0.9976324263038548 -1.0 -0.9976324263038548
probs:  [0.012952708497453856, 0.9611038723414516, 0.018463022594563477, 0.007480396566531093]
maxi score, test score, baseline:  -0.997637556561086 -1.0 -0.997637556561086
probs:  [0.013027233796858785, 0.9608800595721283, 0.018571894204639904, 0.007520812426372982]
using explorer policy with actor:  1
from probs:  [0.013027233796858785, 0.9608800595721283, 0.018571894204639904, 0.007520812426372982]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.997637556561086 -1.0 -0.997637556561086
probs:  [0.01317795320124229, 0.9604274223247694, 0.01879207356925786, 0.007602550904730487]
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
probs:  [0.013254196369555927, 0.9601984504886634, 0.018903454756546905, 0.007643898385233813]
894 686
maxi score, test score, baseline:  -0.9976528089887641 -1.0 -0.9976528089887641
probs:  [0.013486449894214611, 0.9595009517265966, 0.01924274555434428, 0.00776985282484453]
Printing some Q and Qe and total Qs values:  [[0.438]
 [0.467]
 [0.601]
 [0.562]
 [0.433]
 [0.658]
 [0.504]] [[ 2.066]
 [ 1.64 ]
 [ 0.3  ]
 [ 1.371]
 [ 1.693]
 [-0.348]
 [ 1.652]] [[1.959]
 [1.734]
 [1.11 ]
 [1.745]
 [1.702]
 [0.793]
 [1.816]]
maxi score, test score, baseline:  -0.9976528089887641 -1.0 -0.9976528089887641
probs:  [0.013486449894214611, 0.9595009517265966, 0.01924274555434428, 0.00776985282484453]
Printing some Q and Qe and total Qs values:  [[0.806]
 [1.204]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]] [[1.687]
 [2.147]
 [1.687]
 [1.687]
 [1.687]
 [1.687]
 [1.687]] [[0.897]
 [2.   ]
 [0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.897]]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.013644300181418238, 0.9590268991600934, 0.01947334305094896, 0.007855457607539383]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.013644300181418238, 0.9590268991600934, 0.01947334305094896, 0.007855457607539383]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.013644300181418238, 0.9590268991600934, 0.01947334305094896, 0.007855457607539383]
from probs:  [0.013644300181418238, 0.9590268991600934, 0.01947334305094896, 0.007855457607539383]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.013644319174535131, 0.9590268421141698, 0.019473371697118335, 0.007855467014176727]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.014216671900914357, 0.9573079648145948, 0.02030949688693832, 0.008165866397552613]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.014301070698848969, 0.9570545001743558, 0.02043279141790045, 0.008211637708894675]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.01455843790748048, 0.9562815805397502, 0.020808769889708832, 0.008351211663060446]
Printing some Q and Qe and total Qs values:  [[0.34 ]
 [0.374]
 [0.331]
 [0.33 ]
 [0.333]
 [0.329]
 [0.342]] [[-1.59 ]
 [-0.906]
 [-2.154]
 [-2.124]
 [-1.991]
 [-1.947]
 [-1.586]] [[0.34 ]
 [0.374]
 [0.331]
 [0.33 ]
 [0.333]
 [0.329]
 [0.342]]
Printing some Q and Qe and total Qs values:  [[0.488]
 [0.509]
 [0.6  ]
 [0.629]
 [0.392]
 [0.665]
 [0.543]] [[ 1.651]
 [ 0.131]
 [-1.094]
 [-0.373]
 [ 2.078]
 [-1.173]
 [ 0.447]] [[2.284]
 [1.346]
 [0.732]
 [1.252]
 [2.373]
 [0.805]
 [1.614]]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
probs:  [0.015001591383487771, 0.9549507116274925, 0.021456153579906843, 0.008591543409113155]
maxi score, test score, baseline:  -0.9976728285077952 -1.0 -0.9976728285077952
maxi score, test score, baseline:  -0.9976777777777778 -1.0 -0.9976777777777778
probs:  [0.015001613662442083, 0.9549506447130389, 0.02145618710949092, 0.008591554515028126]
Printing some Q and Qe and total Qs values:  [[0.334]
 [0.372]
 [0.334]
 [0.415]
 [0.334]
 [0.334]
 [0.339]] [[4.206]
 [4.218]
 [4.206]
 [3.919]
 [4.206]
 [4.206]
 [4.511]] [[0.334]
 [0.372]
 [0.334]
 [0.415]
 [0.334]
 [0.334]
 [0.339]]
maxi score, test score, baseline:  -0.9976777777777778 -1.0 -0.9976777777777778
probs:  [0.015092466633739025, 0.954677797039149, 0.021588910280659658, 0.008640826046452445]
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
probs:  [0.015369685139830686, 0.9538452604173667, 0.02199388879531049, 0.008791165647491998]
maxi score, test score, baseline:  -0.9976973568281938 -1.0 -0.9976973568281938
probs:  [0.016049874419502327, 0.9587402063159516, 0.016049874419502327, 0.009160044845043767]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976973568281938 -1.0 -0.9976973568281938
maxi score, test score, baseline:  -0.9976973568281938 -1.0 -0.9976973568281938
probs:  [0.01656047584331465, 0.9574420934130405, 0.01656047584331465, 0.009436954900330313]
Printing some Q and Qe and total Qs values:  [[1.436]
 [1.436]
 [1.436]
 [1.436]
 [1.436]
 [1.436]
 [1.436]] [[1.94]
 [1.94]
 [1.94]
 [1.94]
 [1.94]
 [1.94]
 [1.94]] [[2.405]
 [2.405]
 [2.405]
 [2.405]
 [2.405]
 [2.405]
 [2.405]]
Printing some Q and Qe and total Qs values:  [[0.567]
 [0.379]
 [0.668]
 [0.645]
 [0.657]
 [1.007]
 [0.672]] [[1.911]
 [2.107]
 [1.165]
 [1.255]
 [1.522]
 [1.249]
 [1.307]] [[1.478]
 [1.287]
 [1.249]
 [1.259]
 [1.416]
 [1.82 ]
 [1.328]]
siam score:  -0.75227755
maxi score, test score, baseline:  -0.9976973568281938 -1.0 -0.9976973568281938
probs:  [0.017094508757762934, 0.9560844101311401, 0.017094508757762934, 0.009726572353334269]
Printing some Q and Qe and total Qs values:  [[0.299]
 [0.321]
 [0.299]
 [0.299]
 [0.299]
 [0.299]
 [0.299]] [[0.621]
 [1.899]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]] [[0.299]
 [0.321]
 [0.299]
 [0.299]
 [0.299]
 [0.299]
 [0.299]]
Printing some Q and Qe and total Qs values:  [[0.546]
 [0.546]
 [0.546]
 [1.061]
 [0.546]
 [0.546]
 [0.546]] [[1.848]
 [1.848]
 [1.848]
 [2.264]
 [1.848]
 [1.848]
 [1.848]] [[1.128]
 [1.128]
 [1.128]
 [2.316]
 [1.128]
 [1.128]
 [1.128]]
maxi score, test score, baseline:  -0.9977165938864629 -1.0 -0.9977165938864629
probs:  [0.009913099470560767, 0.9627353420376228, 0.01743845902125576, 0.009913099470560767]
maxi score, test score, baseline:  -0.9977165938864629 -1.0 -0.9977165938864629
maxi score, test score, baseline:  -0.9977213507625272 -1.0 -0.9977213507625272
probs:  [0.010036815765062582, 0.9622597836843959, 0.017666584785479, 0.010036815765062582]
maxi score, test score, baseline:  -0.9977213507625272 -1.0 -0.9977213507625272
probs:  [0.010099548108679813, 0.9620186451770186, 0.017782258605621683, 0.010099548108679813]
maxi score, test score, baseline:  -0.9977213507625272 -1.0 -0.9977213507625272
probs:  [0.010099548108679813, 0.9620186451770186, 0.017782258605621683, 0.010099548108679813]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
probs:  [0.010162894182057925, 0.9617751454585254, 0.017899066177358862, 0.010162894182057925]
using explorer policy with actor:  0
siam score:  -0.75742567
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
probs:  [0.010162894182057925, 0.9617751454585254, 0.017899066177358862, 0.010162894182057925]
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
probs:  [0.010226832882632497, 0.9615293697893744, 0.018016964445360554, 0.010226832882632497]
maxi score, test score, baseline:  -0.9977308026030369 -1.0 -0.9977308026030369
probs:  [0.010422397662023216, 0.9607776310116027, 0.018377573664350746, 0.010422397662023216]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.01055598269336127, 0.9602641377824016, 0.018623896830875977, 0.01055598269336127]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.010623756653298568, 0.9600036196273903, 0.018748867066012396, 0.010623756653298568]
Printing some Q and Qe and total Qs values:  [[1.248]
 [1.38 ]
 [1.248]
 [1.389]
 [1.248]
 [1.248]
 [1.248]] [[2.113]
 [2.031]
 [2.113]
 [2.331]
 [2.113]
 [2.113]
 [2.113]] [[2.581]
 [2.784]
 [2.581]
 [2.994]
 [2.581]
 [2.581]
 [2.581]]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
Printing some Q and Qe and total Qs values:  [[0.457]
 [0.499]
 [0.463]
 [0.508]
 [0.553]
 [0.536]
 [0.536]] [[2.798]
 [3.198]
 [2.842]
 [2.682]
 [2.711]
 [2.903]
 [2.799]] [[0.424]
 [0.775]
 [0.467]
 [0.449]
 [0.559]
 [0.652]
 [0.584]]
maxi score, test score, baseline:  -0.9977401727861771 -1.0 -0.9977401727861771
probs:  [0.010831171235826305, 0.9592063309100892, 0.01913132661825826, 0.010831171235826305]
Printing some Q and Qe and total Qs values:  [[0.202]
 [0.12 ]
 [0.181]
 [0.214]
 [0.22 ]
 [0.272]
 [0.293]] [[-2.347]
 [ 0.641]
 [-2.292]
 [-2.597]
 [-2.302]
 [-2.415]
 [-1.729]] [[0.202]
 [0.12 ]
 [0.181]
 [0.214]
 [0.22 ]
 [0.272]
 [0.293]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.01090171383250802, 0.9589351680937613, 0.01926140424122253, 0.01090171383250802]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.011117619783267262, 0.9581052412820898, 0.019659519151375718, 0.011117619783267262]
913 751
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.011191068258407945, 0.9578229106720195, 0.019794952811164574, 0.011191068258407945]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.011340254120822547, 0.9572494510396896, 0.02007004071866528, 0.011340254120822547]
siam score:  -0.76506585
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.01156993634372403, 0.9563665692373128, 0.020493558075239223, 0.01156993634372403]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.01156993634372403, 0.9563665692373128, 0.020493558075239223, 0.01156993634372403]
Printing some Q and Qe and total Qs values:  [[1.091]
 [1.091]
 [1.091]
 [1.303]
 [1.091]
 [1.091]
 [1.091]] [[2.21 ]
 [2.21 ]
 [2.21 ]
 [3.026]
 [2.21 ]
 [2.21 ]
 [2.21 ]] [[1.811]
 [1.811]
 [1.811]
 [2.515]
 [1.811]
 [1.811]
 [1.811]]
Printing some Q and Qe and total Qs values:  [[0.612]
 [0.832]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.612]] [[1.855]
 [2.595]
 [1.855]
 [1.855]
 [1.855]
 [1.855]
 [1.855]] [[1.076]
 [2.009]
 [1.076]
 [1.076]
 [1.076]
 [1.076]
 [1.076]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.011648121432443021, 0.9560660314282682, 0.020637725706845963, 0.011648121432443021]
Printing some Q and Qe and total Qs values:  [[0.304]
 [0.304]
 [0.304]
 [0.304]
 [0.304]
 [0.304]
 [0.304]] [[-1.09]
 [-1.09]
 [-1.09]
 [-1.09]
 [-1.09]
 [-1.09]
 [-1.09]] [[0.304]
 [0.304]
 [0.304]
 [0.304]
 [0.304]
 [0.304]
 [0.304]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.011648121432443021, 0.9560660314282682, 0.020637725706845963, 0.011648121432443021]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.011648121432443021, 0.9560660314282682, 0.020637725706845963, 0.011648121432443021]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9977494623655914 -1.0 -0.9977494623655914
probs:  [0.011648140646174036, 0.9560659552079772, 0.020637763499674708, 0.011648140646174036]
maxi score, test score, baseline:  -0.9977540772532189 -1.0 -0.9977540772532189
probs:  [0.01180704590041499, 0.9554551325142606, 0.020930775684909503, 0.01180704590041499]
916 759
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.011887793372362308, 0.9551447426576685, 0.021079670597606903, 0.011887793372362308]
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.01196939622179988, 0.954831067170267, 0.021230140386133158, 0.01196939622179988]
using explorer policy with actor:  0
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 5.758602375390025
maxi score, test score, baseline:  -0.9977632478632479 -1.0 -0.9977632478632479
probs:  [0.012219619927216967, 0.9538692227744398, 0.02169153737112627, 0.012219619927216967]
maxi score, test score, baseline:  -0.9977632478632479 -1.0 -0.9977632478632479
probs:  [0.012304869059578581, 0.953541531218906, 0.021848730661936846, 0.012304869059578581]
from probs:  [0.012304869059578581, 0.953541531218906, 0.021848730661936846, 0.012304869059578581]
maxi score, test score, baseline:  -0.9977632478632479 -1.0 -0.9977632478632479
probs:  [0.012478232338483351, 0.9528751351986419, 0.02216840012439129, 0.012478232338483351]
maxi score, test score, baseline:  -0.997767803837953 -1.0 -0.997767803837953
probs:  [0.012655546119172618, 0.9521935511890758, 0.022495356572578902, 0.012655546119172618]
using another actor
using explorer policy with actor:  0
from probs:  [0.013116864169690452, 0.9504202775619846, 0.023345994098634602, 0.013116864169690452]
maxi score, test score, baseline:  -0.997772340425532 -1.0 -0.997772340425532
probs:  [0.013212398185506407, 0.9500530489770109, 0.02352215465197627, 0.013212398185506407]
maxi score, test score, baseline:  -0.997772340425532 -1.0 -0.997772340425532
probs:  [0.013212398185506407, 0.9500530489770109, 0.02352215465197627, 0.013212398185506407]
maxi score, test score, baseline:  -0.997772340425532 -1.0 -0.997772340425532
using another actor
maxi score, test score, baseline:  -0.997772340425532 -1.0 -0.997772340425532
probs:  [0.33034386355915935, 0.004725866657365746, 0.3345864062243155, 0.33034386355915935]
maxi score, test score, baseline:  -0.9977813559322034 -1.0 -0.9977813559322034
maxi score, test score, baseline:  -0.9977813559322034 -1.0 -0.9977813559322034
probs:  [0.3303438812186319, 0.0047258366623326685, 0.3345864009004035, 0.3303438812186319]
line 256 mcts: sample exp_bonus -3.143487272050903
maxi score, test score, baseline:  -0.9977858350951374 -1.0 -0.9977858350951374
probs:  [0.33034388999216685, 0.004725821760278969, 0.33458639825538733, 0.33034388999216685]
siam score:  -0.74764633
maxi score, test score, baseline:  -0.9977858350951374 -1.0 -0.9977858350951374
maxi score, test score, baseline:  -0.9977858350951374 -1.0 -0.9977858350951374
probs:  [0.3317527410842813, 0.0047417767471560355, 0.3317527410842813, 0.3317527410842813]
maxi score, test score, baseline:  -0.9977858350951374 -1.0 -0.9977858350951374
probs:  [0.33316388955252746, 0.004757757751407281, 0.3289144631435378, 0.33316388955252746]
maxi score, test score, baseline:  -0.9977902953586498 -1.0 -0.9977902953586498
probs:  [0.3345486844004752, 0.004822375697224532, 0.3217578282514722, 0.3388711116508281]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
probs:  [0.3360025046332164, 0.004839022384968418, 0.3231559683485988, 0.3360025046332164]
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
probs:  [0.3374293222491424, 0.004855390035996519, 0.32028596546571864, 0.3374293222491424]
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
probs:  [0.3433113794042182, 0.00492286569495041, 0.32158118612848496, 0.33018456877234653]
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
probs:  [0.3447811546754836, 0.0049397261320947876, 0.31868113680743315, 0.33159798238498855]
Printing some Q and Qe and total Qs values:  [[0.4  ]
 [0.517]
 [0.517]
 [0.619]
 [0.237]
 [0.588]
 [0.517]] [[2.179]
 [2.044]
 [2.044]
 [0.466]
 [2.33 ]
 [1.155]
 [2.044]] [[1.851]
 [1.889]
 [1.889]
 [0.541]
 [1.763]
 [1.15 ]
 [1.889]]
from probs:  [0.3447811546754836, 0.0049397261320947876, 0.31868113680743315, 0.33159798238498855]
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
probs:  [0.34778954822528696, 0.004974236734731561, 0.3214611344303738, 0.3257750806096078]
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
probs:  [0.3492981149606295, 0.004991542165783915, 0.32285517143679326, 0.32285517143679326]
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
926 795
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.35080950852702003, 0.005008848075373789, 0.32425196415212904, 0.31992967924547716]
Printing some Q and Qe and total Qs values:  [[1.459]
 [1.459]
 [1.459]
 [1.459]
 [1.459]
 [1.459]
 [1.459]] [[1.836]
 [1.836]
 [1.836]
 [1.836]
 [1.836]
 [1.836]
 [1.836]] [[2.435]
 [2.435]
 [2.435]
 [2.435]
 [2.435]
 [2.435]
 [2.435]]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.35091596727721713, 0.0050624031204965616, 0.3198354785838715, 0.3241861510184148]
928 798
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.34500402422959675, 0.0050996116003573485, 0.32275294098654767, 0.3271434231834982]
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.658]
 [0.685]
 [0.686]
 [0.683]
 [0.692]
 [0.681]] [[-2.62 ]
 [ 0.14 ]
 [-2.749]
 [-2.739]
 [-2.627]
 [-2.51 ]
 [-2.838]] [[0.585]
 [1.955]
 [0.523]
 [0.529]
 [0.583]
 [0.648]
 [0.475]]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.34959343419768363, 0.005154357659727488, 0.32262610407129444, 0.32262610407129444]
line 256 mcts: sample exp_bonus -2.8117607729139658
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
Printing some Q and Qe and total Qs values:  [[0.506]
 [0.508]
 [0.52 ]
 [0.515]
 [0.518]
 [0.519]
 [0.521]] [[5.345]
 [5.236]
 [5.429]
 [5.556]
 [5.601]
 [5.503]
 [5.472]] [[0.506]
 [0.508]
 [0.52 ]
 [0.515]
 [0.518]
 [0.519]
 [0.521]]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.3526833563122384, 0.005191216659186852, 0.3254769912838019, 0.3166484357447728]
maxi score, test score, baseline:  -0.9978123173277662 -1.0 -0.9978123173277662
probs:  [0.3542333199034445, 0.005209688713176627, 0.3269071267131078, 0.3136498646702711]
maxi score, test score, baseline:  -0.9978166666666667 -1.0 -0.9978166666666667
maxi score, test score, baseline:  -0.9978166666666667 -1.0 -0.9978166666666667
probs:  [0.3575460005347317, 0.0053056948436402355, 0.3252647605897989, 0.31188354403182916]
maxi score, test score, baseline:  -0.9978166666666667 -1.0 -0.9978166666666667
probs:  [0.3591288430425342, 0.005324826924033599, 0.32670429606914375, 0.3088420339642885]
maxi score, test score, baseline:  -0.9978166666666667 -1.0 -0.9978166666666667
maxi score, test score, baseline:  -0.9978166666666667 -1.0 -0.9978166666666667
probs:  [0.36235878512498826, 0.005363867770664134, 0.3250913543886678, 0.30718599271567987]
Printing some Q and Qe and total Qs values:  [[1.271]
 [1.27 ]
 [1.27 ]
 [1.271]
 [1.271]
 [1.27 ]
 [1.27 ]] [[1.799]
 [1.821]
 [1.821]
 [1.777]
 [1.799]
 [1.821]
 [1.821]] [[2.071]
 [2.078]
 [2.078]
 [2.065]
 [2.072]
 [2.078]
 [2.078]]
first move QE:  1.8164530690946976
Printing some Q and Qe and total Qs values:  [[0.651]
 [0.66 ]
 [0.651]
 [0.651]
 [0.651]
 [0.651]
 [0.692]] [[2.289]
 [2.822]
 [2.289]
 [2.289]
 [2.289]
 [2.289]
 [2.132]] [[1.168]
 [1.364]
 [1.168]
 [1.168]
 [1.168]
 [1.168]
 [1.197]]
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
probs:  [0.3563507333303706, 0.005467042469951023, 0.3327483902384595, 0.305433833961219]
first move QE:  1.8138676432107894
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
line 256 mcts: sample exp_bonus 2.419978606477383
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
probs:  [0.36836267503445635, 0.005745622867454249, 0.3339488584550824, 0.2919428436430069]
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
probs:  [0.3736251298266541, 0.0058136600481213776, 0.3290354606552228, 0.29152574947000176]
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
probs:  [0.3725335257321102, 0.005933896747352732, 0.3274256328478512, 0.29410694467268583]
934 838
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
probs:  [0.3797291816566672, 0.0060295298674989456, 0.3238886634757624, 0.2903526250000714]
934 840
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.37832129030041967, 0.0060812061914578275, 0.3222726708190059, 0.29332483268911674]
Printing some Q and Qe and total Qs values:  [[0.208]
 [0.287]
 [0.651]
 [0.573]
 [0.483]
 [0.664]
 [0.416]] [[ 3.103]
 [ 2.73 ]
 [ 0.506]
 [ 2.479]
 [ 2.934]
 [-0.304]
 [ 1.827]] [[0.868]
 [0.902]
 [0.887]
 [1.39 ]
 [1.362]
 [0.643]
 [0.858]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.37832129030041967, 0.0060812061914578275, 0.3222726708190059, 0.29332483268911674]
Printing some Q and Qe and total Qs values:  [[1.025]
 [1.275]
 [1.195]
 [1.039]
 [1.195]
 [1.057]
 [1.075]] [[1.888]
 [1.824]
 [1.999]
 [1.915]
 [1.999]
 [1.985]
 [1.82 ]] [[2.249]
 [2.728]
 [2.626]
 [2.286]
 [2.626]
 [2.346]
 [2.327]]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.37173490572128387, 0.006135315697710104, 0.32569283791610615, 0.2964369406648999]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.37173490572128387, 0.006135315697710104, 0.32569283791610615, 0.2964369406648999]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.3702680950587247, 0.006188506125801096, 0.3240487207172036, 0.2994946780982707]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.3705875801358484, 0.006268230141392295, 0.32395945571141516, 0.2991847340113441]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.3709622352978409, 0.006350584069733924, 0.31884462898220167, 0.30384255165022345]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.37280578948746596, 0.006377266063925564, 0.3204284793760529, 0.3003884650725556]
using another actor
siam score:  -0.7389866
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.399]
 [0.406]
 [0.397]
 [0.393]
 [0.393]
 [0.394]
 [0.424]] [[-1.015]
 [ 0.281]
 [-2.254]
 [-1.429]
 [-1.946]
 [-2.027]
 [ 0.288]] [[0.399]
 [0.406]
 [0.397]
 [0.393]
 [0.393]
 [0.394]
 [0.424]]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.3731975839013946, 0.006462181914668711, 0.3152273716347138, 0.3051128625492228]
line 256 mcts: sample exp_bonus 1.0572865597760834
Printing some Q and Qe and total Qs values:  [[0.68 ]
 [0.565]
 [0.68 ]
 [0.659]
 [0.68 ]
 [0.68 ]
 [0.68 ]] [[-1.488]
 [-0.675]
 [-1.488]
 [-0.003]
 [-1.488]
 [-1.488]
 [-1.488]] [[1.634]
 [1.675]
 [1.634]
 [2.087]
 [1.634]
 [1.634]
 [1.634]]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.3716700586256669, 0.006520493221364354, 0.3134523645566368, 0.308357083596332]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.3682214281735401, 0.0065509595643257704, 0.31517549631847774, 0.31005211594365634]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.37012015620316085, 0.0065796812344992035, 0.31165008128116994, 0.31165008128116994]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.3685473625176216, 0.006639765876764915, 0.314992964027116, 0.30981990757849753]
UNIT TEST: sample policy line 217 mcts : [0.02  0.878 0.02  0.02  0.02  0.02  0.02 ]
siam score:  -0.73615843
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.37081025511744387, 0.006760926007577898, 0.3164497447442042, 0.3059790741307741]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.37277043564274237, 0.006791482603984035, 0.31284246129225923, 0.3075956204610143]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.38273931747212464, 0.006946884157437677, 0.3104624043029383, 0.2998513940674994]
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.3755591403759933, 0.007016443316170785, 0.3140797288396059, 0.30334468746823]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
maxi score, test score, baseline:  -0.9978296066252588 -1.0 -0.9978296066252588
probs:  [0.3775948343156038, 0.007049163428567039, 0.3103680954792182, 0.3049879067766109]
Printing some Q and Qe and total Qs values:  [[0.71 ]
 [0.741]
 [0.71 ]
 [0.71 ]
 [0.71 ]
 [0.71 ]
 [0.71 ]] [[1.339]
 [1.301]
 [1.339]
 [1.339]
 [1.339]
 [1.339]
 [1.339]] [[2.397]
 [2.44 ]
 [2.397]
 [2.397]
 [2.397]
 [2.397]
 [2.397]]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.37962746625639227, 0.007081804327680515, 0.3120381308322317, 0.3012525985836956]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.37962746625639227, 0.007081804327680515, 0.3120381308322317, 0.3012525985836956]
Printing some Q and Qe and total Qs values:  [[0.397]
 [0.379]
 [0.364]
 [0.405]
 [0.386]
 [0.456]
 [0.407]] [[0.493]
 [0.458]
 [0.706]
 [0.615]
 [0.818]
 [0.887]
 [0.798]] [[0.206]
 [0.16 ]
 [0.212]
 [0.265]
 [0.294]
 [0.456]
 [0.329]]
946 868
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.3723395826869075, 0.007153643705306069, 0.3157098115598999, 0.3047969620478866]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.37525073949451065, 0.007402204937985419, 0.3170603109359431, 0.30028674463156085]
Printing some Q and Qe and total Qs values:  [[0.179]
 [0.179]
 [0.179]
 [0.179]
 [0.179]
 [0.179]
 [0.179]] [[-4.318]
 [-4.318]
 [-4.318]
 [-4.318]
 [-4.318]
 [-4.318]
 [-4.318]] [[0.179]
 [0.179]
 [0.179]
 [0.179]
 [0.179]
 [0.179]
 [0.179]]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.37786586316042375, 0.0075517664099699995, 0.3129612572566306, 0.30162111317297563]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.38000408258268603, 0.0075889613012398915, 0.31473123207147763, 0.2976757240445964]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
948 880
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.36849239138123946, 0.0077119677568915305, 0.32058467917493055, 0.3032109616869384]
siam score:  -0.7518921
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.36460796638782983, 0.00775347419954384, 0.3225598256437132, 0.30507873376891304]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.36460796638782983, 0.00775347419954384, 0.3225598256437132, 0.30507873376891304]
using another actor
line 256 mcts: sample exp_bonus -3.1299014117804687
maxi score, test score, baseline:  -0.997846611909651 -1.0 -0.997846611909651
probs:  [0.36391917547100694, 0.008222447793364746, 0.3078269495252956, 0.3200314272103327]
maxi score, test score, baseline:  -0.997846611909651 -1.0 -0.997846611909651
probs:  [0.36391917547100694, 0.008222447793364746, 0.3078269495252956, 0.3200314272103327]
maxi score, test score, baseline:  -0.997846611909651 -1.0 -0.997846611909651
Printing some Q and Qe and total Qs values:  [[0.064]
 [1.428]
 [0.064]
 [0.064]
 [0.064]
 [0.064]
 [0.064]] [[2.723]
 [1.696]
 [2.723]
 [2.723]
 [2.723]
 [2.723]
 [2.723]] [[1.109]
 [2.577]
 [1.109]
 [1.109]
 [1.109]
 [1.109]
 [1.109]]
maxi score, test score, baseline:  -0.9978508196721312 -1.0 -0.9978508196721312
probs:  [0.36655072608975425, 0.008405134870054762, 0.3032204326747699, 0.3218237063654211]
maxi score, test score, baseline:  -0.9978508196721312 -1.0 -0.9978508196721312
Printing some Q and Qe and total Qs values:  [[0.726]
 [0.926]
 [0.807]
 [0.898]
 [0.807]
 [0.807]
 [0.807]] [[2.856]
 [2.653]
 [2.876]
 [3.125]
 [2.876]
 [2.876]
 [2.762]] [[1.597]
 [1.931]
 [1.766]
 [2.032]
 [1.766]
 [1.766]
 [1.729]]
maxi score, test score, baseline:  -0.9978508196721312 -1.0 -0.9978508196721312
probs:  [0.3646984101833326, 0.008501160309184583, 0.3071373940020709, 0.3196630355054119]
maxi score, test score, baseline:  -0.9978550102249489 -1.0 -0.9978550102249489
probs:  [0.3693165510977869, 0.00859641301063479, 0.304738566817868, 0.3173484690737104]
from probs:  [0.3693165510977869, 0.00859641301063479, 0.304738566817868, 0.3173484690737104]
Printing some Q and Qe and total Qs values:  [[0.808]
 [1.207]
 [0.808]
 [0.808]
 [0.808]
 [0.808]
 [0.808]] [[3.024]
 [1.793]
 [3.024]
 [3.024]
 [3.024]
 [3.024]
 [3.024]] [[2.443]
 [2.811]
 [2.443]
 [2.443]
 [2.443]
 [2.443]
 [2.443]]
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
maxi score, test score, baseline:  -0.9978591836734694 -1.0 -0.9978591836734694
probs:  [0.37698321856013794, 0.008896863836737445, 0.29737197262320797, 0.31674794497991665]
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.37698298909267114, 0.008896812484841496, 0.29737216427999524, 0.31674803414249203]
maxi score, test score, baseline:  -0.9978674796747967 -1.0 -0.9978674796747967
probs:  [0.37940801187832207, 0.008947724025464883, 0.2928594251700855, 0.31878483892612747]
maxi score, test score, baseline:  -0.9978674796747967 -1.0 -0.9978674796747967
probs:  [0.37940801187832207, 0.008947724025464883, 0.2928594251700855, 0.31878483892612747]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9978674796747967 -1.0 -0.9978674796747967
maxi score, test score, baseline:  -0.9978674796747967 -1.0 -0.9978674796747967
probs:  [0.37940801187832207, 0.008947724025464883, 0.2928594251700855, 0.31878483892612747]
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.48 ]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]] [[3.603]
 [4.135]
 [3.603]
 [3.603]
 [3.603]
 [3.603]
 [3.603]] [[0.422]
 [0.48 ]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]]
maxi score, test score, baseline:  -0.9978674796747967 -1.0 -0.9978674796747967
probs:  [0.37940801187832207, 0.008947724025464883, 0.2928594251700855, 0.31878483892612747]
maxi score, test score, baseline:  -0.9978716024340771 -1.0 -0.9978716024340771
probs:  [0.37940777000472337, 0.008947672494125522, 0.2928596403231551, 0.318784917177996]
Printing some Q and Qe and total Qs values:  [[0.29 ]
 [0.298]
 [0.317]
 [0.317]
 [0.317]
 [0.317]
 [0.288]] [[-3.212]
 [-1.454]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-2.608]] [[0.29 ]
 [0.298]
 [0.317]
 [0.317]
 [0.317]
 [0.317]
 [0.288]]
maxi score, test score, baseline:  -0.9978757085020243 -1.0 -0.9978757085020243
probs:  [0.38184990813445313, 0.008998943167444555, 0.2883150502022183, 0.32083609849588385]
maxi score, test score, baseline:  -0.9978757085020243 -1.0 -0.9978757085020243
maxi score, test score, baseline:  -0.9978757085020243 -1.0 -0.9978757085020243
probs:  [0.3843828789638711, 0.009052168778740158, 0.2902259424037703, 0.3163390098536184]
first move QE:  1.706312330315569
maxi score, test score, baseline:  -0.9978757085020243 -1.0 -0.9978757085020243
probs:  [0.38693465681849626, 0.009105789584248692, 0.2921510227662696, 0.3118085308309856]
maxi score, test score, baseline:  -0.9978757085020243 -1.0 -0.9978757085020243
maxi score, test score, baseline:  -0.9978757085020243 -1.0 -0.9978757085020243
probs:  [0.38693465681849626, 0.009105789584248692, 0.2921510227662696, 0.3118085308309856]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.476]
 [0.573]
 [0.567]
 [0.57 ]
 [0.573]
 [0.57 ]] [[3.313]
 [3.149]
 [3.292]
 [3.541]
 [3.318]
 [3.532]
 [3.573]] [[ 0.175]
 [-0.069]
 [ 0.173]
 [ 0.243]
 [ 0.175]
 [ 0.253]
 [ 0.26 ]]
maxi score, test score, baseline:  -0.997879797979798 -1.0 -0.997879797979798
probs:  [0.38693437192465263, 0.009105736609239376, 0.292151244205819, 0.311808647260289]
Printing some Q and Qe and total Qs values:  [[0.589]
 [0.507]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]] [[0.344]
 [1.75 ]
 [0.344]
 [0.344]
 [0.344]
 [0.344]
 [0.344]] [[1.248]
 [1.782]
 [1.248]
 [1.248]
 [1.248]
 [1.248]
 [1.248]]
from probs:  [0.38333626420859956, 0.009333175211738504, 0.3003167459411057, 0.30701381463855626]
maxi score, test score, baseline:  -0.997879797979798 -1.0 -0.997879797979798
probs:  [0.3789014911781895, 0.009393424313714, 0.30247980947264635, 0.3092252750354503]
maxi score, test score, baseline:  -0.997879797979798 -1.0 -0.997879797979798
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.997879797979798 -1.0 -0.997879797979798
probs:  [0.3795792559399864, 0.009570830175686195, 0.30200087835301553, 0.308849035531312]
from probs:  [0.3795789973041708, 0.00957077177313159, 0.3020010561343542, 0.3088491747883434]
Printing some Q and Qe and total Qs values:  [[0.206]
 [0.188]
 [0.196]
 [0.196]
 [0.197]
 [0.199]
 [0.198]] [[-3.196]
 [-1.56 ]
 [-3.226]
 [-3.15 ]
 [-3.064]
 [-3.06 ]
 [-3.004]] [[0.206]
 [0.188]
 [0.196]
 [0.196]
 [0.197]
 [0.199]
 [0.198]]
Printing some Q and Qe and total Qs values:  [[0.196]
 [0.196]
 [0.196]
 [0.196]
 [0.196]
 [0.196]
 [0.196]] [[-3.082]
 [-3.082]
 [-3.082]
 [-3.082]
 [-3.082]
 [-3.082]
 [-3.082]] [[0.196]
 [0.196]
 [0.196]
 [0.196]
 [0.196]
 [0.196]
 [0.196]]
maxi score, test score, baseline:  -0.9978879275653924 -1.0 -0.9978879275653924
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.37504345876869716, 0.009633636064683771, 0.3042122822484085, 0.3111106229182106]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997895991983968 -1.0 -0.997895991983968
probs:  [0.37763676613914265, 0.00969346804127131, 0.2994087676264566, 0.31326099819312947]
965 922
siam score:  -0.7459851
Printing some Q and Qe and total Qs values:  [[0.502]
 [0.424]
 [0.501]
 [0.502]
 [0.501]
 [0.504]
 [0.521]] [[0.186]
 [2.054]
 [0.236]
 [0.24 ]
 [0.289]
 [0.277]
 [0.655]] [[0.502]
 [0.424]
 [0.501]
 [0.502]
 [0.501]
 [0.504]
 [0.521]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.37819321341885287, 0.009851510002015836, 0.29896217307810125, 0.3129931035010301]
Printing some Q and Qe and total Qs values:  [[0.431]
 [0.551]
 [0.582]
 [0.586]
 [0.498]
 [0.584]
 [0.565]] [[ 2.016]
 [ 1.041]
 [-0.777]
 [ 0.043]
 [ 1.875]
 [-1.2  ]
 [ 0.628]] [[1.25 ]
 [1.165]
 [0.621]
 [0.902]
 [1.338]
 [0.482]
 [1.055]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.37819321341885287, 0.009851510002015836, 0.29896217307810125, 0.3129931035010301]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.413]
 [0.851]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]] [[2.567]
 [4.721]
 [2.567]
 [2.567]
 [2.567]
 [2.567]
 [2.567]] [[0.415]
 [1.576]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]]
Printing some Q and Qe and total Qs values:  [[1.451]
 [1.451]
 [1.451]
 [1.451]
 [1.451]
 [1.451]
 [1.451]] [[1.686]
 [1.686]
 [1.686]
 [1.686]
 [1.686]
 [1.686]
 [1.686]] [[2.72]
 [2.72]
 [2.72]
 [2.72]
 [2.72]
 [2.72]
 [2.72]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3714931559644846, 0.010049141801854974, 0.29850162800484226, 0.3199560742288181]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3714931559644846, 0.010049141801854974, 0.29850162800484226, 0.3199560742288181]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3667521303678035, 0.01011775860716553, 0.30075652702703287, 0.3223735839979981]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3667521303678035, 0.01011775860716553, 0.30075652702703287, 0.3223735839979981]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3667521303678035, 0.01011775860716553, 0.30075652702703287, 0.3223735839979981]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3667521303678035, 0.01011775860716553, 0.30075652702703287, 0.3223735839979981]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.36196713378769546, 0.010187011803979917, 0.30303233927264134, 0.3248135151356833]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.36196713378769546, 0.010187011803979917, 0.30303233927264134, 0.3248135151356833]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.36463312014378296, 0.010254892773870395, 0.3052630571257771, 0.3198489299565695]
Printing some Q and Qe and total Qs values:  [[0.851]
 [0.848]
 [0.697]
 [0.851]
 [0.853]
 [0.697]
 [0.851]] [[1.962]
 [1.925]
 [2.7  ]
 [1.849]
 [1.88 ]
 [2.7  ]
 [1.875]] [[0.422]
 [0.387]
 [0.766]
 [0.332]
 [0.358]
 [0.766]
 [0.352]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
970 932
from probs:  [0.36243191275119463, 0.010394581728868412, 0.30251403200190474, 0.32465947351803226]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3650996569338938, 0.010463952174471373, 0.2973879700838477, 0.32704842080778695]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3655544691108979, 0.010680559172993128, 0.2892571393741642, 0.3345078323419447]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.357]
 [0.305]
 [0.357]
 [0.357]
 [0.357]
 [0.328]
 [0.357]] [[ 0.   ]
 [ 0.929]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-0.891]
 [ 0.   ]] [[ 0.238]
 [ 0.444]
 [ 0.238]
 [ 0.238]
 [ 0.238]
 [-0.116]
 [ 0.238]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3633567162039031, 0.010833446689518137, 0.29380784725948306, 0.33200198984709567]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3633567162039031, 0.010833446689518137, 0.29380784725948306, 0.33200198984709567]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3582862101594263, 0.010912165761441876, 0.29615092607631843, 0.3346506980028133]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3531639221719519, 0.010991688742572997, 0.2985179333083195, 0.33732645577715553]
Printing some Q and Qe and total Qs values:  [[0.31 ]
 [0.305]
 [0.475]
 [0.463]
 [0.238]
 [0.56 ]
 [0.345]] [[2.47 ]
 [2.529]
 [2.165]
 [1.657]
 [2.505]
 [1.428]
 [2.894]] [[1.477]
 [1.486]
 [1.706]
 [1.512]
 [1.345]
 [1.629]
 [1.688]]
using another actor
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.433]
 [0.444]
 [0.436]
 [0.431]
 [0.43 ]
 [0.433]
 [0.43 ]] [[0.963]
 [1.804]
 [1.386]
 [0.782]
 [1.397]
 [1.114]
 [1.017]] [[0.433]
 [0.444]
 [0.436]
 [0.431]
 [0.43 ]
 [0.433]
 [0.43 ]]
siam score:  -0.74567515
Printing some Q and Qe and total Qs values:  [[0.435]
 [0.516]
 [0.625]
 [0.682]
 [0.807]
 [0.571]
 [0.616]] [[3.275]
 [3.089]
 [2.442]
 [2.619]
 [2.356]
 [2.309]
 [3.161]] [[0.435]
 [0.516]
 [0.625]
 [0.682]
 [0.807]
 [0.571]
 [0.616]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33492043810131555, 0.011662888276074606, 0.3184962355212943, 0.33492043810131555]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.584]
 [0.58 ]
 [0.605]
 [0.59 ]
 [0.587]
 [0.605]
 [0.598]] [[0.05 ]
 [1.018]
 [0.532]
 [0.509]
 [0.591]
 [0.532]
 [0.833]] [[0.392]
 [0.709]
 [0.596]
 [0.557]
 [0.579]
 [0.596]
 [0.682]]
line 256 mcts: sample exp_bonus 1.8361436411549674
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33495321010723683, 0.011933686091426398, 0.3265565519006684, 0.3265565519006684]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 1.6347244380629793
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3321237566368792, 0.012120724268245325, 0.3321237566368792, 0.3236317624579963]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3292287624072764, 0.012313712778170737, 0.3292287624072764, 0.3292287624072764]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31754080701728943, 0.01251180212487698, 0.3349736954289168, 0.3349736954289168]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31754080701728943, 0.01251180212487698, 0.3349736954289168, 0.3349736954289168]
using explorer policy with actor:  1
first move QE:  1.6642184334617847
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3143671049714142, 0.012716365962905696, 0.34090639987600363, 0.3320101291896765]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3143671049714142, 0.012716365962905696, 0.34090639987600363, 0.3320101291896765]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3143671049714142, 0.012716365962905696, 0.34090639987600363, 0.3320101291896765]
line 256 mcts: sample exp_bonus 1.6627135698060147
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32005059409200426, 0.012928933376418768, 0.3380136029537367, 0.32900686957784026]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.322716253180006, 0.013374160723283759, 0.3319547930483552, 0.3319547930483552]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.648]
 [0.671]
 [0.734]
 [0.735]
 [0.72 ]
 [0.731]
 [0.703]] [[-3.784]
 [ 0.365]
 [-3.359]
 [-3.423]
 [-3.318]
 [-3.275]
 [-3.401]] [[0.97 ]
 [2.401]
 [1.283]
 [1.263]
 [1.269]
 [1.304]
 [1.207]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33508342661175666, 0.014227835136630179, 0.31560531163985645, 0.33508342661175666]
line 256 mcts: sample exp_bonus 1.6242315373436156
first move QE:  1.656479459335222
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3285288327310789, 0.01435886016094847, 0.31872065730745414, 0.3383916498005185]
first move QE:  1.6537059021032987
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33174904806616806, 0.014906807450953368, 0.33174904806616806, 0.32159509641671047]
Printing some Q and Qe and total Qs values:  [[0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]] [[-0.898]
 [-0.898]
 [-0.898]
 [-0.898]
 [-0.898]
 [-0.898]
 [-0.898]] [[0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]
 [0.43]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32489712815430893, 0.0150500825813992, 0.3351556611099829, 0.32489712815430893]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32489712815430893, 0.0150500825813992, 0.3351556611099829, 0.32489712815430893]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3212558436824121, 0.015344010436075873, 0.3421443021990999, 0.3212558436824121]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31415440996235117, 0.01549479165828505, 0.3457293855051966, 0.3246214128741671]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31415440996235117, 0.01549479165828505, 0.3457293855051966, 0.3246214128741671]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3209157028249779, 0.01580782963100506, 0.34236076471903915, 0.3209157028249779]
Printing some Q and Qe and total Qs values:  [[0.193]
 [0.188]
 [0.188]
 [0.188]
 [0.188]
 [0.188]
 [0.188]] [[-0.366]
 [-0.21 ]
 [-0.21 ]
 [-0.21 ]
 [-0.21 ]
 [-0.21 ]
 [-0.21 ]] [[0.193]
 [0.188]
 [0.188]
 [0.188]
 [0.188]
 [0.188]
 [0.188]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31706800508893657, 0.01613284793031708, 0.33886338876674754, 0.3279357582139987]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3277040799692173, 0.016642214416637692, 0.3502328957156628, 0.3054208098984821]
Printing some Q and Qe and total Qs values:  [[1.226]
 [1.226]
 [1.226]
 [1.226]
 [1.226]
 [1.226]
 [1.226]] [[1.645]
 [1.645]
 [1.645]
 [1.645]
 [1.645]
 [1.645]
 [1.645]] [[1.911]
 [1.911]
 [1.911]
 [1.911]
 [1.911]
 [1.911]
 [1.911]]
989 979
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3314516235064403, 0.01682168598912802, 0.34281393995685583, 0.308912750547576]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3314516235064403, 0.01682168598912802, 0.34281393995685583, 0.308912750547576]
Printing some Q and Qe and total Qs values:  [[0.312]
 [0.326]
 [0.299]
 [0.324]
 [0.299]
 [0.299]
 [0.325]] [[2.675]
 [3.748]
 [2.438]
 [2.655]
 [2.438]
 [2.438]
 [2.662]] [[0.312]
 [0.326]
 [0.299]
 [0.324]
 [0.299]
 [0.299]
 [0.325]]
Printing some Q and Qe and total Qs values:  [[0.242]
 [0.266]
 [0.245]
 [0.241]
 [0.243]
 [0.243]
 [0.244]] [[0.607]
 [1.951]
 [0.901]
 [0.505]
 [0.888]
 [0.901]
 [0.571]] [[0.242]
 [0.266]
 [0.245]
 [0.241]
 [0.243]
 [0.243]
 [0.244]]
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.501]
 [0.424]
 [0.424]
 [0.424]
 [0.424]
 [0.551]] [[2.633]
 [3.127]
 [2.633]
 [2.633]
 [2.633]
 [2.633]
 [3.112]] [[0.871]
 [1.191]
 [0.871]
 [0.871]
 [0.871]
 [0.871]
 [1.285]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3390178112030467, 0.017184034175394363, 0.3506402818677129, 0.2931578727538461]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33107956018422957, 0.017960970009781686, 0.36742128343796054, 0.2835381863680282]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.556]
 [0.502]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]] [[0.365]
 [0.832]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]] [[1.3  ]
 [1.347]
 [1.3  ]
 [1.3  ]
 [1.3  ]
 [1.3  ]
 [1.3  ]]
using explorer policy with actor:  0
using another actor
Printing some Q and Qe and total Qs values:  [[0.624]
 [0.813]
 [0.624]
 [0.624]
 [0.624]
 [0.624]
 [0.624]] [[1.322]
 [2.076]
 [1.322]
 [1.322]
 [1.322]
 [1.322]
 [1.322]] [[0.868]
 [1.497]
 [0.868]
 [0.868]
 [0.868]
 [0.868]
 [0.868]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3185377468332978, 0.018590274774288616, 0.38101360827863806, 0.2818583701137755]
Printing some Q and Qe and total Qs values:  [[0.357]
 [0.368]
 [0.358]
 [0.365]
 [0.36 ]
 [0.352]
 [0.362]] [[0.846]
 [2.011]
 [1.56 ]
 [0.994]
 [1.044]
 [0.988]
 [1.336]] [[0.357]
 [0.368]
 [0.358]
 [0.365]
 [0.36 ]
 [0.352]
 [0.362]]
from probs:  [0.3226167448593772, 0.01881628269730374, 0.37310077105315237, 0.28546620139016676]
siam score:  -0.73781747
from probs:  [0.32662185089021095, 0.019038196434377604, 0.37773454886906277, 0.27660540380634857]
Printing some Q and Qe and total Qs values:  [[0.156]
 [0.245]
 [0.231]
 [0.257]
 [0.232]
 [0.226]
 [0.199]] [[4.475]
 [4.312]
 [3.599]
 [5.086]
 [4.412]
 [3.468]
 [3.936]] [[ 0.123]
 [ 0.246]
 [-0.021]
 [ 0.528]
 [ 0.252]
 [-0.075]
 [ 0.029]]
Printing some Q and Qe and total Qs values:  [[0.194]
 [0.196]
 [0.224]
 [0.224]
 [0.225]
 [0.23 ]
 [0.221]] [[-0.212]
 [ 0.09 ]
 [-0.239]
 [-0.234]
 [-0.334]
 [-0.165]
 [-0.225]] [[0.194]
 [0.196]
 [0.224]
 [0.224]
 [0.225]
 [0.23 ]
 [0.221]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32662185089021095, 0.019038196434377604, 0.37773454886906277, 0.27660540380634857]
Printing some Q and Qe and total Qs values:  [[0.417]
 [0.45 ]
 [0.446]
 [0.424]
 [0.446]
 [0.446]
 [0.446]] [[-0.129]
 [ 0.725]
 [ 0.   ]
 [-0.239]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[0.417]
 [0.45 ]
 [0.446]
 [0.424]
 [0.446]
 [0.446]
 [0.446]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32662185089021095, 0.019038196434377604, 0.37773454886906277, 0.27660540380634857]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32662185089021095, 0.019038196434377604, 0.37773454886906277, 0.27660540380634857]
siam score:  -0.73351896
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32223702879363525, 0.01951202791578655, 0.3744073675482877, 0.2838435757422906]
Printing some Q and Qe and total Qs values:  [[0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]] [[-0.608]
 [-0.608]
 [-0.608]
 [-0.608]
 [-0.608]
 [-0.608]
 [-0.608]] [[0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32223702879363525, 0.01951202791578655, 0.3744073675482877, 0.2838435757422906]
from probs:  [0.32223702879363525, 0.01951202791578655, 0.3744073675482877, 0.2838435757422906]
siam score:  -0.73185563
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.1091636555186826
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31764101038136544, 0.020008639008288, 0.37092062533208026, 0.29142972527826627]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31764101038136544, 0.020008639008288, 0.37092062533208026, 0.29142972527826627]
siam score:  -0.72939456
using another actor
from probs:  [0.30855793620031075, 0.020262834551711795, 0.3758664545716835, 0.295312774676294]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3126805972303456, 0.020521093318630956, 0.38089134109647527, 0.28590696835454826]
Printing some Q and Qe and total Qs values:  [[0.547]
 [0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.349]] [[ 0.171]
 [-0.097]
 [-0.097]
 [-0.097]
 [-0.097]
 [-0.097]
 [-0.097]] [[0.547]
 [0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.349]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3126805972303456, 0.020521093318630956, 0.38089134109647527, 0.28590696835454826]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3126805972303456, 0.020521093318630956, 0.38089134109647527, 0.28590696835454826]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3126805972303456, 0.020521093318630956, 0.38089134109647527, 0.28590696835454826]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3118975413658231, 0.021348520915460675, 0.38261558623040526, 0.28413835148831096]
Printing some Q and Qe and total Qs values:  [[0.081]
 [1.357]
 [0.081]
 [0.081]
 [0.081]
 [0.081]
 [0.081]] [[2.008]
 [1.567]
 [2.008]
 [2.008]
 [2.008]
 [2.008]
 [2.008]] [[0.634]
 [2.599]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]]
siam score:  -0.7253224
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.320189983502083, 0.022870523966962156, 0.39578781742871977, 0.26115167510223525]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.320189983502083, 0.022870523966962156, 0.39578781742871977, 0.26115167510223525]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.554]
 [0.749]
 [0.569]
 [0.559]
 [0.552]
 [0.554]
 [0.559]] [[ 0.056]
 [ 1.857]
 [ 0.054]
 [-0.203]
 [-0.144]
 [-0.33 ]
 [-0.219]] [[0.779]
 [1.769]
 [0.807]
 [0.702]
 [0.708]
 [0.649]
 [0.696]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.320189983502083, 0.022870523966962156, 0.39578781742871977, 0.26115167510223525]
1003 1006
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.32492686287743355, 0.02319514446880553, 0.4016465783455015, 0.2502314143082595]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.308654641960378, 0.02424115376538926, 0.4205249866734259, 0.24657921760080684]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.31899708555034095, 0.025022576766088326, 0.4011454425395019, 0.2548348951440689]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2963084173495049, 0.025826586668372644, 0.41453579431148535, 0.26332920167063706]
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.024]
 [0.037]
 [0.026]
 [0.026]
 [0.022]
 [0.054]] [[1.574]
 [1.58 ]
 [1.564]
 [1.578]
 [1.647]
 [1.698]
 [1.587]] [[0.037]
 [0.075]
 [0.079]
 [0.077]
 [0.168]
 [0.227]
 [0.143]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3355858032353303, 0.029129122910478863, 0.39238143130189096, 0.2429036425522999]
Printing some Q and Qe and total Qs values:  [[0.519]
 [0.574]
 [0.519]
 [0.519]
 [0.519]
 [0.519]
 [0.519]] [[3.051]
 [3.861]
 [3.051]
 [3.051]
 [3.051]
 [3.051]
 [3.051]] [[0.925]
 [1.644]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [0.925]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.34182980586903366, 0.02965413353754945, 0.39968533493882835, 0.2288307256545884]
start point for exploration sampling:  10723
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.34859594559901275, 0.030223046696443608, 0.38782736933758216, 0.2333536383669614]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33567454746531417, 0.030805472325790787, 0.39553600372828035, 0.23798397648061467]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3422646351353763, 0.031392444337728316, 0.4033048112971898, 0.22303810922970552]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3147560401582036, 0.03266952179320939, 0.4202074383397906, 0.23236699970879637]
line 256 mcts: sample exp_bonus 1.5686586465651804
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.928]
 [1.401]
 [0.928]
 [0.928]
 [0.928]
 [0.928]
 [0.928]] [[0.273]
 [1.057]
 [0.273]
 [0.273]
 [0.273]
 [0.273]
 [0.273]] [[1.189]
 [2.396]
 [1.189]
 [1.189]
 [1.189]
 [1.189]
 [1.189]]
Printing some Q and Qe and total Qs values:  [[0.42 ]
 [0.42 ]
 [0.42 ]
 [0.509]
 [0.42 ]
 [0.42 ]
 [0.42 ]] [[3.804]
 [3.804]
 [3.804]
 [4.632]
 [3.804]
 [3.804]
 [3.804]] [[0.011]
 [0.011]
 [0.011]
 [0.466]
 [0.011]
 [0.011]
 [0.011]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.28516062641723366, 0.03404347912202217, 0.43839230896114273, 0.24240358549960137]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2913442350442725, 0.03476261363392122, 0.44791033967723026, 0.22598281164457598]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2787488030634821, 0.03901895375852001, 0.4278894429241939, 0.2543428002538039]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2676173985159611, 0.04101123965114423, 0.4237539633169336, 0.2676173985159611]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.26212827694258034, 0.04434149823382136, 0.4589379046261419, 0.2345923201974564]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.26212827694258034, 0.04434149823382136, 0.4589379046261419, 0.2345923201974564]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2695135734356424, 0.04556738750988672, 0.4718893362552132, 0.21302970279925773]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2695135734356424, 0.04556738750988672, 0.4718893362552132, 0.21302970279925773]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2482271315021846, 0.04687153600093835, 0.4856675708362561, 0.2192337616606209]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.22577698815288774, 0.04824698055218873, 0.5001990431420359, 0.22577698815288774]
Printing some Q and Qe and total Qs values:  [[-0.039]
 [-0.037]
 [-0.039]
 [-0.039]
 [-0.039]
 [-0.039]
 [-0.033]] [[3.18 ]
 [3.15 ]
 [3.18 ]
 [3.18 ]
 [3.18 ]
 [3.18 ]
 [3.058]] [[-0.351]
 [-0.358]
 [-0.351]
 [-0.351]
 [-0.351]
 [-0.351]
 [-0.381]]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.036]
 [0.038]
 [0.035]
 [0.047]
 [0.068]
 [0.079]] [[1.858]
 [2.678]
 [2.152]
 [2.121]
 [2.225]
 [2.553]
 [2.54 ]] [[-0.839]
 [-0.514]
 [-0.685]
 [-0.702]
 [-0.642]
 [-0.492]
 [-0.473]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.22577698815288774, 0.04824698055218873, 0.5001990431420359, 0.22577698815288774]
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.404]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]] [[ 0.   ]
 [-1.393]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[0.422]
 [0.404]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2020650346419318, 0.049699731955540685, 0.515547256754721, 0.23268797664780652]
using another actor
from probs:  [0.2020650346419318, 0.049699731955540685, 0.515547256754721, 0.23268797664780652]
from probs:  [0.2020650346419318, 0.049699731955540685, 0.515547256754721, 0.23268797664780652]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.176]
 [0.176]
 [0.176]
 [0.176]
 [0.176]
 [0.176]
 [0.176]] [[-1.429]
 [-1.429]
 [-1.429]
 [-1.429]
 [-1.429]
 [-1.429]
 [-1.429]] [[0.176]
 [0.176]
 [0.176]
 [0.176]
 [0.176]
 [0.176]
 [0.176]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.503]
 [0.601]
 [0.607]
 [0.601]
 [0.554]
 [0.601]] [[ 0.773]
 [ 2.237]
 [ 0.773]
 [ 1.668]
 [ 0.773]
 [-0.655]
 [ 0.773]] [[0.601]
 [0.503]
 [0.601]
 [0.607]
 [0.601]
 [0.554]
 [0.601]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.17698181493346576, 0.05123649621307943, 0.5317830601018207, 0.23999862875163414]
Printing some Q and Qe and total Qs values:  [[0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]] [[0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]] [[0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
rdn probs:  [0.17698181493346576, 0.05123649621307943, 0.5317830601018207, 0.23999862875163414]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1892058954884215, 0.05472623050711393, 0.5332513810777045, 0.22281649292675998]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1892058954884215, 0.05472623050711393, 0.5332513810777045, 0.22281649292675998]
from probs:  [0.1892058954884215, 0.05472623050711393, 0.5332513810777045, 0.22281649292675998]
Printing some Q and Qe and total Qs values:  [[0.579]
 [0.58 ]
 [0.58 ]
 [0.58 ]
 [0.58 ]
 [0.58 ]
 [0.58 ]] [[1.759]
 [1.911]
 [1.911]
 [1.911]
 [1.911]
 [1.911]
 [1.911]] [[0.579]
 [0.58 ]
 [0.58 ]
 [0.58 ]
 [0.58 ]
 [0.58 ]
 [0.58 ]]
Printing some Q and Qe and total Qs values:  [[0.121]
 [0.121]
 [0.121]
 [0.121]
 [0.121]
 [0.121]
 [0.121]] [[1.628]
 [1.628]
 [1.628]
 [1.628]
 [1.628]
 [1.628]
 [1.628]] [[0.121]
 [0.121]
 [0.121]
 [0.121]
 [0.121]
 [0.121]
 [0.121]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.19610413572012902, 0.05669554225999787, 0.5162536982932149, 0.23094662372665825]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.19610413572012902, 0.05669554225999787, 0.5162536982932149, 0.23094662372665825]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.19610413572012902, 0.05669554225999787, 0.5162536982932149, 0.23094662372665825]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.19610413572012902, 0.05669554225999787, 0.5162536982932149, 0.23094662372665825]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.418]
 [0.404]
 [0.372]
 [0.398]
 [0.335]
 [0.428]] [[2.983]
 [4.14 ]
 [3.637]
 [3.84 ]
 [3.825]
 [3.78 ]
 [3.655]] [[0.909]
 [1.462]
 [1.206]
 [1.273]
 [1.291]
 [1.209]
 [1.238]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21111556239076207, 0.06098100898441764, 0.5167878662340583, 0.21111556239076207]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21111556239076207, 0.06098100898441764, 0.5167878662340583, 0.21111556239076207]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21965670680539012, 0.0634193375310943, 0.49726724885812545, 0.21965670680539012]
siam score:  -0.74356574
siam score:  -0.74652296
line 256 mcts: sample exp_bonus 0.9737754363502902
line 256 mcts: sample exp_bonus -1.6647809194339884
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21965670680539012, 0.0634193375310943, 0.49726724885812545, 0.21965670680539012]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21965670680539012, 0.0634193375310943, 0.49726724885812545, 0.21965670680539012]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21965670680539012, 0.0634193375310943, 0.49726724885812545, 0.21965670680539012]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21965670680539012, 0.0634193375310943, 0.49726724885812545, 0.21965670680539012]
Printing some Q and Qe and total Qs values:  [[0.921]
 [0.922]
 [0.922]
 [0.922]
 [0.922]
 [0.922]
 [0.922]] [[0.909]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]] [[1.103]
 [1.119]
 [1.119]
 [1.119]
 [1.119]
 [1.119]
 [1.119]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.18810556739360287, 0.0659529628380258, 0.5174098065226136, 0.2285316632457577]
from probs:  [0.15406637418425495, 0.06868638429127857, 0.5391407621982064, 0.23810647932626008]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16108630187101616, 0.07179071811776945, 0.518142427312269, 0.24898055269894545]
line 256 mcts: sample exp_bonus -0.8903906826691848
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16108630187101616, 0.07179071811776945, 0.518142427312269, 0.24898055269894545]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16108630187101616, 0.07179071811776945, 0.518142427312269, 0.24898055269894545]
siam score:  -0.74472857
using explorer policy with actor:  1
1031 1038
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.13544189934976744, 0.08271165308071667, 0.5454671979312055, 0.23637924963831042]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10669935898039438, 0.10338533942109848, 0.6832159426181128, 0.10669935898039438]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10669935898039438, 0.10338533942109848, 0.6832159426181128, 0.10669935898039438]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10669935898039438, 0.10338533942109848, 0.6832159426181128, 0.10669935898039438]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10669935898039438, 0.10338533942109848, 0.6832159426181128, 0.10669935898039438]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10545875094397499, 0.16592093293102078, 0.5593104571473507, 0.16930985897765355]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1128520749295307, 0.17759345274914196, 0.5283322431308224, 0.18122222919050496]
siam score:  -0.74006486
Printing some Q and Qe and total Qs values:  [[0.346]
 [0.703]
 [0.67 ]
 [0.346]
 [0.346]
 [0.346]
 [0.346]] [[ 0.892]
 [ 2.358]
 [-2.213]
 [ 0.892]
 [ 0.892]
 [ 0.892]
 [ 0.892]] [[1.181]
 [2.075]
 [0.173]
 [1.181]
 [1.181]
 [1.181]
 [1.181]]
Printing some Q and Qe and total Qs values:  [[0.439]
 [0.358]
 [0.43 ]
 [0.431]
 [0.482]
 [0.432]
 [0.42 ]] [[-1.679]
 [-1.213]
 [-1.691]
 [-2.14 ]
 [-1.597]
 [-1.858]
 [-2.215]] [[0.439]
 [0.358]
 [0.43 ]
 [0.431]
 [0.482]
 [0.432]
 [0.42 ]]
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.416]
 [0.411]
 [0.414]
 [0.414]
 [0.413]
 [0.411]] [[-2.129]
 [-1.569]
 [-2.411]
 [-2.364]
 [-2.227]
 [-2.434]
 [-2.051]] [[0.422]
 [0.416]
 [0.411]
 [0.414]
 [0.414]
 [0.413]
 [0.411]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1217200223351484, 0.26536092588371046, 0.343632147741303, 0.2692869040398381]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1217200223351484, 0.26536092588371046, 0.343632147741303, 0.2692869040398381]
start point for exploration sampling:  10723
Printing some Q and Qe and total Qs values:  [[0.44]
 [0.44]
 [0.44]
 [0.44]
 [0.44]
 [0.44]
 [0.44]] [[3.166]
 [3.166]
 [3.166]
 [3.166]
 [3.166]
 [3.166]
 [3.166]] [[0.44]
 [0.44]
 [0.44]
 [0.44]
 [0.44]
 [0.44]
 [0.44]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.12188584387041375, 0.3395779887158481, 0.2692680837068691, 0.2692680837068691]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.13157087450995764, 0.36670332123061833, 0.21096523238797857, 0.2907605718714454]
using another actor
using another actor
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.81 ]
 [0.643]
 [0.641]
 [0.645]
 [0.652]
 [0.652]] [[-2.284]
 [ 1.611]
 [-2.145]
 [-2.135]
 [-2.34 ]
 [-2.385]
 [-2.269]] [[0.204]
 [1.542]
 [0.24 ]
 [0.242]
 [0.183]
 [0.175]
 [0.211]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14294287946663395, 0.3985534440944521, 0.22925183821945694, 0.22925183821945694]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14294287946663395, 0.3985534440944521, 0.22925183821945694, 0.22925183821945694]
from probs:  [0.14294287946663395, 0.3985534440944521, 0.22925183821945694, 0.22925183821945694]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.13163044206812552, 0.44666190922597504, 0.21085382435294978, 0.21085382435294978]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.14291903842090567, 0.4851735215667405, 0.22898840159144812, 0.14291903842090567]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[1.361]
 [1.361]
 [1.361]
 [1.361]
 [1.361]
 [1.361]
 [1.361]] [[1.565]
 [1.565]
 [1.565]
 [1.565]
 [1.565]
 [1.565]
 [1.565]] [[2.459]
 [2.459]
 [2.459]
 [2.459]
 [2.459]
 [2.459]
 [2.459]]
Printing some Q and Qe and total Qs values:  [[0.503]
 [0.503]
 [0.503]
 [0.503]
 [0.503]
 [0.503]
 [0.503]] [[1.621]
 [1.621]
 [1.621]
 [1.621]
 [1.621]
 [1.621]
 [1.621]] [[2.383]
 [2.383]
 [2.383]
 [2.383]
 [2.383]
 [2.383]
 [2.383]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2639652337981154, 0.49093255868616936, 0.0944373828380445, 0.15066482467767078]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3030772131345788, 0.518212759337554, 0.08935501376393364, 0.08935501376393364]
Printing some Q and Qe and total Qs values:  [[0.281]
 [0.266]
 [0.281]
 [0.281]
 [0.281]
 [0.281]
 [0.281]] [[1.312]
 [4.129]
 [1.312]
 [1.312]
 [1.312]
 [1.312]
 [1.312]] [[1.182]
 [1.737]
 [1.182]
 [1.182]
 [1.182]
 [1.182]
 [1.182]]
Printing some Q and Qe and total Qs values:  [[0.175]
 [0.18 ]
 [0.175]
 [0.175]
 [0.175]
 [0.175]
 [0.164]] [[1.871]
 [2.576]
 [1.871]
 [1.871]
 [1.871]
 [1.871]
 [2.105]] [[0.296]
 [0.795]
 [0.296]
 [0.296]
 [0.296]
 [0.296]
 [0.448]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.22859138453778832, 0.5153455300654047, 0.1881282568997419, 0.06793482849706507]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2486784198603878, 0.5145781513079074, 0.17382333289366136, 0.06292009593804339]
Printing some Q and Qe and total Qs values:  [[0.783]
 [0.319]
 [0.493]
 [0.45 ]
 [0.44 ]
 [0.446]
 [0.413]] [[1.093]
 [1.546]
 [0.499]
 [0.44 ]
 [0.549]
 [0.514]
 [0.443]] [[1.187]
 [0.411]
 [0.408]
 [0.302]
 [0.32 ]
 [0.32 ]
 [0.23 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2486784198603878, 0.5145781513079074, 0.17382333289366136, 0.06292009593804339]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2486784198603878, 0.5145781513079074, 0.17382333289366136, 0.06292009593804339]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.2193848189090003, 0.5346823822147843, 0.18058867780701957, 0.06534412106919582]
Printing some Q and Qe and total Qs values:  [[0.101]
 [0.142]
 [0.101]
 [0.132]
 [0.135]
 [0.101]
 [0.123]] [[3.95 ]
 [3.084]
 [3.95 ]
 [3.632]
 [3.702]
 [3.95 ]
 [3.79 ]] [[ 0.256]
 [-0.239]
 [ 0.256]
 [ 0.104]
 [ 0.157]
 [ 0.256]
 [ 0.193]]
Printing some Q and Qe and total Qs values:  [[0.115]
 [0.115]
 [0.115]
 [0.087]
 [0.07 ]
 [0.074]
 [0.043]] [[3.025]
 [3.025]
 [3.025]
 [3.904]
 [3.49 ]
 [3.821]
 [3.586]] [[-0.355]
 [-0.355]
 [-0.355]
 [ 0.173]
 [-0.136]
 [ 0.093]
 [-0.126]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.18786757267118634, 0.5563127033543892, 0.18786757267118634, 0.06795215130323806]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.21571936687119997, 0.5136735784149458, 0.21571936687119997, 0.0548876878426544]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21571936687119997, 0.5136735784149458, 0.21571936687119997, 0.0548876878426544]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21571936687119997, 0.5136735784149458, 0.21571936687119997, 0.0548876878426544]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21571936687119997, 0.5136735784149458, 0.21571936687119997, 0.0548876878426544]
UNIT TEST: sample policy line 217 mcts : [0.143 0.306 0.102 0.082 0.102 0.082 0.184]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21571936687119997, 0.5136735784149458, 0.21571936687119997, 0.0548876878426544]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.21571936687119997, 0.5136735784149458, 0.21571936687119997, 0.0548876878426544]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.22295844145373558, 0.5309577307692, 0.18937926333198515, 0.056704564445079216]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1959519077847228, 0.5494479626412667, 0.1959519077847228, 0.05864822178928767]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1959519077847228, 0.5494479626412667, 0.1959519077847228, 0.05864822178928767]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1959519077847228, 0.5494479626412667, 0.1959519077847228, 0.05864822178928767]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1959519077847228, 0.5494479626412667, 0.1959519077847228, 0.05864822178928767]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1959519077847228, 0.5494479626412667, 0.1959519077847228, 0.05864822178928767]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1959519077847228, 0.5494479626412667, 0.1959519077847228, 0.05864822178928767]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1959519077847228, 0.5494479626412667, 0.1959519077847228, 0.05864822178928767]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using another actor
Printing some Q and Qe and total Qs values:  [[0.361]
 [0.395]
 [0.361]
 [0.361]
 [0.361]
 [0.361]
 [0.361]] [[-0.475]
 [ 0.367]
 [-0.475]
 [-0.475]
 [-0.475]
 [-0.475]
 [-0.475]] [[0.361]
 [0.395]
 [0.361]
 [0.361]
 [0.361]
 [0.361]
 [0.361]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1959519077847228, 0.5494479626412667, 0.1959519077847228, 0.05864822178928767]
Printing some Q and Qe and total Qs values:  [[0.484]
 [0.477]
 [0.463]
 [0.48 ]
 [0.462]
 [0.463]
 [0.483]] [[1.782]
 [2.798]
 [1.123]
 [1.627]
 [1.315]
 [1.215]
 [1.517]] [[0.484]
 [0.477]
 [0.463]
 [0.48 ]
 [0.462]
 [0.463]
 [0.483]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1959519077847228, 0.5494479626412667, 0.1959519077847228, 0.05864822178928767]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1959519077847228, 0.5494479626412667, 0.1959519077847228, 0.05864822178928767]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16714053176150007, 0.5691738937715528, 0.20296380102195236, 0.06072177344499476]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.18297586369444105, 0.5467279492512412, 0.21538807157639875, 0.05490811547791906]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.18297586369444105, 0.5467279492512412, 0.21538807157639875, 0.05490811547791906]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.18297586369444105, 0.5467279492512412, 0.21538807157639875, 0.05490811547791906]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.18297586369444105, 0.5467279492512412, 0.21538807157639875, 0.05490811547791906]
Printing some Q and Qe and total Qs values:  [[0.577]
 [0.39 ]
 [0.452]
 [0.545]
 [0.542]
 [0.497]
 [0.56 ]] [[1.621]
 [2.562]
 [2.066]
 [1.655]
 [1.837]
 [2.37 ]
 [1.774]] [[0.914]
 [0.854]
 [0.813]
 [0.861]
 [0.916]
 [1.004]
 [0.93 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.18909701960344116, 0.5650844337163794, 0.18909701960344116, 0.05672152707673816]
Printing some Q and Qe and total Qs values:  [[0.533]
 [0.52 ]
 [0.533]
 [0.533]
 [0.533]
 [0.533]
 [0.533]] [[4.804]
 [3.667]
 [4.804]
 [4.804]
 [4.804]
 [4.804]
 [4.804]] [[0.426]
 [0.021]
 [0.426]
 [0.426]
 [0.426]
 [0.426]
 [0.426]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16111870330510902, 0.5846189707527555, 0.1956110090896583, 0.05865131685247702]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16111870330510902, 0.5846189707527555, 0.1956110090896583, 0.05865131685247702]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.446]
 [0.333]
 [0.362]
 [0.435]
 [0.435]
 [0.449]
 [0.448]] [[2.937]
 [2.816]
 [2.884]
 [2.85 ]
 [2.838]
 [2.91 ]
 [2.87 ]] [[-0.424]
 [-0.69 ]
 [-0.609]
 [-0.474]
 [-0.479]
 [-0.427]
 [-0.442]]
Printing some Q and Qe and total Qs values:  [[0.589]
 [0.589]
 [0.589]
 [1.083]
 [0.589]
 [1.275]
 [0.589]] [[1.984]
 [1.984]
 [1.984]
 [1.664]
 [1.984]
 [1.459]
 [1.984]] [[1.287]
 [1.287]
 [1.287]
 [2.02 ]
 [1.287]
 [2.254]
 [1.287]]
Printing some Q and Qe and total Qs values:  [[0.46 ]
 [0.469]
 [0.503]
 [0.503]
 [0.48 ]
 [0.495]
 [0.489]] [[6.116]
 [6.182]
 [5.795]
 [5.795]
 [6.186]
 [6.101]
 [6.115]] [[1.549]
 [1.611]
 [1.42 ]
 [1.42 ]
 [1.635]
 [1.609]
 [1.607]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16111870330510902, 0.5846189707527555, 0.1956110090896583, 0.05865131685247702]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16111870330510902, 0.5846189707527555, 0.1956110090896583, 0.05865131685247702]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16111870330510902, 0.5846189707527555, 0.1956110090896583, 0.05865131685247702]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16111870330510902, 0.5846189707527555, 0.1956110090896583, 0.05865131685247702]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.16111870330510902, 0.5846189707527555, 0.1956110090896583, 0.05865131685247702]
Printing some Q and Qe and total Qs values:  [[0.429]
 [0.386]
 [0.429]
 [0.557]
 [0.429]
 [0.429]
 [0.507]] [[1.626]
 [2.18 ]
 [1.626]
 [1.375]
 [1.626]
 [1.626]
 [1.723]] [[1.319]
 [1.42 ]
 [1.319]
 [1.493]
 [1.319]
 [1.319]
 [1.508]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1361321394938437, 0.6279346592623141, 0.1730027876992256, 0.06293041354461663]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1361321394938437, 0.6279346592623141, 0.1730027876992256, 0.06293041354461663]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1361321394938437, 0.6279346592623141, 0.1730027876992256, 0.06293041354461663]
first move QE:  1.5292817537401957
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10320694334391622, 0.6519125450264168, 0.17958135606136003, 0.06529915556830701]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10320694334391622, 0.6519125450264168, 0.17958135606136003, 0.06529915556830701]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10320694334391622, 0.6519125450264168, 0.17958135606136003, 0.06529915556830701]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10320694334391622, 0.6519125450264168, 0.17958135606136003, 0.06529915556830701]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.10320694334391622, 0.6519125450264168, 0.17958135606136003, 0.06529915556830701]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.6288398645210995
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06784332532027701, 0.6776662197901149, 0.1866471295693312, 0.06784332532027701]
using another actor
from probs:  [0.06784332532027701, 0.6776662197901149, 0.1866471295693312, 0.06784332532027701]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06784332532027701, 0.6776662197901149, 0.1866471295693312, 0.06784332532027701]
Printing some Q and Qe and total Qs values:  [[0.437]
 [0.445]
 [0.437]
 [0.462]
 [0.437]
 [0.437]
 [0.451]] [[3.085]
 [3.246]
 [3.085]
 [3.199]
 [3.085]
 [3.085]
 [3.561]] [[0.437]
 [0.445]
 [0.437]
 [0.462]
 [0.437]
 [0.437]
 [0.451]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06784332532027701, 0.6776662197901149, 0.1866471295693312, 0.06784332532027701]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.44 ]
 [0.136]
 [0.491]
 [0.51 ]
 [0.521]
 [0.532]
 [0.502]] [[2.424]
 [2.664]
 [2.922]
 [3.317]
 [3.471]
 [3.943]
 [3.275]] [[0.803]
 [0.422]
 [1.173]
 [1.428]
 [1.536]
 [1.822]
 [1.392]]
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.699]
 [0.76 ]
 [0.699]] [[4.51 ]
 [4.51 ]
 [4.51 ]
 [4.51 ]
 [4.51 ]
 [4.607]
 [4.51 ]] [[1.701]
 [1.701]
 [1.701]
 [1.701]
 [1.701]
 [1.882]
 [1.701]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06784332532027701, 0.6776662197901149, 0.1866471295693312, 0.06784332532027701]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.829131716445441
1068 1134
Printing some Q and Qe and total Qs values:  [[0.359]
 [0.375]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]] [[0.068]
 [0.604]
 [0.068]
 [0.068]
 [0.068]
 [0.068]
 [0.068]] [[0.359]
 [0.375]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]]
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.403]
 [0.414]
 [0.412]
 [0.414]
 [0.412]
 [0.421]] [[2.125]
 [2.81 ]
 [0.655]
 [2.399]
 [0.721]
 [0.693]
 [1.06 ]] [[0.422]
 [0.403]
 [0.414]
 [0.412]
 [0.414]
 [0.412]
 [0.421]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
from probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
Printing some Q and Qe and total Qs values:  [[0.294]
 [0.151]
 [0.289]
 [0.292]
 [0.302]
 [0.435]
 [0.294]] [[3.85 ]
 [3.386]
 [3.655]
 [3.678]
 [3.724]
 [3.647]
 [3.85 ]] [[0.704]
 [0.176]
 [0.579]
 [0.6  ]
 [0.644]
 [0.834]
 [0.704]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
Printing some Q and Qe and total Qs values:  [[0.71 ]
 [0.542]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]] [[0.122]
 [1.122]
 [0.405]
 [0.405]
 [0.405]
 [0.405]
 [0.405]] [[0.863]
 [1.193]
 [0.958]
 [0.958]
 [0.958]
 [0.958]
 [0.958]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
Printing some Q and Qe and total Qs values:  [[0.428]
 [0.379]
 [0.495]
 [0.421]
 [0.507]
 [0.412]
 [0.441]] [[-0.333]
 [ 0.774]
 [-0.194]
 [ 0.659]
 [ 0.096]
 [ 0.819]
 [-0.378]] [[0.25 ]
 [0.89 ]
 [0.477]
 [0.897]
 [0.695]
 [0.986]
 [0.247]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
first move QE:  1.5153265317378144
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07062533507034648, 0.7058274595176321, 0.15292187034167493, 0.07062533507034648]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.09928221038994983, 0.6652241586958704, 0.17260542471453785, 0.06288820619964187]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.248]
 [1.454]
 [1.248]
 [1.248]
 [1.248]
 [1.248]
 [1.248]] [[1.711]
 [1.883]
 [1.711]
 [1.711]
 [1.711]
 [1.711]
 [1.711]] [[2.218]
 [2.744]
 [2.218]
 [2.218]
 [2.218]
 [2.218]
 [2.218]]
UNIT TEST: sample policy line 217 mcts : [0.102 0.122 0.061 0.102 0.408 0.102 0.102]
siam score:  -0.7365358
Printing some Q and Qe and total Qs values:  [[0.494]
 [0.463]
 [0.456]
 [0.685]
 [0.381]
 [0.597]
 [0.616]] [[ 0.95 ]
 [ 0.584]
 [ 1.186]
 [ 0.219]
 [ 1.322]
 [-1.365]
 [ 0.824]] [[1.971]
 [1.761]
 [2.027]
 [1.898]
 [1.986]
 [1.057]
 [2.08 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1030477403614268, 0.6906719949190806, 0.14102085167098893, 0.06525941304850365]
Printing some Q and Qe and total Qs values:  [[0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.672]
 [0.798]
 [0.672]] [[4.66 ]
 [4.66 ]
 [4.66 ]
 [4.66 ]
 [4.66 ]
 [4.377]
 [4.66 ]] [[1.07 ]
 [1.07 ]
 [1.07 ]
 [1.07 ]
 [1.07 ]
 [1.059]
 [1.07 ]]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.479]
 [0.568]
 [0.58 ]
 [0.623]
 [0.814]
 [0.599]] [[3.525]
 [3.62 ]
 [3.981]
 [4.314]
 [4.879]
 [5.012]
 [4.549]] [[0.482]
 [0.46 ]
 [0.86 ]
 [1.124]
 [1.606]
 [1.989]
 [1.327]]
siam score:  -0.73412114
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1030477403614268, 0.6906719949190806, 0.14102085167098893, 0.06525941304850365]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1030477403614268, 0.6906719949190806, 0.14102085167098893, 0.06525941304850365]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07055000106357708, 0.7474506843854536, 0.11144931348739215, 0.07055000106357708]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.7370581
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.589]
 [0.563]
 [0.563]
 [0.563]
 [0.563]
 [0.563]] [[-0.905]
 [ 0.446]
 [-0.905]
 [-0.905]
 [-0.905]
 [-0.905]
 [-0.905]] [[0.942]
 [1.446]
 [0.942]
 [0.942]
 [0.942]
 [0.942]
 [0.942]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07352839144760492, 0.7794148256571855, 0.07352839144760492, 0.07352839144760492]
line 256 mcts: sample exp_bonus 3.2277022210035407
from probs:  [0.07352839144760492, 0.7794148256571855, 0.07352839144760492, 0.07352839144760492]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07352839144760492, 0.7794148256571855, 0.07352839144760492, 0.07352839144760492]
Printing some Q and Qe and total Qs values:  [[1.186]
 [1.439]
 [1.186]
 [1.455]
 [1.186]
 [1.186]
 [1.186]] [[1.584]
 [1.741]
 [1.584]
 [2.188]
 [1.584]
 [1.584]
 [1.584]] [[2.163]
 [2.56 ]
 [2.163]
 [2.773]
 [2.163]
 [2.163]
 [2.163]]
Printing some Q and Qe and total Qs values:  [[0.431]
 [0.405]
 [0.431]
 [0.431]
 [0.431]
 [0.431]
 [0.431]] [[1.09 ]
 [2.062]
 [1.09 ]
 [1.09 ]
 [1.09 ]
 [1.09 ]
 [1.09 ]] [[1.069]
 [1.665]
 [1.069]
 [1.069]
 [1.069]
 [1.069]
 [1.069]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0651956021194611, 0.7291025209114604, 0.10285093848453929, 0.10285093848453929]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0651956021194611, 0.7291025209114604, 0.10285093848453929, 0.10285093848453929]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0651956021194611, 0.7291025209114604, 0.10285093848453929, 0.10285093848453929]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0651956021194611, 0.7291025209114604, 0.10285093848453929, 0.10285093848453929]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0677180941882139, 0.7577108499241435, 0.1068529616994287, 0.0677180941882139]
Printing some Q and Qe and total Qs values:  [[0.947]
 [0.478]
 [0.543]
 [0.542]
 [0.513]
 [0.553]
 [0.481]] [[4.567]
 [2.121]
 [0.668]
 [2.636]
 [2.591]
 [0.62 ]
 [1.197]] [[2.475]
 [0.845]
 [0.313]
 [1.144]
 [1.089]
 [0.305]
 [0.458]]
Printing some Q and Qe and total Qs values:  [[0.166]
 [0.166]
 [0.166]
 [0.197]
 [0.166]
 [0.166]
 [0.166]] [[4.288]
 [4.288]
 [4.288]
 [4.731]
 [4.288]
 [4.288]
 [4.288]] [[0.561]
 [0.561]
 [0.561]
 [0.919]
 [0.561]
 [0.561]
 [0.561]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0677180941882139, 0.7577108499241435, 0.1068529616994287, 0.0677180941882139]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0677180941882139, 0.7577108499241435, 0.1068529616994287, 0.0677180941882139]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0677180941882139, 0.7577108499241435, 0.1068529616994287, 0.0677180941882139]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0677180941882139, 0.7577108499241435, 0.1068529616994287, 0.0677180941882139]
rdn beta is 0 so we're just using the maxi policy
1079 1167
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0677180941882139, 0.7577108499241435, 0.1068529616994287, 0.0677180941882139]
from probs:  [0.06060745434524382, 0.7133798941613783, 0.13052918719510664, 0.09548346429827112]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.054867426083221704, 0.6775939530111876, 0.14964170118603307, 0.11789691971955756]
Printing some Q and Qe and total Qs values:  [[0.456]
 [0.437]
 [0.494]
 [0.505]
 [0.483]
 [0.524]
 [0.452]] [[2.732]
 [3.565]
 [3.48 ]
 [3.79 ]
 [3.815]
 [3.548]
 [3.553]] [[0.125]
 [0.641]
 [0.698]
 [0.927]
 [0.9  ]
 [0.802]
 [0.662]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05664092737890399, 0.6998682412613866, 0.12174541567985478, 0.12174541567985478]
Printing some Q and Qe and total Qs values:  [[1.475]
 [0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]] [[1.454]
 [2.674]
 [2.674]
 [2.674]
 [2.674]
 [2.674]
 [2.674]] [[2.283]
 [1.837]
 [1.837]
 [1.837]
 [1.837]
 [1.837]
 [1.837]]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05161150634721412, 0.6675223295121805, 0.14043308207030275, 0.14043308207030275]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05161150634721412, 0.6675223295121805, 0.14043308207030275, 0.14043308207030275]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05316991840055368, 0.6880441625026568, 0.1140596769132249, 0.14472624218356475]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0548273436120061, 0.709869842887212, 0.11765140675039096, 0.11765140675039096]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0548273436120061, 0.709869842887212, 0.11765140675039096, 0.11765140675039096]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0548273436120061, 0.709869842887212, 0.11765140675039096, 0.11765140675039096]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0548273436120061, 0.709869842887212, 0.11765140675039096, 0.11765140675039096]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0548273436120061, 0.709869842887212, 0.11765140675039096, 0.11765140675039096]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0548273436120061, 0.709869842887212, 0.11765140675039096, 0.11765140675039096]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0548273436120061, 0.709869842887212, 0.11765140675039096, 0.11765140675039096]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0548273436120061, 0.709869842887212, 0.11765140675039096, 0.11765140675039096]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0548273436120061, 0.709869842887212, 0.11765140675039096, 0.11765140675039096]
Printing some Q and Qe and total Qs values:  [[0.806]
 [0.755]
 [0.851]
 [0.846]
 [0.851]
 [0.861]
 [1.013]] [[4.537]
 [4.229]
 [4.572]
 [4.493]
 [4.572]
 [4.591]
 [5.152]] [[1.281]
 [1.058]
 [1.362]
 [1.316]
 [1.362]
 [1.386]
 [1.877]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05658471689183983, 0.7330116819620498, 0.12145972944308248, 0.08894387170302794]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05658471689183983, 0.7330116819620498, 0.12145972944308248, 0.08894387170302794]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05658471689183983, 0.7330116819620498, 0.12145972944308248, 0.08894387170302794]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05658471689183983, 0.7330116819620498, 0.12145972944308248, 0.08894387170302794]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05846070458767084, 0.7577154861347221, 0.09191190463880364, 0.09191190463880364]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05846070458767084, 0.7577154861347221, 0.09191190463880364, 0.09191190463880364]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05846070458767084, 0.7577154861347221, 0.09191190463880364, 0.09191190463880364]
from probs:  [0.05846070458767084, 0.7577154861347221, 0.09191190463880364, 0.09191190463880364]
line 256 mcts: sample exp_bonus 5.944942386310261
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05846070458767084, 0.7577154861347221, 0.09191190463880364, 0.09191190463880364]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.45 ]
 [0.425]
 [0.45 ]
 [0.45 ]
 [0.45 ]
 [0.425]
 [0.403]] [[2.272]
 [3.422]
 [2.272]
 [2.272]
 [2.272]
 [2.117]
 [2.951]] [[0.45 ]
 [0.425]
 [0.45 ]
 [0.45 ]
 [0.45 ]
 [0.425]
 [0.403]]
Printing some Q and Qe and total Qs values:  [[0.466]
 [0.491]
 [0.466]
 [0.466]
 [0.466]
 [0.466]
 [0.466]] [[1.409]
 [1.856]
 [1.409]
 [1.409]
 [1.409]
 [1.409]
 [1.409]] [[0.466]
 [0.491]
 [0.466]
 [0.466]
 [0.466]
 [0.466]
 [0.466]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05846070458767084, 0.7577154861347221, 0.09191190463880364, 0.09191190463880364]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05846070458767084, 0.7577154861347221, 0.09191190463880364, 0.09191190463880364]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0604577264228313, 0.7840131193516067, 0.0604577264228313, 0.09507142780273067]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0604577264228313, 0.7840131193516067, 0.0604577264228313, 0.09507142780273067]
line 256 mcts: sample exp_bonus 0.7785382326363047
Printing some Q and Qe and total Qs values:  [[0.24 ]
 [0.593]
 [0.549]
 [0.648]
 [0.397]
 [0.648]
 [0.473]] [[2.356]
 [1.627]
 [2.051]
 [1.892]
 [1.741]
 [0.789]
 [1.618]] [[1.419]
 [1.64 ]
 [1.833]
 [1.926]
 [1.323]
 [1.19 ]
 [1.392]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0604577264228313, 0.7840131193516067, 0.0604577264228313, 0.09507142780273067]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0604577264228313, 0.7840131193516067, 0.0604577264228313, 0.09507142780273067]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06259854721111245, 0.8122043583666627, 0.06259854721111245, 0.06259854721111245]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06259854721111245, 0.8122043583666627, 0.06259854721111245, 0.06259854721111245]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06259854721111245, 0.8122043583666627, 0.06259854721111245, 0.06259854721111245]
Printing some Q and Qe and total Qs values:  [[0.805]
 [0.763]
 [0.805]
 [0.806]
 [0.792]
 [0.912]
 [0.893]] [[4.997]
 [4.272]
 [4.997]
 [5.097]
 [5.061]
 [5.529]
 [5.401]] [[1.975]
 [1.408]
 [1.975]
 [2.043]
 [1.992]
 [2.543]
 [2.42 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.088760151738761, 0.7659599185633494, 0.088760151738761, 0.05651977795912862]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.088760151738761, 0.7659599185633494, 0.088760151738761, 0.05651977795912862]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.186]
 [0.967]
 [0.186]
 [0.186]
 [0.186]
 [0.967]
 [0.186]] [[2.467]
 [1.413]
 [2.467]
 [2.467]
 [2.467]
 [1.427]
 [2.467]] [[0.489]
 [1.35 ]
 [0.489]
 [0.489]
 [0.489]
 [1.36 ]
 [0.489]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.088760151738761, 0.7659599185633494, 0.088760151738761, 0.05651977795912862]
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.746]
 [0.577]
 [0.561]
 [0.586]
 [0.548]
 [0.528]] [[1.017]
 [1.264]
 [1.073]
 [1.183]
 [1.172]
 [1.137]
 [1.049]] [[0.847]
 [1.431]
 [0.965]
 [1.006]
 [1.048]
 [0.949]
 [0.85 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.088760151738761, 0.7659599185633494, 0.088760151738761, 0.05651977795912862]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using another actor
from probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
Printing some Q and Qe and total Qs values:  [[0.462]
 [0.28 ]
 [0.506]
 [0.496]
 [0.54 ]
 [1.006]
 [0.414]] [[1.092]
 [1.654]
 [1.094]
 [1.127]
 [1.211]
 [1.252]
 [1.03 ]] [[0.503]
 [0.513]
 [0.592]
 [0.594]
 [0.738]
 [1.698]
 [0.365]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
Printing some Q and Qe and total Qs values:  [[0.654]
 [0.553]
 [0.654]
 [0.654]
 [0.654]
 [0.644]
 [0.654]] [[5.491]
 [4.422]
 [5.491]
 [5.491]
 [5.491]
 [5.111]
 [5.491]] [[2.36 ]
 [1.496]
 [2.36 ]
 [2.36 ]
 [2.36 ]
 [2.103]
 [2.36 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
from probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
siam score:  -0.7189807
line 256 mcts: sample exp_bonus 4.273678066477808
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.71751785
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
Printing some Q and Qe and total Qs values:  [[0.433]
 [0.433]
 [0.433]
 [0.684]
 [0.433]
 [0.433]
 [0.433]] [[1.935]
 [1.935]
 [1.935]
 [2.898]
 [1.935]
 [1.935]
 [1.935]] [[0.718]
 [0.718]
 [0.718]
 [1.862]
 [0.718]
 [0.718]
 [0.718]]
Printing some Q and Qe and total Qs values:  [[0.382]
 [0.684]
 [0.684]
 [0.605]
 [0.684]
 [0.684]
 [0.684]] [[2.442]
 [1.491]
 [1.491]
 [1.571]
 [1.491]
 [1.491]
 [1.491]] [[1.222]
 [1.19 ]
 [1.19 ]
 [1.086]
 [1.19 ]
 [1.19 ]
 [1.19 ]]
using another actor
from probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
line 256 mcts: sample exp_bonus 3.846930830798674
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
Printing some Q and Qe and total Qs values:  [[0.503]
 [0.497]
 [0.503]
 [0.503]
 [0.503]
 [0.503]
 [0.503]] [[4.623]
 [5.025]
 [4.623]
 [4.623]
 [4.623]
 [4.623]
 [4.623]] [[1.161]
 [1.379]
 [1.161]
 [1.161]
 [1.161]
 [1.161]
 [1.161]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
Printing some Q and Qe and total Qs values:  [[0.031]
 [0.56 ]
 [0.031]
 [0.031]
 [0.031]
 [0.031]
 [0.031]] [[2.045]
 [3.536]
 [2.045]
 [2.045]
 [2.045]
 [2.045]
 [2.045]] [[-0.083]
 [ 1.204]
 [-0.083]
 [-0.083]
 [-0.083]
 [-0.083]
 [-0.083]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.548]] [[3.482]
 [3.482]
 [3.482]
 [3.482]
 [3.482]
 [3.482]
 [3.482]] [[1.48]
 [1.48]
 [1.48]
 [1.48]
 [1.48]
 [1.48]
 [1.48]]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
from probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
Printing some Q and Qe and total Qs values:  [[0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]] [[5.35]
 [5.35]
 [5.35]
 [5.35]
 [5.35]
 [5.35]
 [5.35]] [[1.803]
 [1.803]
 [1.803]
 [1.803]
 [1.803]
 [1.803]
 [1.803]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
using explorer policy with actor:  1
siam score:  -0.7121754
Printing some Q and Qe and total Qs values:  [[0.145]
 [0.199]
 [0.145]
 [0.183]
 [0.149]
 [0.139]
 [0.166]] [[5.025]
 [3.379]
 [5.025]
 [4.12 ]
 [4.335]
 [4.547]
 [4.285]] [[1.394]
 [0.111]
 [1.394]
 [0.698]
 [0.834]
 [0.995]
 [0.813]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.11354217124608532, 0.7501519812636526, 0.08323421895161236, 0.053071628538649836]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.1170568700352737, 0.7735473389904496, 0.0546978954871384, 0.0546978954871384]
line 256 mcts: sample exp_bonus 6.228870191781108
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.13542212885529348, 0.7361949386857753, 0.07835568519914339, 0.05002724725978772]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.208]
 [0.209]] [[6.216]
 [6.216]
 [6.216]
 [6.216]
 [6.216]
 [6.189]
 [6.216]] [[1.208]
 [1.208]
 [1.208]
 [1.208]
 [1.208]
 [1.188]
 [1.208]]
Printing some Q and Qe and total Qs values:  [[0.225]
 [0.222]
 [0.223]
 [0.232]
 [0.241]
 [0.234]
 [0.229]] [[2.577]
 [3.255]
 [2.833]
 [2.71 ]
 [2.692]
 [2.739]
 [2.911]] [[-0.598]
 [-0.379]
 [-0.518]
 [-0.541]
 [-0.528]
 [-0.527]
 [-0.478]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.13542212885529348, 0.7361949386857753, 0.07835568519914339, 0.05002724725978772]
using explorer policy with actor:  1
from probs:  [0.13542212885529348, 0.7361949386857753, 0.07835568519914339, 0.05002724725978772]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0830573664312504, 0.7808780534133047, 0.0830573664312504, 0.05300721372419429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0830573664312504, 0.7808780534133047, 0.0830573664312504, 0.05300721372419429]
siam score:  -0.71398944
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0830573664312504, 0.7808780534133047, 0.0830573664312504, 0.05300721372419429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0830573664312504, 0.7808780534133047, 0.0830573664312504, 0.05300721372419429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05634713964166261, 0.8309585810750123, 0.05634713964166261, 0.05634713964166261]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05634713964166261, 0.8309585810750123, 0.05634713964166261, 0.05634713964166261]
Printing some Q and Qe and total Qs values:  [[0.577]
 [0.584]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]] [[2.619]
 [3.274]
 [2.619]
 [2.619]
 [2.619]
 [2.619]
 [2.619]] [[2.301]
 [2.522]
 [2.301]
 [2.301]
 [2.301]
 [2.301]
 [2.301]]
first move QE:  1.4589779184271536
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.6993048416041054
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05634713964166261, 0.8309585810750123, 0.05634713964166261, 0.05634713964166261]
siam score:  -0.7172978
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05634713964166261, 0.8309585810750123, 0.05634713964166261, 0.05634713964166261]
first move QE:  1.4586399240515653
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
siam score:  -0.71815765
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.446]
 [0.447]
 [0.446]
 [0.447]
 [0.446]
 [0.446]
 [0.447]] [[4.452]
 [4.536]
 [4.452]
 [4.467]
 [4.486]
 [4.458]
 [4.535]] [[1.055]
 [1.114]
 [1.055]
 [1.068]
 [1.078]
 [1.06 ]
 [1.113]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.42 ]
 [0.423]
 [0.422]
 [0.425]
 [0.431]
 [0.433]
 [0.438]] [[4.496]
 [4.291]
 [4.348]
 [4.299]
 [4.241]
 [4.368]
 [4.29 ]] [[1.119]
 [0.987]
 [1.025]
 [0.997]
 [0.971]
 [1.06 ]
 [1.017]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
Printing some Q and Qe and total Qs values:  [[0.384]
 [0.364]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.407]] [[2.436]
 [3.203]
 [2.512]
 [2.512]
 [2.512]
 [2.512]
 [2.187]] [[0.384]
 [0.364]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.407]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
Printing some Q and Qe and total Qs values:  [[0.612]
 [0.615]
 [0.611]
 [0.612]
 [0.615]
 [0.611]
 [0.611]] [[4.181]
 [4.285]
 [4.901]
 [3.957]
 [3.962]
 [4.901]
 [4.901]] [[1.289]
 [1.361]
 [1.746]
 [1.146]
 [1.153]
 [1.746]
 [1.746]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05141287561953978, 0.7876483197214447, 0.08046940232950783, 0.08046940232950783]
Printing some Q and Qe and total Qs values:  [[0.686]
 [0.65 ]
 [0.722]
 [0.652]
 [0.634]
 [0.444]
 [0.624]] [[5.662]
 [4.605]
 [4.929]
 [5.87 ]
 [5.759]
 [4.628]
 [5.664]] [[1.79 ]
 [1.344]
 [1.55 ]
 [1.83 ]
 [1.768]
 [1.116]
 [1.719]]
line 256 mcts: sample exp_bonus 4.207799463139012
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.054536736003872835, 0.8363897919883814, 0.054536736003872835, 0.054536736003872835]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.054536736003872835, 0.8363897919883814, 0.054536736003872835, 0.054536736003872835]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.054536736003872835, 0.8363897919883814, 0.054536736003872835, 0.054536736003872835]
Printing some Q and Qe and total Qs values:  [[0.762]
 [0.659]
 [0.729]
 [0.715]
 [0.718]
 [0.724]
 [0.737]] [[6.442]
 [6.483]
 [6.754]
 [6.724]
 [6.868]
 [6.473]
 [6.513]] [[1.991]
 [1.849]
 [2.105]
 [2.068]
 [2.149]
 [1.947]
 [1.99 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.054536736003872835, 0.8363897919883814, 0.054536736003872835, 0.054536736003872835]
Printing some Q and Qe and total Qs values:  [[0.596]
 [1.387]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]] [[1.398]
 [1.792]
 [1.398]
 [1.398]
 [1.398]
 [1.398]
 [1.398]] [[0.881]
 [2.596]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.054536736003872835, 0.8363897919883814, 0.054536736003872835, 0.054536736003872835]
siam score:  -0.70667297
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.576]
 [0.552]
 [0.544]] [[5.531]
 [5.531]
 [5.531]
 [5.531]
 [5.408]
 [5.725]
 [5.822]] [[1.417]
 [1.417]
 [1.417]
 [1.417]
 [1.466]
 [1.624]
 [1.672]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]] [[2.39]
 [2.39]
 [2.39]
 [2.39]
 [2.39]
 [2.39]
 [2.39]] [[0.793]
 [0.793]
 [0.793]
 [0.793]
 [0.793]
 [0.793]
 [0.793]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
Printing some Q and Qe and total Qs values:  [[0.685]
 [0.567]
 [0.666]
 [0.642]
 [0.643]
 [0.655]
 [0.672]] [[4.979]
 [4.87 ]
 [4.903]
 [4.909]
 [4.791]
 [5.569]
 [4.813]] [[1.439]
 [1.13 ]
 [1.349]
 [1.305]
 [1.229]
 [1.771]
 [1.301]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.36 ]
 [0.342]
 [0.397]
 [0.393]
 [0.393]
 [0.429]
 [0.371]] [[5.865]
 [5.587]
 [5.214]
 [5.154]
 [5.25 ]
 [4.896]
 [5.559]] [[1.142]
 [0.952]
 [0.834]
 [0.792]
 [0.846]
 [0.706]
 [0.985]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.69049776
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
Printing some Q and Qe and total Qs values:  [[0.321]
 [0.334]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.323]] [[-0.521]
 [ 0.604]
 [-0.483]
 [-0.483]
 [-0.483]
 [-0.483]
 [-0.692]] [[0.321]
 [0.334]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.323]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0499136228682485, 0.7940141630482342, 0.0780361070417586, 0.0780361070417586]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.6838322
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05133494111747568, 0.8170555838198108, 0.08027453394523794, 0.05133494111747568]
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.679]
 [0.685]
 [0.678]
 [0.68 ]
 [0.679]
 [0.682]] [[6.336]
 [5.162]
 [5.564]
 [5.572]
 [5.7  ]
 [5.621]
 [5.236]] [[1.452]
 [0.896]
 [1.076]
 [1.07 ]
 [1.127]
 [1.092]
 [0.932]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07374473511054735, 0.778639235362793, 0.10038546893200515, 0.047230560594654525]
siam score:  -0.68653643
Printing some Q and Qe and total Qs values:  [[ 0.025]
 [-0.005]
 [ 0.029]
 [ 0.011]
 [ 0.015]
 [ 0.029]
 [-0.001]] [[4.827]
 [4.643]
 [5.222]
 [5.032]
 [5.061]
 [5.222]
 [4.824]] [[ 0.044]
 [-0.057]
 [ 0.194]
 [ 0.104]
 [ 0.119]
 [ 0.194]
 [ 0.013]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
Printing some Q and Qe and total Qs values:  [[0.965]
 [0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.547]
 [0.547]] [[6.912]
 [2.188]
 [2.188]
 [2.188]
 [2.188]
 [2.188]
 [2.188]] [[2.317]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]]
Printing some Q and Qe and total Qs values:  [[0.588]
 [0.602]
 [0.588]
 [0.588]
 [0.588]
 [1.106]
 [0.588]] [[3.097]
 [2.443]
 [3.097]
 [3.097]
 [3.097]
 [4.862]
 [3.097]] [[0.846]
 [0.61 ]
 [0.846]
 [0.846]
 [0.846]
 [2.12 ]
 [0.846]]
line 256 mcts: sample exp_bonus 7.391846373593409
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
Printing some Q and Qe and total Qs values:  [[-0.074]
 [-0.082]
 [-0.074]
 [-0.075]
 [-0.078]
 [-0.075]
 [-0.071]] [[6.257]
 [5.053]
 [6.087]
 [6.248]
 [6.032]
 [5.817]
 [6.076]] [[ 0.595]
 [-0.014]
 [ 0.511]
 [ 0.59 ]
 [ 0.478]
 [ 0.376]
 [ 0.511]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
Printing some Q and Qe and total Qs values:  [[0.279]
 [0.261]
 [0.279]
 [0.279]
 [0.277]
 [0.273]
 [0.266]] [[6.323]
 [5.635]
 [6.323]
 [6.323]
 [6.2  ]
 [6.011]
 [6.353]] [[1.522]
 [1.053]
 [1.522]
 [1.522]
 [1.441]
 [1.313]
 [1.516]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.6922446
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
from probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04849499438334279, 0.7999064149025086, 0.10310359633080567, 0.04849499438334279]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05125028713750016, 0.8462491385874994, 0.05125028713750016, 0.05125028713750016]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05125028713750016, 0.8462491385874994, 0.05125028713750016, 0.05125028713750016]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05125028713750016, 0.8462491385874994, 0.05125028713750016, 0.05125028713750016]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05125028713750016, 0.8462491385874994, 0.05125028713750016, 0.05125028713750016]
Printing some Q and Qe and total Qs values:  [[0.539]
 [0.5  ]
 [0.539]
 [0.539]
 [0.539]
 [0.539]
 [0.539]] [[1.641]
 [1.566]
 [1.641]
 [1.641]
 [1.641]
 [1.641]
 [1.641]] [[1.19]
 [1.12]
 [1.19]
 [1.19]
 [1.19]
 [1.19]
 [1.19]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.05125028713750016, 0.8462491385874994, 0.05125028713750016, 0.05125028713750016]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07358128431430726, 0.8056691671456414, 0.047168264225744085, 0.07358128431430726]
siam score:  -0.7033757
Printing some Q and Qe and total Qs values:  [[0.79]
 [0.79]
 [0.79]
 [0.98]
 [0.79]
 [0.79]
 [0.79]] [[5.113]
 [5.113]
 [5.113]
 [5.601]
 [5.113]
 [5.113]
 [5.113]] [[1.724]
 [1.724]
 [1.724]
 [2.073]
 [1.724]
 [1.724]
 [1.724]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07358128431430726, 0.8056691671456414, 0.047168264225744085, 0.07358128431430726]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07555858462955832, 0.8275893241019064, 0.048426045634267625, 0.048426045634267625]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07555858462955832, 0.8275893241019064, 0.048426045634267625, 0.048426045634267625]
Printing some Q and Qe and total Qs values:  [[0.516]
 [0.27 ]
 [0.417]
 [0.513]
 [0.517]
 [0.586]
 [0.508]] [[0.712]
 [1.597]
 [1.238]
 [0.927]
 [1.058]
 [1.16 ]
 [1.009]] [[0.416]
 [0.514]
 [0.569]
 [0.554]
 [0.648]
 [0.856]
 [0.598]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07555858462955832, 0.8275893241019064, 0.048426045634267625, 0.048426045634267625]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07555858462955832, 0.8275893241019064, 0.048426045634267625, 0.048426045634267625]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.07555858462955832, 0.8275893241019064, 0.048426045634267625, 0.048426045634267625]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04975427267786128, 0.8507371819664162, 0.04975427267786128, 0.04975427267786128]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.70264864
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04590830083896196, 0.8110172749471725, 0.07153721210693287, 0.07153721210693287]
Printing some Q and Qe and total Qs values:  [[0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.238]] [[0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]] [[-0.206]
 [-0.206]
 [-0.206]
 [-0.206]
 [-0.206]
 [-0.206]
 [-0.206]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04590830083896196, 0.8110172749471725, 0.07153721210693287, 0.07153721210693287]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04590830083896196, 0.8110172749471725, 0.07153721210693287, 0.07153721210693287]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04590830083896196, 0.8110172749471725, 0.07153721210693287, 0.07153721210693287]
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]] [[3.66 ]
 [3.879]
 [3.879]
 [3.879]
 [3.879]
 [3.879]
 [3.879]] [[1.328]
 [1.509]
 [1.509]
 [1.509]
 [1.509]
 [1.509]
 [1.509]]
using another actor
Printing some Q and Qe and total Qs values:  [[0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.3  ]
 [0.272]] [[5.716]
 [5.716]
 [5.716]
 [5.716]
 [5.716]
 [6.208]
 [5.917]] [[1.07 ]
 [1.07 ]
 [1.07 ]
 [1.07 ]
 [1.07 ]
 [1.305]
 [1.055]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04590830083896196, 0.8110172749471725, 0.07153721210693287, 0.07153721210693287]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04590830083896196, 0.8110172749471725, 0.07153721210693287, 0.07153721210693287]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04590830083896196, 0.8110172749471725, 0.07153721210693287, 0.07153721210693287]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04590830083896196, 0.8110172749471725, 0.07153721210693287, 0.07153721210693287]
from probs:  [0.048345015481363295, 0.8549649535559103, 0.048345015481363295, 0.048345015481363295]
siam score:  -0.6993793
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.566]
 [0.577]
 [0.587]
 [0.596]
 [0.593]
 [0.595]] [[3.455]
 [3.958]
 [3.368]
 [3.483]
 [3.554]
 [3.595]
 [3.453]] [[0.582]
 [0.566]
 [0.577]
 [0.587]
 [0.596]
 [0.593]
 [0.595]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.048345015481363295, 0.8549649535559103, 0.048345015481363295, 0.048345015481363295]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.048345015481363295, 0.8549649535559103, 0.048345015481363295, 0.048345015481363295]
Starting evaluation
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.048345015481363295, 0.8549649535559103, 0.048345015481363295, 0.048345015481363295]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.048345015481363295, 0.8549649535559103, 0.048345015481363295, 0.048345015481363295]
Printing some Q and Qe and total Qs values:  [[0.277]
 [0.26 ]
 [0.277]
 [0.341]
 [0.277]
 [0.277]
 [0.329]] [[0.731]
 [2.431]
 [0.731]
 [0.942]
 [0.731]
 [0.731]
 [0.578]] [[0.277]
 [0.26 ]
 [0.277]
 [0.341]
 [0.277]
 [0.277]
 [0.329]]
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.435]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]] [[0.302]
 [0.94 ]
 [0.302]
 [0.302]
 [0.302]
 [0.302]
 [0.302]] [[0.422]
 [0.435]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]]
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.634]
 [0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.657]] [[1.982]
 [2.99 ]
 [1.982]
 [1.982]
 [1.982]
 [1.982]
 [1.982]] [[0.862]
 [1.356]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.009812839455698
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.401]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]] [[2.37 ]
 [2.949]
 [2.37 ]
 [2.37 ]
 [2.37 ]
 [2.37 ]
 [2.37 ]] [[0.427]
 [0.401]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.048345015481363295, 0.8549649535559103, 0.048345015481363295, 0.048345015481363295]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.472]
 [0.432]
 [0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]] [[2.837]
 [3.425]
 [2.837]
 [2.837]
 [2.837]
 [2.837]
 [2.837]] [[0.472]
 [0.432]
 [0.472]
 [0.472]
 [0.472]
 [0.472]
 [0.472]]
first move QE:  1.4362250286156344
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.048345015481363295, 0.8549649535559103, 0.048345015481363295, 0.048345015481363295]
Printing some Q and Qe and total Qs values:  [[0.169]
 [0.244]
 [0.169]
 [0.169]
 [0.169]
 [0.236]
 [0.169]] [[5.165]
 [5.027]
 [5.165]
 [5.165]
 [5.165]
 [5.336]
 [5.165]] [[0.722]
 [0.782]
 [0.722]
 [0.722]
 [0.722]
 [0.971]
 [0.722]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
rdn probs:  [0.048345015481363295, 0.8549649535559103, 0.048345015481363295, 0.048345015481363295]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.048345015481363295, 0.8549649535559103, 0.048345015481363295, 0.048345015481363295]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.048345015481363295, 0.8549649535559103, 0.048345015481363295, 0.048345015481363295]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04583586051248396, 0.8369677848723598, 0.07136049410267213, 0.04583586051248396]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04583586051248396, 0.8369677848723598, 0.07136049410267213, 0.04583586051248396]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04583586051248396, 0.8369677848723598, 0.07136049410267213, 0.04583586051248396]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.553]
 [0.635]
 [0.553]
 [0.553]
 [0.553]
 [0.553]
 [0.553]] [[1.737]
 [3.404]
 [1.737]
 [1.737]
 [1.737]
 [1.737]
 [1.737]] [[0.869]
 [1.59 ]
 [0.869]
 [0.869]
 [0.869]
 [0.869]
 [0.869]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04583586051248396, 0.8369677848723598, 0.07136049410267213, 0.04583586051248396]
Printing some Q and Qe and total Qs values:  [[0.192]
 [0.166]
 [0.22 ]
 [0.186]
 [0.186]
 [0.219]
 [0.308]] [[-0.88 ]
 [ 0.661]
 [-0.477]
 [-0.574]
 [-0.573]
 [-0.655]
 [-0.472]] [[0.192]
 [0.166]
 [0.22 ]
 [0.186]
 [0.186]
 [0.219]
 [0.308]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04583586051248396, 0.8369677848723598, 0.07136049410267213, 0.04583586051248396]
1164 1279
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04583586051248396, 0.8369677848723598, 0.07136049410267213, 0.04583586051248396]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
from probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[1.088]
 [1.088]
 [1.088]
 [1.088]
 [1.088]
 [1.088]
 [1.088]] [[1.431]
 [1.431]
 [1.431]
 [1.431]
 [1.431]
 [1.431]
 [1.431]] [[1.754]
 [1.754]
 [1.754]
 [1.754]
 [1.754]
 [1.754]
 [1.754]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Printing some Q and Qe and total Qs values:  [[0.332]
 [0.387]
 [0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]] [[-0.844]
 [ 1.213]
 [-0.844]
 [-0.844]
 [-0.844]
 [-0.844]
 [-0.844]] [[0.332]
 [0.387]
 [0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]]
Printing some Q and Qe and total Qs values:  [[0.282]
 [0.372]
 [0.292]
 [0.292]
 [0.292]
 [0.292]
 [0.286]] [[-1.176]
 [ 0.618]
 [-0.807]
 [-0.807]
 [-0.807]
 [-0.807]
 [-1.184]] [[0.282]
 [0.372]
 [0.292]
 [0.292]
 [0.292]
 [0.292]
 [0.286]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
siam score:  -0.6953364
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Printing some Q and Qe and total Qs values:  [[0.492]
 [0.44 ]
 [0.492]
 [0.479]
 [0.469]
 [0.488]
 [0.495]] [[5.433]
 [5.215]
 [5.422]
 [5.417]
 [5.437]
 [5.494]
 [5.429]] [[1.271]
 [1.023]
 [1.266]
 [1.235]
 [1.228]
 [1.306]
 [1.276]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Printing some Q and Qe and total Qs values:  [[0.35 ]
 [0.333]
 [0.332]
 [0.355]
 [0.337]
 [0.33 ]
 [0.333]] [[5.187]
 [5.219]
 [4.34 ]
 [6.353]
 [5.402]
 [4.817]
 [5.219]] [[0.912]
 [0.904]
 [0.457]
 [1.512]
 [1.002]
 [0.695]
 [0.904]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Printing some Q and Qe and total Qs values:  [[0.575]
 [0.639]
 [0.632]
 [0.603]
 [0.57 ]
 [0.656]
 [0.601]] [[3.814]
 [3.248]
 [3.88 ]
 [3.819]
 [3.627]
 [3.97 ]
 [3.905]] [[0.579]
 [0.33 ]
 [0.738]
 [0.639]
 [0.446]
 [0.845]
 [0.692]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.69225997
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]] [[5.706]
 [5.706]
 [5.706]
 [5.706]
 [5.706]
 [5.706]
 [5.706]] [[1.745]
 [1.745]
 [1.745]
 [1.745]
 [1.745]
 [1.745]
 [1.745]]
siam score:  -0.6901554
from probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.454]
 [0.175]
 [0.358]
 [0.383]
 [0.41 ]
 [0.385]
 [0.353]] [[4.082]
 [4.136]
 [3.939]
 [3.722]
 [3.526]
 [3.843]
 [3.66 ]] [[0.718]
 [0.197]
 [0.431]
 [0.336]
 [0.261]
 [0.421]
 [0.236]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Printing some Q and Qe and total Qs values:  [[0.49 ]
 [0.482]
 [0.499]
 [0.498]
 [0.49 ]
 [0.497]
 [0.501]] [[3.743]
 [4.79 ]
 [4.064]
 [4.102]
 [3.983]
 [4.003]
 [4.179]] [[0.49 ]
 [0.482]
 [0.499]
 [0.498]
 [0.49 ]
 [0.497]
 [0.501]]
using explorer policy with actor:  1
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 4.529462224220978
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.431]
 [0.421]
 [0.429]
 [0.435]
 [0.439]
 [0.454]] [[4.022]
 [3.939]
 [4.259]
 [4.338]
 [4.447]
 [4.529]
 [4.541]] [[0.573]
 [0.532]
 [0.726]
 [0.793]
 [0.879]
 [0.941]
 [0.979]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Printing some Q and Qe and total Qs values:  [[-0.013]
 [-0.013]
 [-0.013]
 [-0.013]
 [-0.013]
 [-0.013]
 [-0.013]] [[3.583]
 [3.583]
 [3.583]
 [3.583]
 [3.583]
 [3.583]
 [3.583]] [[-0.488]
 [-0.488]
 [-0.488]
 [-0.488]
 [-0.488]
 [-0.488]
 [-0.488]]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Printing some Q and Qe and total Qs values:  [[-0.023]
 [-0.017]
 [-0.023]
 [ 0.01 ]
 [ 0.013]
 [-0.002]
 [-0.023]] [[3.984]
 [3.699]
 [3.984]
 [4.715]
 [4.385]
 [4.484]
 [3.984]] [[ 0.149]
 [-0.014]
 [ 0.149]
 [ 0.65 ]
 [ 0.456]
 [ 0.489]
 [ 0.149]]
siam score:  -0.69412285
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Printing some Q and Qe and total Qs values:  [[1.22 ]
 [1.327]
 [1.218]
 [1.284]
 [1.273]
 [1.289]
 [1.288]] [[3.457]
 [2.739]
 [3.514]
 [3.057]
 [3.016]
 [3.07 ]
 [3.081]] [[2.453]
 [2.283]
 [2.476]
 [2.364]
 [2.333]
 [2.377]
 [2.38 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
Printing some Q and Qe and total Qs values:  [[0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]] [[3.262]
 [3.262]
 [3.262]
 [3.262]
 [3.262]
 [3.262]
 [3.262]] [[2.023]
 [2.023]
 [2.023]
 [2.023]
 [2.023]
 [2.023]
 [2.023]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.042570344689774005, 0.8013542736861702, 0.0898973462817037, 0.0661780353423521]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04357966757112587, 0.8207850120058474, 0.09205565285190083, 0.04357966757112587]
Printing some Q and Qe and total Qs values:  [[0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]] [[1.811]
 [1.811]
 [1.811]
 [1.811]
 [1.811]
 [1.811]
 [1.811]] [[0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04357966757112587, 0.8207850120058474, 0.09205565285190083, 0.04357966757112587]
Printing some Q and Qe and total Qs values:  [[0.761]
 [0.761]
 [0.761]
 [0.843]
 [0.761]
 [0.761]
 [0.761]] [[6.183]
 [6.183]
 [6.183]
 [6.925]
 [6.183]
 [6.183]
 [6.183]] [[1.83]
 [1.83]
 [1.83]
 [2.28]
 [1.83]
 [1.83]
 [1.83]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04357966757112587, 0.8207850120058474, 0.09205565285190083, 0.04357966757112587]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04357966757112587, 0.8207850120058474, 0.09205565285190083, 0.04357966757112587]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
siam score:  -0.69658643
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.475]
 [0.525]
 [0.475]
 [0.475]
 [0.475]
 [0.475]
 [0.475]] [[2.176]
 [2.574]
 [2.176]
 [2.176]
 [2.176]
 [2.176]
 [2.176]] [[0.475]
 [0.525]
 [0.475]
 [0.475]
 [0.475]
 [0.475]
 [0.475]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
Printing some Q and Qe and total Qs values:  [[0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.477]] [[5.178]
 [5.178]
 [5.178]
 [5.178]
 [5.178]
 [5.178]
 [5.178]] [[0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.477]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
using explorer policy with actor:  1
start point for exploration sampling:  10723
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.372066655471902
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
Printing some Q and Qe and total Qs values:  [[0.636]
 [0.627]
 [0.636]
 [0.636]
 [0.636]
 [0.636]
 [0.636]] [[4.197]
 [5.515]
 [4.197]
 [4.197]
 [4.197]
 [4.197]
 [4.197]] [[0.85]
 [1.71]
 [0.85]
 [0.85]
 [0.85]
 [0.85]
 [0.85]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
using explorer policy with actor:  1
1187 1290
line 256 mcts: sample exp_bonus 3.022248044203601
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
Printing some Q and Qe and total Qs values:  [[0.572]
 [0.56 ]
 [0.572]
 [0.61 ]
 [0.572]
 [0.572]
 [0.579]] [[2.789]
 [4.266]
 [2.789]
 [2.707]
 [2.789]
 [2.789]
 [2.853]] [[0.572]
 [0.56 ]
 [0.572]
 [0.61 ]
 [0.572]
 [0.572]
 [0.579]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
Printing some Q and Qe and total Qs values:  [[0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.435]] [[3.211]
 [3.211]
 [3.211]
 [3.211]
 [3.211]
 [3.211]
 [3.211]] [[0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.435]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04251085064828644, 0.8254350816957197, 0.06602703382799698, 0.06602703382799698]
Printing some Q and Qe and total Qs values:  [[1.373]
 [1.373]
 [1.373]
 [1.373]
 [1.373]
 [1.373]
 [1.373]] [[1.409]
 [1.409]
 [1.409]
 [1.409]
 [1.409]
 [1.409]
 [1.409]] [[2.618]
 [2.618]
 [2.618]
 [2.618]
 [2.618]
 [2.618]
 [2.618]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04351472798057, 0.8453709840233049, 0.04351472798057, 0.06759956001555516]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04351472798057, 0.8453709840233049, 0.04351472798057, 0.06759956001555516]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.1679412538489784
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.281]
 [0.245]
 [0.263]
 [0.257]
 [0.255]
 [0.252]
 [0.256]] [[0.733]
 [2.077]
 [0.776]
 [0.969]
 [1.048]
 [1.417]
 [0.929]] [[0.281]
 [0.245]
 [0.263]
 [0.257]
 [0.255]
 [0.252]
 [0.256]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.69109213
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04351472798057, 0.8453709840233049, 0.04351472798057, 0.06759956001555516]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04351472798057, 0.8453709840233049, 0.04351472798057, 0.06759956001555516]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04351472798057, 0.8453709840233049, 0.04351472798057, 0.06759956001555516]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04351472798057, 0.8453709840233049, 0.04351472798057, 0.06759956001555516]
Printing some Q and Qe and total Qs values:  [[0.787]
 [0.23 ]
 [0.559]
 [0.524]
 [0.578]
 [0.618]
 [0.578]] [[ 0.781]
 [ 1.686]
 [-0.025]
 [-0.206]
 [ 0.015]
 [-0.023]
 [-0.307]] [[1.374]
 [0.934]
 [0.52 ]
 [0.356]
 [0.576]
 [0.623]
 [0.391]]
Printing some Q and Qe and total Qs values:  [[0.109]
 [0.109]
 [0.109]
 [0.109]
 [0.109]
 [1.47 ]
 [0.109]] [[2.826]
 [2.826]
 [2.826]
 [2.826]
 [2.826]
 [1.369]
 [2.826]] [[0.943]
 [0.943]
 [0.943]
 [0.943]
 [0.943]
 [2.694]
 [0.943]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04351472798057, 0.8453709840233049, 0.04351472798057, 0.06759956001555516]
using explorer policy with actor:  1
1195 1308
siam score:  -0.69361097
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04351472798057, 0.8453709840233049, 0.04351472798057, 0.06759956001555516]
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.709]
 [0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.657]] [[2.058]
 [3.712]
 [2.058]
 [2.058]
 [2.058]
 [2.058]
 [2.058]] [[1.378]
 [1.857]
 [1.378]
 [1.378]
 [1.378]
 [1.378]
 [1.378]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06294225446398416, 0.8110679861939499, 0.040576541467893176, 0.08541321787417264]
Printing some Q and Qe and total Qs values:  [[0.54 ]
 [0.534]
 [0.54 ]
 [0.607]
 [0.59 ]
 [0.54 ]
 [0.562]] [[4.81 ]
 [4.091]
 [4.193]
 [3.945]
 [3.154]
 [4.193]
 [4.209]] [[2.036]
 [1.559]
 [1.635]
 [1.605]
 [1.06 ]
 [1.635]
 [1.688]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06294225446398416, 0.8110679861939499, 0.040576541467893176, 0.08541321787417264]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06294225446398416, 0.8110679861939499, 0.040576541467893176, 0.08541321787417264]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06294225446398416, 0.8110679861939499, 0.040576541467893176, 0.08541321787417264]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06294225446398416, 0.8110679861939499, 0.040576541467893176, 0.08541321787417264]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06294225446398416, 0.8110679861939499, 0.040576541467893176, 0.08541321787417264]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06294225446398416, 0.8110679861939499, 0.040576541467893176, 0.08541321787417264]
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.06294225446398416, 0.8110679861939499, 0.040576541467893176, 0.08541321787417264]
Printing some Q and Qe and total Qs values:  [[0.546]
 [0.595]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.58 ]] [[ 1.181]
 [-0.245]
 [ 0.44 ]
 [ 0.44 ]
 [ 0.44 ]
 [ 0.44 ]
 [ 0.192]] [[1.379]
 [0.527]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.789]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.06294225446398416, 0.8110679861939499, 0.040576541467893176, 0.08541321787417264]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.6825888
Printing some Q and Qe and total Qs values:  [[0.392]
 [0.381]
 [0.412]
 [0.456]
 [0.408]
 [0.443]
 [0.408]] [[3.739]
 [3.922]
 [3.604]
 [3.768]
 [3.769]
 [3.768]
 [4.045]] [[0.105]
 [0.145]
 [0.1  ]
 [0.243]
 [0.147]
 [0.217]
 [0.24 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04148574546449067, 0.8296761441958245, 0.04148574546449067, 0.08735236487519418]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04148574546449067, 0.8296761441958245, 0.04148574546449067, 0.08735236487519418]
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.9952812026544176
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04148574546449067, 0.8296761441958245, 0.04148574546449067, 0.08735236487519418]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04148574546449067, 0.8296761441958245, 0.04148574546449067, 0.08735236487519418]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04148574546449067, 0.8296761441958245, 0.04148574546449067, 0.08735236487519418]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04148574546449067, 0.8296761441958245, 0.04148574546449067, 0.08735236487519418]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04148574546449067, 0.8296761441958245, 0.04148574546449067, 0.08735236487519418]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04148574546449067, 0.8296761441958245, 0.04148574546449067, 0.08735236487519418]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04148574546449067, 0.8296761441958245, 0.04148574546449067, 0.08735236487519418]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.266910945226202
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
Printing some Q and Qe and total Qs values:  [[0.28 ]
 [0.289]
 [0.3  ]
 [0.305]
 [0.327]
 [0.329]
 [0.313]] [[4.299]
 [4.227]
 [4.228]
 [4.332]
 [4.839]
 [4.533]
 [4.365]] [[0.341]
 [0.312]
 [0.335]
 [0.414]
 [0.797]
 [0.596]
 [0.451]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
Printing some Q and Qe and total Qs values:  [[0.449]
 [0.442]
 [0.453]
 [0.45 ]
 [0.448]
 [0.445]
 [0.437]] [[5.483]
 [6.034]
 [5.455]
 [5.482]
 [5.561]
 [5.622]
 [5.66 ]] [[1.227]
 [1.534]
 [1.218]
 [1.228]
 [1.27 ]
 [1.301]
 [1.309]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
from probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
1209 1326
from probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
start point for exploration sampling:  10723
Printing some Q and Qe and total Qs values:  [[0.012]
 [0.096]
 [0.106]
 [0.135]
 [0.106]
 [0.106]
 [0.128]] [[ 1.345]
 [ 1.322]
 [-0.544]
 [-1.239]
 [-0.544]
 [-0.544]
 [ 0.182]] [[0.012]
 [0.096]
 [0.106]
 [0.135]
 [0.106]
 [0.106]
 [0.128]]
siam score:  -0.68090713
Printing some Q and Qe and total Qs values:  [[0.542]
 [0.494]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]] [[2.661]
 [3.232]
 [3.031]
 [3.031]
 [3.031]
 [3.031]
 [3.031]] [[0.763]
 [1.047]
 [0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
Printing some Q and Qe and total Qs values:  [[0.29 ]
 [0.3  ]
 [0.311]
 [0.311]
 [0.311]
 [0.311]
 [0.326]] [[2.459]
 [3.499]
 [2.697]
 [2.697]
 [2.697]
 [2.697]
 [2.822]] [[0.29 ]
 [0.3  ]
 [0.311]
 [0.311]
 [0.311]
 [0.311]
 [0.326]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04244228780001435, 0.849253148896109, 0.04244228780001435, 0.06586227550386224]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
1211 1328
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
UNIT TEST: sample policy line 217 mcts : [0.02  0.102 0.551 0.041 0.082 0.143 0.061]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04051854631566316, 0.8338873555381581, 0.06279704907308949, 0.06279704907308949]
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]] [[4.325]
 [4.325]
 [4.325]
 [4.325]
 [4.325]
 [4.325]
 [4.325]] [[1.005]
 [1.005]
 [1.005]
 [1.005]
 [1.005]
 [1.005]
 [1.005]]
siam score:  -0.68195933
using another actor
from probs:  [0.04051854631566316, 0.8338873555381581, 0.06279704907308949, 0.06279704907308949]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04142279706309051, 0.8529433878602479, 0.04142279706309051, 0.06421101801357121]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04142279706309051, 0.8529433878602479, 0.04142279706309051, 0.06421101801357121]
Printing some Q and Qe and total Qs values:  [[0.472]
 [0.206]
 [0.543]
 [0.505]
 [0.496]
 [0.509]
 [0.481]] [[0.739]
 [1.92 ]
 [0.556]
 [0.215]
 [0.22 ]
 [0.287]
 [0.171]] [[0.734]
 [0.989]
 [0.753]
 [0.451]
 [0.435]
 [0.506]
 [0.372]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04142279706309051, 0.8529433878602479, 0.04142279706309051, 0.06421101801357121]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04142279706309051, 0.8529433878602479, 0.04142279706309051, 0.06421101801357121]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.389361498722404
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04142279706309051, 0.8529433878602479, 0.04142279706309051, 0.06421101801357121]
from probs:  [0.04142279706309051, 0.8529433878602479, 0.04142279706309051, 0.06421101801357121]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04142279706309051, 0.8529433878602479, 0.04142279706309051, 0.06421101801357121]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04142279706309051, 0.8529433878602479, 0.04142279706309051, 0.06421101801357121]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04236939404768917, 0.8728918178569324, 0.04236939404768917, 0.04236939404768917]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04236939404768917, 0.8728918178569324, 0.04236939404768917, 0.04236939404768917]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04236939404768917, 0.8728918178569324, 0.04236939404768917, 0.04236939404768917]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04236939404768917, 0.8728918178569324, 0.04236939404768917, 0.04236939404768917]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04236939404768917, 0.8728918178569324, 0.04236939404768917, 0.04236939404768917]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.04236939404768917, 0.8728918178569324, 0.04236939404768917, 0.04236939404768917]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.03716562700704189, 0.8071553038940801, 0.07783953454943902, 0.07783953454943902]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3319515906712605, 0.001052715130699165, 0.33349784709902014, 0.33349784709902014]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3319515906712605, 0.001052715130699165, 0.33349784709902014, 0.33349784709902014]
Printing some Q and Qe and total Qs values:  [[1.059]
 [1.059]
 [1.059]
 [1.319]
 [1.059]
 [1.059]
 [1.059]] [[2.429]
 [2.429]
 [2.429]
 [3.62 ]
 [2.429]
 [2.429]
 [2.429]] [[1.692]
 [1.692]
 [1.692]
 [2.628]
 [1.692]
 [1.692]
 [1.692]]
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.206]
 [0.526]
 [0.498]
 [0.456]
 [0.601]
 [0.576]] [[1.411]
 [2.087]
 [1.017]
 [0.975]
 [1.317]
 [1.268]
 [0.919]] [[0.704]
 [0.719]
 [0.645]
 [0.561]
 [0.705]
 [0.962]
 [0.681]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322092845634601, 0.0010527592787275284, 0.33298121119582547, 0.33375674496198693]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322092845634601, 0.0010527592787275284, 0.33298121119582547, 0.33375674496198693]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322092845634601, 0.0010527592787275284, 0.33298121119582547, 0.33375674496198693]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322092845634601, 0.0010527592787275284, 0.33298121119582547, 0.33375674496198693]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322092845634601, 0.0010527592787275284, 0.33298121119582547, 0.33375674496198693]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322092845634601, 0.0010527592787275284, 0.33298121119582547, 0.33375674496198693]
Printing some Q and Qe and total Qs values:  [[ 0.006]
 [ 0.01 ]
 [-0.   ]
 [ 0.023]
 [-0.001]
 [ 0.045]
 [ 0.005]] [[5.466]
 [4.481]
 [5.3  ]
 [5.836]
 [5.29 ]
 [5.493]
 [5.169]] [[ 0.308]
 [-0.222]
 [ 0.208]
 [ 0.537]
 [ 0.202]
 [ 0.387]
 [ 0.145]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322092845634601, 0.0010527592787275284, 0.33298121119582547, 0.33375674496198693]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322092845634601, 0.0010527592787275284, 0.33298121119582547, 0.33375674496198693]
Printing some Q and Qe and total Qs values:  [[-0.052]
 [-0.069]
 [-0.06 ]
 [-0.062]
 [-0.064]
 [-0.064]
 [-0.064]] [[5.219]
 [5.176]
 [6.475]
 [6.447]
 [6.067]
 [6.218]
 [6.225]] [[-0.557]
 [-0.612]
 [ 0.164]
 [ 0.144]
 [-0.082]
 [ 0.007]
 [ 0.01 ]]
first move QE:  1.3878415229537482
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.6904257
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3319539425774841, 0.0010528473705130419, 0.33349660502600137, 0.33349660502600137]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 2.0153340381986737
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.671]
 [0.671]
 [0.671]
 [0.671]
 [0.671]
 [0.88 ]
 [0.671]] [[1.551]
 [1.551]
 [1.551]
 [1.551]
 [1.551]
 [1.545]
 [1.551]] [[1.395]
 [1.395]
 [1.395]
 [1.395]
 [1.395]
 [1.707]
 [1.395]]
siam score:  -0.68784624
Printing some Q and Qe and total Qs values:  [[0.515]
 [0.527]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]] [[-2.117]
 [ 0.418]
 [-2.117]
 [-2.117]
 [-2.117]
 [-2.117]
 [-2.117]] [[2.016]
 [2.768]
 [2.016]
 [2.016]
 [2.016]
 [2.016]
 [2.016]]
start point for exploration sampling:  10723
first move QE:  1.3855664002247867
Printing some Q and Qe and total Qs values:  [[0.941]
 [0.941]
 [0.941]
 [0.941]
 [0.941]
 [1.408]
 [0.941]] [[-0.335]
 [-0.335]
 [-0.335]
 [-0.335]
 [-0.335]
 [ 3.014]
 [-0.335]] [[0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.934]
 [1.96 ]
 [0.934]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.332214518372267, 0.0010531559971254105, 0.33298109559998723, 0.3337512300306204]
Printing some Q and Qe and total Qs values:  [[0.892]
 [0.9  ]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [0.88 ]
 [1.062]] [[4.228]
 [4.103]
 [3.985]
 [3.985]
 [3.985]
 [3.985]
 [6.143]] [[1.548]
 [1.536]
 [1.499]
 [1.499]
 [1.499]
 [1.499]
 [2.002]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3324708196521329, 0.001053200212864039, 0.33323799006750154, 0.33323799006750154]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33145261089416417, 0.001053287830512382, 0.3337470506376617, 0.3337470506376617]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33094584928711546, 0.001053331437739224, 0.33400040963757266, 0.33400040963757266]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33044063995971895, 0.0010533749113912053, 0.33425299256444496, 0.33425299256444496]
Printing some Q and Qe and total Qs values:  [[0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]] [[6.748]
 [6.748]
 [6.748]
 [6.748]
 [6.748]
 [6.748]
 [6.748]] [[7.988]
 [7.988]
 [7.988]
 [7.988]
 [7.988]
 [7.988]
 [7.988]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3309493038796436, 0.001053463473896124, 0.3332296898732316, 0.3347675427732286]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3309493038796436, 0.001053463473896124, 0.3332296898732316, 0.3347675427732286]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3309493038796436, 0.001053463473896124, 0.3332296898732316, 0.3347675427732286]
siam score:  -0.6815567
start point for exploration sampling:  10723
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33096424600944957, 0.001053860400851439, 0.3339909467948495, 0.3339909467948495]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33096424600944957, 0.001053860400851439, 0.3339909467948495, 0.3339909467948495]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33096424600944957, 0.001053860400851439, 0.3339909467948495, 0.3339909467948495]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33071600729609263, 0.0010539482265359752, 0.33373350898093984, 0.33449653549643155]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33071600729609263, 0.0010539482265359752, 0.33373350898093984, 0.33449653549643155]
Printing some Q and Qe and total Qs values:  [[0.423]
 [0.429]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]] [[2.933]
 [2.813]
 [2.933]
 [2.933]
 [2.933]
 [2.933]
 [2.933]] [[0.423]
 [0.429]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3309687923858254, 0.001053992641250218, 0.3339886074864622, 0.3339886074864622]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3312208084524124, 0.0010540369208459587, 0.3342429299309622, 0.3334822246957794]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33147320976679373, 0.0010540812681303067, 0.33373635448253797, 0.33373635448253797]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33147320976679373, 0.0010540812681303067, 0.33373635448253797, 0.33373635448253797]
Printing some Q and Qe and total Qs values:  [[-0.04 ]
 [-0.034]
 [-0.035]
 [-0.037]
 [-0.037]
 [-0.034]
 [-0.041]] [[7.273]
 [7.432]
 [6.975]
 [7.077]
 [7.102]
 [7.353]
 [7.174]] [[0.961]
 [1.04 ]
 [0.829]
 [0.875]
 [0.885]
 [1.003]
 [0.915]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33147320976679373, 0.0010540812681303067, 0.33373635448253797, 0.33373635448253797]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.55 ]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]] [[6.875]
 [4.835]
 [6.875]
 [6.875]
 [6.875]
 [6.875]
 [6.875]] [[2.023]
 [1.211]
 [2.023]
 [2.023]
 [2.023]
 [2.023]
 [2.023]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33172484468488, 0.0010541254807576918, 0.333231317209728, 0.3339897126246343]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33172484468488, 0.0010541254807576918, 0.333231317209728, 0.3339897126246343]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.331975716692031, 0.001054169559340497, 0.3327278111173326, 0.334242302631296]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3329807467931471, 0.001054346144616139, 0.33222978208579756, 0.3337351249764392]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.334982834849099, 0.0010546979144495274, 0.33198123361822574, 0.33198123361822574]
Printing some Q and Qe and total Qs values:  [[0.667]
 [0.667]
 [0.667]
 [0.606]
 [0.667]
 [0.629]
 [0.579]] [[7.266]
 [7.266]
 [7.266]
 [8.434]
 [7.266]
 [6.693]
 [6.909]] [[1.684]
 [1.684]
 [1.684]
 [2.132]
 [1.684]
 [1.408]
 [1.457]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3342278835244642, 0.0010548307513702862, 0.3319868091784568, 0.33273047654570864]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3342278835244642, 0.0010548307513702862, 0.3319868091784568, 0.33273047654570864]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33347857515219825, 0.00105496338540881, 0.3327332307311965, 0.3327332307311965]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33372645186875577, 0.0010550073326768433, 0.3322379890296682, 0.33298055176889907]
Printing some Q and Qe and total Qs values:  [[1.25 ]
 [0.471]
 [0.578]
 [0.502]
 [0.493]
 [0.613]
 [0.51 ]] [[-1.339]
 [-0.218]
 [-0.22 ]
 [-0.293]
 [-0.193]
 [ 0.02 ]
 [-0.251]] [[1.652]
 [0.468]
 [0.681]
 [0.504]
 [0.52 ]
 [0.831]
 [0.534]]
Printing some Q and Qe and total Qs values:  [[1.126]
 [0.624]
 [0.624]
 [0.624]
 [0.624]
 [0.624]
 [0.624]] [[0.922]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]] [[2.189]
 [1.146]
 [1.146]
 [1.146]
 [1.146]
 [1.146]
 [1.146]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33372645186875577, 0.0010550073326768433, 0.3322379890296682, 0.33298055176889907]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3332293559018811, 0.0010550515434808278, 0.3324862366527571, 0.3332293559018811]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3332293559018811, 0.0010550515434808278, 0.3324862366527571, 0.3332293559018811]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3332293559018811, 0.0010550515434808278, 0.3324862366527571, 0.3332293559018811]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3332293559018811, 0.0010550515434808278, 0.3324862366527571, 0.3332293559018811]
using explorer policy with actor:  1
from probs:  [0.3332293559018811, 0.0010550515434808278, 0.3324862366527571, 0.3332293559018811]
Printing some Q and Qe and total Qs values:  [[0.595]
 [0.628]
 [0.591]
 [0.612]
 [0.501]
 [0.617]
 [0.591]] [[4.783]
 [5.029]
 [4.397]
 [4.49 ]
 [4.858]
 [5.005]
 [4.397]] [[1.392]
 [1.509]
 [1.244]
 [1.295]
 [1.349]
 [1.492]
 [1.244]]
siam score:  -0.68068695
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33298162007763904, 0.0010551397670828223, 0.33298162007763904, 0.33298162007763904]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33298162007763904, 0.0010551397670828223, 0.33298162007763904, 0.33298162007763904]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.794]
 [0.794]
 [0.794]
 [1.206]
 [0.794]
 [0.794]
 [0.794]] [[1.371]
 [1.371]
 [1.371]
 [1.524]
 [1.371]
 [1.371]
 [1.371]] [[1.494]
 [1.494]
 [1.494]
 [2.257]
 [1.494]
 [1.494]
 [1.494]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3324872994920001, 0.0010551837803232842, 0.3332287583638383, 0.3332287583638383]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.912]
 [0.912]
 [0.912]
 [0.912]
 [0.912]
 [1.346]
 [0.912]] [[2.136]
 [2.136]
 [2.136]
 [2.136]
 [2.136]
 [1.433]
 [2.136]] [[1.174]
 [1.174]
 [1.174]
 [1.174]
 [1.174]
 [1.805]
 [1.174]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33273425363250586, 0.0010552278591416488, 0.33273425363250586, 0.33347626487584664]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327325621396339, 0.0010553597023806357, 0.3319955016897733, 0.3342165764682122]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327325621396339, 0.0010553597023806357, 0.3319955016897733, 0.3342165764682122]
Printing some Q and Qe and total Qs values:  [[ 0.039]
 [-0.01 ]
 [ 0.052]
 [ 0.035]
 [ 0.073]
 [ 0.05 ]
 [-0.008]] [[4.203]
 [4.015]
 [4.132]
 [4.774]
 [4.44 ]
 [4.392]
 [4.803]] [[0.852]
 [0.699]
 [0.828]
 [1.152]
 [1.014]
 [0.964]
 [1.122]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327325621396339, 0.0010553597023806357, 0.3319955016897733, 0.3342165764682122]
Printing some Q and Qe and total Qs values:  [[1.05 ]
 [1.05 ]
 [1.05 ]
 [1.349]
 [1.05 ]
 [1.05 ]
 [1.05 ]] [[2.745]
 [2.745]
 [2.745]
 [3.022]
 [2.745]
 [2.745]
 [2.745]] [[1.824]
 [1.824]
 [1.824]
 [2.335]
 [1.824]
 [1.824]
 [1.824]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327325621396339, 0.0010553597023806357, 0.3319955016897733, 0.3342165764682122]
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.661]
 [0.637]
 [0.672]
 [0.637]
 [0.637]
 [0.59 ]] [[2.167]
 [1.451]
 [0.845]
 [0.703]
 [0.845]
 [0.845]
 [1.723]] [[2.413]
 [2.463]
 [2.28 ]
 [2.296]
 [2.28 ]
 [2.28 ]
 [2.426]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33322537959639287, 0.0010554478616269733, 0.3317523422051079, 0.33396683033687224]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33322537959639287, 0.0010554478616269733, 0.3317523422051079, 0.33396683033687224]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33273307719097966, 0.0010554919397705016, 0.3319976501726844, 0.3342137806965655]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3329771170322575, 0.001055535692839283, 0.33150843746880887, 0.3344589098060943]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3329771170322575, 0.001055535692839283, 0.33150843746880887, 0.3344589098060943]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33272923020806927, 0.0010556233936736142, 0.33126488757312716, 0.33495025882512997]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3324817182400342, 0.0010557109644200673, 0.33102169177626495, 0.33544087901928077]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327232490898296, 0.0010557544600845307, 0.33053643044391917, 0.33568456600616664]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327232490898296, 0.0010557544600845307, 0.33053643044391917, 0.33568456600616664]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327302863054146, 0.0010558878711949234, 0.3312723768617477, 0.33494144896164274]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33370652833944453, 0.0010560640649281848, 0.3307949269015932, 0.33444248069403415]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33370652833944453, 0.0010560640649281848, 0.3307949269015932, 0.33444248069403415]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33370652833944453, 0.0010560640649281848, 0.3307949269015932, 0.33444248069403415]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33394719666146916, 0.001056107501134225, 0.3303130144653956, 0.33468368137200094]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33394719666146916, 0.001056107501134225, 0.3303130144653956, 0.33468368137200094]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33394719666146916, 0.001056107501134225, 0.3303130144653956, 0.33468368137200094]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33394719666146916, 0.001056107501134225, 0.3303130144653956, 0.33468368137200094]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3341871624747208, 0.0010561508105503498, 0.3298325087274767, 0.33492417798725216]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3341871624747208, 0.0010561508105503498, 0.3298325087274767, 0.33492417798725216]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3341871624747208, 0.0010561508105503498, 0.3298325087274767, 0.33492417798725216]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3341871624747208, 0.0010561508105503498, 0.3298325087274767, 0.33492417798725216]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3341871624747208, 0.0010561508105503498, 0.3298325087274767, 0.33492417798725216]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3344338943591395, 0.0010561953411178883, 0.33007601594060326, 0.3344338943591395]
line 256 mcts: sample exp_bonus 1.2096558857584687
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.300853393518754
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3344338943591395, 0.0010561953411178883, 0.33007601594060326, 0.3344338943591395]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3344338943591395, 0.0010561953411178883, 0.33007601594060326, 0.3344338943591395]
siam score:  -0.65131325
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3344338943591395, 0.0010561953411178883, 0.33007601594060326, 0.3344338943591395]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3346735153527048, 0.0010562385883004027, 0.3295967307062899, 0.3346735153527048]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3354051474296422, 0.001056370634434984, 0.32960299945922644, 0.33393548247669624]
Printing some Q and Qe and total Qs values:  [[0.829]
 [0.829]
 [0.829]
 [0.829]
 [0.829]
 [0.829]
 [0.829]] [[0.992]
 [0.992]
 [0.992]
 [0.992]
 [0.992]
 [0.992]
 [0.992]] [[1.145]
 [1.145]
 [1.145]
 [1.145]
 [1.145]
 [1.145]
 [1.145]]
Printing some Q and Qe and total Qs values:  [[0.498]
 [0.484]
 [0.498]
 [0.505]
 [0.498]
 [0.498]
 [0.498]] [[1.993]
 [2.464]
 [1.993]
 [2.183]
 [1.993]
 [1.993]
 [1.993]] [[0.498]
 [0.484]
 [0.498]
 [0.505]
 [0.498]
 [0.498]
 [0.498]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33516069201070486, 0.0010564596265807958, 0.3300875257922908, 0.3336953225704236]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3354050736266853, 0.0010565038303155863, 0.33032819729572094, 0.33321022524727817]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33588855379818594, 0.0010565912821854494, 0.33009059773730287, 0.3329642571823257]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33613186337010054, 0.001056635292008962, 0.3303296949185318, 0.33248180641935876]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3363713272472021, 0.0010566786062233837, 0.32985333191724786, 0.33271866222932656]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3358821552656979, 0.0010567235239552829, 0.3300968346308514, 0.3329642865794954]
Printing some Q and Qe and total Qs values:  [[0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [1.005]
 [0.757]] [[4.554]
 [4.554]
 [4.554]
 [4.554]
 [4.554]
 [8.268]
 [4.554]] [[0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [2.432]
 [0.862]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3358821552656979, 0.0010567235239552829, 0.3300968346308514, 0.3329642865794954]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3358821552656979, 0.0010567235239552829, 0.3300968346308514, 0.3329642865794954]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3361249308064148, 0.0010567675338908958, 0.3303354161062416, 0.3324828855534526]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3361249308064148, 0.0010567675338908958, 0.3303354161062416, 0.3324828855534526]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3363670030562521, 0.0010568114163351386, 0.33057330644044364, 0.3320028790869691]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.66415495
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33539223182399835, 0.0010569011191098434, 0.331059592549205, 0.3324912745076869]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33539223182399835, 0.0010569011191098434, 0.331059592549205, 0.3324912745076869]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33539223182399835, 0.0010569011191098434, 0.331059592549205, 0.3324912745076869]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3356311805890899, 0.0010569446257004216, 0.33058372444309053, 0.332728150342119]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3356311805890899, 0.0010569446257004216, 0.33058372444309053, 0.332728150342119]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3356311805890899, 0.0010569446257004216, 0.33058372444309053, 0.332728150342119]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33586944114931083, 0.0010569880069861168, 0.33010922690170097, 0.33296434394200214]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33610701647357066, 0.0010570312635074868, 0.329636094012432, 0.33319985825048976]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33610701647357066, 0.0010570312635074868, 0.329636094012432, 0.33319985825048976]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33610701647357066, 0.0010570312635074868, 0.329636094012432, 0.33319985825048976]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33658012320470504, 0.0010571174044040235, 0.32869389870939886, 0.333668860681492]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.727]
 [0.686]
 [0.67 ]
 [0.665]
 [0.726]
 [0.768]] [[-1.131]
 [ 0.45 ]
 [-1.614]
 [-1.495]
 [-1.368]
 [-1.093]
 [-0.127]] [[1.141]
 [1.716]
 [0.945]
 [0.953]
 [0.984]
 [1.199]
 [1.606]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33658012320470504, 0.0010571174044040235, 0.32869389870939886, 0.333668860681492]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33658012320470504, 0.0010571174044040235, 0.32869389870939886, 0.333668860681492]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33658012320470504, 0.0010571174044040235, 0.32869389870939886, 0.333668860681492]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3365784482150516, 0.0010572507756094137, 0.329409191859508, 0.3329551091498309]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.336819622724595, 0.001057294783522009, 0.3296452140079054, 0.33247786848397765]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3363343984195695, 0.0010573398218915106, 0.32988676267730643, 0.3327214990812325]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3363343984195695, 0.0010573398218915106, 0.32988676267730643, 0.3327214990812325]
siam score:  -0.6607025
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33559875337185596, 0.0010577384354824386, 0.3313189109632883, 0.33202459722937333]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
first move QE:  1.3422361433637995
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33559875337185596, 0.0010577384354824386, 0.3313189109632883, 0.33202459722937333]
Printing some Q and Qe and total Qs values:  [[0.425]
 [0.376]
 [0.425]
 [0.416]
 [0.425]
 [0.416]
 [0.429]] [[4.798]
 [4.332]
 [4.798]
 [5.225]
 [4.798]
 [4.906]
 [5.541]] [[1.059]
 [0.735]
 [1.059]
 [1.292]
 [1.059]
 [1.109]
 [1.488]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.64791757
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3358349802786807, 0.001057782011082524, 0.3308489369002271, 0.33225830081000973]
Printing some Q and Qe and total Qs values:  [[0.679]
 [0.637]
 [0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.709]] [[0.993]
 [2.272]
 [1.019]
 [1.019]
 [1.019]
 [1.019]
 [1.019]] [[1.768]
 [2.098]
 [1.834]
 [1.834]
 [1.834]
 [1.834]
 [1.834]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33535568402566485, 0.0010578267861571047, 0.331088051805586, 0.3324984373825921]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33535568402566485, 0.0010578267861571047, 0.331088051805586, 0.3324984373825921]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33535568402566485, 0.0010578267861571047, 0.331088051805586, 0.3324984373825921]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33535568402566485, 0.0010578267861571047, 0.331088051805586, 0.3324984373825921]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33535568402566485, 0.0010578267861571047, 0.331088051805586, 0.3324984373825921]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3351149947408625, 0.0010579153840119646, 0.33156119602430023, 0.3322658938508254]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3351149947408625, 0.0010579153840119646, 0.33156119602430023, 0.3322658938508254]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3351149947408625, 0.0010579153840119646, 0.33156119602430023, 0.3322658938508254]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33534544097412416, 0.001058091261044323, 0.3310960255116697, 0.3325004422531618]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33534544097412416, 0.001058091261044323, 0.3310960255116697, 0.3325004422531618]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.3339218848650894, 0.0010582248142865151, 0.33180622600883425, 0.3332136643117898]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33415578062397716, 0.0010582685188889349, 0.33133888834401864, 0.33344706251311523]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]] [[-1.34]
 [-1.34]
 [-1.34]
 [-1.34]
 [-1.34]
 [-1.34]
 [-1.34]] [[0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33368378748947314, 0.0010583128464412305, 0.3315741121746125, 0.33368378748947314]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334490186140674, 0.0010584013134032155, 0.33204356145846203, 0.3334490186140674]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334490186140674, 0.0010584013134032155, 0.33204356145846203, 0.3334490186140674]
Printing some Q and Qe and total Qs values:  [[0.697]
 [0.629]
 [0.707]
 [0.697]
 [0.676]
 [0.698]
 [0.697]] [[2.882]
 [2.843]
 [2.745]
 [2.882]
 [2.749]
 [2.939]
 [2.882]] [[0.666]
 [0.515]
 [0.638]
 [0.666]
 [0.579]
 [0.687]
 [0.666]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334490186140674, 0.0010584013134032155, 0.33204356145846203, 0.3334490186140674]
Printing some Q and Qe and total Qs values:  [[0.518]
 [0.55 ]
 [0.518]
 [0.518]
 [0.518]
 [0.75 ]
 [0.518]] [[3.787]
 [3.475]
 [3.787]
 [3.787]
 [3.787]
 [3.458]
 [3.787]] [[0.797]
 [0.757]
 [0.797]
 [0.797]
 [0.797]
 [1.151]
 [0.797]]
siam score:  -0.6597603
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33297952492550775, 0.001058445453211736, 0.33227778902810334, 0.3336842405931772]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334479845292935, 0.0010585335470657566, 0.33204549739434736, 0.3334479845292935]
Printing some Q and Qe and total Qs values:  [[1.105]
 [1.105]
 [1.105]
 [1.105]
 [1.105]
 [1.393]
 [1.105]] [[1.052]
 [1.052]
 [1.052]
 [1.052]
 [1.052]
 [1.485]
 [1.052]] [[1.272]
 [1.272]
 [1.272]
 [1.272]
 [1.272]
 [1.994]
 [1.272]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334479845292935, 0.0010585335470657566, 0.33204549739434736, 0.3334479845292935]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3336807313947746, 0.001058577315126492, 0.33157995989532424, 0.3336807313947746]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3329794451351875, 0.0010587099200391307, 0.3322806646399977, 0.3336811803047756]
1286 1439
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3332115401427868, 0.0010587537504215042, 0.33181594019996175, 0.33391376590682986]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3332115401427868, 0.0010587537504215042, 0.33181594019996175, 0.33391376590682986]
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.537]
 [0.566]
 [0.526]
 [0.566]
 [0.566]
 [0.586]] [[-0.38 ]
 [ 0.776]
 [-0.38 ]
 [ 0.402]
 [-0.38 ]
 [-0.38 ]
 [ 0.503]] [[1.199]
 [1.527]
 [1.199]
 [1.38 ]
 [1.199]
 [1.199]
 [1.533]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.65861666
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33297646312354423, 0.0010588415964660806, 0.33158477498296945, 0.33437992029702024]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33251124940349497, 0.0010588856112206868, 0.3318163807162993, 0.334613484268985]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327417228104691, 0.0010589293189804594, 0.3313539286954419, 0.3348454191751085]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327417228104691, 0.0010589293189804594, 0.3313539286954419, 0.3348454191751085]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327417228104691, 0.0010589293189804594, 0.3313539286954419, 0.3348454191751085]
Printing some Q and Qe and total Qs values:  [[0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.641]
 [0.635]] [[2.809]
 [2.809]
 [2.809]
 [2.809]
 [2.809]
 [3.101]
 [2.809]] [[1.059]
 [1.059]
 [1.059]
 [1.059]
 [1.059]
 [1.406]
 [1.059]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322776497411028, 0.001058973271584886, 0.3315847236397021, 0.33507865334761033]
siam score:  -0.6532258
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322776497411028, 0.001058973271584886, 0.3315847236397021, 0.33507865334761033]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3322776497411028, 0.001058973271584886, 0.3315847236397021, 0.33507865334761033]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3318148735930933, 0.001059017101357211, 0.3318148735930933, 0.33531123571245625]
1290 1443
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33204925735162316, 0.0010590617374156659, 0.33204925735162316, 0.33484242355933796]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33227909045274306, 0.0010591055068466236, 0.331587608229474, 0.3350741958109363]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33227909045274306, 0.0010591055068466236, 0.331587608229474, 0.3350741958109363]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33251314234707385, 0.0010591500797048387, 0.3318211715907746, 0.3346065359824468]
first move QE:  1.3236017660847819
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33274265923692614, 0.0010591937889165013, 0.33136064479755956, 0.3348375021765978]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.327]
 [0.327]
 [0.327]
 [0.636]
 [0.491]
 [0.404]
 [0.327]] [[3.698]
 [3.698]
 [3.698]
 [0.973]
 [1.527]
 [0.902]
 [3.698]] [[2.037]
 [2.037]
 [2.037]
 [0.368]
 [0.617]
 [0.059]
 [2.037]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.2025575931097325
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3332094482516505, 0.0010592826842472979, 0.331825489228453, 0.33390577983564923]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33367171150877556, 0.0010593707176925168, 0.33159720626475636, 0.33367171150877556]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334379782642645, 0.0010594586285038363, 0.3313692322914279, 0.3341333308158038]
Printing some Q and Qe and total Qs values:  [[0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]] [[-2.212]
 [-2.212]
 [-2.212]
 [-2.212]
 [-2.212]
 [-2.212]
 [-2.212]] [[0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334379782642645, 0.0010594586285038363, 0.3313692322914279, 0.3341333308158038]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334379782642645, 0.0010594586285038363, 0.3313692322914279, 0.3341333308158038]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334379782642645, 0.0010594586285038363, 0.3313692322914279, 0.3341333308158038]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334379782642645, 0.0010594586285038363, 0.3313692322914279, 0.3341333308158038]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334379782642645, 0.0010594586285038363, 0.3313692322914279, 0.3341333308158038]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334379782642645, 0.0010594586285038363, 0.3313692322914279, 0.3341333308158038]
from probs:  [0.3336663919572548, 0.0010595022186075894, 0.33091188355362205, 0.33436222227051554]
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.388]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]] [[-0.292]
 [ 0.059]
 [-0.292]
 [-0.292]
 [-0.292]
 [-0.292]
 [-0.292]] [[0.368]
 [0.388]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3341270631826347, 0.0010595901323672558, 0.33068628350236334, 0.3341270631826347]
Printing some Q and Qe and total Qs values:  [[0.742]
 [0.696]
 [0.684]
 [0.69 ]
 [0.696]
 [0.693]
 [0.701]] [[5.447]
 [5.17 ]
 [4.472]
 [4.377]
 [4.668]
 [4.724]
 [4.559]] [[2.128]
 [1.958]
 [1.623]
 [1.585]
 [1.726]
 [1.749]
 [1.68 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33435453411359906, 0.001059633542555812, 0.330231298230246, 0.33435453411359906]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3348190104036462, 0.0010597221824679359, 0.3306900295184358, 0.3334312378954501]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 4.760034746376808
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3348190104036462, 0.0010597221824679359, 0.3306900295184358, 0.3334312378954501]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.316]
 [0.316]
 [0.316]
 [0.314]
 [0.316]
 [0.316]
 [0.316]] [[3.641]
 [3.641]
 [3.641]
 [3.959]
 [3.641]
 [3.641]
 [3.641]] [[1.03 ]
 [1.03 ]
 [1.03 ]
 [1.233]
 [1.03 ]
 [1.03 ]
 [1.03 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3348190104036462, 0.0010597221824679359, 0.3306900295184358, 0.3334312378954501]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.235]
 [0.114]
 [0.157]
 [0.153]
 [0.124]
 [0.157]
 [0.218]] [[2.854]
 [2.735]
 [3.168]
 [3.197]
 [2.823]
 [2.779]
 [2.926]] [[ 0.29 ]
 [-0.071]
 [ 0.448]
 [ 0.469]
 [ 0.036]
 [ 0.059]
 [ 0.327]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33505028476911725, 0.001059766318497847, 0.33091844330374875, 0.3329715056086362]
Starting evaluation
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3352780767478672, 0.001059809789954651, 0.33046423339662157, 0.33319788006555656]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.367]
 [0.382]
 [0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]] [[0.804]
 [1.155]
 [0.804]
 [0.804]
 [0.804]
 [0.804]
 [0.804]] [[0.367]
 [0.382]
 [0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]]
Printing some Q and Qe and total Qs values:  [[0.5 ]
 [0.73]
 [0.5 ]
 [0.5 ]
 [0.5 ]
 [0.5 ]
 [0.5 ]] [[2.942]
 [1.88 ]
 [2.942]
 [2.942]
 [2.942]
 [2.942]
 [2.942]] [[0.5 ]
 [0.73]
 [0.5 ]
 [0.5 ]
 [0.5 ]
 [0.5 ]
 [0.5 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3355052421978534, 0.0010598531418457063, 0.33001127276777525, 0.3334236318925256]
Printing some Q and Qe and total Qs values:  [[0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]] [[4.587]
 [4.587]
 [4.587]
 [4.587]
 [4.587]
 [4.587]
 [4.587]] [[0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3355052421978534, 0.0010598531418457063, 0.33001127276777525, 0.3334236318925256]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.7377335623091614
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3350421623751994, 0.0010598978303143125, 0.33024159594436936, 0.33365634385011683]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3350421623751994, 0.0010598978303143125, 0.33024159594436936, 0.33365634385011683]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3350421623751994, 0.0010598978303143125, 0.33024159594436936, 0.33365634385011683]
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.561]
 [0.537]
 [0.537]
 [0.547]
 [0.537]
 [0.537]] [[5.023]
 [4.942]
 [5.023]
 [5.023]
 [5.096]
 [5.023]
 [5.023]] [[0.537]
 [0.561]
 [0.537]
 [0.537]
 [0.547]
 [0.537]
 [0.537]]
Printing some Q and Qe and total Qs values:  [[0.72 ]
 [0.72 ]
 [0.72 ]
 [0.705]
 [0.72 ]
 [0.72 ]
 [0.72 ]] [[2.871]
 [2.871]
 [2.871]
 [2.83 ]
 [2.871]
 [2.871]
 [2.871]] [[0.72 ]
 [0.72 ]
 [0.72 ]
 [0.705]
 [0.72 ]
 [0.72 ]
 [0.72 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3350421623751994, 0.0010598978303143125, 0.33024159594436936, 0.33365634385011683]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.671939779388544
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3350421623751994, 0.0010598978303143125, 0.33024159594436936, 0.33365634385011683]
Printing some Q and Qe and total Qs values:  [[0.44 ]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]] [[0.38 ]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]] [[0.44 ]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]]
Printing some Q and Qe and total Qs values:  [[0.802]
 [0.836]
 [0.802]
 [1.094]
 [0.802]
 [0.977]
 [0.802]] [[2.527]
 [3.009]
 [2.527]
 [3.427]
 [2.527]
 [3.005]
 [2.527]] [[2.127]
 [2.275]
 [2.127]
 [2.697]
 [2.127]
 [2.456]
 [2.127]]
using explorer policy with actor:  1
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.62 ]
 [0.627]
 [0.618]
 [0.621]
 [0.648]
 [0.62 ]
 [0.619]] [[2.83 ]
 [2.813]
 [3.015]
 [2.939]
 [2.913]
 [2.955]
 [2.857]] [[0.62 ]
 [0.627]
 [0.618]
 [0.621]
 [0.648]
 [0.62 ]
 [0.619]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3345803632821046, 0.001059942395189018, 0.33047128212128013, 0.33388841220142634]
Printing some Q and Qe and total Qs values:  [[0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.588]
 [0.809]
 [0.588]] [[2.113]
 [2.113]
 [2.113]
 [2.113]
 [2.113]
 [3.767]
 [2.113]] [[0.581]
 [0.581]
 [0.581]
 [0.581]
 [0.581]
 [1.574]
 [0.581]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3345803632821046, 0.001059942395189018, 0.33047128212128013, 0.33388841220142634]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus -1.0890215995989876
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33411983961277814, 0.0010599868369818432, 0.33070033393746195, 0.33411983961277814]
Printing some Q and Qe and total Qs values:  [[0.425]
 [0.346]
 [0.433]
 [0.524]
 [0.425]
 [0.638]
 [0.425]] [[2.047]
 [1.848]
 [2.267]
 [2.163]
 [2.047]
 [2.186]
 [2.047]] [[0.397]
 [0.173]
 [0.486]
 [0.633]
 [0.397]
 [0.87 ]
 [0.397]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33411983961277814, 0.0010599868369818432, 0.33070033393746195, 0.33411983961277814]
Printing some Q and Qe and total Qs values:  [[0.603]
 [0.595]
 [0.603]
 [0.603]
 [0.597]
 [0.612]
 [0.603]] [[3.812]
 [2.201]
 [3.812]
 [3.757]
 [3.773]
 [3.843]
 [3.812]] [[0.603]
 [0.595]
 [0.603]
 [0.603]
 [0.597]
 [0.612]
 [0.603]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33411983961277814, 0.0010599868369818432, 0.33070033393746195, 0.33411983961277814]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33411983961277814, 0.0010599868369818432, 0.33070033393746195, 0.33411983961277814]
line 256 mcts: sample exp_bonus 1.1495915823569578
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33411983961277814, 0.0010599868369818432, 0.33070033393746195, 0.33411983961277814]
Printing some Q and Qe and total Qs values:  [[0.177]
 [0.263]
 [0.165]
 [0.169]
 [0.17 ]
 [0.158]
 [0.157]] [[3.835]
 [4.72 ]
 [3.841]
 [3.998]
 [4.027]
 [4.012]
 [3.882]] [[-0.565]
 [-0.098]
 [-0.588]
 [-0.528]
 [-0.514]
 [-0.544]
 [-0.589]]
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.404]
 [0.517]
 [0.507]
 [0.498]
 [0.607]
 [0.515]] [[1.103]
 [1.931]
 [0.89 ]
 [0.868]
 [1.035]
 [1.221]
 [0.93 ]] [[0.535]
 [0.404]
 [0.517]
 [0.507]
 [0.498]
 [0.607]
 [0.515]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33411983961277814, 0.0010599868369818432, 0.33070033393746195, 0.33411983961277814]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.65147614
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33434591567622646, 0.0010600302511371321, 0.3302481383964099, 0.33434591567622646]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
1306 1456
rdn probs:  [0.3336535107644884, 0.0010601623029965698, 0.3302527607802196, 0.3350335661522954]
line 256 mcts: sample exp_bonus -2.4992242248682492
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327406879955099, 0.0010602505724154139, 0.33070583868616577, 0.335493222745909]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33296491209824214, 0.001060293988195289, 0.3302554866442826, 0.3357193072692799]
Printing some Q and Qe and total Qs values:  [[0.696]
 [0.346]
 [0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]] [[-2.981]
 [-0.691]
 [-2.301]
 [-2.301]
 [-2.301]
 [-2.301]
 [-2.301]] [[0.696]
 [0.346]
 [0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33296491209824214, 0.001060293988195289, 0.3302554866442826, 0.3357193072692799]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33296491209824214, 0.001060293988195289, 0.3302554866442826, 0.3357193072692799]
Printing some Q and Qe and total Qs values:  [[0.922]
 [0.921]
 [0.921]
 [0.921]
 [0.921]
 [0.921]
 [0.921]] [[1.348]
 [1.353]
 [1.353]
 [1.353]
 [1.353]
 [1.353]
 [1.353]] [[0.922]
 [0.921]
 [0.921]
 [0.921]
 [0.921]
 [0.921]
 [0.921]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3331960061268403, 0.0010603387341764506, 0.330484694556288, 0.33525896058269533]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 5.028747590052552
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3331960061268403, 0.0010603387341764506, 0.330484694556288, 0.33525896058269533]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334199298902803, 0.0010603820918026123, 0.330035413110255, 0.3354842749076621]
Printing some Q and Qe and total Qs values:  [[0.608]
 [0.583]
 [0.592]
 [0.597]
 [0.619]
 [0.695]
 [0.613]] [[4.88 ]
 [4.326]
 [4.848]
 [4.916]
 [5.122]
 [4.969]
 [5.031]] [[1.685]
 [1.209]
 [1.634]
 [1.695]
 [1.892]
 [1.89 ]
 [1.812]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334199298902803, 0.0010603820918026123, 0.330035413110255, 0.3354842749076621]
Printing some Q and Qe and total Qs values:  [[0.448]
 [0.268]
 [0.427]
 [0.422]
 [0.404]
 [0.472]
 [0.411]] [[4.871]
 [4.808]
 [5.564]
 [5.576]
 [5.407]
 [6.983]
 [5.747]] [[0.871]
 [0.683]
 [1.161]
 [1.162]
 [1.071]
 [1.833]
 [1.228]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334199298902803, 0.0010603820918026123, 0.330035413110255, 0.3354842749076621]
Printing some Q and Qe and total Qs values:  [[ 0.185]
 [-0.003]
 [ 0.097]
 [ 0.096]
 [ 0.087]
 [ 0.217]
 [ 0.139]] [[2.925]
 [2.513]
 [2.806]
 [2.981]
 [3.051]
 [2.776]
 [2.956]] [[ 0.501]
 [-0.287]
 [ 0.205]
 [ 0.379]
 [ 0.43 ]
 [ 0.417]
 [ 0.44 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334199298902803, 0.0010603820918026123, 0.330035413110255, 0.3354842749076621]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334199298902803, 0.0010603820918026123, 0.330035413110255, 0.3354842749076621]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33364324363535897, 0.001060425331312913, 0.3295873556072609, 0.3357089754260673]
from probs:  [0.33364324363535897, 0.001060425331312913, 0.3295873556072609, 0.3357089754260673]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3340973397090828, 0.0010605132564509311, 0.32936862209210827, 0.33547352494235805]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33432809531092483, 0.0010605579369036228, 0.3295961018796507, 0.3350152448725207]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33432809531092483, 0.0010605579369036228, 0.3295961018796507, 0.3350152448725207]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33455081382385315, 0.0010606010611610686, 0.3291501626050241, 0.3352384225099618]
Printing some Q and Qe and total Qs values:  [[1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]] [[1.309]
 [1.309]
 [1.309]
 [1.309]
 [1.309]
 [1.309]
 [1.309]] [[1.925]
 [1.925]
 [1.925]
 [1.925]
 [1.925]
 [1.925]
 [1.925]]
from probs:  [0.33455081382385315, 0.0010606010611610686, 0.3291501626050241, 0.3352384225099618]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3345549639995654, 0.0010607347318184566, 0.3298293372690508, 0.3345549639995654]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3345549639995654, 0.0010607347318184566, 0.3298293372690508, 0.3345549639995654]
rdn beta is 0 so we're just using the maxi policy
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.629]
 [0.495]
 [0.603]
 [0.577]
 [0.622]
 [0.634]
 [1.122]] [[1.395]
 [2.392]
 [1.654]
 [1.848]
 [2.032]
 [2.047]
 [1.688]] [[0.553]
 [0.619]
 [0.588]
 [0.6  ]
 [0.752]
 [0.782]
 [1.637]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3345549639995654, 0.0010607347318184566, 0.3298293372690508, 0.3345549639995654]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33477754144044525, 0.0010607779174202111, 0.32938413920168924, 0.33477754144044525]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.8725289972490535
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33477754144044525, 0.0010607779174202111, 0.32938413920168924, 0.33477754144044525]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.772]
 [0.738]
 [0.761]
 [0.753]
 [0.773]
 [0.846]
 [0.78 ]] [[5.098]
 [5.051]
 [5.197]
 [5.373]
 [5.358]
 [5.912]
 [5.083]] [[0.86 ]
 [0.776]
 [0.871]
 [0.915]
 [0.948]
 [1.28 ]
 [0.871]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33477754144044525, 0.0010607779174202111, 0.32938413920168924, 0.33477754144044525]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33477754144044525, 0.0010607779174202111, 0.32938413920168924, 0.33477754144044525]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33386880035935196, 0.001060866786062226, 0.32983476480088786, 0.3352355680536981]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33341628341472596, 0.0010609110391142707, 0.3300591584412349, 0.33546364710492477]
siam score:  -0.6499741
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334208577065038, 0.0010611767618022643, 0.33074053769888523, 0.3347774278328087]
Printing some Q and Qe and total Qs values:  [[0.341]
 [0.324]
 [0.339]
 [0.324]
 [0.325]
 [0.35 ]
 [0.324]] [[1.07 ]
 [1.335]
 [1.328]
 [1.335]
 [1.543]
 [1.465]
 [1.335]] [[-0.053]
 [ 0.001]
 [ 0.028]
 [ 0.001]
 [ 0.072]
 [ 0.095]
 [ 0.001]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3334208577065038, 0.0010611767618022643, 0.33074053769888523, 0.3347774278328087]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3329713990704083, 0.0010612208960530413, 0.33096387783145054, 0.33500350220208813]
Printing some Q and Qe and total Qs values:  [[0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]] [[3.696]
 [3.696]
 [3.696]
 [3.696]
 [3.696]
 [3.696]
 [3.696]] [[1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]
 [1.8]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3325231545408458, 0.0010612649110855437, 0.33118661466330646, 0.3352289658847622]
Printing some Q and Qe and total Qs values:  [[0.355]
 [0.236]
 [0.355]
 [0.34 ]
 [0.355]
 [0.355]
 [0.355]] [[0.292]
 [1.422]
 [0.292]
 [0.563]
 [0.292]
 [0.292]
 [0.292]] [[0.355]
 [0.236]
 [0.355]
 [0.34 ]
 [0.355]
 [0.355]
 [0.355]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.52 ]
 [0.502]
 [0.571]
 [0.547]
 [0.528]
 [0.577]
 [0.543]] [[3.114]
 [2.559]
 [1.477]
 [2.497]
 [2.358]
 [1.715]
 [2.505]] [[1.253]
 [1.032]
 [0.808]
 [1.101]
 [1.017]
 [0.899]
 [1.094]]
from probs:  [0.3325231545408458, 0.0010612649110855437, 0.33118661466330646, 0.3352289658847622]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3325231545408458, 0.0010612649110855437, 0.33118661466330646, 0.3352289658847622]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3325231545408458, 0.0010612649110855437, 0.33118661466330646, 0.3352289658847622]
Printing some Q and Qe and total Qs values:  [[0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]] [[1.336]
 [1.336]
 [1.336]
 [1.336]
 [1.336]
 [1.336]
 [1.336]] [[0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33230265608008835, 0.0010613534831051994, 0.3316348308732396, 0.3350011595635668]
Printing some Q and Qe and total Qs values:  [[0.138]
 [0.296]
 [0.138]
 [0.138]
 [0.157]
 [0.135]
 [0.159]] [[2.839]
 [2.847]
 [2.839]
 [2.839]
 [2.692]
 [2.749]
 [2.684]] [[-0.771]
 [-0.451]
 [-0.771]
 [-0.771]
 [-0.782]
 [-0.807]
 [-0.78 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.3327502764229404, 0.0010614417590754895, 0.33141551250075185, 0.3347727693172323]
Printing some Q and Qe and total Qs values:  [[0.536]
 [0.645]
 [0.527]
 [0.59 ]
 [0.527]
 [0.527]
 [0.504]] [[1.587]
 [1.478]
 [0.913]
 [0.876]
 [0.913]
 [0.913]
 [1.342]] [[1.494]
 [1.675]
 [1.251]
 [1.364]
 [1.251]
 [1.251]
 [1.349]]
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.53 ]
 [0.57 ]
 [0.565]
 [0.593]
 [0.576]
 [0.572]] [[1.752]
 [2.978]
 [1.894]
 [1.924]
 [1.819]
 [1.922]
 [1.779]] [[0.605]
 [0.948]
 [0.665]
 [0.667]
 [0.687]
 [0.687]
 [0.631]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33230398990229315, 0.001061485715642447, 0.3316375059904488, 0.33499701839161555]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33230398990229315, 0.001061485715642447, 0.3316375059904488, 0.33499701839161555]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33185890284076164, 0.0010615295540698144, 0.33185890284076164, 0.33522066476440693]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33185890284076164, 0.0010615295540698144, 0.33185890284076164, 0.33522066476440693]
siam score:  -0.6297299
Printing some Q and Qe and total Qs values:  [[0.526]
 [0.526]
 [0.526]
 [0.538]
 [0.528]
 [0.552]
 [0.526]] [[3.348]
 [3.348]
 [3.348]
 [3.106]
 [3.608]
 [3.053]
 [3.348]] [[0.614]
 [0.614]
 [0.614]
 [0.557]
 [0.705]
 [0.568]
 [0.614]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33185890284076164, 0.0010615295540698144, 0.33185890284076164, 0.33522066476440693]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33185890284076164, 0.0010615295540698144, 0.33185890284076164, 0.33522066476440693]
Printing some Q and Qe and total Qs values:  [[0.456]
 [0.378]
 [0.459]
 [0.459]
 [0.461]
 [0.551]
 [0.459]] [[2.071]
 [2.034]
 [2.123]
 [2.123]
 [1.998]
 [1.867]
 [2.123]] [[0.339]
 [0.17 ]
 [0.362]
 [0.362]
 [0.324]
 [0.461]
 [0.362]]
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.734]
 [0.734]
 [0.734]
 [0.734]
 [0.915]
 [0.734]] [[1.28 ]
 [1.28 ]
 [1.28 ]
 [1.28 ]
 [1.28 ]
 [1.556]
 [1.28 ]] [[0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.96 ]
 [0.506]]
Printing some Q and Qe and total Qs values:  [[0.483]
 [0.475]
 [0.566]
 [0.534]
 [0.28 ]
 [0.561]
 [0.473]] [[ 1.635]
 [ 2.742]
 [ 0.847]
 [ 0.587]
 [ 1.833]
 [-0.894]
 [ 1.551]] [[1.243]
 [1.597]
 [1.145]
 [0.995]
 [0.902]
 [0.554]
 [1.194]]
Printing some Q and Qe and total Qs values:  [[0.311]
 [0.197]
 [0.466]
 [0.466]
 [0.285]
 [0.334]
 [0.303]] [[1.941]
 [1.961]
 [1.571]
 [1.571]
 [1.934]
 [1.801]
 [1.917]] [[-0.118]
 [-0.341]
 [ 0.067]
 [ 0.067]
 [-0.175]
 [-0.12 ]
 [-0.144]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33185890284076164, 0.0010615295540698144, 0.33185890284076164, 0.33522066476440693]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33185890284076164, 0.0010615295540698144, 0.33185890284076164, 0.33522066476440693]
Printing some Q and Qe and total Qs values:  [[0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]] [[2.239]
 [2.239]
 [2.239]
 [2.239]
 [2.239]
 [2.239]
 [2.239]] [[0.241]
 [0.241]
 [0.241]
 [0.241]
 [0.241]
 [0.241]
 [0.241]]
line 256 mcts: sample exp_bonus 6.602736773535403
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33185890284076164, 0.0010615295540698144, 0.33185890284076164, 0.33522066476440693]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33141501040925725, 0.0010615732748332361, 0.33207970545379334, 0.33544371086211616]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33141501040925725, 0.0010615732748332361, 0.33207970545379334, 0.33544371086211616]
siam score:  -0.64018446
siam score:  -0.64001256
Printing some Q and Qe and total Qs values:  [[-0.034]
 [-0.046]
 [-0.028]
 [-0.033]
 [-0.034]
 [-0.033]
 [-0.034]] [[1.852]
 [1.7  ]
 [2.055]
 [2.034]
 [2.184]
 [2.146]
 [2.131]] [[-0.794]
 [-0.869]
 [-0.715]
 [-0.731]
 [-0.684]
 [-0.694]
 [-0.701]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.526]
 [0.507]
 [0.563]
 [0.498]
 [0.502]
 [0.534]
 [0.486]] [[2.745]
 [2.588]
 [2.712]
 [3.045]
 [3.109]
 [3.13 ]
 [2.796]] [[0.709]
 [0.528]
 [0.748]
 [0.938]
 [1.005]
 [1.085]
 [0.683]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33053079024924364, 0.0010616603652580394, 0.3325195375121248, 0.3358880118733735]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33053079024924364, 0.0010616603652580394, 0.3325195375121248, 0.3358880118733735]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.33053079024924364, 0.0010616603652580394, 0.3325195375121248, 0.3358880118733735]
Printing some Q and Qe and total Qs values:  [[0.14 ]
 [0.255]
 [0.14 ]
 [0.14 ]
 [0.14 ]
 [0.14 ]
 [0.14 ]] [[2.615]
 [2.896]
 [2.615]
 [2.615]
 [2.615]
 [2.615]
 [2.615]] [[-1.048]
 [-0.726]
 [-1.048]
 [-1.048]
 [-1.048]
 [-1.048]
 [-1.048]]
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.559]
 [0.608]
 [0.6  ]
 [0.663]
 [0.656]
 [0.663]] [[2.582]
 [2.408]
 [2.612]
 [2.632]
 [2.648]
 [2.94 ]
 [2.648]] [[0.882]
 [0.598]
 [0.901]
 [0.904]
 [1.047]
 [1.325]
 [1.047]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0010941079183760586, 0.0010941079183760586, 0.4963891489867642, 0.5014226351764837]
siam score:  -0.63788086
Printing some Q and Qe and total Qs values:  [[0.336]
 [0.359]
 [0.336]
 [0.336]
 [0.336]
 [0.336]
 [0.336]] [[2.053]
 [3.024]
 [2.053]
 [2.053]
 [2.053]
 [2.053]
 [2.053]] [[0.336]
 [0.359]
 [0.336]
 [0.336]
 [0.336]
 [0.336]
 [0.336]]
from probs:  [0.0010941079183760586, 0.0010941079183760586, 0.4963891489867642, 0.5014226351764837]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.31]
 [0.41]
 [0.31]
 [0.31]
 [0.31]
 [0.31]
 [0.31]] [[-0.11 ]
 [ 1.725]
 [-0.11 ]
 [-0.11 ]
 [-0.11 ]
 [-0.11 ]
 [-0.11 ]] [[0.31]
 [0.41]
 [0.31]
 [0.31]
 [0.31]
 [0.31]
 [0.31]]
Printing some Q and Qe and total Qs values:  [[0.414]
 [0.414]
 [0.389]
 [0.414]
 [0.47 ]
 [0.528]
 [0.414]] [[2.277]
 [2.277]
 [2.394]
 [2.277]
 [2.358]
 [2.22 ]
 [2.277]] [[0.153]
 [0.153]
 [0.219]
 [0.153]
 [0.345]
 [0.325]
 [0.153]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0010942059656989596, 0.0010942059656989596, 0.49588875410661254, 0.5019228339619896]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0010942059656989596, 0.0010942059656989596, 0.49588875410661254, 0.5019228339619896]
from probs:  [0.0010942059656989596, 0.0010942059656989596, 0.49588875410661254, 0.5019228339619896]
Printing some Q and Qe and total Qs values:  [[0.421]
 [0.447]
 [0.417]
 [0.454]
 [0.454]
 [0.454]
 [0.454]] [[-1.494]
 [ 0.432]
 [-1.287]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[0.421]
 [0.447]
 [0.417]
 [0.454]
 [0.454]
 [0.454]
 [0.454]]
Printing some Q and Qe and total Qs values:  [[0.208]
 [0.656]
 [0.673]
 [0.57 ]
 [0.429]
 [0.637]
 [0.448]] [[ 1.987]
 [ 3.078]
 [-1.622]
 [-0.371]
 [-0.036]
 [-1.461]
 [ 0.681]] [[1.189]
 [1.813]
 [0.16 ]
 [0.548]
 [0.591]
 [0.198]
 [0.855]]
siam score:  -0.63771355
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0010943038150693243, 0.0010943038150693243, 0.49538936949816065, 0.5024220228717006]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0010943038150693243, 0.0010943038150693243, 0.49538936949816065, 0.5024220228717006]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0010943038150693243, 0.0010943038150693243, 0.49538936949816065, 0.5024220228717006]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0010944042655681137, 0.0010944042655681137, 0.49589464094732183, 0.5019165505215419]
line 256 mcts: sample exp_bonus 1.0636629354155902
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001094502117387468, 0.001094502117387468, 0.495396256220622, 0.502414739544603]
Printing some Q and Qe and total Qs values:  [[0.787]
 [0.763]
 [0.787]
 [0.772]
 [0.787]
 [0.785]
 [0.78 ]] [[4.323]
 [4.097]
 [4.323]
 [4.109]
 [4.323]
 [4.171]
 [4.121]] [[1.993]
 [1.854]
 [1.993]
 [1.867]
 [1.993]
 [1.911]
 [1.88 ]]
siam score:  -0.6325237
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.001094602565092052, 0.001094602565092052, 0.4959005033008849, 0.501910291568931]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0011919295183157668, 0.0011919295183157668, 0.0011919295183157668, 0.9964242114450528]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.433]
 [0.616]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]] [[-0.913]
 [ 2.596]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[0.012]
 [1.413]
 [0.349]
 [0.349]
 [0.349]
 [0.349]
 [0.349]]
start point for exploration sampling:  10723
Printing some Q and Qe and total Qs values:  [[0.514]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]] [[3.423]
 [3.692]
 [3.692]
 [3.692]
 [3.692]
 [3.692]
 [3.692]] [[1.331]
 [1.591]
 [1.591]
 [1.591]
 [1.591]
 [1.591]
 [1.591]]
Printing some Q and Qe and total Qs values:  [[0.655]
 [0.577]
 [0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.655]] [[2.639]
 [3.257]
 [2.639]
 [2.639]
 [2.639]
 [2.639]
 [2.639]] [[1.13 ]
 [1.798]
 [1.13 ]
 [1.13 ]
 [1.13 ]
 [1.13 ]
 [1.13 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.504]
 [0.441]
 [0.586]
 [0.57 ]
 [0.575]
 [0.59 ]
 [0.57 ]] [[3.229]
 [3.657]
 [3.068]
 [3.297]
 [3.187]
 [4.083]
 [3.006]] [[0.814]
 [0.92 ]
 [0.852]
 [0.932]
 [0.889]
 [1.309]
 [0.803]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.618]
 [0.488]
 [0.565]
 [0.553]
 [0.525]
 [0.737]
 [0.622]] [[6.36 ]
 [6.174]
 [6.022]
 [6.39 ]
 [6.462]
 [6.117]
 [6.442]] [[1.715]
 [1.374]
 [1.42 ]
 [1.619]
 [1.611]
 [1.784]
 [1.772]]
Printing some Q and Qe and total Qs values:  [[0.612]
 [0.599]
 [0.599]
 [0.574]
 [0.599]
 [0.616]
 [0.58 ]] [[6.356]
 [6.697]
 [6.697]
 [6.859]
 [6.697]
 [6.826]
 [6.91 ]] [[1.602]
 [1.776]
 [1.776]
 [1.825]
 [1.776]
 [1.879]
 [1.866]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.751]
 [0.697]] [[8.106]
 [8.106]
 [8.106]
 [8.106]
 [8.106]
 [9.408]
 [8.106]] [[1.622]
 [1.622]
 [1.622]
 [1.622]
 [1.622]
 [1.992]
 [1.622]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.553]
 [0.565]] [[4.949]
 [4.949]
 [4.949]
 [4.949]
 [4.949]
 [3.992]
 [4.949]] [[2.007]
 [2.007]
 [2.007]
 [2.007]
 [2.007]
 [1.364]
 [2.007]]
siam score:  -0.6336341
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.551]
 [0.479]
 [0.545]
 [0.532]
 [0.528]
 [0.553]
 [0.528]] [[1.73 ]
 [2.277]
 [1.986]
 [2.024]
 [2.072]
 [1.957]
 [1.897]] [[0.381]
 [0.421]
 [0.457]
 [0.442]
 [0.451]
 [0.461]
 [0.392]]
Printing some Q and Qe and total Qs values:  [[0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.522]
 [0.487]] [[1.798]
 [1.798]
 [1.798]
 [1.798]
 [1.798]
 [1.928]
 [1.798]] [[0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.506]
 [0.393]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6269338
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.898173659049413
first move QE:  1.2924308544010774
Printing some Q and Qe and total Qs values:  [[0.384]
 [0.384]
 [0.384]
 [0.384]
 [0.384]
 [0.425]
 [0.384]] [[2.55 ]
 [2.55 ]
 [2.55 ]
 [2.55 ]
 [2.55 ]
 [2.922]
 [2.55 ]] [[0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.55 ]
 [0.345]]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.61 ]
 [0.653]
 [0.61 ]
 [0.679]
 [0.61 ]
 [0.61 ]
 [0.656]] [[4.491]
 [4.479]
 [4.491]
 [5.899]
 [4.491]
 [4.491]
 [4.479]] [[1.388]
 [1.436]
 [1.388]
 [2.045]
 [1.388]
 [1.388]
 [1.438]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.61630464
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.475927263842372
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.6139847
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.004]
 [-0.003]
 [-0.003]] [[4.494]
 [4.494]
 [4.494]
 [4.494]
 [4.746]
 [4.494]
 [4.494]] [[0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.685]
 [0.501]
 [0.501]]
Printing some Q and Qe and total Qs values:  [[-0.008]
 [-0.03 ]
 [-0.009]
 [-0.01 ]
 [-0.008]
 [-0.006]
 [-0.009]] [[2.974]
 [2.492]
 [2.946]
 [2.987]
 [3.197]
 [3.186]
 [2.801]] [[-0.502]
 [-0.935]
 [-0.525]
 [-0.494]
 [-0.317]
 [-0.323]
 [-0.645]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
UNIT TEST: sample policy line 217 mcts : [0.02  0.02  0.02  0.02  0.02  0.878 0.02 ]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.542]
 [0.397]
 [0.542]
 [0.584]
 [0.542]
 [0.691]
 [0.535]] [[2.711]
 [2.96 ]
 [2.711]
 [4.1  ]
 [2.711]
 [2.507]
 [2.224]] [[0.579]
 [0.371]
 [0.579]
 [1.126]
 [0.579]
 [0.808]
 [0.4  ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.736]
 [1.232]
 [0.736]
 [0.736]
 [0.736]
 [0.736]
 [0.736]] [[1.648]
 [1.843]
 [1.648]
 [1.648]
 [1.648]
 [1.648]
 [1.648]] [[0.654]
 [1.711]
 [0.654]
 [0.654]
 [0.654]
 [0.654]
 [0.654]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.431]
 [0.412]
 [0.439]
 [0.436]
 [0.438]
 [0.443]
 [0.431]] [[0.514]
 [1.333]
 [0.299]
 [0.226]
 [0.499]
 [0.462]
 [0.197]] [[0.431]
 [0.412]
 [0.439]
 [0.436]
 [0.438]
 [0.443]
 [0.431]]
siam score:  -0.64117616
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.63980114
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.522]
 [0.711]
 [0.522]
 [0.522]
 [0.522]
 [0.522]
 [0.522]] [[1.002]
 [4.421]
 [1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]] [[1.019]
 [2.165]
 [1.019]
 [1.019]
 [1.019]
 [1.019]
 [1.019]]
siam score:  -0.6410965
Printing some Q and Qe and total Qs values:  [[1.224]
 [1.403]
 [1.224]
 [1.224]
 [1.224]
 [1.224]
 [1.224]] [[1.508]
 [1.377]
 [1.508]
 [1.508]
 [1.508]
 [1.508]
 [1.508]] [[2.122]
 [2.436]
 [2.122]
 [2.122]
 [2.122]
 [2.122]
 [2.122]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.2892891025728885
using explorer policy with actor:  1
using explorer policy with actor:  1
in main func line 156:  1371
line 256 mcts: sample exp_bonus 2.566147124773518
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.167]
 [0.167]
 [0.167]
 [0.167]
 [0.597]
 [0.167]
 [0.167]] [[1.513]
 [1.513]
 [1.513]
 [1.513]
 [2.353]
 [1.513]
 [1.513]] [[-0.069]
 [-0.069]
 [-0.069]
 [-0.069]
 [ 1.07 ]
 [-0.069]
 [-0.069]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.681]
 [0.677]
 [0.686]
 [0.69 ]
 [0.699]
 [0.7  ]
 [0.707]] [[6.   ]
 [5.171]
 [5.849]
 [5.771]
 [5.877]
 [5.502]
 [5.869]] [[2.145]
 [1.693]
 [2.072]
 [2.037]
 [2.108]
 [1.909]
 [2.116]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.283]
 [0.283]
 [0.283]
 [0.287]
 [0.283]
 [0.283]
 [0.283]] [[4.507]
 [4.507]
 [4.507]
 [4.211]
 [4.507]
 [4.507]
 [4.507]] [[1.306]
 [1.306]
 [1.306]
 [1.071]
 [1.306]
 [1.306]
 [1.306]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.387]
 [0.511]
 [0.387]
 [0.514]
 [0.387]
 [0.387]
 [0.506]] [[3.157]
 [3.054]
 [3.157]
 [3.305]
 [3.157]
 [3.157]
 [3.975]] [[0.332]
 [0.546]
 [0.332]
 [0.635]
 [0.332]
 [0.332]
 [0.843]]
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [0.813]
 [0.822]
 [0.808]
 [0.818]
 [0.823]
 [0.826]] [[3.749]
 [4.393]
 [3.813]
 [4.267]
 [3.927]
 [3.969]
 [3.902]] [[1.208]
 [1.639]
 [1.267]
 [1.548]
 [1.337]
 [1.37 ]
 [1.331]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.362]
 [0.369]
 [0.352]
 [0.35 ]
 [0.366]
 [0.375]
 [0.36 ]] [[-0.398]
 [-0.172]
 [-0.225]
 [-0.429]
 [-0.24 ]
 [-0.308]
 [-0.092]] [[0.362]
 [0.369]
 [0.352]
 [0.35 ]
 [0.366]
 [0.375]
 [0.36 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.731]
 [0.731]
 [0.731]
 [0.901]
 [0.731]
 [0.731]
 [0.731]] [[2.161]
 [2.161]
 [2.161]
 [2.198]
 [2.161]
 [2.161]
 [2.161]] [[0.161]
 [0.161]
 [0.161]
 [0.514]
 [0.161]
 [0.161]
 [0.161]]
Printing some Q and Qe and total Qs values:  [[0.627]
 [0.448]
 [0.659]
 [0.787]
 [0.612]
 [0.796]
 [0.735]] [[2.809]
 [3.386]
 [2.776]
 [4.239]
 [3.73 ]
 [3.798]
 [3.05 ]] [[0.291]
 [0.486]
 [0.318]
 [1.852]
 [1.086]
 [1.475]
 [0.699]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 3.1981108920317247
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
siam score:  -0.63183016
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.629966
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.576]
 [0.588]
 [0.592]
 [0.59 ]
 [0.58 ]
 [0.589]
 [0.568]] [[1.815]
 [2.47 ]
 [1.956]
 [2.046]
 [2.075]
 [2.041]
 [1.864]] [[0.65 ]
 [1.314]
 [0.819]
 [0.904]
 [0.913]
 [0.895]
 [0.682]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.313]
 [0.337]
 [0.319]
 [0.316]
 [0.32 ]
 [0.321]
 [0.316]] [[-1.048]
 [-0.478]
 [-1.146]
 [-1.021]
 [-1.065]
 [-0.966]
 [-0.991]] [[0.313]
 [0.337]
 [0.319]
 [0.316]
 [0.32 ]
 [0.321]
 [0.316]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.2796233672583617
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.331]
 [0.361]
 [0.331]
 [0.32 ]
 [0.331]
 [0.356]
 [0.331]] [[0.384]
 [0.6  ]
 [0.384]
 [0.622]
 [0.384]
 [0.125]
 [0.384]] [[0.331]
 [0.361]
 [0.331]
 [0.32 ]
 [0.331]
 [0.356]
 [0.331]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.6338037
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.63521564
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]] [[3.183]
 [3.183]
 [3.183]
 [3.183]
 [3.183]
 [3.183]
 [3.183]] [[2.329]
 [2.329]
 [2.329]
 [2.329]
 [2.329]
 [2.329]
 [2.329]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.524]
 [0.527]
 [0.533]
 [0.535]
 [0.537]
 [0.532]
 [0.529]] [[3.522]
 [3.628]
 [4.082]
 [3.548]
 [3.509]
 [3.498]
 [3.497]] [[0.385]
 [0.463]
 [0.775]
 [0.425]
 [0.402]
 [0.386]
 [0.377]]
Printing some Q and Qe and total Qs values:  [[0.287]
 [0.287]
 [0.287]
 [0.287]
 [0.726]
 [0.287]
 [0.287]] [[1.291]
 [1.291]
 [1.291]
 [1.291]
 [6.457]
 [1.291]
 [1.291]] [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [1.634]
 [0.004]
 [0.004]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.2778063506210338
Printing some Q and Qe and total Qs values:  [[0.055]
 [0.101]
 [0.147]
 [0.148]
 [0.092]
 [0.141]
 [0.186]] [[3.486]
 [3.882]
 [3.625]
 [3.858]
 [4.448]
 [4.717]
 [3.941]] [[-0.327]
 [ 0.03 ]
 [-0.049]
 [ 0.108]
 [ 0.389]
 [ 0.665]
 [ 0.238]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.2772674233585717
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.585]
 [0.54 ]
 [0.54 ]
 [0.54 ]
 [0.54 ]
 [0.54 ]] [[-1.435]
 [ 0.651]
 [-1.44 ]
 [-1.44 ]
 [-1.44 ]
 [-1.44 ]
 [-1.44 ]] [[0.376]
 [0.988]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.633]
 [0.611]
 [0.633]
 [0.622]
 [0.633]
 [0.888]
 [0.627]] [[4.454]
 [4.602]
 [5.075]
 [4.526]
 [5.075]
 [5.993]
 [4.392]] [[0.455]
 [0.484]
 [0.628]
 [0.469]
 [0.628]
 [1.024]
 [0.435]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.854]
 [1.025]
 [0.854]
 [0.862]
 [0.854]
 [0.867]
 [0.854]] [[3.458]
 [4.423]
 [3.458]
 [3.46 ]
 [3.458]
 [3.447]
 [3.458]] [[1.336]
 [2.182]
 [1.336]
 [1.346]
 [1.336]
 [1.342]
 [1.336]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.495]
 [0.525]
 [0.495]
 [0.302]
 [0.495]
 [0.495]
 [0.46 ]] [[3.516]
 [3.197]
 [3.516]
 [2.731]
 [3.516]
 [3.516]
 [3.427]] [[1.727]
 [1.568]
 [1.727]
 [1.101]
 [1.727]
 [1.727]
 [1.645]]
start point for exploration sampling:  10723
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.518]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]] [[3.543]
 [5.555]
 [3.543]
 [3.543]
 [3.543]
 [3.543]
 [3.543]] [[0.846]
 [1.799]
 [0.846]
 [0.846]
 [0.846]
 [0.846]
 [0.846]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.64106804
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
UNIT TEST: sample policy line 217 mcts : [0.02  0.02  0.02  0.02  0.878 0.02  0.02 ]
from probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.784]
 [0.477]] [[1.388]
 [1.388]
 [1.388]
 [1.388]
 [1.388]
 [1.057]
 [1.388]] [[0.304]
 [0.304]
 [0.304]
 [0.304]
 [0.304]
 [0.808]
 [0.304]]
Printing some Q and Qe and total Qs values:  [[0.726]
 [0.664]
 [0.726]
 [0.776]
 [0.813]
 [0.775]
 [0.726]] [[3.747]
 [3.347]
 [3.747]
 [4.444]
 [3.725]
 [3.53 ]
 [3.747]] [[1.626]
 [1.189]
 [1.626]
 [2.309]
 [1.722]
 [1.5  ]
 [1.626]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.402]
 [0.402]
 [0.402]
 [0.402]
 [0.402]
 [0.841]
 [0.402]] [[1.356]
 [1.356]
 [1.356]
 [1.356]
 [1.356]
 [0.989]
 [1.356]] [[0.143]
 [0.143]
 [0.143]
 [0.143]
 [0.143]
 [0.899]
 [0.143]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.552]
 [0.359]] [[1.656]
 [1.656]
 [1.656]
 [1.656]
 [1.656]
 [2.132]
 [1.656]] [[0.157]
 [0.157]
 [0.157]
 [0.157]
 [0.157]
 [0.703]
 [0.157]]
Printing some Q and Qe and total Qs values:  [[0.702]
 [0.717]
 [0.745]
 [0.766]
 [0.751]
 [0.747]
 [0.738]] [[3.402]
 [3.411]
 [3.627]
 [3.491]
 [3.618]
 [3.493]
 [3.442]] [[1.733]
 [1.765]
 [2.024]
 [1.919]
 [2.022]
 [1.892]
 [1.827]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.465]
 [0.487]
 [0.465]
 [0.609]
 [0.622]
 [0.603]
 [0.465]] [[3.627]
 [3.102]
 [3.627]
 [3.34 ]
 [3.272]
 [3.011]
 [3.627]] [[1.766]
 [1.531]
 [1.766]
 [1.732]
 [1.709]
 [1.57 ]
 [1.766]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.295]
 [0.348]
 [0.316]
 [0.299]
 [0.315]
 [0.313]
 [0.308]] [[-1.938]
 [-1.355]
 [-2.064]
 [-1.708]
 [-1.427]
 [-1.543]
 [-1.728]] [[0.295]
 [0.348]
 [0.316]
 [0.299]
 [0.315]
 [0.313]
 [0.308]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.064]
 [0.204]
 [0.104]
 [0.261]
 [0.235]
 [0.101]
 [0.104]] [[2.34 ]
 [2.648]
 [2.689]
 [2.503]
 [2.573]
 [1.651]
 [2.689]] [[-0.279]
 [ 0.098]
 [ 0.019]
 [ 0.054]
 [ 0.077]
 [-0.74 ]
 [ 0.019]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]] [[0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]
 [0.764]] [[1.837]
 [1.837]
 [1.837]
 [1.837]
 [1.837]
 [1.837]
 [1.837]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.317]
 [0.337]
 [0.308]
 [0.322]
 [0.319]
 [0.319]
 [0.321]] [[-2.123]
 [-1.724]
 [-2.22 ]
 [-1.963]
 [-1.973]
 [-1.871]
 [-1.685]] [[0.317]
 [0.337]
 [0.308]
 [0.322]
 [0.319]
 [0.319]
 [0.321]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.376]
 [0.524]
 [0.507]
 [0.528]
 [0.336]
 [0.5  ]
 [0.514]] [[ 1.411]
 [ 3.121]
 [-1.131]
 [-0.153]
 [ 0.683]
 [-1.284]
 [ 0.616]] [[0.854]
 [1.45 ]
 [0.176]
 [0.479]
 [0.613]
 [0.126]
 [0.699]]
in main func line 156:  1420
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.102]
 [0.082]
 [0.096]
 [0.09 ]
 [0.085]
 [0.099]
 [0.087]] [[-2.138]
 [ 0.757]
 [-2.153]
 [-2.067]
 [-2.082]
 [-1.927]
 [-1.895]] [[0.102]
 [0.082]
 [0.096]
 [0.09 ]
 [0.085]
 [0.099]
 [0.087]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.959907781639899
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 4.002125482343981
siam score:  -0.6327153
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 1.2040017290888496
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.512]
 [0.489]
 [0.525]
 [0.505]
 [0.521]
 [0.586]
 [0.503]] [[2.911]
 [2.281]
 [2.704]
 [2.916]
 [2.874]
 [2.624]
 [2.757]] [[0.496]
 [0.238]
 [0.452]
 [0.484]
 [0.502]
 [0.547]
 [0.427]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.63571185
rdn beta is 0 so we're just using the maxi policy
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.634598
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.824]
 [0.82 ]
 [0.805]
 [0.833]
 [0.805]
 [0.805]
 [0.805]] [[6.074]
 [4.996]
 [6.783]
 [6.268]
 [6.783]
 [6.783]
 [6.783]] [[1.832]
 [1.148]
 [2.242]
 [1.972]
 [2.242]
 [2.242]
 [2.242]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6120706
line 256 mcts: sample exp_bonus 5.062508408580811
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.708]
 [0.768]
 [0.767]
 [0.776]
 [0.771]
 [0.755]] [[2.322]
 [3.033]
 [3.049]
 [3.084]
 [3.1  ]
 [3.135]
 [2.964]] [[0.785]
 [1.495]
 [1.608]
 [1.643]
 [1.674]
 [1.703]
 [1.495]]
siam score:  -0.61489314
1433 1530
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 5.7641031919762025
Printing some Q and Qe and total Qs values:  [[0.516]
 [0.516]
 [0.516]
 [0.518]
 [0.516]
 [0.519]
 [0.516]] [[6.202]
 [6.202]
 [6.202]
 [6.695]
 [6.202]
 [6.05 ]
 [6.202]] [[1.371]
 [1.371]
 [1.371]
 [1.591]
 [1.371]
 [1.309]
 [1.371]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 5.304790366682039
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.051]
 [-0.07 ]
 [-0.058]
 [-0.057]
 [-0.06 ]
 [-0.06 ]
 [-0.059]] [[8.16 ]
 [7.169]
 [8.069]
 [8.136]
 [7.811]
 [8.165]
 [8.195]] [[0.714]
 [0.285]
 [0.668]
 [0.696]
 [0.56 ]
 [0.705]
 [0.718]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.046]
 [-0.047]
 [-0.047]
 [-0.047]
 [-0.047]
 [-0.047]
 [-0.047]] [[7.27]
 [6.46]
 [6.46]
 [6.46]
 [6.46]
 [6.46]
 [6.46]] [[1.038]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]]
Printing some Q and Qe and total Qs values:  [[-0.052]
 [-0.049]
 [-0.049]
 [-0.049]
 [-0.049]
 [-0.049]
 [-0.049]] [[7.704]
 [8.258]
 [8.258]
 [8.258]
 [8.258]
 [8.258]
 [8.258]] [[0.999]
 [1.234]
 [1.234]
 [1.234]
 [1.234]
 [1.234]
 [1.234]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.432]
 [1.432]
 [1.432]
 [1.432]
 [1.432]
 [1.432]
 [1.432]] [[1.265]
 [1.265]
 [1.265]
 [1.265]
 [1.265]
 [1.265]
 [1.265]] [[1.924]
 [1.924]
 [1.924]
 [1.924]
 [1.924]
 [1.924]
 [1.924]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 9.160561385503229
Printing some Q and Qe and total Qs values:  [[-0.064]
 [-0.064]
 [-0.064]
 [-0.064]
 [-0.064]
 [-0.058]
 [-0.064]] [[5.059]
 [5.059]
 [5.059]
 [5.059]
 [5.059]
 [4.94 ]
 [5.059]] [[0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.238]
 [0.17 ]
 [0.238]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
UNIT TEST: sample policy line 217 mcts : [0.02  0.02  0.02  0.735 0.143 0.02  0.041]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6271928
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.62696165
Printing some Q and Qe and total Qs values:  [[1.287]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]] [[6.151]
 [5.927]
 [5.927]
 [5.927]
 [5.927]
 [5.927]
 [5.927]] [[1.901]
 [1.497]
 [1.497]
 [1.497]
 [1.497]
 [1.497]
 [1.497]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 1.8504375575162217
Printing some Q and Qe and total Qs values:  [[0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]] [[4.186]
 [4.186]
 [4.186]
 [4.186]
 [4.186]
 [4.186]
 [4.186]] [[1.64]
 [1.64]
 [1.64]
 [1.64]
 [1.64]
 [1.64]
 [1.64]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.615958
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Starting evaluation
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.473]
 [0.35 ]
 [0.331]
 [0.268]
 [0.331]
 [0.331]
 [0.331]] [[3.111]
 [1.947]
 [1.184]
 [2.543]
 [1.184]
 [1.184]
 [1.184]] [[0.473]
 [0.35 ]
 [0.331]
 [0.268]
 [0.331]
 [0.331]
 [0.331]]
Printing some Q and Qe and total Qs values:  [[0.468]
 [0.623]
 [0.468]
 [0.468]
 [0.468]
 [0.468]
 [0.468]] [[-0.104]
 [-0.617]
 [-0.104]
 [-0.104]
 [-0.104]
 [-0.104]
 [-0.104]] [[0.468]
 [0.623]
 [0.468]
 [0.468]
 [0.468]
 [0.468]
 [0.468]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.625]
 [0.625]
 [0.625]
 [0.638]
 [0.625]
 [0.625]
 [0.625]] [[3.367]
 [3.367]
 [3.367]
 [2.312]
 [3.367]
 [3.367]
 [3.367]] [[0.625]
 [0.625]
 [0.625]
 [0.638]
 [0.625]
 [0.625]
 [0.625]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.491]
 [0.465]
 [0.501]
 [0.503]
 [0.472]
 [0.497]
 [0.472]] [[1.132]
 [2.181]
 [0.105]
 [0.128]
 [0.903]
 [0.435]
 [0.903]] [[0.491]
 [0.465]
 [0.501]
 [0.503]
 [0.472]
 [0.497]
 [0.472]]
Printing some Q and Qe and total Qs values:  [[0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]] [[3.637]
 [3.637]
 [3.637]
 [3.637]
 [3.637]
 [3.637]
 [3.637]] [[0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]]
Printing some Q and Qe and total Qs values:  [[0.573]
 [0.527]
 [0.573]
 [0.573]
 [0.555]
 [0.563]
 [0.573]] [[3.615]
 [3.379]
 [3.615]
 [3.615]
 [3.299]
 [3.467]
 [3.615]] [[0.573]
 [0.527]
 [0.573]
 [0.573]
 [0.555]
 [0.563]
 [0.573]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
using explorer policy with actor:  0
siam score:  -0.6071739
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 4.593392174071704
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.612]
 [0.665]
 [0.612]
 [0.678]
 [0.667]
 [0.687]
 [0.612]] [[3.097]
 [3.464]
 [3.097]
 [3.133]
 [3.23 ]
 [3.172]
 [3.097]] [[0.612]
 [0.665]
 [0.612]
 [0.678]
 [0.667]
 [0.687]
 [0.612]]
using explorer policy with actor:  0
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  0
using explorer policy with actor:  0
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 3.9286735018241576
Printing some Q and Qe and total Qs values:  [[0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]] [[3.624]
 [3.624]
 [3.624]
 [3.624]
 [3.624]
 [3.624]
 [3.624]] [[0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]]
Printing some Q and Qe and total Qs values:  [[0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.955]
 [0.784]
 [0.784]] [[2.564]
 [2.564]
 [2.564]
 [2.564]
 [2.706]
 [2.564]
 [2.564]] [[0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.955]
 [0.784]
 [0.784]]
1450 1537
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.944]
 [0.785]
 [0.785]] [[2.777]
 [2.777]
 [2.777]
 [2.777]
 [2.719]
 [2.777]
 [2.777]] [[0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.944]
 [0.785]
 [0.785]]
using explorer policy with actor:  0
start point for exploration sampling:  10723
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.980038817485459
Printing some Q and Qe and total Qs values:  [[0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]] [[3.944]
 [3.944]
 [3.944]
 [3.944]
 [3.944]
 [3.944]
 [3.944]] [[0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.653]
 [0.66 ]
 [0.659]] [[3.291]
 [3.66 ]
 [3.66 ]
 [3.66 ]
 [3.566]
 [3.573]
 [3.66 ]] [[0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.653]
 [0.66 ]
 [0.659]]
Printing some Q and Qe and total Qs values:  [[0.624]
 [0.624]
 [0.624]
 [0.624]
 [0.639]
 [0.602]
 [0.624]] [[3.861]
 [3.861]
 [3.861]
 [3.861]
 [3.442]
 [3.858]
 [3.861]] [[0.624]
 [0.624]
 [0.624]
 [0.624]
 [0.639]
 [0.602]
 [0.624]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.651]
 [0.651]
 [0.651]
 [0.651]
 [0.651]
 [0.651]
 [0.651]] [[3.741]
 [3.741]
 [3.741]
 [3.741]
 [3.741]
 [3.741]
 [3.741]] [[2.028]
 [2.028]
 [2.028]
 [2.028]
 [2.028]
 [2.028]
 [2.028]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]] [[3.541]
 [3.541]
 [3.541]
 [3.541]
 [3.541]
 [3.541]
 [3.541]] [[0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.61478335
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.628]
 [0.601]
 [0.634]
 [0.631]
 [0.695]
 [0.669]
 [0.629]] [[3.247]
 [3.709]
 [3.554]
 [3.566]
 [3.103]
 [3.078]
 [3.707]] [[0.628]
 [0.601]
 [0.634]
 [0.631]
 [0.695]
 [0.669]
 [0.629]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.626]
 [0.626]
 [0.626]
 [0.628]
 [0.666]
 [0.804]
 [0.626]] [[3.707]
 [3.707]
 [3.707]
 [3.9  ]
 [4.038]
 [2.492]
 [3.975]] [[0.626]
 [0.626]
 [0.626]
 [0.628]
 [0.666]
 [0.804]
 [0.626]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]] [[2.236]
 [2.236]
 [2.236]
 [2.236]
 [2.236]
 [2.236]
 [2.236]] [[0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.747]
 [0.751]] [[1.983]
 [1.983]
 [1.983]
 [1.983]
 [1.983]
 [2.144]
 [1.983]] [[0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.747]
 [0.751]]
Printing some Q and Qe and total Qs values:  [[0.62 ]
 [0.598]
 [0.637]
 [0.643]
 [0.852]
 [0.632]
 [0.655]] [[2.778]
 [2.504]
 [2.536]
 [2.751]
 [2.605]
 [3.018]
 [2.757]] [[0.62 ]
 [0.598]
 [0.637]
 [0.643]
 [0.852]
 [0.632]
 [0.655]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.737869055535986
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.685]
 [0.685]
 [0.685]
 [0.664]
 [0.685]
 [0.667]
 [0.685]] [[3.29 ]
 [3.29 ]
 [3.29 ]
 [3.168]
 [3.29 ]
 [3.243]
 [3.29 ]] [[0.685]
 [0.685]
 [0.685]
 [0.664]
 [0.685]
 [0.667]
 [0.685]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.3015226553455044
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.748]
 [0.748]
 [0.748]
 [0.748]
 [0.939]
 [0.748]
 [0.748]] [[2.596]
 [2.596]
 [2.596]
 [2.596]
 [3.923]
 [2.596]
 [2.596]] [[0.748]
 [0.748]
 [0.748]
 [0.748]
 [0.939]
 [0.748]
 [0.748]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 4.396590881490177
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.572]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.567]
 [0.561]] [[0.692]
 [1.64 ]
 [1.64 ]
 [1.64 ]
 [1.64 ]
 [1.572]
 [1.405]] [[0.572]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.567]
 [0.561]]
Printing some Q and Qe and total Qs values:  [[0.033]
 [0.033]
 [0.033]
 [0.033]
 [0.253]
 [0.033]
 [0.033]] [[2.929]
 [2.929]
 [2.929]
 [2.929]
 [7.175]
 [2.929]
 [2.929]] [[0.059]
 [0.059]
 [0.059]
 [0.059]
 [1.577]
 [0.059]
 [0.059]]
Printing some Q and Qe and total Qs values:  [[0.645]
 [0.645]
 [0.645]
 [0.65 ]
 [0.645]
 [0.645]
 [0.645]] [[3.166]
 [3.166]
 [3.166]
 [3.241]
 [3.166]
 [3.166]
 [3.166]] [[0.645]
 [0.645]
 [0.645]
 [0.65 ]
 [0.645]
 [0.645]
 [0.645]]
Printing some Q and Qe and total Qs values:  [[0.013]
 [0.013]
 [0.013]
 [0.013]
 [0.164]
 [0.013]
 [0.013]] [[2.947]
 [2.947]
 [2.947]
 [2.947]
 [5.328]
 [2.947]
 [2.947]] [[-0.043]
 [-0.043]
 [-0.043]
 [-0.043]
 [ 1.067]
 [-0.043]
 [-0.043]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 5.445212722981326
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.759]
 [0.759]
 [0.759]
 [0.726]
 [0.759]
 [0.739]
 [0.759]] [[3.49 ]
 [3.49 ]
 [3.49 ]
 [3.635]
 [3.49 ]
 [3.694]
 [3.49 ]] [[1.969]
 [1.969]
 [1.969]
 [2.071]
 [1.969]
 [2.153]
 [1.969]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.67]
 [0.67]
 [0.67]
 [0.67]
 [0.67]
 [0.67]
 [0.67]] [[2.117]
 [2.117]
 [2.117]
 [2.117]
 [2.117]
 [2.117]
 [2.117]] [[1.47]
 [1.47]
 [1.47]
 [1.47]
 [1.47]
 [1.47]
 [1.47]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.63079435
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6306736
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]
 [0.448]] [[1.176]
 [1.176]
 [1.176]
 [1.176]
 [1.176]
 [1.176]
 [1.176]] [[0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.49 ]
 [0.524]
 [0.49 ]
 [0.49 ]
 [0.49 ]
 [0.49 ]
 [0.49 ]] [[2.867]
 [3.136]
 [2.867]
 [2.867]
 [2.867]
 [2.867]
 [2.867]] [[0.953]
 [1.23 ]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.1]
 [0.1]
 [0.1]
 [0.1]
 [0.1]
 [0.1]
 [0.1]] [[-0.736]
 [-0.736]
 [-0.736]
 [-0.736]
 [-0.736]
 [-0.736]
 [-0.736]] [[0.1]
 [0.1]
 [0.1]
 [0.1]
 [0.1]
 [0.1]
 [0.1]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.172]
 [0.164]
 [0.171]
 [0.169]
 [0.171]
 [0.166]
 [0.159]] [[-2.198]
 [ 0.315]
 [-2.321]
 [-1.834]
 [-1.928]
 [-0.988]
 [-1.985]] [[0.172]
 [0.164]
 [0.171]
 [0.169]
 [0.171]
 [0.166]
 [0.159]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.988]
 [0.357]
 [0.427]
 [0.425]
 [0.415]
 [0.487]
 [0.417]] [[0.788]
 [1.626]
 [0.912]
 [0.916]
 [1.052]
 [1.005]
 [0.926]] [[1.124]
 [0.14 ]
 [0.042]
 [0.039]
 [0.064]
 [0.194]
 [0.028]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.625]
 [0.476]
 [0.569]
 [0.617]
 [0.776]
 [0.603]
 [0.554]] [[1.396]
 [1.818]
 [0.943]
 [1.497]
 [1.177]
 [1.402]
 [1.568]] [[0.625]
 [0.476]
 [0.569]
 [0.617]
 [0.776]
 [0.603]
 [0.554]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.933]
 [0.237]
 [0.307]
 [0.287]
 [0.295]
 [0.367]
 [0.297]] [[0.896]
 [1.626]
 [0.912]
 [0.955]
 [1.052]
 [1.006]
 [0.926]] [[ 1.049]
 [-0.1  ]
 [-0.198]
 [-0.224]
 [-0.176]
 [-0.046]
 [-0.212]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.64 ]
 [0.679]
 [0.64 ]
 [0.552]
 [0.64 ]
 [0.64 ]
 [0.64 ]] [[2.026]
 [2.713]
 [2.026]
 [2.238]
 [2.026]
 [2.026]
 [2.026]] [[1.137]
 [1.571]
 [1.137]
 [1.109]
 [1.137]
 [1.137]
 [1.137]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.61347395
first move QE:  1.2504829068504715
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.61328745
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]] [[1.49]
 [1.49]
 [1.49]
 [1.49]
 [1.49]
 [1.49]
 [1.49]] [[1.737]
 [1.737]
 [1.737]
 [1.737]
 [1.737]
 [1.737]
 [1.737]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6112092
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.536]
 [0.488]] [[4.908]
 [4.908]
 [4.908]
 [4.908]
 [4.908]
 [4.908]
 [3.41 ]] [[3.845]
 [3.845]
 [3.845]
 [3.845]
 [3.845]
 [3.845]
 [1.751]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.44 ]
 [0.44 ]
 [0.44 ]
 [0.438]
 [0.564]
 [0.439]
 [0.44 ]] [[0.946]
 [0.946]
 [0.739]
 [0.822]
 [0.852]
 [0.863]
 [0.946]] [[0.946]
 [0.946]
 [0.779]
 [0.843]
 [1.069]
 [0.876]
 [0.946]]
siam score:  -0.623316
Printing some Q and Qe and total Qs values:  [[0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.701]
 [0.494]
 [0.494]] [[2.495]
 [2.495]
 [2.495]
 [2.495]
 [5.356]
 [2.495]
 [2.495]] [[0.848]
 [0.848]
 [0.848]
 [0.848]
 [1.84 ]
 [0.848]
 [0.848]]
Printing some Q and Qe and total Qs values:  [[-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]] [[4.957]
 [4.957]
 [4.957]
 [4.957]
 [4.957]
 [4.957]
 [4.957]] [[0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.2496465965479648
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[-0.07 ]
 [-0.07 ]
 [-0.07 ]
 [-0.07 ]
 [-0.07 ]
 [-0.07 ]
 [-0.058]] [[8.318]
 [8.318]
 [8.318]
 [8.318]
 [8.318]
 [8.318]
 [7.453]] [[1.235]
 [1.235]
 [1.235]
 [1.235]
 [1.235]
 [1.235]
 [0.892]]
line 256 mcts: sample exp_bonus 5.687784354842465
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.82 ]
 [0.68 ]
 [0.852]
 [0.816]
 [0.844]
 [0.646]
 [0.824]] [[4.66 ]
 [4.512]
 [5.178]
 [5.265]
 [5.159]
 [4.341]
 [4.957]] [[1.31 ]
 [1.238]
 [1.424]
 [1.431]
 [1.418]
 [1.193]
 [1.371]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 4.94016521363041
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.809]
 [0.809]
 [0.809]
 [0.809]
 [0.809]
 [0.809]
 [0.809]] [[5.435]
 [5.435]
 [5.435]
 [5.435]
 [5.435]
 [5.435]
 [5.435]] [[1.588]
 [1.588]
 [1.588]
 [1.588]
 [1.588]
 [1.588]
 [1.588]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.9678747231671302
Printing some Q and Qe and total Qs values:  [[0.642]
 [0.613]
 [0.623]
 [0.618]
 [0.618]
 [0.623]
 [0.612]] [[-0.897]
 [-0.767]
 [-1.354]
 [-1.309]
 [-1.031]
 [-1.042]
 [-1.187]] [[0.642]
 [0.613]
 [0.623]
 [0.618]
 [0.618]
 [0.623]
 [0.612]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 1.019444162251025
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.759002221772403
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
UNIT TEST: sample policy line 217 mcts : [0.163 0.245 0.163 0.082 0.102 0.122 0.122]
siam score:  -0.6424763
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 0.8158254640926181
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.496]
 [0.421]
 [0.471]
 [0.468]
 [0.439]
 [0.424]
 [0.474]] [[5.754]
 [5.668]
 [5.926]
 [6.264]
 [5.851]
 [6.218]
 [6.244]] [[1.338]
 [1.244]
 [1.366]
 [1.465]
 [1.315]
 [1.412]
 [1.465]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 6.549456187826571
Printing some Q and Qe and total Qs values:  [[0.871]
 [0.832]
 [0.871]
 [0.869]
 [0.871]
 [0.866]
 [0.871]] [[4.994]
 [6.585]
 [4.994]
 [5.936]
 [4.994]
 [5.878]
 [4.994]] [[1.29 ]
 [2.001]
 [1.29 ]
 [1.73 ]
 [1.29 ]
 [1.701]
 [1.29 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.68 ]
 [0.652]
 [0.68 ]
 [0.667]
 [0.68 ]
 [0.651]
 [0.673]] [[5.673]
 [5.6  ]
 [5.673]
 [6.06 ]
 [5.673]
 [5.93 ]
 [6.135]] [[1.604]
 [1.5  ]
 [1.604]
 [1.836]
 [1.604]
 [1.718]
 [1.897]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[-0.019]
 [-0.015]
 [-0.017]
 [-0.016]
 [-0.009]
 [-0.021]
 [-0.016]] [[6.058]
 [4.608]
 [5.939]
 [5.984]
 [6.439]
 [5.979]
 [6.17 ]] [[ 0.241]
 [-0.605]
 [ 0.174]
 [ 0.203]
 [ 0.483]
 [ 0.191]
 [ 0.312]]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.0000],
        [-0.4156],
        [-0.0000],
        [-0.4250],
        [-0.0000],
        [-0.4165],
        [-0.4930],
        [-0.0000],
        [-0.0000],
        [-0.5270]], dtype=torch.float64)
-0.9467202737024999 -0.9467202737024999
-0.024259925299500003 -0.4398932248339064
-0.9464801247 -0.9464801247
-0.024259925299500003 -0.4492772698689701
-0.9608890648499999 -0.9608890648499999
-0.024259925299500003 -0.4407638172125027
-0.0727797758985 -0.5658208407517415
-0.965448 -0.965448
-0.13113787499999935 -0.13113787499999935
-0.024259925299500003 -0.5512872069062645
start point for exploration sampling:  10723
start point for exploration sampling:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.183]
 [0.18 ]
 [0.191]
 [0.2  ]
 [0.524]
 [0.182]
 [0.192]] [[4.69 ]
 [3.75 ]
 [4.666]
 [4.745]
 [5.387]
 [4.825]
 [4.68 ]] [[ 0.317]
 [-0.038]
 [ 0.318]
 [ 0.357]
 [ 0.963]
 [ 0.367]
 [ 0.324]]
Printing some Q and Qe and total Qs values:  [[0.694]
 [0.725]
 [0.693]
 [0.734]
 [0.693]
 [0.722]
 [0.693]] [[0.359]
 [1.449]
 [1.889]
 [0.9  ]
 [1.889]
 [0.988]
 [1.889]] [[2.1  ]
 [2.389]
 [2.445]
 [2.276]
 [2.445]
 [2.28 ]
 [2.445]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.95 ]
 [0.961]
 [0.95 ]
 [0.95 ]
 [0.95 ]
 [0.95 ]
 [0.95 ]] [[7.412]
 [6.703]
 [7.412]
 [7.412]
 [7.412]
 [7.412]
 [7.412]] [[2.246]
 [2.132]
 [2.246]
 [2.246]
 [2.246]
 [2.246]
 [2.246]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.247195737965925
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.6737036
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.489]
 [0.494]
 [0.489]
 [0.489]
 [0.489]
 [0.499]
 [0.495]] [[1.882]
 [2.489]
 [1.65 ]
 [1.65 ]
 [1.65 ]
 [2.024]
 [1.96 ]] [[0.489]
 [0.494]
 [0.489]
 [0.489]
 [0.489]
 [0.499]
 [0.495]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1500 1564
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.705]
 [0.667]
 [0.705]
 [0.705]
 [0.705]
 [0.713]
 [0.718]] [[0.489]
 [1.323]
 [0.489]
 [0.489]
 [0.489]
 [0.236]
 [0.492]] [[0.705]
 [0.667]
 [0.705]
 [0.705]
 [0.705]
 [0.713]
 [0.718]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6806123
Printing some Q and Qe and total Qs values:  [[0.867]
 [0.962]
 [0.867]
 [0.867]
 [0.96 ]
 [0.942]
 [0.867]] [[1.311]
 [3.467]
 [1.311]
 [1.311]
 [1.988]
 [1.76 ]
 [1.311]] [[1.86 ]
 [2.25 ]
 [1.86 ]
 [1.86 ]
 [2.036]
 [1.989]
 [1.86 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[ 0.009]
 [ 0.009]
 [ 0.009]
 [ 0.009]
 [ 0.009]
 [-0.011]
 [ 0.009]] [[4.718]
 [4.718]
 [4.718]
 [4.718]
 [4.718]
 [7.127]
 [4.718]] [[0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [1.262]
 [0.514]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.2440975490411932
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Sims:  50 1 epoch:  104699 pick best:  False frame count:  104699
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.551]
 [0.552]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]] [[1.458]
 [2.606]
 [1.458]
 [1.458]
 [1.458]
 [1.458]
 [1.458]] [[0.551]
 [0.552]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.672]
 [0.671]
 [0.672]
 [0.672]
 [0.672]
 [0.674]
 [0.672]] [[-0.129]
 [ 1.077]
 [-0.129]
 [-0.129]
 [-0.129]
 [ 0.028]
 [-0.129]] [[0.672]
 [0.671]
 [0.672]
 [0.672]
 [0.672]
 [0.674]
 [0.672]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.728]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.733]] [[1.763]
 [2.491]
 [2.491]
 [2.491]
 [2.308]
 [2.491]
 [1.916]] [[0.728]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.733]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[-0.051]
 [-0.051]
 [-0.051]
 [-0.066]
 [-0.066]
 [-0.064]
 [-0.051]] [[4.382]
 [4.382]
 [4.382]
 [6.558]
 [3.805]
 [3.753]
 [4.382]] [[-0.478]
 [-0.478]
 [-0.478]
 [ 0.219]
 [-0.7  ]
 [-0.713]
 [-0.478]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6886212
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]] [[2.004]
 [2.004]
 [2.004]
 [2.004]
 [2.004]
 [2.004]
 [2.004]] [[0.161]
 [0.161]
 [0.161]
 [0.161]
 [0.161]
 [0.161]
 [0.161]]
first move QE:  1.2391978672434731
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.352]
 [0.352]
 [0.352]
 [0.352]
 [0.352]
 [0.544]
 [0.352]] [[6.257]
 [6.257]
 [6.257]
 [6.257]
 [6.257]
 [9.084]
 [6.257]] [[0.921]
 [0.921]
 [0.921]
 [0.921]
 [0.921]
 [1.767]
 [0.921]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.69494474
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.755]
 [0.33 ]
 [0.359]
 [0.348]
 [0.345]
 [0.416]
 [0.36 ]] [[-2.397]
 [-0.685]
 [-1.272]
 [-1.244]
 [-0.693]
 [-0.612]
 [-1.18 ]] [[0.755]
 [0.33 ]
 [0.359]
 [0.348]
 [0.345]
 [0.416]
 [0.36 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus -0.7222319854390769
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.652]
 [0.668]
 [0.656]] [[2.097]
 [2.097]
 [2.097]
 [2.097]
 [2.03 ]
 [1.928]
 [2.097]] [[0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.652]
 [0.668]
 [0.656]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.2362166879351844
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.216]
 [0.188]
 [0.234]
 [0.232]
 [0.251]
 [0.239]
 [0.231]] [[4.148]
 [3.605]
 [3.93 ]
 [4.037]
 [4.082]
 [4.035]
 [4.194]] [[1.156]
 [0.629]
 [0.996]
 [1.086]
 [1.159]
 [1.097]
 [1.223]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.421]
 [0.4  ]
 [0.424]
 [0.417]
 [0.407]
 [0.421]
 [0.418]] [[ 0.214]
 [ 1.622]
 [ 0.302]
 [-0.018]
 [ 0.293]
 [ 0.078]
 [ 0.937]] [[0.421]
 [0.4  ]
 [0.424]
 [0.417]
 [0.407]
 [0.421]
 [0.418]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1531 1579
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.411]
 [0.671]
 [0.351]
 [0.375]
 [0.37 ]
 [0.364]
 [0.356]] [[ 0.49 ]
 [ 0.042]
 [-3.025]
 [-0.67 ]
 [ 0.613]
 [-2.826]
 [-0.122]] [[0.411]
 [0.671]
 [0.351]
 [0.375]
 [0.37 ]
 [0.364]
 [0.356]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6911231
first move QE:  1.2336845371695553
siam score:  -0.6877801
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.246]
 [0.174]
 [0.233]
 [0.249]
 [0.222]
 [0.259]
 [0.248]] [[3.372]
 [3.069]
 [3.793]
 [3.919]
 [4.219]
 [3.717]
 [3.721]] [[ 0.137]
 [-0.208]
 [ 0.391]
 [ 0.509]
 [ 0.654]
 [ 0.393]
 [ 0.375]]
Printing some Q and Qe and total Qs values:  [[0.941]
 [0.941]
 [0.941]
 [0.941]
 [0.941]
 [0.986]
 [0.941]] [[2.026]
 [2.026]
 [2.026]
 [2.026]
 [2.026]
 [2.432]
 [2.026]] [[0.779]
 [0.779]
 [0.779]
 [0.779]
 [0.779]
 [1.004]
 [0.779]]
Printing some Q and Qe and total Qs values:  [[0.3  ]
 [0.3  ]
 [0.3  ]
 [0.3  ]
 [0.314]
 [0.3  ]
 [0.3  ]] [[5.446]
 [5.446]
 [5.446]
 [5.446]
 [6.502]
 [5.446]
 [5.446]] [[1.153]
 [1.153]
 [1.153]
 [1.153]
 [1.598]
 [1.153]
 [1.153]]
siam score:  -0.6869875
siam score:  -0.6891043
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.816]
 [0.763]
 [0.816]
 [0.816]
 [0.859]
 [0.831]
 [0.816]] [[3.412]
 [3.602]
 [3.412]
 [3.412]
 [3.386]
 [3.383]
 [3.412]] [[0.721]
 [0.679]
 [0.721]
 [0.721]
 [0.798]
 [0.741]
 [0.721]]
Printing some Q and Qe and total Qs values:  [[0.761]
 [0.711]
 [0.792]
 [0.763]
 [0.816]
 [0.787]
 [0.794]] [[2.902]
 [2.927]
 [3.034]
 [3.08 ]
 [3.306]
 [3.138]
 [3.196]] [[0.454]
 [0.361]
 [0.561]
 [0.517]
 [0.699]
 [0.585]
 [0.617]]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.408]
 [0.428]
 [0.406]
 [0.402]
 [0.433]
 [0.478]
 [0.531]] [[2.438]
 [2.441]
 [2.273]
 [2.296]
 [2.539]
 [3.028]
 [2.744]] [[-0.258]
 [-0.218]
 [-0.318]
 [-0.319]
 [-0.175]
 [ 0.079]
 [ 0.089]]
UNIT TEST: sample policy line 217 mcts : [0.02  0.755 0.02  0.02  0.143 0.02  0.02 ]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1537 1588
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.53 ]
 [0.53 ]
 [0.53 ]
 [0.544]
 [0.546]
 [0.53 ]
 [0.53 ]] [[3.617]
 [3.617]
 [3.617]
 [3.618]
 [4.253]
 [3.617]
 [3.617]] [[0.53 ]
 [0.53 ]
 [0.53 ]
 [0.544]
 [0.546]
 [0.53 ]
 [0.53 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 0.45072984349381673
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.408]
 [0.438]
 [0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]] [[3.409]
 [4.277]
 [3.409]
 [3.409]
 [3.409]
 [3.409]
 [3.409]] [[0.408]
 [0.438]
 [0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]]
Printing some Q and Qe and total Qs values:  [[0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.492]
 [0.494]] [[3.522]
 [3.522]
 [3.522]
 [3.522]
 [3.522]
 [3.47 ]
 [3.522]] [[0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.673]
 [0.711]]
Printing some Q and Qe and total Qs values:  [[0.909]
 [0.899]
 [0.886]
 [0.881]
 [0.903]
 [0.891]
 [0.883]] [[3.121]
 [3.004]
 [3.35 ]
 [3.333]
 [3.354]
 [3.301]
 [3.365]] [[1.857]
 [1.715]
 [2.067]
 [2.042]
 [2.1  ]
 [2.022]
 [2.08 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6927037
Printing some Q and Qe and total Qs values:  [[0.992]
 [0.818]
 [0.985]
 [0.969]
 [0.956]
 [0.971]
 [0.923]] [[4.463]
 [3.838]
 [4.92 ]
 [4.988]
 [4.609]
 [4.78 ]
 [4.52 ]] [[1.982]
 [1.701]
 [2.089]
 [2.093]
 [1.99 ]
 [2.044]
 [1.945]]
UNIT TEST: sample policy line 217 mcts : [0.327 0.061 0.061 0.061 0.143 0.163 0.184]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
siam score:  -0.6985409
siam score:  -0.69831514
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1550 1596
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.152]
 [0.137]
 [0.119]
 [0.124]
 [0.135]
 [0.132]
 [0.126]] [[5.036]
 [5.823]
 [5.26 ]
 [5.386]
 [5.418]
 [5.3  ]
 [5.556]] [[0.631]
 [1.09 ]
 [0.709]
 [0.795]
 [0.835]
 [0.756]
 [0.905]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 6.419829277753184
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.71873106317467
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.936]
 [0.936]
 [0.936]
 [0.936]
 [0.936]
 [0.936]
 [0.936]] [[4.383]
 [4.383]
 [4.383]
 [4.383]
 [4.383]
 [4.383]
 [4.383]] [[2.131]
 [2.131]
 [2.131]
 [2.131]
 [2.131]
 [2.131]
 [2.131]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [0.818]
 [0.88 ]
 [0.866]
 [0.875]
 [0.895]
 [0.88 ]] [[3.129]
 [2.772]
 [3.129]
 [3.501]
 [3.653]
 [3.926]
 [3.129]] [[0.922]
 [0.68 ]
 [0.922]
 [1.02 ]
 [1.087]
 [1.22 ]
 [0.922]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.64 ]
 [0.693]
 [0.64 ]
 [0.714]
 [0.64 ]
 [0.64 ]
 [0.64 ]] [[4.684]
 [6.841]
 [4.684]
 [5.44 ]
 [4.684]
 [4.684]
 [4.684]] [[1.247]
 [2.104]
 [1.247]
 [1.589]
 [1.247]
 [1.247]
 [1.247]]
Printing some Q and Qe and total Qs values:  [[-0.016]
 [-0.004]
 [-0.008]
 [-0.004]
 [ 0.019]
 [ 0.012]
 [ 0.042]] [[2.682]
 [2.624]
 [2.647]
 [2.675]
 [2.649]
 [2.633]
 [2.588]] [[-0.219]
 [-0.236]
 [-0.228]
 [-0.202]
 [-0.173]
 [-0.196]
 [-0.166]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.906]
 [0.906]
 [0.906]
 [0.921]
 [0.906]
 [0.906]
 [0.906]] [[4.464]
 [4.464]
 [4.464]
 [5.237]
 [4.464]
 [4.464]
 [4.464]] [[1.589]
 [1.589]
 [1.589]
 [2.079]
 [1.589]
 [1.589]
 [1.589]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.69409364
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.518]
 [0.54 ]
 [0.518]
 [0.518]
 [0.518]
 [0.518]
 [0.518]] [[2.33 ]
 [3.452]
 [2.33 ]
 [2.33 ]
 [2.33 ]
 [2.33 ]
 [2.33 ]] [[0.77 ]
 [1.131]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]] [[5.048]
 [5.048]
 [5.048]
 [5.048]
 [5.048]
 [5.048]
 [5.048]] [[1.947]
 [1.947]
 [1.947]
 [1.947]
 [1.947]
 [1.947]
 [1.947]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.755]
 [0.717]
 [0.789]
 [0.77 ]
 [0.773]
 [0.759]
 [0.752]] [[4.366]
 [3.71 ]
 [4.274]
 [4.607]
 [4.225]
 [4.71 ]
 [4.317]] [[1.351]
 [0.839]
 [1.357]
 [1.542]
 [1.294]
 [1.589]
 [1.312]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.2115859457416702
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[-0.058]
 [-0.058]
 [-0.058]
 [-0.058]
 [-0.058]
 [-0.058]
 [-0.058]] [[7.28]
 [7.28]
 [7.28]
 [7.28]
 [7.28]
 [7.28]
 [7.28]] [[0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
in main func line 156:  1567
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.694]
 [0.543]
 [0.699]
 [0.699]
 [0.691]
 [0.685]
 [0.683]] [[-1.036]
 [ 1.382]
 [-0.962]
 [-1.058]
 [-0.656]
 [-0.473]
 [-0.899]] [[0.694]
 [0.543]
 [0.699]
 [0.699]
 [0.691]
 [0.685]
 [0.683]]
Printing some Q and Qe and total Qs values:  [[0.675]
 [0.7  ]
 [0.675]
 [0.878]
 [0.675]
 [0.675]
 [0.675]] [[3.424]
 [4.255]
 [3.424]
 [4.353]
 [3.424]
 [3.424]
 [3.424]] [[1.711]
 [1.973]
 [1.711]
 [2.083]
 [1.711]
 [1.711]
 [1.711]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7080798
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7130922
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.675]
 [0.675]
 [0.675]
 [0.897]
 [0.675]
 [0.675]
 [0.675]] [[3.952]
 [3.952]
 [3.952]
 [4.139]
 [3.952]
 [3.952]
 [3.952]] [[1.658]
 [1.658]
 [1.658]
 [2.015]
 [1.658]
 [1.658]
 [1.658]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.6786277965058707
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.404460583583853
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1575 1612
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.352]
 [0.356]
 [0.352]
 [0.352]
 [0.352]
 [0.345]
 [0.352]] [[3.701]
 [4.159]
 [3.701]
 [3.701]
 [3.701]
 [5.355]
 [3.701]] [[-0.011]
 [ 0.148]
 [-0.011]
 [-0.011]
 [-0.011]
 [ 0.526]
 [-0.011]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.982]
 [0.965]
 [0.982]
 [0.963]
 [0.982]
 [0.982]
 [0.982]] [[4.793]
 [4.952]
 [4.793]
 [5.215]
 [4.793]
 [4.793]
 [4.793]] [[2.031]
 [2.057]
 [2.031]
 [2.119]
 [2.031]
 [2.031]
 [2.031]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
start point for exploration sampling:  10723
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.395907128213058
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.72039765
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.2513058533932986
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Starting evaluation
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.218]
 [0.48 ]
 [0.353]
 [0.353]
 [0.213]
 [0.353]
 [0.359]] [[ 1.48 ]
 [ 1.985]
 [-0.542]
 [-0.542]
 [-1.064]
 [-0.542]
 [ 1.351]] [[0.218]
 [0.48 ]
 [0.353]
 [0.353]
 [0.213]
 [0.353]
 [0.359]]
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]] [[3.381]
 [3.381]
 [3.381]
 [3.381]
 [3.381]
 [3.381]
 [3.381]] [[0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.506]
 [0.464]
 [0.559]
 [0.582]
 [0.554]
 [0.492]
 [0.341]] [[2.599]
 [3.3  ]
 [4.44 ]
 [1.748]
 [3.78 ]
 [2.1  ]
 [2.68 ]] [[0.506]
 [0.464]
 [0.559]
 [0.582]
 [0.554]
 [0.492]
 [0.341]]
using explorer policy with actor:  1
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.775]
 [0.746]
 [0.782]
 [0.786]
 [0.788]
 [0.783]
 [0.78 ]] [[4.317]
 [3.91 ]
 [4.844]
 [4.453]
 [4.234]
 [4.522]
 [4.903]] [[0.775]
 [0.746]
 [0.782]
 [0.786]
 [0.788]
 [0.783]
 [0.78 ]]
line 256 mcts: sample exp_bonus 4.651073620080059
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.787]
 [0.787]
 [0.787]
 [0.787]
 [0.787]
 [0.791]
 [0.793]] [[2.772]
 [2.772]
 [2.772]
 [2.772]
 [2.772]
 [3.02 ]
 [3.289]] [[0.787]
 [0.787]
 [0.787]
 [0.787]
 [0.787]
 [0.791]
 [0.793]]
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.62 ]
 [0.616]
 [0.616]] [[3.346]
 [3.346]
 [3.346]
 [3.346]
 [3.018]
 [3.346]
 [3.346]] [[0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.62 ]
 [0.616]
 [0.616]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.71944046
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
siam score:  -0.71951246
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]] [[5.037]
 [5.037]
 [5.037]
 [5.037]
 [5.037]
 [5.037]
 [5.037]] [[0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.78 ]
 [0.717]
 [0.717]] [[3.2  ]
 [3.2  ]
 [3.2  ]
 [3.2  ]
 [2.737]
 [3.2  ]
 [3.2  ]] [[0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.78 ]
 [0.717]
 [0.717]]
Printing some Q and Qe and total Qs values:  [[0.774]
 [0.774]
 [0.774]
 [0.777]
 [0.774]
 [0.774]
 [0.774]] [[5.092]
 [5.092]
 [5.092]
 [5.073]
 [5.092]
 [5.092]
 [5.092]] [[0.774]
 [0.774]
 [0.774]
 [0.777]
 [0.774]
 [0.774]
 [0.774]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.776]
 [0.776]
 [0.68 ]
 [0.776]
 [0.776]
 [0.776]] [[3.361]
 [3.185]
 [3.185]
 [3.821]
 [3.185]
 [3.185]
 [3.185]] [[0.699]
 [0.776]
 [0.776]
 [0.68 ]
 [0.776]
 [0.776]
 [0.776]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.718]
 [0.718]
 [0.702]
 [0.832]
 [0.69 ]
 [0.718]] [[3.176]
 [3.176]
 [3.176]
 [3.108]
 [2.694]
 [2.98 ]
 [3.176]] [[0.718]
 [0.718]
 [0.718]
 [0.702]
 [0.832]
 [0.69 ]
 [0.718]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]] [[2.939]
 [2.939]
 [2.939]
 [2.939]
 [2.939]
 [2.939]
 [2.939]] [[0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]]
start point for exploration sampling:  10723
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]] [[1.869]
 [1.869]
 [1.869]
 [1.869]
 [1.869]
 [1.869]
 [1.869]] [[0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]
 [0.631]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.721]
 [0.684]
 [0.709]
 [0.714]
 [0.734]
 [0.715]
 [0.71 ]] [[3.188]
 [3.498]
 [3.404]
 [3.335]
 [3.203]
 [3.104]
 [3.387]] [[0.721]
 [0.684]
 [0.709]
 [0.714]
 [0.734]
 [0.715]
 [0.71 ]]
siam score:  -0.72131366
Printing some Q and Qe and total Qs values:  [[0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.85 ]
 [0.688]
 [0.688]] [[3.469]
 [3.469]
 [3.469]
 [3.469]
 [6.083]
 [3.469]
 [3.469]] [[0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.85 ]
 [0.688]
 [0.688]]
Printing some Q and Qe and total Qs values:  [[0.771]
 [0.771]
 [0.771]
 [0.771]
 [0.837]
 [0.771]
 [0.771]] [[3.44 ]
 [3.44 ]
 [3.44 ]
 [3.44 ]
 [4.432]
 [3.44 ]
 [3.44 ]] [[0.771]
 [0.771]
 [0.771]
 [0.771]
 [0.837]
 [0.771]
 [0.771]]
line 256 mcts: sample exp_bonus 3.7524414843563303
Printing some Q and Qe and total Qs values:  [[0.817]
 [0.744]
 [0.817]
 [0.775]
 [0.84 ]
 [0.777]
 [0.775]] [[3.895]
 [4.423]
 [3.895]
 [4.282]
 [3.831]
 [4.645]
 [4.509]] [[0.817]
 [0.744]
 [0.817]
 [0.775]
 [0.84 ]
 [0.777]
 [0.775]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.767]
 [0.731]
 [0.731]] [[3.569]
 [3.569]
 [3.569]
 [3.569]
 [3.69 ]
 [3.569]
 [3.569]] [[0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.767]
 [0.731]
 [0.731]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.038765238195459
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.728]
 [0.689]
 [0.689]] [[3.385]
 [3.385]
 [3.385]
 [3.385]
 [3.792]
 [3.385]
 [3.385]] [[0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.728]
 [0.689]
 [0.689]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]] [[3.407]
 [3.407]
 [3.407]
 [3.407]
 [3.407]
 [3.407]
 [3.407]] [[0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]]
Printing some Q and Qe and total Qs values:  [[0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.679]
 [0.676]
 [0.676]] [[3.496]
 [3.496]
 [3.496]
 [3.496]
 [3.486]
 [3.496]
 [3.496]] [[0.676]
 [0.676]
 [0.676]
 [0.676]
 [0.679]
 [0.676]
 [0.676]]
Printing some Q and Qe and total Qs values:  [[0.295]
 [0.425]
 [0.295]
 [0.271]
 [0.295]
 [0.272]
 [0.295]] [[2.584]
 [2.027]
 [2.584]
 [2.062]
 [2.584]
 [2.162]
 [2.584]] [[-0.502]
 [-0.426]
 [-0.502]
 [-0.724]
 [-0.502]
 [-0.688]
 [-0.502]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.622]
 [0.634]
 [0.637]
 [0.641]
 [0.649]
 [0.637]
 [0.63 ]] [[1.679]
 [1.401]
 [1.778]
 [1.87 ]
 [1.831]
 [1.66 ]
 [1.786]] [[0.622]
 [0.634]
 [0.637]
 [0.641]
 [0.649]
 [0.637]
 [0.63 ]]
Printing some Q and Qe and total Qs values:  [[0.636]
 [0.604]
 [0.632]
 [0.632]
 [0.647]
 [0.636]
 [0.633]] [[4.372]
 [4.445]
 [4.358]
 [4.394]
 [4.381]
 [4.591]
 [4.931]] [[0.636]
 [0.604]
 [0.632]
 [0.632]
 [0.647]
 [0.636]
 [0.633]]
line 256 mcts: sample exp_bonus 3.7459412373302547
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]] [[3.79]
 [3.79]
 [3.79]
 [3.79]
 [3.79]
 [3.79]
 [3.79]] [[0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]]
Printing some Q and Qe and total Qs values:  [[-0.013]
 [-0.013]
 [-0.013]
 [-0.013]
 [-0.012]
 [-0.014]
 [-0.013]] [[2.393]
 [2.393]
 [2.393]
 [2.393]
 [2.406]
 [2.392]
 [2.393]] [[-1.078]
 [-1.078]
 [-1.078]
 [-1.078]
 [-1.072]
 [-1.08 ]
 [-1.078]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
main train batch thing paused
add a thread
Adding thread: now have 4 threads
main train batch thing paused
add a thread
Adding thread: now have 5 threads
Printing some Q and Qe and total Qs values:  [[0.643]
 [0.62 ]
 [0.643]
 [0.643]
 [0.643]
 [0.622]
 [0.643]] [[1.514]
 [1.657]
 [1.514]
 [1.514]
 [1.514]
 [1.236]
 [1.514]] [[0.643]
 [0.62 ]
 [0.643]
 [0.643]
 [0.643]
 [0.622]
 [0.643]]
siam score:  -0.7282164
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.5206328456004137
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 1.9202638078295873
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]] [[3.626]
 [3.626]
 [3.626]
 [3.626]
 [3.626]
 [3.626]
 [3.626]] [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.763]
 [0.763]
 [0.763]
 [0.761]
 [0.771]
 [0.763]
 [0.763]] [[5.674]
 [5.674]
 [5.674]
 [4.339]
 [4.303]
 [5.674]
 [5.674]] [[1.661]
 [1.661]
 [1.661]
 [0.962]
 [0.953]
 [1.661]
 [1.661]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.636]
 [0.656]
 [0.666]
 [0.656]
 [0.687]
 [0.648]
 [0.69 ]] [[3.468]
 [3.465]
 [3.689]
 [3.558]
 [3.521]
 [3.563]
 [3.403]] [[0.636]
 [0.656]
 [0.666]
 [0.656]
 [0.687]
 [0.648]
 [0.69 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.932]
 [0.932]
 [0.932]
 [0.968]
 [0.932]
 [0.932]
 [0.932]] [[3.816]
 [3.816]
 [3.816]
 [4.313]
 [3.816]
 [3.816]
 [3.816]] [[1.84 ]
 [1.84 ]
 [1.84 ]
 [2.163]
 [1.84 ]
 [1.84 ]
 [1.84 ]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.634]
 [0.635]] [[3.583]
 [3.583]
 [3.583]
 [3.583]
 [3.583]
 [3.966]
 [3.583]] [[0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.634]
 [0.635]]
Printing some Q and Qe and total Qs values:  [[0.387]
 [0.397]
 [0.387]
 [0.387]
 [0.387]
 [0.387]
 [0.387]] [[-1.779]
 [-0.681]
 [-1.779]
 [-1.779]
 [-1.779]
 [-1.779]
 [-1.779]] [[0.387]
 [0.397]
 [0.387]
 [0.387]
 [0.387]
 [0.387]
 [0.387]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.6379752720192164
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.529]
 [0.559]
 [0.541]
 [0.553]
 [0.541]
 [0.529]] [[2.512]
 [2.49 ]
 [2.646]
 [2.98 ]
 [3.01 ]
 [2.952]
 [3.016]] [[0.537]
 [0.529]
 [0.559]
 [0.541]
 [0.553]
 [0.541]
 [0.529]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.74215776
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.868]
 [0.859]
 [0.866]
 [0.866]
 [0.884]
 [0.865]
 [0.858]] [[4.509]
 [3.983]
 [4.134]
 [4.203]
 [3.99 ]
 [4.082]
 [4.047]] [[1.684]
 [1.323]
 [1.433]
 [1.478]
 [1.362]
 [1.397]
 [1.364]]
line 256 mcts: sample exp_bonus 5.086134592573756
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.688]
 [0.685]
 [0.657]
 [0.661]
 [0.691]
 [0.71 ]
 [0.638]] [[2.535]
 [2.527]
 [3.119]
 [4.144]
 [4.502]
 [4.999]
 [3.485]] [[0.263]
 [0.255]
 [0.396]
 [0.747]
 [0.926]
 [1.13 ]
 [0.48 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.949]
 [0.702]
 [0.949]
 [0.931]
 [0.949]
 [0.949]
 [0.949]] [[2.956]
 [3.019]
 [2.956]
 [3.822]
 [2.956]
 [2.956]
 [2.956]] [[1.766]
 [1.292]
 [1.766]
 [2.02 ]
 [1.766]
 [1.766]
 [1.766]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[ 0.012]
 [ 0.034]
 [ 0.002]
 [ 0.012]
 [ 0.012]
 [-0.002]
 [ 0.012]] [[ 0.588]
 [ 1.529]
 [-1.319]
 [ 0.588]
 [ 0.588]
 [-0.873]
 [ 0.588]] [[ 0.012]
 [ 0.034]
 [ 0.002]
 [ 0.012]
 [ 0.012]
 [-0.002]
 [ 0.012]]
from probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -1.1799943601486722
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.077]
 [0.098]
 [0.077]
 [0.077]
 [0.077]
 [0.077]
 [0.077]] [[-1.696]
 [-1.596]
 [-1.696]
 [-1.696]
 [-1.696]
 [-1.696]
 [-1.696]] [[0.077]
 [0.098]
 [0.077]
 [0.077]
 [0.077]
 [0.077]
 [0.077]]
Printing some Q and Qe and total Qs values:  [[0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.516]
 [0.501]] [[4.504]
 [4.504]
 [4.504]
 [4.504]
 [4.504]
 [6.952]
 [4.504]] [[0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]
 [1.494]
 [0.715]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.283]
 [0.196]
 [0.222]
 [0.216]
 [0.27 ]
 [0.236]
 [0.203]] [[1.529]
 [2.766]
 [1.459]
 [1.647]
 [1.376]
 [1.923]
 [1.721]] [[0.283]
 [0.196]
 [0.222]
 [0.216]
 [0.27 ]
 [0.236]
 [0.203]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 6.3622827082433835
Printing some Q and Qe and total Qs values:  [[0.683]
 [0.659]
 [0.683]
 [0.683]
 [0.7  ]
 [0.704]
 [0.683]] [[2.139]
 [2.225]
 [2.139]
 [2.139]
 [1.945]
 [1.427]
 [2.139]] [[0.455]
 [0.436]
 [0.455]
 [0.455]
 [0.425]
 [0.259]
 [0.455]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.941]] [[3.888]
 [3.888]
 [3.888]
 [3.888]
 [3.888]
 [3.888]
 [3.289]] [[2.239]
 [2.239]
 [2.239]
 [2.239]
 [2.239]
 [2.239]
 [1.856]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.331]
 [0.316]
 [0.32 ]
 [0.333]
 [0.315]
 [0.286]
 [0.292]] [[-0.147]
 [ 1.817]
 [-0.018]
 [ 0.166]
 [ 0.072]
 [ 0.037]
 [-0.292]] [[0.331]
 [0.316]
 [0.32 ]
 [0.333]
 [0.315]
 [0.286]
 [0.292]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7404468
siam score:  -0.7405704
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]] [[3.88]
 [3.88]
 [3.88]
 [3.88]
 [3.88]
 [3.88]
 [3.88]] [[1.673]
 [1.673]
 [1.673]
 [1.673]
 [1.673]
 [1.673]
 [1.673]]
Printing some Q and Qe and total Qs values:  [[0.938]
 [0.992]
 [0.938]
 [0.938]
 [0.938]
 [0.998]
 [0.938]] [[2.411]
 [1.682]
 [2.411]
 [2.411]
 [2.411]
 [1.592]
 [2.411]] [[0.938]
 [0.992]
 [0.938]
 [0.938]
 [0.938]
 [0.998]
 [0.938]]
using explorer policy with actor:  1
siam score:  -0.73223823
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.73107237
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 5.337105012062516
Printing some Q and Qe and total Qs values:  [[0.679]
 [0.61 ]
 [0.634]
 [0.621]
 [0.665]
 [0.609]
 [0.612]] [[4.486]
 [7.23 ]
 [4.535]
 [4.709]
 [4.594]
 [5.216]
 [5.29 ]] [[0.831]
 [1.882]
 [0.796]
 [0.851]
 [0.859]
 [1.047]
 [1.081]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.624]
 [0.617]
 [0.811]
 [0.706]
 [0.793]
 [0.583]
 [0.664]] [[0.366]
 [0.767]
 [0.251]
 [0.825]
 [0.665]
 [0.727]
 [0.788]] [[0.693]
 [0.813]
 [1.029]
 [1.011]
 [1.131]
 [0.731]
 [0.914]]
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.729]
 [0.589]
 [0.729]
 [0.61 ]
 [0.729]
 [0.587]] [[0.522]
 [1.051]
 [0.944]
 [1.051]
 [1.455]
 [1.051]
 [0.812]] [[0.677]
 [1.108]
 [0.793]
 [1.108]
 [1.005]
 [1.108]
 [0.745]]
Printing some Q and Qe and total Qs values:  [[0.311]
 [0.42 ]
 [0.386]
 [0.424]
 [0.406]
 [0.408]
 [0.358]] [[ 0.491]
 [ 0.679]
 [-2.506]
 [-0.452]
 [ 0.351]
 [-1.287]
 [ 0.261]] [[0.311]
 [0.42 ]
 [0.386]
 [0.424]
 [0.406]
 [0.408]
 [0.358]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.744]
 [0.093]
 [0.744]
 [0.744]
 [0.744]
 [0.744]
 [0.744]] [[1.021]
 [1.174]
 [1.021]
 [1.021]
 [1.021]
 [1.021]
 [1.021]] [[1.338]
 [1.014]
 [1.338]
 [1.338]
 [1.338]
 [1.338]
 [1.338]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.804]
 [0.804]
 [0.804]
 [0.804]
 [0.804]
 [0.83 ]
 [0.804]] [[4.696]
 [4.696]
 [4.696]
 [4.696]
 [4.696]
 [4.08 ]
 [4.696]] [[1.997]
 [1.997]
 [1.997]
 [1.997]
 [1.997]
 [1.633]
 [1.997]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7339248
Printing some Q and Qe and total Qs values:  [[0.313]
 [0.392]
 [0.309]
 [0.307]
 [0.397]
 [0.394]
 [0.309]] [[2.99 ]
 [3.454]
 [3.392]
 [3.599]
 [3.74 ]
 [3.642]
 [3.643]] [[0.4  ]
 [0.828]
 [0.691]
 [0.841]
 [1.042]
 [0.968]
 [0.876]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.255]
 [0.345]
 [0.252]
 [0.249]
 [0.305]
 [0.261]
 [0.28 ]] [[3.973]
 [4.659]
 [3.996]
 [3.994]
 [4.074]
 [3.991]
 [4.457]] [[0.679]
 [1.261]
 [0.691]
 [0.687]
 [0.804]
 [0.698]
 [1.049]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7349033
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7344614
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
in main func line 156:  1638
1638 1643
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.283776500585878
Printing some Q and Qe and total Qs values:  [[0.949]
 [0.949]
 [0.949]
 [0.949]
 [0.949]
 [0.98 ]
 [0.949]] [[5.465]
 [5.465]
 [5.465]
 [5.465]
 [5.465]
 [5.343]
 [5.465]] [[2.413]
 [2.413]
 [2.413]
 [2.413]
 [2.413]
 [2.394]
 [2.413]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.66 ]
 [0.511]
 [0.683]
 [0.613]
 [0.757]
 [0.704]
 [0.384]] [[2.618]
 [1.755]
 [0.701]
 [2.058]
 [5.532]
 [0.522]
 [1.906]] [[1.117]
 [0.604]
 [0.394]
 [0.842]
 [2.37 ]
 [0.349]
 [0.514]]
Printing some Q and Qe and total Qs values:  [[0.869]
 [0.869]
 [0.869]
 [0.849]
 [0.869]
 [0.869]
 [0.869]] [[3.362]
 [3.362]
 [3.362]
 [3.449]
 [3.362]
 [3.362]
 [3.362]] [[2.042]
 [2.042]
 [2.042]
 [2.09 ]
 [2.042]
 [2.042]
 [2.042]]
Printing some Q and Qe and total Qs values:  [[0.604]
 [0.634]
 [0.604]
 [0.682]
 [0.604]
 [0.604]
 [0.604]] [[3.597]
 [5.22 ]
 [3.597]
 [6.088]
 [3.597]
 [3.597]
 [3.597]] [[0.871]
 [1.473]
 [0.871]
 [1.859]
 [0.871]
 [0.871]
 [0.871]]
siam score:  -0.73083025
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 3.0788251076998234
Printing some Q and Qe and total Qs values:  [[0.705]
 [0.705]
 [0.705]
 [0.705]
 [0.705]
 [0.705]
 [0.705]] [[4.993]
 [4.993]
 [4.993]
 [4.993]
 [4.993]
 [4.993]
 [4.993]] [[2.113]
 [2.113]
 [2.113]
 [2.113]
 [2.113]
 [2.113]
 [2.113]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
siam score:  -0.7278453
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.077]
 [0.03 ]
 [0.05 ]
 [0.047]
 [0.053]
 [0.051]
 [0.045]] [[3.673]
 [3.596]
 [3.583]
 [3.588]
 [3.861]
 [3.736]
 [3.768]] [[0.387]
 [0.216]
 [0.243]
 [0.242]
 [0.528]
 [0.397]
 [0.417]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.928]
 [0.803]
 [0.921]
 [0.916]
 [0.984]
 [0.921]
 [0.921]] [[1.408]
 [1.891]
 [2.483]
 [1.466]
 [2.518]
 [2.483]
 [2.483]] [[1.647]
 [1.784]
 [2.14 ]
 [1.666]
 [2.2  ]
 [2.14 ]
 [2.14 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.673]
 [0.726]
 [0.673]
 [0.673]
 [0.673]
 [0.673]
 [0.673]] [[-3.03 ]
 [ 0.392]
 [-3.03 ]
 [-3.03 ]
 [-3.03 ]
 [-3.03 ]
 [-3.03 ]] [[0.576]
 [1.621]
 [0.576]
 [0.576]
 [0.576]
 [0.576]
 [0.576]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1647 1653
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.73098886
Printing some Q and Qe and total Qs values:  [[0.809]
 [0.809]
 [0.809]
 [0.881]
 [0.809]
 [0.809]
 [0.688]] [[3.629]
 [3.629]
 [3.629]
 [2.891]
 [3.629]
 [3.629]
 [3.254]] [[1.143]
 [1.143]
 [1.143]
 [0.845]
 [1.143]
 [1.143]
 [0.88 ]]
Printing some Q and Qe and total Qs values:  [[0.809]
 [0.389]
 [0.833]
 [0.838]
 [0.859]
 [0.844]
 [0.829]] [[-0.46 ]
 [ 1.447]
 [-0.296]
 [-0.199]
 [-0.147]
 [-0.128]
 [-0.33 ]] [[0.771]
 [0.568]
 [0.875]
 [0.917]
 [0.975]
 [0.951]
 [0.855]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.703]
 [0.703]
 [0.703]
 [0.705]
 [0.709]
 [0.704]] [[2.929]
 [2.929]
 [2.929]
 [2.929]
 [3.223]
 [3.206]
 [2.974]] [[1.082]
 [1.082]
 [1.082]
 [1.082]
 [1.382]
 [1.372]
 [1.129]]
Printing some Q and Qe and total Qs values:  [[0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.686]
 [0.681]] [[2.91 ]
 [2.91 ]
 [2.91 ]
 [2.91 ]
 [2.91 ]
 [3.234]
 [2.91 ]] [[1.198]
 [1.198]
 [1.198]
 [1.198]
 [1.198]
 [1.588]
 [1.198]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.426]
 [0.442]
 [0.45 ]
 [0.444]
 [0.44 ]
 [0.433]
 [0.45 ]] [[6.289]
 [4.947]
 [5.683]
 [5.917]
 [6.172]
 [6.317]
 [5.683]] [[1.103]
 [0.321]
 [0.781]
 [0.912]
 [1.059]
 [1.133]
 [0.781]]
using explorer policy with actor:  1
1652 1655
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.405]
 [1.351]
 [1.351]
 [1.351]
 [1.351]
 [1.351]
 [1.351]] [[1.022]
 [1.115]
 [1.115]
 [1.115]
 [1.115]
 [1.115]
 [1.115]] [[2.176]
 [2.099]
 [2.099]
 [2.099]
 [2.099]
 [2.099]
 [2.099]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7292973
first move QE:  1.1880997080682099
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.067]
 [-0.058]
 [-0.063]
 [-0.063]
 [-0.064]
 [-0.063]
 [-0.061]] [[5.699]
 [4.691]
 [5.569]
 [5.462]
 [5.566]
 [5.659]
 [5.327]] [[ 0.469]
 [-0.149]
 [ 0.394]
 [ 0.327]
 [ 0.39 ]
 [ 0.452]
 [ 0.245]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.97 ]
 [0.973]
 [0.97 ]
 [0.97 ]
 [0.97 ]
 [0.971]
 [0.971]] [[7.036]
 [6.289]
 [7.036]
 [7.036]
 [7.036]
 [7.144]
 [6.994]] [[2.233]
 [2.085]
 [2.233]
 [2.233]
 [2.233]
 [2.255]
 [2.224]]
Printing some Q and Qe and total Qs values:  [[0.893]
 [0.893]
 [0.893]
 [0.892]
 [0.893]
 [0.893]
 [0.893]] [[1.905]
 [1.905]
 [1.905]
 [2.547]
 [1.905]
 [1.905]
 [1.905]] [[1.153]
 [1.153]
 [1.153]
 [2.008]
 [1.153]
 [1.153]
 [1.153]]
line 256 mcts: sample exp_bonus 0.6093578287140706
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.956]
 [0.939]
 [0.956]
 [0.956]
 [0.956]
 [0.956]
 [0.956]] [[6.126]
 [5.524]
 [6.126]
 [6.126]
 [6.126]
 [6.036]
 [6.126]] [[2.246]
 [2.101]
 [2.246]
 [2.246]
 [2.246]
 [2.226]
 [2.246]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.134617945801811
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.433]
 [0.39 ]
 [0.435]
 [0.434]
 [0.436]
 [0.416]
 [0.426]] [[0.471]
 [1.05 ]
 [0.604]
 [0.732]
 [0.718]
 [0.647]
 [0.697]] [[0.433]
 [0.39 ]
 [0.435]
 [0.434]
 [0.436]
 [0.416]
 [0.426]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[1.03 ]
 [1.036]
 [1.03 ]
 [1.032]
 [1.03 ]
 [1.256]
 [1.029]] [[1.635]
 [1.525]
 [1.635]
 [1.682]
 [1.635]
 [1.702]
 [1.482]] [[0.769]
 [0.685]
 [0.769]
 [0.811]
 [0.769]
 [1.104]
 [0.642]]
siam score:  -0.7307448
line 256 mcts: sample exp_bonus 1.1677107938685825
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.071]
 [0.052]
 [0.079]
 [0.077]
 [0.084]
 [0.105]
 [0.112]] [[5.155]
 [4.101]
 [5.175]
 [5.395]
 [5.327]
 [5.22 ]
 [4.415]] [[ 0.356]
 [-0.372]
 [ 0.386]
 [ 0.527]
 [ 0.495]
 [ 0.467]
 [-0.047]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.586]
 [0.579]
 [0.628]
 [0.619]
 [0.648]
 [0.585]
 [0.563]] [[3.494]
 [3.276]
 [3.684]
 [3.818]
 [3.428]
 [3.54 ]
 [3.77 ]] [[1.178]
 [1.002]
 [1.385]
 [1.472]
 [1.223]
 [1.212]
 [1.352]]
Printing some Q and Qe and total Qs values:  [[0.398]
 [0.364]
 [0.39 ]
 [0.404]
 [0.403]
 [0.399]
 [0.407]] [[-1.519]
 [ 0.409]
 [-1.219]
 [-1.897]
 [-1.59 ]
 [-1.484]
 [-1.19 ]] [[0.398]
 [0.364]
 [0.39 ]
 [0.404]
 [0.403]
 [0.399]
 [0.407]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 4.570998054174394
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.1790868351894537
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.835]
 [0.835]
 [0.825]
 [0.859]
 [0.868]
 [0.867]
 [0.867]] [[5.577]
 [5.819]
 [4.523]
 [6.171]
 [5.105]
 [3.58 ]
 [8.831]] [[1.295]
 [1.373]
 [0.94 ]
 [1.512]
 [1.172]
 [0.672]
 [2.39 ]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.8782938342832465
siam score:  -0.73736376
Printing some Q and Qe and total Qs values:  [[0.877]
 [0.798]
 [0.881]
 [0.87 ]
 [0.853]
 [0.97 ]
 [0.87 ]] [[5.836]
 [5.477]
 [6.016]
 [5.906]
 [5.873]
 [5.416]
 [6.429]] [[2.059]
 [1.866]
 [2.12 ]
 [2.074]
 [2.047]
 [2.013]
 [2.243]]
Printing some Q and Qe and total Qs values:  [[0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.886]
 [0.876]] [[6.795]
 [6.795]
 [6.795]
 [6.795]
 [6.795]
 [6.936]
 [6.795]] [[2.352]
 [2.352]
 [2.352]
 [2.352]
 [2.352]
 [2.453]
 [2.352]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.829]
 [0.829]
 [0.829]
 [0.829]
 [0.829]
 [0.858]
 [0.829]] [[6.617]
 [6.617]
 [6.617]
 [6.617]
 [6.617]
 [6.728]
 [6.617]] [[2.014]
 [2.014]
 [2.014]
 [2.014]
 [2.014]
 [2.123]
 [2.014]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.673]
 [0.673]
 [0.665]
 [0.673]
 [0.673]
 [0.673]
 [0.673]] [[3.812]
 [3.812]
 [3.285]
 [3.812]
 [3.812]
 [3.812]
 [3.812]] [[2.066]
 [2.066]
 [1.523]
 [2.066]
 [2.066]
 [2.066]
 [2.066]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.504]] [[8.859]
 [8.859]
 [8.859]
 [8.859]
 [8.859]
 [8.859]
 [8.859]] [[1.852]
 [1.852]
 [1.852]
 [1.852]
 [1.852]
 [1.852]
 [1.852]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.406]
 [0.403]
 [0.403]
 [0.403]
 [0.403]
 [0.418]
 [0.403]] [[5.489]
 [5.086]
 [5.086]
 [5.086]
 [5.086]
 [5.283]
 [5.086]] [[1.285]
 [1.207]
 [1.207]
 [1.207]
 [1.207]
 [1.253]
 [1.207]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 4.554539974529436
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 4.5824740874703345
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.386]
 [0.45 ]
 [0.395]
 [0.413]
 [0.19 ]
 [0.383]
 [0.39 ]] [[-1.317]
 [-0.87 ]
 [-3.583]
 [-2.861]
 [ 0.092]
 [-3.818]
 [ 0.208]] [[0.386]
 [0.45 ]
 [0.395]
 [0.413]
 [0.19 ]
 [0.383]
 [0.39 ]]
siam score:  -0.7340039
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.24479794655828
line 256 mcts: sample exp_bonus 4.681719979962374
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.608]
 [0.622]
 [0.59 ]
 [0.602]
 [0.604]
 [0.602]
 [0.603]] [[0.344]
 [1.966]
 [1.06 ]
 [0.761]
 [0.882]
 [0.581]
 [0.706]] [[0.608]
 [0.622]
 [0.59 ]
 [0.602]
 [0.604]
 [0.602]
 [0.603]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.387]
 [0.347]
 [0.442]
 [0.4  ]
 [0.395]
 [0.387]
 [0.394]] [[3.33 ]
 [3.057]
 [4.795]
 [4.776]
 [4.872]
 [4.741]
 [5.009]] [[-0.186]
 [-0.356]
 [ 0.415]
 [ 0.323]
 [ 0.346]
 [ 0.287]
 [ 0.39 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.153]
 [0.238]
 [0.181]
 [0.089]
 [0.138]
 [0.131]
 [0.155]] [[1.605]
 [1.186]
 [1.307]
 [1.553]
 [2.311]
 [1.451]
 [1.5  ]] [[0.301]
 [0.192]
 [0.158]
 [0.14 ]
 [0.741]
 [0.154]
 [0.235]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.178]
 [0.786]
 [0.752]
 [0.785]
 [0.782]
 [0.73 ]
 [0.683]] [[3.909]
 [1.523]
 [1.313]
 [1.864]
 [2.057]
 [2.211]
 [1.887]] [[2.981]
 [0.997]
 [0.822]
 [1.21 ]
 [1.326]
 [1.357]
 [1.095]]
siam score:  -0.72810954
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
siam score:  -0.74936414
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.576]
 [0.596]] [[4.114]
 [4.114]
 [4.114]
 [4.114]
 [4.114]
 [4.156]
 [4.362]] [[1.635]
 [1.635]
 [1.635]
 [1.635]
 [1.635]
 [1.702]
 [1.877]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.39]
 [0.39]
 [0.39]
 [0.39]
 [0.39]
 [0.39]
 [0.39]] [[6.081]
 [6.081]
 [6.081]
 [6.081]
 [6.081]
 [6.081]
 [6.081]] [[1.413]
 [1.413]
 [1.413]
 [1.413]
 [1.413]
 [1.413]
 [1.413]]
line 256 mcts: sample exp_bonus 9.34756536415163
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.405]
 [0.403]
 [0.396]
 [0.397]
 [0.399]
 [0.389]
 [0.386]] [[-0.713]
 [-0.044]
 [-0.769]
 [-0.314]
 [-0.358]
 [-0.725]
 [-0.754]] [[0.405]
 [0.403]
 [0.396]
 [0.397]
 [0.399]
 [0.389]
 [0.386]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1700 1685
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7461913
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.054]
 [-0.054]
 [-0.054]
 [-0.042]
 [-0.054]
 [-0.054]
 [-0.054]] [[3.284]
 [3.284]
 [3.284]
 [4.602]
 [3.284]
 [3.284]
 [3.284]] [[-0.509]
 [-0.509]
 [-0.509]
 [-0.044]
 [-0.509]
 [-0.509]
 [-0.509]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.698]
 [0.871]
 [0.904]
 [0.889]
 [0.904]
 [0.901]
 [0.906]] [[4.168]
 [4.232]
 [4.303]
 [4.289]
 [4.348]
 [4.166]
 [4.333]] [[1.072]
 [1.406]
 [1.516]
 [1.48 ]
 [1.553]
 [1.4  ]
 [1.543]]
Printing some Q and Qe and total Qs values:  [[0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.898]] [[3.718]
 [3.718]
 [3.718]
 [3.718]
 [3.718]
 [3.718]
 [3.718]] [[1.272]
 [1.272]
 [1.272]
 [1.272]
 [1.272]
 [1.272]
 [1.272]]
siam score:  -0.7476076
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.531]
 [0.531]
 [0.531]
 [0.531]
 [0.58 ]
 [0.524]
 [0.531]] [[4.907]
 [4.907]
 [4.907]
 [4.907]
 [5.967]
 [4.312]
 [4.907]] [[1.358]
 [1.358]
 [1.358]
 [1.358]
 [1.927]
 [1.059]
 [1.358]]
siam score:  -0.74413073
Printing some Q and Qe and total Qs values:  [[0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.542]
 [0.548]] [[7.616]
 [7.616]
 [7.616]
 [7.616]
 [7.616]
 [7.791]
 [7.616]] [[1.742]
 [1.742]
 [1.742]
 [1.742]
 [1.742]
 [1.787]
 [1.742]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 3.966325412522416
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.877]
 [0.877]
 [0.877]
 [0.924]
 [0.877]
 [0.877]
 [0.882]] [[3.911]
 [3.911]
 [3.911]
 [3.637]
 [3.911]
 [3.911]
 [4.448]] [[2.155]
 [2.155]
 [2.155]
 [2.014]
 [2.155]
 [2.155]
 [2.532]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.743657
using explorer policy with actor:  1
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.039]
 [-0.039]
 [-0.039]
 [-0.039]
 [-0.137]
 [-0.039]
 [-0.039]] [[2.77]
 [2.77]
 [2.77]
 [2.77]
 [6.  ]
 [2.77]
 [2.77]] [[-0.261]
 [-0.261]
 [-0.261]
 [-0.261]
 [ 0.507]
 [-0.261]
 [-0.261]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.222]
 [0.222]
 [0.222]
 [0.222]
 [0.326]
 [0.222]
 [0.222]] [[5.593]
 [5.593]
 [5.593]
 [5.593]
 [5.509]
 [5.593]
 [5.593]] [[0.421]
 [0.421]
 [0.421]
 [0.421]
 [0.461]
 [0.421]
 [0.421]]
Printing some Q and Qe and total Qs values:  [[1.132]
 [0.957]
 [1.039]
 [0.998]
 [1.062]
 [1.005]
 [1.098]] [[2.33 ]
 [1.694]
 [1.89 ]
 [1.705]
 [1.613]
 [1.889]
 [1.555]] [[1.717]
 [0.837]
 [1.148]
 [0.907]
 [0.91 ]
 [1.098]
 [0.907]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.011]
 [-0.011]
 [-0.011]
 [-0.011]
 [ 0.046]
 [-0.011]
 [-0.011]] [[7.096]
 [7.096]
 [7.096]
 [7.096]
 [6.825]
 [7.096]
 [7.096]] [[0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.876]
 [0.934]
 [0.934]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.025]
 [-0.034]
 [-0.025]
 [-0.028]
 [-0.029]
 [-0.027]
 [-0.026]] [[5.28 ]
 [5.126]
 [5.577]
 [5.897]
 [6.247]
 [6.976]
 [5.456]] [[ 0.072]
 [-0.031]
 [ 0.249]
 [ 0.438]
 [ 0.646]
 [ 1.086]
 [ 0.176]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.442]
 [0.423]
 [0.447]
 [0.536]
 [0.476]
 [0.536]
 [0.536]] [[1.124]
 [2.536]
 [1.434]
 [1.746]
 [1.638]
 [1.746]
 [1.746]] [[0.442]
 [0.423]
 [0.447]
 [0.536]
 [0.476]
 [0.536]
 [0.536]]
line 256 mcts: sample exp_bonus 2.1826603059758938
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.9423641788049686
rdn beta is 0 so we're just using the maxi policy
UNIT TEST: sample policy line 217 mcts : [0.    0.959 0.02  0.    0.02  0.    0.   ]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.1682310108086
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.444]
 [0.518]
 [0.444]
 [0.539]
 [0.444]
 [0.444]
 [0.444]] [[4.914]
 [5.215]
 [4.914]
 [4.517]
 [4.914]
 [4.914]
 [4.914]] [[1.424]
 [1.689]
 [1.424]
 [1.261]
 [1.424]
 [1.424]
 [1.424]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.884]
 [0.825]
 [0.839]
 [0.858]
 [1.217]
 [0.813]
 [0.824]] [[1.839]
 [2.215]
 [2.778]
 [2.769]
 [1.83 ]
 [2.69 ]
 [2.614]] [[0.516]
 [0.525]
 [0.74 ]
 [0.775]
 [1.18 ]
 [0.66 ]
 [0.654]]
siam score:  -0.739637
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]] [[0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.406]] [[0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]
 [0.415]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Starting evaluation
line 256 mcts: sample exp_bonus 2.779968480857514
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.501]
 [0.312]
 [0.492]
 [0.424]
 [0.524]
 [0.492]
 [0.372]] [[2.62 ]
 [2.321]
 [1.803]
 [1.254]
 [3.037]
 [1.803]
 [1.631]] [[0.501]
 [0.312]
 [0.492]
 [0.424]
 [0.524]
 [0.492]
 [0.372]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.463]
 [0.46 ]
 [0.46 ]
 [0.461]
 [0.454]
 [0.456]
 [0.462]] [[-1.395]
 [-0.472]
 [-1.703]
 [-1.71 ]
 [-1.124]
 [-1.32 ]
 [-1.603]] [[0.463]
 [0.46 ]
 [0.46 ]
 [0.461]
 [0.454]
 [0.456]
 [0.462]]
line 256 mcts: sample exp_bonus 4.571756621535562
Printing some Q and Qe and total Qs values:  [[0.62 ]
 [0.607]
 [0.617]
 [0.618]
 [0.623]
 [0.617]
 [0.615]] [[2.036]
 [3.547]
 [1.664]
 [2.032]
 [2.313]
 [2.302]
 [2.223]] [[0.62 ]
 [0.607]
 [0.617]
 [0.618]
 [0.623]
 [0.617]
 [0.615]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]] [[2.038]
 [2.038]
 [2.038]
 [2.038]
 [2.038]
 [2.038]
 [2.038]] [[0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]
 [0.593]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]] [[2.122]
 [2.122]
 [2.122]
 [2.122]
 [2.122]
 [1.989]
 [2.122]] [[0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.043]
 [0.066]
 [0.043]
 [0.086]
 [0.043]
 [0.031]
 [0.043]] [[ 0.889]
 [ 1.728]
 [ 0.889]
 [ 0.109]
 [ 0.889]
 [-2.129]
 [ 0.889]] [[0.043]
 [0.066]
 [0.043]
 [0.086]
 [0.043]
 [0.031]
 [0.043]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.628]
 [0.573]
 [0.599]
 [0.607]
 [0.679]
 [0.602]
 [0.668]] [[2.141]
 [2.673]
 [2.5  ]
 [2.353]
 [2.122]
 [2.768]
 [3.96 ]] [[0.628]
 [0.573]
 [0.599]
 [0.607]
 [0.679]
 [0.602]
 [0.668]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]] [[2.264]
 [2.264]
 [2.264]
 [2.264]
 [2.264]
 [2.264]
 [2.264]] [[0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.679]
 [0.646]
 [0.674]
 [0.671]
 [0.696]
 [0.67 ]
 [0.667]] [[3.133]
 [3.108]
 [3.547]
 [3.567]
 [3.531]
 [3.475]
 [3.605]] [[1.351]
 [1.261]
 [1.756]
 [1.771]
 [1.784]
 [1.676]
 [1.801]]
Printing some Q and Qe and total Qs values:  [[0.672]
 [0.601]
 [0.63 ]
 [0.633]
 [0.648]
 [0.642]
 [0.623]] [[1.948]
 [3.152]
 [2.255]
 [1.995]
 [2.207]
 [2.005]
 [2.274]] [[0.672]
 [0.601]
 [0.63 ]
 [0.633]
 [0.648]
 [0.642]
 [0.623]]
line 256 mcts: sample exp_bonus 2.08697165275812
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
line 256 mcts: sample exp_bonus 2.1866761651474973
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.063]
 [0.063]
 [0.063]
 [0.063]
 [0.234]
 [0.063]
 [0.063]] [[-1.097]
 [-1.097]
 [-1.097]
 [-1.097]
 [-0.01 ]
 [-1.097]
 [-1.097]] [[0.063]
 [0.063]
 [0.063]
 [0.063]
 [0.234]
 [0.063]
 [0.063]]
Printing some Q and Qe and total Qs values:  [[0.284]
 [0.335]
 [0.335]
 [0.295]
 [0.347]
 [0.309]
 [0.291]] [[4.695]
 [4.545]
 [4.545]
 [4.704]
 [4.756]
 [5.468]
 [4.346]] [[1.135]
 [1.102]
 [1.102]
 [1.156]
 [1.265]
 [1.704]
 [0.903]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.873]
 [0.853]
 [0.869]
 [0.872]
 [0.874]
 [0.872]
 [0.87 ]] [[2.579]
 [4.392]
 [2.64 ]
 [2.553]
 [2.909]
 [2.818]
 [2.572]] [[1.482]
 [2.59 ]
 [1.514]
 [1.464]
 [1.694]
 [1.631]
 [1.473]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]] [[-3.155]
 [-3.155]
 [-3.155]
 [-3.155]
 [-3.155]
 [-3.155]
 [-3.155]] [[0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.646]
 [0.671]
 [0.646]
 [0.646]
 [0.646]
 [0.646]
 [0.646]] [[3.277]
 [3.863]
 [3.277]
 [3.277]
 [3.277]
 [3.277]
 [3.277]] [[1.213]
 [1.488]
 [1.213]
 [1.213]
 [1.213]
 [1.213]
 [1.213]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.854]
 [0.782]
 [0.854]
 [0.859]
 [0.871]
 [0.857]
 [0.854]] [[2.822]
 [2.661]
 [2.822]
 [2.073]
 [2.41 ]
 [2.261]
 [2.822]] [[0.996]
 [0.798]
 [0.996]
 [0.757]
 [0.893]
 [0.814]
 [0.996]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.865]
 [0.616]
 [0.677]
 [0.742]
 [0.765]
 [0.672]
 [0.58 ]] [[ 3.434]
 [ 1.644]
 [-1.742]
 [ 0.415]
 [ 2.435]
 [-1.69 ]
 [ 1.182]] [[2.106]
 [1.334]
 [0.16 ]
 [0.963]
 [1.696]
 [0.176]
 [1.15 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.734989
Printing some Q and Qe and total Qs values:  [[0.425]
 [0.41 ]
 [0.4  ]
 [0.4  ]
 [0.41 ]
 [0.4  ]
 [0.4  ]] [[-0.835]
 [-0.257]
 [-0.735]
 [-0.735]
 [-0.818]
 [-0.735]
 [-0.735]] [[0.425]
 [0.41 ]
 [0.4  ]
 [0.4  ]
 [0.41 ]
 [0.4  ]
 [0.4  ]]
in main func line 156:  1749
siam score:  -0.735573
Printing some Q and Qe and total Qs values:  [[0.827]
 [0.827]
 [0.827]
 [0.827]
 [0.827]
 [0.897]
 [0.827]] [[5.669]
 [5.669]
 [5.669]
 [5.669]
 [5.669]
 [6.693]
 [5.669]] [[1.874]
 [1.874]
 [1.874]
 [1.874]
 [1.874]
 [2.415]
 [1.874]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.33250114383981
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1750 1734
line 256 mcts: sample exp_bonus 4.351492200774767
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]] [[5.166]
 [5.166]
 [5.166]
 [5.166]
 [5.166]
 [5.166]
 [5.166]] [[5.13]
 [5.13]
 [5.13]
 [5.13]
 [5.13]
 [5.13]
 [5.13]]
Printing some Q and Qe and total Qs values:  [[0.909]
 [0.87 ]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]] [[3.076]
 [3.642]
 [3.076]
 [3.076]
 [3.076]
 [3.076]
 [3.076]] [[1.206]
 [1.487]
 [1.206]
 [1.206]
 [1.206]
 [1.206]
 [1.206]]
Printing some Q and Qe and total Qs values:  [[0.041]
 [0.039]
 [0.039]
 [0.039]
 [0.044]
 [0.042]
 [0.039]] [[-1.383]
 [-1.548]
 [-1.548]
 [-1.548]
 [-1.129]
 [-1.346]
 [-1.548]] [[0.041]
 [0.039]
 [0.039]
 [0.039]
 [0.044]
 [0.042]
 [0.039]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.059]
 [0.086]
 [0.076]
 [0.082]
 [0.336]
 [0.074]
 [0.083]] [[-1.306]
 [ 0.689]
 [-0.997]
 [-1.29 ]
 [-0.582]
 [-1.423]
 [-1.399]] [[0.059]
 [0.086]
 [0.076]
 [0.082]
 [0.336]
 [0.074]
 [0.083]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.106]
 [0.084]
 [0.106]
 [0.165]
 [0.231]
 [0.106]
 [0.106]] [[4.244]
 [3.54 ]
 [4.244]
 [4.1  ]
 [4.723]
 [4.244]
 [4.244]] [[ 0.402]
 [-0.112]
 [ 0.402]
 [ 0.423]
 [ 0.97 ]
 [ 0.402]
 [ 0.402]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.822]
 [0.822]
 [0.822]
 [0.822]
 [0.851]
 [0.821]
 [0.822]] [[3.501]
 [3.501]
 [3.501]
 [3.501]
 [3.582]
 [3.671]
 [3.501]] [[1.919]
 [1.919]
 [1.919]
 [1.919]
 [2.035]
 [2.074]
 [1.919]]
siam score:  -0.74169594
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.662]
 [0.662]
 [0.662]
 [0.662]
 [0.656]
 [0.654]
 [0.667]] [[3.509]
 [3.509]
 [3.509]
 [3.509]
 [3.439]
 [3.388]
 [3.565]] [[1.7  ]
 [1.7  ]
 [1.7  ]
 [1.7  ]
 [1.632]
 [1.586]
 [1.754]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.805]
 [0.871]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[0.614]
 [1.34 ]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]] [[2.263]
 [2.636]
 [2.263]
 [2.263]
 [2.263]
 [2.263]
 [2.263]]
Printing some Q and Qe and total Qs values:  [[0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.535]
 [0.519]
 [0.532]] [[3.474]
 [3.474]
 [3.474]
 [3.474]
 [3.413]
 [3.373]
 [3.54 ]] [[1.509]
 [1.509]
 [1.509]
 [1.509]
 [1.466]
 [1.411]
 [1.572]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.4819742198421877
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.559]
 [0.484]
 [0.527]
 [0.519]
 [0.546]
 [0.513]
 [0.526]] [[0.668]
 [1.288]
 [0.59 ]
 [0.759]
 [0.747]
 [0.77 ]
 [0.713]] [[0.199]
 [0.256]
 [0.108]
 [0.149]
 [0.199]
 [0.141]
 [0.147]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 5.364415645609014
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.902]
 [0.868]
 [0.89 ]
 [0.909]
 [0.917]
 [0.898]
 [0.89 ]] [[1.352]
 [2.348]
 [2.962]
 [1.408]
 [1.696]
 [1.493]
 [2.962]] [[1.96 ]
 [2.188]
 [2.403]
 [1.987]
 [2.084]
 [1.993]
 [2.403]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
in main func line 156:  1763
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.7456827049320136
1763 1748
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7344019
Printing some Q and Qe and total Qs values:  [[0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.734]
 [0.742]
 [0.754]] [[0.934]
 [0.934]
 [0.934]
 [0.934]
 [1.67 ]
 [1.568]
 [0.934]] [[0.748]
 [0.748]
 [0.748]
 [0.748]
 [1.385]
 [1.305]
 [0.748]]
Printing some Q and Qe and total Qs values:  [[0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]] [[2.729]
 [2.729]
 [2.729]
 [2.729]
 [2.729]
 [2.729]
 [2.729]] [[0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.413]
 [0.384]
 [0.398]
 [0.413]
 [0.413]
 [0.395]
 [0.413]] [[ 0.828]
 [ 1.784]
 [-0.542]
 [ 0.828]
 [ 0.828]
 [ 0.241]
 [ 0.828]] [[0.413]
 [0.384]
 [0.398]
 [0.413]
 [0.413]
 [0.395]
 [0.413]]
Printing some Q and Qe and total Qs values:  [[0.389]
 [0.397]
 [0.387]
 [0.39 ]
 [0.391]
 [0.386]
 [0.384]] [[-1.697]
 [-1.451]
 [-1.951]
 [-1.709]
 [-1.603]
 [-1.941]
 [-1.777]] [[0.389]
 [0.397]
 [0.387]
 [0.39 ]
 [0.391]
 [0.386]
 [0.384]]
1769 1748
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[1.146]
 [1.146]
 [1.146]
 [1.146]
 [1.256]
 [1.146]
 [1.146]] [[1.852]
 [1.852]
 [1.852]
 [1.852]
 [1.718]
 [1.852]
 [1.852]] [[1.029]
 [1.029]
 [1.029]
 [1.029]
 [1.205]
 [1.029]
 [1.029]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[1.021]
 [1.021]
 [1.021]
 [1.021]
 [1.26 ]
 [1.021]
 [1.021]] [[2.531]
 [2.531]
 [2.531]
 [2.531]
 [4.228]
 [2.531]
 [2.531]] [[0.964]
 [0.964]
 [0.964]
 [0.964]
 [2.009]
 [0.964]
 [0.964]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.19 ]
 [0.171]
 [0.186]
 [0.173]
 [0.185]
 [0.178]
 [0.187]] [[3.814]
 [4.183]
 [4.113]
 [4.125]
 [4.09 ]
 [4.378]
 [3.985]] [[-0.51 ]
 [-0.424]
 [-0.418]
 [-0.438]
 [-0.428]
 [-0.346]
 [-0.458]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.863]
 [0.864]
 [0.868]
 [0.875]
 [0.868]
 [0.866]
 [0.862]] [[2.   ]
 [3.183]
 [1.849]
 [2.658]
 [2.188]
 [2.033]
 [2.062]] [[1.023]
 [1.419]
 [0.983]
 [1.267]
 [1.095]
 [1.04 ]
 [1.042]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.935]
 [0.885]
 [0.923]
 [0.912]
 [0.92 ]
 [0.916]
 [0.918]] [[5.163]
 [4.809]
 [5.144]
 [5.081]
 [5.307]
 [5.096]
 [5.167]] [[2.103]
 [1.97 ]
 [2.089]
 [2.063]
 [2.129]
 [2.07 ]
 [2.091]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.73312044
from probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus -0.8497277514361259
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.926]
 [0.874]
 [0.926]
 [0.903]
 [0.926]
 [0.926]
 [0.926]] [[3.543]
 [4.279]
 [3.543]
 [4.696]
 [3.543]
 [3.543]
 [3.543]] [[3.003]
 [3.14 ]
 [3.003]
 [3.33 ]
 [3.003]
 [3.003]
 [3.003]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.744]
 [0.674]
 [0.674]
 [0.69 ]
 [0.784]
 [0.691]
 [0.692]] [[4.62 ]
 [4.154]
 [4.154]
 [4.541]
 [4.439]
 [4.52 ]
 [4.49 ]] [[1.518]
 [1.068]
 [1.068]
 [1.356]
 [1.477]
 [1.345]
 [1.328]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.339]
 [0.276]
 [0.335]
 [0.346]
 [0.328]
 [0.325]
 [0.332]] [[-0.876]
 [ 1.017]
 [-0.804]
 [-0.716]
 [-0.553]
 [-0.677]
 [-0.751]] [[0.339]
 [0.276]
 [0.335]
 [0.346]
 [0.328]
 [0.325]
 [0.332]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
UNIT TEST: sample policy line 217 mcts : [0.041 0.02  0.02  0.735 0.041 0.122 0.02 ]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.838]
 [0.835]
 [0.838]
 [0.838]
 [0.838]
 [0.846]
 [0.838]] [[4.419]
 [4.563]
 [4.419]
 [4.419]
 [4.419]
 [4.862]
 [4.419]] [[1.744]
 [1.834]
 [1.744]
 [1.744]
 [1.744]
 [2.056]
 [1.744]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.434357049342873
Printing some Q and Qe and total Qs values:  [[0.261]
 [0.254]
 [0.261]
 [0.263]
 [0.264]
 [0.255]
 [0.259]] [[-0.479]
 [ 0.385]
 [-0.209]
 [-0.503]
 [-0.699]
 [-1.255]
 [-0.458]] [[0.261]
 [0.254]
 [0.261]
 [0.263]
 [0.264]
 [0.255]
 [0.259]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.4787916963839844
1797 1764
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 5.1393139464584845
Printing some Q and Qe and total Qs values:  [[0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.898]
 [0.888]
 [0.888]] [[2.852]
 [2.852]
 [2.852]
 [2.852]
 [2.863]
 [2.852]
 [2.852]] [[2.661]
 [2.661]
 [2.661]
 [2.661]
 [2.684]
 [2.661]
 [2.661]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.793]
 [0.689]
 [0.806]
 [0.723]
 [0.754]
 [0.751]
 [0.749]] [[3.854]
 [3.779]
 [3.651]
 [3.891]
 [3.813]
 [3.882]
 [3.626]] [[2.565]
 [2.282]
 [2.387]
 [2.461]
 [2.446]
 [2.509]
 [2.249]]
Printing some Q and Qe and total Qs values:  [[0.754]
 [0.786]
 [0.754]
 [0.785]
 [0.792]
 [0.796]
 [0.791]] [[3.735]
 [3.076]
 [3.735]
 [3.074]
 [3.157]
 [3.196]
 [3.318]] [[1.52 ]
 [1.089]
 [1.52 ]
 [1.087]
 [1.157]
 [1.19 ]
 [1.271]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7187194
siam score:  -0.7186682
first move QE:  1.1590262690478403
using explorer policy with actor:  1
siam score:  -0.7161116
siam score:  -0.7126734
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.1577733643537942
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [1.126]
 [0.84 ]] [[2.362]
 [2.362]
 [2.362]
 [2.362]
 [2.362]
 [2.751]
 [2.362]] [[0.898]
 [0.898]
 [0.898]
 [0.898]
 [0.898]
 [1.6  ]
 [0.898]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.349]
 [0.355]
 [0.356]
 [0.349]
 [0.351]
 [0.351]
 [0.35 ]] [[-1.356]
 [-0.847]
 [-1.295]
 [-1.212]
 [-1.456]
 [-1.418]
 [-1.31 ]] [[0.349]
 [0.355]
 [0.356]
 [0.349]
 [0.351]
 [0.351]
 [0.35 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.536]
 [0.596]
 [0.536]
 [0.562]
 [0.536]
 [0.536]
 [0.536]] [[4.512]
 [7.466]
 [4.512]
 [5.71 ]
 [4.512]
 [4.512]
 [4.512]] [[0.538]
 [1.645]
 [0.538]
 [0.992]
 [0.538]
 [0.538]
 [0.538]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.626]] [[2.35 ]
 [2.35 ]
 [2.35 ]
 [2.35 ]
 [2.35 ]
 [2.35 ]
 [2.823]] [[0.105]
 [0.105]
 [0.105]
 [0.105]
 [0.105]
 [0.105]
 [0.432]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.7037361
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
in main func line 156:  1818
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.654]
 [0.778]
 [0.778]
 [0.688]
 [0.778]
 [0.68 ]
 [0.778]] [[1.696]
 [3.061]
 [3.061]
 [1.565]
 [3.061]
 [1.45 ]
 [3.061]] [[1.346]
 [2.051]
 [2.051]
 [1.371]
 [2.051]
 [1.317]
 [2.051]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.531]
 [0.528]
 [0.531]
 [0.531]
 [0.599]
 [0.531]
 [0.531]] [[0.167]
 [1.672]
 [0.167]
 [0.167]
 [0.601]
 [0.167]
 [0.167]] [[0.531]
 [0.528]
 [0.531]
 [0.531]
 [0.599]
 [0.531]
 [0.531]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.597]
 [0.597]
 [0.597]
 [0.601]
 [0.597]
 [0.622]
 [0.597]] [[4.298]
 [4.298]
 [4.298]
 [4.657]
 [4.298]
 [4.833]
 [4.298]] [[1.294]
 [1.294]
 [1.294]
 [1.422]
 [1.294]
 [1.523]
 [1.294]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.408]
 [0.406]
 [0.415]
 [0.403]
 [0.406]
 [0.407]
 [0.407]] [[-2.308]
 [-1.769]
 [-2.273]
 [-2.283]
 [-2.026]
 [-2.201]
 [-2.019]] [[0.408]
 [0.406]
 [0.415]
 [0.403]
 [0.406]
 [0.407]
 [0.407]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]] [[2.309]
 [2.309]
 [2.309]
 [2.309]
 [2.309]
 [2.309]
 [2.309]] [[1.998]
 [1.998]
 [1.998]
 [1.998]
 [1.998]
 [1.998]
 [1.998]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.811]
 [0.826]
 [0.827]
 [0.816]
 [0.839]
 [0.811]
 [0.82 ]] [[1.227]
 [1.757]
 [1.209]
 [1.392]
 [1.377]
 [1.247]
 [1.317]] [[0.959]
 [1.164]
 [0.983]
 [1.024]
 [1.065]
 [0.965]
 [1.007]]
siam score:  -0.7059089
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.672]
 [0.65 ]
 [0.677]
 [0.661]
 [0.674]
 [0.688]
 [0.702]] [[4.743]
 [4.625]
 [4.811]
 [5.004]
 [4.911]
 [4.968]
 [4.92 ]] [[0.779]
 [0.696]
 [0.812]
 [0.843]
 [0.839]
 [0.885]
 [0.898]]
siam score:  -0.70286804
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.445]
 [0.413]
 [0.469]
 [0.429]
 [0.59 ]
 [0.492]
 [0.434]] [[0.759]
 [1.894]
 [0.78 ]
 [1.012]
 [1.237]
 [0.996]
 [0.94 ]] [[0.445]
 [0.413]
 [0.469]
 [0.429]
 [0.59 ]
 [0.492]
 [0.434]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.879]
 [0.872]
 [0.879]
 [0.879]
 [0.879]
 [0.879]
 [0.879]] [[1.542]
 [2.626]
 [1.542]
 [1.542]
 [1.542]
 [1.542]
 [1.542]] [[1.55 ]
 [2.588]
 [1.55 ]
 [1.55 ]
 [1.55 ]
 [1.55 ]
 [1.55 ]]
siam score:  -0.7063417
first move QE:  1.1523568698738769
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.714]] [[4.055]
 [4.055]
 [4.055]
 [4.055]
 [4.055]
 [4.055]
 [4.282]] [[1.592]
 [1.592]
 [1.592]
 [1.592]
 [1.592]
 [1.592]
 [1.784]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
siam score:  -0.6996716
Printing some Q and Qe and total Qs values:  [[-0.01 ]
 [ 0.036]
 [-0.01 ]
 [-0.01 ]
 [-0.005]
 [-0.01 ]
 [-0.01 ]] [[3.025]
 [4.181]
 [3.025]
 [3.025]
 [3.689]
 [3.025]
 [3.025]] [[0.071]
 [0.946]
 [0.071]
 [0.071]
 [0.544]
 [0.071]
 [0.071]]
Printing some Q and Qe and total Qs values:  [[0.923]
 [0.923]
 [0.923]
 [0.936]
 [0.945]
 [0.946]
 [0.933]] [[3.618]
 [3.618]
 [3.618]
 [3.332]
 [3.485]
 [3.398]
 [3.334]] [[2.521]
 [2.521]
 [2.521]
 [2.217]
 [2.407]
 [2.31 ]
 [2.215]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.844]
 [0.844]
 [0.844]
 [0.76 ]
 [0.844]
 [0.844]
 [0.844]] [[2.981]
 [2.981]
 [2.981]
 [3.699]
 [2.981]
 [2.981]
 [2.981]] [[1.339]
 [1.339]
 [1.339]
 [2.061]
 [1.339]
 [1.339]
 [1.339]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]] [[1.15 ]
 [1.135]
 [1.15 ]
 [1.112]
 [1.135]
 [1.15 ]
 [1.135]] [[2.934]
 [2.919]
 [2.934]
 [2.896]
 [2.919]
 [2.934]
 [2.919]]
Printing some Q and Qe and total Qs values:  [[0.169]
 [0.172]
 [0.164]
 [0.156]
 [0.162]
 [0.162]
 [0.153]] [[-1.77 ]
 [-1.89 ]
 [-1.863]
 [-1.886]
 [-2.114]
 [-1.846]
 [-1.768]] [[0.169]
 [0.172]
 [0.164]
 [0.156]
 [0.162]
 [0.162]
 [0.153]]
Printing some Q and Qe and total Qs values:  [[0.611]
 [0.595]
 [0.637]
 [0.598]
 [0.73 ]
 [0.622]
 [0.54 ]] [[1.814]
 [2.256]
 [1.255]
 [1.556]
 [1.441]
 [1.75 ]
 [1.86 ]] [[0.611]
 [0.595]
 [0.637]
 [0.598]
 [0.73 ]
 [0.622]
 [0.54 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6931688
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.595]
 [0.595]
 [0.595]
 [0.595]
 [0.595]
 [0.595]
 [0.595]] [[4.185]
 [4.185]
 [4.185]
 [4.185]
 [4.185]
 [4.185]
 [4.185]] [[1.182]
 [1.182]
 [1.182]
 [1.182]
 [1.182]
 [1.182]
 [1.182]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.70638365
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.97027005376112
Printing some Q and Qe and total Qs values:  [[0.066]
 [0.085]
 [0.176]
 [0.138]
 [0.114]
 [0.214]
 [0.173]] [[4.647]
 [4.399]
 [3.651]
 [4.504]
 [4.417]
 [4.962]
 [3.659]] [[ 0.089]
 [-0.033]
 [-0.34 ]
 [ 0.137]
 [ 0.034]
 [ 0.581]
 [-0.34 ]]
in main func line 156:  1844
Printing some Q and Qe and total Qs values:  [[-0.001]
 [-0.021]
 [-0.   ]
 [ 0.002]
 [-0.   ]
 [ 0.075]
 [ 0.042]] [[4.173]
 [3.755]
 [3.943]
 [4.113]
 [4.084]
 [3.854]
 [3.528]] [[-0.306]
 [-0.624]
 [-0.458]
 [-0.341]
 [-0.364]
 [-0.368]
 [-0.649]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.642]
 [0.642]
 [0.614]
 [0.642]
 [0.642]
 [0.627]] [[3.948]
 [3.638]
 [3.638]
 [3.842]
 [3.638]
 [3.638]
 [4.09 ]] [[1.291]
 [1.002]
 [1.002]
 [1.149]
 [1.002]
 [1.002]
 [1.423]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.1468007714194508
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.824]
 [0.845]
 [0.845]] [[2.27 ]
 [2.27 ]
 [2.27 ]
 [2.27 ]
 [4.243]
 [2.27 ]
 [2.27 ]] [[1.671]
 [1.671]
 [1.671]
 [1.671]
 [2.387]
 [1.671]
 [1.671]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.505]
 [0.292]
 [0.499]
 [0.498]
 [0.5  ]
 [0.493]
 [0.494]] [[0.247]
 [1.822]
 [0.398]
 [0.595]
 [0.747]
 [0.454]
 [0.682]] [[0.505]
 [0.292]
 [0.499]
 [0.498]
 [0.5  ]
 [0.493]
 [0.494]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 4.286205749213485
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[1.38]
 [1.38]
 [1.38]
 [1.38]
 [1.38]
 [1.38]
 [1.38]] [[1.145]
 [1.145]
 [1.145]
 [1.145]
 [1.102]
 [1.145]
 [1.145]] [[2.705]
 [2.705]
 [2.705]
 [2.705]
 [2.691]
 [2.705]
 [2.705]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.67 ]
 [0.67 ]
 [0.67 ]
 [0.614]
 [0.722]
 [0.67 ]
 [0.659]] [[3.877]
 [3.877]
 [3.877]
 [4.136]
 [3.427]
 [3.877]
 [3.995]] [[1.842]
 [1.842]
 [1.842]
 [2.019]
 [1.466]
 [1.842]
 [1.945]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
1858 1826
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.975]
 [0.975]
 [0.975]
 [0.975]
 [1.119]
 [0.975]
 [0.975]] [[2.583]
 [2.583]
 [2.583]
 [2.583]
 [7.904]
 [2.583]
 [2.583]] [[0.967]
 [0.967]
 [0.967]
 [0.967]
 [2.189]
 [0.967]
 [0.967]]
siam score:  -0.71316206
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.85 ]
 [0.834]
 [0.85 ]
 [0.865]
 [0.851]
 [0.857]
 [0.867]] [[3.701]
 [3.827]
 [3.701]
 [4.043]
 [4.79 ]
 [4.594]
 [3.705]] [[2.344]
 [2.355]
 [2.344]
 [2.49 ]
 [2.71 ]
 [2.657]
 [2.379]]
Printing some Q and Qe and total Qs values:  [[0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.677]
 [0.691]
 [0.677]] [[4.833]
 [4.833]
 [4.833]
 [4.833]
 [4.833]
 [4.683]
 [4.833]] [[1.844]
 [1.844]
 [1.844]
 [1.844]
 [1.844]
 [1.781]
 [1.844]]
Printing some Q and Qe and total Qs values:  [[0.146]
 [0.146]
 [0.146]
 [0.146]
 [0.135]
 [0.146]
 [0.146]] [[4.147]
 [4.147]
 [4.147]
 [4.147]
 [5.192]
 [4.147]
 [4.147]] [[0.761]
 [0.761]
 [0.761]
 [0.761]
 [1.474]
 [0.761]
 [0.761]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.522]
 [0.544]
 [0.522]
 [0.522]
 [0.522]
 [0.514]
 [0.522]] [[4.337]
 [4.949]
 [4.337]
 [4.337]
 [4.337]
 [4.304]
 [4.337]] [[1.38 ]
 [1.764]
 [1.38 ]
 [1.38 ]
 [1.38 ]
 [1.35 ]
 [1.38 ]]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.304]
 [0.34 ]
 [0.311]
 [0.314]
 [0.312]
 [0.354]
 [0.314]] [[4.562]
 [4.447]
 [4.599]
 [4.736]
 [4.762]
 [5.166]
 [5.356]] [[0.538]
 [0.515]
 [0.568]
 [0.648]
 [0.66 ]
 [0.934]
 [0.996]]
line 256 mcts: sample exp_bonus 5.9985723470952985
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.433]
 [0.438]
 [0.455]
 [0.459]
 [0.447]
 [0.433]
 [0.449]] [[4.823]
 [4.893]
 [5.297]
 [5.452]
 [5.218]
 [5.161]
 [5.005]] [[1.029]
 [1.071]
 [1.304]
 [1.39 ]
 [1.253]
 [1.209]
 [1.143]]
Printing some Q and Qe and total Qs values:  [[0.278]
 [0.278]
 [0.278]
 [0.278]
 [0.278]
 [0.262]
 [0.278]] [[5.542]
 [5.542]
 [5.542]
 [5.542]
 [5.542]
 [4.873]
 [5.542]] [[1.188]
 [1.188]
 [1.188]
 [1.188]
 [1.188]
 [0.731]
 [1.188]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 5.352052196573062
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.043]
 [0.051]
 [0.053]
 [0.054]
 [0.054]
 [0.05 ]
 [0.05 ]] [[3.637]
 [4.266]
 [3.233]
 [3.302]
 [3.328]
 [3.544]
 [3.234]] [[ 0.126]
 [ 0.576]
 [-0.142]
 [-0.092]
 [-0.074]
 [ 0.071]
 [-0.146]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.788]
 [0.477]
 [0.477]] [[3.834]
 [3.834]
 [3.834]
 [3.834]
 [3.564]
 [3.834]
 [3.834]] [[0.982]
 [0.982]
 [0.982]
 [0.982]
 [1.514]
 [0.982]
 [0.982]]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1871 1833
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.399]
 [0.399]
 [0.399]
 [0.399]
 [0.394]
 [0.399]
 [0.399]] [[4.114]
 [4.114]
 [4.114]
 [4.114]
 [3.907]
 [4.114]
 [4.114]] [[1.849]
 [1.849]
 [1.849]
 [1.849]
 [1.647]
 [1.849]
 [1.849]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.127]
 [0.127]
 [0.127]
 [0.127]
 [0.222]
 [0.127]
 [0.127]] [[5.542]
 [5.542]
 [5.542]
 [5.542]
 [7.882]
 [5.542]
 [5.542]] [[0.424]
 [0.424]
 [0.424]
 [0.424]
 [1.395]
 [0.424]
 [0.424]]
Printing some Q and Qe and total Qs values:  [[0.392]
 [0.372]
 [0.386]
 [0.396]
 [0.398]
 [0.402]
 [0.4  ]] [[4.649]
 [4.787]
 [6.05 ]
 [4.628]
 [4.585]
 [4.852]
 [4.737]] [[1.36 ]
 [1.401]
 [1.945]
 [1.355]
 [1.338]
 [1.453]
 [1.404]]
Printing some Q and Qe and total Qs values:  [[0.106]
 [0.106]
 [0.106]
 [0.106]
 [0.135]
 [0.106]
 [0.106]] [[4.755]
 [4.755]
 [4.755]
 [4.755]
 [4.708]
 [4.755]
 [4.755]] [[0.048]
 [0.048]
 [0.048]
 [0.048]
 [0.092]
 [0.048]
 [0.048]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.845]
 [0.832]
 [0.86 ]
 [0.871]
 [0.873]
 [0.858]
 [0.859]] [[2.823]
 [3.232]
 [2.926]
 [3.077]
 [3.021]
 [3.069]
 [3.113]] [[1.804]
 [2.132]
 [1.908]
 [2.051]
 [2.006]
 [2.027]
 [2.065]]
line 256 mcts: sample exp_bonus 9.762856766812106
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.001]
 [-0.001]
 [-0.001]
 [-0.003]
 [-0.001]
 [-0.001]
 [-0.001]] [[5.395]
 [5.395]
 [5.395]
 [5.806]
 [5.395]
 [5.395]
 [5.395]] [[-0.006]
 [-0.006]
 [-0.006]
 [ 0.127]
 [-0.006]
 [-0.006]
 [-0.006]]
Printing some Q and Qe and total Qs values:  [[0.011]
 [0.011]
 [0.011]
 [0.011]
 [0.381]
 [0.011]
 [0.011]] [[4.767]
 [4.767]
 [4.767]
 [4.767]
 [6.899]
 [4.767]
 [4.767]] [[0.144]
 [0.144]
 [0.144]
 [0.144]
 [1.13 ]
 [0.144]
 [0.144]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.784]
 [0.859]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]] [[2.016]
 [3.059]
 [2.016]
 [2.016]
 [2.016]
 [2.016]
 [2.016]] [[1.452]
 [1.869]
 [1.452]
 [1.452]
 [1.452]
 [1.452]
 [1.452]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.517]
 [0.512]
 [0.518]
 [0.519]
 [0.562]
 [0.518]
 [0.524]] [[2.849]
 [3.066]
 [2.671]
 [2.945]
 [2.44 ]
 [2.681]
 [2.861]] [[0.517]
 [0.512]
 [0.518]
 [0.519]
 [0.562]
 [0.518]
 [0.524]]
Printing some Q and Qe and total Qs values:  [[0.52 ]
 [0.523]
 [0.52 ]
 [0.52 ]
 [0.614]
 [0.504]
 [0.52 ]] [[2.873]
 [2.903]
 [2.873]
 [2.873]
 [2.009]
 [2.202]
 [2.873]] [[0.52 ]
 [0.523]
 [0.52 ]
 [0.52 ]
 [0.614]
 [0.504]
 [0.52 ]]
Printing some Q and Qe and total Qs values:  [[0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.654]] [[3.737]
 [3.737]
 [3.737]
 [3.737]
 [3.737]
 [3.737]
 [3.285]] [[0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.556]
 [0.654]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]] [[1.758]
 [1.758]
 [1.758]
 [1.758]
 [1.758]
 [1.758]
 [1.758]] [[0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.485]
 [0.45 ]
 [0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.485]] [[3.555]
 [3.874]
 [3.555]
 [3.381]
 [3.555]
 [3.555]
 [3.555]] [[0.485]
 [0.45 ]
 [0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.485]]
Printing some Q and Qe and total Qs values:  [[0.606]
 [0.583]
 [0.588]
 [0.598]
 [0.644]
 [0.592]
 [0.593]] [[3.191]
 [3.312]
 [3.332]
 [3.06 ]
 [3.267]
 [3.573]
 [3.7  ]] [[0.606]
 [0.583]
 [0.588]
 [0.598]
 [0.644]
 [0.592]
 [0.593]]
Printing some Q and Qe and total Qs values:  [[0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.748]
 [0.634]
 [0.634]] [[2.949]
 [2.949]
 [2.949]
 [2.949]
 [1.492]
 [2.949]
 [2.949]] [[0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.748]
 [0.634]
 [0.634]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.601]
 [0.601]
 [0.604]
 [0.744]
 [0.601]
 [0.601]] [[3.028]
 [3.028]
 [3.028]
 [2.916]
 [1.218]
 [3.028]
 [3.028]] [[0.601]
 [0.601]
 [0.601]
 [0.604]
 [0.744]
 [0.601]
 [0.601]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.353]
 [0.317]
 [0.353]
 [0.362]
 [0.359]
 [0.358]
 [0.347]] [[6.023]
 [5.939]
 [6.144]
 [6.188]
 [5.874]
 [6.187]
 [6.308]] [[1.334]
 [1.25 ]
 [1.4  ]
 [1.434]
 [1.26 ]
 [1.429]
 [1.483]]
siam score:  -0.71670175
Printing some Q and Qe and total Qs values:  [[0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.709]
 [0.615]
 [0.615]] [[2.933]
 [2.933]
 [2.933]
 [2.933]
 [2.872]
 [2.933]
 [2.933]] [[0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.709]
 [0.615]
 [0.615]]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]] [[3.026]
 [3.026]
 [3.026]
 [3.026]
 [3.026]
 [3.026]
 [3.026]] [[0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.543]
 [0.52 ]
 [0.526]
 [0.535]
 [0.707]
 [0.534]
 [0.531]] [[3.267]
 [3.47 ]
 [3.33 ]
 [3.322]
 [2.22 ]
 [3.518]
 [3.713]] [[0.543]
 [0.52 ]
 [0.526]
 [0.535]
 [0.707]
 [0.534]
 [0.531]]
line 256 mcts: sample exp_bonus 5.5386624051796876
Printing some Q and Qe and total Qs values:  [[0.523]
 [0.516]
 [0.528]
 [0.525]
 [0.801]
 [0.542]
 [0.531]] [[3.487]
 [3.159]
 [2.863]
 [3.33 ]
 [2.03 ]
 [3.222]
 [3.579]] [[0.523]
 [0.516]
 [0.528]
 [0.525]
 [0.801]
 [0.542]
 [0.531]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.785]
 [0.785]
 [0.785]
 [0.811]
 [0.89 ]
 [0.812]
 [0.812]] [[1.953]
 [1.953]
 [1.953]
 [1.869]
 [1.599]
 [1.84 ]
 [1.933]] [[0.785]
 [0.785]
 [0.785]
 [0.811]
 [0.89 ]
 [0.812]
 [0.812]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.605]
 [0.574]
 [0.616]
 [0.623]
 [0.628]
 [0.612]
 [0.611]] [[3.077]
 [2.933]
 [2.638]
 [2.958]
 [3.113]
 [3.259]
 [4.227]] [[0.605]
 [0.574]
 [0.616]
 [0.623]
 [0.628]
 [0.612]
 [0.611]]
Printing some Q and Qe and total Qs values:  [[0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.854]
 [0.816]
 [0.816]] [[1.828]
 [1.828]
 [1.828]
 [1.828]
 [1.781]
 [1.828]
 [1.828]] [[0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.854]
 [0.816]
 [0.816]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.591]
 [0.591]
 [0.593]
 [0.591]
 [0.591]
 [0.591]] [[3.334]
 [3.334]
 [3.334]
 [3.452]
 [3.334]
 [3.334]
 [3.334]] [[0.591]
 [0.591]
 [0.591]
 [0.593]
 [0.591]
 [0.591]
 [0.591]]
Printing some Q and Qe and total Qs values:  [[0.546]
 [0.546]
 [0.546]
 [0.683]
 [0.844]
 [0.642]
 [0.658]] [[3.896]
 [3.896]
 [3.896]
 [2.515]
 [1.502]
 [2.338]
 [2.425]] [[0.546]
 [0.546]
 [0.546]
 [0.683]
 [0.844]
 [0.642]
 [0.658]]
Printing some Q and Qe and total Qs values:  [[0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]] [[2.949]
 [2.949]
 [2.949]
 [2.949]
 [2.949]
 [2.949]
 [2.949]] [[0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.1337262205060643
Printing some Q and Qe and total Qs values:  [[0.518]
 [0.505]
 [0.517]
 [0.515]
 [0.728]
 [0.525]
 [0.518]] [[3.044]
 [2.978]
 [2.826]
 [3.151]
 [2.276]
 [3.491]
 [3.513]] [[0.518]
 [0.505]
 [0.517]
 [0.515]
 [0.728]
 [0.525]
 [0.518]]
Printing some Q and Qe and total Qs values:  [[0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]] [[1.526]
 [1.526]
 [1.526]
 [1.526]
 [1.526]
 [1.526]
 [1.526]] [[0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]]
Printing some Q and Qe and total Qs values:  [[0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.805]
 [0.589]
 [0.589]] [[3.299]
 [3.299]
 [3.299]
 [3.299]
 [1.939]
 [3.299]
 [3.299]] [[0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.805]
 [0.589]
 [0.589]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.591]
 [0.619]
 [0.66 ]
 [0.642]
 [0.624]
 [0.613]] [[2.716]
 [2.357]
 [2.236]
 [2.464]
 [3.017]
 [2.919]
 [3.138]] [[0.614]
 [0.591]
 [0.619]
 [0.66 ]
 [0.642]
 [0.624]
 [0.613]]
Printing some Q and Qe and total Qs values:  [[0.529]
 [0.529]
 [0.529]
 [0.529]
 [0.529]
 [0.529]
 [0.529]] [[2.774]
 [2.774]
 [2.774]
 [2.774]
 [2.774]
 [2.774]
 [2.774]] [[0.529]
 [0.529]
 [0.529]
 [0.529]
 [0.529]
 [0.529]
 [0.529]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.53 ]
 [0.511]
 [0.533]
 [0.534]
 [0.675]
 [0.539]
 [0.53 ]] [[2.826]
 [2.513]
 [2.535]
 [2.936]
 [2.069]
 [3.051]
 [3.29 ]] [[0.53 ]
 [0.511]
 [0.533]
 [0.534]
 [0.675]
 [0.539]
 [0.53 ]]
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.728]
 [0.617]
 [0.617]] [[2.954]
 [2.954]
 [2.954]
 [2.954]
 [1.86 ]
 [2.954]
 [2.954]] [[0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.728]
 [0.617]
 [0.617]]
Printing some Q and Qe and total Qs values:  [[0.598]
 [0.588]
 [0.602]
 [0.603]
 [0.754]
 [0.604]
 [0.599]] [[2.912]
 [2.504]
 [2.588]
 [2.982]
 [2.032]
 [3.047]
 [3.222]] [[0.598]
 [0.588]
 [0.602]
 [0.603]
 [0.754]
 [0.604]
 [0.599]]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 3.043111399788814
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.603]
 [0.603]
 [0.603]
 [0.603]
 [0.7  ]
 [0.603]
 [0.603]] [[2.711]
 [2.711]
 [2.711]
 [2.711]
 [2.276]
 [2.711]
 [2.711]] [[0.603]
 [0.603]
 [0.603]
 [0.603]
 [0.7  ]
 [0.603]
 [0.603]]
Printing some Q and Qe and total Qs values:  [[0.695]
 [0.567]
 [0.604]
 [0.7  ]
 [0.723]
 [0.7  ]
 [0.651]] [[1.642]
 [1.737]
 [1.853]
 [2.213]
 [3.055]
 [2.127]
 [2.54 ]] [[1.086]
 [0.862]
 [0.976]
 [1.287]
 [1.615]
 [1.258]
 [1.298]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.667]
 [0.667]
 [0.667]
 [0.666]
 [0.743]
 [0.667]
 [0.667]] [[2.884]
 [2.884]
 [2.884]
 [2.827]
 [2.404]
 [2.884]
 [2.884]] [[0.667]
 [0.667]
 [0.667]
 [0.666]
 [0.743]
 [0.667]
 [0.667]]
Printing some Q and Qe and total Qs values:  [[0.622]
 [0.928]
 [0.622]
 [0.622]
 [0.767]
 [0.622]
 [0.622]] [[2.777]
 [1.76 ]
 [2.777]
 [2.777]
 [2.68 ]
 [2.777]
 [2.777]] [[0.622]
 [0.928]
 [0.622]
 [0.622]
 [0.767]
 [0.622]
 [0.622]]
1884 1849
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.758]
 [0.607]
 [0.607]] [[2.948]
 [2.948]
 [2.948]
 [2.948]
 [1.732]
 [2.948]
 [2.948]] [[0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.758]
 [0.607]
 [0.607]]
Printing some Q and Qe and total Qs values:  [[0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.89 ]
 [0.773]
 [0.773]] [[2.04 ]
 [2.04 ]
 [2.04 ]
 [2.04 ]
 [1.879]
 [2.04 ]
 [2.04 ]] [[0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.89 ]
 [0.773]
 [0.773]]
Printing some Q and Qe and total Qs values:  [[0.64]
 [0.64]
 [0.64]
 [0.64]
 [0.64]
 [0.64]
 [0.64]] [[2.339]
 [2.339]
 [2.339]
 [2.339]
 [2.339]
 [2.339]
 [2.339]] [[0.64]
 [0.64]
 [0.64]
 [0.64]
 [0.64]
 [0.64]
 [0.64]]
first move QE:  1.1408952661210308
line 256 mcts: sample exp_bonus 2.131277845703555
Printing some Q and Qe and total Qs values:  [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.915]
 [0.743]
 [0.743]] [[2.451]
 [2.451]
 [2.451]
 [2.451]
 [2.428]
 [2.451]
 [2.451]] [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.915]
 [0.743]
 [0.743]]
Printing some Q and Qe and total Qs values:  [[0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.204]] [[4.254]
 [4.254]
 [4.254]
 [4.254]
 [4.254]
 [4.254]
 [6.117]] [[0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [1.366]]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.89 ]
 [0.773]
 [0.773]] [[2.262]
 [2.262]
 [2.262]
 [2.262]
 [1.861]
 [2.262]
 [2.262]] [[0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.89 ]
 [0.773]
 [0.773]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 2.4058895413705343
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.765]
 [0.798]
 [0.769]
 [0.75 ]
 [0.856]
 [0.733]
 [0.721]] [[2.972]
 [2.507]
 [2.831]
 [2.988]
 [3.853]
 [3.832]
 [3.468]] [[1.091]
 [0.709]
 [0.966]
 [1.085]
 [2.028]
 [1.839]
 [1.487]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.78 ]
 [0.862]
 [0.78 ]
 [0.78 ]
 [0.838]
 [0.78 ]
 [0.78 ]] [[1.63 ]
 [2.697]
 [1.63 ]
 [1.63 ]
 [1.287]
 [1.63 ]
 [1.63 ]] [[2.159]
 [2.68 ]
 [2.159]
 [2.159]
 [2.161]
 [2.159]
 [2.159]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.747]
 [0.734]
 [0.747]
 [0.747]
 [0.889]
 [0.747]
 [0.747]] [[1.844]
 [2.056]
 [1.844]
 [1.844]
 [1.814]
 [1.844]
 [1.844]] [[0.747]
 [0.734]
 [0.747]
 [0.747]
 [0.889]
 [0.747]
 [0.747]]
Printing some Q and Qe and total Qs values:  [[0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.87 ]
 [0.629]
 [0.629]] [[2.628]
 [2.628]
 [2.628]
 [2.628]
 [1.665]
 [2.628]
 [2.628]] [[0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.87 ]
 [0.629]
 [0.629]]
Printing some Q and Qe and total Qs values:  [[0.665]
 [0.54 ]
 [0.665]
 [0.545]
 [0.696]
 [0.665]
 [0.665]] [[2.035]
 [2.62 ]
 [2.035]
 [2.43 ]
 [2.086]
 [2.035]
 [2.035]] [[0.665]
 [0.54 ]
 [0.665]
 [0.545]
 [0.696]
 [0.665]
 [0.665]]
Printing some Q and Qe and total Qs values:  [[0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.624]
 [0.592]
 [0.585]] [[3.164]
 [3.164]
 [3.164]
 [3.164]
 [3.596]
 [3.438]
 [3.164]] [[0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.624]
 [0.592]
 [0.585]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.637]
 [0.637]
 [0.637]
 [0.637]
 [0.637]
 [0.637]
 [0.632]] [[3.409]
 [3.409]
 [3.409]
 [3.409]
 [3.409]
 [3.409]
 [3.933]] [[1.259]
 [1.259]
 [1.259]
 [1.259]
 [1.259]
 [1.259]
 [1.679]]
Printing some Q and Qe and total Qs values:  [[ 0.037]
 [-0.016]
 [-0.006]
 [-0.008]
 [-0.008]
 [-0.006]
 [-0.005]] [[5.108]
 [3.783]
 [4.416]
 [4.471]
 [4.787]
 [4.661]
 [4.834]] [[1.303]
 [0.076]
 [0.636]
 [0.68 ]
 [0.95 ]
 [0.846]
 [0.996]]
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.095]
 [0.139]
 [0.102]
 [0.097]
 [0.127]
 [0.099]
 [0.101]] [[-0.787]
 [ 0.634]
 [-0.9  ]
 [-0.4  ]
 [ 0.098]
 [-0.425]
 [-0.454]] [[0.095]
 [0.139]
 [0.102]
 [0.097]
 [0.127]
 [0.099]
 [0.101]]
Printing some Q and Qe and total Qs values:  [[0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]] [[2.106]
 [2.106]
 [2.106]
 [2.106]
 [2.106]
 [2.106]
 [2.106]] [[0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.733]
 [0.699]
 [0.699]
 [0.873]
 [0.699]
 [0.699]] [[1.599]
 [1.892]
 [1.599]
 [1.599]
 [1.569]
 [1.599]
 [1.599]] [[0.699]
 [0.733]
 [0.699]
 [0.699]
 [0.873]
 [0.699]
 [0.699]]
Printing some Q and Qe and total Qs values:  [[0.796]
 [0.796]
 [0.796]
 [0.796]
 [0.796]
 [0.796]
 [0.796]] [[1.516]
 [1.516]
 [1.516]
 [1.516]
 [1.516]
 [1.516]
 [1.516]] [[0.796]
 [0.796]
 [0.796]
 [0.796]
 [0.796]
 [0.796]
 [0.796]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.809]
 [0.809]
 [0.809]
 [0.809]
 [0.886]
 [0.809]
 [0.809]] [[2.362]
 [2.362]
 [2.362]
 [2.362]
 [2.59 ]
 [2.362]
 [2.362]] [[0.809]
 [0.809]
 [0.809]
 [0.809]
 [0.886]
 [0.809]
 [0.809]]
Printing some Q and Qe and total Qs values:  [[0.626]
 [0.619]
 [0.626]
 [0.69 ]
 [0.916]
 [0.626]
 [0.626]] [[2.826]
 [2.29 ]
 [2.826]
 [2.02 ]
 [1.084]
 [2.826]
 [2.826]] [[0.626]
 [0.619]
 [0.626]
 [0.69 ]
 [0.916]
 [0.626]
 [0.626]]
line 256 mcts: sample exp_bonus 2.0188337868506743
Printing some Q and Qe and total Qs values:  [[0.552]
 [0.526]
 [0.56 ]
 [0.572]
 [0.581]
 [0.57 ]
 [0.561]] [[2.487]
 [2.36 ]
 [1.775]
 [2.178]
 [2.405]
 [2.261]
 [2.431]] [[0.552]
 [0.526]
 [0.56 ]
 [0.572]
 [0.581]
 [0.57 ]
 [0.561]]
rdn probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.07 ]
 [0.066]
 [0.049]
 [0.04 ]
 [0.046]
 [0.071]
 [0.037]] [[1.006]
 [1.451]
 [0.333]
 [0.669]
 [1.029]
 [0.922]
 [0.774]] [[0.07 ]
 [0.066]
 [0.049]
 [0.04 ]
 [0.046]
 [0.071]
 [0.037]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.654]
 [0.833]
 [0.85 ]
 [0.842]
 [0.774]
 [0.5  ]
 [0.81 ]] [[3.042]
 [4.319]
 [5.026]
 [4.891]
 [4.25 ]
 [3.607]
 [4.656]] [[1.263]
 [2.262]
 [2.68 ]
 [2.591]
 [2.126]
 [1.319]
 [2.41 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7331192
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.008]
 [0.066]
 [0.016]
 [0.013]
 [0.022]
 [0.015]
 [0.019]] [[-0.84 ]
 [ 0.696]
 [-0.689]
 [-0.431]
 [-0.591]
 [-0.679]
 [-0.478]] [[0.008]
 [0.066]
 [0.016]
 [0.013]
 [0.022]
 [0.015]
 [0.019]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.905]
 [0.832]
 [0.832]
 [0.832]
 [0.857]
 [0.832]
 [0.832]] [[2.245]
 [1.933]
 [1.933]
 [1.933]
 [2.446]
 [1.933]
 [1.933]] [[2.814]
 [2.614]
 [2.614]
 [2.614]
 [2.791]
 [2.614]
 [2.614]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.039]
 [0.039]
 [0.039]
 [0.039]
 [1.432]
 [0.039]
 [0.039]] [[1.766]
 [1.766]
 [1.766]
 [1.766]
 [1.124]
 [1.766]
 [1.766]] [[0.241]
 [0.241]
 [0.241]
 [0.241]
 [2.813]
 [0.241]
 [0.241]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.71345824
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.70063776
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7013556
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.882]
 [0.882]
 [0.882]
 [0.882]
 [0.908]
 [0.882]
 [0.882]] [[2.408]
 [2.408]
 [2.408]
 [2.408]
 [3.818]
 [2.408]
 [2.408]] [[1.368]
 [1.368]
 [1.368]
 [1.368]
 [1.886]
 [1.368]
 [1.368]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
1904 1873
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.813]
 [0.773]
 [0.813]
 [0.802]
 [0.813]
 [0.813]
 [0.783]] [[5.291]
 [6.487]
 [5.291]
 [4.548]
 [5.291]
 [5.291]
 [5.407]] [[1.546]
 [2.104]
 [1.546]
 [1.141]
 [1.546]
 [1.546]
 [1.559]]
Printing some Q and Qe and total Qs values:  [[0.75 ]
 [0.711]
 [0.75 ]
 [0.751]
 [0.75 ]
 [0.75 ]
 [0.712]] [[5.567]
 [5.556]
 [5.567]
 [6.348]
 [5.567]
 [5.567]
 [6.806]] [[1.885]
 [1.818]
 [1.885]
 [2.299]
 [1.885]
 [1.885]
 [2.478]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.693]
 [0.693]
 [0.693]
 [0.693]
 [0.693]
 [0.693]] [[6.295]
 [6.295]
 [6.295]
 [6.295]
 [6.295]
 [6.295]
 [6.295]] [[1.832]
 [1.832]
 [1.832]
 [1.832]
 [1.832]
 [1.832]
 [1.832]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.439]
 [0.434]
 [0.44 ]
 [0.454]
 [0.443]
 [0.47 ]
 [0.435]] [[5.278]
 [4.902]
 [4.963]
 [5.286]
 [5.55 ]
 [5.628]
 [5.38 ]] [[1.448]
 [1.252]
 [1.288]
 [1.464]
 [1.591]
 [1.651]
 [1.498]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 5.312398001860483
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.163]
 [0.163]
 [0.163]
 [0.163]
 [0.251]
 [0.171]
 [0.163]] [[8.34 ]
 [8.34 ]
 [8.34 ]
 [8.34 ]
 [8.916]
 [7.753]
 [8.34 ]] [[1.233]
 [1.233]
 [1.233]
 [1.233]
 [1.503]
 [1.051]
 [1.233]]
Printing some Q and Qe and total Qs values:  [[0.86 ]
 [0.86 ]
 [0.86 ]
 [0.86 ]
 [0.86 ]
 [0.86 ]
 [0.847]] [[4.522]
 [4.522]
 [4.522]
 [4.522]
 [4.522]
 [4.522]
 [4.688]] [[2.888]
 [2.888]
 [2.888]
 [2.888]
 [2.888]
 [2.888]
 [3.015]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.131897043207303
UNIT TEST: sample policy line 217 mcts : [0.184 0.02  0.143 0.143 0.184 0.204 0.122]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[-0.011]
 [-0.012]
 [-0.013]
 [-0.01 ]
 [-0.012]
 [-0.011]
 [-0.012]] [[5.188]
 [5.683]
 [6.377]
 [6.519]
 [5.787]
 [6.218]
 [6.411]] [[0.152]
 [0.413]
 [0.78 ]
 [0.86 ]
 [0.469]
 [0.7  ]
 [0.801]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.039]
 [-0.044]
 [-0.039]
 [-0.035]
 [-0.039]
 [-0.039]
 [-0.039]] [[4.597]
 [4.51 ]
 [4.597]
 [4.657]
 [4.597]
 [4.597]
 [4.597]] [[0.266]
 [0.197]
 [0.266]
 [0.314]
 [0.266]
 [0.266]
 [0.266]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 4.488343060457003
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6960631
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 6.752512347471586
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.83 ]
 [0.928]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.83 ]] [[0.719]
 [2.473]
 [0.719]
 [0.719]
 [0.719]
 [0.719]
 [0.719]] [[0.762]
 [1.521]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.7073919
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]
 [0.939]] [[6.192]
 [6.192]
 [6.192]
 [6.192]
 [6.192]
 [6.192]
 [6.192]] [[2.778]
 [2.778]
 [2.778]
 [2.778]
 [2.778]
 [2.778]
 [2.778]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
start point for exploration sampling:  10723
Printing some Q and Qe and total Qs values:  [[0.323]
 [0.298]
 [0.323]
 [0.279]
 [0.323]
 [0.323]
 [0.323]] [[6.147]
 [6.024]
 [6.147]
 [6.393]
 [6.147]
 [6.147]
 [6.147]] [[1.578]
 [1.447]
 [1.578]
 [1.654]
 [1.578]
 [1.578]
 [1.578]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.636]
 [0.653]
 [0.626]
 [0.627]
 [0.63 ]
 [0.632]
 [0.632]] [[0.464]
 [0.958]
 [0.6  ]
 [0.501]
 [0.468]
 [0.49 ]
 [0.492]] [[0.636]
 [0.653]
 [0.626]
 [0.627]
 [0.63 ]
 [0.632]
 [0.632]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.413]
 [0.413]
 [0.413]
 [0.385]
 [0.413]
 [0.413]
 [0.413]] [[5.464]
 [5.464]
 [5.464]
 [5.23 ]
 [5.464]
 [5.464]
 [5.464]] [[1.953]
 [1.953]
 [1.953]
 [1.727]
 [1.953]
 [1.953]
 [1.953]]
line 256 mcts: sample exp_bonus 6.1586373336976745
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.578]
 [0.338]
 [0.592]
 [0.581]
 [0.574]
 [0.603]
 [0.57 ]] [[1.248]
 [2.082]
 [1.231]
 [1.317]
 [1.304]
 [1.256]
 [1.294]] [[0.818]
 [0.616]
 [0.839]
 [0.845]
 [0.828]
 [0.869]
 [0.816]]
Printing some Q and Qe and total Qs values:  [[0.877]
 [0.826]
 [0.871]
 [0.874]
 [0.877]
 [0.86 ]
 [0.877]] [[4.678]
 [4.459]
 [4.531]
 [4.509]
 [4.678]
 [4.893]
 [4.678]] [[1.924]
 [1.654]
 [1.789]
 [1.776]
 [1.924]
 [2.075]
 [1.924]]
Printing some Q and Qe and total Qs values:  [[0.75 ]
 [0.823]
 [0.746]
 [0.736]
 [0.739]
 [0.784]
 [0.743]] [[6.92 ]
 [6.204]
 [7.596]
 [7.528]
 [7.297]
 [7.632]
 [7.573]] [[2.456]
 [2.361]
 [2.673]
 [2.63 ]
 [2.559]
 [2.76 ]
 [2.659]]
using explorer policy with actor:  1
from probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]] [[0.821]
 [0.821]
 [0.821]
 [0.821]
 [0.821]
 [0.821]
 [0.821]] [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]]
Printing some Q and Qe and total Qs values:  [[0.795]
 [0.811]
 [0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.795]] [[1.909]
 [4.847]
 [1.909]
 [1.909]
 [1.909]
 [1.909]
 [1.909]] [[1.107]
 [1.732]
 [1.107]
 [1.107]
 [1.107]
 [1.107]
 [1.107]]
using explorer policy with actor:  1
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.173]
 [0.161]
 [0.178]
 [0.178]
 [0.201]
 [0.176]
 [0.178]] [[5.184]
 [4.021]
 [4.521]
 [4.59 ]
 [5.037]
 [4.234]
 [4.26 ]] [[ 0.015]
 [-0.399]
 [-0.198]
 [-0.174]
 [ 0.022]
 [-0.297]
 [-0.284]]
Printing some Q and Qe and total Qs values:  [[0.127]
 [0.113]
 [0.132]
 [0.133]
 [0.275]
 [0.133]
 [0.137]] [[3.841]
 [3.806]
 [3.997]
 [4.048]
 [5.381]
 [3.904]
 [3.837]] [[-0.671]
 [-0.71 ]
 [-0.607]
 [-0.589]
 [ 0.14 ]
 [-0.637]
 [-0.652]]
Printing some Q and Qe and total Qs values:  [[0.262]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.283]] [[0.501]
 [0.843]
 [0.843]
 [0.843]
 [0.843]
 [0.843]
 [1.01 ]] [[0.262]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.31 ]
 [0.283]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.022]
 [-0.022]
 [-0.022]
 [-0.022]
 [-0.022]
 [-0.022]
 [-0.022]] [[4.004]
 [4.004]
 [4.004]
 [4.004]
 [4.004]
 [4.004]
 [4.004]] [[-0.717]
 [-0.717]
 [-0.717]
 [-0.717]
 [-0.717]
 [-0.717]
 [-0.717]]
Printing some Q and Qe and total Qs values:  [[-0.036]
 [-0.039]
 [-0.015]
 [-0.033]
 [-0.011]
 [-0.031]
 [-0.009]] [[2.986]
 [3.856]
 [3.602]
 [3.216]
 [4.405]
 [3.344]
 [3.605]] [[-1.106]
 [-0.821]
 [-0.858]
 [-1.022]
 [-0.582]
 [-0.975]
 [-0.844]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
in main func line 156:  1942
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.264]
 [0.404]
 [0.281]
 [0.347]
 [0.341]
 [0.311]
 [0.289]] [[1.687]
 [1.185]
 [1.811]
 [2.029]
 [2.238]
 [1.9  ]
 [1.773]] [[0.375]
 [0.487]
 [0.452]
 [0.656]
 [0.713]
 [0.541]
 [0.454]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.886]
 [0.89 ]
 [0.909]
 [0.907]
 [0.909]
 [0.901]
 [0.889]] [[4.917]
 [5.06 ]
 [4.553]
 [4.675]
 [4.553]
 [4.834]
 [4.928]] [[2.092]
 [2.196]
 [1.895]
 [1.972]
 [1.895]
 [2.066]
 [2.104]]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.911]
 [0.892]
 [0.906]] [[4.702]
 [4.702]
 [4.702]
 [4.702]
 [4.226]
 [4.455]
 [4.702]] [[1.586]
 [1.586]
 [1.586]
 [1.586]
 [1.297]
 [1.421]
 [1.586]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
UNIT TEST: sample policy line 217 mcts : [0.122 0.265 0.082 0.102 0.061 0.224 0.143]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.882]
 [0.89 ]
 [0.902]
 [0.91 ]
 [0.908]
 [0.908]
 [0.908]] [[1.399]
 [2.522]
 [1.394]
 [1.637]
 [1.84 ]
 [1.619]
 [1.805]] [[1.388]
 [1.78 ]
 [1.426]
 [1.524]
 [1.587]
 [1.513]
 [1.576]]
start point for exploration sampling:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.445]
 [0.465]
 [0.442]] [[4.066]
 [4.066]
 [4.066]
 [4.066]
 [3.179]
 [4.631]
 [4.066]] [[1.563]
 [1.563]
 [1.563]
 [1.563]
 [1.104]
 [1.874]
 [1.563]]
Printing some Q and Qe and total Qs values:  [[0.044]
 [0.044]
 [0.044]
 [0.044]
 [0.048]
 [0.067]
 [0.044]] [[4.066]
 [4.066]
 [4.066]
 [4.066]
 [3.179]
 [4.631]
 [4.066]] [[0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.272]
 [1.168]
 [0.806]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.066]
 [-0.066]
 [-0.066]
 [-0.066]
 [-0.066]
 [-0.053]
 [-0.059]] [[3.805]
 [3.805]
 [3.805]
 [3.805]
 [3.805]
 [3.853]
 [3.713]] [[0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.844]
 [0.904]
 [0.771]]
1956 1901
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[-0.068]
 [-0.02 ]
 [-0.02 ]
 [-0.054]
 [-0.049]
 [-0.076]
 [-0.02 ]] [[5.754]
 [6.393]
 [6.393]
 [6.328]
 [8.791]
 [5.883]
 [6.393]] [[0.888]
 [1.11 ]
 [1.11 ]
 [1.074]
 [1.848]
 [0.924]
 [1.11 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 1.062638922629172
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.843]
 [0.843]
 [0.843]
 [0.783]
 [0.843]
 [0.841]
 [0.843]] [[2.793]
 [2.793]
 [2.793]
 [3.063]
 [2.793]
 [4.164]
 [2.793]] [[1.309]
 [1.309]
 [1.309]
 [1.458]
 [1.309]
 [2.44 ]
 [1.309]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]
 [0.916]] [[1.707]
 [1.707]
 [1.707]
 [1.707]
 [1.707]
 [1.707]
 [1.707]] [[2.489]
 [2.489]
 [2.489]
 [2.489]
 [2.489]
 [2.489]
 [2.489]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]] [[0.471]
 [0.471]
 [0.471]
 [0.471]
 [0.471]
 [0.471]
 [0.471]] [[0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
siam score:  -0.6856723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.683638
Printing some Q and Qe and total Qs values:  [[0.585]
 [0.598]
 [0.581]
 [0.581]
 [0.576]
 [0.58 ]
 [0.581]] [[1.149]
 [1.985]
 [1.148]
 [1.148]
 [1.333]
 [1.29 ]
 [1.148]] [[0.585]
 [0.598]
 [0.581]
 [0.581]
 [0.576]
 [0.58 ]
 [0.581]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.889]
 [0.866]
 [0.889]
 [0.88 ]
 [0.889]
 [0.854]
 [0.877]] [[3.677]
 [3.765]
 [3.677]
 [4.594]
 [3.677]
 [3.663]
 [3.189]] [[2.003]
 [1.986]
 [2.003]
 [2.291]
 [2.003]
 [1.928]
 [1.816]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.744]
 [0.709]
 [0.762]
 [0.749]
 [0.75 ]
 [0.792]
 [0.754]] [[0.834]
 [2.946]
 [0.916]
 [0.952]
 [0.973]
 [0.986]
 [0.893]] [[0.162]
 [1.389]
 [0.227]
 [0.237]
 [0.25 ]
 [0.295]
 [0.206]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
deleting a thread, now have 4 threads
Frames:  137154 train batches done:  16063 episodes:  3878
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.623]
 [0.332]
 [0.332]] [[2.918]
 [2.918]
 [2.918]
 [2.918]
 [4.139]
 [2.918]
 [2.918]] [[-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [ 0.986]
 [-0.005]
 [-0.005]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.1299788555676569
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.247]
 [0.247]
 [0.247]
 [0.247]
 [0.445]
 [0.247]
 [0.247]] [[3.629]
 [3.629]
 [3.629]
 [3.629]
 [7.84 ]
 [3.629]
 [3.629]] [[0.266]
 [0.266]
 [0.266]
 [0.266]
 [1.747]
 [0.266]
 [0.266]]
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.719]
 [0.511]
 [0.511]] [[2.56]
 [2.56]
 [2.56]
 [2.56]
 [4.21]
 [2.56]
 [2.56]] [[0.165]
 [0.165]
 [0.165]
 [0.165]
 [1.131]
 [0.165]
 [0.165]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.67972237
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
deleting a thread, now have 3 threads
Frames:  137338 train batches done:  16087 episodes:  3882
siam score:  -0.6794038
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.795]
 [1.115]
 [0.795]] [[5.174]
 [5.174]
 [5.174]
 [5.174]
 [5.174]
 [7.863]
 [5.174]] [[1.235]
 [1.235]
 [1.235]
 [1.235]
 [1.235]
 [2.387]
 [1.235]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.903]
 [0.85 ]
 [0.903]
 [0.798]
 [0.77 ]
 [0.696]
 [0.936]] [[4.088]
 [3.638]
 [4.088]
 [3.094]
 [2.691]
 [2.188]
 [3.833]] [[2.177]
 [2.012]
 [2.177]
 [1.819]
 [1.68 ]
 [1.488]
 [2.114]]
Printing some Q and Qe and total Qs values:  [[0.986]
 [0.986]
 [0.986]
 [0.981]
 [0.986]
 [0.986]
 [0.997]] [[3.72 ]
 [3.72 ]
 [3.72 ]
 [3.287]
 [3.72 ]
 [3.72 ]
 [3.821]] [[2.286]
 [2.286]
 [2.286]
 [2.054]
 [2.286]
 [2.286]
 [2.349]]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[1.163]
 [1.163]
 [1.163]
 [1.163]
 [1.163]
 [1.163]
 [1.163]] [[0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]
 [0.954]] [[2.327]
 [2.327]
 [2.327]
 [2.327]
 [2.327]
 [2.327]
 [2.327]]
Printing some Q and Qe and total Qs values:  [[0.724]
 [0.724]
 [0.724]
 [0.724]
 [0.809]
 [0.724]
 [0.724]] [[0.388]
 [0.388]
 [0.388]
 [0.388]
 [0.833]
 [0.388]
 [0.388]] [[1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.321]
 [1.002]
 [1.002]]
Printing some Q and Qe and total Qs values:  [[0.813]
 [0.75 ]
 [0.75 ]
 [0.771]
 [0.835]
 [0.75 ]
 [0.75 ]] [[2.173]
 [1.53 ]
 [1.53 ]
 [1.077]
 [3.053]
 [1.53 ]
 [1.53 ]] [[1.755]
 [1.414]
 [1.414]
 [1.305]
 [2.092]
 [1.414]
 [1.414]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
start point for exploration sampling:  10723
Printing some Q and Qe and total Qs values:  [[0.387]
 [0.477]
 [0.387]
 [0.387]
 [0.387]
 [0.387]
 [0.387]] [[3.155]
 [2.859]
 [3.155]
 [3.155]
 [3.155]
 [3.155]
 [3.155]] [[-0.223]
 [-0.143]
 [-0.223]
 [-0.223]
 [-0.223]
 [-0.223]
 [-0.223]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
in main func line 156:  1977
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 7.865994996114792
Printing some Q and Qe and total Qs values:  [[0.111]
 [0.128]
 [0.134]
 [0.119]
 [0.119]
 [0.121]
 [0.109]] [[-2.279]
 [-1.909]
 [-2.232]
 [-2.316]
 [-2.287]
 [-2.27 ]
 [-2.226]] [[0.111]
 [0.128]
 [0.134]
 [0.119]
 [0.119]
 [0.121]
 [0.109]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 1.9940263442838222
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.65923494
Printing some Q and Qe and total Qs values:  [[0.848]
 [0.808]
 [0.848]
 [0.848]
 [0.844]
 [0.848]
 [0.848]] [[0.461]
 [0.601]
 [0.461]
 [0.461]
 [3.912]
 [0.461]
 [0.461]] [[1.074]
 [1.087]
 [1.074]
 [1.074]
 [1.793]
 [1.074]
 [1.074]]
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.657]] [[3.594]
 [3.594]
 [3.594]
 [3.594]
 [3.594]
 [3.594]
 [3.594]] [[2.258]
 [2.258]
 [2.258]
 [2.258]
 [2.258]
 [2.258]
 [2.258]]
siam score:  -0.661223
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.038]
 [-0.035]
 [-0.035]
 [-0.035]
 [-0.035]
 [-0.035]
 [-0.035]] [[3.316]
 [3.447]
 [3.447]
 [3.447]
 [3.447]
 [3.447]
 [3.447]] [[0.482]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.585]
 [0.776]
 [0.893]
 [0.893]
 [0.893]
 [0.893]
 [0.893]] [[-0.839]
 [-1.025]
 [ 0.429]
 [ 0.429]
 [ 0.429]
 [ 0.429]
 [ 0.429]] [[1.356]
 [1.49 ]
 [3.663]
 [3.663]
 [3.663]
 [3.663]
 [3.663]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.668607
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6700273
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 4.742667898849035
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.66320986
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.481]
 [0.483]
 [0.483]] [[0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.87 ]
 [0.715]
 [0.715]] [[0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.481]
 [0.483]
 [0.483]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 3.7660692410013668
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.929]
 [0.849]
 [0.929]
 [0.898]
 [0.929]
 [0.929]
 [0.877]] [[4.118]
 [5.671]
 [4.118]
 [4.798]
 [4.118]
 [4.118]
 [5.093]] [[1.859]
 [2.141]
 [1.859]
 [1.984]
 [1.859]
 [1.859]
 [2.035]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.711]
 [0.705]
 [0.711]
 [0.651]
 [0.711]
 [0.711]
 [0.711]] [[4.438]
 [5.103]
 [4.438]
 [4.447]
 [4.438]
 [4.438]
 [4.438]] [[2.13 ]
 [2.385]
 [2.13 ]
 [2.087]
 [2.13 ]
 [2.13 ]
 [2.13 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
UNIT TEST: sample policy line 217 mcts : [0.041 0.041 0.061 0.041 0.061 0.286 0.469]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6713522
siam score:  -0.67097974
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]] [[0.641]
 [0.641]
 [0.641]
 [0.641]
 [0.641]
 [0.641]
 [0.641]] [[0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.1237105064251676
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.76 ]
 [0.76 ]
 [0.76 ]
 [0.76 ]
 [0.837]
 [0.76 ]
 [0.76 ]] [[3.004]
 [3.004]
 [3.004]
 [3.004]
 [3.806]
 [3.004]
 [3.004]] [[1.503]
 [1.503]
 [1.503]
 [1.503]
 [2.076]
 [1.503]
 [1.503]]
siam score:  -0.6710281
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 6.496982073417999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
from probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.175644146412361
Starting evaluation
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.01 ]
 [0.075]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.01 ]] [[0.519]
 [2.207]
 [0.519]
 [0.519]
 [0.519]
 [0.519]
 [0.519]] [[0.01 ]
 [0.075]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.01 ]]
Printing some Q and Qe and total Qs values:  [[0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]] [[0.86]
 [0.86]
 [0.86]
 [0.86]
 [0.86]
 [0.86]
 [0.86]] [[0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]]
Printing some Q and Qe and total Qs values:  [[0.135]
 [0.077]
 [0.116]
 [0.116]
 [0.096]
 [0.116]
 [0.116]] [[2.885]
 [1.894]
 [1.648]
 [1.648]
 [2.321]
 [1.648]
 [1.648]] [[0.135]
 [0.077]
 [0.116]
 [0.116]
 [0.096]
 [0.116]
 [0.116]]
line 256 mcts: sample exp_bonus 3.789012981784276
using explorer policy with actor:  0
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.721]
 [0.768]
 [0.721]
 [0.778]
 [0.734]
 [0.735]
 [0.734]] [[2.037]
 [1.97 ]
 [2.037]
 [2.016]
 [2.048]
 [2.055]
 [2.086]] [[0.721]
 [0.768]
 [0.721]
 [0.778]
 [0.734]
 [0.735]
 [0.734]]
Printing some Q and Qe and total Qs values:  [[0.627]
 [0.577]
 [0.573]
 [0.873]
 [0.793]
 [0.792]
 [0.724]] [[4.12 ]
 [4.64 ]
 [4.684]
 [1.959]
 [2.771]
 [2.561]
 [3.431]] [[0.627]
 [0.577]
 [0.573]
 [0.873]
 [0.793]
 [0.792]
 [0.724]]
Printing some Q and Qe and total Qs values:  [[0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.735]
 [0.686]
 [0.686]] [[4.519]
 [4.519]
 [4.519]
 [4.519]
 [5.865]
 [4.519]
 [4.519]] [[1.492]
 [1.492]
 [1.492]
 [1.492]
 [1.962]
 [1.492]
 [1.492]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
line 256 mcts: sample exp_bonus 5.759560689062536
Printing some Q and Qe and total Qs values:  [[0.534]
 [0.52 ]
 [0.536]
 [0.539]
 [0.639]
 [0.61 ]
 [0.555]] [[4.638]
 [5.38 ]
 [4.775]
 [4.872]
 [4.143]
 [4.57 ]
 [4.83 ]] [[0.534]
 [0.52 ]
 [0.536]
 [0.539]
 [0.639]
 [0.61 ]
 [0.555]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.834]
 [0.834]
 [0.834]
 [0.834]
 [1.213]
 [0.834]
 [0.834]] [[0.933]
 [0.933]
 [0.933]
 [0.933]
 [3.997]
 [0.933]
 [0.933]] [[1.007]
 [1.007]
 [1.007]
 [1.007]
 [2.581]
 [1.007]
 [1.007]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.915]
 [0.915]
 [0.915]
 [0.915]
 [1.309]
 [0.915]
 [0.915]] [[1.058]
 [1.058]
 [1.058]
 [1.058]
 [2.03 ]
 [1.058]
 [1.058]] [[1.346]
 [1.346]
 [1.346]
 [1.346]
 [2.46 ]
 [1.346]
 [1.346]]
Printing some Q and Qe and total Qs values:  [[0.534]
 [0.525]
 [0.566]
 [0.54 ]
 [0.656]
 [0.614]
 [0.555]] [[4.695]
 [5.849]
 [4.504]
 [4.964]
 [4.078]
 [4.72 ]
 [4.888]] [[0.534]
 [0.525]
 [0.566]
 [0.54 ]
 [0.656]
 [0.614]
 [0.555]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 5.097632034484154
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.609]] [[4.118]
 [4.118]
 [4.118]
 [4.118]
 [4.118]
 [4.118]
 [4.118]] [[0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.609]]
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.587]
 [0.581]
 [0.813]
 [0.759]
 [0.78 ]
 [0.581]] [[4.491]
 [4.064]
 [4.491]
 [2.101]
 [1.886]
 [1.961]
 [4.491]] [[0.581]
 [0.587]
 [0.581]
 [0.813]
 [0.759]
 [0.78 ]
 [0.581]]
Printing some Q and Qe and total Qs values:  [[0.534]
 [0.533]
 [0.534]
 [0.534]
 [0.534]
 [0.534]
 [0.534]] [[4.864]
 [5.086]
 [4.864]
 [4.864]
 [4.864]
 [4.864]
 [4.864]] [[0.534]
 [0.533]
 [0.534]
 [0.534]
 [0.534]
 [0.534]
 [0.534]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.526]
 [0.522]
 [0.532]
 [0.535]
 [0.811]
 [0.67 ]
 [0.573]] [[5.499]
 [5.463]
 [4.79 ]
 [4.932]
 [2.532]
 [4.532]
 [4.856]] [[0.526]
 [0.522]
 [0.532]
 [0.535]
 [0.811]
 [0.67 ]
 [0.573]]
start point for exploration sampling:  10723
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.534]
 [0.533]
 [0.534]
 [0.534]
 [0.534]
 [0.534]
 [0.534]] [[4.87 ]
 [4.957]
 [4.87 ]
 [4.87 ]
 [4.87 ]
 [4.87 ]
 [4.87 ]] [[0.534]
 [0.533]
 [0.534]
 [0.534]
 [0.534]
 [0.534]
 [0.534]]
using explorer policy with actor:  0
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 2.1696044824347394
siam score:  -0.66092384
Printing some Q and Qe and total Qs values:  [[0.623]
 [0.639]
 [0.623]
 [0.623]
 [0.729]
 [0.623]
 [0.623]] [[3.441]
 [3.299]
 [3.441]
 [3.441]
 [1.707]
 [3.441]
 [3.441]] [[0.623]
 [0.639]
 [0.623]
 [0.623]
 [0.729]
 [0.623]
 [0.623]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.738]
 [0.738]
 [0.738]
 [0.57 ]
 [0.64 ]
 [0.738]
 [0.738]] [[2.696]
 [2.696]
 [2.696]
 [4.145]
 [3.435]
 [2.696]
 [2.696]] [[0.738]
 [0.738]
 [0.738]
 [0.57 ]
 [0.64 ]
 [0.738]
 [0.738]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.522]
 [0.535]
 [0.53 ]
 [0.655]
 [0.635]
 [0.529]] [[4.167]
 [4.089]
 [3.919]
 [4.132]
 [2.632]
 [3.829]
 [4.117]] [[0.507]
 [0.522]
 [0.535]
 [0.53 ]
 [0.655]
 [0.635]
 [0.529]]
Printing some Q and Qe and total Qs values:  [[0.755]
 [0.752]
 [0.764]
 [0.784]
 [0.811]
 [0.785]
 [0.79 ]] [[3.895]
 [4.774]
 [4.387]
 [4.269]
 [4.218]
 [4.296]
 [4.35 ]] [[1.407]
 [1.837]
 [1.658]
 [1.62 ]
 [1.621]
 [1.634]
 [1.666]]
first move QE:  1.1216485862500623
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.531]
 [0.562]
 [0.574]
 [0.565]
 [0.774]
 [0.658]
 [0.564]] [[4.157]
 [4.211]
 [3.638]
 [3.865]
 [2.237]
 [3.799]
 [4.05 ]] [[0.531]
 [0.562]
 [0.574]
 [0.565]
 [0.774]
 [0.658]
 [0.564]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.706]
 [0.679]
 [0.707]
 [0.707]
 [0.732]
 [0.74 ]
 [0.703]] [[3.991]
 [4.351]
 [4.364]
 [4.445]
 [4.584]
 [4.448]
 [4.432]] [[1.456]
 [1.648]
 [1.692]
 [1.742]
 [1.861]
 [1.786]
 [1.729]]
Printing some Q and Qe and total Qs values:  [[0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]] [[1.972]
 [1.972]
 [1.972]
 [1.972]
 [2.003]
 [1.972]
 [1.972]] [[0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.819]
 [0.634]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.819]] [[2.208]
 [3.144]
 [2.208]
 [2.208]
 [2.208]
 [2.208]
 [2.208]] [[1.79 ]
 [1.952]
 [1.79 ]
 [1.79 ]
 [1.79 ]
 [1.79 ]
 [1.79 ]]
using explorer policy with actor:  0
using explorer policy with actor:  0
using explorer policy with actor:  0
siam score:  -0.6684416
Printing some Q and Qe and total Qs values:  [[0.506]
 [0.504]
 [0.51 ]
 [0.51 ]
 [0.586]
 [0.503]
 [0.501]] [[3.946]
 [3.628]
 [3.908]
 [3.995]
 [4.707]
 [4.33 ]
 [4.162]] [[1.283]
 [1.041]
 [1.261]
 [1.326]
 [1.974]
 [1.567]
 [1.438]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.59 ]
 [0.591]
 [0.591]] [[3.291]
 [3.291]
 [3.291]
 [3.291]
 [3.333]
 [3.291]
 [3.291]] [[0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.59 ]
 [0.591]
 [0.591]]
line 256 mcts: sample exp_bonus 3.604746498440229
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.447]
 [0.447]
 [0.447]
 [0.447]
 [0.447]
 [0.447]
 [0.467]] [[4.142]
 [4.142]
 [4.142]
 [4.142]
 [4.142]
 [4.142]
 [7.37 ]] [[0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [1.33 ]]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]] [[3.278]
 [3.278]
 [3.278]
 [3.278]
 [3.278]
 [3.278]
 [3.278]] [[0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.608]] [[2.953]
 [2.953]
 [2.953]
 [2.953]
 [2.953]
 [2.953]
 [3.315]] [[0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.608]]
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.558]] [[3.178]
 [3.178]
 [3.178]
 [3.178]
 [3.178]
 [3.178]
 [3.745]] [[0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.558]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.558]
 [0.552]
 [0.553]
 [0.563]
 [0.652]
 [0.566]
 [0.545]] [[3.053]
 [4.103]
 [3.368]
 [3.599]
 [3.389]
 [4.977]
 [4.527]] [[0.558]
 [0.552]
 [0.553]
 [0.563]
 [0.652]
 [0.566]
 [0.545]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.328881957247068
Printing some Q and Qe and total Qs values:  [[0.277]
 [0.238]
 [0.254]
 [0.277]
 [0.269]
 [0.26 ]
 [0.264]] [[6.09 ]
 [4.539]
 [4.441]
 [6.09 ]
 [5.901]
 [6.85 ]
 [8.181]] [[0.72 ]
 [0.22 ]
 [0.2  ]
 [0.72 ]
 [0.657]
 [0.943]
 [1.354]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.578]
 [0.578]
 [0.578]
 [0.578]
 [0.578]
 [0.578]
 [0.578]] [[3.415]
 [3.415]
 [3.415]
 [3.415]
 [3.415]
 [3.415]
 [3.415]] [[0.578]
 [0.578]
 [0.578]
 [0.578]
 [0.578]
 [0.578]
 [0.578]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.904]
 [0.918]
 [0.918]
 [0.918]
 [0.874]
 [0.918]
 [0.918]] [[2.174]
 [2.507]
 [2.507]
 [2.507]
 [3.182]
 [2.507]
 [2.507]] [[1.613]
 [1.706]
 [1.706]
 [1.706]
 [1.866]
 [1.706]
 [1.706]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.572]
 [0.534]
 [0.565]
 [0.563]
 [0.69 ]
 [0.578]
 [0.547]] [[2.773]
 [3.581]
 [2.859]
 [3.021]
 [2.086]
 [2.947]
 [3.5  ]] [[0.572]
 [0.534]
 [0.565]
 [0.563]
 [0.69 ]
 [0.578]
 [0.547]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
rdn probs:  [0.25, 0.25, 0.25, 0.25]
first move QE:  1.119266732659175
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.92 ]
 [0.867]
 [0.917]
 [0.92 ]
 [0.925]
 [0.922]
 [0.923]] [[2.58 ]
 [3.606]
 [2.636]
 [3.093]
 [3.584]
 [2.902]
 [3.204]] [[0.746]
 [1.229]
 [0.772]
 [1.008]
 [1.262]
 [0.911]
 [1.066]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.764]
 [0.75 ]
 [0.748]] [[3.381]
 [3.381]
 [3.381]
 [3.381]
 [3.778]
 [3.766]
 [3.841]] [[1.295]
 [1.295]
 [1.295]
 [1.295]
 [1.69 ]
 [1.657]
 [1.729]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.078]
 [-0.077]
 [-0.077]
 [-0.075]
 [-0.078]
 [-0.078]
 [-0.075]] [[3.176]
 [2.648]
 [2.908]
 [2.806]
 [3.058]
 [3.149]
 [3.406]] [[-0.138]
 [-0.665]
 [-0.404]
 [-0.503]
 [-0.256]
 [-0.166]
 [ 0.097]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.749]] [[3.595]
 [3.595]
 [3.595]
 [3.595]
 [3.595]
 [3.595]
 [3.552]] [[0.216]
 [0.216]
 [0.216]
 [0.216]
 [0.216]
 [0.216]
 [0.2  ]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.436]
 [0.431]
 [0.442]
 [0.456]
 [0.418]
 [0.423]] [[7.721]
 [5.796]
 [7.148]
 [7.054]
 [7.124]
 [7.209]
 [7.707]] [[0.748]
 [0.125]
 [0.565]
 [0.555]
 [0.608]
 [0.559]
 [0.736]]
line 256 mcts: sample exp_bonus 0.7598775224901838
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus 10.0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10723
Printing some Q and Qe and total Qs values:  [[0.941]
 [0.941]
 [0.941]
 [0.941]
 [1.187]
 [0.941]
 [0.941]] [[1.208]
 [1.208]
 [1.208]
 [1.208]
 [0.698]
 [1.208]
 [1.208]] [[1.404]
 [1.404]
 [1.404]
 [1.404]
 [1.726]
 [1.404]
 [1.404]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.57 ]
 [0.397]
 [0.397]] [[4.928]
 [4.928]
 [4.928]
 [4.928]
 [6.034]
 [4.928]
 [4.928]] [[-0.301]
 [-0.301]
 [-0.301]
 [-0.301]
 [ 0.414]
 [-0.301]
 [-0.301]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.588]
 [0.571]
 [0.556]] [[4.126]
 [4.126]
 [4.126]
 [4.126]
 [3.271]
 [3.517]
 [3.674]] [[1.469]
 [1.469]
 [1.469]
 [1.469]
 [0.959]
 [1.087]
 [1.163]]
siam score:  -0.66443855
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.906]
 [0.873]
 [0.816]
 [0.895]
 [0.906]
 [0.964]
 [0.878]] [[7.598]
 [5.386]
 [4.237]
 [7.256]
 [7.598]
 [7.1  ]
 [6.753]] [[2.502]
 [1.228]
 [0.522]
 [2.298]
 [2.502]
 [2.288]
 [1.998]]
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.596]
 [0.587]
 [0.586]
 [0.582]
 [0.574]
 [0.572]] [[5.764]
 [5.024]
 [5.764]
 [5.309]
 [5.73 ]
 [5.693]
 [6.021]] [[0.646]
 [0.417]
 [0.646]
 [0.494]
 [0.626]
 [0.598]
 [0.703]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.756]
 [0.742]
 [0.743]] [[3.816]
 [3.816]
 [3.816]
 [3.816]
 [3.851]
 [3.947]
 [3.816]] [[1.687]
 [1.687]
 [1.687]
 [1.687]
 [1.74 ]
 [1.8  ]
 [1.687]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  1
siam score:  -0.65105057
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6477877
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  -0.6459419
start point for exploration sampling:  10723
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
start point for exploration sampling:  10723
Printing some Q and Qe and total Qs values:  [[0.88 ]
 [0.892]
 [0.88 ]
 [0.909]
 [0.88 ]
 [0.791]
 [0.9  ]] [[5.81 ]
 [5.576]
 [5.81 ]
 [5.095]
 [5.81 ]
 [3.901]
 [5.518]] [[1.89 ]
 [1.836]
 [1.89 ]
 [1.709]
 [1.89 ]
 [1.075]
 [1.832]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.25, 0.25, 0.25, 0.25]
