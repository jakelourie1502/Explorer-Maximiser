dirichlet_alpha:0.3
noise:0.3
dirichlet_alpha:0.5
noise:0.5
sims:{-1: 6, 6000: 50}
c1:1
c2:19652
temperature_init:1
temperature_changes:{-1: 1, 3000000.0: 0.5}
manual_over_ride_play_limit:None
exponent_node_n:1
ucb_denom_k:1
use_policy:True
model_expV_on_dones:True
norm_Qs_OnMaxi:True
norm_Qs_OnAll:True
norm_each_turn:False
state_channels:64
res_block_kernel_size:3
conv1:{'channels': 32, 'kernel_size': 3, 'stride': 2, 'padding': 1}
conv2:{'channels': 64, 'kernel_size': 3, 'stride': 2, 'padding': 1}
res_block_channels:[32, 64, 64]
res_block_ds:[False, False, False]
reward_support:[-1, 1, 41]
conv1:{'kernel_size': 3, 'stride': 1, 'padding': 1}
res_blocks:[64, 64]
reward_conv_channels:32
reward_hidden_dim:128
terminal_conv_channels:32
terminal_hidden_dim:64
value_support:[-1, 1, 41]
res_block:[64]
value_conv_channels:32
value_hidden_dim:128
policy_conv_channels:32
policy_hidden_dim:128
expV_conv_channels:32
expV_hidden_dim:128
expV_support:[-10, 10, 51]
proj_l1:256
proj_out:128
pred_hid:256
replay_buffer_size:50000
replay_buffer_size_exploration:200000
all_time_buffer_size:200000
batch_size:128
play_workers:2
min_workers:2
max_workers:6
lr:0.001
lr_warmup:1000
lr_decay:1
lr_decay_step:100000
optimizer:<class 'torch.optim.rmsprop.RMSprop'>
momentum:0.9
l2:0.0001
rho:0.99
k:5
value:0.25
dones:2.0
siam:2
rdn:0.5
expV:0.5
train_start_batch_multiple:2
prioritised_replay:True
resampling:False
resampling_use_max:False
resampling_assess_best_child:False
rs_start:1000
ep_to_batch_ratio:[15, 16]
main_to_rdn_ratio:2
train_to_RS_ratio:4
on_policy_expV:False
env:<class 'game_play.Car_Driving_Env.RaceWorld'>
same_env_each_time:True
channels:3
env_size:[8, 60]
observable_size:[8, 10]
game_modes:1
env_map:[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.
  0. 0. 0. 0. 0. 0. 2. 2. 2. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.
  1. 1. 1. 1. 2. 1. 1. 1. 0. 0. 2. 2. 2. 1. 1. 0. 0. 0. 2. 1. 1. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 2. 1. 1. 1. 2. 2. 2. 2. 2.
  1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 0. 1. 1. 1. 1. 1. 1. 1. 2. 0. 0.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1.
  1. 1. 1. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 0. 2. 2. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 1. 2. 2. 2. 2. 1. 1. 2. 2. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.
  1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 2. 2. 1. 2. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 1. 1. 2. 1. 1. 2. 2. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 2. 2.
  2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
max_steps:200
actions_size:7
optimal_score:0.86
total_frames:305000
exp_gamma:0.975
atari_env:False
reward_clipping:False
memory_size:100
image_size:[48, 48]
timesteps_in_obs:2
store_prev_actions:True
running_reward_in_obs:False
deque_length:3
PRESET_CONFIG:1
VK:True
use_two_heads:True
follow_better_policy:0.5
use_siam:True
exploration_type:rdn
rdn_beta:[0.16666666666666666, 0.6666666666666666, 4]
explorer_percentage:0.8
reward_exploration:False
train_dones:True
state_size:[6, 6]
norm_state_vecs:False
RND_output_vector:256
RND_loss:cosine
prediction_bias:True
distance_measure:False
update_play_model:16
gamma:0.99
calc_n_step_rewards_after_frames:10000
N_steps_reward:5
start_frame_count:0
load_in_model:False
log_states:True
log_metrics:False
exploration_logger_dims:(1, 480)
device_train:cpu
device_selfplay:cpu
eval_x_frames:10000
eval_count:20
detach_expV_calc:True
use_new_episode_expV:True
start_training_expV_min:10000
start_training_expV_max:20000
start_training_expV_siam_override:0.8
value_only:False
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.
  0. 0. 0. 0. 0. 0. 2. 2. 2. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.
  1. 1. 1. 1. 2. 1. 1. 1. 0. 0. 2. 2. 2. 1. 1. 0. 0. 0. 2. 1. 1. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 2. 1. 1. 1. 2. 2. 2. 2. 2.
  1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 2. 2. 2. 0. 1. 1. 1. 1. 1. 1. 1. 2. 0. 0.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1.
  1. 1. 1. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 0. 2. 2. 1. 1. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 1. 1. 1. 2. 2. 2. 2. 1. 1. 2. 2. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.
  1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 2. 2. 1. 2. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 1. 1. 2. 1. 1. 2. 2. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 2. 2.
  2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.
  3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Starting evaluation
main train batch thing paused
add a thread
Adding thread: now have 5 threads
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.003]
 [0.003]
 [0.003]
 [0.002]
 [0.002]
 [0.002]
 [0.002]] [[-0.]
 [-0.]
 [-0.]
 [ 0.]
 [ 0.]
 [ 0.]
 [ 0.]] [[0.003]
 [0.003]
 [0.003]
 [0.002]
 [0.002]
 [0.002]
 [0.002]]
using explorer policy with actor:  1
rdn probs:  [0.25, 0.25, 0.25, 0.25]
siam score:  0.0008243836928158998
maxi score, test score, baseline:  -0.9564217391304348 -1.0 -0.9564217391304348
UNIT TEST: sample policy line 217 mcts : [0.  0.  0.2 0.4 0.  0.4 0. ]
Printing some Q and Qe and total Qs values:  [[0.007]
 [0.008]
 [0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.008]] [[ 0.041]
 [-0.052]
 [ 0.041]
 [ 0.041]
 [ 0.041]
 [ 0.041]
 [-0.024]] [[0.114]
 [0.086]
 [0.114]
 [0.114]
 [0.114]
 [0.114]
 [0.095]]
deleting a thread, now have 4 threads
Frames:  825 train batches done:  6 episodes:  17
14 7
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
siam score:  -0.07897089828336842
deleting a thread, now have 3 threads
Frames:  1024 train batches done:  27 episodes:  21
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
deleting a thread, now have 2 threads
Frames:  1024 train batches done:  50 episodes:  21
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
siam score:  -0.4361734
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
first move QE:  -0.039798024571659464
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
maxi score, test score, baseline:  -0.9582333333333334 -1.0 -0.9582333333333334
probs:  [0.4894576064270461, 0.01054239357295387, 0.01054239357295387, 0.4894576064270461]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
deleting a thread, now have 2 threads
Frames:  1261 train batches done:  131 episodes:  27
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.005807356796982368, 0.40800700442548204, 0.40800700442548204, 0.17817863435205344]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.004477378516205038, 0.4409620389318405, 0.4409620389318405, 0.11359854362011398]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.004477378516205038, 0.4409620389318405, 0.4409620389318405, 0.11359854362011398]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.004477378516205038, 0.4409620389318405, 0.4409620389318405, 0.11359854362011398]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.004477378516205038, 0.4409620389318405, 0.4409620389318405, 0.11359854362011398]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.004477378516205038, 0.4409620389318405, 0.4409620389318405, 0.11359854362011398]
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
maxi score, test score, baseline:  -0.9599 -1.0 -0.9599
probs:  [0.004477378516205038, 0.4409620389318405, 0.4409620389318405, 0.11359854362011398]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.01115597650726491, 0.32961467449757836, 0.32961467449757836, 0.32961467449757836]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.02917625479970674, 0.02917625479970674, 0.02917625479970674, 0.9124712356008797]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.02917625479970674, 0.02917625479970674, 0.02917625479970674, 0.9124712356008797]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.02917625479970674, 0.02917625479970674, 0.02917625479970674, 0.9124712356008797]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.02917625479970674, 0.02917625479970674, 0.02917625479970674, 0.9124712356008797]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.02917625479970674, 0.02917625479970674, 0.02917625479970674, 0.9124712356008797]
siam score:  -0.49670053
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.02917625479970674, 0.02917625479970674, 0.02917625479970674, 0.9124712356008797]
maxi score, test score, baseline:  -0.9614384615384616 -1.0 -0.9614384615384616
probs:  [0.017674810533824296, 0.4823251894661757, 0.4823251894661757, 0.017674810533824296]
using another actor
from probs:  [0.18581858720994754, 0.40304798434550915, 0.40304798434550915, 0.008085444099034224]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
probs:  [0.18581858078818217, 0.40304799965895005, 0.40304799965895005, 0.008085419893917827]
maxi score, test score, baseline:  -0.9628629629629629 -1.0 -0.9628629629629629
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.48060716880758925, 0.48060716880758925, 0.0193928311924108, 0.0193928311924108]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.48060716880758925, 0.48060716880758925, 0.0193928311924108, 0.0193928311924108]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.48060716880758925, 0.48060716880758925, 0.0193928311924108, 0.0193928311924108]
siam score:  -0.50104976
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.48060716880758925, 0.48060716880758925, 0.0193928311924108, 0.0193928311924108]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.48060716880758925, 0.48060716880758925, 0.0193928311924108, 0.0193928311924108]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.48060716880758925, 0.48060716880758925, 0.0193928311924108, 0.0193928311924108]
siam score:  -0.5291651
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.48060716880758925, 0.48060716880758925, 0.0193928311924108, 0.0193928311924108]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.48060716880758925, 0.48060716880758925, 0.0193928311924108, 0.0193928311924108]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.48060716880758925, 0.48060716880758925, 0.0193928311924108, 0.0193928311924108]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.009579938158769546, 0.4007719031885683, 0.4007719031885683, 0.18887625546409376]
using another actor
from probs:  [0.009579938158769546, 0.4007719031885683, 0.4007719031885683, 0.18887625546409376]
maxi score, test score, baseline:  -0.9641857142857143 -1.0 -0.9641857142857143
probs:  [0.011899602355655675, 0.23964780879807196, 0.5088047800482004, 0.23964780879807196]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.015937166851009793, 0.3280209443829968, 0.3280209443829968, 0.3280209443829968]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.015937166851009793, 0.3280209443829968, 0.3280209443829968, 0.3280209443829968]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.015937166851009793, 0.3280209443829968, 0.3280209443829968, 0.3280209443829968]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.015937166851009793, 0.3280209443829968, 0.3280209443829968, 0.3280209443829968]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.022754934898148404, 0.4772450651018516, 0.022754934898148404, 0.4772450651018516]
from probs:  [0.24051228881977327, 0.506168201866121, 0.24051228881977327, 0.012807220494332533]
maxi score, test score, baseline:  -0.9654172413793104 -1.0 -0.9654172413793104
probs:  [0.3276322189095848, 0.3276322189095848, 0.3276322189095848, 0.017103343271245495]
maxi score, test score, baseline:  -0.9665666666666667 -1.0 -0.9665666666666667
probs:  [0.32763223681259196, 0.32763223681259196, 0.32763223681259196, 0.017103289562224108]
maxi score, test score, baseline:  -0.9665666666666667 -1.0 -0.9665666666666667
probs:  [0.32763223681259196, 0.32763223681259196, 0.32763223681259196, 0.017103289562224108]
siam score:  -0.55907327
40 19
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.3276322535028491, 0.3276322535028491, 0.3276322535028491, 0.01710323949145291]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.39890709461149443, 0.19112975329313034, 0.39890709461149443, 0.01105605748388076]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.39890709461149443, 0.19112975329313034, 0.39890709461149443, 0.01105605748388076]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.39890709461149443, 0.19112975329313034, 0.39890709461149443, 0.01105605748388076]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.39890709461149443, 0.19112975329313034, 0.39890709461149443, 0.01105605748388076]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.39890709461149443, 0.19112975329313034, 0.39890709461149443, 0.01105605748388076]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.39890709461149443, 0.19112975329313034, 0.39890709461149443, 0.01105605748388076]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.39890709461149443, 0.19112975329313034, 0.39890709461149443, 0.01105605748388076]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.6526708760632062, 0.31238562868584896, 0.017471747625472444, 0.017471747625472444]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.4844677136188372, 0.2547850553799763, 0.005962175621210161, 0.2547850553799763]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.4614403567346458, 0.3252103282344713, 0.00734026173406421, 0.20600905329681868]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.4614403567346458, 0.3252103282344713, 0.00734026173406421, 0.20600905329681868]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
siam score:  -0.5692867
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.4614403567346458, 0.3252103282344713, 0.00734026173406421, 0.20600905329681868]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.4614403567346458, 0.3252103282344713, 0.00734026173406421, 0.20600905329681868]
siam score:  -0.58484197
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.4614403567346458, 0.3252103282344713, 0.00734026173406421, 0.20600905329681868]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.4614403567346458, 0.3252103282344713, 0.00734026173406421, 0.20600905329681868]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.4614403567346458, 0.3252103282344713, 0.00734026173406421, 0.20600905329681868]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.4614403567346458, 0.3252103282344713, 0.00734026173406421, 0.20600905329681868]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.4614403567346458, 0.3252103282344713, 0.00734026173406421, 0.20600905329681868]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.5158031141826671, 0.3634889701004645, 0.00808930057532547, 0.11261861514154287]
47 24
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.5761656948477395, 0.4059922888402231, 0.00892100815601867, 0.00892100815601867]
maxi score, test score, baseline:  -0.967641935483871 -1.0 -0.967641935483871
probs:  [0.5761656948477395, 0.4059922888402231, 0.00892100815601867, 0.00892100815601867]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.96865 -1.0 -0.96865
probs:  [0.4894460018099992, 0.4894460018099992, 0.010553998190000835, 0.010553998190000835]
maxi score, test score, baseline:  -0.96865 -1.0 -0.96865
probs:  [0.4894460018099992, 0.4894460018099992, 0.010553998190000835, 0.010553998190000835]
maxi score, test score, baseline:  -0.96865 -1.0 -0.96865
probs:  [0.4894460018099992, 0.4894460018099992, 0.010553998190000835, 0.010553998190000835]
maxi score, test score, baseline:  -0.96865 -1.0 -0.96865
probs:  [0.4894460018099992, 0.4894460018099992, 0.010553998190000835, 0.010553998190000835]
first move QE:  -0.2668767334301043
maxi score, test score, baseline:  -0.96865 -1.0 -0.96865
probs:  [0.4894460018099992, 0.4894460018099992, 0.010553998190000835, 0.010553998190000835]
maxi score, test score, baseline:  -0.96865 -1.0 -0.96865
probs:  [0.4894460018099992, 0.4894460018099992, 0.010553998190000835, 0.010553998190000835]
using another actor
maxi score, test score, baseline:  -0.96865 -1.0 -0.96865
probs:  [0.4894460018099992, 0.4894460018099992, 0.010553998190000835, 0.010553998190000835]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.4840555424674864, 0.4840555424674864, 0.01594445753251359, 0.01594445753251359]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.029199746238829948, 0.91240076128351, 0.029199746238829948, 0.029199746238829948]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.029199746238829948, 0.91240076128351, 0.029199746238829948, 0.029199746238829948]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
first move QE:  -0.25641774071617307
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.3952038064824522, 0.014669692942232719, 0.194922694092863, 0.3952038064824522]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.48230893747718373, 0.017691062522816263, 0.017691062522816263, 0.48230893747718373]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.48230893747718373, 0.017691062522816263, 0.017691062522816263, 0.48230893747718373]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.48230893747718373, 0.017691062522816263, 0.017691062522816263, 0.48230893747718373]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.3148217940185545, 0.02312372093505687, 0.02312372093505687, 0.6389307641113318]
UNIT TEST: sample policy line 217 mcts : [0.2 0.  0.2 0.2 0.2 0.2 0. ]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.018972623532061108, 0.24407622111620683, 0.24407622111620683, 0.4928749342355253]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.018972623532061108, 0.24407622111620683, 0.24407622111620683, 0.4928749342355253]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.018972623532061108, 0.24407622111620683, 0.24407622111620683, 0.4928749342355253]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.018972623532061108, 0.24407622111620683, 0.24407622111620683, 0.4928749342355253]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.018972623532061108, 0.24407622111620683, 0.24407622111620683, 0.4928749342355253]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.32465391302862373, 0.32465391302862373, 0.026038260914128877, 0.32465391302862373]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.8093732639786606, 0.06354224534044645, 0.06354224534044645, 0.06354224534044645]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.8093732639786606, 0.06354224534044645, 0.06354224534044645, 0.06354224534044645]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.8093732639786606, 0.06354224534044645, 0.06354224534044645, 0.06354224534044645]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.8093732639786606, 0.06354224534044645, 0.06354224534044645, 0.06354224534044645]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.8093732639786606, 0.06354224534044645, 0.06354224534044645, 0.06354224534044645]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.8093732639786606, 0.06354224534044645, 0.06354224534044645, 0.06354224534044645]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.8093732639786606, 0.06354224534044645, 0.06354224534044645, 0.06354224534044645]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.8093732639786606, 0.06354224534044645, 0.06354224534044645, 0.06354224534044645]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.8093732639786606, 0.06354224534044645, 0.06354224534044645, 0.06354224534044645]
Printing some Q and Qe and total Qs values:  [[-0.022]
 [-0.022]
 [-0.022]
 [-0.022]
 [-0.022]
 [-0.022]
 [-0.022]] [[0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]] [[-0.044]
 [-0.044]
 [-0.044]
 [-0.044]
 [-0.044]
 [-0.044]
 [-0.044]]
UNIT TEST: sample policy line 217 mcts : [0.2 0.  0.  0.6 0.  0.  0.2]
Printing some Q and Qe and total Qs values:  [[-0.017]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]] [[-0.04 ]
 [ 0.097]
 [ 0.097]
 [ 0.097]
 [ 0.097]
 [ 0.097]
 [ 0.097]] [[-0.307]
 [-0.26 ]
 [-0.26 ]
 [-0.26 ]
 [-0.26 ]
 [-0.26 ]
 [-0.26 ]]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.028168166066116235, 0.32394394464462795, 0.32394394464462795, 0.32394394464462795]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.028168166066116235, 0.32394394464462795, 0.32394394464462795, 0.32394394464462795]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
probs:  [0.028168166066116235, 0.32394394464462795, 0.32394394464462795, 0.32394394464462795]
maxi score, test score, baseline:  -0.9695969696969697 -1.0 -0.9695969696969697
using another actor
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
using another actor
from probs:  [0.02816805290149996, 0.32394398236616667, 0.32394398236616667, 0.32394398236616667]
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
maxi score, test score, baseline:  -0.9704882352941177 -1.0 -0.9704882352941177
probs:  [0.039645309857556946, 0.46035469014244307, 0.039645309857556946, 0.46035469014244307]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.06790810293279607, 0.7962756912016117, 0.06790810293279607, 0.06790810293279607]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.06790810293279607, 0.7962756912016117, 0.06790810293279607, 0.06790810293279607]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
probs:  [0.06790810293279607, 0.7962756912016117, 0.06790810293279607, 0.06790810293279607]
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
maxi score, test score, baseline:  -0.972872972972973 -1.0 -0.972872972972973
siam score:  -0.5758886
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.06790775104915923, 0.7962767468525223, 0.06790775104915923, 0.06790775104915923]
siam score:  -0.5744803
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.3280146597870195, 0.015956020638941533, 0.3280146597870195, 0.3280146597870195]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.3280146597870195, 0.015956020638941533, 0.3280146597870195, 0.3280146597870195]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.3280146597870195, 0.015956020638941533, 0.3280146597870195, 0.3280146597870195]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.3280146597870195, 0.015956020638941533, 0.3280146597870195, 0.3280146597870195]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.3280146597870195, 0.015956020638941533, 0.3280146597870195, 0.3280146597870195]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.3280146597870195, 0.015956020638941533, 0.3280146597870195, 0.3280146597870195]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.3280146597870195, 0.015956020638941533, 0.3280146597870195, 0.3280146597870195]
maxi score, test score, baseline:  -0.9742589743589744 -1.0 -0.9742589743589744
probs:  [0.3280146597870195, 0.015956020638941533, 0.3280146597870195, 0.3280146597870195]
siam score:  -0.5597078
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
probs:  [0.32324731821264624, 0.030258045362061326, 0.32324731821264624, 0.32324731821264624]
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
probs:  [0.04245311728448695, 0.04245311728448695, 0.457546882715513, 0.457546882715513]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
probs:  [0.012950976360339806, 0.24309565950564105, 0.37197668206700957, 0.37197668206700957]
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
probs:  [0.012950976360339806, 0.24309565950564105, 0.37197668206700957, 0.37197668206700957]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
probs:  [0.012950976360339806, 0.24309565950564105, 0.37197668206700957, 0.37197668206700957]
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
probs:  [0.012950976360339806, 0.24309565950564105, 0.37197668206700957, 0.37197668206700957]
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
probs:  [0.012950976360339806, 0.24309565950564105, 0.37197668206700957, 0.37197668206700957]
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
maxi score, test score, baseline:  -0.9749 -1.0 -0.9749
probs:  [0.012950976360339806, 0.24309565950564105, 0.37197668206700957, 0.37197668206700957]
siam score:  -0.5727227
from probs:  [0.020234786547609056, 0.39060259330668706, 0.1985600268390168, 0.39060259330668706]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.020234786547609056, 0.39060259330668706, 0.1985600268390168, 0.39060259330668706]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.020234786547609056, 0.39060259330668706, 0.1985600268390168, 0.39060259330668706]
siam score:  -0.60036343
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.020234786547609056, 0.39060259330668706, 0.1985600268390168, 0.39060259330668706]
first move QE:  -0.163954821026048
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.020234786547609056, 0.39060259330668706, 0.1985600268390168, 0.39060259330668706]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.020234786547609056, 0.39060259330668706, 0.1985600268390168, 0.39060259330668706]
first move QE:  -0.163954821026048
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.020234786547609056, 0.39060259330668706, 0.1985600268390168, 0.39060259330668706]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.020234786547609056, 0.39060259330668706, 0.1985600268390168, 0.39060259330668706]
maxi score, test score, baseline:  -0.9760904761904762 -1.0 -0.9760904761904762
probs:  [0.020234786547609056, 0.39060259330668706, 0.1985600268390168, 0.39060259330668706]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
main train batch thing paused
add a thread
Adding thread: now have 4 threads
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.015]
 [-0.067]
 [-0.019]
 [-0.02 ]
 [-0.018]
 [-0.016]
 [-0.016]] [[-0.071]
 [-0.063]
 [-0.139]
 [-0.084]
 [-0.083]
 [-0.079]
 [-0.072]] [[-0.342]
 [-0.438]
 [-0.416]
 [-0.364]
 [-0.358]
 [-0.352]
 [-0.344]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9771727272727273 -1.0 -0.9771727272727273
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.032309953319244154, 0.3225633488935853, 0.3225633488935853, 0.3225633488935853]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
probs:  [0.032309953319244154, 0.3225633488935853, 0.3225633488935853, 0.3225633488935853]
maxi score, test score, baseline:  -0.9776777777777778 -1.0 -0.9776777777777778
main train batch thing paused
add a thread
Adding thread: now have 5 threads
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
probs:  [0.020912344516763947, 0.390089573496943, 0.19890850848935013, 0.390089573496943]
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
Printing some Q and Qe and total Qs values:  [[-0.021]
 [-0.022]
 [-0.022]
 [-0.022]
 [-0.027]
 [-0.022]
 [-0.022]] [[0.184]
 [0.206]
 [0.074]
 [0.084]
 [0.008]
 [0.034]
 [0.065]] [[-0.754]
 [-0.732]
 [-0.864]
 [-0.855]
 [-0.94 ]
 [-0.905]
 [-0.874]]
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
probs:  [0.020912344516763947, 0.390089573496943, 0.19890850848935013, 0.390089573496943]
siam score:  -0.5848478
main train batch thing paused
add a thread
Adding thread: now have 6 threads
using another actor
siam score:  -0.5856816
94 43
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
probs:  [0.3154076625171446, 0.6172891818270342, 0.03365157782791069, 0.03365157782791069]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
probs:  [0.3154076625171446, 0.6172891818270342, 0.03365157782791069, 0.03365157782791069]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
probs:  [0.3154076625171446, 0.6172891818270342, 0.03365157782791069, 0.03365157782791069]
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
probs:  [0.3233662965690611, 0.49204529733352653, 0.01865584357518629, 0.16593256252222607]
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
probs:  [0.19689741765681434, 0.5842339006306413, 0.021971264055730137, 0.19689741765681434]
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
probs:  [0.19689741765681434, 0.5842339006306413, 0.021971264055730137, 0.19689741765681434]
using explorer policy with actor:  1
main train batch thing paused
using explorer policy with actor:  1
from probs:  [0.03465192574753184, 0.6153658338440753, 0.03465192574753184, 0.315330314660861]
maxi score, test score, baseline:  -0.9781608695652174 -1.0 -0.9781608695652174
probs:  [0.08171274797302591, 0.08171274797302591, 0.08171274797302591, 0.7548617560809222]
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.08171258147799229, 0.08171258147799229, 0.08171258147799229, 0.754862255566023]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9786234042553191 -1.0 -0.9786234042553191
probs:  [0.08171258147799229, 0.08171258147799229, 0.08171258147799229, 0.754862255566023]
main train batch thing paused
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.3212320564895627, 0.3212320564895627, 0.3212320564895627, 0.036303830531311795]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.3212320564895627, 0.3212320564895627, 0.3212320564895627, 0.036303830531311795]
siam score:  -0.58242583
Printing some Q and Qe and total Qs values:  [[-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]] [[ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-0.167]
 [ 0.   ]
 [-0.142]
 [ 0.   ]] [[-1.138]
 [-1.138]
 [-1.138]
 [-1.248]
 [-1.138]
 [-1.233]
 [-1.138]]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.3212320564895627, 0.3212320564895627, 0.3212320564895627, 0.036303830531311795]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.36995085465009614, 0.36995085465009614, 0.24446380670845735, 0.01563448399135023]
Printing some Q and Qe and total Qs values:  [[-0.023]
 [-0.023]
 [-0.023]
 [-0.023]
 [-0.023]
 [-0.023]
 [-0.023]] [[0.726]
 [0.726]
 [0.726]
 [0.726]
 [0.726]
 [0.726]
 [0.726]] [[-0.765]
 [-0.765]
 [-0.765]
 [-0.765]
 [-0.765]
 [-0.765]
 [-0.765]]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.36995085465009614, 0.36995085465009614, 0.24446380670845735, 0.01563448399135023]
Printing some Q and Qe and total Qs values:  [[-0.108]
 [-0.108]
 [-0.108]
 [-0.108]
 [-0.108]
 [-0.108]
 [-0.108]] [[1.027]
 [1.027]
 [1.027]
 [1.027]
 [1.027]
 [1.027]
 [1.027]] [[0.136]
 [0.136]
 [0.136]
 [0.136]
 [0.136]
 [0.136]
 [0.136]]
104 48
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.42313582548281453, 0.2795597750824317, 0.2795597750824317, 0.017744624352322044]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.42313582548281453, 0.2795597750824317, 0.2795597750824317, 0.017744624352322044]
main train batch thing paused
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.41901481886422565, 0.14387441606199777, 0.41901481886422565, 0.01809594620955105]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.41901481886422565, 0.14387441606199777, 0.41901481886422565, 0.01809594620955105]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.41901481886422565, 0.14387441606199777, 0.41901481886422565, 0.01809594620955105]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.479432540959302, 0.020567459040697997, 0.479432540959302, 0.020567459040697997]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.479432540959302, 0.020567459040697997, 0.479432540959302, 0.020567459040697997]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.479432540959302, 0.020567459040697997, 0.479432540959302, 0.020567459040697997]
Printing some Q and Qe and total Qs values:  [[0.325]
 [0.319]
 [0.319]
 [0.319]
 [0.319]
 [0.319]
 [0.319]] [[-0.087]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]] [[0.325]
 [0.319]
 [0.319]
 [0.319]
 [0.319]
 [0.319]
 [0.319]]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.479432540959302, 0.020567459040697997, 0.479432540959302, 0.020567459040697997]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.479432540959302, 0.020567459040697997, 0.479432540959302, 0.020567459040697997]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.3787306332720438, 0.024375341684482087, 0.572518683358992, 0.024375341684482087]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
probs:  [0.3787306332720438, 0.024375341684482087, 0.572518683358992, 0.024375341684482087]
maxi score, test score, baseline:  -0.9790666666666666 -1.0 -0.9790666666666666
using explorer policy with actor:  1
siam score:  -0.5723774
using another actor
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.319947653615919, 0.319947653615919, 0.319947653615919, 0.040157039152242974]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.4445448606336734, 0.4445448606336734, 0.05545513936632662, 0.05545513936632662]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.24692885536670972, 0.4741935582301861, 0.0319487310363945, 0.24692885536670972]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.24692885536670972, 0.4741935582301861, 0.0319487310363945, 0.24692885536670972]
Printing some Q and Qe and total Qs values:  [[-0.058]
 [-0.092]
 [-0.028]
 [-0.021]
 [-0.021]
 [-0.033]
 [-0.03 ]] [[ 0.014]
 [ 0.071]
 [-0.023]
 [-0.048]
 [ 0.005]
 [ 0.022]
 [-0.001]] [[-0.156]
 [-0.147]
 [-0.145]
 [-0.165]
 [-0.093]
 [-0.094]
 [-0.12 ]]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.04046846654530941, 0.6044411921055977, 0.04046846654530941, 0.31462187480378356]
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.04046846654530941, 0.6044411921055977, 0.04046846654530941, 0.31462187480378356]
Printing some Q and Qe and total Qs values:  [[-0.017]
 [-0.031]
 [-0.024]
 [-0.022]
 [-0.022]
 [-0.022]
 [-0.021]] [[0.063]
 [0.073]
 [0.036]
 [0.174]
 [0.052]
 [0.052]
 [0.332]] [[-1.597]
 [-1.618]
 [-1.627]
 [-1.533]
 [-1.613]
 [-1.613]
 [-1.425]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9794918367346939 -1.0 -0.9794918367346939
probs:  [0.04046846654530941, 0.6044411921055977, 0.04046846654530941, 0.31462187480378356]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.040468258275208245, 0.6044415444129655, 0.040468258275208245, 0.31462193903661795]
siam score:  -0.5848206
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.040468258275208245, 0.6044415444129655, 0.040468258275208245, 0.31462193903661795]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.0566674782340005, 0.4433325217659995, 0.0566674782340005, 0.4433325217659995]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.0566674782340005, 0.4433325217659995, 0.0566674782340005, 0.4433325217659995]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.09199393569868801, 0.7240181929039361, 0.09199393569868801, 0.09199393569868801]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.09199393569868801, 0.7240181929039361, 0.09199393569868801, 0.09199393569868801]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.09199393569868801, 0.7240181929039361, 0.09199393569868801, 0.09199393569868801]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.09199393569868801, 0.7240181929039361, 0.09199393569868801, 0.09199393569868801]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.09199393569868801, 0.7240181929039361, 0.09199393569868801, 0.09199393569868801]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
probs:  [0.27973846454773077, 0.42032029695518386, 0.27973846454773077, 0.0202027739493545]
maxi score, test score, baseline:  -0.9802921568627451 -1.0 -0.9802921568627451
Printing some Q and Qe and total Qs values:  [[0.312]
 [0.197]
 [0.289]
 [0.297]
 [0.289]
 [0.3  ]
 [0.304]] [[-0.261]
 [ 0.001]
 [-0.156]
 [-0.113]
 [-0.156]
 [-0.131]
 [-0.095]] [[0.312]
 [0.197]
 [0.289]
 [0.297]
 [0.289]
 [0.3  ]
 [0.304]]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.3255469517903813, 0.3255469517903813, 0.3255469517903813, 0.023359144628855917]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.38539400510124516, 0.20172909383346926, 0.38539400510124516, 0.027482895964040317]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.38539400510124516, 0.20172909383346926, 0.38539400510124516, 0.027482895964040317]
maxi score, test score, baseline:  -0.9806692307692307 -1.0 -0.9806692307692307
probs:  [0.38539400510124516, 0.20172909383346926, 0.38539400510124516, 0.027482895964040317]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.38539404812152456, 0.20172907849580438, 0.38539404812152456, 0.02748282526114651]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.38539404812152456, 0.20172907849580438, 0.38539404812152456, 0.02748282526114651]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.38539404812152456, 0.20172907849580438, 0.38539404812152456, 0.02748282526114651]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.38539404812152456, 0.20172907849580438, 0.38539404812152456, 0.02748282526114651]
maxi score, test score, baseline:  -0.9810320754716981 -1.0 -0.9810320754716981
probs:  [0.38539404812152456, 0.20172907849580438, 0.38539404812152456, 0.02748282526114651]
Printing some Q and Qe and total Qs values:  [[-0.017]
 [-0.064]
 [-0.02 ]
 [-0.015]
 [-0.016]
 [-0.014]
 [-0.018]] [[-0.067]
 [-0.108]
 [-0.111]
 [-0.185]
 [-0.038]
 [-0.06 ]
 [-0.015]] [[-0.079]
 [-0.188]
 [-0.101]
 [-0.115]
 [-0.068]
 [-0.071]
 [-0.065]]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.4669010497456696, 0.03309895025433042, 0.4669010497456696, 0.03309895025433042]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.3143197457663402, 0.042339106525814955, 0.6010020411820298, 0.042339106525814955]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.3143197457663402, 0.042339106525814955, 0.6010020411820298, 0.042339106525814955]
siam score:  -0.62073755
using explorer policy with actor:  1
first move QE:  -0.11834126068121222
in main func line 156:  125
from probs:  [0.3143197457663402, 0.042339106525814955, 0.6010020411820298, 0.042339106525814955]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
Printing some Q and Qe and total Qs values:  [[-0.044]
 [-0.035]
 [-0.035]
 [-0.035]
 [-0.035]
 [-0.035]
 [-0.028]] [[-0.001]
 [-0.005]
 [-0.005]
 [-0.001]
 [-0.005]
 [-0.005]
 [ 0.018]] [[-0.13 ]
 [-0.113]
 [-0.113]
 [-0.112]
 [-0.113]
 [-0.113]
 [-0.092]]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.03422485393584121, 0.24719772537579046, 0.4713796953125779, 0.24719772537579046]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.02117206483769046, 0.2797731514151701, 0.4192816323319694, 0.2797731514151701]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.024458352558362886, 0.3251805491472124, 0.3251805491472124, 0.3251805491472124]
Printing some Q and Qe and total Qs values:  [[-0.03 ]
 [-0.042]
 [-0.034]
 [-0.031]
 [-0.03 ]
 [-0.03 ]
 [-0.031]] [[-0.023]
 [ 0.093]
 [-0.031]
 [-0.05 ]
 [-0.062]
 [-0.027]
 [-0.018]] [[-1.274]
 [-1.18 ]
 [-1.288]
 [-1.303]
 [-1.312]
 [-1.276]
 [-1.27 ]]
from probs:  [0.02875344255111241, 0.20219295492310463, 0.38452680126289146, 0.38452680126289146]
siam score:  -0.5981534
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.014455754099667898, 0.26670908838194557, 0.3594175787591932, 0.3594175787591932]
Printing some Q and Qe and total Qs values:  [[0.142]
 [0.13 ]
 [0.201]
 [0.429]
 [0.261]
 [0.365]
 [0.303]] [[0.992]
 [0.029]
 [0.145]
 [0.564]
 [0.363]
 [0.511]
 [0.657]] [[0.142]
 [0.13 ]
 [0.201]
 [0.429]
 [0.261]
 [0.365]
 [0.303]]
maxi score, test score, baseline:  -0.9813814814814815 -1.0 -0.9813814814814815
probs:  [0.014455754099667898, 0.26670908838194557, 0.3594175787591932, 0.3594175787591932]
maxi score, test score, baseline:  -0.9817181818181818 -1.0 -0.9817181818181818
probs:  [0.01445571528702876, 0.26670909113524494, 0.3594175967888632, 0.3594175967888632]
maxi score, test score, baseline:  -0.9817181818181818 -1.0 -0.9817181818181818
maxi score, test score, baseline:  -0.9817181818181818 -1.0 -0.9817181818181818
from probs:  [0.015837114986715157, 0.2939798311953883, 0.2939798311953883, 0.3962032226225082]
maxi score, test score, baseline:  -0.9820428571428571 -1.0 -0.9820428571428571
probs:  [0.01583707400252346, 0.29397983889292684, 0.29397983889292684, 0.3962032482116229]
maxi score, test score, baseline:  -0.9820428571428571 -1.0 -0.9820428571428571
probs:  [0.01583707400252346, 0.29397983889292684, 0.29397983889292684, 0.3962032482116229]
siam score:  -0.6144507
maxi score, test score, baseline:  -0.9820428571428571 -1.0 -0.9820428571428571
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9820428571428571 -1.0 -0.9820428571428571
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.030009903723199678, 0.3836781924744196, 0.20263371132796107, 0.3836781924744196]
maxi score, test score, baseline:  -0.9826586206896551 -1.0 -0.9826586206896551
probs:  [0.030009903723199678, 0.3836781924744196, 0.20263371132796107, 0.3836781924744196]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
136 66
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.03000977091231033, 0.38367827317768677, 0.2026336827323161, 0.38367827317768677]
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.03645513051167654, 0.24742717024712838, 0.24742717024712838, 0.46869052899406666]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.03645513051167654, 0.24742717024712838, 0.24742717024712838, 0.46869052899406666]
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.03645513051167654, 0.24742717024712838, 0.24742717024712838, 0.46869052899406666]
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.03645513051167654, 0.24742717024712838, 0.24742717024712838, 0.46869052899406666]
line 256 mcts: sample exp_bonus 0.033346238789560424
using another actor
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.04598438328640162, 0.04598438328640162, 0.3136528724146427, 0.594378361012554]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.04598438328640162, 0.04598438328640162, 0.3136528724146427, 0.594378361012554]
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
probs:  [0.04598438328640162, 0.04598438328640162, 0.3136528724146427, 0.594378361012554]
maxi score, test score, baseline:  -0.9832333333333333 -1.0 -0.9832333333333333
siam score:  -0.63339925
Printing some Q and Qe and total Qs values:  [[-0.026]
 [-0.026]
 [-0.026]
 [-0.026]
 [-0.026]
 [-0.026]
 [-0.026]] [[0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]] [[-1.181]
 [-1.181]
 [-1.181]
 [-1.181]
 [-1.181]
 [-1.181]
 [-1.181]]
using explorer policy with actor:  1
siam score:  -0.6345712
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.10110072272485209, 0.10110072272485209, 0.6966978318254439, 0.10110072272485209]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.2474963376743293, 0.03718870231796187, 0.46781862233337945, 0.2474963376743293]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.2474963376743293, 0.03718870231796187, 0.46781862233337945, 0.2474963376743293]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.2474963376743293, 0.03718870231796187, 0.46781862233337945, 0.2474963376743293]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.2474963376743293, 0.03718870231796187, 0.46781862233337945, 0.2474963376743293]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.2474963376743293, 0.03718870231796187, 0.46781862233337945, 0.2474963376743293]
maxi score, test score, baseline:  -0.9835065573770492 -1.0 -0.9835065573770492
probs:  [0.2797966101860142, 0.02308735319881393, 0.4173194264291576, 0.2797966101860142]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.2797966167653346, 0.023087303094759964, 0.4173194633745708, 0.2797966167653346]
Printing some Q and Qe and total Qs values:  [[-0.019]
 [-0.045]
 [-0.018]
 [-0.018]
 [-0.018]
 [-0.018]
 [-0.017]] [[-0.09 ]
 [ 0.008]
 [-0.021]
 [-0.101]
 [-0.021]
 [-0.021]
 [-0.02 ]] [[-0.043]
 [-0.03 ]
 [ 0.004]
 [-0.048]
 [ 0.004]
 [ 0.004]
 [ 0.007]]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
Printing some Q and Qe and total Qs values:  [[0.299]
 [0.29 ]
 [0.308]
 [0.308]
 [0.303]
 [0.303]
 [0.3  ]] [[-0.064]
 [ 0.006]
 [-0.063]
 [-0.075]
 [-0.045]
 [-0.056]
 [-0.031]] [[0.299]
 [0.29 ]
 [0.308]
 [0.308]
 [0.303]
 [0.303]
 [0.3  ]]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.3766045022940564, 0.03075805700297613, 0.5618793836999914, 0.03075805700297613]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.3766045022940564, 0.03075805700297613, 0.5618793836999914, 0.03075805700297613]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.3766045022940564, 0.03075805700297613, 0.5618793836999914, 0.03075805700297613]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.4624405622157557, 0.03755943778424434, 0.4624405622157557, 0.03755943778424434]
maxi score, test score, baseline:  -0.9837709677419355 -1.0 -0.9837709677419355
probs:  [0.4624405622157557, 0.03755943778424434, 0.4624405622157557, 0.03755943778424434]
maxi score, test score, baseline:  -0.9840269841269841 -1.0 -0.9840269841269841
probs:  [0.46244063732998864, 0.03755936267001141, 0.46244063732998864, 0.03755936267001141]
maxi score, test score, baseline:  -0.9840269841269841 -1.0 -0.9840269841269841
probs:  [0.46244063732998864, 0.03755936267001141, 0.46244063732998864, 0.03755936267001141]
maxi score, test score, baseline:  -0.9840269841269841 -1.0 -0.9840269841269841
maxi score, test score, baseline:  -0.9840269841269841 -1.0 -0.9840269841269841
probs:  [0.41432172709250364, 0.02342422652002834, 0.41432172709250364, 0.14793231929496434]
maxi score, test score, baseline:  -0.9840269841269841 -1.0 -0.9840269841269841
probs:  [0.41432172709250364, 0.02342422652002834, 0.41432172709250364, 0.14793231929496434]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.4143217623545307, 0.02342417789881905, 0.4143217623545307, 0.14793229739211966]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.3220029608381599, 0.026977594566395337, 0.4798072265184084, 0.17121221807703632]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.3824366997095979, 0.03186896518419133, 0.3824366997095979, 0.20325763539661296]
Printing some Q and Qe and total Qs values:  [[0.393]
 [0.373]
 [0.522]
 [0.513]
 [0.523]
 [0.517]
 [0.502]] [[0.399]
 [0.181]
 [0.118]
 [0.035]
 [0.002]
 [0.   ]
 [0.068]] [[0.393]
 [0.373]
 [0.522]
 [0.513]
 [0.523]
 [0.517]
 [0.502]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.3824366997095979, 0.03186896518419133, 0.3824366997095979, 0.20325763539661296]
Printing some Q and Qe and total Qs values:  [[-0.027]
 [-0.028]
 [-0.027]
 [-0.029]
 [-0.026]
 [-0.03 ]
 [-0.032]] [[-0.332]
 [-0.053]
 [-0.281]
 [-0.375]
 [-0.643]
 [-0.315]
 [-0.272]] [[-1.479]
 [-1.389]
 [-1.462]
 [-1.498]
 [-1.582]
 [-1.48 ]
 [-1.469]]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.3824366997095979, 0.03186896518419133, 0.3824366997095979, 0.20325763539661296]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.3824366997095979, 0.03186896518419133, 0.3824366997095979, 0.20325763539661296]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.466108467178815, 0.038641169462477615, 0.24762518167935368, 0.24762518167935368]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.466108467178815, 0.038641169462477615, 0.24762518167935368, 0.24762518167935368]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.466108467178815, 0.038641169462477615, 0.24762518167935368, 0.24762518167935368]
main train batch thing paused
Printing some Q and Qe and total Qs values:  [[-0.029]
 [-0.029]
 [-0.026]
 [-0.027]
 [-0.027]
 [-0.028]
 [-0.029]] [[-0.005]
 [-0.018]
 [ 0.002]
 [ 0.003]
 [-0.411]
 [ 0.194]
 [ 0.117]] [[-1.328]
 [-1.332]
 [-1.321]
 [-1.322]
 [-1.459]
 [-1.26 ]
 [-1.287]]
main train batch thing paused
Starting evaluation
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.3820305420256574, 0.20345685928591925, 0.032482056662765935, 0.3820305420256574]
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
probs:  [0.3820305420256574, 0.20345685928591925, 0.032482056662765935, 0.3820305420256574]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.984275 -1.0 -0.984275
Printing some Q and Qe and total Qs values:  [[0.689]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]] [[-0.001]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]] [[0.689]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]]
using explorer policy with actor:  1
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9849746268656716 -1.0 -0.9849746268656716
probs:  [0.3239246760838033, 0.3239246760838033, 0.028225971748590078, 0.3239246760838033]
using explorer policy with actor:  1
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9851941176470589 -1.0 -0.9851941176470589
probs:  [0.3239246938156519, 0.3239246938156519, 0.02822591855304419, 0.3239246938156519]
Printing some Q and Qe and total Qs values:  [[0.254]
 [0.178]
 [0.21 ]
 [0.176]
 [0.072]
 [0.017]
 [0.151]] [[-0.002]
 [-0.006]
 [-0.003]
 [-0.003]
 [-0.008]
 [-0.02 ]
 [-0.01 ]] [[0.254]
 [0.178]
 [0.21 ]
 [0.176]
 [0.072]
 [0.017]
 [0.151]]
Printing some Q and Qe and total Qs values:  [[-0.075]
 [-0.085]
 [-0.073]
 [-0.073]
 [-0.073]
 [-0.078]
 [-0.073]] [[0.011]
 [0.014]
 [0.011]
 [0.011]
 [0.011]
 [0.011]
 [0.011]] [[-1.17 ]
 [-1.189]
 [-1.167]
 [-1.167]
 [-1.167]
 [-1.176]
 [-1.168]]
Printing some Q and Qe and total Qs values:  [[-0.068]
 [-0.07 ]
 [-0.07 ]
 [-0.07 ]
 [-0.07 ]
 [-0.07 ]
 [-0.07 ]] [[0.006]
 [0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.008]] [[-1.072]
 [-1.075]
 [-1.075]
 [-1.075]
 [-1.075]
 [-1.075]
 [-1.075]]
using explorer policy with actor:  0
from probs:  [0.323924727726462, 0.323924727726462, 0.02822581682061401, 0.323924727726462]
using another actor
maxi score, test score, baseline:  -0.9858154929577465 -1.0 -0.9858154929577465
probs:  [0.24774273350668738, 0.24774273350668738, 0.040074216121880786, 0.46444031686474446]
Printing some Q and Qe and total Qs values:  [[0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]] [[-0.013]
 [-0.013]
 [-0.013]
 [-0.013]
 [-0.013]
 [-0.013]
 [-0.013]] [[0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]]
maxi score, test score, baseline:  -0.9858154929577465 -1.0 -0.9858154929577465
Printing some Q and Qe and total Qs values:  [[-0.07]
 [-0.07]
 [-0.07]
 [-0.07]
 [-0.07]
 [-0.07]
 [-0.07]] [[0.009]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.01 ]
 [0.01 ]] [[-1.372]
 [-1.372]
 [-1.372]
 [-1.372]
 [-1.372]
 [-1.372]
 [-1.372]]
maxi score, test score, baseline:  -0.9862013698630137 -1.0 -0.9862013698630137
probs:  [0.24774273214445922, 0.24774273214445922, 0.040074089434687016, 0.46444044627639447]
siam score:  -0.70914674
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9870794871794872 -1.0 -0.9870794871794872
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  305000
maxi score, test score, baseline:  -0.9870794871794872 -1.0 -0.9870794871794872
probs:  [0.05036779882892362, 0.3127415489394816, 0.05036779882892362, 0.5865228534026712]
line 256 mcts: sample exp_bonus -0.00037788282779910336
maxi score, test score, baseline:  -0.9870794871794872 -1.0 -0.9870794871794872
probs:  [0.05036779882892362, 0.3127415489394816, 0.05036779882892362, 0.5865228534026712]
siam score:  -0.7589886
maxi score, test score, baseline:  -0.9881352941176471 -1.0 -0.9881352941176471
probs:  [0.033213542156070176, 0.37560588759197727, 0.033213542156070176, 0.5579670280958825]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.03321350338449884, 0.37560591005619165, 0.03321350338449884, 0.5579670831748107]
siam score:  -0.7850716
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.03321350338449884, 0.37560591005619165, 0.03321350338449884, 0.5579670831748107]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.03321350338449884, 0.37560591005619165, 0.03321350338449884, 0.5579670831748107]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.03321350338449884, 0.37560591005619165, 0.03321350338449884, 0.5579670831748107]
siam score:  -0.79591507
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.03321350338449884, 0.37560591005619165, 0.03321350338449884, 0.5579670831748107]
Printing some Q and Qe and total Qs values:  [[-0.104]
 [-0.109]
 [-0.104]
 [-0.103]
 [-0.103]
 [-0.104]
 [-0.104]] [[-0.006]
 [-0.006]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]] [[-0.917]
 [-0.926]
 [-0.916]
 [-0.915]
 [-0.915]
 [-0.917]
 [-0.917]]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
STARTED EXPV TRAINING ON FRAME NO.  10768
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
Printing some Q and Qe and total Qs values:  [[-0.105]
 [-0.108]
 [-0.106]
 [-0.103]
 [-0.103]
 [-0.1  ]
 [-0.099]] [[-0.006]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.007]
 [-0.008]
 [-0.009]] [[-0.376]
 [-0.381]
 [-0.377]
 [-0.372]
 [-0.373]
 [-0.369]
 [-0.367]]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.040434279409147414, 0.4595657205908526, 0.040434279409147414, 0.4595657205908526]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.040434279409147414, 0.4595657205908526, 0.040434279409147414, 0.4595657205908526]
166 71
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.25, 0.25, 0.25, 0.25]
Printing some Q and Qe and total Qs values:  [[-0.12]
 [-0.12]
 [-0.12]
 [-0.12]
 [-0.12]
 [-0.12]
 [-0.12]] [[-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]] [[-0.959]
 [-0.959]
 [-0.959]
 [-0.959]
 [-0.959]
 [-0.959]
 [-0.959]]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.25, 0.25, 0.25, 0.25]
using explorer policy with actor:  0
170 71
from probs:  [0.31578923840154577, 0.31578923840154577, 0.31578923840154577, 0.052632284795362715]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.07117397361991591, 0.4288260263800841, 0.4288260263800841, 0.07117397361991591]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.07117397361991591, 0.4288260263800841, 0.4288260263800841, 0.07117397361991591]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.2042157281705716, 0.38044198200459867, 0.38044198200459867, 0.03490030782023119]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.2042157281705716, 0.38044198200459867, 0.38044198200459867, 0.03490030782023119]
maxi score, test score, baseline:  -0.9882720930232558 -1.0 -0.9882720930232558
probs:  [0.24790089445190733, 0.24790089445190733, 0.4620096603573997, 0.04218855073878566]
maxi score, test score, baseline:  -0.9884057471264368 -1.0 -0.9884057471264368
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
probs:  [0.31551063802489815, 0.31551063802489815, 0.31551063802489815, 0.05346808592530543]
maxi score, test score, baseline:  -0.9886640449438202 -1.0 -0.9886640449438202
probs:  [0.31551063802489815, 0.31551063802489815, 0.31551063802489815, 0.05346808592530543]
rdn probs:  [0.31551063802489815, 0.31551063802489815, 0.31551063802489815, 0.05346808592530543]
using explorer policy with actor:  1
first move QE:  -0.10231112061791964
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.00026291830337563706
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.4612170628809652, 0.24794934890406825, 0.24794934890406825, 0.0428842393108982]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.4612170628809652, 0.24794934890406825, 0.24794934890406825, 0.0428842393108982]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.4612170628809652, 0.24794934890406825, 0.24794934890406825, 0.0428842393108982]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.5805358324524034, 0.05374434948138439, 0.31197546858482794, 0.05374434948138439]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.5805358324524034, 0.05374434948138439, 0.31197546858482794, 0.05374434948138439]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.5805358324524034, 0.05374434948138439, 0.31197546858482794, 0.05374434948138439]
Printing some Q and Qe and total Qs values:  [[0.443]
 [0.443]
 [0.443]
 [0.443]
 [0.443]
 [0.443]
 [0.443]] [[-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]] [[0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.826]]
maxi score, test score, baseline:  -0.9887888888888889 -1.0 -0.9887888888888889
probs:  [0.5805358324524034, 0.05374434948138439, 0.31197546858482794, 0.05374434948138439]
Printing some Q and Qe and total Qs values:  [[0.622]
 [0.603]
 [0.623]
 [0.623]
 [0.624]
 [0.624]
 [0.625]] [[-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]
 [-0.003]] [[1.214]
 [1.175]
 [1.216]
 [1.216]
 [1.217]
 [1.218]
 [1.219]]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.47508756233612154, 0.03066600979953296, 0.32113761276462416, 0.1731088150997214]
maxi score, test score, baseline:  -0.9889109890109891 -1.0 -0.9889109890109891
probs:  [0.47508756233612154, 0.03066600979953296, 0.32113761276462416, 0.1731088150997214]
siam score:  -0.8394699
using explorer policy with actor:  1
from probs:  [0.49089967603286205, 0.019867744747606823, 0.29161693587371523, 0.19761564334581597]
maxi score, test score, baseline:  -0.9890304347826087 -1.0 -0.9890304347826087
line 256 mcts: sample exp_bonus -0.003448389008585443
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.989147311827957 -1.0 -0.989147311827957
probs:  [0.6243422987522182, 0.17189980817399728, 0.17189980817399728, 0.031858084899787274]
maxi score, test score, baseline:  -0.989147311827957 -1.0 -0.989147311827957
probs:  [0.6243422987522182, 0.17189980817399728, 0.17189980817399728, 0.031858084899787274]
line 256 mcts: sample exp_bonus -0.002093578097412154
Printing some Q and Qe and total Qs values:  [[0.045]
 [0.004]
 [0.046]
 [0.048]
 [0.049]
 [0.05 ]
 [0.048]] [[-0.]
 [-0.]
 [-0.]
 [-0.]
 [-0.]
 [-0.]
 [-0.]] [[0.045]
 [0.004]
 [0.046]
 [0.048]
 [0.049]
 [0.05 ]
 [0.048]]
maxi score, test score, baseline:  -0.9892617021276596 -1.0 -0.9892617021276596
maxi score, test score, baseline:  -0.9892617021276596 -1.0 -0.9892617021276596
probs:  [0.3141513262467308, 0.3141513262467308, 0.3141513262467308, 0.0575460212598074]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.308]
 [0.323]
 [0.308]
 [0.309]
 [0.311]
 [0.314]
 [0.318]] [[0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.004]
 [0.003]
 [0.002]] [[0.308]
 [0.323]
 [0.308]
 [0.309]
 [0.311]
 [0.314]
 [0.318]]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.0771710853317812, 0.4228289146682188, 0.4228289146682188, 0.0771710853317812]
maxi score, test score, baseline:  -0.9893736842105263 -1.0 -0.9893736842105263
probs:  [0.03843310702726893, 0.3781534226250592, 0.3781534226250592, 0.20526004772261272]
from probs:  [0.0462965604076416, 0.45737377183726613, 0.24816483387754618, 0.24816483387754618]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  False
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.05860558617075765, 0.5719929550303732, 0.31079587262811154, 0.05860558617075765]
UNIT TEST: sample policy line 217 mcts : [0.204 0.082 0.061 0.102 0.286 0.082 0.184]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.05860558617075765, 0.5719929550303732, 0.31079587262811154, 0.05860558617075765]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.05860558617075765, 0.5719929550303732, 0.31079587262811154, 0.05860558617075765]
using explorer policy with actor:  1
from probs:  [0.07813781663911683, 0.7655865500826496, 0.07813781663911683, 0.07813781663911683]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.20433455833639086, 0.55198114648516, 0.03934973684205841, 0.20433455833639086]
maxi score, test score, baseline:  -0.9894833333333334 -1.0 -0.9894833333333334
probs:  [0.31336184457536204, 0.31336184457536204, 0.05991446627391387, 0.31336184457536204]
from probs:  [0.31336184457536204, 0.31336184457536204, 0.05991446627391387, 0.31336184457536204]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus -0.012030479788634947
using another actor
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
Printing some Q and Qe and total Qs values:  [[-0.061]
 [-0.074]
 [-0.061]
 [-0.089]
 [-0.088]
 [-0.086]
 [-0.061]] [[ 0.   ]
 [-0.001]
 [ 0.   ]
 [-0.001]
 [-0.001]
 [-0.001]
 [ 0.   ]] [[-0.646]
 [-0.674]
 [-0.646]
 [-0.704]
 [-0.703]
 [-0.698]
 [-0.646]]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9896959183673469 -1.0 -0.9896959183673469
probs:  [0.3131029079969677, 0.3131029079969677, 0.3131029079969677, 0.0606912760090968]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.3131029271782513, 0.3131029271782513, 0.3131029271782513, 0.060691218465246305]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.3131029271782513, 0.3131029271782513, 0.3131029271782513, 0.060691218465246305]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
probs:  [0.3131029271782513, 0.3131029271782513, 0.3131029271782513, 0.060691218465246305]
maxi score, test score, baseline:  -0.98979898989899 -1.0 -0.98979898989899
Printing some Q and Qe and total Qs values:  [[0.057]
 [0.133]
 [0.065]
 [0.061]
 [0.068]
 [0.07 ]
 [0.071]] [[-0.074]
 [-0.072]
 [-0.073]
 [-0.074]
 [-0.073]
 [-0.073]
 [-0.074]] [[0.057]
 [0.133]
 [0.065]
 [0.061]
 [0.068]
 [0.07 ]
 [0.071]]
maxi score, test score, baseline:  -0.9899 -1.0 -0.9899
deleting a thread, now have 5 threads
Frames:  13251 train batches done:  1546 episodes:  298
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.24831049260907745, 0.0489486204802436, 0.45443039430160154, 0.24831049260907745]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
siam score:  -0.8773318
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.3128461193098463, 0.06146164207046112, 0.3128461193098463, 0.3128461193098463]
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
maxi score, test score, baseline:  -0.9903761904761905 -1.0 -0.9903761904761905
probs:  [0.3128461193098463, 0.06146164207046112, 0.3128461193098463, 0.3128461193098463]
Printing some Q and Qe and total Qs values:  [[0.557]
 [0.557]
 [0.557]
 [0.591]
 [0.557]
 [0.557]
 [0.557]] [[1.047]
 [1.047]
 [1.047]
 [0.975]
 [1.047]
 [1.047]
 [1.047]] [[0.557]
 [0.557]
 [0.557]
 [0.591]
 [0.557]
 [0.557]
 [0.557]]
deleting a thread, now have 4 threads
Frames:  13452 train batches done:  1563 episodes:  302
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
probs:  [0.418125475774278, 0.081874524225722, 0.081874524225722, 0.418125475774278]
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
probs:  [0.418125475774278, 0.081874524225722, 0.081874524225722, 0.418125475774278]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
probs:  [0.418125475774278, 0.081874524225722, 0.081874524225722, 0.418125475774278]
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
probs:  [0.418125475774278, 0.081874524225722, 0.081874524225722, 0.418125475774278]
deleting a thread, now have 3 threads
Frames:  13502 train batches done:  1581 episodes:  303
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
probs:  [0.418125475774278, 0.081874524225722, 0.081874524225722, 0.418125475774278]
maxi score, test score, baseline:  -0.9904660377358491 -1.0 -0.9904660377358491
probs:  [0.418125475774278, 0.081874524225722, 0.081874524225722, 0.418125475774278]
line 256 mcts: sample exp_bonus -0.1286012072856808
maxi score, test score, baseline:  -0.9905542056074766 -1.0 -0.9905542056074766
probs:  [0.5665630381943688, 0.06171740865563629, 0.31000214449435864, 0.06171740865563629]
using explorer policy with actor:  1
siam score:  -0.87660325
maxi score, test score, baseline:  -0.9905542056074766 -1.0 -0.9905542056074766
probs:  [0.062480131180324604, 0.062480131180324604, 0.5652361037995639, 0.3098036338397869]
214 99
line 256 mcts: sample exp_bonus 0.05432674840266293
maxi score, test score, baseline:  -0.9905542056074766 -1.0 -0.9905542056074766
first move QE:  -0.06783935703577548
in main func line 156:  216
maxi score, test score, baseline:  -0.9906407407407407 -1.0 -0.9906407407407407
probs:  [0.06373742024979291, 0.3120875265834024, 0.3120875265834024, 0.3120875265834024]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.06373736810560351, 0.3120875439647988, 0.3120875439647988, 0.3120875439647988]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.0845779985989042, 0.0845779985989042, 0.4154220014010958, 0.4154220014010958]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2484372812951431, 0.2484372812951431, 0.05153472448317389, 0.45159071292654]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
Printing some Q and Qe and total Qs values:  [[0.51 ]
 [0.463]
 [0.46 ]
 [0.476]
 [0.476]
 [0.476]
 [0.477]] [[2.73 ]
 [2.173]
 [1.786]
 [2.368]
 [2.38 ]
 [2.322]
 [2.235]] [[1.348]
 [0.697]
 [0.303]
 [0.918]
 [0.93 ]
 [0.871]
 [0.786]]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2484372812951431, 0.2484372812951431, 0.05153472448317389, 0.45159071292654]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2484372812951431, 0.2484372812951431, 0.05153472448317389, 0.45159071292654]
Printing some Q and Qe and total Qs values:  [[0.78 ]
 [0.786]
 [0.733]
 [0.724]
 [0.725]
 [0.713]
 [0.722]] [[-0.743]
 [-0.054]
 [-0.91 ]
 [-0.932]
 [-0.865]
 [-0.881]
 [-0.985]] [[0.765]
 [1.102]
 [0.64 ]
 [0.621]
 [0.654]
 [0.634]
 [0.594]]
Printing some Q and Qe and total Qs values:  [[0.105]
 [0.055]
 [0.032]
 [0.027]
 [0.069]
 [0.047]
 [0.105]] [[2.57 ]
 [1.984]
 [2.1  ]
 [2.877]
 [2.726]
 [2.998]
 [2.57 ]] [[0.85 ]
 [0.258]
 [0.318]
 [0.981]
 [0.924]
 [1.12 ]
 [0.85 ]]
siam score:  -0.8940708
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2793701979251207, 0.2793701979251207, 0.032660535354104875, 0.40859906879565383]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2793701979251207, 0.2793701979251207, 0.032660535354104875, 0.40859906879565383]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2793701979251207, 0.2793701979251207, 0.032660535354104875, 0.40859906879565383]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2793701979251207, 0.2793701979251207, 0.032660535354104875, 0.40859906879565383]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2793701979251207, 0.2793701979251207, 0.032660535354104875, 0.40859906879565383]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2793701979251207, 0.2793701979251207, 0.032660535354104875, 0.40859906879565383]
siam score:  -0.8971129
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2793701979251207, 0.2793701979251207, 0.032660535354104875, 0.40859906879565383]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.2793701979251207, 0.2793701979251207, 0.032660535354104875, 0.40859906879565383]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.31941217942935374, 0.17614296023488676, 0.037215232531161005, 0.4672296278045985]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.31941217942935374, 0.17614296023488676, 0.037215232531161005, 0.4672296278045985]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.31941217942935374, 0.17614296023488676, 0.037215232531161005, 0.4672296278045985]
221 102
from probs:  [0.32344859218008576, 0.22139065206251723, 0.02641428885283526, 0.42874646690456175]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.3590225116428371, 0.13582182210995647, 0.029218507706192783, 0.47593715854101376]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.3590225116428371, 0.13582182210995647, 0.029218507706192783, 0.47593715854101376]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.3590225116428371, 0.13582182210995647, 0.029218507706192783, 0.47593715854101376]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.028723070624384825
first move QE:  -0.032375258594448106
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.3192767325068916, 0.1763570168515858, 0.03770356136509384, 0.4666626892764288]
maxi score, test score, baseline:  -0.9907256880733946 -1.0 -0.9907256880733946
probs:  [0.3192767325068916, 0.1763570168515858, 0.03770356136509384, 0.4666626892764288]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.2484946853038702, 0.2484946853038702, 0.052803774806943725, 0.45020685458531584]
Printing some Q and Qe and total Qs values:  [[0.713]
 [0.703]
 [0.806]
 [0.812]
 [0.82 ]
 [0.822]
 [0.806]] [[0.999]
 [0.681]
 [0.783]
 [0.963]
 [1.029]
 [1.033]
 [0.978]] [[0.598]
 [0.472]
 [0.713]
 [0.785]
 [0.822]
 [0.828]
 [0.778]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.038189712895785856, 0.31914114831460916, 0.176568778102072, 0.46610036068753297]
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.038189712895785856, 0.31914114831460916, 0.176568778102072, 0.46610036068753297]
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.038189712895785856, 0.31914114831460916, 0.176568778102072, 0.46610036068753297]
Printing some Q and Qe and total Qs values:  [[0.093]
 [0.092]
 [0.092]
 [0.092]
 [0.092]
 [0.092]
 [0.092]] [[2.557]
 [2.478]
 [2.478]
 [2.478]
 [2.478]
 [2.478]
 [2.478]] [[-0.244]
 [-0.273]
 [-0.273]
 [-0.273]
 [-0.273]
 [-0.273]
 [-0.273]]
Printing some Q and Qe and total Qs values:  [[-0.002]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]] [[2.063]
 [1.861]
 [1.861]
 [1.861]
 [1.861]
 [1.861]
 [1.861]] [[-0.452]
 [-0.517]
 [-0.517]
 [-0.517]
 [-0.517]
 [-0.517]
 [-0.517]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.044627393979587204, 0.37420738447941115, 0.20695783706159043, 0.37420738447941115]
Printing some Q and Qe and total Qs values:  [[0.213]
 [0.213]
 [0.213]
 [0.213]
 [0.213]
 [0.213]
 [0.213]] [[-1.341]
 [-1.341]
 [-1.341]
 [-1.341]
 [-1.341]
 [-1.341]
 [-1.341]] [[0.213]
 [0.213]
 [0.213]
 [0.213]
 [0.213]
 [0.213]
 [0.213]]
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.030205410517747305, 0.36113209580563366, 0.2475303978709854, 0.36113209580563366]
line 256 mcts: sample exp_bonus 3.106069705982942
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.022950131121082462, 0.3545542992930168, 0.2679412702928839, 0.3545542992930168]
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.022950131121082462, 0.3545542992930168, 0.2679412702928839, 0.3545542992930168]
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.022950131121082462, 0.3545542992930168, 0.2679412702928839, 0.3545542992930168]
maxi score, test score, baseline:  -0.990809090909091 -1.0 -0.990809090909091
probs:  [0.022950131121082462, 0.3545542992930168, 0.2679412702928839, 0.3545542992930168]
230 107
maxi score, test score, baseline:  -0.990890990990991 -1.0 -0.990890990990991
probs:  [0.027572212737911522, 0.3241425957540295, 0.3241425957540295, 0.3241425957540295]
maxi score, test score, baseline:  -0.990890990990991 -1.0 -0.990890990990991
maxi score, test score, baseline:  -0.990890990990991 -1.0 -0.990890990990991
probs:  [0.030596539839050054, 0.3609161403765687, 0.3609161403765687, 0.2475711794078125]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.990890990990991 -1.0 -0.990890990990991
Printing some Q and Qe and total Qs values:  [[0.429]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.426]] [[1.947]
 [1.915]
 [1.915]
 [1.915]
 [1.915]
 [1.915]
 [1.845]] [[1.124]
 [1.101]
 [1.101]
 [1.101]
 [1.101]
 [1.101]
 [1.049]]
maxi score, test score, baseline:  -0.990890990990991 -1.0 -0.990890990990991
maxi score, test score, baseline:  -0.990890990990991 -1.0 -0.990890990990991
probs:  [0.034397582719528974, 0.4071339651366147, 0.2792342260719282, 0.2792342260719282]
maxi score, test score, baseline:  -0.990890990990991 -1.0 -0.990890990990991
probs:  [0.034397582719528974, 0.4071339651366147, 0.2792342260719282, 0.2792342260719282]
using another actor
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.04571627634048645, 0.3735203910499383, 0.3735203910499383, 0.20724294155963707]
maxi score, test score, baseline:  -0.9909714285714286 -1.0 -0.9909714285714286
probs:  [0.05437248652981728, 0.4456275134701827, 0.4456275134701827, 0.05437248652981728]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.15470518942410805, 0.40529524686441665, 0.40529524686441665, 0.034704316847058644]
Printing some Q and Qe and total Qs values:  [[0.559]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.556]] [[1.88 ]
 [2.021]
 [2.021]
 [2.021]
 [2.021]
 [2.021]
 [1.949]] [[1.167]
 [1.251]
 [1.251]
 [1.251]
 [1.251]
 [1.251]
 [1.207]]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.15470518942410805, 0.40529524686441665, 0.40529524686441665, 0.034704316847058644]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.15470518942410805, 0.40529524686441665, 0.40529524686441665, 0.034704316847058644]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.382]
 [0.45 ]
 [0.374]
 [0.407]
 [0.407]
 [0.407]
 [0.379]] [[-0.378]
 [ 0.336]
 [-0.711]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-0.69 ]] [[0.382]
 [0.45 ]
 [0.374]
 [0.407]
 [0.407]
 [0.407]
 [0.379]]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.039321846487934034, 0.460678153512066, 0.460678153512066, 0.039321846487934034]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
probs:  [0.039321846487934034, 0.460678153512066, 0.460678153512066, 0.039321846487934034]
maxi score, test score, baseline:  -0.9910504424778761 -1.0 -0.9910504424778761
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.04582681741028355, 0.36964667551175834, 0.5386996896676746, 0.04582681741028355]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.04582681741028355, 0.36964667551175834, 0.5386996896676746, 0.04582681741028355]
Printing some Q and Qe and total Qs values:  [[0.586]
 [0.555]
 [0.546]
 [0.554]
 [0.557]
 [0.558]
 [0.555]] [[1.67 ]
 [1.721]
 [1.672]
 [1.635]
 [1.627]
 [1.603]
 [1.631]] [[0.723]
 [0.712]
 [0.644]
 [0.623]
 [0.623]
 [0.6  ]
 [0.621]]
start point for exploration sampling:  10768
line 256 mcts: sample exp_bonus 1.6377411913484217
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.06837114510198647, 0.3082255180773518, 0.5550321917186752, 0.06837114510198647]
Printing some Q and Qe and total Qs values:  [[0.407]
 [0.397]
 [0.404]
 [0.41 ]
 [0.412]
 [0.414]
 [0.413]] [[1.587]
 [0.946]
 [1.581]
 [1.59 ]
 [1.547]
 [1.501]
 [1.543]] [[0.818]
 [0.156]
 [0.805]
 [0.825]
 [0.786]
 [0.746]
 [0.784]]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.2486234649016516, 0.2486234649016516, 0.4468445190639243, 0.05590855113277241]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.2486234649016516, 0.2486234649016516, 0.4468445190639243, 0.05590855113277241]
maxi score, test score, baseline:  -0.9911280701754386 -1.0 -0.9911280701754386
probs:  [0.31014927194202735, 0.31014927194202735, 0.31014927194202735, 0.06955218417391791]
from probs:  [0.31014927194202735, 0.31014927194202735, 0.31014927194202735, 0.06955218417391791]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.3101492904867158, 0.3101492904867158, 0.3101492904867158, 0.06955212853985253]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.3101492904867158, 0.3101492904867158, 0.3101492904867158, 0.06955212853985253]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.3101492904867158, 0.3101492904867158, 0.3101492904867158, 0.06955212853985253]
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.503]
 [0.613]
 [0.615]
 [0.619]
 [0.613]
 [0.608]] [[1.405]
 [0.591]
 [1.231]
 [1.342]
 [1.334]
 [1.332]
 [1.336]] [[1.025]
 [0.071]
 [0.918]
 [1.031]
 [1.031]
 [1.017]
 [1.012]]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.4086130869836264, 0.4086130869836264, 0.09138691301637357, 0.09138691301637357]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.37250592466905824, 0.37250592466905824, 0.047328908035982754, 0.20765924262590071]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.37250592466905824, 0.37250592466905824, 0.047328908035982754, 0.20765924262590071]
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.37250592466905824, 0.37250592466905824, 0.047328908035982754, 0.20765924262590071]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.991204347826087 -1.0 -0.991204347826087
probs:  [0.4461878799271762, 0.24864698013843267, 0.056518159795958416, 0.24864698013843267]
maxi score, test score, baseline:  -0.9912793103448276 -1.0 -0.9912793103448276
probs:  [0.4461879287221901, 0.24864697980191527, 0.056518111673979445, 0.24864697980191527]
maxi score, test score, baseline:  -0.9912793103448276 -1.0 -0.9912793103448276
probs:  [0.40571314335271136, 0.2790892685384184, 0.03610831957045176, 0.2790892685384184]
Printing some Q and Qe and total Qs values:  [[0.152]
 [0.189]
 [0.232]
 [0.238]
 [0.081]
 [0.207]
 [0.191]] [[ 0.937]
 [ 0.569]
 [-0.877]
 [-0.622]
 [-0.069]
 [-0.656]
 [-0.132]] [[0.152]
 [0.189]
 [0.232]
 [0.238]
 [0.081]
 [0.207]
 [0.191]]
siam score:  -0.87542176
maxi score, test score, baseline:  -0.9914254237288136 -1.0 -0.9914254237288136
probs:  [0.4057131917240038, 0.2790892775748136, 0.03610825312636913, 0.2790892775748136]
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
probs:  [0.40571321529218607, 0.2790892819776618, 0.03610822075249024, 0.2790892819776618]
Printing some Q and Qe and total Qs values:  [[0.296]
 [0.296]
 [0.296]
 [0.296]
 [0.296]
 [0.296]
 [0.296]] [[-0.097]
 [-0.097]
 [-0.097]
 [-0.097]
 [-0.097]
 [-0.097]
 [-0.097]] [[0.296]
 [0.296]
 [0.296]
 [0.296]
 [0.296]
 [0.296]
 [0.296]]
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
probs:  [0.40571321529218607, 0.2790892819776618, 0.03610822075249024, 0.2790892819776618]
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
probs:  [0.40571321529218607, 0.2790892819776618, 0.03610822075249024, 0.2790892819776618]
maxi score, test score, baseline:  -0.9914966386554622 -1.0 -0.9914966386554622
probs:  [0.40571321529218607, 0.2790892819776618, 0.03610822075249024, 0.2790892819776618]
from probs:  [0.40571321529218607, 0.2790892819776618, 0.03610822075249024, 0.2790892819776618]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.674]
 [0.66 ]
 [0.678]
 [0.669]
 [0.651]
 [0.706]
 [0.654]] [[ 0.389]
 [ 0.514]
 [ 0.053]
 [ 0.099]
 [ 0.171]
 [-0.064]
 [ 0.287]] [[0.496]
 [0.552]
 [0.28 ]
 [0.294]
 [0.306]
 [0.259]
 [0.39 ]]
maxi score, test score, baseline:  -0.9917032786885246 -1.0 -0.9917032786885246
Printing some Q and Qe and total Qs values:  [[0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]] [[0.012]
 [0.012]
 [0.012]
 [0.012]
 [0.012]
 [0.012]
 [0.012]] [[0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]
 [0.929]]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.40571330568564606, 0.2790892988643511, 0.03610809658565173, 0.2790892988643511]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.46281620630060305, 0.17779521788368238, 0.041062176143133206, 0.3183263996725814]
siam score:  -0.8837526
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.24866981895307896, 0.24866981895307896, 0.05712374819643605, 0.445536613897406]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.24866981895307896, 0.24866981895307896, 0.05712374819643605, 0.445536613897406]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.24866981895307896, 0.24866981895307896, 0.05712374819643605, 0.445536613897406]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.07048788653896887, 0.3076415043223472, 0.07048788653896887, 0.5513827225997151]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.04817453402342802, 0.20698801544761622, 0.20698801544761622, 0.5378494350813394]
maxi score, test score, baseline:  -0.991769918699187 -1.0 -0.991769918699187
probs:  [0.04817453402342802, 0.20698801544761622, 0.20698801544761622, 0.5378494350813394]
from probs:  [0.057124083397805246, 0.057124083397805246, 0.24606375680403714, 0.6396880764003524]
256 120
using explorer policy with actor:  1
siam score:  -0.8741476
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
Printing some Q and Qe and total Qs values:  [[0.534]
 [0.523]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]] [[0.086]
 [0.966]
 [0.315]
 [0.161]
 [0.315]
 [0.315]
 [0.315]] [[0.534]
 [0.523]
 [0.535]
 [0.535]
 [0.535]
 [0.535]
 [0.535]]
UNIT TEST: sample policy line 217 mcts : [0.306 0.265 0.082 0.082 0.061 0.082 0.122]
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
probs:  [0.4054112278943409, 0.09458877210565907, 0.4054112278943409, 0.09458877210565907]
maxi score, test score, baseline:  -0.9918354838709678 -1.0 -0.9918354838709678
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9919 -1.0 -0.9919
probs:  [0.09536959628292915, 0.4046304037170709, 0.4046304037170709, 0.09536959628292915]
maxi score, test score, baseline:  -0.9919 -1.0 -0.9919
probs:  [0.13786807708579757, 0.13786807708579757, 0.5863957687426075, 0.13786807708579757]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9919 -1.0 -0.9919
probs:  [0.30877143458342843, 0.30877143458342843, 0.30877143458342843, 0.07368569624971484]
maxi score, test score, baseline:  -0.9919 -1.0 -0.9919
probs:  [0.30877143458342843, 0.30877143458342843, 0.30877143458342843, 0.07368569624971484]
261 129
first move QE:  0.029295091874667507
maxi score, test score, baseline:  -0.9919634920634921 -1.0 -0.9919634920634921
probs:  [0.30877145185779287, 0.30877145185779287, 0.30877145185779287, 0.07368564442662136]
Printing some Q and Qe and total Qs values:  [[-0.012]
 [-0.036]
 [-0.027]
 [-0.01 ]
 [-0.027]
 [-0.027]
 [-0.009]] [[1.046]
 [1.615]
 [0.982]
 [0.791]
 [0.982]
 [0.982]
 [0.683]] [[-0.711]
 [-0.189]
 [-0.803]
 [-0.962]
 [-0.803]
 [-0.803]
 [-1.066]]
maxi score, test score, baseline:  -0.9919634920634921 -1.0 -0.9919634920634921
using explorer policy with actor:  1
siam score:  -0.88778824
maxi score, test score, baseline:  -0.9919634920634921 -1.0 -0.9919634920634921
probs:  [0.24877483263867076, 0.4423512757286458, 0.06009905899401258, 0.24877483263867076]
maxi score, test score, baseline:  -0.9919634920634921 -1.0 -0.9919634920634921
probs:  [0.24877483263867076, 0.4423512757286458, 0.06009905899401258, 0.24877483263867076]
maxi score, test score, baseline:  -0.9919634920634921 -1.0 -0.9919634920634921
probs:  [0.07391146780273732, 0.5454962063911153, 0.07391146780273732, 0.30668085800341]
maxi score, test score, baseline:  -0.9919634920634921 -1.0 -0.9919634920634921
maxi score, test score, baseline:  -0.9919634920634921 -1.0 -0.9919634920634921
probs:  [0.09690845079424189, 0.4030915492057581, 0.09690845079424189, 0.4030915492057581]
maxi score, test score, baseline:  -0.9919634920634921 -1.0 -0.9919634920634921
probs:  [0.09690845079424189, 0.4030915492057581, 0.09690845079424189, 0.4030915492057581]
maxi score, test score, baseline:  -0.9919634920634921 -1.0 -0.9919634920634921
probs:  [0.09690845079424189, 0.4030915492057581, 0.09690845079424189, 0.4030915492057581]
Printing some Q and Qe and total Qs values:  [[0.767]
 [0.464]
 [0.464]
 [0.756]
 [0.464]
 [0.881]
 [0.464]] [[1.347]
 [1.573]
 [1.573]
 [1.055]
 [1.573]
 [0.843]
 [1.573]] [[2.246]
 [2.143]
 [2.143]
 [2.108]
 [2.143]
 [2.096]
 [2.143]]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.20858330387497853, 0.3702094350945748, 0.050997825935871675, 0.3702094350945748]
line 256 mcts: sample exp_bonus 1.8451742641649538
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.20858330387497853, 0.3702094350945748, 0.050997825935871675, 0.3702094350945748]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.255]
 [0.257]
 [0.257]
 [0.257]
 [0.257]
 [0.257]
 [0.257]] [[1.081]
 [0.969]
 [0.969]
 [0.969]
 [0.969]
 [0.969]
 [0.969]] [[0.612]
 [0.541]
 [0.541]
 [0.541]
 [0.541]
 [0.541]
 [0.541]]
266 132
siam score:  -0.8770812
Printing some Q and Qe and total Qs values:  [[0.207]
 [0.079]
 [0.242]
 [0.216]
 [0.211]
 [0.215]
 [0.216]] [[3.318]
 [1.263]
 [3.175]
 [3.44 ]
 [3.438]
 [3.409]
 [3.406]] [[ 1.727]
 [-0.139]
 [ 1.652]
 [ 1.839]
 [ 1.832]
 [ 1.813]
 [ 1.811]]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.24879416220213882, 0.24879416220213882, 0.060683465735692346, 0.44172820986003]
Printing some Q and Qe and total Qs values:  [[0.447]
 [0.54 ]
 [0.544]
 [0.544]
 [0.859]
 [0.653]
 [0.41 ]] [[1.719]
 [1.109]
 [1.022]
 [1.36 ]
 [2.211]
 [0.776]
 [1.465]] [[0.417]
 [0.397]
 [0.377]
 [0.489]
 [1.405]
 [0.513]
 [0.256]]
siam score:  -0.88171214
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.24879416220213882, 0.24879416220213882, 0.060683465735692346, 0.44172820986003]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.24879416220213882, 0.24879416220213882, 0.060683465735692346, 0.44172820986003]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.306490881546812, 0.07458094677569249, 0.07458094677569249, 0.544347224901803]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.32191983097949944, 0.031697965073867705, 0.2227606934617419, 0.42362151048489094]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.32191983097949944, 0.031697965073867705, 0.2227606934617419, 0.42362151048489094]
Printing some Q and Qe and total Qs values:  [[0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]] [[1.464]
 [1.464]
 [1.464]
 [1.464]
 [1.464]
 [1.464]
 [1.464]] [[0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]]
siam score:  -0.8927182
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.3584153813264224, 0.035189399732119556, 0.24797983761503556, 0.3584153813264224]
Printing some Q and Qe and total Qs values:  [[0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.494]] [[2.603]
 [2.603]
 [2.603]
 [2.603]
 [2.603]
 [2.603]
 [2.603]] [[1.657]
 [1.657]
 [1.657]
 [1.657]
 [1.657]
 [1.657]
 [1.657]]
Printing some Q and Qe and total Qs values:  [[0.799]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.762]
 [0.813]] [[1.905]
 [2.352]
 [2.352]
 [2.352]
 [2.352]
 [2.352]
 [2.201]] [[1.558]
 [2.032]
 [2.032]
 [2.032]
 [2.032]
 [2.032]
 [1.942]]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.40298705689894676, 0.03945345634699379, 0.27877974337702977, 0.27877974337702977]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.40298705689894676, 0.03945345634699379, 0.27877974337702977, 0.27877974337702977]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.4586491297439657, 0.04477850250834397, 0.3172433321051299, 0.17932903564256036]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.3078864669368835, 0.07634059918934956, 0.3078864669368835, 0.3078864669368835]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.3078864669368835, 0.07634059918934956, 0.3078864669368835, 0.3078864669368835]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
siam score:  -0.88015956
Printing some Q and Qe and total Qs values:  [[0.097]
 [0.097]
 [0.097]
 [0.06 ]
 [0.061]
 [0.097]
 [0.061]] [[ 1.244]
 [ 1.244]
 [ 1.244]
 [-1.1  ]
 [-0.348]
 [ 1.244]
 [-0.885]] [[0.097]
 [0.097]
 [0.097]
 [0.06 ]
 [0.061]
 [0.097]
 [0.061]]
Printing some Q and Qe and total Qs values:  [[-0.159]
 [-0.153]
 [-0.153]
 [-0.153]
 [-0.153]
 [-0.153]
 [-0.153]] [[8.332]
 [7.75 ]
 [7.75 ]
 [7.75 ]
 [7.75 ]
 [7.75 ]
 [7.75 ]] [[-0.433]
 [-0.616]
 [-0.616]
 [-0.616]
 [-0.616]
 [-0.616]
 [-0.616]]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
Printing some Q and Qe and total Qs values:  [[0.165]
 [0.125]
 [0.164]
 [0.162]
 [0.16 ]
 [0.167]
 [0.168]] [[ 0.461]
 [ 1.959]
 [-0.09 ]
 [-0.205]
 [ 0.114]
 [ 0.169]
 [ 0.203]] [[0.165]
 [0.125]
 [0.164]
 [0.162]
 [0.16 ]
 [0.167]
 [0.168]]
maxi score, test score, baseline:  -0.9920259842519685 -1.0 -0.9920259842519685
probs:  [0.14181229998483819, 0.14181229998483819, 0.14181229998483819, 0.5745631000454855]
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.24884917833896808, 0.24884917833896808, 0.06241606925172636, 0.43988557407033757]
276 136
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.09989781020541048, 0.4001021897945895, 0.09989781020541048, 0.4001021897945895]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.09989781020541048, 0.4001021897945895, 0.09989781020541048, 0.4001021897945895]
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.06298681893456921, 0.24886658678142132, 0.24886658678142132, 0.4392800075025881]
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.07721015140546528, 0.07721015140546528, 0.30573866083694695, 0.5398410363521225]
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.10062738805873317, 0.10062738805873317, 0.39937261194126683, 0.39937261194126683]
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.2092078924510289, 0.05354145904576386, 0.3686253242516036, 0.3686253242516036]
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.2092078924510289, 0.05354145904576386, 0.3686253242516036, 0.3686253242516036]
from probs:  [0.2092078924510289, 0.05354145904576386, 0.3686253242516036, 0.3686253242516036]
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.248883558194671, 0.06355421851011912, 0.4386786651005389, 0.248883558194671]
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.248883558194671, 0.06355421851011912, 0.4386786651005389, 0.248883558194671]
Printing some Q and Qe and total Qs values:  [[0.366]
 [0.425]
 [0.457]
 [0.364]
 [0.366]
 [0.366]
 [0.371]] [[0.72 ]
 [2.04 ]
 [1.585]
 [0.671]
 [0.699]
 [0.767]
 [0.647]] [[-0.174]
 [ 0.384]
 [ 0.296]
 [-0.196]
 [-0.183]
 [-0.159]
 [-0.19 ]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.475]
 [0.473]
 [0.485]
 [0.485]
 [0.489]
 [0.48 ]
 [0.486]] [[2.648]
 [2.585]
 [2.262]
 [1.889]
 [1.878]
 [2.192]
 [2.601]] [[0.488]
 [0.461]
 [0.379]
 [0.255]
 [0.259]
 [0.344]
 [0.494]]
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.248883558194671, 0.06355421851011912, 0.4386786651005389, 0.248883558194671]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.3055526023322326, 0.07785551622974826, 0.5387363652082708, 0.07785551622974826]
maxi score, test score, baseline:  -0.9920875 -1.0 -0.9920875
probs:  [0.14405015117251366, 0.14405015117251366, 0.567849546482459, 0.14405015117251366]
from probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9921480620155039 -1.0 -0.9921480620155039
probs:  [0.30702708422782804, 0.30702708422782804, 0.07891874731651594, 0.30702708422782804]
Printing some Q and Qe and total Qs values:  [[0.299]
 [0.299]
 [0.299]
 [0.299]
 [0.299]
 [0.299]
 [0.299]] [[-0.043]
 [-0.043]
 [-0.043]
 [-0.043]
 [-0.043]
 [-0.043]
 [-0.043]] [[0.299]
 [0.299]
 [0.299]
 [0.299]
 [0.299]
 [0.299]
 [0.299]]
maxi score, test score, baseline:  -0.9921480620155039 -1.0 -0.9921480620155039
probs:  [0.30702708422782804, 0.30702708422782804, 0.07891874731651594, 0.30702708422782804]
maxi score, test score, baseline:  -0.9921480620155039 -1.0 -0.9921480620155039
probs:  [0.10206583516657802, 0.397934164833422, 0.10206583516657802, 0.397934164833422]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9921480620155039 -1.0 -0.9921480620155039
probs:  [0.10206583516657802, 0.397934164833422, 0.10206583516657802, 0.397934164833422]
maxi score, test score, baseline:  -0.9921480620155039 -1.0 -0.9921480620155039
probs:  [0.05454146198348777, 0.368004105702277, 0.20945032661195814, 0.368004105702277]
maxi score, test score, baseline:  -0.9921480620155039 -1.0 -0.9921480620155039
probs:  [0.06467903387403, 0.24891625166008174, 0.24891625166008174, 0.43748846280580655]
line 256 mcts: sample exp_bonus 1.4325971297753854
maxi score, test score, baseline:  -0.9921480620155039 -1.0 -0.9921480620155039
probs:  [0.07913221154195893, 0.07913221154195893, 0.30518298226465834, 0.5365525946514238]
maxi score, test score, baseline:  -0.9922076923076923 -1.0 -0.9922076923076923
probs:  [0.07913215508306842, 0.07913215508306842, 0.30518300049846303, 0.5365526893354001]
maxi score, test score, baseline:  -0.9922076923076923 -1.0 -0.9922076923076923
probs:  [0.07913215508306842, 0.07913215508306842, 0.30518300049846303, 0.5365526893354001]
maxi score, test score, baseline:  -0.9922664122137405 -1.0 -0.9922664122137405
probs:  [0.07913209949605587, 0.07913209949605587, 0.30518301845068974, 0.5365527825571985]
Printing some Q and Qe and total Qs values:  [[0.538]
 [0.503]
 [0.555]
 [0.558]
 [0.39 ]
 [0.546]
 [0.547]] [[ 1.945]
 [ 1.945]
 [ 0.142]
 [ 0.27 ]
 [ 1.191]
 [-0.218]
 [ 1.354]] [[1.841]
 [1.792]
 [0.607]
 [0.7  ]
 [1.108]
 [0.342]
 [1.441]]
282 150
maxi score, test score, baseline:  -0.9922664122137405 -1.0 -0.9922664122137405
probs:  [0.14549187615896636, 0.14549187615896636, 0.14549187615896636, 0.563524371523101]
maxi score, test score, baseline:  -0.9922664122137405 -1.0 -0.9922664122137405
probs:  [0.14549187615896636, 0.14549187615896636, 0.14549187615896636, 0.563524371523101]
start point for exploration sampling:  10768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9922664122137405 -1.0 -0.9922664122137405
probs:  [0.14549187615896636, 0.14549187615896636, 0.14549187615896636, 0.563524371523101]
maxi score, test score, baseline:  -0.9922664122137405 -1.0 -0.9922664122137405
probs:  [0.14549187615896636, 0.14549187615896636, 0.14549187615896636, 0.563524371523101]
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Printing some Q and Qe and total Qs values:  [[0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]] [[0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]] [[0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]
 [0.152]]
main train batch thing paused
add a thread
Adding thread: now have 5 threads
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9923242424242424 -1.0 -0.9923242424242424
probs:  [0.08017995770182554, 0.3066066807660582, 0.3066066807660582, 0.3066066807660582]
siam score:  -0.8892842
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.20968878097685628, 0.36738981363882955, 0.36738981363882955, 0.05553159174548457]
Printing some Q and Qe and total Qs values:  [[0.307]
 [0.471]
 [0.503]
 [0.482]
 [0.338]
 [0.611]
 [0.435]] [[ 1.963]
 [ 1.629]
 [ 0.422]
 [ 1.606]
 [ 1.534]
 [-0.339]
 [ 1.661]] [[2.108]
 [2.176]
 [1.697]
 [2.181]
 [1.963]
 [1.508]
 [2.144]]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.20968878097685628, 0.36738981363882955, 0.36738981363882955, 0.05553159174548457]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.20968878097685628, 0.36738981363882955, 0.36738981363882955, 0.05553159174548457]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.06551788827039239, 0.4344821117296076, 0.4344821117296076, 0.06551788827039239]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.06551788827039239, 0.4344821117296076, 0.4344821117296076, 0.06551788827039239]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.06551788827039239, 0.4344821117296076, 0.4344821117296076, 0.06551788827039239]
Printing some Q and Qe and total Qs values:  [[0.39 ]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.416]
 [0.406]] [[4.756]
 [4.631]
 [4.631]
 [4.631]
 [4.631]
 [5.379]
 [4.838]] [[1.339]
 [1.294]
 [1.294]
 [1.294]
 [1.294]
 [1.665]
 [1.391]]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.06551788827039239, 0.4344821117296076, 0.4344821117296076, 0.06551788827039239]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.06551788827039239, 0.4344821117296076, 0.4344821117296076, 0.06551788827039239]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.06551788827039239, 0.4344821117296076, 0.4344821117296076, 0.06551788827039239]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.06551788827039239, 0.4344821117296076, 0.4344821117296076, 0.06551788827039239]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.08039043254312898, 0.5344023545569592, 0.30481678035678283, 0.08039043254312898]
Printing some Q and Qe and total Qs values:  [[0.271]
 [0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.233]] [[5.401]
 [4.046]
 [4.046]
 [4.046]
 [4.046]
 [4.046]
 [4.046]] [[1.275]
 [0.604]
 [0.604]
 [0.604]
 [0.604]
 [0.604]
 [0.604]]
UNIT TEST: sample policy line 217 mcts : [0.735 0.02  0.02  0.061 0.102 0.02  0.041]
UNIT TEST: sample policy line 217 mcts : [0.51  0.02  0.041 0.082 0.041 0.265 0.041]
Printing some Q and Qe and total Qs values:  [[0.212]
 [0.173]
 [0.173]
 [0.173]
 [0.173]
 [0.173]
 [0.173]] [[5.452]
 [4.046]
 [4.046]
 [4.046]
 [4.046]
 [4.046]
 [4.046]] [[1.216]
 [0.522]
 [0.522]
 [0.522]
 [0.522]
 [0.522]
 [0.522]]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.08039043254312898, 0.5344023545569592, 0.30481678035678283, 0.08039043254312898]
Printing some Q and Qe and total Qs values:  [[0.331]
 [0.328]
 [0.31 ]
 [0.342]
 [0.316]
 [0.312]
 [0.304]] [[2.978]
 [1.95 ]
 [2.825]
 [3.941]
 [2.749]
 [2.842]
 [2.805]] [[0.579]
 [0.192]
 [0.497]
 [0.948]
 [0.476]
 [0.506]
 [0.484]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.08039043254312898, 0.5344023545569592, 0.30481678035678283, 0.08039043254312898]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.08039043254312898, 0.5344023545569592, 0.30481678035678283, 0.08039043254312898]
maxi score, test score, baseline:  -0.9923812030075188 -1.0 -0.9923812030075188
probs:  [0.10417317084189327, 0.39582682915810674, 0.39582682915810674, 0.10417317084189327]
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.2784111501511468, 0.04309997713458924, 0.40007772256311713, 0.2784111501511468]
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.2784111501511468, 0.04309997713458924, 0.40007772256311713, 0.2784111501511468]
siam score:  -0.89013016
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.3667821362629303, 0.05651225394075294, 0.3667821362629303, 0.20992347353338658]
line 256 mcts: sample exp_bonus 6.012146918287612
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.3667821362629303, 0.05651225394075294, 0.3667821362629303, 0.20992347353338658]
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.3667821362629303, 0.05651225394075294, 0.3667821362629303, 0.20992347353338658]
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.3667821362629303, 0.05651225394075294, 0.3667821362629303, 0.20992347353338658]
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.35644189772692514, 0.038880434895214075, 0.35644189772692514, 0.24823576965093555]
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.35644189772692514, 0.038880434895214075, 0.35644189772692514, 0.24823576965093555]
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.35644189772692514, 0.038880434895214075, 0.35644189772692514, 0.24823576965093555]
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.35644189772692514, 0.038880434895214075, 0.35644189772692514, 0.24823576965093555]
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
maxi score, test score, baseline:  -0.9924373134328358 -1.0 -0.9924373134328358
probs:  [0.3639602890333917, 0.05661284285242544, 0.5228140252617575, 0.05661284285242544]
maxi score, test score, baseline:  -0.9924925925925926 -1.0 -0.9924925925925926
maxi score, test score, baseline:  -0.9924925925925926 -1.0 -0.9924925925925926
probs:  [0.6181203589978042, 0.06743624472466622, 0.06743624472466622, 0.24700715155286337]
296 165
maxi score, test score, baseline:  -0.9925470588235294 -1.0 -0.9925470588235294
probs:  [0.5231242309933457, 0.20955259479945837, 0.05777057940773777, 0.20955259479945837]
Printing some Q and Qe and total Qs values:  [[0.35 ]
 [0.446]
 [0.366]
 [0.368]
 [0.446]
 [0.368]
 [0.367]] [[1.688]
 [3.31 ]
 [1.634]
 [1.617]
 [3.31 ]
 [1.608]
 [1.656]] [[0.302]
 [2.115]
 [0.279]
 [0.267]
 [2.115]
 [0.258]
 [0.304]]
maxi score, test score, baseline:  -0.9925470588235294 -1.0 -0.9925470588235294
probs:  [0.4334476391223857, 0.2490189965822324, 0.06851436771314945, 0.2490189965822324]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.37504244656965396
using explorer policy with actor:  1
siam score:  -0.88190424
maxi score, test score, baseline:  -0.9925470588235294 -1.0 -0.9925470588235294
maxi score, test score, baseline:  -0.9925470588235294 -1.0 -0.9925470588235294
probs:  [0.4334476391223857, 0.2490189965822324, 0.06851436771314945, 0.2490189965822324]
Printing some Q and Qe and total Qs values:  [[0.269]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]] [[1.256]
 [1.463]
 [1.463]
 [1.463]
 [1.463]
 [1.463]
 [1.463]] [[0.103]
 [0.479]
 [0.479]
 [0.479]
 [0.479]
 [0.479]
 [0.479]]
maxi score, test score, baseline:  -0.9925470588235294 -1.0 -0.9925470588235294
probs:  [0.452309708753736, 0.18162386816928788, 0.05055493483366115, 0.31551148824331493]
maxi score, test score, baseline:  -0.9925470588235294 -1.0 -0.9925470588235294
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9925470588235294 -1.0 -0.9925470588235294
probs:  [0.36558629017790545, 0.2103820842853121, 0.058445335358877075, 0.36558629017790545]
Printing some Q and Qe and total Qs values:  [[0.197]
 [0.26 ]
 [0.191]
 [0.19 ]
 [0.191]
 [0.195]
 [0.196]] [[-0.339]
 [-0.079]
 [-0.415]
 [-0.419]
 [-0.38 ]
 [-0.338]
 [-0.329]] [[0.197]
 [0.26 ]
 [0.191]
 [0.19 ]
 [0.191]
 [0.195]
 [0.196]]
maxi score, test score, baseline:  -0.9926007299270073 -1.0 -0.9926007299270073
maxi score, test score, baseline:  -0.9926007299270073 -1.0 -0.9926007299270073
probs:  [0.39178356532924424, 0.10821643467075577, 0.10821643467075577, 0.39178356532924424]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.47 ]
 [0.4  ]
 [0.4  ]
 [0.505]
 [0.4  ]
 [0.476]
 [0.469]] [[1.433]
 [1.648]
 [1.648]
 [1.145]
 [1.648]
 [1.43 ]
 [1.619]] [[1.946]
 [2.038]
 [2.038]
 [1.748]
 [2.038]
 [1.951]
 [2.101]]
maxi score, test score, baseline:  -0.9927057553956835 -1.0 -0.9927057553956835
probs:  [0.25, 0.25, 0.25, 0.25]
maxi score, test score, baseline:  -0.9927057553956835 -1.0 -0.9927057553956835
probs:  [0.051560041533011074, 0.3161466528223297, 0.3161466528223297, 0.3161466528223297]
304 173
using another actor
siam score:  -0.8944884
maxi score, test score, baseline:  -0.9927571428571429 -1.0 -0.9927571428571429
maxi score, test score, baseline:  -0.9927571428571429 -1.0 -0.9927571428571429
probs:  [0.0593978866460929, 0.36499793477928844, 0.36499793477928844, 0.21060624379533033]
maxi score, test score, baseline:  -0.9927571428571429 -1.0 -0.9927571428571429
probs:  [0.21003672330392717, 0.5202467127071099, 0.05967984068503582, 0.21003672330392717]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9927571428571429 -1.0 -0.9927571428571429
probs:  [0.21003672330392717, 0.5202467127071099, 0.05967984068503582, 0.21003672330392717]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9928078014184397 -1.0 -0.9928078014184397
probs:  [0.21003671384105727, 0.5202467766985933, 0.05967979561929211, 0.21003671384105727]
maxi score, test score, baseline:  -0.9928078014184397 -1.0 -0.9928078014184397
probs:  [0.21003671384105727, 0.5202467766985933, 0.05967979561929211, 0.21003671384105727]
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.613]] [[1.822]
 [1.397]
 [1.397]
 [1.397]
 [1.397]
 [1.397]
 [1.672]] [[1.474]
 [1.012]
 [1.012]
 [1.012]
 [1.012]
 [1.012]
 [1.186]]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.41 ]
 [0.404]
 [0.352]
 [0.361]
 [0.352]
 [0.352]
 [0.351]] [[2.172]
 [1.797]
 [1.455]
 [1.935]
 [1.455]
 [1.455]
 [1.935]] [[ 0.409]
 [ 0.147]
 [-0.185]
 [ 0.153]
 [-0.185]
 [-0.185]
 [ 0.134]]
maxi score, test score, baseline:  -0.9928577464788733 -1.0 -0.9928577464788733
probs:  [0.3149884313783424, 0.4504525545350025, 0.05227013192299959, 0.18228888216365546]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.992906993006993 -1.0 -0.992906993006993
probs:  [0.3644157055214923, 0.3644157055214923, 0.060341423728780166, 0.21082716522823516]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.992906993006993 -1.0 -0.992906993006993
probs:  [0.3644157055214923, 0.3644157055214923, 0.060341423728780166, 0.21082716522823516]
using explorer policy with actor:  0
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.341]
 [0.346]
 [0.346]
 [0.346]
 [0.34 ]
 [0.346]
 [0.346]] [[3.304]
 [3.945]
 [3.945]
 [3.945]
 [3.268]
 [3.945]
 [3.945]] [[0.341]
 [0.346]
 [0.346]
 [0.346]
 [0.34 ]
 [0.346]
 [0.346]]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 2.0794811993352105
maxi score, test score, baseline:  -0.9929555555555556 -1.0 -0.9929555555555556
probs:  [0.4612531531368938, 0.3532116893962236, 0.041923907727559065, 0.14361124973932357]
maxi score, test score, baseline:  -0.9932774834437086 -1.0 -0.9932774834437086
probs:  [0.4612533813286356, 0.35321180088357873, 0.041923682967620474, 0.14361113482016527]
from probs:  [0.46125344265335816, 0.35321183084492014, 0.04192362256516869, 0.14361110393655285]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.5135859560670986, 0.3932597117155628, 0.046577166108669354, 0.046577166108669354]
Printing some Q and Qe and total Qs values:  [[0.592]
 [0.572]
 [0.594]
 [0.667]
 [0.621]
 [0.616]
 [0.573]] [[3.067]
 [4.013]
 [2.544]
 [2.484]
 [2.57 ]
 [2.862]
 [2.684]] [[1.311]
 [1.571]
 [1.163]
 [1.177]
 [1.182]
 [1.263]
 [1.194]]
maxi score, test score, baseline:  -0.9934064935064936 -1.0 -0.9934064935064936
probs:  [0.5135859560670986, 0.3932597117155628, 0.046577166108669354, 0.046577166108669354]
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
probs:  [0.5135859972929456, 0.3932597341219306, 0.046577134292561946, 0.046577134292561946]
maxi score, test score, baseline:  -0.9934483870967742 -1.0 -0.9934483870967742
probs:  [0.5135859972929456, 0.3932597341219306, 0.046577134292561946, 0.046577134292561946]
Printing some Q and Qe and total Qs values:  [[0.166]
 [0.104]
 [0.165]
 [0.166]
 [0.166]
 [0.166]
 [0.169]] [[0.69 ]
 [1.615]
 [0.777]
 [0.74 ]
 [0.869]
 [0.829]
 [0.884]] [[0.166]
 [0.104]
 [0.165]
 [0.166]
 [0.166]
 [0.166]
 [0.169]]
Printing some Q and Qe and total Qs values:  [[0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]] [[0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]] [[0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]
 [0.331]]
Printing some Q and Qe and total Qs values:  [[0.855]
 [0.853]
 [0.853]
 [0.853]
 [0.853]
 [0.853]
 [0.852]] [[1.452]
 [0.401]
 [0.401]
 [0.401]
 [0.401]
 [0.401]
 [0.874]] [[0.855]
 [0.853]
 [0.853]
 [0.853]
 [0.853]
 [0.853]
 [0.852]]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.5135861569615903, 0.3932598209022895, 0.04657701106806001, 0.04657701106806001]
maxi score, test score, baseline:  -0.9936106918238994 -1.0 -0.9936106918238994
probs:  [0.5135861569615903, 0.3932598209022895, 0.04657701106806001, 0.04657701106806001]
maxi score, test score, baseline:  -0.99365 -1.0 -0.99365
probs:  [0.5135861956196012, 0.393259841913027, 0.04657698123368592, 0.04657698123368592]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.5135862337928975, 0.39325986266031937, 0.046576951773391516, 0.046576951773391516]
Printing some Q and Qe and total Qs values:  [[0.21 ]
 [0.224]
 [0.192]
 [0.198]
 [0.198]
 [0.201]
 [0.206]] [[0.855]
 [0.727]
 [0.825]
 [0.717]
 [0.763]
 [0.61 ]
 [0.986]] [[0.21 ]
 [0.224]
 [0.192]
 [0.198]
 [0.198]
 [0.201]
 [0.206]]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.46862077188089435, 0.37832927124278487, 0.11818247237457345, 0.03486748450174741]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.41594555332872085, 0.41594555332872085, 0.12986476843526454, 0.03824412490729381]
maxi score, test score, baseline:  -0.9936888198757764 -1.0 -0.9936888198757764
probs:  [0.41594555332872085, 0.41594555332872085, 0.12986476843526454, 0.03824412490729381]
Printing some Q and Qe and total Qs values:  [[0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]] [[-0.55]
 [-0.55]
 [-0.55]
 [-0.55]
 [-0.55]
 [-0.55]
 [-0.55]] [[0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]
 [0.367]]
from probs:  [0.46086351531969766, 0.3530455713637958, 0.14381470982560768, 0.04227620349089884]
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
maxi score, test score, baseline:  -0.9938024390243902 -1.0 -0.9938024390243902
probs:  [0.4490864065809365, 0.31459978905385216, 0.1827762728639371, 0.053537531501274174]
rdn probs:  [0.4490864065809365, 0.31459978905385216, 0.1827762728639371, 0.053537531501274174]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
siam score:  -0.88564193
Printing some Q and Qe and total Qs values:  [[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]] [[0]
 [0]
 [0]
 [0]
 [0]
 [0]
 [0]] [[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.7378200520899564, 0.08739331597001448, 0.08739331597001448, 0.08739331597001448]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.719]
 [0.711]
 [0.722]
 [0.71 ]
 [0.717]
 [0.722]
 [0.728]] [[0.19 ]
 [1.093]
 [0.307]
 [0.163]
 [0.192]
 [0.318]
 [0.268]] [[0.719]
 [0.711]
 [0.722]
 [0.71 ]
 [0.717]
 [0.722]
 [0.728]]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.7378200520899564, 0.08739331597001448, 0.08739331597001448, 0.08739331597001448]
Printing some Q and Qe and total Qs values:  [[0.673]
 [0.642]
 [0.673]
 [0.673]
 [0.673]
 [0.673]
 [0.673]] [[3.141]
 [3.258]
 [3.141]
 [3.141]
 [3.141]
 [3.141]
 [3.141]] [[1.217]
 [1.232]
 [1.217]
 [1.217]
 [1.217]
 [1.217]
 [1.217]]
maxi score, test score, baseline:  -0.9938759036144579 -1.0 -0.9938759036144579
probs:  [0.7378200520899564, 0.08739331597001448, 0.08739331597001448, 0.08739331597001448]
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
probs:  [0.7378203017169135, 0.08739323276102888, 0.08739323276102888, 0.08739323276102888]
line 256 mcts: sample exp_bonus 3.2223987748044656
maxi score, test score, baseline:  -0.9939476190476191 -1.0 -0.9939476190476191
325 187
using explorer policy with actor:  1
from probs:  [0.6638481096182022, 0.11205063012726595, 0.11205063012726595, 0.11205063012726595]
using another actor
Printing some Q and Qe and total Qs values:  [[0.211]
 [1.461]
 [0.211]
 [0.211]
 [0.211]
 [0.211]
 [0.211]] [[1.205]
 [0.196]
 [1.205]
 [1.205]
 [1.205]
 [1.205]
 [1.205]] [[0.572]
 [2.735]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]]
Printing some Q and Qe and total Qs values:  [[0.616]
 [1.117]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.616]] [[1.214]
 [0.626]
 [1.214]
 [1.214]
 [1.214]
 [1.214]
 [1.214]] [[1.691]
 [2.497]
 [1.691]
 [1.691]
 [1.691]
 [1.691]
 [1.691]]
siam score:  -0.8858942
Printing some Q and Qe and total Qs values:  [[0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]] [[1.812]
 [1.812]
 [1.812]
 [1.812]
 [1.812]
 [1.812]
 [1.812]] [[2.339]
 [2.339]
 [2.339]
 [2.339]
 [2.339]
 [2.339]
 [2.339]]
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
326 204
maxi score, test score, baseline:  -0.9940520467836257 -1.0 -0.9940520467836257
probs:  [0.11567679486795908, 0.38432320513204093, 0.11567679486795908, 0.38432320513204093]
from probs:  [0.11567679486795908, 0.38432320513204093, 0.11567679486795908, 0.38432320513204093]
Printing some Q and Qe and total Qs values:  [[0.034]
 [0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.032]] [[-0.634]
 [-1.075]
 [-1.075]
 [-1.075]
 [-1.075]
 [-1.075]
 [-1.075]] [[0.034]
 [0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.032]
 [0.032]]
siam score:  -0.880934
maxi score, test score, baseline:  -0.9941196531791907 -1.0 -0.9941196531791907
probs:  [0.3940939565979558, 0.05078813650665109, 0.2775589534476965, 0.2775589534476965]
maxi score, test score, baseline:  -0.9941196531791907 -1.0 -0.9941196531791907
probs:  [0.3940939565979558, 0.05078813650665109, 0.2775589534476965, 0.2775589534476965]
Printing some Q and Qe and total Qs values:  [[0.522]
 [0.561]
 [0.522]
 [0.537]
 [0.522]
 [0.535]
 [0.522]] [[ 0.   ]
 [ 1.268]
 [ 0.   ]
 [-0.125]
 [ 0.   ]
 [-0.267]
 [ 0.   ]] [[0.522]
 [0.561]
 [0.522]
 [0.537]
 [0.522]
 [0.535]
 [0.522]]
siam score:  -0.87815195
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.3142047526407712, 0.05738574207768648, 0.3142047526407712, 0.3142047526407712]
Printing some Q and Qe and total Qs values:  [[0.408]
 [0.343]
 [0.454]
 [0.548]
 [0.461]
 [0.73 ]
 [0.738]] [[1.252]
 [1.596]
 [1.811]
 [1.345]
 [1.431]
 [1.936]
 [1.738]] [[0.97 ]
 [1.112]
 [1.332]
 [1.144]
 [1.119]
 [1.644]
 [1.536]]
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.3142047526407712, 0.05738574207768648, 0.3142047526407712, 0.3142047526407712]
maxi score, test score, baseline:  -0.9941857142857143 -1.0 -0.9941857142857143
probs:  [0.24921104088796922, 0.07721795446534072, 0.4243599637587208, 0.24921104088796922]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.24921104071280117, 0.07721791610338062, 0.42436000247101713, 0.24921104071280117]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.24921104071280117, 0.07721791610338062, 0.42436000247101713, 0.24921104071280117]
maxi score, test score, baseline:  -0.9942181818181818 -1.0 -0.9942181818181818
probs:  [0.24921104071280117, 0.07721791610338062, 0.42436000247101713, 0.24921104071280117]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 5.458217900817117
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.323]
 [0.323]
 [0.323]
 [0.323]
 [0.323]
 [0.323]
 [0.323]] [[-1.706]
 [-1.706]
 [-1.706]
 [-1.706]
 [-1.706]
 [-1.706]
 [-1.706]] [[0.323]
 [0.323]
 [0.323]
 [0.323]
 [0.323]
 [0.323]
 [0.323]]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.11799595115090165, 0.11799595115090165, 0.38200404884909833, 0.38200404884909833]
Printing some Q and Qe and total Qs values:  [[0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.412]] [[-1.322]
 [-1.322]
 [-1.322]
 [-1.322]
 [-1.322]
 [-1.322]
 [-1.225]] [[0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.412]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.21219103166824269, 0.06626168021232415, 0.36077364405971657, 0.36077364405971657]
actor:  1 policy actor:  1  step number:  55 total reward:  0.46999999999999964  reward:  1.0 rdn_beta:  0.5
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.00679150420116807, 0.002786997556265002, 0.9795526781847703, 0.010868820057796547]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.382]] [[-0.191]
 [-0.14 ]
 [-0.14 ]
 [-0.14 ]
 [-0.14 ]
 [-0.14 ]
 [-0.14 ]] [[0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.382]
 [0.382]]
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9942502824858758 -1.0 -0.9942502824858758
probs:  [0.006941666173631293, 0.0028334021593653647, 0.979100305769756, 0.01112462589724742]
siam score:  -0.86145425
maxi score, test score, baseline:  -0.9942820224719101 -1.0 -0.9942820224719101
probs:  [0.006941784815710232, 0.002833437915289679, 0.9790999483364982, 0.011124828932502103]
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
probs:  [0.007094418502612271, 0.002880605408901091, 0.9786401297086411, 0.011384846379845376]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.994313407821229 -1.0 -0.994313407821229
probs:  [0.007406714724121744, 0.002977114316766702, 0.9776993176384101, 0.011916853320701392]
Printing some Q and Qe and total Qs values:  [[0.768]
 [0.835]
 [0.768]
 [0.816]
 [0.768]
 [0.768]
 [0.822]] [[ 0.246]
 [ 0.339]
 [ 0.246]
 [-0.441]
 [ 0.246]
 [ 0.246]
 [ 0.017]] [[1.244]
 [1.471]
 [1.244]
 [0.653]
 [1.244]
 [1.244]
 [1.124]]
maxi score, test score, baseline:  -0.9943444444444445 -1.0 -0.9943444444444445
probs:  [0.007406842811078693, 0.0029771529422567126, 0.9776989317509672, 0.011917072495697319]
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]] [[5.226]
 [5.226]
 [5.226]
 [5.226]
 [5.226]
 [5.226]
 [5.226]] [[1.762]
 [1.762]
 [1.762]
 [1.762]
 [1.762]
 [1.762]
 [1.762]]
Printing some Q and Qe and total Qs values:  [[0.835]
 [0.827]
 [0.792]
 [0.785]
 [0.779]
 [0.793]
 [0.858]] [[2.803]
 [4.258]
 [4.076]
 [3.677]
 [3.882]
 [3.729]
 [3.374]] [[1.034]
 [1.729]
 [1.608]
 [1.408]
 [1.501]
 [1.441]
 [1.333]]
siam score:  -0.8539006
maxi score, test score, baseline:  -0.9943444444444445 -1.0 -0.9943444444444445
probs:  [0.007486474409629926, 0.0030017614849326257, 0.9774590365361158, 0.012052727569321678]
Printing some Q and Qe and total Qs values:  [[0.836]
 [0.793]
 [0.836]
 [0.836]
 [0.836]
 [0.836]
 [0.836]] [[2.759]
 [3.657]
 [2.759]
 [2.759]
 [2.759]
 [2.759]
 [2.759]] [[1.459]
 [1.826]
 [1.459]
 [1.459]
 [1.459]
 [1.459]
 [1.459]]
maxi score, test score, baseline:  -0.9943444444444445 -1.0 -0.9943444444444445
probs:  [0.007486474409629926, 0.0030017614849326257, 0.9774590365361158, 0.012052727569321678]
using another actor
from probs:  [0.0077292228512671245, 0.003076778004683825, 0.9767277415398972, 0.012466257604151895]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.15 ]
 [0.144]
 [0.148]
 [0.147]
 [0.111]
 [0.135]
 [0.088]] [[-0.31 ]
 [ 1.127]
 [-0.276]
 [-0.259]
 [ 0.056]
 [-0.155]
 [ 1.541]] [[0.15 ]
 [0.144]
 [0.148]
 [0.147]
 [0.111]
 [0.135]
 [0.088]]
Printing some Q and Qe and total Qs values:  [[0.178]
 [0.178]
 [0.178]
 [0.178]
 [0.178]
 [0.178]
 [1.363]] [[1.721]
 [1.721]
 [1.721]
 [1.721]
 [1.721]
 [1.721]
 [0.772]] [[1.452]
 [1.452]
 [1.452]
 [1.452]
 [1.452]
 [1.452]
 [2.874]]
from probs:  [0.007894484516503718, 0.0031278477773123634, 0.9762298803279581, 0.012747787378225852]
Printing some Q and Qe and total Qs values:  [[0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.813]] [[-0.426]
 [-0.426]
 [-0.426]
 [-0.426]
 [-0.426]
 [-0.426]
 [-0.426]] [[0.327]
 [0.327]
 [0.327]
 [0.327]
 [0.327]
 [0.327]
 [0.327]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.4043774614026705
line 256 mcts: sample exp_bonus -0.14890668815325891
maxi score, test score, baseline:  -0.9944054945054945 -1.0 -0.9944054945054945
probs:  [0.008147416457102024, 0.00320601022088761, 0.9754679068789444, 0.013178666443065942]
siam score:  -0.8644352
maxi score, test score, baseline:  -0.9944054945054945 -1.0 -0.9944054945054945
probs:  [0.008233074110517652, 0.0032324809693699322, 0.9752098577931534, 0.013324587126959192]
from probs:  [0.008233074110517652, 0.0032324809693699322, 0.9752098577931534, 0.013324587126959192]
maxi score, test score, baseline:  -0.9944054945054945 -1.0 -0.9944054945054945
probs:  [0.008319442741081717, 0.0032591714308203316, 0.9749496668438408, 0.01347171898425715]
maxi score, test score, baseline:  -0.9944054945054945 -1.0 -0.9944054945054945
probs:  [0.008319442741081717, 0.0032591714308203316, 0.9749496668438408, 0.01347171898425715]
maxi score, test score, baseline:  -0.9944054945054945 -1.0 -0.9944054945054945
probs:  [0.008494348637594807, 0.003313222526198876, 0.9744227517942808, 0.013769677041925355]
maxi score, test score, baseline:  -0.9944355191256831 -1.0 -0.9944355191256831
maxi score, test score, baseline:  -0.9944355191256831 -1.0 -0.9944355191256831
probs:  [0.008583059477753221, 0.0033406357040811608, 0.9741555047708554, 0.01392080004731003]
siam score:  -0.8632388
deleting a thread, now have 4 threads
Frames:  22376 train batches done:  2623 episodes:  586
maxi score, test score, baseline:  -0.9944652173913043 -1.0 -0.9944652173913043
probs:  [0.008762585949136028, 0.0033961135585920234, 0.9736146699273092, 0.014226630564962758]
Printing some Q and Qe and total Qs values:  [[0.409]
 [0.401]
 [0.401]
 [0.403]
 [0.401]
 [0.401]
 [0.406]] [[0.826]
 [0.068]
 [0.068]
 [0.425]
 [0.068]
 [0.068]
 [0.509]] [[0.409]
 [0.401]
 [0.401]
 [0.403]
 [0.401]
 [0.401]
 [0.406]]
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.008853576978368229, 0.0034242313418068513, 0.9733405536896851, 0.01438163799013978]
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.008853576978368229, 0.0034242313418068513, 0.9733405536896851, 0.01438163799013978]
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.008853576978368229, 0.0034242313418068513, 0.9733405536896851, 0.01438163799013978]
maxi score, test score, baseline:  -0.9944945945945947 -1.0 -0.9944945945945947
probs:  [0.008853576978368229, 0.0034242313418068513, 0.9733405536896851, 0.01438163799013978]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.008853734692880044, 0.0034242789821883842, 0.973340078544802, 0.01438190778012963]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.008853734692880044, 0.0034242789821883842, 0.973340078544802, 0.01438190778012963]
deleting a thread, now have 3 threads
Frames:  22583 train batches done:  2644 episodes:  590
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.008853734692880044, 0.0034242789821883842, 0.973340078544802, 0.01438190778012963]
Training Flag: True
Self play flag: False
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.008853734692880044, 0.0034242789821883842, 0.973340078544802, 0.01438190778012963]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.008853734692880044, 0.0034242789821883842, 0.973340078544802, 0.01438190778012963]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.008853734692880044, 0.0034242789821883842, 0.973340078544802, 0.01438190778012963]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.008945347884433366, 0.0034525901160504234, 0.9730640880236383, 0.014537973975877801]
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.009037747664066497, 0.0034811443284478013, 0.972785727856244, 0.014695380151241872]
Printing some Q and Qe and total Qs values:  [[0.233]
 [0.198]
 [0.211]
 [0.209]
 [0.207]
 [0.209]
 [0.203]] [[-0.925]
 [ 0.801]
 [-0.993]
 [-1.115]
 [-1.072]
 [-1.027]
 [-0.861]] [[0.233]
 [0.198]
 [0.211]
 [0.209]
 [0.207]
 [0.209]
 [0.203]]
line 256 mcts: sample exp_bonus 3.0831187664647777
maxi score, test score, baseline:  -0.9945236559139785 -1.0 -0.9945236559139785
probs:  [0.009037747664066497, 0.0034811443284478013, 0.972785727856244, 0.014695380151241872]
Printing some Q and Qe and total Qs values:  [[0.496]
 [0.523]
 [0.494]
 [0.495]
 [0.506]
 [0.506]
 [0.504]] [[-0.445]
 [ 0.789]
 [-0.495]
 [-0.516]
 [-0.34 ]
 [-0.45 ]
 [-0.465]] [[0.496]
 [0.523]
 [0.494]
 [0.495]
 [0.506]
 [0.506]
 [0.504]]
from probs:  [0.009037747664066497, 0.0034811443284478013, 0.972785727856244, 0.014695380151241872]
Printing some Q and Qe and total Qs values:  [[0.195]
 [0.218]
 [0.19 ]
 [0.186]
 [0.189]
 [0.194]
 [0.193]] [[-2.108]
 [-1.543]
 [-2.316]
 [-2.466]
 [-2.248]
 [-2.215]
 [-2.173]] [[0.195]
 [0.218]
 [0.19 ]
 [0.186]
 [0.189]
 [0.194]
 [0.193]]
maxi score, test score, baseline:  -0.9945524064171123 -1.0 -0.9945524064171123
probs:  [0.009037908726944757, 0.0034811929899290516, 0.9727852426239474, 0.014695655659178828]
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
probs:  [0.0091312697394873, 0.0035100431258083408, 0.9725039866612892, 0.014854700473415078]
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
probs:  [0.0091312697394873, 0.0035100431258083408, 0.9725039866612892, 0.014854700473415078]
from probs:  [0.0091312697394873, 0.0035100431258083408, 0.9725039866612892, 0.014854700473415078]
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
maxi score, test score, baseline:  -0.9945808510638298 -1.0 -0.9945808510638298
maxi score, test score, baseline:  -0.9946089947089947 -1.0 -0.9946089947089947
probs:  [0.009320270510531432, 0.0035684486687769072, 0.9719346098894647, 0.015176670931226951]
Printing some Q and Qe and total Qs values:  [[0.402]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]
 [0.551]] [[1.489]
 [0.739]
 [0.739]
 [0.739]
 [0.739]
 [0.739]
 [0.739]] [[1.695]
 [1.263]
 [1.263]
 [1.263]
 [1.263]
 [1.263]
 [1.263]]
maxi score, test score, baseline:  -0.9946089947089947 -1.0 -0.9946089947089947
probs:  [0.009320270510531432, 0.0035684486687769072, 0.9719346098894647, 0.015176670931226951]
maxi score, test score, baseline:  -0.9946368421052632 -1.0 -0.9946368421052632
probs:  [0.009416094365738835, 0.003598059853496008, 0.9716459344571065, 0.015339911323658648]
siam score:  -0.86176836
using explorer policy with actor:  0
using another actor
maxi score, test score, baseline:  -0.9946643979057592 -1.0 -0.9946643979057592
probs:  [0.009512761130070727, 0.0036279315073940452, 0.9713547197075575, 0.015504587654977756]
Printing some Q and Qe and total Qs values:  [[0.945]
 [0.098]
 [0.098]
 [0.098]
 [0.098]
 [0.098]
 [0.098]] [[0.294]
 [0.35 ]
 [0.35 ]
 [0.35 ]
 [0.35 ]
 [0.35 ]
 [0.35 ]] [[0.945]
 [0.098]
 [0.098]
 [0.098]
 [0.098]
 [0.098]
 [0.098]]
maxi score, test score, baseline:  -0.9947186528497409 -1.0 -0.9947186528497409
probs:  [0.009513090082107543, 0.0036280309422318927, 0.9713537286784071, 0.015505150297253543]
Printing some Q and Qe and total Qs values:  [[0.616]
 [0.625]
 [0.783]
 [0.811]
 [0.814]
 [0.853]
 [0.714]] [[2.335]
 [2.286]
 [1.806]
 [2.025]
 [2.532]
 [2.603]
 [2.241]] [[0.927]
 [0.903]
 [0.774]
 [0.99 ]
 [1.397]
 [1.513]
 [1.009]]
Printing some Q and Qe and total Qs values:  [[0.278]
 [0.322]
 [0.31 ]
 [0.293]
 [0.274]
 [0.275]
 [0.258]] [[0.373]
 [0.409]
 [0.318]
 [0.323]
 [0.366]
 [0.386]
 [0.479]] [[0.048]
 [0.173]
 [0.057]
 [0.029]
 [0.033]
 [0.055]
 [0.115]]
360 249
from probs:  [0.009807931491184807, 0.0037191440836835134, 0.9704655003008544, 0.016007424124277133]
maxi score, test score, baseline:  -0.9947453608247423 -1.0 -0.9947453608247423
probs:  [0.009907912798992185, 0.0037500411016825946, 0.970164300299436, 0.01617774579988931]
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
probs:  [0.009908083513852214, 0.003750092725446585, 0.9701637859895631, 0.016178037771137962]
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
probs:  [0.01011075499441965, 0.003812723850671084, 0.9695532253595819, 0.01652329579532724]
Printing some Q and Qe and total Qs values:  [[0.588]
 [0.493]
 [0.605]
 [0.607]
 [0.605]
 [0.601]
 [0.601]] [[-0.064]
 [ 0.899]
 [-0.561]
 [-0.53 ]
 [-0.494]
 [-0.582]
 [-0.63 ]] [[1.615]
 [2.228]
 [1.25 ]
 [1.277]
 [1.302]
 [1.227]
 [1.187]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
probs:  [0.010741299182247114, 0.004007579544609156, 0.9676536711871195, 0.017597450086024164]
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
probs:  [0.010849813070046267, 0.004041113354478772, 0.967326766249578, 0.017782307325896883]
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
probs:  [0.010849813070046267, 0.004041113354478772, 0.967326766249578, 0.017782307325896883]
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
probs:  [0.010849813070046267, 0.004041113354478772, 0.967326766249578, 0.017782307325896883]
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
probs:  [0.010849813070046267, 0.004041113354478772, 0.967326766249578, 0.017782307325896883]
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
probs:  [0.01095934159238038, 0.004074960714643922, 0.9669968046614452, 0.017968893031530393]
maxi score, test score, baseline:  -0.9947717948717949 -1.0 -0.9947717948717949
probs:  [0.011069899046758399, 0.004109126043432447, 0.9666637433505736, 0.018157231559235664]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.011070100011797406, 0.004109186880892788, 0.9666631379076825, 0.018157575199627345]
siam score:  -0.86909485
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.17633491203093504
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.01118170416011666, 0.004143675653196395, 0.9663269233649788, 0.01834769682170809]
first move QE:  0.2746388421101648
Printing some Q and Qe and total Qs values:  [[0.482]
 [0.528]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]] [[3.322]
 [3.51 ]
 [3.322]
 [3.322]
 [3.322]
 [3.322]
 [3.322]] [[1.074]
 [1.293]
 [1.074]
 [1.074]
 [1.074]
 [1.074]
 [1.074]]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.011294366703392865, 0.004178491498850107, 0.9659875203406479, 0.018539621457109128]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.011294366703392865, 0.004178491498850107, 0.9659875203406479, 0.018539621457109128]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.011522927774974524, 0.00424912319914042, 0.9652989656827884, 0.018928983343096454]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.011874095097125465, 0.004357643625992975, 0.9642410519546031, 0.01952720932227834]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.012113947679037316, 0.004431764715652861, 0.9635184809090085, 0.019935806696301326]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.012113947679037316, 0.004431764715652861, 0.9635184809090085, 0.019935806696301326]
Printing some Q and Qe and total Qs values:  [[0.648]
 [0.65 ]
 [0.65 ]
 [0.642]
 [0.645]
 [0.651]
 [0.654]] [[-0.034]
 [-0.12 ]
 [-0.12 ]
 [-0.357]
 [-0.236]
 [-0.215]
 [-0.147]] [[0.648]
 [0.65 ]
 [0.65 ]
 [0.642]
 [0.645]
 [0.651]
 [0.654]]
Printing some Q and Qe and total Qs values:  [[0.652]
 [0.621]
 [0.642]
 [0.641]
 [0.645]
 [0.646]
 [0.648]] [[-0.276]
 [ 1.139]
 [-0.257]
 [-0.457]
 [-0.212]
 [-0.346]
 [-0.324]] [[0.652]
 [0.621]
 [0.642]
 [0.641]
 [0.645]
 [0.646]
 [0.648]]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.012235647212651902, 0.00446937324156784, 0.963151853380752, 0.02014312616502826]
Printing some Q and Qe and total Qs values:  [[0.575]
 [0.452]
 [0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.575]] [[1.32 ]
 [1.705]
 [1.32 ]
 [1.32 ]
 [1.32 ]
 [1.32 ]
 [1.32 ]] [[2.128]
 [2.268]
 [2.128]
 [2.128]
 [2.128]
 [2.128]
 [2.128]]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.012358552329566216, 0.004507354326106774, 0.9627815939566929, 0.02035249938763411]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.012482681033127585, 0.004545713532802348, 0.9624076484006117, 0.02056395703345849]
maxi score, test score, baseline:  -0.9947979591836735 -1.0 -0.9947979591836735
probs:  [0.012608051686941549, 0.004584456536517365, 0.9620299613909858, 0.020777530385555226]
maxi score, test score, baseline:  -0.9948238578680203 -1.0 -0.9948238578680203
probs:  [0.012734931285907612, 0.004623664385565324, 0.9616477285622711, 0.020993675766255958]
Printing some Q and Qe and total Qs values:  [[0.775]
 [0.833]
 [0.704]
 [0.704]
 [0.704]
 [0.704]
 [0.704]] [[1.058]
 [1.581]
 [1.787]
 [1.787]
 [1.787]
 [1.787]
 [1.787]] [[1.258]
 [1.834]
 [1.788]
 [1.788]
 [1.788]
 [1.788]
 [1.788]]
maxi score, test score, baseline:  -0.9948494949494949 -1.0 -0.9948494949494949
probs:  [0.013254729877625302, 0.004784294970023406, 0.960081802459713, 0.02187917269263827]
Printing some Q and Qe and total Qs values:  [[0.5  ]
 [0.474]
 [0.499]
 [0.497]
 [0.474]
 [0.474]
 [0.474]] [[1.157]
 [1.165]
 [1.196]
 [1.156]
 [1.165]
 [1.165]
 [1.165]] [[0.166]
 [0.123]
 [0.204]
 [0.159]
 [0.123]
 [0.123]
 [0.123]]
maxi score, test score, baseline:  -0.9948494949494949 -1.0 -0.9948494949494949
probs:  [0.013522587074742642, 0.0048670701949561634, 0.9592748657415943, 0.02233547698870703]
from probs:  [0.013522587074742642, 0.0048670701949561634, 0.9592748657415943, 0.02233547698870703]
maxi score, test score, baseline:  -0.9948494949494949 -1.0 -0.9948494949494949
probs:  [0.013658609564507445, 0.004909104877269603, 0.9588650894030732, 0.02256719615514962]
maxi score, test score, baseline:  -0.9948494949494949 -1.0 -0.9948494949494949
maxi score, test score, baseline:  -0.9948494949494949 -1.0 -0.9948494949494949
probs:  [0.013658609564507445, 0.004909104877269603, 0.9588650894030732, 0.02256719615514962]
siam score:  -0.8649753
siam score:  -0.8662586
maxi score, test score, baseline:  -0.9948748743718593 -1.0 -0.9948748743718593
probs:  [0.021686684503077966, 0.004777569598835672, 0.9431639251032842, 0.03037182079480226]
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.863199
maxi score, test score, baseline:  -0.9948748743718593 -1.0 -0.9948748743718593
probs:  [0.02190557853616245, 0.004817576016697623, 0.9425942474350707, 0.030682598012069177]
maxi score, test score, baseline:  -0.9948748743718593 -1.0 -0.9948748743718593
maxi score, test score, baseline:  -0.9948748743718593 -1.0 -0.9948748743718593
probs:  [0.022575499617343207, 0.00494001490793006, 0.9408507596202759, 0.0316337258544508]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.12488079190223131
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]] [[1.309]
 [1.309]
 [1.309]
 [1.309]
 [1.309]
 [1.309]
 [1.309]] [[1.19]
 [1.19]
 [1.19]
 [1.19]
 [1.19]
 [1.19]
 [1.19]]
using another actor
maxi score, test score, baseline:  -0.9948748743718593 -1.0 -0.9948748743718593
probs:  [0.023738218217303753, 0.005152520500295556, 0.9378247528740884, 0.03328450840831224]
maxi score, test score, baseline:  -0.9949 -1.0 -0.9949
probs:  [0.023738713452028933, 0.0051526090757571434, 0.9378234649541907, 0.03328521251802312]
maxi score, test score, baseline:  -0.9949 -1.0 -0.9949
probs:  [0.023978516566014706, 0.005196436945240644, 0.9371993708447868, 0.033625675643957784]
siam score:  -0.8618778
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
probs:  [0.024221331354715284, 0.005240813288685632, 0.9365674397225142, 0.03397041563408503]
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
probs:  [0.024221331354715284, 0.005240813288685632, 0.9365674397225142, 0.03397041563408503]
siam score:  -0.8576816
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
probs:  [0.024221331354715284, 0.005240813288685632, 0.9365674397225142, 0.03397041563408503]
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
probs:  [0.024221331354715284, 0.005240813288685632, 0.9365674397225142, 0.03397041563408503]
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
probs:  [0.024221331354715284, 0.005240813288685632, 0.9365674397225142, 0.03397041563408503]
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
probs:  [0.024221331354715284, 0.005240813288685632, 0.9365674397225142, 0.03397041563408503]
maxi score, test score, baseline:  -0.9949248756218906 -1.0 -0.9949248756218906
maxi score, test score, baseline:  -0.9949495049504951 -1.0 -0.9949495049504951
maxi score, test score, baseline:  -0.9949738916256158 -1.0 -0.9949738916256158
probs:  [0.024467206185596915, 0.005285746942755821, 0.9359275457113185, 0.03431950116032886]
379 287
maxi score, test score, baseline:  -0.9949980392156863 -1.0 -0.9949980392156863
probs:  [0.024965275915275358, 0.005376775097310343, 0.9346313067429115, 0.03502664224450274]
Printing some Q and Qe and total Qs values:  [[0.243]
 [0.286]
 [0.221]
 [0.218]
 [0.211]
 [0.216]
 [0.266]] [[-0.645]
 [-0.069]
 [-1.086]
 [-1.158]
 [-1.005]
 [-0.741]
 [ 0.812]] [[0.243]
 [0.286]
 [0.221]
 [0.218]
 [0.211]
 [0.216]
 [0.266]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9949980392156863 -1.0 -0.9949980392156863
maxi score, test score, baseline:  -0.9950219512195122 -1.0 -0.9950219512195122
maxi score, test score, baseline:  -0.9950219512195122 -1.0 -0.9950219512195122
probs:  [0.027361945260486423, 0.005814801970118752, 0.950331071758067, 0.016492181011327763]
UNIT TEST: sample policy line 217 mcts : [0.02  0.878 0.02  0.02  0.02  0.02  0.02 ]
maxi score, test score, baseline:  -0.9950219512195122 -1.0 -0.9950219512195122
maxi score, test score, baseline:  -0.9950219512195122 -1.0 -0.9950219512195122
probs:  [0.027361945260486423, 0.005814801970118752, 0.950331071758067, 0.016492181011327763]
from probs:  [0.027361945260486423, 0.005814801970118752, 0.950331071758067, 0.016492181011327763]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9950456310679612 -1.0 -0.9950456310679612
probs:  [0.027362534996671923, 0.005814907638491726, 0.9503300308122463, 0.016492526552589926]
siam score:  -0.8651828
maxi score, test score, baseline:  -0.9950456310679612 -1.0 -0.9950456310679612
probs:  [0.028227352647459902, 0.005972966523389662, 0.9487988711817796, 0.01700080964737081]
maxi score, test score, baseline:  -0.9950690821256039 -1.0 -0.9950690821256039
probs:  [0.02882158299227233, 0.006081569156489117, 0.9477467896957676, 0.017350058155471054]
maxi score, test score, baseline:  -0.9950690821256039 -1.0 -0.9950690821256039
probs:  [0.02912368935169461, 0.0061367837713762075, 0.9472119104295916, 0.01752761644733762]
maxi score, test score, baseline:  -0.9950690821256039 -1.0 -0.9950690821256039
probs:  [0.03005197114116787, 0.006306441641572948, 0.9455683876540119, 0.018073199563247266]
maxi score, test score, baseline:  -0.9950690821256039 -1.0 -0.9950690821256039
probs:  [0.03005197114116787, 0.006306441641572948, 0.9455683876540119, 0.018073199563247266]
maxi score, test score, baseline:  -0.9950690821256039 -1.0 -0.9950690821256039
probs:  [0.03005197114116787, 0.006306441641572948, 0.9455683876540119, 0.018073199563247266]
maxi score, test score, baseline:  -0.9950690821256039 -1.0 -0.9950690821256039
maxi score, test score, baseline:  -0.9950690821256039 -1.0 -0.9950690821256039
probs:  [0.018281081632344657, 0.006371085924115268, 0.9570667508111954, 0.018281081632344657]
from probs:  [0.018281081632344657, 0.006371085924115268, 0.9570667508111954, 0.018281081632344657]
maxi score, test score, baseline:  -0.9950690821256039 -1.0 -0.9950690821256039
probs:  [0.018471965070562348, 0.0064304442081960286, 0.9566256256506792, 0.018471965070562348]
maxi score, test score, baseline:  -0.9950690821256039 -1.0 -0.9950690821256039
probs:  [0.018471965070562348, 0.0064304442081960286, 0.9566256256506792, 0.018471965070562348]
maxi score, test score, baseline:  -0.9950690821256039 -1.0 -0.9950690821256039
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.165]
 [0.132]
 [0.167]
 [0.147]
 [0.15 ]
 [0.149]
 [0.154]] [[-0.724]
 [ 1.037]
 [-0.926]
 [-0.794]
 [-1.045]
 [-1.021]
 [-1.675]] [[0.165]
 [0.132]
 [0.167]
 [0.147]
 [0.15 ]
 [0.149]
 [0.154]]
maxi score, test score, baseline:  -0.9951380952380953 -1.0 -0.9951380952380953
probs:  [0.019289044445181106, 0.006684522085259677, 0.9673419113842995, 0.006684522085259677]
maxi score, test score, baseline:  -0.9951380952380953 -1.0 -0.9951380952380953
probs:  [0.019289044445181106, 0.006684522085259677, 0.9673419113842995, 0.006684522085259677]
maxi score, test score, baseline:  -0.9951380952380953 -1.0 -0.9951380952380953
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9951380952380953 -1.0 -0.9951380952380953
probs:  [0.01970354291769918, 0.006813416932196741, 0.9666696232179075, 0.006813416932196741]
maxi score, test score, baseline:  -0.9951380952380953 -1.0 -0.9951380952380953
probs:  [0.01970354291769918, 0.006813416932196741, 0.9666696232179075, 0.006813416932196741]
392 307
siam score:  -0.8708344
maxi score, test score, baseline:  -0.9951380952380953 -1.0 -0.9951380952380953
maxi score, test score, baseline:  -0.9951380952380953 -1.0 -0.9951380952380953
probs:  [0.00702555313943742, 0.00702555313943742, 0.9789233405816878, 0.00702555313943742]
maxi score, test score, baseline:  -0.995160663507109 -1.0 -0.995160663507109
probs:  [0.007095030336826253, 0.007095030336826253, 0.9787149089895214, 0.007095030336826253]
Printing some Q and Qe and total Qs values:  [[1.464]
 [1.461]
 [1.461]
 [1.461]
 [1.461]
 [1.461]
 [1.461]] [[0.284]
 [0.297]
 [0.297]
 [0.297]
 [0.297]
 [0.289]
 [0.288]] [[2.2  ]
 [2.204]
 [2.204]
 [2.204]
 [2.204]
 [2.197]
 [2.197]]
maxi score, test score, baseline:  -0.995160663507109 -1.0 -0.995160663507109
probs:  [0.007236585927594733, 0.007236585927594733, 0.9782902422172159, 0.007236585927594733]
siam score:  -0.8662763
Printing some Q and Qe and total Qs values:  [[0.466]
 [0.513]
 [0.474]
 [0.468]
 [0.473]
 [0.483]
 [0.475]] [[-0.335]
 [ 0.172]
 [-0.31 ]
 [-0.499]
 [-0.355]
 [-0.246]
 [-0.407]] [[0.466]
 [0.513]
 [0.474]
 [0.468]
 [0.473]
 [0.483]
 [0.475]]
siam score:  -0.8658971
maxi score, test score, baseline:  -0.995160663507109 -1.0 -0.995160663507109
probs:  [0.007456459270289537, 0.007456459270289537, 0.9776306221891312, 0.007456459270289537]
using explorer policy with actor:  1
396 313
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.007456620704817934, 0.007456620704817934, 0.9776301378855462, 0.007456620704817934]
siam score:  -0.86178625
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.007608489290449819, 0.007608489290449819, 0.9771745321286504, 0.007608489290449819]
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.007608489290449819, 0.007608489290449819, 0.9771745321286504, 0.007608489290449819]
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.007608489290449819, 0.007608489290449819, 0.9771745321286504, 0.007608489290449819]
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.0077647984178402536, 0.0077647984178402536, 0.9767056047464792, 0.0077647984178402536]
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.007925745734498417, 0.007925745734498417, 0.9762227627965048, 0.007925745734498417]
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.007925745734498417, 0.007925745734498417, 0.9762227627965048, 0.007925745734498417]
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
siam score:  -0.84878737
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9951830188679245 -1.0 -0.9951830188679245
probs:  [0.00826240596746158, 0.00826240596746158, 0.9752127820976152, 0.00826240596746158]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.2708072844283481
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.008438979036872277, 0.008438979036872277, 0.9746830628893831, 0.008438979036872277]
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.008438979036872277, 0.008438979036872277, 0.9746830628893831, 0.008438979036872277]
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.008438979036872277, 0.008438979036872277, 0.9746830628893831, 0.008438979036872277]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.008438979036872277, 0.008438979036872277, 0.9746830628893831, 0.008438979036872277]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9952271028037384 -1.0 -0.9952271028037384
probs:  [0.008438979036872277, 0.008438979036872277, 0.9746830628893831, 0.008438979036872277]
using explorer policy with actor:  0
using explorer policy with actor:  0
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.7563052567259783
maxi score, test score, baseline:  -0.9952488372093024 -1.0 -0.9952488372093024
probs:  [0.008529342582448932, 0.008529342582448932, 0.9744119722526533, 0.008529342582448932]
using another actor
maxi score, test score, baseline:  -0.9952703703703704 -1.0 -0.9952703703703704
probs:  [0.008621134582525381, 0.008621134582525381, 0.974136596252424, 0.008621134582525381]
maxi score, test score, baseline:  -0.9952917050691245 -1.0 -0.9952917050691245
probs:  [0.009002640270412273, 0.009002640270412273, 0.9729920791887633, 0.009002640270412273]
line 256 mcts: sample exp_bonus -0.10595897120824452
maxi score, test score, baseline:  -0.9952917050691245 -1.0 -0.9952917050691245
maxi score, test score, baseline:  -0.9952917050691245 -1.0 -0.9952917050691245
probs:  [0.009002640270412273, 0.009002640270412273, 0.9729920791887633, 0.009002640270412273]
Printing some Q and Qe and total Qs values:  [[0.854]
 [0.854]
 [0.854]
 [0.854]
 [0.854]
 [0.854]
 [0.854]] [[1.518]
 [1.518]
 [1.518]
 [1.518]
 [1.518]
 [1.518]
 [1.518]] [[1.117]
 [1.117]
 [1.117]
 [1.117]
 [1.117]
 [1.117]
 [1.117]]
Printing some Q and Qe and total Qs values:  [[0.552]
 [0.735]
 [0.516]
 [0.516]
 [0.516]
 [0.516]
 [0.666]] [[3.354]
 [3.466]
 [2.783]
 [2.783]
 [2.783]
 [2.783]
 [2.836]] [[1.24 ]
 [1.545]
 [0.831]
 [0.831]
 [0.831]
 [0.831]
 [1.056]]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.009002857728586106, 0.009002857728586106, 0.9729914268142418, 0.009002857728586106]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.009202989289970213, 0.009202989289970213, 0.9723910321300895, 0.009202989289970213]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.009305561288956474, 0.009305561288956474, 0.9720833161331307, 0.009305561288956474]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.009305561288956474, 0.009305561288956474, 0.9720833161331307, 0.009305561288956474]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.009409860365438808, 0.009409860365438808, 0.9717704189036835, 0.009409860365438808]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.009409860365438808, 0.009409860365438808, 0.9717704189036835, 0.009409860365438808]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.925]
 [0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]] [[2.697]
 [2.6  ]
 [2.6  ]
 [2.6  ]
 [2.6  ]
 [2.6  ]
 [2.6  ]] [[1.309]
 [0.666]
 [0.666]
 [0.666]
 [0.666]
 [0.666]
 [0.666]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.009093343217503509, 0.026874819341002627, 0.937157018100491, 0.026874819341002627]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
Printing some Q and Qe and total Qs values:  [[0.075]
 [0.055]
 [0.084]
 [0.084]
 [0.084]
 [0.086]
 [0.079]] [[-0.885]
 [-0.151]
 [-1.21 ]
 [-1.363]
 [-1.194]
 [-1.145]
 [-0.973]] [[0.075]
 [0.055]
 [0.084]
 [0.084]
 [0.084]
 [0.086]
 [0.079]]
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.009492668268926707, 0.02815104965026822, 0.9342052324305369, 0.02815104965026822]
siam score:  -0.8671458
maxi score, test score, baseline:  -0.9953128440366973 -1.0 -0.9953128440366973
probs:  [0.009596600258824233, 0.028483213022279918, 0.9334369736966158, 0.028483213022279918]
Printing some Q and Qe and total Qs values:  [[0.727]
 [0.643]
 [0.569]
 [0.757]
 [0.744]
 [0.675]
 [0.702]] [[2.603]
 [2.917]
 [2.176]
 [2.007]
 [2.129]
 [2.176]
 [3.388]] [[1.386]
 [1.496]
 [0.822]
 [0.98 ]
 [1.052]
 [0.983]
 [1.943]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
probs:  [0.009702499019137945, 0.028821671285352284, 0.9326541584101574, 0.028821671285352284]
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
probs:  [0.0098099229103276, 0.02916499477705899, 0.9318600875355544, 0.02916499477705899]
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
probs:  [0.009919156497057068, 0.029514102000715758, 0.9310526395015114, 0.029514102000715758]
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
probs:  [0.009919156497057068, 0.029514102000715758, 0.9310526395015114, 0.029514102000715758]
using explorer policy with actor:  1
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9953337899543379 -1.0 -0.9953337899543379
probs:  [0.010258184586010619, 0.030597625470190286, 0.9285465644736087, 0.030597625470190286]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.010651798676199194, 0.0530551984007364, 0.8832378045223279, 0.0530551984007364]
Printing some Q and Qe and total Qs values:  [[0.197]
 [0.195]
 [0.195]
 [0.195]
 [0.195]
 [0.195]
 [0.195]] [[-1.204]
 [-1.536]
 [-1.536]
 [-1.536]
 [-1.536]
 [-1.536]
 [-1.536]] [[0.197]
 [0.195]
 [0.195]
 [0.195]
 [0.195]
 [0.195]
 [0.195]]
using explorer policy with actor:  1
from probs:  [0.011670819835889742, 0.05854925413047466, 0.8712306719031608, 0.05854925413047466]
maxi score, test score, baseline:  -0.9953545454545455 -1.0 -0.9953545454545455
probs:  [0.011808809262849447, 0.059293224552110696, 0.8696047416329291, 0.059293224552110696]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
probs:  [0.011809153004832026, 0.05929510035551267, 0.8696006462841425, 0.05929510035551267]
maxi score, test score, baseline:  -0.995375113122172 -1.0 -0.995375113122172
Printing some Q and Qe and total Qs values:  [[0.524]
 [0.524]
 [0.524]
 [0.524]
 [0.524]
 [0.524]
 [0.524]] [[1.783]
 [1.783]
 [1.783]
 [1.783]
 [1.783]
 [1.783]
 [1.783]] [[0.524]
 [0.524]
 [0.524]
 [0.524]
 [0.524]
 [0.524]
 [0.524]]
Printing some Q and Qe and total Qs values:  [[0.972]
 [1.266]
 [0.972]
 [0.972]
 [0.972]
 [0.972]
 [0.972]] [[0.195]
 [0.521]
 [0.195]
 [0.195]
 [0.195]
 [0.195]
 [0.195]] [[1.203]
 [1.788]
 [1.203]
 [1.203]
 [1.203]
 [1.203]
 [1.203]]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
Printing some Q and Qe and total Qs values:  [[0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]] [[-1.015]
 [-1.015]
 [-1.015]
 [-1.015]
 [-1.015]
 [-1.015]
 [-1.015]] [[0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]
 [0.562]]
maxi score, test score, baseline:  -0.9953954954954956 -1.0 -0.9953954954954956
probs:  [0.011950077056591752, 0.06005491571331003, 0.8679400915167882, 0.06005491571331003]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9954156950672646 -1.0 -0.9954156950672646
probs:  [0.012388414255667666, 0.06241823718956858, 0.8627751113651954, 0.06241823718956858]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.012388780511102258, 0.062420234946810205, 0.8627707495952772, 0.062420234946810205]
maxi score, test score, baseline:  -0.9954357142857143 -1.0 -0.9954357142857143
probs:  [0.012695103084965497, 0.06407177656704138, 0.8591613437809518, 0.06407177656704138]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.01301407493541389, 0.0657915410419166, 0.855402842980753, 0.0657915410419166]
Printing some Q and Qe and total Qs values:  [[0.865]
 [0.893]
 [0.865]
 [0.865]
 [0.865]
 [0.865]
 [0.865]] [[-0.805]
 [ 0.548]
 [-0.805]
 [-0.805]
 [-0.805]
 [-0.805]
 [-0.805]] [[0.505]
 [1.058]
 [0.505]
 [0.505]
 [0.505]
 [0.505]
 [0.505]]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.01301407493541389, 0.0657915410419166, 0.855402842980753, 0.0657915410419166]
Printing some Q and Qe and total Qs values:  [[0.841]
 [0.884]
 [0.841]
 [0.841]
 [0.841]
 [0.841]
 [0.841]] [[1.322]
 [1.998]
 [1.322]
 [1.322]
 [1.322]
 [1.322]
 [1.322]] [[1.337]
 [1.643]
 [1.337]
 [1.337]
 [1.337]
 [1.337]
 [1.337]]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.01301407493541389, 0.0657915410419166, 0.855402842980753, 0.0657915410419166]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.013345668536878933, 0.06757933235914276, 0.8514956667448357, 0.06757933235914276]
maxi score, test score, baseline:  -0.9954555555555555 -1.0 -0.9954555555555555
probs:  [0.013516592353114263, 0.06850087039010136, 0.849481666866683, 0.06850087039010136]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
siam score:  -0.85541797
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.014060816756213361, 0.07143511528565694, 0.8720077435974117, 0.04249632436071808]
Printing some Q and Qe and total Qs values:  [[0.759]
 [0.83 ]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]] [[-0.34 ]
 [ 1.619]
 [-0.34 ]
 [-0.34 ]
 [-0.34 ]
 [-0.34 ]
 [-0.34 ]] [[0.32 ]
 [1.323]
 [0.32 ]
 [0.32 ]
 [0.32 ]
 [0.32 ]
 [0.32 ]]
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.014249576495938868, 0.07245281668370468, 0.8702016875997793, 0.04309591922057705]
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.014442511117352903, 0.07349302702850888, 0.8683556862720462, 0.04370877558209203]
first move QE:  0.31501431335874874
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.014639760675813565, 0.07455650143095147, 0.8664683995624629, 0.044335338330771995]
maxi score, test score, baseline:  -0.9954947136563876 -1.0 -0.9954947136563876
probs:  [0.014639760675813565, 0.07455650143095147, 0.8664683995624629, 0.044335338330771995]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9955140350877193 -1.0 -0.9955140350877193
probs:  [0.014841973158936022, 0.0756467606022212, 0.8645335870224894, 0.04497767921635335]
maxi score, test score, baseline:  -0.9955140350877193 -1.0 -0.9955140350877193
probs:  [0.014841973158936022, 0.0756467606022212, 0.8645335870224894, 0.04497767921635335]
maxi score, test score, baseline:  -0.9955140350877193 -1.0 -0.9955140350877193
probs:  [0.014841973158936022, 0.0756467606022212, 0.8645335870224894, 0.04497767921635335]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9955140350877193 -1.0 -0.9955140350877193
probs:  [0.015475482113447172, 0.07906233631477269, 0.8584721620690795, 0.04699001950270055]
first move QE:  0.31743782194757414
maxi score, test score, baseline:  -0.9955140350877193 -1.0 -0.9955140350877193
siam score:  -0.8571082
maxi score, test score, baseline:  -0.9955140350877193 -1.0 -0.9955140350877193
probs:  [0.01639277827968268, 0.08400795623742706, 0.8496954560223959, 0.04990380946049432]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.018380457283252393, 0.018380457283252393, 0.9070213997661862, 0.056217685667308955]
line 256 mcts: sample exp_bonus 0.5724211754735511
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.016504567129208024, 0.04996206823464268, 0.8495268215924668, 0.08400654304368256]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
siam score:  -0.8509399
siam score:  -0.8494821
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.016504567129208024, 0.04996206823464268, 0.8495268215924668, 0.08400654304368256]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.016999339072244917, 0.051524240518636154, 0.8448215784187159, 0.08665484199040317]
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.01725616295780613, 0.05233512553654673, 0.8423792029942411, 0.08802950851140609]
from probs:  [0.01725616295780613, 0.05233512553654673, 0.8423792029942411, 0.08802950851140609]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9955331877729258 -1.0 -0.9955331877729258
probs:  [0.01751960296345237, 0.053166900015894615, 0.8398739087759564, 0.08943958824469662]
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
probs:  [0.017520279595840904, 0.053169052117023254, 0.8398674265871552, 0.08944324169998068]
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
probs:  [0.017520279595840904, 0.053169052117023254, 0.8398674265871552, 0.08944324169998068]
maxi score, test score, baseline:  -0.9955521739130435 -1.0 -0.9955521739130435
probs:  [0.017520279595840904, 0.053169052117023254, 0.8398674265871552, 0.08944324169998068]
first move QE:  0.3301007192912794
maxi score, test score, baseline:  -0.9955709956709957 -1.0 -0.9955709956709957
probs:  [0.017791305627752167, 0.05402479450605772, 0.8372899412383492, 0.09089395862784076]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.01779199046835074, 0.05402697250656834, 0.8372833810410277, 0.09089765598405332]
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.76 ]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]] [[4.151]
 [5.117]
 [4.151]
 [4.151]
 [4.151]
 [4.151]
 [4.151]] [[1.447]
 [1.921]
 [1.447]
 [1.447]
 [1.447]
 [1.447]
 [1.447]]
in main func line 156:  447
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.018354478862775876, 0.05580295148052273, 0.8319341548107524, 0.09390841484594907]
first move QE:  0.3310541482044759
siam score:  -0.85517395
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.018354478862775876, 0.05580295148052273, 0.8319341548107524, 0.09390841484594907]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.02036828203842778, 0.06216125528391793, 0.8553092073937364, 0.06216125528391793]
siam score:  -0.84897345
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.02036828203842778, 0.06216125528391793, 0.8553092073937364, 0.06216125528391793]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.021090893501390973, 0.06444280060517207, 0.8500235052882648, 0.06444280060517207]
maxi score, test score, baseline:  -0.9955896551724138 -1.0 -0.9955896551724138
probs:  [0.021090893501390973, 0.06444280060517207, 0.8500235052882648, 0.06444280060517207]
maxi score, test score, baseline:  -0.9956081545064378 -1.0 -0.9956081545064378
probs:  [0.019573463179891306, 0.0997220293650454, 0.780982478090018, 0.0997220293650454]
from probs:  [0.019573463179891306, 0.0997220293650454, 0.780982478090018, 0.0997220293650454]
maxi score, test score, baseline:  -0.9956264957264958 -1.0 -0.9956264957264958
probs:  [0.02181337865827314, 0.06633238602250936, 0.8002285983261375, 0.11162563699308001]
maxi score, test score, baseline:  -0.9956264957264958 -1.0 -0.9956264957264958
probs:  [0.02181337865827314, 0.06633238602250936, 0.8002285983261375, 0.11162563699308001]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9956446808510638 -1.0 -0.9956446808510638
probs:  [0.021814366123408004, 0.06633550420440995, 0.800219206724491, 0.11163092294769109]
maxi score, test score, baseline:  -0.9956627118644068 -1.0 -0.9956627118644068
maxi score, test score, baseline:  -0.9956627118644068 -1.0 -0.9956627118644068
probs:  [0.022207184777127808, 0.06756840539788099, 0.7965058930129539, 0.11371851681203733]
line 256 mcts: sample exp_bonus 4.784608260089114
from probs:  [0.022207184777127808, 0.06756840539788099, 0.7965058930129539, 0.11371851681203733]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.02220818962831089, 0.06757157817990939, 0.7964963369637208, 0.11372389522805883]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.02220818962831089, 0.06757157817990939, 0.7964963369637208, 0.11372389522805883]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.02220818962831089, 0.06757157817990939, 0.7964963369637208, 0.11372389522805883]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.02323885439504198, 0.07080637567525302, 0.835148394254452, 0.07080637567525302]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.02323885439504198, 0.07080637567525302, 0.835148394254452, 0.07080637567525302]
maxi score, test score, baseline:  -0.9956805907172996 -1.0 -0.9956805907172996
probs:  [0.02323885439504198, 0.07080637567525302, 0.835148394254452, 0.07080637567525302]
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
line 256 mcts: sample exp_bonus 3.3027102645562083
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
probs:  [0.02323995049238476, 0.07080983559502152, 0.835140378317572, 0.07080983559502152]
maxi score, test score, baseline:  -0.9956983193277311 -1.0 -0.9956983193277311
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.023687245457149605, 0.07221373540151299, 0.8318852837398243, 0.07221373540151299]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.023687245457149605, 0.07221373540151299, 0.8318852837398243, 0.07221373540151299]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.02414764371038735, 0.07365872160691848, 0.8285349130757756, 0.07365872160691848]
Printing some Q and Qe and total Qs values:  [[0.859]
 [0.909]
 [0.827]
 [0.859]
 [0.834]
 [0.859]
 [0.859]] [[1.773]
 [2.904]
 [0.698]
 [1.773]
 [0.775]
 [1.773]
 [1.318]] [[0.825]
 [1.359]
 [0.331]
 [0.825]
 [0.37 ]
 [0.825]
 [0.628]]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.02414764371038735, 0.07365872160691848, 0.8285349130757756, 0.07365872160691848]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.02414764371038735, 0.07365872160691848, 0.8285349130757756, 0.07365872160691848]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.02414764371038735, 0.07365872160691848, 0.8285349130757756, 0.07365872160691848]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.02414764371038735, 0.07365872160691848, 0.8285349130757756, 0.07365872160691848]
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.02414764371038735, 0.07365872160691848, 0.8285349130757756, 0.07365872160691848]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.026158787977408667, 0.07997081272040357, 0.8138995865817842, 0.07997081272040357]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9957333333333334 -1.0 -0.9957333333333334
probs:  [0.026158787977408667, 0.07997081272040357, 0.8138995865817842, 0.07997081272040357]
Printing some Q and Qe and total Qs values:  [[0.632]
 [0.626]
 [0.628]
 [0.625]
 [0.635]
 [0.642]
 [0.653]] [[2.326]
 [3.734]
 [2.407]
 [2.286]
 [2.541]
 [2.608]
 [2.747]] [[0.632]
 [0.626]
 [0.628]
 [0.625]
 [0.635]
 [0.642]
 [0.653]]
maxi score, test score, baseline:  -0.9957677685950413 -1.0 -0.9957677685950413
probs:  [0.02671152003444131, 0.08170563820078859, 0.8098772035639815, 0.08170563820078859]
Printing some Q and Qe and total Qs values:  [[-0.028]
 [-0.029]
 [-0.024]
 [-0.041]
 [-0.041]
 [-0.019]
 [-0.026]] [[2.794]
 [2.971]
 [2.788]
 [2.865]
 [2.865]
 [2.78 ]
 [2.763]] [[0.756]
 [0.89 ]
 [0.757]
 [0.791]
 [0.791]
 [0.758]
 [0.735]]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.026712896605608594, 0.08170998055591361, 0.8098671422825642, 0.08170998055591361]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.02787745685842006, 0.08536502240377354, 0.8013924983340328, 0.08536502240377354]
Printing some Q and Qe and total Qs values:  [[0.278]
 [0.278]
 [0.278]
 [0.278]
 [0.278]
 [0.278]
 [0.278]] [[-0.664]
 [-0.664]
 [-0.664]
 [-0.664]
 [-0.664]
 [-0.664]
 [-0.664]] [[0.278]
 [0.278]
 [0.278]
 [0.278]
 [0.278]
 [0.278]
 [0.278]]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.02787745685842006, 0.08536502240377354, 0.8013924983340328, 0.08536502240377354]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.02787745685842006, 0.08536502240377354, 0.8013924983340328, 0.08536502240377354]
from probs:  [0.02787745685842006, 0.08536502240377354, 0.8013924983340328, 0.08536502240377354]
maxi score, test score, baseline:  -0.9957847736625515 -1.0 -0.9957847736625515
probs:  [0.029524022529949078, 0.029524022529949078, 0.8504190879184502, 0.09053286702165164]
Printing some Q and Qe and total Qs values:  [[0.475]
 [0.515]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.479]] [[0.058]
 [0.864]
 [0.037]
 [0.037]
 [0.037]
 [0.037]
 [0.004]] [[0.475]
 [0.515]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.479]]
maxi score, test score, baseline:  -0.9958016393442624 -1.0 -0.9958016393442624
probs:  [0.030221660952593734, 0.030221660952593734, 0.8468342065635462, 0.0927224715312664]
maxi score, test score, baseline:  -0.9958016393442624 -1.0 -0.9958016393442624
probs:  [0.030221660952593734, 0.030221660952593734, 0.8468342065635462, 0.0927224715312664]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.03250374943245046, 0.03250374943245046, 0.8351075042191513, 0.0998849969159477]
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.03333410951340961, 0.03333410951340961, 0.830840647304737, 0.10249113366844383]
using explorer policy with actor:  1
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.2803805172884317
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.09573186458940955, 0.03135936358545439, 0.7771769072357265, 0.09573186458940955]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
maxi score, test score, baseline:  -0.9958349593495935 -1.0 -0.9958349593495935
probs:  [0.09573186458940955, 0.03135936358545439, 0.7771769072357265, 0.09573186458940955]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.09573756646155815, 0.031361183046847645, 0.777163684030036, 0.09573756646155815]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
Printing some Q and Qe and total Qs values:  [[0.878]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.86 ]] [[3.869]
 [5.12 ]
 [5.058]
 [5.058]
 [5.058]
 [5.058]
 [5.223]] [[1.555]
 [2.081]
 [2.055]
 [2.055]
 [2.055]
 [2.055]
 [2.106]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.09573756646155815, 0.031361183046847645, 0.777163684030036, 0.09573756646155815]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.11081893514570444, 0.03619484132889423, 0.8167913821965072, 0.03619484132889423]
siam score:  -0.8468879
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.11081893514570444, 0.03619484132889423, 0.8167913821965072, 0.03619484132889423]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.11081893514570444, 0.03619484132889423, 0.8167913821965072, 0.03619484132889423]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.11081893514570444, 0.03619484132889423, 0.8167913821965072, 0.03619484132889423]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
Printing some Q and Qe and total Qs values:  [[-0.03 ]
 [-0.012]
 [-0.004]
 [-0.022]
 [-0.045]
 [ 0.014]
 [-0.002]] [[1.762]
 [1.644]
 [2.03 ]
 [1.36 ]
 [1.562]
 [1.131]
 [2.006]] [[-0.252]
 [-0.304]
 [-0.053]
 [-0.492]
 [-0.396]
 [-0.591]
 [-0.065]]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.041467598472371234, 0.041467598472371234, 0.8755972045828864, 0.041467598472371234]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.04278610485533441, 0.04278610485533441, 0.8716416854339969, 0.04278610485533441]
line 256 mcts: sample exp_bonus 4.387289928220533
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.04278610485533441, 0.04278610485533441, 0.8716416854339969, 0.04278610485533441]
first move QE:  0.37159868704664845
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.04278610485533441, 0.04278610485533441, 0.8716416854339969, 0.04278610485533441]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.045671967865909775, 0.045671967865909775, 0.8629840964022707, 0.045671967865909775]
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.045671967865909775, 0.045671967865909775, 0.8629840964022707, 0.045671967865909775]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.045671967865909775, 0.045671967865909775, 0.8629840964022707, 0.045671967865909775]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.1169823175893905
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.045671967865909775, 0.045671967865909775, 0.8629840964022707, 0.045671967865909775]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9958514170040486 -1.0 -0.9958514170040486
probs:  [0.045671967865909775, 0.045671967865909775, 0.8629840964022707, 0.045671967865909775]
from probs:  [0.0456757928855248, 0.0456757928855248, 0.8629726213434258, 0.0456757928855248]
Printing some Q and Qe and total Qs values:  [[0.266]
 [0.266]
 [0.266]
 [0.266]
 [0.266]
 [0.266]
 [0.266]] [[4.044]
 [4.044]
 [4.044]
 [4.044]
 [4.044]
 [4.044]
 [4.044]] [[0.835]
 [0.835]
 [0.835]
 [0.835]
 [0.835]
 [0.835]
 [0.835]]
Starting evaluation
maxi score, test score, baseline:  -0.9958677419354839 -1.0 -0.9958677419354839
probs:  [0.04894970258931955, 0.04894970258931955, 0.8531508922320415, 0.04894970258931955]
using explorer policy with actor:  0
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.601]
 [0.63 ]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]] [[5.619]
 [5.375]
 [5.619]
 [5.619]
 [5.619]
 [5.619]
 [5.619]] [[0.601]
 [0.63 ]
 [0.601]
 [0.601]
 [0.601]
 [0.601]
 [0.601]]
siam score:  -0.8555999
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.04896264332024025, 0.04896264332024025, 0.8531120700392794, 0.04896264332024025]
Printing some Q and Qe and total Qs values:  [[0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]] [[5.074]
 [5.074]
 [5.074]
 [5.074]
 [5.074]
 [5.074]
 [5.074]] [[0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]]
maxi score, test score, baseline:  -0.9959159362549801 -1.0 -0.9959159362549801
probs:  [0.04896264332024025, 0.04896264332024025, 0.8531120700392794, 0.04896264332024025]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 4.4122141867435305
Printing some Q and Qe and total Qs values:  [[0.518]
 [0.552]
 [0.597]
 [0.588]
 [0.638]
 [0.52 ]
 [0.537]] [[2.886]
 [3.342]
 [3.55 ]
 [3.113]
 [2.751]
 [3.091]
 [3.497]] [[0.518]
 [0.552]
 [0.597]
 [0.588]
 [0.638]
 [0.52 ]
 [0.537]]
Printing some Q and Qe and total Qs values:  [[0.667]
 [0.709]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]] [[1.751]
 [2.432]
 [1.751]
 [1.751]
 [1.751]
 [1.751]
 [1.751]] [[0.667]
 [0.709]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]]
maxi score, test score, baseline:  -0.9960538461538462 -1.0 -0.9960538461538462
Printing some Q and Qe and total Qs values:  [[-0.029]
 [-0.048]
 [-0.041]
 [-0.041]
 [-0.037]
 [-0.037]
 [-0.038]] [[2.554]
 [2.076]
 [2.667]
 [2.771]
 [2.754]
 [2.672]
 [2.731]] [[ 0.274]
 [-0.122]
 [ 0.344]
 [ 0.423]
 [ 0.416]
 [ 0.353]
 [ 0.397]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]] [[4.157]
 [4.157]
 [4.157]
 [4.157]
 [4.157]
 [4.157]
 [4.157]] [[0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]]
using explorer policy with actor:  0
start point for exploration sampling:  10768
rdn probs:  [0.05278406161292363, 0.05278406161292363, 0.8416478151612292, 0.05278406161292363]
maxi score, test score, baseline:  -0.996168656716418 -1.0 -0.996168656716418
probs:  [0.05278841106312553, 0.05278841106312553, 0.8416347668106233, 0.05278841106312553]
maxi score, test score, baseline:  -0.996168656716418 -1.0 -0.996168656716418
probs:  [0.05487813946955379, 0.05487813946955379, 0.8353655815913386, 0.05487813946955379]
maxi score, test score, baseline:  -0.996168656716418 -1.0 -0.996168656716418
probs:  [0.05487813946955379, 0.05487813946955379, 0.8353655815913386, 0.05487813946955379]
maxi score, test score, baseline:  -0.9961825278810409 -1.0 -0.9961825278810409
probs:  [0.05488280006534204, 0.05488280006534204, 0.8353515998039738, 0.05488280006534204]
maxi score, test score, baseline:  -0.9961825278810409 -1.0 -0.9961825278810409
probs:  [0.05488280006534204, 0.05488280006534204, 0.8353515998039738, 0.05488280006534204]
maxi score, test score, baseline:  -0.9961825278810409 -1.0 -0.9961825278810409
maxi score, test score, baseline:  -0.9961825278810409 -1.0 -0.9961825278810409
probs:  [0.05713530209614702, 0.05713530209614702, 0.8285940937115589, 0.05713530209614702]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.0246891067496398
maxi score, test score, baseline:  -0.9961825278810409 -1.0 -0.9961825278810409
probs:  [0.0595699354253276, 0.0595699354253276, 0.8212901937240172, 0.0595699354253276]
maxi score, test score, baseline:  -0.9961825278810409 -1.0 -0.9961825278810409
maxi score, test score, baseline:  -0.9961825278810409 -1.0 -0.9961825278810409
probs:  [0.0595699354253276, 0.0595699354253276, 0.8212901937240172, 0.0595699354253276]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
siam score:  -0.84274554
maxi score, test score, baseline:  -0.9961962962962964 -1.0 -0.9961962962962964
probs:  [0.1417968026559914, 0.04638759177203679, 0.6700188029159805, 0.1417968026559914]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9961962962962964 -1.0 -0.9961962962962964
probs:  [0.1417968026559914, 0.04638759177203679, 0.6700188029159805, 0.1417968026559914]
Printing some Q and Qe and total Qs values:  [[0.898]
 [0.894]
 [0.694]
 [0.882]
 [0.694]
 [0.894]
 [0.894]] [[0.501]
 [0.486]
 [0.343]
 [0.414]
 [0.343]
 [0.48 ]
 [0.471]] [[0.898]
 [0.894]
 [0.694]
 [0.882]
 [0.694]
 [0.894]
 [0.894]]
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.14180690426751486, 0.0463908383448651, 0.6699953531201053, 0.14180690426751486]
from probs:  [0.14180690426751486, 0.0463908383448651, 0.6699953531201053, 0.14180690426751486]
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.14666114635798597, 0.047955756088349094, 0.658721951195679, 0.14666114635798597]
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.15183202066789545, 0.04962275019496507, 0.646713208469244, 0.15183202066789545]
siam score:  -0.8427996
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.15183202066789545, 0.04962275019496507, 0.646713208469244, 0.15183202066789545]
Printing some Q and Qe and total Qs values:  [[0.431]
 [0.431]
 [0.431]
 [0.431]
 [0.431]
 [0.431]
 [0.431]] [[0.244]
 [0.244]
 [0.244]
 [0.244]
 [0.244]
 [0.244]
 [0.244]] [[0.431]
 [0.431]
 [0.431]
 [0.431]
 [0.431]
 [0.431]
 [0.431]]
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.15183202066789545, 0.04962275019496507, 0.646713208469244, 0.15183202066789545]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.15183202066789545, 0.04962275019496507, 0.646713208469244, 0.15183202066789545]
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.15183202066789545, 0.04962275019496507, 0.646713208469244, 0.15183202066789545]
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.15183202066789545, 0.04962275019496507, 0.646713208469244, 0.15183202066789545]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9962099630996311 -1.0 -0.9962099630996311
probs:  [0.1759633920064726, 0.05740225737209375, 0.70923209324934, 0.05740225737209375]
siam score:  -0.84236604
using explorer policy with actor:  1
using another actor
siam score:  -0.84894586
maxi score, test score, baseline:  -0.9962235294117647 -1.0 -0.9962235294117647
probs:  [0.07941068740530452, 0.07941068740530452, 0.7617679377840865, 0.07941068740530452]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.055381361237523054, 0.16872295155905243, 0.6071727356443721, 0.16872295155905243]
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.055381361237523054, 0.16872295155905243, 0.6071727356443721, 0.16872295155905243]
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
line 256 mcts: sample exp_bonus 2.6563011261666465
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
maxi score, test score, baseline:  -0.9962503649635036 -1.0 -0.9962503649635036
probs:  [0.07150772156123544, 0.07150772156123544, 0.6385271596721002, 0.21845739720542912]
using another actor
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.0715151739236023, 0.0715151739236023, 0.6384892247405434, 0.21848042741225207]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9962636363636364 -1.0 -0.9962636363636364
probs:  [0.04980400530170779, 0.15066446696717117, 0.5463114652889796, 0.25322006244214157]
siam score:  -0.85290146
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
probs:  [0.04980757430017864, 0.15067544334131133, 0.5462784116728496, 0.25323857068566036]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
siam score:  -0.8495253
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
probs:  [0.04980757430017864, 0.15067544334131133, 0.5462784116728496, 0.25323857068566036]
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
maxi score, test score, baseline:  -0.9962768115942029 -1.0 -0.9962768115942029
probs:  [0.062335927355607494, 0.18909332579619817, 0.6862348194925868, 0.062335927355607494]
rdn beta is 0 so we're just using the maxi policy
start point for exploration sampling:  10768
from probs:  [0.06234152860481093, 0.18911054197662772, 0.6862064008137504, 0.06234152860481093]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.341]
 [0.359]
 [0.337]
 [0.336]
 [0.331]
 [0.338]
 [0.337]] [[-0.061]
 [ 0.025]
 [-0.474]
 [-0.603]
 [-0.404]
 [-0.347]
 [-0.37 ]] [[0.341]
 [0.359]
 [0.337]
 [0.336]
 [0.331]
 [0.338]
 [0.337]]
siam score:  -0.84690076
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.04673024456989065, 0.23572878045671727, 0.5770924481455709, 0.14044852682782102]
line 256 mcts: sample exp_bonus -0.24831252173114324
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.051480487828253145, 0.2601095946847741, 0.6369294296587196, 0.051480487828253145]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.051480487828253145, 0.2601095946847741, 0.6369294296587196, 0.051480487828253145]
maxi score, test score, baseline:  -0.9962898916967509 -1.0 -0.9962898916967509
probs:  [0.051480487828253145, 0.2601095946847741, 0.6369294296587196, 0.051480487828253145]
Printing some Q and Qe and total Qs values:  [[0.413]
 [0.443]
 [0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]] [[1.169]
 [1.658]
 [0.116]
 [0.116]
 [0.116]
 [0.116]
 [0.116]] [[0.413]
 [0.443]
 [0.408]
 [0.408]
 [0.408]
 [0.408]
 [0.408]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.05334573226936934, 0.26968310513540394, 0.6236254303258575, 0.05334573226936934]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.05533849350215262, 0.2799110347711334, 0.6094119782245614, 0.05533849350215262]
Printing some Q and Qe and total Qs values:  [[0.423]
 [0.441]
 [0.414]
 [0.414]
 [0.414]
 [0.414]
 [0.414]] [[0.417]
 [1.302]
 [0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]] [[0.423]
 [0.441]
 [0.414]
 [0.414]
 [0.414]
 [0.414]
 [0.414]]
Printing some Q and Qe and total Qs values:  [[0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.417]] [[4.291]
 [4.291]
 [4.291]
 [4.291]
 [4.291]
 [4.291]
 [4.101]] [[1.132]
 [1.132]
 [1.132]
 [1.132]
 [1.132]
 [1.132]
 [0.853]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.05747695597605128, 0.2908867820668238, 0.5941593059810736, 0.05747695597605128]
from probs:  [0.05747695597605128, 0.2908867820668238, 0.5941593059810736, 0.05747695597605128]
Printing some Q and Qe and total Qs values:  [[0.481]
 [0.497]
 [0.551]
 [0.551]
 [0.551]
 [0.521]
 [0.502]] [[2.737]
 [3.611]
 [3.854]
 [3.854]
 [3.854]
 [3.177]
 [3.608]] [[1.234]
 [1.795]
 [2.042]
 [2.042]
 [2.042]
 [1.576]
 [1.803]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.07476400130184019, 0.07476400130184019, 0.7757079960944794, 0.07476400130184019]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.07476400130184019, 0.07476400130184019, 0.7757079960944794, 0.07476400130184019]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
Printing some Q and Qe and total Qs values:  [[0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]] [[3.34]
 [3.34]
 [3.34]
 [3.34]
 [3.34]
 [3.34]
 [3.34]] [[0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.545]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]] [[2.225]
 [2.722]
 [2.722]
 [2.722]
 [2.722]
 [2.722]
 [2.722]] [[0.582]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]]
Printing some Q and Qe and total Qs values:  [[0.488]
 [0.499]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.462]] [[4.557]
 [5.783]
 [4.961]
 [4.961]
 [4.961]
 [4.961]
 [6.579]] [[1.054]
 [1.61 ]
 [1.239]
 [1.239]
 [1.239]
 [1.239]
 [1.932]]
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.07476400130184019, 0.07476400130184019, 0.7757079960944794, 0.07476400130184019]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9963028776978418 -1.0 -0.9963028776978418
probs:  [0.07873820428052072, 0.07873820428052072, 0.7637853871584379, 0.07873820428052072]
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.057595043102727644, 0.17261535040192538, 0.5971742560934217, 0.17261535040192538]
maxi score, test score, baseline:  -0.996315770609319 -1.0 -0.996315770609319
probs:  [0.059886500834577035, 0.17956349899358895, 0.5809865011782451, 0.17956349899358895]
506 433
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.06503622227556026, 0.19517850383092325, 0.5446067700625933, 0.19517850383092325]
Printing some Q and Qe and total Qs values:  [[1.137]
 [1.147]
 [1.147]
 [1.147]
 [1.147]
 [1.188]
 [1.234]] [[0.544]
 [0.685]
 [0.685]
 [0.685]
 [0.685]
 [0.594]
 [0.739]] [[1.254]
 [1.389]
 [1.389]
 [1.389]
 [1.389]
 [1.381]
 [1.58 ]]
siam score:  -0.85835665
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.07454710597565095, 0.2240173718566644, 0.47741815031102025, 0.2240173718566644]
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.07454710597565095, 0.2240173718566644, 0.47741815031102025, 0.2240173718566644]
Printing some Q and Qe and total Qs values:  [[0.52]
 [0.52]
 [0.52]
 [0.52]
 [0.52]
 [0.52]
 [0.52]] [[4.437]
 [4.437]
 [4.437]
 [4.437]
 [4.437]
 [4.437]
 [4.437]] [[1.833]
 [1.833]
 [1.833]
 [1.833]
 [1.833]
 [1.833]
 [1.833]]
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.2942009918699658, 0.09822947766983343, 0.5093400527903673, 0.09822947766983343]
first move QE:  0.4146312786960693
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.30857123828675903, 0.1843606961604907, 0.4449305428445116, 0.062137522708238566]
siam score:  -0.83558327
from probs:  [0.30857123828675903, 0.1843606961604907, 0.4449305428445116, 0.062137522708238566]
maxi score, test score, baseline:  -0.9963285714285715 -1.0 -0.9963285714285715
probs:  [0.32149092676789354, 0.1920629243466078, 0.42174037892143673, 0.06470576996406209]
Printing some Q and Qe and total Qs values:  [[0.857]
 [1.216]
 [0.857]
 [0.857]
 [0.857]
 [0.857]
 [0.857]] [[1.17 ]
 [3.577]
 [1.17 ]
 [1.17 ]
 [1.17 ]
 [1.17 ]
 [1.17 ]] [[1.505]
 [2.717]
 [1.505]
 [1.505]
 [1.505]
 [1.505]
 [1.505]]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.23170428947210026, 0.23170428947210026, 0.45866756673521925, 0.07792385432058019]
514 444
Printing some Q and Qe and total Qs values:  [[0.802]
 [0.815]
 [0.816]
 [0.812]
 [0.81 ]
 [0.803]
 [0.799]] [[ 0.757]
 [ 0.908]
 [ 0.177]
 [-0.061]
 [-0.053]
 [ 0.076]
 [-0.101]] [[1.353]
 [1.429]
 [1.186]
 [1.099]
 [1.097]
 [1.128]
 [1.06 ]]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.1041905377222428, 0.310478648746763, 0.48114027580875135, 0.1041905377222428]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.05354829246504189, 0.2619322860576229, 0.4225871354197123, 0.2619322860576229]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.05354829246504189, 0.2619322860576229, 0.4225871354197123, 0.2619322860576229]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.04447335815093953, 0.3030467755291901, 0.4369923432362276, 0.21548752308364275]
first move QE:  0.4263275747982522
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.04447335815093953, 0.3030467755291901, 0.4369923432362276, 0.21548752308364275]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.04447335815093953, 0.3030467755291901, 0.4369923432362276, 0.21548752308364275]
maxi score, test score, baseline:  -0.9963412811387901 -1.0 -0.9963412811387901
probs:  [0.04447335815093953, 0.3030467755291901, 0.4369923432362276, 0.21548752308364275]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.442]
 [0.442]
 [0.39 ]
 [0.438]
 [0.39 ]
 [0.39 ]
 [0.444]] [[ 0.004]
 [ 0.539]
 [-0.103]
 [ 0.01 ]
 [-0.103]
 [-0.103]
 [-0.022]] [[0.442]
 [0.442]
 [0.39 ]
 [0.438]
 [0.39 ]
 [0.39 ]
 [0.444]]
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.433]
 [0.429]
 [0.424]
 [0.433]
 [0.43 ]
 [0.426]] [[ 0.178]
 [ 0.795]
 [-0.006]
 [-0.053]
 [ 0.023]
 [ 0.171]
 [ 0.105]] [[0.424]
 [0.433]
 [0.429]
 [0.424]
 [0.433]
 [0.43 ]
 [0.426]]
maxi score, test score, baseline:  -0.9963539007092199 -1.0 -0.9963539007092199
maxi score, test score, baseline:  -0.9963539007092199 -1.0 -0.9963539007092199
probs:  [0.0355072877087273, 0.30914600069957016, 0.41623919100288537, 0.23910752058881718]
maxi score, test score, baseline:  -0.9963539007092199 -1.0 -0.9963539007092199
maxi score, test score, baseline:  -0.9963539007092199 -1.0 -0.9963539007092199
probs:  [0.0355072877087273, 0.30914600069957016, 0.41623919100288537, 0.23910752058881718]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.038075424563859525, 0.332076903150609, 0.44708648070063567, 0.18276119158489576]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.038075424563859525, 0.332076903150609, 0.44708648070063567, 0.18276119158489576]
Printing some Q and Qe and total Qs values:  [[1.113]
 [1.386]
 [1.113]
 [1.113]
 [1.113]
 [1.113]
 [1.113]] [[0.619]
 [1.031]
 [0.619]
 [0.619]
 [0.619]
 [0.619]
 [0.619]] [[1.214]
 [2.046]
 [1.214]
 [1.214]
 [1.214]
 [1.214]
 [1.214]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.05352969985111116, 0.363453767576706, 0.5294868327210718, 0.05352969985111116]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.06205685891662469, 0.3003194210382005, 0.57556686112855, 0.06205685891662469]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.06205685891662469, 0.3003194210382005, 0.57556686112855, 0.06205685891662469]
siam score:  -0.8496224
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.07025623643430529, 0.340513192996074, 0.5189743341353154, 0.07025623643430529]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.07025623643430529, 0.340513192996074, 0.5189743341353154, 0.07025623643430529]
maxi score, test score, baseline:  -0.9963664310954063 -1.0 -0.9963664310954063
probs:  [0.07025623643430529, 0.340513192996074, 0.5189743341353154, 0.07025623643430529]
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.07026957224737951, 0.34057873842362313, 0.5188821170816179, 0.07026957224737951]
siam score:  -0.8504059
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.09040130067186322, 0.2634706797177067, 0.5557267189385668, 0.09040130067186322]
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.2034205529870504, 0.0703055399377587, 0.5228533540881406, 0.2034205529870504]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.101635972800571, 0.101635972800571, 0.6950920815982872, 0.101635972800571]
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.06728978392363542, 0.19362080541753585, 0.5454686052412928, 0.19362080541753585]
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.07335305997297352, 0.21123840821834572, 0.504170123590335, 0.21123840821834572]
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.16467530943934958, 0.2733826802782291, 0.5043269903056021, 0.0576150199768193]
maxi score, test score, baseline:  -0.9963912280701754 -1.0 -0.9963912280701754
probs:  [0.16467530943934958, 0.2733826802782291, 0.5043269903056021, 0.0576150199768193]
Printing some Q and Qe and total Qs values:  [[0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.815]
 [0.725]] [[1.997]
 [1.997]
 [1.997]
 [1.997]
 [1.997]
 [1.997]
 [2.069]] [[2.24 ]
 [2.24 ]
 [2.24 ]
 [2.24 ]
 [2.24 ]
 [2.24 ]
 [2.184]]
start point for exploration sampling:  10768
siam score:  -0.8393882
maxi score, test score, baseline:  -0.9964034965034965 -1.0 -0.9964034965034965
probs:  [0.19243543792105355, 0.19243543792105355, 0.5479114934767385, 0.06721763068115441]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
Printing some Q and Qe and total Qs values:  [[0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]] [[0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]
 [0.322]] [[0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.2536956063412205, 0.05384649466466504, 0.5394438527020671, 0.1530140462920474]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.26245148469922336, 0.055677729777339945, 0.5235894122053142, 0.1582813733181226]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.26245148469922336, 0.055677729777339945, 0.5235894122053142, 0.1582813733181226]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.2717882681507923, 0.05763045741891684, 0.5066831154739655, 0.16389815895632537]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.2717882681507923, 0.05763045741891684, 0.5066831154739655, 0.16389815895632537]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.18368761835828742, 0.06451044659337403, 0.5681143166900512, 0.18368761835828742]
start point for exploration sampling:  10768
from probs:  [0.20851848734309925, 0.07314312858522948, 0.6451952554864419, 0.07314312858522948]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.21835845068831183, 0.07656408314073329, 0.6285133830302214, 0.07656408314073329]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.24094762480186432, 0.08441741911138444, 0.5902175369753667, 0.08441741911138444]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.24094762480186432, 0.08441741911138444, 0.5902175369753667, 0.08441741911138444]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
probs:  [0.24094762480186432, 0.08441741911138444, 0.5902175369753667, 0.08441741911138444]
maxi score, test score, baseline:  -0.9964156794425088 -1.0 -0.9964156794425088
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.447247540249802
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.27019649789603295, 0.16311983644898767, 0.509042331526964, 0.05764133412801534]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.27019649789603295, 0.16311983644898767, 0.509042331526964, 0.05764133412801534]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.3144523770889321, 0.06695368134406642, 0.5516402602229351, 0.06695368134406642]
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]] [[0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]] [[0.437]
 [0.437]
 [0.437]
 [0.437]
 [0.437]
 [0.437]
 [0.437]]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.3144523770889321, 0.06695368134406642, 0.5516402602229351, 0.06695368134406642]
siam score:  -0.8388576
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.3144523770889321, 0.06695368134406642, 0.5516402602229351, 0.06695368134406642]
in main func line 156:  544
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.21678468816241225, 0.07639158681393565, 0.6304321382097164, 0.07639158681393565]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.21678468816241225, 0.07639158681393565, 0.6304321382097164, 0.07639158681393565]
Printing some Q and Qe and total Qs values:  [[0.622]
 [0.665]
 [0.665]
 [0.666]
 [0.658]
 [0.642]
 [0.618]] [[3.106]
 [3.208]
 [3.208]
 [3.177]
 [3.03 ]
 [3.096]
 [3.038]] [[2.17 ]
 [2.391]
 [2.391]
 [2.354]
 [2.142]
 [2.199]
 [2.072]]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
Printing some Q and Qe and total Qs values:  [[0.402]
 [0.439]
 [0.439]
 [0.439]
 [0.441]
 [0.423]
 [0.406]] [[2.929]
 [2.772]
 [2.772]
 [2.848]
 [2.999]
 [3.017]
 [2.948]] [[1.588]
 [1.454]
 [1.454]
 [1.555]
 [1.76 ]
 [1.747]
 [1.622]]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.10578428620063092, 0.10578428620063092, 0.6826471413981072, 0.10578428620063092]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.10578428620063092, 0.10578428620063092, 0.6826471413981072, 0.10578428620063092]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.10578428620063092, 0.10578428620063092, 0.6826471413981072, 0.10578428620063092]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.10578428620063092, 0.10578428620063092, 0.6826471413981072, 0.10578428620063092]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.18898398143731168, 0.18898398143731168, 0.555029173842661, 0.06700286328271561]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.07621484074452907, 0.21521975804088558, 0.6323505604700562, 0.07621484074452907]
Printing some Q and Qe and total Qs values:  [[0.448]
 [0.449]
 [0.439]
 [0.447]
 [0.441]
 [0.444]
 [0.453]] [[2.537]
 [2.737]
 [1.926]
 [1.641]
 [1.826]
 [2.134]
 [2.082]] [[0.448]
 [0.449]
 [0.439]
 [0.447]
 [0.441]
 [0.444]
 [0.453]]
Printing some Q and Qe and total Qs values:  [[0.696]
 [0.599]
 [0.698]
 [0.709]
 [0.682]
 [0.65 ]
 [0.667]] [[2.377]
 [3.441]
 [2.692]
 [2.005]
 [1.511]
 [1.817]
 [3.831]] [[0.909]
 [1.425]
 [1.123]
 [0.688]
 [0.305]
 [0.445]
 [1.819]]
Printing some Q and Qe and total Qs values:  [[1.136]
 [0.814]
 [0.87 ]
 [0.911]
 [0.903]
 [0.845]
 [0.852]] [[1.209]
 [1.049]
 [1.039]
 [0.804]
 [0.877]
 [0.966]
 [1.148]] [[1.836]
 [1.086]
 [1.191]
 [1.117]
 [1.149]
 [1.093]
 [1.228]]
maxi score, test score, baseline:  -0.9964277777777778 -1.0 -0.9964277777777778
probs:  [0.18774309033680917, 0.06688808497328484, 0.6784807397166213, 0.06688808497328484]
from probs:  [0.18774309033680917, 0.06688808497328484, 0.6784807397166213, 0.06688808497328484]
maxi score, test score, baseline:  -0.9964397923875432 -1.0 -0.9964397923875432
probs:  [0.18775986800127137, 0.06689399092861789, 0.6784521501414928, 0.06689399092861789]
from probs:  [0.18775986800127137, 0.06689399092861789, 0.6784521501414928, 0.06689399092861789]
maxi score, test score, baseline:  -0.9964397923875432 -1.0 -0.9964397923875432
probs:  [0.22607302977981275, 0.04921397399533045, 0.5877197114541409, 0.13699328477071598]
Printing some Q and Qe and total Qs values:  [[0.612]
 [0.589]
 [0.624]
 [0.622]
 [0.603]
 [0.611]
 [0.619]] [[ 0.265]
 [ 1.531]
 [-0.169]
 [-0.358]
 [ 0.357]
 [ 0.349]
 [ 1.366]] [[1.234]
 [1.809]
 [1.043]
 [0.95 ]
 [1.265]
 [1.273]
 [1.773]]
siam score:  -0.8414444
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.23307655864116694, 0.050714318206722044, 0.5749841341415293, 0.14122498901058175]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
Printing some Q and Qe and total Qs values:  [[0.598]
 [0.497]
 [0.622]
 [0.684]
 [0.598]
 [0.606]
 [0.516]] [[4.044]
 [4.809]
 [3.943]
 [4.253]
 [2.585]
 [3.437]
 [5.164]] [[1.464]
 [1.762]
 [1.445]
 [1.766]
 [0.517]
 [1.086]
 [2.028]]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.23307655864116694, 0.050714318206722044, 0.5749841341415293, 0.14122498901058175]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.23307655864116694, 0.050714318206722044, 0.5749841341415293, 0.14122498901058175]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.23307655864116694, 0.050714318206722044, 0.5749841341415293, 0.14122498901058175]
maxi score, test score, baseline:  -0.996451724137931 -1.0 -0.996451724137931
probs:  [0.23307655864116694, 0.050714318206722044, 0.5749841341415293, 0.14122498901058175]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.715]
 [0.766]
 [0.715]
 [0.691]
 [0.715]
 [0.718]
 [1.014]] [[0.467]
 [1.206]
 [0.467]
 [0.424]
 [0.467]
 [1.412]
 [2.83 ]] [[0.55 ]
 [0.898]
 [0.55 ]
 [0.487]
 [0.55 ]
 [0.871]
 [1.936]]
Printing some Q and Qe and total Qs values:  [[0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [0.667]] [[2.981]
 [2.981]
 [2.981]
 [2.981]
 [2.981]
 [2.981]
 [2.981]] [[2.56]
 [2.56]
 [2.56]
 [2.56]
 [2.56]
 [2.56]
 [2.56]]
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.20122468362809268, 0.04414335966265677, 0.5534072730811579, 0.20122468362809268]
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.20675535542611506, 0.04533516601015963, 0.5411541231376102, 0.20675535542611506]
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.20675535542611506, 0.04533516601015963, 0.5411541231376102, 0.20675535542611506]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.5049],
        [-0.5798],
        [-0.5785],
        [-0.0000],
        [-0.6344],
        [-0.3664],
        [-0.0000],
        [-0.0000],
        [-0.3447],
        [-0.4751]], dtype=torch.float64)
-0.0727797758985 -0.577727449233584
-0.024259925299500003 -0.6040381244045263
-0.024259925299500003 -0.6027685560193075
-0.00989999999999924 -0.00989999999999924
-0.024259925299500003 -0.6586912671165769
-0.0727797758985 -0.43917189834448767
-0.3704165585999995 -0.3704165585999995
-0.22274999999999942 -0.22274999999999942
-0.0727797758985 -0.4174765472909592
-0.0727797758985 -0.5478768308814925
siam score:  -0.84003115
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.21257155248661802, 0.046588500293621014, 0.528268394733143, 0.21257155248661802]
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.21257155248661802, 0.046588500293621014, 0.528268394733143, 0.21257155248661802]
siam score:  -0.8357824
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.23195645295226305, 0.05076575909045097, 0.5765779618405339, 0.14069982611675202]
maxi score, test score, baseline:  -0.9964635738831615 -1.0 -0.9964635738831615
probs:  [0.23927394928143442, 0.05234260886411759, 0.5632573939510791, 0.14512604790336903]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.2392903318626387, 0.05234612610883674, 0.5632275911659759, 0.1451359508625488]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.2392903318626387, 0.05234612610883674, 0.5632275911659759, 0.1451359508625488]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.2392903318626387, 0.05234612610883674, 0.5632275911659759, 0.1451359508625488]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.24704947866162402, 0.05401814686780531, 0.5491030556175126, 0.14982931885305809]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.896]
 [0.557]
 [0.598]
 [0.598]
 [0.598]
 [0.64 ]
 [0.598]] [[3.113]
 [4.007]
 [3.056]
 [3.056]
 [3.056]
 [2.867]
 [3.056]] [[1.137]
 [1.244]
 [0.815]
 [0.815]
 [0.815]
 [0.763]
 [0.815]]
using another actor
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.1786585386118773, 0.06428860808011211, 0.5783943146961332, 0.1786585386118773]
Printing some Q and Qe and total Qs values:  [[ 0.032]
 [ 0.   ]
 [ 0.091]
 [-0.019]
 [-0.023]
 [-0.021]
 [-0.037]] [[2.292]
 [3.306]
 [2.687]
 [3.047]
 [2.19 ]
 [2.118]
 [3.298]] [[0.247]
 [0.665]
 [0.455]
 [0.54 ]
 [0.167]
 [0.137]
 [0.637]]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.20170548743783065, 0.0724991249084964, 0.6532962627451766, 0.0724991249084964]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.20170548743783065, 0.0724991249084964, 0.6532962627451766, 0.0724991249084964]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.20170548743783065, 0.0724991249084964, 0.6532962627451766, 0.0724991249084964]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.20170548743783065, 0.0724991249084964, 0.6532962627451766, 0.0724991249084964]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.20170548743783065, 0.0724991249084964, 0.6532962627451766, 0.0724991249084964]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.20170548743783065, 0.0724991249084964, 0.6532962627451766, 0.0724991249084964]
maxi score, test score, baseline:  -0.9964753424657534 -1.0 -0.9964753424657534
probs:  [0.21078747709633147, 0.07573460000281257, 0.6377433228980434, 0.07573460000281257]
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
maxi score, test score, baseline:  -0.9964870307167235 -1.0 -0.9964870307167235
probs:  [0.21080812942075935, 0.07574194195789517, 0.6377079866634503, 0.07574194195789517]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.21082864472646515, 0.07574923520258756, 0.6376728848683597, 0.07574923520258756]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.22072637224069616, 0.07927531691530987, 0.620722993928684, 0.07927531691530987]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.22072637224069616, 0.07927531691530987, 0.620722993928684, 0.07927531691530987]
maxi score, test score, baseline:  -0.9964986394557823 -1.0 -0.9964986394557823
probs:  [0.0619237530584708, 0.1712117959770572, 0.5956526549874148, 0.1712117959770572]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.06943911576592586, 0.06943911576592586, 0.6689140226094803, 0.19220774585866796]
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.655]
 [0.679]
 [0.679]
 [0.679]
 [0.738]
 [0.679]] [[4.148]
 [5.044]
 [3.811]
 [3.811]
 [3.811]
 [3.533]
 [3.811]] [[1.204]
 [1.809]
 [1.076]
 [1.076]
 [1.076]
 [0.977]
 [1.076]]
first move QE:  0.48184667873479325
using explorer policy with actor:  1
siam score:  -0.8493992
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.05772666678659649, 0.15874417764307586, 0.6247849779272519, 0.15874417764307586]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.05772666678659649, 0.15874417764307586, 0.6247849779272519, 0.15874417764307586]
Printing some Q and Qe and total Qs values:  [[0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]
 [0.332]] [[1.125]
 [1.125]
 [1.125]
 [1.125]
 [1.125]
 [1.125]
 [1.125]] [[0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]
 [0.006]]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.05772666678659649, 0.15874417764307586, 0.6247849779272519, 0.15874417764307586]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.529]
 [0.603]
 [0.608]
 [0.616]
 [0.426]
 [0.674]
 [0.691]] [[2.357]
 [2.705]
 [1.599]
 [1.38 ]
 [0.897]
 [2.269]
 [3.114]] [[1.501]
 [1.807]
 [1.132]
 [1.007]
 [0.475]
 [1.625]
 [2.167]]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.06663904396697459, 0.06663904396697459, 0.6831955206537138, 0.183526391412337]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.06663904396697459, 0.06663904396697459, 0.6831955206537138, 0.183526391412337]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.0753668222720593, 0.0753668222720593, 0.7738995331838222, 0.0753668222720593]
Printing some Q and Qe and total Qs values:  [[0.342]
 [0.406]
 [0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]] [[3.253]
 [3.034]
 [3.253]
 [3.253]
 [3.253]
 [3.253]
 [3.253]] [[0.342]
 [0.406]
 [0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]]
maxi score, test score, baseline:  -0.9965101694915255 -1.0 -0.9965101694915255
probs:  [0.07885644587797286, 0.07885644587797286, 0.7634306623660813, 0.07885644587797286]
siam score:  -0.83713204
Printing some Q and Qe and total Qs values:  [[0.586]
 [0.622]
 [0.586]
 [0.586]
 [0.586]
 [0.586]
 [0.586]] [[1.837]
 [1.798]
 [1.837]
 [1.837]
 [1.837]
 [1.837]
 [1.837]] [[1.173]
 [1.206]
 [1.173]
 [1.173]
 [1.173]
 [1.173]
 [1.173]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.09660247481026579, 0.09660247481026579, 0.7101925755692028, 0.09660247481026579]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.09660247481026579, 0.09660247481026579, 0.7101925755692028, 0.09660247481026579]
actor:  1 policy actor:  1  step number:  65 total reward:  0.36999999999999955  reward:  1.0 rdn_beta:  0.5
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.007208824046451356, 0.007208824046451356, 0.9783735278606459, 0.007208824046451356]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.007208824046451356, 0.007208824046451356, 0.9783735278606459, 0.007208824046451356]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.006970173530828896, 0.01753103515006535, 0.9579677561690406, 0.01753103515006535]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.007037932901288482, 0.017718576652733922, 0.9575249137932436, 0.017718576652733922]
UNIT TEST: sample policy line 217 mcts : [0.204 0.571 0.02  0.02  0.02  0.02  0.143]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.007106605304676846, 0.017908645209096883, 0.9570761042771292, 0.017908645209096883]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.007106605304676846, 0.017908645209096883, 0.9570761042771292, 0.017908645209096883]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.007106605304676846, 0.017908645209096883, 0.9570761042771292, 0.017908645209096883]
using another actor
from probs:  [0.007106605304676846, 0.017908645209096883, 0.9570761042771292, 0.017908645209096883]
maxi score, test score, baseline:  -0.9965216216216216 -1.0 -0.9965216216216216
probs:  [0.007176209320350128, 0.018101292242305483, 0.9566212061950389, 0.018101292242305483]
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
probs:  [0.007246930112294848, 0.01829703728082841, 0.9561589953260484, 0.01829703728082841]
Printing some Q and Qe and total Qs values:  [[0.688]
 [0.689]
 [0.669]
 [0.671]
 [0.67 ]
 [0.687]
 [0.683]] [[1.404]
 [1.544]
 [0.867]
 [0.852]
 [0.941]
 [1.516]
 [1.39 ]] [[1.617]
 [1.701]
 [1.274]
 [1.267]
 [1.319]
 [1.683]
 [1.602]]
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
probs:  [0.007246930112294848, 0.01829703728082841, 0.9561589953260484, 0.01829703728082841]
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
probs:  [0.007246930112294848, 0.01829703728082841, 0.9561589953260484, 0.01829703728082841]
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
probs:  [0.007246930112294848, 0.01829703728082841, 0.9561589953260484, 0.01829703728082841]
584 492
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
probs:  [0.007318458221824865, 0.01849500981970283, 0.9556915221387695, 0.01849500981970283]
using another actor
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
probs:  [0.007390976867500578, 0.01869572392349324, 0.9552175752855129, 0.01869572392349324]
Printing some Q and Qe and total Qs values:  [[0.74]
 [0.74]
 [0.74]
 [0.74]
 [0.74]
 [0.74]
 [0.74]] [[4.458]
 [4.458]
 [4.458]
 [4.458]
 [4.458]
 [4.458]
 [4.458]] [[2.131]
 [2.131]
 [2.131]
 [2.131]
 [2.131]
 [2.131]
 [2.131]]
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
probs:  [0.007390976867500578, 0.01869572392349324, 0.9552175752855129, 0.01869572392349324]
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
probs:  [0.007390976867500578, 0.01869572392349324, 0.9552175752855129, 0.01869572392349324]
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
maxi score, test score, baseline:  -0.9965442953020134 -1.0 -0.9965442953020134
probs:  [0.007390976867500578, 0.01869572392349324, 0.9552175752855129, 0.01869572392349324]
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.007427700180400386, 0.018797368772866647, 0.9549775622738663, 0.018797368772866647]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.0074645936581416595, 0.018899481033001476, 0.9547364442758552, 0.018899481033001476]
using explorer policy with actor:  0
siam score:  -0.8436307
first move QE:  0.5030997538788979
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.0074645936581416595, 0.018899481033001476, 0.9547364442758552, 0.018899481033001476]
maxi score, test score, baseline:  -0.9965555183946488 -1.0 -0.9965555183946488
probs:  [0.0074645936581416595, 0.018899481033001476, 0.9547364442758552, 0.018899481033001476]
maxi score, test score, baseline:  -0.9965777408637874 -1.0 -0.9965777408637874
probs:  [0.007464765705842495, 0.018899964358698354, 0.9547353055767608, 0.018899964358698354]
maxi score, test score, baseline:  -0.9965777408637874 -1.0 -0.9965777408637874
start point for exploration sampling:  10768
using another actor
line 256 mcts: sample exp_bonus 2.3282868002517807
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.007502004895953798, 0.01900303706276411, 0.9544919209785178, 0.01900303706276411]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.007502004895953798, 0.01900303706276411, 0.9544919209785178, 0.01900303706276411]
line 256 mcts: sample exp_bonus 2.1817010688053604
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
line 256 mcts: sample exp_bonus 2.1527667085095077
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.007502004895953798, 0.01900303706276411, 0.9544919209785178, 0.01900303706276411]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.007502004895953798, 0.01900303706276411, 0.9544919209785178, 0.01900303706276411]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.007539419801739276, 0.0191065925718648, 0.9542473950545309, 0.0191065925718648]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.007539419801739276, 0.0191065925718648, 0.9542473950545309, 0.0191065925718648]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.007577098350208456, 0.0192108777808474, 0.9540011460880967, 0.0192108777808474]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.007577098350208456, 0.0192108777808474, 0.9540011460880967, 0.0192108777808474]
Printing some Q and Qe and total Qs values:  [[0.533]
 [0.566]
 [0.645]
 [0.616]
 [0.58 ]
 [0.605]
 [0.57 ]] [[2.14 ]
 [2.262]
 [1.555]
 [1.503]
 [1.192]
 [1.443]
 [2.214]] [[2.326]
 [2.484]
 [2.022]
 [1.93 ]
 [1.606]
 [1.861]
 [2.451]]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.007615043337835882, 0.019315900429684615, 0.9537531558027951, 0.019315900429684615]
maxi score, test score, baseline:  -0.9965887417218543 -1.0 -0.9965887417218543
probs:  [0.007615043337835882, 0.019315900429684615, 0.9537531558027951, 0.019315900429684615]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.007615131163344416, 0.019316147101762358, 0.9537525746331308, 0.019316147101762358]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.007615131163344416, 0.019316147101762358, 0.9537525746331308, 0.019316147101762358]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.007691833506453328, 0.01952844088095287, 0.9532512847316408, 0.01952844088095287]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.007730595838085242, 0.01963572576351107, 0.9529979526348927, 0.01963572576351107]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.007769636208725223, 0.019743780191684, 0.9527428034079066, 0.019743780191684]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.0078089576206671904, 0.019852612475104833, 0.952485817429123, 0.019852612475104833]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.0078089576206671904, 0.019852612475104833, 0.952485817429123, 0.019852612475104833]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.007848563119586654, 0.019962231043476403, 0.9522269747934604, 0.019962231043476403]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.007848563119586654, 0.019962231043476403, 0.9522269747934604, 0.019962231043476403]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.007888455795327083, 0.0200726444487481, 0.9519662553071768, 0.0200726444487481]
Printing some Q and Qe and total Qs values:  [[0.679]
 [0.675]
 [0.669]
 [0.666]
 [0.664]
 [0.684]
 [0.666]] [[2.285]
 [2.977]
 [2.017]
 [1.765]
 [1.757]
 [1.805]
 [2.344]] [[0.729]
 [1.05 ]
 [0.594]
 [0.473]
 [0.466]
 [0.508]
 [0.744]]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.00792863878270351, 0.02018386136733917, 0.951703638482618, 0.02018386136733917]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.00792863878270351, 0.02018386136733917, 0.951703638482618, 0.02018386136733917]
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.00792863878270351, 0.02018386136733917, 0.951703638482618, 0.02018386136733917]
siam score:  -0.84214073
start point for exploration sampling:  10768
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.63429507740896
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.008050961654743404, 0.020522421882367334, 0.9509041945805219, 0.020522421882367334]
rdn beta is 0 so we're just using the maxi policy
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9965996699669967 -1.0 -0.9965996699669967
probs:  [0.008140419200467782, 0.008140419200467782, 0.962949142580949, 0.020770019018115555]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.068]
 [0.034]
 [0.064]
 [0.064]
 [0.064]
 [0.064]
 [0.217]] [[2.53 ]
 [2.875]
 [3.052]
 [3.052]
 [3.052]
 [3.052]
 [2.88 ]] [[0.207]
 [0.336]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.508]]
siam score:  -0.83447206
from probs:  [0.008140419200467782, 0.008140419200467782, 0.962949142580949, 0.020770019018115555]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966105263157895 -1.0 -0.9966105263157895
probs:  [0.008140518544042892, 0.008140518544042892, 0.9629486650829276, 0.020770297828986484]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.008183153827305256, 0.008183153827305256, 0.9627453825323421, 0.020888309813047474]
siam score:  -0.83197385
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.008268997444387154, 0.008268997444387154, 0.9623361005164549, 0.021125904594770775]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.008268997444387154, 0.008268997444387154, 0.9623361005164549, 0.021125904594770775]
maxi score, test score, baseline:  -0.9966320261437909 -1.0 -0.9966320261437909
probs:  [0.008268997444387154, 0.008268997444387154, 0.9623361005164549, 0.021125904594770775]
using another actor
Printing some Q and Qe and total Qs values:  [[0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.353]] [[0.314]
 [0.314]
 [0.314]
 [0.314]
 [0.314]
 [0.314]
 [0.314]] [[0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.353]]
maxi score, test score, baseline:  -0.996642671009772 -1.0 -0.996642671009772
maxi score, test score, baseline:  -0.996642671009772 -1.0 -0.996642671009772
probs:  [0.008356256723630615, 0.008356256723630615, 0.961920065068779, 0.021367421483959637]
maxi score, test score, baseline:  -0.9966532467532467 -1.0 -0.9966532467532467
probs:  [0.00849904286767838, 0.00849904286767838, 0.9745028713969647, 0.00849904286767838]
maxi score, test score, baseline:  -0.9966532467532467 -1.0 -0.9966532467532467
probs:  [0.00849904286767838, 0.00849904286767838, 0.9745028713969647, 0.00849904286767838]
maxi score, test score, baseline:  -0.9966532467532467 -1.0 -0.9966532467532467
probs:  [0.00849904286767838, 0.00849904286767838, 0.9745028713969647, 0.00849904286767838]
maxi score, test score, baseline:  -0.9966637540453075 -1.0 -0.9966637540453075
probs:  [0.008499147622109446, 0.008499147622109446, 0.9745025571336717, 0.008499147622109446]
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.008499251701164336, 0.008499251701164336, 0.974502244896507, 0.008499251701164336]
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.008499251701164336, 0.008499251701164336, 0.974502244896507, 0.008499251701164336]
Printing some Q and Qe and total Qs values:  [[0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]
 [0.359]] [[2.099]
 [2.099]
 [2.099]
 [2.099]
 [2.099]
 [2.099]
 [2.099]] [[0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]]
siam score:  -0.84037244
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.02086588617617094, 0.00820817002172943, 0.9500600576259288, 0.02086588617617094]
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.555]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]] [[1.01 ]
 [1.471]
 [1.01 ]
 [1.01 ]
 [1.01 ]
 [1.01 ]
 [1.01 ]] [[1.205]
 [1.67 ]
 [1.205]
 [1.205]
 [1.205]
 [1.205]
 [1.205]]
siam score:  -0.8406983
Printing some Q and Qe and total Qs values:  [[-0.003]
 [-0.015]
 [-0.003]
 [ 0.044]
 [ 0.019]
 [ 0.044]
 [-0.019]] [[4.15 ]
 [3.676]
 [3.422]
 [3.041]
 [2.583]
 [3.041]
 [3.731]] [[ 0.835]
 [ 0.387]
 [ 0.179]
 [-0.082]
 [-0.541]
 [-0.082]
 [ 0.429]]
maxi score, test score, baseline:  -0.9966741935483872 -1.0 -0.9966741935483872
probs:  [0.02086588617617094, 0.00820817002172943, 0.9500600576259288, 0.02086588617617094]
siam score:  -0.84121454
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
Printing some Q and Qe and total Qs values:  [[0.645]
 [0.645]
 [0.645]
 [0.645]
 [0.645]
 [0.645]
 [0.645]] [[1.953]
 [1.953]
 [1.953]
 [1.953]
 [1.953]
 [1.953]
 [1.953]] [[0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.02109984687417179, 0.008293089223000663, 0.9495072170286557, 0.02109984687417179]
Printing some Q and Qe and total Qs values:  [[0.731]
 [0.753]
 [0.731]
 [0.731]
 [0.731]
 [0.751]
 [0.738]] [[0.264]
 [1.015]
 [0.264]
 [0.264]
 [0.264]
 [1.417]
 [1.012]] [[0.317]
 [0.862]
 [0.317]
 [0.317]
 [0.317]
 [1.125]
 [0.829]]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.02121800648517685, 0.008335977533377866, 0.9492280094962684, 0.02121800648517685]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.02121800648517685, 0.008335977533377866, 0.9492280094962684, 0.02121800648517685]
maxi score, test score, baseline:  -0.9966845659163988 -1.0 -0.9966845659163988
probs:  [0.0326641388927962, 0.008018146898903669, 0.926653575315504, 0.0326641388927962]
Printing some Q and Qe and total Qs values:  [[0.508]
 [0.514]
 [0.515]
 [0.515]
 [0.515]
 [0.524]
 [0.511]] [[1.389]
 [2.658]
 [1.808]
 [1.808]
 [1.808]
 [1.66 ]
 [2.425]] [[0.185]
 [1.078]
 [0.487]
 [0.487]
 [0.487]
 [0.397]
 [0.912]]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.03320708786109164, 0.008138539481240638, 0.9254472847965762, 0.03320708786109164]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.03320708786109164, 0.008138539481240638, 0.9254472847965762, 0.03320708786109164]
Printing some Q and Qe and total Qs values:  [[0.711]
 [0.689]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.716]] [[2.661]
 [2.787]
 [2.661]
 [2.661]
 [2.661]
 [2.661]
 [2.413]] [[1.237]
 [1.29 ]
 [1.237]
 [1.237]
 [1.237]
 [1.237]
 [1.086]]
maxi score, test score, baseline:  -0.9966948717948718 -1.0 -0.9966948717948718
probs:  [0.03320708786109164, 0.008138539481240638, 0.9254472847965762, 0.03320708786109164]
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
probs:  [0.03320751137304328, 0.008138631770443118, 0.9254463454834704, 0.03320751137304328]
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
probs:  [0.03320751137304328, 0.008138631770443118, 0.9254463454834704, 0.03320751137304328]
maxi score, test score, baseline:  -0.9967051118210862 -1.0 -0.9967051118210862
probs:  [0.033575710052626086, 0.008220276589575313, 0.9246283033051726, 0.033575710052626086]
Printing some Q and Qe and total Qs values:  [[0.606]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.639]] [[1.234]
 [1.191]
 [1.191]
 [1.191]
 [1.191]
 [1.191]
 [1.838]] [[0.606]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.583]
 [0.639]]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.033576138754865446, 0.008220370021600056, 0.9246273524686691, 0.033576138754865446]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using another actor
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.03376223474360885, 0.008261635161207714, 0.9242138953515744, 0.03376223474360885]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.03376223474360885, 0.008261635161207714, 0.9242138953515744, 0.03376223474360885]
from probs:  [0.03376223474360885, 0.008261635161207714, 0.9242138953515744, 0.03376223474360885]
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.03394967844441328, 0.008303199144045263, 0.9237974439671282, 0.03394967844441328]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.03413848455073334, 0.008345065228256326, 0.9233779656702772, 0.03413848455073334]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.4957],
        [-0.3741],
        [-0.5199],
        [-0.5370],
        [-0.4905],
        [-0.0000],
        [-0.5244],
        [-0.5394],
        [-0.4778],
        [-0.5099]], dtype=torch.float64)
-0.0727797758985 -0.5685251747666629
-0.0727797758985 -0.44690386361889634
-0.0727797758985 -0.5926911030314214
-0.024259925299500003 -0.561309616755071
-0.0727797758985 -0.5632914383547027
-0.9652499999999999 -0.9652499999999999
-0.024259925299500003 -0.548663042114461
-0.0727797758985 -0.6122042053824421
-0.0727797758985 -0.550627634961703
-0.0727797758985 -0.5826975082720115
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9967152866242038 -1.0 -0.9967152866242038
probs:  [0.03413848455073334, 0.008345065228256326, 0.9233779656702772, 0.03413848455073334]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9967253968253968 -1.0 -0.9967253968253968
probs:  [0.034138922634262055, 0.00834516072291072, 0.9233769940085651, 0.034138922634262055]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.03413935794652836, 0.008345255613489498, 0.9233760284934537, 0.03413935794652836]
Printing some Q and Qe and total Qs values:  [[0.038]
 [0.137]
 [0.038]
 [0.038]
 [0.038]
 [0.038]
 [0.043]] [[2.557]
 [3.701]
 [2.557]
 [2.557]
 [2.557]
 [2.557]
 [2.413]] [[ 0.032]
 [ 0.7  ]
 [ 0.032]
 [ 0.032]
 [ 0.032]
 [ 0.032]
 [-0.033]]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.03413935794652836, 0.008345255613489498, 0.9233760284934537, 0.03413935794652836]
siam score:  -0.8349989
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.03452113378780881, 0.008429910991926555, 0.922527821432456, 0.03452113378780881]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.03452113378780881, 0.008429910991926555, 0.922527821432456, 0.03452113378780881]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.034714125863717665, 0.008472705258757601, 0.9220990430138071, 0.034714125863717665]
siam score:  -0.83491623
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.034714125863717665, 0.008472705258757601, 0.9220990430138071, 0.034714125863717665]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.03536713644326966, 0.008617504514650712, 0.9341172274079386, 0.02189813163414108]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.03536713644326966, 0.008617504514650712, 0.9341172274079386, 0.02189813163414108]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.03536713644326966, 0.008617504514650712, 0.9341172274079386, 0.02189813163414108]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.03577107004388443, 0.008707073178054798, 0.9333780809307034, 0.0221437758473576]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.242]
 [0.336]
 [0.269]
 [0.277]
 [0.257]
 [0.257]
 [0.299]] [[2.668]
 [2.435]
 [2.547]
 [2.432]
 [2.416]
 [2.405]
 [2.659]] [[0.296]
 [0.267]
 [0.253]
 [0.191]
 [0.155]
 [0.147]
 [0.363]]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.03597534454782633, 0.008752369222399187, 0.9330042848915822, 0.022268001338192234]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.6423090354458374
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.036388597531564426, 0.008844004375664143, 0.9322480851432271, 0.02251931294954421]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
Printing some Q and Qe and total Qs values:  [[0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.601]
 [0.585]
 [0.609]] [[2.136]
 [2.136]
 [2.136]
 [2.136]
 [0.67 ]
 [2.136]
 [2.376]] [[1.786]
 [1.786]
 [1.786]
 [1.786]
 [0.352]
 [1.786]
 [2.074]]
maxi score, test score, baseline:  -0.9967354430379747 -1.0 -0.9967354430379747
probs:  [0.036388597531564426, 0.008844004375664143, 0.9322480851432271, 0.02251931294954421]
maxi score, test score, baseline:  -0.9967454258675079 -1.0 -0.9967454258675079
probs:  [0.03638908183753507, 0.008844110030159419, 0.9322472015358084, 0.02251960659649717]
maxi score, test score, baseline:  -0.9967454258675079 -1.0 -0.9967454258675079
probs:  [0.03638908183753507, 0.008844110030159419, 0.9322472015358084, 0.02251960659649717]
using another actor
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.5299791472993913
Printing some Q and Qe and total Qs values:  [[0.138]
 [0.338]
 [0.347]
 [0.34 ]
 [0.192]
 [0.427]
 [0.635]] [[2.895]
 [3.105]
 [0.583]
 [1.649]
 [1.243]
 [1.197]
 [2.478]] [[0.138]
 [0.338]
 [0.347]
 [0.34 ]
 [0.192]
 [0.427]
 [0.635]]
line 256 mcts: sample exp_bonus 2.72925468364753
first move QE:  0.572063423611742
Printing some Q and Qe and total Qs values:  [[0.437]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]
 [0.46 ]] [[3.632]
 [3.274]
 [3.274]
 [3.274]
 [3.274]
 [3.274]
 [3.274]] [[1.357]
 [1.045]
 [1.045]
 [1.045]
 [1.045]
 [1.045]
 [1.045]]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.0372359342699846, 0.00903188842026329, 0.9306975759852257, 0.023034601324526234]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.0372359342699846, 0.00903188842026329, 0.9306975759852257, 0.023034601324526234]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.0372359342699846, 0.00903188842026329, 0.9306975759852257, 0.023034601324526234]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.0372359342699846, 0.00903188842026329, 0.9306975759852257, 0.023034601324526234]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.0372359342699846, 0.00903188842026329, 0.9306975759852257, 0.023034601324526234]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.0372359342699846, 0.00903188842026329, 0.9306975759852257, 0.023034601324526234]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.037451545193545245, 0.00907969818274503, 0.930303035805321, 0.023165720818388778]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.037974508597745794, 0.009195660564096361, 0.9436341702740615, 0.009195660564096361]
Printing some Q and Qe and total Qs values:  [[0.636]
 [0.603]
 [0.636]
 [0.565]
 [0.636]
 [0.636]
 [0.616]] [[2.589]
 [3.165]
 [2.589]
 [2.778]
 [2.589]
 [2.589]
 [2.955]] [[0.751]
 [1.164]
 [0.751]
 [0.79 ]
 [0.751]
 [0.751]
 [1.014]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.03819811203574281, 0.009245242594005573, 0.943311402776246, 0.009245242594005573]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.03842351799195536, 0.009295224315944844, 0.9429860333761552, 0.009295224315944844]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.03842351799195536, 0.009295224315944844, 0.9429860333761552, 0.009295224315944844]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]
 [0.413]] [[1.434]
 [1.434]
 [1.434]
 [1.434]
 [1.434]
 [1.434]
 [1.434]] [[0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.894]
 [0.894]]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.03865074835035315, 0.009345610582485677, 0.9426580304846754, 0.009345610582485677]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.03865074835035315, 0.009345610582485677, 0.9426580304846754, 0.009345610582485677]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.03865074835035315, 0.009345610582485677, 0.9426580304846754, 0.009345610582485677]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.03865074835035315, 0.009345610582485677, 0.9426580304846754, 0.009345610582485677]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.03865074835035315, 0.009345610582485677, 0.9426580304846754, 0.009345610582485677]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.03865074835035315, 0.009345610582485677, 0.9426580304846754, 0.009345610582485677]
maxi score, test score, baseline:  -0.9967652037617555 -1.0 -0.9967652037617555
probs:  [0.03865074835035315, 0.009345610582485677, 0.9426580304846754, 0.009345610582485677]
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.03865127771780106, 0.009345726152606476, 0.9426572699769861, 0.009345726152606476]
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.03865127771780106, 0.009345726152606476, 0.9426572699769861, 0.009345726152606476]
start point for exploration sampling:  10768
first move QE:  0.5811561677363233
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.0388803601128825, 0.009396523080422166, 0.9423265937262733, 0.009396523080422166]
Printing some Q and Qe and total Qs values:  [[0.056]
 [0.056]
 [0.056]
 [0.054]
 [0.056]
 [0.056]
 [0.056]] [[0.297]
 [0.297]
 [0.297]
 [0.185]
 [0.297]
 [0.297]
 [0.297]] [[0.056]
 [0.056]
 [0.056]
 [0.054]
 [0.056]
 [0.056]
 [0.056]]
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.0393441558225145, 0.009499365540991919, 0.9416571130955016, 0.009499365540991919]
Starting evaluation
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
using explorer policy with actor:  0
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
maxi score, test score, baseline:  -0.996775 -1.0 -0.996775
probs:  [0.0393441558225145, 0.009499365540991919, 0.9416571130955016, 0.009499365540991919]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.0023320656918113
using explorer policy with actor:  0
siam score:  -0.8412114
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.231]
 [0.231]
 [0.231]
 [0.23 ]
 [0.226]
 [0.228]
 [0.229]] [[1.043]
 [1.043]
 [1.043]
 [0.777]
 [1.083]
 [1.11 ]
 [1.094]] [[0.231]
 [0.231]
 [0.231]
 [0.23 ]
 [0.226]
 [0.228]
 [0.229]]
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.183431778583818
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.121]
 [0.384]
 [0.39 ]
 [0.384]
 [0.384]
 [0.447]
 [0.547]] [[3.92 ]
 [3.373]
 [4.043]
 [3.373]
 [3.373]
 [4.433]
 [4.008]] [[0.121]
 [0.384]
 [0.39 ]
 [0.384]
 [0.384]
 [0.447]
 [0.547]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.19 ]
 [1.446]
 [0.19 ]
 [0.19 ]
 [0.19 ]
 [0.19 ]
 [0.19 ]] [[2.045]
 [0.609]
 [2.045]
 [2.045]
 [2.045]
 [2.045]
 [2.045]] [[1.21 ]
 [2.286]
 [1.21 ]
 [1.21 ]
 [1.21 ]
 [1.21 ]
 [1.21 ]]
maxi score, test score, baseline:  -0.9967944099378883 -1.0 -0.9967944099378883
probs:  [0.09788266309572835, 0.022479735380846383, 0.8571578661425788, 0.022479735380846383]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9968135802469136 -1.0 -0.9968135802469136
probs:  [0.09788949837810544, 0.022481241916780602, 0.8571480177883334, 0.022481241916780602]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9968230769230769 -1.0 -0.9968230769230769
probs:  [0.09789288471775409, 0.022481988285752225, 0.8571431387107415, 0.022481988285752225]
maxi score, test score, baseline:  -0.9968230769230769 -1.0 -0.9968230769230769
probs:  [0.09789288471775409, 0.022481988285752225, 0.8571431387107415, 0.022481988285752225]
maxi score, test score, baseline:  -0.9968230769230769 -1.0 -0.9968230769230769
probs:  [0.09789288471775409, 0.022481988285752225, 0.8571431387107415, 0.022481988285752225]
maxi score, test score, baseline:  -0.9968230769230769 -1.0 -0.9968230769230769
probs:  [0.09789288471775409, 0.022481988285752225, 0.8571431387107415, 0.022481988285752225]
using explorer policy with actor:  0
using explorer policy with actor:  0
actor:  1 policy actor:  1  step number:  57 total reward:  0.4199999999999996  reward:  1.0 rdn_beta:  0.5
Printing some Q and Qe and total Qs values:  [[0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]] [[2.301]
 [2.301]
 [2.301]
 [2.301]
 [2.301]
 [2.301]
 [2.301]] [[0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]
 [0.46]]
maxi score, test score, baseline:  -0.996869696969697 -1.0 -0.996869696969697
probs:  [0.024723324396421276, 0.00625731873623769, 0.9627620381311032, 0.00625731873623769]
UNIT TEST: sample policy line 217 mcts : [0.102 0.061 0.143 0.102 0.143 0.224 0.224]
maxi score, test score, baseline:  -0.9968788519637463 -1.0 -0.9968788519637463
maxi score, test score, baseline:  -0.9968879518072289 -1.0 -0.9968879518072289
probs:  [0.02472390714421818, 0.006257445827608183, 0.9627612012005656, 0.006257445827608183]
maxi score, test score, baseline:  -0.9968879518072289 -1.0 -0.9968879518072289
probs:  [0.02472390714421818, 0.006257445827608183, 0.9627612012005656, 0.006257445827608183]
maxi score, test score, baseline:  -0.996896996996997 -1.0 -0.996896996996997
maxi score, test score, baseline:  -0.996896996996997 -1.0 -0.996896996996997
probs:  [0.0247241958947062, 0.006257508801164472, 0.9627607865029648, 0.006257508801164472]
line 256 mcts: sample exp_bonus 2.5627687119677325
maxi score, test score, baseline:  -0.996896996996997 -1.0 -0.996896996996997
probs:  [0.0247241958947062, 0.006257508801164472, 0.9627607865029648, 0.006257508801164472]
Printing some Q and Qe and total Qs values:  [[0.729]
 [0.798]
 [0.729]
 [0.729]
 [0.729]
 [0.729]
 [0.729]] [[1.048]
 [2.175]
 [1.048]
 [1.048]
 [1.048]
 [1.048]
 [1.048]] [[0.84 ]
 [1.265]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.996896996996997 -1.0 -0.996896996996997
probs:  [0.0247241958947062, 0.006257508801164472, 0.9627607865029648, 0.006257508801164472]
maxi score, test score, baseline:  -0.996896996996997 -1.0 -0.996896996996997
maxi score, test score, baseline:  -0.996896996996997 -1.0 -0.996896996996997
probs:  [0.0247241958947062, 0.006257508801164472, 0.9627607865029648, 0.006257508801164472]
using explorer policy with actor:  0
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 3.6899512149016576
Printing some Q and Qe and total Qs values:  [[0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.432]] [[3.188]
 [3.188]
 [3.188]
 [3.188]
 [3.188]
 [3.188]
 [2.679]] [[0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.432]]
maxi score, test score, baseline:  -0.9969588235294118 -1.0 -0.9969588235294118
probs:  [0.0247261696172511, 0.006257939250237337, 0.9627579518822741, 0.006257939250237337]
siam score:  -0.84231216
maxi score, test score, baseline:  -0.9969588235294118 -1.0 -0.9969588235294118
probs:  [0.0247261696172511, 0.006257939250237337, 0.9627579518822741, 0.006257939250237337]
Printing some Q and Qe and total Qs values:  [[0.493]
 [0.51 ]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]] [[0.945]
 [2.064]
 [0.945]
 [0.945]
 [0.945]
 [0.945]
 [0.945]] [[0.493]
 [0.51 ]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]]
maxi score, test score, baseline:  -0.9969588235294118 -1.0 -0.9969588235294118
in main func line 156:  656
maxi score, test score, baseline:  -0.9969674486803519 -1.0 -0.9969674486803519
probs:  [0.02472644496659633, 0.00625799930119031, 0.9627575564310232, 0.00625799930119031]
siam score:  -0.8470361
Printing some Q and Qe and total Qs values:  [[0.312]
 [0.338]
 [0.317]
 [0.318]
 [0.32 ]
 [0.316]
 [0.317]] [[0.437]
 [0.4  ]
 [1.007]
 [0.755]
 [1.217]
 [1.498]
 [1.078]] [[0.312]
 [0.338]
 [0.317]
 [0.318]
 [0.32 ]
 [0.316]
 [0.317]]
line 256 mcts: sample exp_bonus 0.40223516191690833
maxi score, test score, baseline:  -0.9969760233918129 -1.0 -0.9969760233918129
probs:  [0.024726718706654976, 0.00625805900117997, 0.9627571632909852, 0.00625805900117997]
Printing some Q and Qe and total Qs values:  [[1.484]
 [1.485]
 [1.484]
 [1.484]
 [1.484]
 [1.484]
 [1.484]] [[0.596]
 [0.595]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]] [[2.723]
 [2.725]
 [2.723]
 [2.723]
 [2.723]
 [2.723]
 [2.723]]
Printing some Q and Qe and total Qs values:  [[0.48 ]
 [0.574]
 [0.623]
 [0.634]
 [0.6  ]
 [0.982]
 [0.585]] [[2.371]
 [1.831]
 [2.258]
 [1.957]
 [2.258]
 [2.752]
 [2.46 ]] [[1.116]
 [1.124]
 [1.364]
 [1.285]
 [1.318]
 [2.246]
 [1.355]]
Printing some Q and Qe and total Qs values:  [[0.26 ]
 [0.262]
 [0.262]
 [0.26 ]
 [0.262]
 [0.262]
 [0.26 ]] [[-0.217]
 [ 0.329]
 [ 0.329]
 [ 0.017]
 [ 0.329]
 [ 0.329]
 [ 0.347]] [[0.26 ]
 [0.262]
 [0.262]
 [0.26 ]
 [0.262]
 [0.262]
 [0.26 ]]
Printing some Q and Qe and total Qs values:  [[0.733]
 [0.75 ]
 [0.73 ]
 [0.656]
 [0.651]
 [0.65 ]
 [0.642]] [[0.862]
 [1.072]
 [0.772]
 [0.122]
 [0.174]
 [0.213]
 [0.52 ]] [[0.948]
 [1.053]
 [0.913]
 [0.548]
 [0.556]
 [0.565]
 [0.653]]
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.024726990851494185, 0.0062581183532741174, 0.9627567724419577, 0.0062581183532741174]
Printing some Q and Qe and total Qs values:  [[0.351]
 [0.351]
 [0.351]
 [0.351]
 [0.351]
 [0.351]
 [0.673]] [[1.653]
 [1.653]
 [1.653]
 [1.653]
 [1.653]
 [1.653]
 [1.94 ]] [[-0.03 ]
 [-0.03 ]
 [-0.03 ]
 [-0.03 ]
 [-0.03 ]
 [-0.03 ]
 [ 0.549]]
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.015563535415701862, 0.006307711880803829, 0.9718210408226903, 0.006307711880803829]
maxi score, test score, baseline:  -0.9969845481049563 -1.0 -0.9969845481049563
probs:  [0.015563535415701862, 0.006307711880803829, 0.9718210408226903, 0.006307711880803829]
rdn beta is 0 so we're just using the maxi policy
rdn probs:  [0.015563535415701862, 0.006307711880803829, 0.9718210408226903, 0.006307711880803829]
line 256 mcts: sample exp_bonus 0.4083051501228566
Printing some Q and Qe and total Qs values:  [[0.315]
 [0.373]
 [0.327]
 [0.327]
 [0.327]
 [0.338]
 [0.336]] [[0.649]
 [0.986]
 [0.807]
 [0.807]
 [0.807]
 [0.465]
 [0.926]] [[0.315]
 [0.373]
 [0.327]
 [0.327]
 [0.327]
 [0.338]
 [0.336]]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.015563702574873623, 0.006307772017599578, 0.9718207533899272, 0.006307772017599578]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.015563702574873623, 0.006307772017599578, 0.9718207533899272, 0.006307772017599578]
maxi score, test score, baseline:  -0.996993023255814 -1.0 -0.996993023255814
probs:  [0.015563702574873623, 0.006307772017599578, 0.9718207533899272, 0.006307772017599578]
Printing some Q and Qe and total Qs values:  [[0.471]
 [0.473]
 [0.465]
 [0.463]
 [0.468]
 [0.465]
 [0.463]] [[1.143]
 [2.15 ]
 [1.089]
 [0.843]
 [1.311]
 [1.247]
 [1.388]] [[0.471]
 [0.473]
 [0.465]
 [0.463]
 [0.468]
 [0.465]
 [0.463]]
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
maxi score, test score, baseline:  -0.9970014492753624 -1.0 -0.9970014492753624
probs:  [0.015563868765608233, 0.006307831805997498, 0.9718204676223968, 0.006307831805997498]
Printing some Q and Qe and total Qs values:  [[0.656]
 [0.679]
 [0.571]
 [0.532]
 [0.577]
 [0.549]
 [0.76 ]] [[1.688]
 [0.76 ]
 [1.152]
 [0.937]
 [0.881]
 [1.078]
 [3.077]] [[0.656]
 [0.679]
 [0.571]
 [0.532]
 [0.577]
 [0.549]
 [0.76 ]]
maxi score, test score, baseline:  -0.9970098265895954 -1.0 -0.9970098265895954
probs:  [0.015564033996297345, 0.006307891249016467, 0.9718201835056696, 0.006307891249016467]
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.015564198275236052, 0.006307950349640579, 0.9718199010254828, 0.006307950349640579]
line 256 mcts: sample exp_bonus 0.8353211176289334
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.015564198275236052, 0.006307950349640579, 0.9718199010254828, 0.006307950349640579]
maxi score, test score, baseline:  -0.9970181556195965 -1.0 -0.9970181556195965
probs:  [0.015564198275236052, 0.006307950349640579, 0.9718199010254828, 0.006307950349640579]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.23 ]
 [0.238]
 [0.238]
 [0.238]
 [0.239]
 [0.241]
 [0.235]] [[0.845]
 [0.629]
 [0.629]
 [0.802]
 [0.878]
 [1.018]
 [0.718]] [[0.23 ]
 [0.238]
 [0.238]
 [0.238]
 [0.239]
 [0.241]
 [0.235]]
from probs:  [0.015564198275236052, 0.006307950349640579, 0.9718199010254828, 0.006307950349640579]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
probs:  [0.015564361610624142, 0.006308009110819665, 0.9718196201677366, 0.006308009110819665]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9970264367816092 -1.0 -0.9970264367816092
probs:  [0.015564361610624142, 0.006308009110819665, 0.9718196201677366, 0.006308009110819665]
line 256 mcts: sample exp_bonus 0.7977038425403098
using another actor
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.015564685483078301, 0.0063081256264735765, 0.9718190632639745, 0.0063081256264735765]
Printing some Q and Qe and total Qs values:  [[0.791]
 [0.566]
 [0.791]
 [0.687]
 [0.791]
 [0.764]
 [0.697]] [[3.057]
 [1.859]
 [3.057]
 [0.934]
 [3.057]
 [0.986]
 [1.762]] [[3.127]
 [1.479]
 [3.127]
 [0.797]
 [3.127]
 [1.002]
 [1.644]]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.015564685483078301, 0.0063081256264735765, 0.9718190632639745, 0.0063081256264735765]
Printing some Q and Qe and total Qs values:  [[0.476]
 [0.477]
 [0.482]
 [0.472]
 [0.482]
 [0.489]
 [0.474]] [[1.127]
 [2.566]
 [1.032]
 [0.899]
 [1.119]
 [1.194]
 [1.392]] [[0.476]
 [0.477]
 [0.482]
 [0.472]
 [0.482]
 [0.489]
 [0.474]]
Printing some Q and Qe and total Qs values:  [[0.314]
 [0.316]
 [0.667]
 [0.52 ]
 [0.472]
 [0.726]
 [0.527]] [[2.289]
 [2.379]
 [1.984]
 [1.998]
 [1.69 ]
 [0.768]
 [1.875]] [[1.095]
 [1.157]
 [1.361]
 [1.176]
 [0.909]
 [0.636]
 [1.103]]
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.015564685483078301, 0.0063081256264735765, 0.9718190632639745, 0.0063081256264735765]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.471369719086516
siam score:  -0.8440615
maxi score, test score, baseline:  -0.9970428571428571 -1.0 -0.9970428571428571
probs:  [0.015564685483078301, 0.0063081256264735765, 0.9718190632639745, 0.0063081256264735765]
from probs:  [0.015564846036079629, 0.006308183386681028, 0.9718187871905581, 0.006308183386681028]
Printing some Q and Qe and total Qs values:  [[0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]] [[5.242]
 [5.242]
 [5.242]
 [5.242]
 [5.242]
 [5.242]
 [5.242]] [[1.731]
 [1.731]
 [1.731]
 [1.731]
 [1.731]
 [1.731]
 [1.731]]
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.592]
 [0.551]
 [0.587]
 [0.605]
 [0.605]
 [0.61 ]
 [0.606]] [[ 0.197]
 [ 1.341]
 [ 0.652]
 [-0.111]
 [ 0.04 ]
 [ 0.324]
 [ 0.276]] [[0.216]
 [0.629]
 [0.389]
 [0.106]
 [0.165]
 [0.28 ]
 [0.258]]
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
probs:  [0.01556500567740315, 0.006308240818909641, 0.9718185126847777, 0.006308240818909641]
Printing some Q and Qe and total Qs values:  [[0.253]
 [0.322]
 [0.43 ]
 [0.43 ]
 [0.326]
 [0.253]
 [0.263]] [[2.053]
 [2.012]
 [2.892]
 [1.493]
 [1.313]
 [2.329]
 [1.775]] [[1.047]
 [1.123]
 [1.982]
 [0.885]
 [0.582]
 [1.263]
 [0.844]]
maxi score, test score, baseline:  -0.997059090909091 -1.0 -0.997059090909091
probs:  [0.01556500567740315, 0.006308240818909641, 0.9718185126847777, 0.006308240818909641]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
672 533
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
Printing some Q and Qe and total Qs values:  [[0.646]
 [0.642]
 [0.646]
 [0.646]
 [0.646]
 [0.646]
 [0.646]] [[2.181]
 [1.94 ]
 [2.181]
 [2.181]
 [2.181]
 [2.181]
 [2.181]] [[0.231]
 [0.102]
 [0.231]
 [0.231]
 [0.231]
 [0.231]
 [0.231]]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
678 547
maxi score, test score, baseline:  -0.9970671388101983 -1.0 -0.9970671388101983
probs:  [0.015565164414791997, 0.00630829792594504, 0.9718182397333178, 0.00630829792594504]
Printing some Q and Qe and total Qs values:  [[0.336]
 [0.313]
 [0.334]
 [0.337]
 [0.334]
 [0.333]
 [0.337]] [[-0.61 ]
 [ 1.328]
 [-0.474]
 [-0.456]
 [-0.239]
 [-0.242]
 [-0.288]] [[0.336]
 [0.313]
 [0.334]
 [0.337]
 [0.334]
 [0.333]
 [0.337]]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
probs:  [0.015565322255901997, 0.006308354710541402, 0.9718179683230153, 0.006308354710541402]
Printing some Q and Qe and total Qs values:  [[0.352]
 [0.426]
 [0.359]
 [0.356]
 [0.359]
 [0.355]
 [0.355]] [[-0.976]
 [ 0.149]
 [-0.531]
 [-0.69 ]
 [-0.641]
 [-0.552]
 [-0.545]] [[0.352]
 [0.426]
 [0.359]
 [0.356]
 [0.359]
 [0.355]
 [0.355]]
Printing some Q and Qe and total Qs values:  [[0.471]
 [0.473]
 [0.584]
 [0.577]
 [0.559]
 [0.591]
 [0.637]] [[2.067]
 [2.771]
 [1.382]
 [1.326]
 [1.316]
 [1.921]
 [2.787]] [[0.547]
 [1.03 ]
 [0.234]
 [0.187]
 [0.155]
 [0.611]
 [1.264]]
using another actor
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.355]
 [0.425]
 [0.364]
 [0.357]
 [0.372]
 [0.365]
 [0.364]] [[-0.366]
 [ 0.092]
 [-0.304]
 [-0.33 ]
 [-0.245]
 [-0.259]
 [-0.24 ]] [[0.355]
 [0.425]
 [0.364]
 [0.357]
 [0.372]
 [0.365]
 [0.364]]
maxi score, test score, baseline:  -0.9970751412429378 -1.0 -0.9970751412429378
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.5286],
        [-0.5362],
        [-0.5045],
        [-0.4747],
        [-0.0000],
        [-0.5276],
        [-0.3261],
        [-0.5366],
        [-0.4818],
        [-0.5059]], dtype=torch.float64)
-0.024259925299500003 -0.5528661891759086
-0.024259925299500003 -0.5604738437208819
-0.0727797758985 -0.5772752442221506
-0.0727797758985 -0.547509015422226
-0.9605475 -0.9605475
-0.024259925299500003 -0.5518338399475512
-0.0727797758985 -0.3988575738797872
-0.024259925299500003 -0.5608215314563698
-0.0727797758985 -0.5545947194056884
-0.0727797758985 -0.5786988191929928
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9970830985915493 -1.0 -0.9970830985915493
probs:  [0.0063582482792273135, 0.0063582482792273135, 0.9809252551623181, 0.0063582482792273135]
Printing some Q and Qe and total Qs values:  [[0.626]
 [0.628]
 [0.626]
 [0.61 ]
 [0.617]
 [0.618]
 [0.632]] [[0.271]
 [1.333]
 [0.356]
 [0.298]
 [0.424]
 [0.571]
 [0.614]] [[0.626]
 [0.628]
 [0.626]
 [0.61 ]
 [0.617]
 [0.618]
 [0.632]]
siam score:  -0.8333386
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.006358362394096816, 0.006358362394096816, 0.9809249128177097, 0.006358362394096816]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.006358362394096816, 0.006358362394096816, 0.9809249128177097, 0.006358362394096816]
Printing some Q and Qe and total Qs values:  [[0.544]
 [0.61 ]
 [0.547]
 [0.547]
 [0.562]
 [0.564]
 [0.566]] [[-0.06 ]
 [ 0.3  ]
 [ 0.026]
 [-0.072]
 [ 0.009]
 [ 0.097]
 [ 0.171]] [[0.594]
 [0.965]
 [0.664]
 [0.589]
 [0.674]
 [0.742]
 [0.801]]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.006358362394096816, 0.006358362394096816, 0.9809249128177097, 0.006358362394096816]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.006358362394096816, 0.006358362394096816, 0.9809249128177097, 0.006358362394096816]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.006358362394096816, 0.006358362394096816, 0.9809249128177097, 0.006358362394096816]
Printing some Q and Qe and total Qs values:  [[0.225]
 [0.214]
 [0.271]
 [0.271]
 [0.271]
 [0.271]
 [0.283]] [[1.423]
 [1.996]
 [3.15 ]
 [3.15 ]
 [3.15 ]
 [3.15 ]
 [2.622]] [[-0.206]
 [ 0.283]
 [ 1.405]
 [ 1.405]
 [ 1.405]
 [ 1.405]
 [ 0.959]]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.006358362394096816, 0.006358362394096816, 0.9809249128177097, 0.006358362394096816]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.006358362394096816, 0.006358362394096816, 0.9809249128177097, 0.006358362394096816]
maxi score, test score, baseline:  -0.9970988795518207 -1.0 -0.9970988795518207
probs:  [0.006358362394096816, 0.006358362394096816, 0.9809249128177097, 0.006358362394096816]
from probs:  [0.0151455246448078, 0.0151455246448078, 0.9635303163009571, 0.006178634409427392]
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
probs:  [0.0151455246448078, 0.0151455246448078, 0.9635303163009571, 0.006178634409427392]
siam score:  -0.84273577
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
probs:  [0.0151455246448078, 0.0151455246448078, 0.9635303163009571, 0.006178634409427392]
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
maxi score, test score, baseline:  -0.9971067039106145 -1.0 -0.9971067039106145
probs:  [0.0151455246448078, 0.0151455246448078, 0.9635303163009571, 0.006178634409427392]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.015145671011247197, 0.015145671011247197, 0.9635299706894395, 0.006178687288066167]
maxi score, test score, baseline:  -0.9971144846796658 -1.0 -0.9971144846796658
probs:  [0.015145671011247197, 0.015145671011247197, 0.9635299706894395, 0.006178687288066167]
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.015145961312723734, 0.015145961312723734, 0.9635292852076036, 0.006178792166949034]
maxi score, test score, baseline:  -0.997129916897507 -1.0 -0.997129916897507
probs:  [0.015145961312723734, 0.015145961312723734, 0.9635292852076036, 0.006178792166949034]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
probs:  [0.015146248416961206, 0.015146248416961206, 0.9635286072753151, 0.006178895890762457]
Printing some Q and Qe and total Qs values:  [[0.894]
 [0.882]
 [0.847]
 [0.894]
 [0.894]
 [0.894]
 [0.894]] [[1.315]
 [1.845]
 [0.433]
 [1.315]
 [1.315]
 [1.315]
 [1.315]] [[1.347]
 [1.735]
 [0.6  ]
 [1.347]
 [1.347]
 [1.347]
 [1.347]]
Printing some Q and Qe and total Qs values:  [[0.322]
 [0.377]
 [0.31 ]
 [0.304]
 [0.33 ]
 [0.333]
 [0.334]] [[-0.255]
 [ 0.524]
 [-0.504]
 [-0.646]
 [-0.16 ]
 [-0.113]
 [-0.037]] [[0.322]
 [0.377]
 [0.31 ]
 [0.304]
 [0.33 ]
 [0.333]
 [0.334]]
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
probs:  [0.015146248416961206, 0.015146248416961206, 0.9635286072753151, 0.006178895890762457]
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
probs:  [0.015146248416961206, 0.015146248416961206, 0.9635286072753151, 0.006178895890762457]
maxi score, test score, baseline:  -0.9971451790633609 -1.0 -0.9971451790633609
probs:  [0.015146248416961206, 0.015146248416961206, 0.9635286072753151, 0.006178895890762457]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.015146390786575715, 0.015146390786575715, 0.9635282711013838, 0.006178947325464828]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.015146390786575715, 0.015146390786575715, 0.9635282711013838, 0.006178947325464828]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.015146390786575715, 0.015146390786575715, 0.9635282711013838, 0.006178947325464828]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.015146390786575715, 0.015146390786575715, 0.9635282711013838, 0.006178947325464828]
line 256 mcts: sample exp_bonus 0.8056081311678625
Printing some Q and Qe and total Qs values:  [[0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]
 [1.368]] [[1.599]
 [1.599]
 [1.599]
 [1.599]
 [1.599]
 [1.599]
 [2.087]] [[1.615]
 [1.615]
 [1.615]
 [1.615]
 [1.615]
 [1.615]
 [2.739]]
Printing some Q and Qe and total Qs values:  [[0.689]
 [0.715]
 [0.692]
 [0.686]
 [0.684]
 [0.7  ]
 [0.716]] [[0.825]
 [1.553]
 [0.771]
 [0.633]
 [0.75 ]
 [0.788]
 [1.311]] [[0.41 ]
 [0.873]
 [0.382]
 [0.292]
 [0.359]
 [0.4  ]
 [0.73 ]]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.01527494848900886, 0.0062260348237335285, 0.9722729818635241, 0.0062260348237335285]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.01527494848900886, 0.0062260348237335285, 0.9722729818635241, 0.0062260348237335285]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.01527494848900886, 0.0062260348237335285, 0.9722729818635241, 0.0062260348237335285]
Printing some Q and Qe and total Qs values:  [[0.619]
 [0.581]
 [0.618]
 [0.613]
 [0.608]
 [0.608]
 [0.603]] [[2.281]
 [3.572]
 [2.153]
 [1.967]
 [2.202]
 [2.354]
 [2.126]] [[0.345]
 [1.324]
 [0.239]
 [0.083]
 [0.263]
 [0.386]
 [0.194]]
Printing some Q and Qe and total Qs values:  [[0.456]
 [0.503]
 [0.456]
 [0.456]
 [0.456]
 [0.456]
 [0.451]] [[1.202]
 [1.093]
 [1.202]
 [1.202]
 [1.202]
 [1.202]
 [0.975]] [[0.456]
 [0.503]
 [0.456]
 [0.456]
 [0.456]
 [0.456]
 [0.451]]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.01527494848900886, 0.0062260348237335285, 0.9722729818635241, 0.0062260348237335285]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.01527494848900886, 0.0062260348237335285, 0.9722729818635241, 0.0062260348237335285]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.01527494848900886, 0.0062260348237335285, 0.9722729818635241, 0.0062260348237335285]
siam score:  -0.8410089
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.01527494848900886, 0.0062260348237335285, 0.9722729818635241, 0.0062260348237335285]
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.01527494848900886, 0.0062260348237335285, 0.9722729818635241, 0.0062260348237335285]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9971527472527473 -1.0 -0.9971527472527473
probs:  [0.01527494848900886, 0.0062260348237335285, 0.9722729818635241, 0.0062260348237335285]
Printing some Q and Qe and total Qs values:  [[0.55 ]
 [0.533]
 [0.568]
 [0.563]
 [0.549]
 [0.536]
 [0.53 ]] [[4.925]
 [4.753]
 [4.884]
 [4.004]
 [4.413]
 [4.662]
 [5.446]] [[0.55 ]
 [0.533]
 [0.568]
 [0.563]
 [0.549]
 [0.536]
 [0.53 ]]
Printing some Q and Qe and total Qs values:  [[0.553]
 [0.568]
 [0.556]
 [0.557]
 [0.554]
 [0.557]
 [0.556]] [[0.523]
 [1.421]
 [0.361]
 [0.199]
 [0.379]
 [0.515]
 [0.648]] [[0.866]
 [1.793]
 [0.709]
 [0.548]
 [0.723]
 [0.865]
 [0.995]]
using explorer policy with actor:  1
siam score:  -0.8390544
using explorer policy with actor:  0
main train batch thing paused
add a thread
Adding thread: now have 4 threads
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.015275236070696238, 0.0062261387331066275, 0.9722724864630905, 0.0062261387331066275]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
probs:  [0.015275236070696238, 0.0062261387331066275, 0.9722724864630905, 0.0062261387331066275]
maxi score, test score, baseline:  -0.9971677595628415 -1.0 -0.9971677595628415
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.006274196295330971, 0.006274196295330971, 0.981177411114007, 0.006274196295330971]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.006274196295330971, 0.006274196295330971, 0.981177411114007, 0.006274196295330971]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.006274196295330971, 0.006274196295330971, 0.981177411114007, 0.006274196295330971]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.006274196295330971, 0.006274196295330971, 0.981177411114007, 0.006274196295330971]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.006274196295330971, 0.006274196295330971, 0.981177411114007, 0.006274196295330971]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.006274196295330971, 0.006274196295330971, 0.981177411114007, 0.006274196295330971]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.006274196295330971, 0.006274196295330971, 0.981177411114007, 0.006274196295330971]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.006274196295330971, 0.006274196295330971, 0.981177411114007, 0.006274196295330971]
Printing some Q and Qe and total Qs values:  [[0.583]
 [0.535]
 [0.579]
 [0.59 ]
 [0.561]
 [0.578]
 [0.606]] [[5.688]
 [5.471]
 [6.026]
 [4.988]
 [4.735]
 [5.307]
 [5.344]] [[1.621]
 [1.448]
 [1.804]
 [1.242]
 [1.07 ]
 [1.405]
 [1.456]]
maxi score, test score, baseline:  -0.9971826086956522 -1.0 -0.9971826086956522
probs:  [0.006100579069549549, 0.014870236604824167, 0.9641589477208022, 0.014870236604824167]
maxi score, test score, baseline:  -0.997189972899729 -1.0 -0.997189972899729
probs:  [0.006100627928602568, 0.014870371265538692, 0.9641586295403201, 0.014870371265538692]
maxi score, test score, baseline:  -0.997189972899729 -1.0 -0.997189972899729
probs:  [0.006100627928602568, 0.014870371265538692, 0.9641586295403201, 0.014870371265538692]
using explorer policy with actor:  1
using another actor
maxi score, test score, baseline:  -0.997189972899729 -1.0 -0.997189972899729
probs:  [0.006100627928602568, 0.014870371265538692, 0.9641586295403201, 0.014870371265538692]
maxi score, test score, baseline:  -0.997189972899729 -1.0 -0.997189972899729
probs:  [0.006100627928602568, 0.014870371265538692, 0.9641586295403201, 0.014870371265538692]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
siam score:  -0.83098793
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
from probs:  [0.02601596110980039, 0.06900033369882001, 0.8359833714925595, 0.06900033369882001]
Printing some Q and Qe and total Qs values:  [[0.225]
 [0.225]
 [0.225]
 [0.225]
 [0.225]
 [0.225]
 [0.395]] [[1.428]
 [1.428]
 [1.428]
 [1.428]
 [1.428]
 [1.428]
 [1.614]] [[-0.408]
 [-0.408]
 [-0.408]
 [-0.408]
 [-0.408]
 [-0.408]
 [ 0.118]]
maxi score, test score, baseline:  -0.9971972972972973 -1.0 -0.9971972972972973
probs:  [0.02601596110980039, 0.06900033369882001, 0.8359833714925595, 0.06900033369882001]
maxi score, test score, baseline:  -0.9972045822102426 -1.0 -0.9972045822102426
probs:  [0.026016685895808973, 0.0690023126966017, 0.8359786887109876, 0.0690023126966017]
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
probs:  [0.026017406815100123, 0.0690042811364274, 0.8359740309120453, 0.0690042811364274]
maxi score, test score, baseline:  -0.9972118279569893 -1.0 -0.9972118279569893
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.6799002545408652
Printing some Q and Qe and total Qs values:  [[0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.674]] [[2.114]
 [2.114]
 [2.114]
 [2.114]
 [2.114]
 [2.114]
 [2.452]] [[1.241]
 [1.241]
 [1.241]
 [1.241]
 [1.241]
 [1.241]
 [1.66 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.02601812389853484, 0.06900623910256125, 0.8359693978963427, 0.06900623910256125]
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.02601812389853484, 0.06900623910256125, 0.8359693978963427, 0.06900623910256125]
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.02601812389853484, 0.06900623910256125, 0.8359693978963427, 0.06900623910256125]
line 256 mcts: sample exp_bonus 3.357720555730204
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
Printing some Q and Qe and total Qs values:  [[0.621]
 [0.691]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]] [[1.002]
 [1.189]
 [1.002]
 [1.002]
 [1.002]
 [1.002]
 [1.002]] [[0.662]
 [0.946]
 [0.662]
 [0.662]
 [0.662]
 [0.662]
 [0.662]]
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.027146793215390586, 0.027146793215390586, 0.8736324452315342, 0.07207396833768463]
maxi score, test score, baseline:  -0.9972190348525469 -1.0 -0.9972190348525469
probs:  [0.02838209385021736, 0.02838209385021736, 0.9148537184493478, 0.02838209385021736]
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.02838294880590534, 0.02838294880590534, 0.9148511535822839, 0.02838294880590534]
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.02838294880590534, 0.02838294880590534, 0.9148511535822839, 0.02838294880590534]
Printing some Q and Qe and total Qs values:  [[0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.487]] [[1.042]
 [1.042]
 [1.042]
 [1.042]
 [1.042]
 [1.042]
 [1.092]] [[0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.487]]
Printing some Q and Qe and total Qs values:  [[0.185]
 [0.775]
 [0.843]
 [0.967]
 [0.886]
 [0.469]
 [1.333]] [[2.076]
 [2.219]
 [1.192]
 [0.925]
 [1.403]
 [2.161]
 [4.124]] [[0.244]
 [0.961]
 [0.478]
 [0.468]
 [0.64 ]
 [0.598]
 [2.603]]
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
probs:  [0.02838294880590534, 0.02838294880590534, 0.9148511535822839, 0.02838294880590534]
Printing some Q and Qe and total Qs values:  [[0.858]
 [0.858]
 [0.858]
 [0.858]
 [0.858]
 [0.858]
 [1.079]] [[2.232]
 [2.232]
 [2.232]
 [2.232]
 [2.232]
 [2.232]
 [1.786]] [[1.325]
 [1.325]
 [1.325]
 [1.325]
 [1.325]
 [1.325]
 [1.321]]
maxi score, test score, baseline:  -0.9972262032085562 -1.0 -0.9972262032085562
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.028383799241233246, 0.028383799241233246, 0.9148486022763004, 0.028383799241233246]
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.028383799241233246, 0.028383799241233246, 0.9148486022763004, 0.028383799241233246]
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.028383799241233246, 0.028383799241233246, 0.9148486022763004, 0.028383799241233246]
using explorer policy with actor:  1
actor:  1 policy actor:  1  step number:  67 total reward:  0.27999999999999947  reward:  1.0 rdn_beta:  0.5
maxi score, test score, baseline:  -0.9972333333333333 -1.0 -0.9972333333333333
probs:  [0.007461337066466195, 0.007461337066466195, 0.9776159888006014, 0.007461337066466195]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9972474801061008 -1.0 -0.9972474801061008
probs:  [0.007461459805777454, 0.007461459805777454, 0.9776156205826677, 0.007461459805777454]
Printing some Q and Qe and total Qs values:  [[0.411]
 [0.411]
 [0.411]
 [0.411]
 [0.411]
 [0.415]
 [0.427]] [[1.118]
 [1.118]
 [1.118]
 [1.118]
 [1.118]
 [1.172]
 [1.047]] [[0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.752]
 [0.651]]
maxi score, test score, baseline:  -0.9972474801061008 -1.0 -0.9972474801061008
probs:  [0.007461459805777454, 0.007461459805777454, 0.9776156205826677, 0.007461459805777454]
maxi score, test score, baseline:  -0.9972474801061008 -1.0 -0.9972474801061008
probs:  [0.007461459805777454, 0.007461459805777454, 0.9776156205826677, 0.007461459805777454]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
first move QE:  0.6573890107126321
Printing some Q and Qe and total Qs values:  [[0.637]
 [0.532]
 [0.637]
 [0.637]
 [0.637]
 [0.698]
 [0.684]] [[5.232]
 [4.378]
 [5.232]
 [5.232]
 [5.232]
 [3.577]
 [3.947]] [[1.649]
 [0.965]
 [1.649]
 [1.649]
 [1.649]
 [0.662]
 [0.883]]
from probs:  [0.007461459805777454, 0.007461459805777454, 0.9776156205826677, 0.007461459805777454]
siam score:  -0.84108657
Printing some Q and Qe and total Qs values:  [[0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]] [[0.072]
 [0.072]
 [0.072]
 [0.072]
 [0.072]
 [0.072]
 [0.072]] [[0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]
 [0.316]]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.007461520688682903, 0.007461520688682903, 0.9776154379339514, 0.007461520688682903]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.007461520688682903, 0.007461520688682903, 0.9776154379339514, 0.007461520688682903]
maxi score, test score, baseline:  -0.9972544973544973 -1.0 -0.9972544973544973
probs:  [0.007461520688682903, 0.007461520688682903, 0.9776154379339514, 0.007461520688682903]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
probs:  [0.007461641493794514, 0.007461641493794514, 0.9776150755186166, 0.007461641493794514]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
probs:  [0.007461641493794514, 0.007461641493794514, 0.9776150755186166, 0.007461641493794514]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
probs:  [0.007461641493794514, 0.007461641493794514, 0.9776150755186166, 0.007461641493794514]
maxi score, test score, baseline:  -0.9972684210526316 -1.0 -0.9972684210526316
maxi score, test score, baseline:  -0.9972821989528796 -1.0 -0.9972821989528796
probs:  [0.0074617610347293035, 0.0074617610347293035, 0.9776147168958123, 0.0074617610347293035]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.506]] [[3.068]
 [3.068]
 [3.068]
 [3.068]
 [3.068]
 [3.068]
 [1.823]] [[2.352]
 [2.352]
 [2.352]
 [2.352]
 [2.352]
 [2.352]
 [1.389]]
Printing some Q and Qe and total Qs values:  [[0.376]
 [0.401]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]] [[1.446]
 [1.264]
 [1.446]
 [1.446]
 [1.446]
 [1.446]
 [1.446]] [[0.376]
 [0.401]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]]
maxi score, test score, baseline:  -0.9972821989528796 -1.0 -0.9972821989528796
probs:  [0.0074617610347293035, 0.0074617610347293035, 0.9776147168958123, 0.0074617610347293035]
maxi score, test score, baseline:  -0.9972821989528796 -1.0 -0.9972821989528796
probs:  [0.0074617610347293035, 0.0074617610347293035, 0.9776147168958123, 0.0074617610347293035]
siam score:  -0.82992464
maxi score, test score, baseline:  -0.9972890339425587 -1.0 -0.9972890339425587
probs:  [0.007461820337315351, 0.007461820337315351, 0.9776145389880538, 0.007461820337315351]
line 256 mcts: sample exp_bonus 0.9496937251363646
Printing some Q and Qe and total Qs values:  [[1.006]
 [1.001]
 [1.006]
 [1.006]
 [1.006]
 [1.006]
 [0.979]] [[3.014]
 [3.218]
 [3.014]
 [3.014]
 [3.014]
 [3.014]
 [5.743]] [[1.283]
 [1.338]
 [1.283]
 [1.283]
 [1.283]
 [1.283]
 [2.037]]
using another actor
from probs:  [0.007461879331227635, 0.007461879331227635, 0.9776143620063171, 0.007461879331227635]
Printing some Q and Qe and total Qs values:  [[0.485]
 [0.504]
 [0.499]
 [0.487]
 [0.491]
 [0.493]
 [0.488]] [[0.627]
 [2.779]
 [0.78 ]
 [0.739]
 [0.52 ]
 [0.909]
 [1.049]] [[0.485]
 [0.504]
 [0.499]
 [0.487]
 [0.491]
 [0.493]
 [0.488]]
maxi score, test score, baseline:  -0.9973025974025974 -1.0 -0.9973025974025974
probs:  [0.007461938018869897, 0.007461938018869897, 0.9776141859433902, 0.007461938018869897]
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
probs:  [0.007461996402620991, 0.007461996402620991, 0.977614010792137, 0.007461996402620991]
from probs:  [0.007461996402620991, 0.007461996402620991, 0.977614010792137, 0.007461996402620991]
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
probs:  [0.007461996402620991, 0.007461996402620991, 0.977614010792137, 0.007461996402620991]
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
maxi score, test score, baseline:  -0.9973093264248705 -1.0 -0.9973093264248705
probs:  [0.007461996402620991, 0.007461996402620991, 0.977614010792137, 0.007461996402620991]
Printing some Q and Qe and total Qs values:  [[0.195]
 [0.138]
 [0.207]
 [0.198]
 [0.2  ]
 [0.2  ]
 [0.199]] [[3.705]
 [2.347]
 [3.727]
 [3.746]
 [3.719]
 [3.54 ]
 [3.734]] [[1.287]
 [0.019]
 [1.328]
 [1.328]
 [1.309]
 [1.153]
 [1.319]]
Printing some Q and Qe and total Qs values:  [[1.051]
 [1.107]
 [0.625]
 [0.625]
 [0.625]
 [0.968]
 [0.785]] [[2.116]
 [1.302]
 [2.43 ]
 [2.43 ]
 [2.43 ]
 [1.817]
 [2.116]] [[2.583]
 [1.963]
 [2.108]
 [2.108]
 [2.108]
 [2.172]
 [2.114]]
maxi score, test score, baseline:  -0.9973160206718347 -1.0 -0.9973160206718347
probs:  [0.007462054484835201, 0.007462054484835201, 0.9776138365454945, 0.007462054484835201]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973160206718347 -1.0 -0.9973160206718347
maxi score, test score, baseline:  -0.9973160206718347 -1.0 -0.9973160206718347
probs:  [0.007462054484835201, 0.007462054484835201, 0.9776138365454945, 0.007462054484835201]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
probs:  [0.007462112267842534, 0.007462112267842534, 0.9776136631964724, 0.007462112267842534]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.571]
 [0.783]] [[1.921]
 [1.921]
 [1.921]
 [1.921]
 [1.921]
 [1.921]
 [2.895]] [[1.554]
 [1.554]
 [1.554]
 [1.554]
 [1.554]
 [1.554]
 [2.431]]
maxi score, test score, baseline:  -0.9973226804123712 -1.0 -0.9973226804123712
probs:  [0.007462112267842534, 0.007462112267842534, 0.9776136631964724, 0.007462112267842534]
first move QE:  0.6770392597104329
Printing some Q and Qe and total Qs values:  [[0.709]
 [0.632]
 [0.758]
 [0.599]
 [0.599]
 [0.691]
 [0.629]] [[2.338]
 [3.279]
 [2.344]
 [4.238]
 [4.238]
 [2.917]
 [4.17 ]] [[0.709]
 [0.632]
 [0.758]
 [0.599]
 [0.599]
 [0.691]
 [0.629]]
maxi score, test score, baseline:  -0.9973293059125964 -1.0 -0.9973293059125964
siam score:  -0.8189412
maxi score, test score, baseline:  -0.9973293059125964 -1.0 -0.9973293059125964
probs:  [0.007462169753949069, 0.007462169753949069, 0.9776134907381527, 0.007462169753949069]
maxi score, test score, baseline:  -0.9973293059125964 -1.0 -0.9973293059125964
probs:  [0.007462169753949069, 0.007462169753949069, 0.9776134907381527, 0.007462169753949069]
maxi score, test score, baseline:  -0.9973293059125964 -1.0 -0.9973293059125964
probs:  [0.007462169753949069, 0.007462169753949069, 0.9776134907381527, 0.007462169753949069]
maxi score, test score, baseline:  -0.9973293059125964 -1.0 -0.9973293059125964
probs:  [0.007462169753949069, 0.007462169753949069, 0.9776134907381527, 0.007462169753949069]
maxi score, test score, baseline:  -0.9973293059125964 -1.0 -0.9973293059125964
probs:  [0.007462169753949069, 0.007462169753949069, 0.9776134907381527, 0.007462169753949069]
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
probs:  [0.007462226945437262, 0.007462226945437262, 0.9776133191636884, 0.007462226945437262]
Printing some Q and Qe and total Qs values:  [[0.709]
 [0.781]
 [0.709]
 [0.709]
 [0.709]
 [0.709]
 [0.58 ]] [[2.171]
 [2.301]
 [2.171]
 [2.171]
 [2.171]
 [2.171]
 [2.088]] [[1.979]
 [2.168]
 [1.979]
 [1.979]
 [1.979]
 [1.979]
 [1.742]]
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
probs:  [0.007462226945437262, 0.007462226945437262, 0.9776133191636884, 0.007462226945437262]
Printing some Q and Qe and total Qs values:  [[0.671]
 [0.806]
 [0.671]
 [0.671]
 [0.671]
 [0.671]
 [0.671]] [[1.297]
 [1.579]
 [1.297]
 [1.297]
 [1.297]
 [1.297]
 [1.297]] [[0.356]
 [0.642]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]]
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
probs:  [0.007462226945437262, 0.007462226945437262, 0.9776133191636884, 0.007462226945437262]
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
probs:  [0.007462226945437262, 0.007462226945437262, 0.9776133191636884, 0.007462226945437262]
Printing some Q and Qe and total Qs values:  [[0.642]
 [0.721]
 [0.683]
 [0.678]
 [0.669]
 [0.714]
 [0.684]] [[2.191]
 [2.484]
 [1.688]
 [1.708]
 [1.85 ]
 [1.411]
 [2.372]] [[2.302]
 [2.753]
 [1.88 ]
 [1.892]
 [2.015]
 [1.665]
 [2.567]]
Printing some Q and Qe and total Qs values:  [[0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]] [[3.938]
 [3.938]
 [3.938]
 [3.938]
 [3.938]
 [3.938]
 [3.938]] [[0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]]
rdn beta is 0 so we're just using the maxi policy
759 631
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
probs:  [0.007462226945437262, 0.007462226945437262, 0.9776133191636884, 0.007462226945437262]
siam score:  -0.8190323
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
probs:  [0.007462226945437262, 0.007462226945437262, 0.9776133191636884, 0.007462226945437262]
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9973358974358975 -1.0 -0.9973358974358975
probs:  [0.007462226945437262, 0.007462226945437262, 0.9776133191636884, 0.007462226945437262]
761 632
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973424552429667 -1.0 -0.9973424552429667
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973424552429667 -1.0 -0.9973424552429667
probs:  [0.0074622838445662035, 0.0074622838445662035, 0.9776131484663013, 0.0074622838445662035]
maxi score, test score, baseline:  -0.9973424552429667 -1.0 -0.9973424552429667
probs:  [0.0074622838445662035, 0.0074622838445662035, 0.9776131484663013, 0.0074622838445662035]
maxi score, test score, baseline:  -0.9973424552429667 -1.0 -0.9973424552429667
probs:  [0.0074622838445662035, 0.0074622838445662035, 0.9776131484663013, 0.0074622838445662035]
maxi score, test score, baseline:  -0.9973489795918368 -1.0 -0.9973489795918368
maxi score, test score, baseline:  -0.9973489795918368 -1.0 -0.9973489795918368
probs:  [0.00746234045357197, 0.00746234045357197, 0.977612978639284, 0.00746234045357197]
using explorer policy with actor:  1
first move QE:  0.695127951651033
maxi score, test score, baseline:  -0.9973489795918368 -1.0 -0.9973489795918368
probs:  [0.00746234045357197, 0.00746234045357197, 0.977612978639284, 0.00746234045357197]
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.561]
 [0.599]
 [0.599]
 [0.599]
 [0.515]
 [0.569]] [[3.036]
 [4.94 ]
 [4.151]
 [4.151]
 [4.151]
 [2.389]
 [4.253]] [[0.579]
 [1.656]
 [1.261]
 [1.261]
 [1.261]
 [0.192]
 [1.284]]
maxi score, test score, baseline:  -0.9973489795918368 -1.0 -0.9973489795918368
probs:  [0.00746234045357197, 0.00746234045357197, 0.977612978639284, 0.00746234045357197]
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.638]
 [0.646]
 [0.635]
 [0.635]
 [0.651]
 [0.647]] [[1.977]
 [2.428]
 [1.351]
 [2.091]
 [2.091]
 [1.494]
 [1.706]] [[1.638]
 [2.137]
 [1.074]
 [1.794]
 [1.794]
 [1.228]
 [1.431]]
maxi score, test score, baseline:  -0.9973489795918368 -1.0 -0.9973489795918368
probs:  [0.00746234045357197, 0.00746234045357197, 0.977612978639284, 0.00746234045357197]
maxi score, test score, baseline:  -0.9973489795918368 -1.0 -0.9973489795918368
probs:  [0.00746234045357197, 0.00746234045357197, 0.977612978639284, 0.00746234045357197]
maxi score, test score, baseline:  -0.9973489795918368 -1.0 -0.9973489795918368
probs:  [0.00746234045357197, 0.00746234045357197, 0.977612978639284, 0.00746234045357197]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.007462396774667876, 0.007462396774667876, 0.9776128096759964, 0.007462396774667876]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.007462396774667876, 0.007462396774667876, 0.9776128096759964, 0.007462396774667876]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.007462396774667876, 0.007462396774667876, 0.9776128096759964, 0.007462396774667876]
Printing some Q and Qe and total Qs values:  [[-0.009]
 [-0.009]
 [-0.009]
 [-0.009]
 [-0.009]
 [-0.009]
 [-0.009]] [[2.503]
 [2.503]
 [2.503]
 [2.503]
 [2.503]
 [2.503]
 [2.503]] [[2.484]
 [2.484]
 [2.484]
 [2.484]
 [2.484]
 [2.484]
 [2.484]]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
770 637
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.007462396774667876, 0.007462396774667876, 0.9776128096759964, 0.007462396774667876]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.007462396774667876, 0.007462396774667876, 0.9776128096759964, 0.007462396774667876]
Printing some Q and Qe and total Qs values:  [[0.452]
 [0.852]
 [0.452]
 [0.452]
 [0.452]
 [0.452]
 [0.518]] [[5.255]
 [1.656]
 [5.255]
 [5.255]
 [5.255]
 [5.255]
 [4.857]] [[0.452]
 [0.852]
 [0.452]
 [0.452]
 [0.452]
 [0.452]
 [0.518]]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.007462396774667876, 0.007462396774667876, 0.9776128096759964, 0.007462396774667876]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.258]
 [0.381]
 [0.381]
 [0.39 ]
 [0.384]
 [0.381]
 [0.489]] [[2.987]
 [2.373]
 [2.373]
 [2.423]
 [2.606]
 [2.373]
 [2.572]] [[1.349]
 [0.982]
 [0.982]
 [1.05 ]
 [1.221]
 [0.982]
 [1.397]]
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.007462396774667876, 0.007462396774667876, 0.9776128096759964, 0.007462396774667876]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9973554707379135 -1.0 -0.9973554707379135
probs:  [0.007462396774667876, 0.007462396774667876, 0.9776128096759964, 0.007462396774667876]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.007462452810044799, 0.007462452810044799, 0.9776126415698657, 0.007462452810044799]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.7200495469963648
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.007462452810044799, 0.007462452810044799, 0.9776126415698657, 0.007462452810044799]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.007462452810044799, 0.007462452810044799, 0.9776126415698657, 0.007462452810044799]
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.007462452810044799, 0.007462452810044799, 0.9776126415698657, 0.007462452810044799]
Printing some Q and Qe and total Qs values:  [[0.246]
 [0.246]
 [0.246]
 [0.246]
 [0.246]
 [0.246]
 [0.178]] [[4.689]
 [4.689]
 [4.689]
 [4.689]
 [4.689]
 [4.689]
 [6.383]] [[0.475]
 [0.475]
 [0.475]
 [0.475]
 [0.475]
 [0.475]
 [1.549]]
siam score:  -0.8058516
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.007462452810044799, 0.007462452810044799, 0.9776126415698657, 0.007462452810044799]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.007462452810044799, 0.007462452810044799, 0.9776126415698657, 0.007462452810044799]
using another actor
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973619289340102 -1.0 -0.9973619289340102
probs:  [0.007462452810044799, 0.007462452810044799, 0.9776126415698657, 0.007462452810044799]
maxi score, test score, baseline:  -0.9973683544303797 -1.0 -0.9973683544303797
maxi score, test score, baseline:  -0.9973683544303797 -1.0 -0.9973683544303797
maxi score, test score, baseline:  -0.9973683544303797 -1.0 -0.9973683544303797
probs:  [0.0074625085618714075, 0.0074625085618714075, 0.9776124743143856, 0.0074625085618714075]
line 256 mcts: sample exp_bonus 0.9791039190296191
maxi score, test score, baseline:  -0.9973683544303797 -1.0 -0.9973683544303797
probs:  [0.0074625085618714075, 0.0074625085618714075, 0.9776124743143856, 0.0074625085618714075]
maxi score, test score, baseline:  -0.9973683544303797 -1.0 -0.9973683544303797
probs:  [0.0074625085618714075, 0.0074625085618714075, 0.9776124743143856, 0.0074625085618714075]
maxi score, test score, baseline:  -0.9973683544303797 -1.0 -0.9973683544303797
probs:  [0.0074625085618714075, 0.0074625085618714075, 0.9776124743143856, 0.0074625085618714075]
from probs:  [0.0074625085618714075, 0.0074625085618714075, 0.9776124743143856, 0.0074625085618714075]
maxi score, test score, baseline:  -0.9973683544303797 -1.0 -0.9973683544303797
probs:  [0.0074625085618714075, 0.0074625085618714075, 0.9776124743143856, 0.0074625085618714075]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
probs:  [0.007462564032294536, 0.007462564032294536, 0.9776123079031164, 0.007462564032294536]
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
probs:  [0.007462564032294536, 0.007462564032294536, 0.9776123079031164, 0.007462564032294536]
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
probs:  [0.007462564032294536, 0.007462564032294536, 0.9776123079031164, 0.007462564032294536]
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
probs:  [0.007462564032294536, 0.007462564032294536, 0.9776123079031164, 0.007462564032294536]
using another actor
maxi score, test score, baseline:  -0.9973747474747475 -1.0 -0.9973747474747475
probs:  [0.007462564032294536, 0.007462564032294536, 0.9776123079031164, 0.007462564032294536]
Printing some Q and Qe and total Qs values:  [[0.5  ]
 [0.488]
 [0.607]
 [0.497]
 [0.471]
 [0.508]
 [0.528]] [[4.548]
 [4.578]
 [3.776]
 [3.777]
 [4.385]
 [4.59 ]
 [4.437]] [[1.677]
 [1.681]
 [1.324]
 [1.186]
 [1.537]
 [1.714]
 [1.643]]
maxi score, test score, baseline:  -0.9973811083123426 -1.0 -0.9973811083123426
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.689]
 [0.653]
 [0.624]
 [0.612]
 [0.588]
 [0.621]
 [0.599]] [[3.279]
 [3.602]
 [2.422]
 [2.141]
 [2.796]
 [3.632]
 [2.866]] [[1.313]
 [1.493]
 [0.6  ]
 [0.381]
 [0.818]
 [1.469]
 [0.885]]
maxi score, test score, baseline:  -0.9973811083123426 -1.0 -0.9973811083123426
probs:  [0.0074626192234393375, 0.0074626192234393375, 0.977612142329682, 0.0074626192234393375]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.3759151472826616
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973811083123426 -1.0 -0.9973811083123426
maxi score, test score, baseline:  -0.9973811083123426 -1.0 -0.9973811083123426
probs:  [0.0074626192234393375, 0.0074626192234393375, 0.977612142329682, 0.0074626192234393375]
Printing some Q and Qe and total Qs values:  [[0.843]
 [0.843]
 [0.854]
 [0.84 ]
 [0.845]
 [0.843]
 [0.825]] [[2.852]
 [2.852]
 [2.413]
 [2.176]
 [2.216]
 [2.236]
 [2.719]] [[1.489]
 [1.489]
 [1.071]
 [0.807]
 [0.857]
 [0.873]
 [1.32 ]]
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.64 ]
 [0.613]
 [0.613]
 [0.601]
 [0.613]
 [0.613]] [[1.661]
 [2.35 ]
 [1.661]
 [1.661]
 [1.752]
 [1.661]
 [1.661]] [[0.416]
 [1.16 ]
 [0.416]
 [0.416]
 [0.484]
 [0.416]
 [0.416]]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.3999],
        [-0.5725],
        [-0.3975],
        [-0.3209],
        [-0.4363],
        [-0.5353],
        [-0.5318],
        [-0.5327],
        [-0.5688],
        [-0.5622]], dtype=torch.float64)
-0.0727797758985 -0.47266619912371743
-0.024259925299500003 -0.5967341418598061
-0.0727797758985 -0.47029612355417333
-0.024259925299500003 -0.3452093998962456
-0.0727797758985 -0.5090468302404013
-0.024259925299500003 -0.5595751492214452
-0.0727797758985 -0.6045406689856164
-0.0727797758985 -0.6054568365151421
-0.024259925299500003 -0.5930518601087673
-0.024259925299500003 -0.5864705044521051
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
probs:  [0.0074626741374096625, 0.0074626741374096625, 0.9776119775877712, 0.0074626741374096625]
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
probs:  [0.0074626741374096625, 0.0074626741374096625, 0.9776119775877712, 0.0074626741374096625]
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
786 642
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
probs:  [0.0074626741374096625, 0.0074626741374096625, 0.9776119775877712, 0.0074626741374096625]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.493]
 [0.511]
 [0.504]
 [0.532]
 [0.523]
 [0.503]
 [0.607]] [[2.998]
 [2.995]
 [2.767]
 [2.476]
 [2.292]
 [2.157]
 [3.661]] [[1.565]
 [1.584]
 [1.449]
 [1.318]
 [1.207]
 [1.11 ]
 [2.06 ]]
Printing some Q and Qe and total Qs values:  [[0.383]
 [0.477]
 [0.477]
 [0.396]
 [0.382]
 [0.477]
 [0.477]] [[1.694]
 [3.843]
 [3.843]
 [1.151]
 [1.165]
 [3.843]
 [3.843]] [[0.995]
 [3.334]
 [3.334]
 [0.48 ]
 [0.463]
 [3.334]
 [3.334]]
Printing some Q and Qe and total Qs values:  [[0.506]
 [0.505]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.502]] [[3.454]
 [3.532]
 [3.454]
 [3.454]
 [3.454]
 [3.454]
 [3.825]] [[1.662]
 [1.7  ]
 [1.662]
 [1.662]
 [1.662]
 [1.662]
 [1.839]]
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
probs:  [0.0074626741374096625, 0.0074626741374096625, 0.9776119775877712, 0.0074626741374096625]
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
probs:  [0.0074626741374096625, 0.0074626741374096625, 0.9776119775877712, 0.0074626741374096625]
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
probs:  [0.0074626741374096625, 0.0074626741374096625, 0.9776119775877712, 0.0074626741374096625]
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
probs:  [0.0074626741374096625, 0.0074626741374096625, 0.9776119775877712, 0.0074626741374096625]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9973874371859297 -1.0 -0.9973874371859297
probs:  [0.0074626741374096625, 0.0074626741374096625, 0.9776119775877712, 0.0074626741374096625]
maxi score, test score, baseline:  -0.9973937343358396 -1.0 -0.9973937343358396
probs:  [0.007462728776288271, 0.007462728776288271, 0.9776118136711349, 0.007462728776288271]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9973937343358396 -1.0 -0.9973937343358396
probs:  [0.007462728776288271, 0.007462728776288271, 0.9776118136711349, 0.007462728776288271]
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.733]
 [0.563]
 [0.563]
 [0.563]
 [0.563]
 [0.57 ]] [[1.753]
 [1.963]
 [1.753]
 [1.753]
 [1.753]
 [1.753]
 [3.342]] [[1.232]
 [1.636]
 [1.232]
 [1.232]
 [1.232]
 [1.232]
 [2.407]]
Printing some Q and Qe and total Qs values:  [[0.225]
 [0.436]
 [0.232]
 [0.221]
 [0.217]
 [0.221]
 [0.216]] [[2.314]
 [2.331]
 [2.485]
 [2.234]
 [2.159]
 [2.104]
 [2.212]] [[ 0.131]
 [ 0.571]
 [ 0.316]
 [ 0.043]
 [-0.039]
 [-0.086]
 [ 0.013]]
maxi score, test score, baseline:  -0.9974000000000001 -1.0 -0.9974000000000001
probs:  [0.007462783142137112, 0.007462783142137112, 0.9776116505735888, 0.007462783142137112]
from probs:  [0.007462783142137112, 0.007462783142137112, 0.9776116505735888, 0.007462783142137112]
maxi score, test score, baseline:  -0.9974000000000001 -1.0 -0.9974000000000001
probs:  [0.007462783142137112, 0.007462783142137112, 0.9776116505735888, 0.007462783142137112]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
Printing some Q and Qe and total Qs values:  [[0.476]
 [0.369]
 [0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.37 ]] [[1.873]
 [1.913]
 [2.97 ]
 [2.97 ]
 [2.97 ]
 [2.97 ]
 [1.55 ]] [[0.327]
 [0.232]
 [0.876]
 [0.876]
 [0.876]
 [0.876]
 [0.037]]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007462837236997564, 0.007462837236997564, 0.9776114882890072, 0.007462837236997564]
Printing some Q and Qe and total Qs values:  [[0.037]
 [0.075]
 [0.243]
 [0.059]
 [0.04 ]
 [0.088]
 [0.068]] [[1.712]
 [1.794]
 [0.65 ]
 [1.099]
 [1.273]
 [0.932]
 [1.792]] [[0.037]
 [0.075]
 [0.243]
 [0.059]
 [0.04 ]
 [0.088]
 [0.068]]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007462837236997564, 0.007462837236997564, 0.9776114882890072, 0.007462837236997564]
siam score:  -0.79721206
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007462837236997564, 0.007462837236997564, 0.9776114882890072, 0.007462837236997564]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007462837236997564, 0.007462837236997564, 0.9776114882890072, 0.007462837236997564]
maxi score, test score, baseline:  -0.9974062344139651 -1.0 -0.9974062344139651
probs:  [0.007462837236997564, 0.007462837236997564, 0.9776114882890072, 0.007462837236997564]
Printing some Q and Qe and total Qs values:  [[0.195]
 [0.267]
 [0.268]
 [0.292]
 [0.213]
 [0.312]
 [0.241]] [[2.129]
 [2.027]
 [2.654]
 [2.124]
 [1.813]
 [2.01 ]
 [2.479]] [[0.195]
 [0.267]
 [0.268]
 [0.292]
 [0.213]
 [0.312]
 [0.241]]
using another actor
maxi score, test score, baseline:  -0.9974124378109452 -1.0 -0.9974124378109452
maxi score, test score, baseline:  -0.9974124378109452 -1.0 -0.9974124378109452
probs:  [0.007462891062890719, 0.007462891062890719, 0.9776113268113279, 0.007462891062890719]
Printing some Q and Qe and total Qs values:  [[0.59 ]
 [0.542]
 [0.594]
 [0.577]
 [0.577]
 [0.623]
 [0.559]] [[4.41 ]
 [4.893]
 [4.155]
 [5.244]
 [5.244]
 [4.283]
 [4.951]] [[1.195]
 [1.467]
 [1.023]
 [1.762]
 [1.762]
 [1.153]
 [1.532]]
maxi score, test score, baseline:  -0.9974124378109452 -1.0 -0.9974124378109452
maxi score, test score, baseline:  -0.9974124378109452 -1.0 -0.9974124378109452
probs:  [0.007462891062890719, 0.007462891062890719, 0.9776113268113279, 0.007462891062890719]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [0.611]] [[2.618]
 [2.618]
 [2.618]
 [2.618]
 [2.618]
 [2.618]
 [2.546]] [[2.589]
 [2.589]
 [2.589]
 [2.589]
 [2.589]
 [2.589]
 [2.513]]
maxi score, test score, baseline:  -0.9974186104218362 -1.0 -0.9974186104218362
maxi score, test score, baseline:  -0.9974247524752475 -1.0 -0.9974247524752475
806 651
siam score:  -0.79044974
line 256 mcts: sample exp_bonus 2.461523778783445
from probs:  [0.007462997915759509, 0.007462997915759509, 0.9776110062527216, 0.007462997915759509]
Printing some Q and Qe and total Qs values:  [[ 0.006]
 [ 1.599]
 [ 0.011]
 [ 0.012]
 [-0.006]
 [ 0.008]
 [ 0.016]] [[2.073]
 [0.   ]
 [1.607]
 [1.431]
 [1.72 ]
 [1.562]
 [2.381]] [[ 0.006]
 [ 1.599]
 [ 0.011]
 [ 0.012]
 [-0.006]
 [ 0.008]
 [ 0.016]]
maxi score, test score, baseline:  -0.9974247524752475 -1.0 -0.9974247524752475
probs:  [0.007462997915759509, 0.007462997915759509, 0.9776110062527216, 0.007462997915759509]
maxi score, test score, baseline:  -0.9974247524752475 -1.0 -0.9974247524752475
probs:  [0.007462997915759509, 0.007462997915759509, 0.9776110062527216, 0.007462997915759509]
maxi score, test score, baseline:  -0.9974247524752475 -1.0 -0.9974247524752475
maxi score, test score, baseline:  -0.9974247524752475 -1.0 -0.9974247524752475
probs:  [0.007462997915759509, 0.007462997915759509, 0.9776110062527216, 0.007462997915759509]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9974247524752475 -1.0 -0.9974247524752475
probs:  [0.007462997915759509, 0.007462997915759509, 0.9776110062527216, 0.007462997915759509]
Printing some Q and Qe and total Qs values:  [[0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]
 [0.429]] [[4.568]
 [4.568]
 [4.568]
 [4.568]
 [4.568]
 [4.568]
 [4.568]] [[5.427]
 [5.427]
 [5.427]
 [5.427]
 [5.427]
 [5.427]
 [5.427]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9974247524752475 -1.0 -0.9974247524752475
probs:  [0.007462997915759509, 0.007462997915759509, 0.9776110062527216, 0.007462997915759509]
Printing some Q and Qe and total Qs values:  [[-0.018]
 [-0.007]
 [-0.012]
 [-0.012]
 [-0.012]
 [-0.012]
 [ 0.004]] [[3.305]
 [3.783]
 [4.72 ]
 [4.72 ]
 [4.72 ]
 [4.72 ]
 [4.172]] [[0.237]
 [0.51 ]
 [1.016]
 [1.016]
 [1.016]
 [1.016]
 [0.735]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9974247524752475 -1.0 -0.9974247524752475
probs:  [0.007462997915759509, 0.007462997915759509, 0.9776110062527216, 0.007462997915759509]
Printing some Q and Qe and total Qs values:  [[0.274]
 [0.274]
 [0.274]
 [0.274]
 [0.274]
 [0.274]
 [0.274]] [[4.264]
 [4.264]
 [4.264]
 [4.264]
 [4.264]
 [4.264]
 [4.264]] [[1.203]
 [1.203]
 [1.203]
 [1.203]
 [1.203]
 [1.203]
 [1.203]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9974308641975309 -1.0 -0.9974308641975309
probs:  [0.00746305094667806, 0.00746305094667806, 0.9776108471599659, 0.00746305094667806]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.538]
 [0.735]
 [0.717]
 [0.672]
 [0.51 ]
 [0.72 ]
 [0.539]] [[2.593]
 [2.056]
 [1.89 ]
 [2.003]
 [1.393]
 [1.615]
 [2.643]] [[1.819]
 [1.677]
 [1.474]
 [1.497]
 [0.564]
 [1.205]
 [1.871]]
maxi score, test score, baseline:  -0.9974369458128078 -1.0 -0.9974369458128078
probs:  [0.007463103716515639, 0.007463103716515639, 0.977610688850453, 0.007463103716515639]
maxi score, test score, baseline:  -0.9974369458128078 -1.0 -0.9974369458128078
probs:  [0.007463103716515639, 0.007463103716515639, 0.977610688850453, 0.007463103716515639]
first move QE:  0.7581429276400181
maxi score, test score, baseline:  -0.9974369458128078 -1.0 -0.9974369458128078
using another actor
Printing some Q and Qe and total Qs values:  [[0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.431]] [[ 1.365]
 [ 1.365]
 [ 1.365]
 [ 1.365]
 [ 1.365]
 [ 1.365]
 [-0.263]] [[0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.235]
 [0.431]]
maxi score, test score, baseline:  -0.9974369458128078 -1.0 -0.9974369458128078
probs:  [0.007463103716515639, 0.007463103716515639, 0.977610688850453, 0.007463103716515639]
siam score:  -0.7955973
maxi score, test score, baseline:  -0.9974369458128078 -1.0 -0.9974369458128078
probs:  [0.007463103716515639, 0.007463103716515639, 0.977610688850453, 0.007463103716515639]
siam score:  -0.79729027
maxi score, test score, baseline:  -0.9974369458128078 -1.0 -0.9974369458128078
probs:  [0.007463103716515639, 0.007463103716515639, 0.977610688850453, 0.007463103716515639]
maxi score, test score, baseline:  -0.9974369458128078 -1.0 -0.9974369458128078
Printing some Q and Qe and total Qs values:  [[0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.666]] [[1.486]
 [1.486]
 [1.486]
 [1.486]
 [1.486]
 [1.486]
 [1.467]] [[0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.432]
 [0.666]]
from probs:  [0.007463312223240842, 0.007463312223240842, 0.9776100633302776, 0.007463312223240842]
maxi score, test score, baseline:  -0.9974669099756691 -1.0 -0.9974669099756691
probs:  [0.007463363716149491, 0.007463363716149491, 0.9776099088515517, 0.007463363716149491]
maxi score, test score, baseline:  -0.9974669099756691 -1.0 -0.9974669099756691
probs:  [0.007463363716149491, 0.007463363716149491, 0.9776099088515517, 0.007463363716149491]
maxi score, test score, baseline:  -0.9974669099756691 -1.0 -0.9974669099756691
probs:  [0.007463363716149491, 0.007463363716149491, 0.9776099088515517, 0.007463363716149491]
maxi score, test score, baseline:  -0.9974669099756691 -1.0 -0.9974669099756691
822 660
maxi score, test score, baseline:  -0.9974669099756691 -1.0 -0.9974669099756691
probs:  [0.007463363716149491, 0.007463363716149491, 0.9776099088515517, 0.007463363716149491]
siam score:  -0.78655463
maxi score, test score, baseline:  -0.9974669099756691 -1.0 -0.9974669099756691
probs:  [0.007463363716149491, 0.007463363716149491, 0.9776099088515517, 0.007463363716149491]
maxi score, test score, baseline:  -0.9974669099756691 -1.0 -0.9974669099756691
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9974728155339806 -1.0 -0.9974728155339806
rdn beta is 0 so we're just using the maxi policy
siam score:  -0.7809364
maxi score, test score, baseline:  -0.9974728155339806 -1.0 -0.9974728155339806
Printing some Q and Qe and total Qs values:  [[-0.033]
 [-0.033]
 [-0.033]
 [-0.033]
 [-0.033]
 [-0.033]
 [-0.033]] [[4.611]
 [4.611]
 [4.611]
 [4.611]
 [4.611]
 [4.611]
 [4.611]] [[0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]]
maxi score, test score, baseline:  -0.9974728155339806 -1.0 -0.9974728155339806
maxi score, test score, baseline:  -0.9974786924939467 -1.0 -0.9974786924939467
probs:  [0.0074634659543223745, 0.0074634659543223745, 0.9776096021370331, 0.0074634659543223745]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.204]
 [0.204]
 [0.279]
 [0.204]
 [0.293]
 [0.204]
 [0.197]] [[6.123]
 [6.123]
 [5.884]
 [6.123]
 [5.247]
 [6.123]
 [7.476]] [[1.268]
 [1.268]
 [1.231]
 [1.268]
 [0.979]
 [1.268]
 [1.823]]
maxi score, test score, baseline:  -0.9974786924939467 -1.0 -0.9974786924939467
probs:  [0.0074634659543223745, 0.0074634659543223745, 0.9776096021370331, 0.0074634659543223745]
maxi score, test score, baseline:  -0.9974786924939467 -1.0 -0.9974786924939467
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.102]
 [-0.109]
 [-0.1  ]
 [-0.1  ]
 [-0.1  ]
 [-0.108]
 [-0.119]] [[5.926]
 [5.24 ]
 [6.77 ]
 [6.77 ]
 [6.77 ]
 [5.207]
 [6.331]] [[ 0.173]
 [-0.165]
 [ 0.581]
 [ 0.581]
 [ 0.581]
 [-0.18 ]
 [ 0.351]]
maxi score, test score, baseline:  -0.9974786924939467 -1.0 -0.9974786924939467
using another actor
from probs:  [0.0074634659543223745, 0.0074634659543223745, 0.9776096021370331, 0.0074634659543223745]
Printing some Q and Qe and total Qs values:  [[0.358]
 [0.384]
 [0.359]
 [0.359]
 [0.361]
 [0.371]
 [0.368]] [[2.262]
 [2.491]
 [2.017]
 [1.871]
 [1.913]
 [2.138]
 [2.135]] [[0.358]
 [0.384]
 [0.359]
 [0.359]
 [0.361]
 [0.371]
 [0.368]]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.145]
 [0.139]
 [0.161]
 [0.176]
 [0.161]
 [0.168]
 [0.141]] [[2.805]
 [3.037]
 [2.839]
 [2.507]
 [2.839]
 [2.69 ]
 [2.72 ]] [[0.145]
 [0.139]
 [0.161]
 [0.176]
 [0.161]
 [0.168]
 [0.141]]
Printing some Q and Qe and total Qs values:  [[0.476]
 [0.505]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]] [[3.051]
 [3.123]
 [3.051]
 [3.051]
 [3.051]
 [3.051]
 [3.051]] [[0.476]
 [0.505]
 [0.476]
 [0.476]
 [0.476]
 [0.476]
 [0.476]]
maxi score, test score, baseline:  -0.9974786924939467 -1.0 -0.9974786924939467
probs:  [0.0074634659543223745, 0.0074634659543223745, 0.9776096021370331, 0.0074634659543223745]
maxi score, test score, baseline:  -0.9974786924939467 -1.0 -0.9974786924939467
probs:  [0.0074634659543223745, 0.0074634659543223745, 0.9776096021370331, 0.0074634659543223745]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9974786924939467 -1.0 -0.9974786924939467
probs:  [0.0074634659543223745, 0.0074634659543223745, 0.9776096021370331, 0.0074634659543223745]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]] [[1.133]
 [1.133]
 [1.133]
 [1.133]
 [1.133]
 [1.133]
 [1.133]] [[0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]
 [0.675]]
maxi score, test score, baseline:  -0.9974786924939467 -1.0 -0.9974786924939467
Printing some Q and Qe and total Qs values:  [[0.66 ]
 [0.69 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.763]] [[2.125]
 [3.127]
 [3.091]
 [3.091]
 [3.091]
 [3.091]
 [2.631]] [[0.66 ]
 [0.69 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.763]]
siam score:  -0.7902966
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]] [[2.811]
 [2.811]
 [2.811]
 [2.811]
 [2.811]
 [2.811]
 [2.811]] [[1.237]
 [1.237]
 [1.237]
 [1.237]
 [1.237]
 [1.237]
 [1.237]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.182]
 [0.185]
 [0.199]
 [0.179]
 [0.199]
 [0.183]
 [0.19 ]] [[2.569]
 [3.332]
 [2.25 ]
 [2.602]
 [2.25 ]
 [2.755]
 [2.738]] [[0.182]
 [0.185]
 [0.199]
 [0.179]
 [0.199]
 [0.183]
 [0.19 ]]
Printing some Q and Qe and total Qs values:  [[0.189]
 [0.189]
 [0.189]
 [0.189]
 [0.189]
 [0.189]
 [0.189]] [[2.863]
 [2.863]
 [2.863]
 [2.863]
 [2.863]
 [2.863]
 [2.863]] [[0.189]
 [0.189]
 [0.189]
 [0.189]
 [0.189]
 [0.189]
 [0.189]]
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9975635514018691 -1.0 -0.9975635514018691
probs:  [0.007464202301305637, 0.007464202301305637, 0.977607393096083, 0.007464202301305637]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.007464249561278191, 0.007464249561278191, 0.9776072513161653, 0.007464249561278191]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.007464249561278191, 0.007464249561278191, 0.9776072513161653, 0.007464249561278191]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.007464249561278191, 0.007464249561278191, 0.9776072513161653, 0.007464249561278191]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.007464249561278191, 0.007464249561278191, 0.9776072513161653, 0.007464249561278191]
first move QE:  0.7820142858917242
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.007464249561278191, 0.007464249561278191, 0.9776072513161653, 0.007464249561278191]
835 660
Printing some Q and Qe and total Qs values:  [[0.386]
 [0.372]
 [0.404]
 [0.396]
 [0.404]
 [0.396]
 [0.374]] [[2.835]
 [2.883]
 [2.76 ]
 [2.314]
 [2.222]
 [2.663]
 [2.634]] [[0.386]
 [0.372]
 [0.404]
 [0.396]
 [0.404]
 [0.396]
 [0.374]]
Printing some Q and Qe and total Qs values:  [[0.499]
 [0.393]
 [0.511]
 [0.497]
 [0.502]
 [0.493]
 [0.453]] [[3.489]
 [4.787]
 [3.518]
 [3.206]
 [3.285]
 [3.161]
 [3.434]] [[0.938]
 [1.583]
 [0.969]
 [0.768]
 [0.82 ]
 [0.737]
 [0.85 ]]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.007464249561278191, 0.007464249561278191, 0.9776072513161653, 0.007464249561278191]
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.007464249561278191, 0.007464249561278191, 0.9776072513161653, 0.007464249561278191]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9975689976689976 -1.0 -0.9975689976689976
probs:  [0.007464249561278191, 0.007464249561278191, 0.9776072513161653, 0.007464249561278191]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.378]
 [0.378]
 [0.378]
 [0.378]
 [0.378]
 [0.378]
 [0.379]] [[2.549]
 [2.549]
 [2.549]
 [2.549]
 [2.549]
 [2.549]
 [2.544]] [[0.378]
 [0.378]
 [0.378]
 [0.378]
 [0.378]
 [0.378]
 [0.379]]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.007464296601560132, 0.007464296601560132, 0.9776071101953194, 0.007464296601560132]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.89142155420084
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.007464296601560132, 0.007464296601560132, 0.9776071101953194, 0.007464296601560132]
Printing some Q and Qe and total Qs values:  [[0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.404]
 [0.394]
 [0.421]] [[2.896]
 [2.896]
 [2.896]
 [2.896]
 [2.911]
 [2.896]
 [2.206]] [[0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.404]
 [0.394]
 [0.421]]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.007464296601560132, 0.007464296601560132, 0.9776071101953194, 0.007464296601560132]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.007464296601560132, 0.007464296601560132, 0.9776071101953194, 0.007464296601560132]
Printing some Q and Qe and total Qs values:  [[0.256]
 [0.241]
 [0.256]
 [0.256]
 [0.256]
 [0.256]
 [0.227]] [[2.8  ]
 [3.23 ]
 [2.8  ]
 [2.8  ]
 [2.8  ]
 [2.8  ]
 [3.402]] [[0.256]
 [0.241]
 [0.256]
 [0.256]
 [0.256]
 [0.256]
 [0.227]]
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.007464296601560132, 0.007464296601560132, 0.9776071101953194, 0.007464296601560132]
Printing some Q and Qe and total Qs values:  [[0.5  ]
 [0.499]
 [0.525]
 [0.533]
 [0.517]
 [0.53 ]
 [0.489]] [[5.916]
 [6.287]
 [5.931]
 [5.923]
 [5.928]
 [6.031]
 [6.015]] [[1.098]
 [1.266]
 [1.122]
 [1.124]
 [1.115]
 [1.171]
 [1.136]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9975744186046511 -1.0 -0.9975744186046511
probs:  [0.007464296601560132, 0.007464296601560132, 0.9776071101953194, 0.007464296601560132]
maxi score, test score, baseline:  -0.9975798143851509 -1.0 -0.9975798143851509
probs:  [0.007464343423679776, 0.007464343423679776, 0.9776069697289608, 0.007464343423679776]
maxi score, test score, baseline:  -0.9975798143851509 -1.0 -0.9975798143851509
842 661
maxi score, test score, baseline:  -0.9975798143851509 -1.0 -0.9975798143851509
probs:  [0.007464343423679776, 0.007464343423679776, 0.9776069697289608, 0.007464343423679776]
line 256 mcts: sample exp_bonus 2.5366646639451944
maxi score, test score, baseline:  -0.9975798143851509 -1.0 -0.9975798143851509
maxi score, test score, baseline:  -0.9975798143851509 -1.0 -0.9975798143851509
probs:  [0.007464343423679776, 0.007464343423679776, 0.9776069697289608, 0.007464343423679776]
rdn probs:  [0.007464436419474851, 0.007464436419474851, 0.9776066907415756, 0.007464436419474851]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.00746452856060999, 0.00746452856060999, 0.9776064143181699, 0.00746452856060999]
siam score:  -0.7768509
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.00746452856060999, 0.00746452856060999, 0.9776064143181699, 0.00746452856060999]
Printing some Q and Qe and total Qs values:  [[0.37 ]
 [0.384]
 [0.367]
 [0.354]
 [0.355]
 [0.362]
 [0.36 ]] [[1.663]
 [3.176]
 [1.759]
 [1.799]
 [1.612]
 [1.898]
 [1.941]] [[0.37 ]
 [0.384]
 [0.367]
 [0.354]
 [0.355]
 [0.362]
 [0.36 ]]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.00746452856060999, 0.00746452856060999, 0.9776064143181699, 0.00746452856060999]
maxi score, test score, baseline:  -0.9976011494252873 -1.0 -0.9976011494252873
probs:  [0.01782891816591564, 0.01782891816591564, 0.957125578770904, 0.007216584897264785]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.017829034967779798, 0.017829034967779798, 0.9571253026026224, 0.007216627461818084]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
Printing some Q and Qe and total Qs values:  [[-0.01 ]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.001]
 [-0.017]
 [-0.014]] [[2.338]
 [2.48 ]
 [2.48 ]
 [2.48 ]
 [2.48 ]
 [2.457]
 [2.405]] [[0.086]
 [0.246]
 [0.246]
 [0.246]
 [0.246]
 [0.191]
 [0.145]]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.017829034967779798, 0.017829034967779798, 0.9571253026026224, 0.007216627461818084]
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.5803],
        [-0.5784],
        [-0.4193],
        [-0.4335],
        [-0.3548],
        [-0.5298],
        [-0.0000],
        [-0.4951],
        [-0.0000],
        [-0.0000]], dtype=torch.float64)
-0.024259925299500003 -0.6045779171109883
-0.024259925299500003 -0.6026178191260487
-0.0727797758985 -0.4920867516935965
-0.0439609252995 -0.47743776902817403
-0.0727797758985 -0.4275707954479848
-0.024259925299500003 -0.5540336915812037
-0.6286499999999998 -0.6286499999999998
-0.0727797758985 -0.5678578329038833
-0.7642609226999999 -0.7642609226999999
-0.97044651 -0.97044651
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.017829034967779798, 0.017829034967779798, 0.9571253026026224, 0.007216627461818084]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.017829034967779798, 0.017829034967779798, 0.9571253026026224, 0.007216627461818084]
from probs:  [0.017829034967779798, 0.017829034967779798, 0.9571253026026224, 0.007216627461818084]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.017829034967779798, 0.017829034967779798, 0.9571253026026224, 0.007216627461818084]
Printing some Q and Qe and total Qs values:  [[0.573]
 [0.559]
 [0.588]
 [0.52 ]
 [0.534]
 [0.578]
 [0.595]] [[2.237]
 [2.232]
 [2.177]
 [1.971]
 [1.998]
 [2.26 ]
 [2.079]] [[0.885]
 [0.854]
 [0.856]
 [0.532]
 [0.585]
 [0.917]
 [0.776]]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.017829034967779798, 0.017829034967779798, 0.9571253026026224, 0.007216627461818084]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.017829034967779798, 0.017829034967779798, 0.9571253026026224, 0.007216627461818084]
Printing some Q and Qe and total Qs values:  [[0.477]
 [0.669]
 [0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.486]] [[2.965]
 [3.621]
 [2.965]
 [2.965]
 [2.965]
 [2.965]
 [2.828]] [[0.574]
 [0.982]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.527]]
maxi score, test score, baseline:  -0.9976064220183486 -1.0 -0.9976064220183486
probs:  [0.017829034967779798, 0.017829034967779798, 0.9571253026026224, 0.007216627461818084]
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.017829151235317503, 0.017829151235317503, 0.9571250276977088, 0.007216669831656097]
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.017829151235317503, 0.017829151235317503, 0.9571250276977088, 0.007216669831656097]
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.017829151235317503, 0.017829151235317503, 0.9571250276977088, 0.007216669831656097]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.017829151235317503, 0.017829151235317503, 0.9571250276977088, 0.007216669831656097]
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.017829151235317503, 0.017829151235317503, 0.9571250276977088, 0.007216669831656097]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.017829151235317503, 0.017829151235317503, 0.9571250276977088, 0.007216669831656097]
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.017829151235317503, 0.017829151235317503, 0.9571250276977088, 0.007216669831656097]
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.017829151235317503, 0.017829151235317503, 0.9571250276977088, 0.007216669831656097]
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.017829151235317503, 0.017829151235317503, 0.9571250276977088, 0.007216669831656097]
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
Printing some Q and Qe and total Qs values:  [[-0.075]
 [-0.1  ]
 [-0.075]
 [-0.082]
 [-0.083]
 [-0.085]
 [-0.078]] [[5.287]
 [6.003]
 [6.152]
 [5.3  ]
 [5.906]
 [6.185]
 [6.726]] [[0.586]
 [0.92 ]
 [1.018]
 [0.585]
 [0.888]
 [1.025]
 [1.302]]
siam score:  -0.76211
maxi score, test score, baseline:  -0.9976116704805492 -1.0 -0.9976116704805492
probs:  [0.017829151235317503, 0.017829151235317503, 0.9571250276977088, 0.007216669831656097]
Printing some Q and Qe and total Qs values:  [[0.151]
 [0.26 ]
 [0.63 ]
 [0.542]
 [0.31 ]
 [0.623]
 [0.66 ]] [[2.075]
 [2.245]
 [1.606]
 [1.78 ]
 [1.511]
 [1.155]
 [1.651]] [[0.819]
 [1.208]
 [1.31 ]
 [1.306]
 [0.573]
 [0.843]
 [1.414]]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.017829266972186866, 0.017829266972186866, 0.9571247540475145, 0.007216712008111896]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.739]
 [0.769]
 [0.773]
 [0.758]
 [0.756]
 [0.778]
 [0.763]] [[0.778]
 [3.001]
 [0.764]
 [0.513]
 [0.703]
 [0.965]
 [1.587]] [[0.359]
 [1.406]
 [0.384]
 [0.255]
 [0.341]
 [0.481]
 [0.752]]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.018010556995374048, 0.007283707393180394, 0.9674220282182653, 0.007283707393180394]
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.699]
 [0.66 ]
 [0.655]
 [0.657]
 [0.694]
 [0.669]] [[1.063]
 [1.473]
 [2.237]
 [0.798]
 [1.075]
 [1.449]
 [1.952]] [[0.622]
 [1.117]
 [1.804]
 [0.353]
 [0.635]
 [1.082]
 [1.536]]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.018010556995374048, 0.007283707393180394, 0.9674220282182653, 0.007283707393180394]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.018010556995374048, 0.007283707393180394, 0.9674220282182653, 0.007283707393180394]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.018010556995374048, 0.007283707393180394, 0.9674220282182653, 0.007283707393180394]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.018010556995374048, 0.007283707393180394, 0.9674220282182653, 0.007283707393180394]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.027702695772405295, 0.007049649806547476, 0.947942211241043, 0.017305443180004286]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.027702695772405295, 0.007049649806547476, 0.947942211241043, 0.017305443180004286]
from probs:  [0.027702695772405295, 0.007049649806547476, 0.947942211241043, 0.017305443180004286]
Printing some Q and Qe and total Qs values:  [[0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]] [[0.339]
 [0.339]
 [0.339]
 [0.339]
 [0.339]
 [0.339]
 [0.339]] [[0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.365]]
maxi score, test score, baseline:  -0.997616894977169 -1.0 -0.997616894977169
probs:  [0.027702695772405295, 0.007049649806547476, 0.947942211241043, 0.017305443180004286]
maxi score, test score, baseline:  -0.9976220956719818 -1.0 -0.9976220956719818
probs:  [0.027702875388330085, 0.007049689809852624, 0.9479418822903233, 0.01730555251149397]
maxi score, test score, baseline:  -0.9976220956719818 -1.0 -0.9976220956719818
probs:  [0.027702875388330085, 0.007049689809852624, 0.9479418822903233, 0.01730555251149397]
maxi score, test score, baseline:  -0.9976220956719818 -1.0 -0.9976220956719818
maxi score, test score, baseline:  -0.9976220956719818 -1.0 -0.9976220956719818
probs:  [0.027702875388330085, 0.007049689809852624, 0.9479418822903233, 0.01730555251149397]
maxi score, test score, baseline:  -0.9976220956719818 -1.0 -0.9976220956719818
probs:  [0.027702875388330085, 0.007049689809852624, 0.9479418822903233, 0.01730555251149397]
first move QE:  0.8118546910268983
Printing some Q and Qe and total Qs values:  [[0.583]
 [0.532]
 [0.583]
 [0.608]
 [0.583]
 [0.583]
 [0.583]] [[2.617]
 [3.077]
 [2.617]
 [0.628]
 [2.617]
 [2.617]
 [2.617]] [[1.473]
 [1.715]
 [1.473]
 [0.168]
 [1.473]
 [1.473]
 [1.473]]
Printing some Q and Qe and total Qs values:  [[0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.969]] [[1.754]
 [1.754]
 [1.754]
 [1.754]
 [1.754]
 [1.754]
 [1.153]] [[1.286]
 [1.286]
 [1.286]
 [1.286]
 [1.286]
 [1.286]
 [1.836]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
probs:  [0.027980916506898344, 0.007112712988391339, 0.9577936575163191, 0.007112712988391339]
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
probs:  [0.027980916506898344, 0.007112712988391339, 0.9577936575163191, 0.007112712988391339]
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
probs:  [0.027980916506898344, 0.007112712988391339, 0.9577936575163191, 0.007112712988391339]
maxi score, test score, baseline:  -0.9976272727272727 -1.0 -0.9976272727272727
probs:  [0.027980916506898344, 0.007112712988391339, 0.9577936575163191, 0.007112712988391339]
maxi score, test score, baseline:  -0.9976324263038548 -1.0 -0.9976324263038548
probs:  [0.027981098228590753, 0.007112753468128145, 0.957793394835153, 0.007112753468128145]
maxi score, test score, baseline:  -0.9976324263038548 -1.0 -0.9976324263038548
probs:  [0.027981098228590753, 0.007112753468128145, 0.957793394835153, 0.007112753468128145]
867 677
maxi score, test score, baseline:  -0.9976324263038548 -1.0 -0.9976324263038548
probs:  [0.027981098228590753, 0.007112753468128145, 0.957793394835153, 0.007112753468128145]
maxi score, test score, baseline:  -0.9976324263038548 -1.0 -0.9976324263038548
probs:  [0.027981098228590753, 0.007112753468128145, 0.957793394835153, 0.007112753468128145]
Printing some Q and Qe and total Qs values:  [[0.4]
 [0.4]
 [0.4]
 [0.4]
 [0.4]
 [0.4]
 [0.4]] [[0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]
 [0.024]] [[0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]]
maxi score, test score, baseline:  -0.9976324263038548 -1.0 -0.9976324263038548
probs:  [0.027981098228590753, 0.007112753468128145, 0.957793394835153, 0.007112753468128145]
using explorer policy with actor:  0
siam score:  -0.7392624
maxi score, test score, baseline:  -0.997637556561086 -1.0 -0.997637556561086
probs:  [0.027981279128344166, 0.007112793764775188, 0.9577931333421054, 0.007112793764775188]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.419]
 [1.419]
 [1.419]
 [1.419]
 [1.419]
 [1.419]
 [1.419]] [[0.813]
 [0.803]
 [0.813]
 [0.813]
 [0.813]
 [0.813]
 [0.813]] [[2.696]
 [2.686]
 [2.696]
 [2.696]
 [2.696]
 [2.696]
 [2.696]]
Printing some Q and Qe and total Qs values:  [[-0.073]
 [-0.059]
 [-0.073]
 [-0.073]
 [-0.073]
 [-0.073]
 [-0.06 ]] [[2.589]
 [3.111]
 [2.589]
 [2.589]
 [2.589]
 [2.589]
 [3.125]] [[0.416]
 [0.805]
 [0.416]
 [0.416]
 [0.416]
 [0.416]
 [0.814]]
maxi score, test score, baseline:  -0.997637556561086 -1.0 -0.997637556561086
maxi score, test score, baseline:  -0.997637556561086 -1.0 -0.997637556561086
probs:  [0.017651243927804074, 0.0071779996783122475, 0.9679927567155714, 0.0071779996783122475]
maxi score, test score, baseline:  -0.997637556561086 -1.0 -0.997637556561086
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
probs:  [0.0176513559069638, 0.007178040662752199, 0.9679925627675319, 0.007178040662752199]
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
probs:  [0.0176513559069638, 0.007178040662752199, 0.9679925627675319, 0.007178040662752199]
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
maxi score, test score, baseline:  -0.9976426636568849 -1.0 -0.9976426636568849
probs:  [0.0176513559069638, 0.007178040662752199, 0.9679925627675319, 0.007178040662752199]
using another actor
Printing some Q and Qe and total Qs values:  [[0.515]
 [0.519]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]] [[1.972]
 [2.289]
 [1.972]
 [1.972]
 [1.972]
 [1.972]
 [1.972]] [[0.515]
 [0.519]
 [0.515]
 [0.515]
 [0.515]
 [0.515]
 [0.515]]
from probs:  [0.027132934552837388, 0.01697407684150725, 0.9489404876145139, 0.006952500991141319]
maxi score, test score, baseline:  -0.9976477477477478 -1.0 -0.9976477477477478
probs:  [0.027133104742432516, 0.01697418053633007, 0.948940175631468, 0.006952539089769325]
maxi score, test score, baseline:  -0.9976477477477478 -1.0 -0.9976477477477478
probs:  [0.027133104742432516, 0.01697418053633007, 0.948940175631468, 0.006952539089769325]
maxi score, test score, baseline:  -0.9976477477477478 -1.0 -0.9976477477477478
probs:  [0.027133104742432516, 0.01697418053633007, 0.948940175631468, 0.006952539089769325]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.3550811216415446
Printing some Q and Qe and total Qs values:  [[0.565]
 [0.557]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.764]] [[1.052]
 [1.33 ]
 [1.052]
 [1.052]
 [1.052]
 [1.052]
 [1.523]] [[0.565]
 [0.557]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.764]]
maxi score, test score, baseline:  -0.9976477477477478 -1.0 -0.9976477477477478
probs:  [0.027133104742432516, 0.01697418053633007, 0.948940175631468, 0.006952539089769325]
maxi score, test score, baseline:  -0.9976578475336323 -1.0 -0.9976578475336323
probs:  [0.027133442832858255, 0.01697438653145738, 0.948939555861014, 0.006952614774670352]
Printing some Q and Qe and total Qs values:  [[0.518]
 [0.573]
 [0.615]
 [0.596]
 [0.583]
 [0.618]
 [0.591]] [[ 0.377]
 [ 0.798]
 [-0.826]
 [-1.421]
 [-1.204]
 [-1.071]
 [-1.2  ]] [[1.463]
 [1.796]
 [0.943]
 [0.571]
 [0.673]
 [0.809]
 [0.688]]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.7708845155691016
Printing some Q and Qe and total Qs values:  [[0.512]
 [0.595]
 [0.592]
 [0.7  ]
 [0.627]
 [0.627]
 [0.63 ]] [[2.026]
 [3.471]
 [1.846]
 [1.349]
 [2.93 ]
 [2.93 ]
 [3.01 ]] [[0.515]
 [1.538]
 [0.503]
 [0.324]
 [1.236]
 [1.236]
 [1.29 ]]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
siam score:  -0.74852735
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
Printing some Q and Qe and total Qs values:  [[0.336]
 [0.29 ]
 [0.431]
 [0.431]
 [0.431]
 [0.431]
 [0.356]] [[4.26 ]
 [4.353]
 [3.713]
 [3.713]
 [3.713]
 [3.713]
 [4.484]] [[0.973]
 [0.974]
 [0.667]
 [0.667]
 [0.667]
 [0.667]
 [1.2  ]]
using explorer policy with actor:  1
from probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
line 256 mcts: sample exp_bonus 2.8113355606204866
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
Printing some Q and Qe and total Qs values:  [[0.649]
 [0.803]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.733]] [[3.748]
 [3.575]
 [3.748]
 [3.748]
 [3.748]
 [3.748]
 [3.528]] [[1.884]
 [2.007]
 [1.884]
 [1.884]
 [1.884]
 [1.884]
 [1.838]]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
Printing some Q and Qe and total Qs values:  [[0.717]
 [0.745]
 [0.755]
 [0.755]
 [0.755]
 [0.717]
 [0.755]] [[1.241]
 [3.088]
 [2.444]
 [2.444]
 [2.444]
 [1.166]
 [2.444]] [[0.334]
 [1.355]
 [1.02 ]
 [1.02 ]
 [1.02 ]
 [0.293]
 [1.02 ]]
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
Printing some Q and Qe and total Qs values:  [[0.725]
 [0.803]
 [0.725]
 [0.725]
 [0.725]
 [0.725]
 [0.725]] [[2.4  ]
 [3.042]
 [2.4  ]
 [2.4  ]
 [2.4  ]
 [2.4  ]
 [2.4  ]] [[1.064]
 [1.438]
 [1.064]
 [1.064]
 [1.064]
 [1.064]
 [1.064]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.440231709436832
using another actor
from probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
Printing some Q and Qe and total Qs values:  [[ 0.002]
 [ 0.015]
 [-0.002]
 [-0.002]
 [-0.002]
 [-0.002]
 [ 0.012]] [[3.578]
 [4.324]
 [4.448]
 [4.448]
 [4.448]
 [4.448]
 [4.347]] [[0.421]
 [0.95 ]
 [1.012]
 [1.012]
 [1.012]
 [1.012]
 [0.963]]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
from probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
Printing some Q and Qe and total Qs values:  [[0.405]
 [0.443]
 [0.405]
 [0.405]
 [0.405]
 [0.458]
 [0.405]] [[1.293]
 [1.922]
 [1.293]
 [1.293]
 [1.293]
 [1.553]
 [1.293]] [[0.405]
 [0.443]
 [0.405]
 [0.405]
 [0.405]
 [0.458]
 [0.405]]
siam score:  -0.7376918
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
maxi score, test score, baseline:  -0.9976628635346756 -1.0 -0.9976628635346756
probs:  [0.027399278359041122, 0.007013196778484643, 0.9585743280839897, 0.007013196778484643]
Printing some Q and Qe and total Qs values:  [[0.594]
 [0.763]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.759]] [[1.968]
 [1.555]
 [1.968]
 [1.968]
 [1.968]
 [1.968]
 [1.666]] [[0.594]
 [0.763]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.759]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.604]
 [0.679]
 [0.604]
 [0.604]
 [0.604]
 [0.604]
 [0.771]] [[3.172]
 [2.573]
 [3.172]
 [3.172]
 [3.172]
 [3.172]
 [2.421]] [[0.604]
 [0.679]
 [0.604]
 [0.604]
 [0.604]
 [0.604]
 [0.771]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.027399448945140445, 0.007013234972846523, 0.9585740811091664, 0.007013234972846523]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.027399448945140445, 0.007013234972846523, 0.9585740811091664, 0.007013234972846523]
maxi score, test score, baseline:  -0.9976678571428571 -1.0 -0.9976678571428571
probs:  [0.027399448945140445, 0.007013234972846523, 0.9585740811091664, 0.007013234972846523]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.535]
 [0.516]
 [0.57 ]
 [0.534]
 [0.532]
 [0.556]
 [0.669]] [[2.46 ]
 [3.672]
 [1.813]
 [2.253]
 [2.406]
 [2.592]
 [2.767]] [[0.535]
 [0.516]
 [0.57 ]
 [0.534]
 [0.532]
 [0.556]
 [0.669]]
Printing some Q and Qe and total Qs values:  [[-0.007]
 [-0.03 ]
 [-0.011]
 [-0.018]
 [-0.019]
 [-0.02 ]
 [ 0.13 ]] [[2.129]
 [2.591]
 [2.761]
 [2.364]
 [2.74 ]
 [3.127]
 [3.056]] [[-0.746]
 [-0.338]
 [-0.132]
 [-0.538]
 [-0.169]
 [ 0.211]
 [ 0.437]]
Printing some Q and Qe and total Qs values:  [[0.911]
 [0.911]
 [0.911]
 [0.911]
 [0.911]
 [0.911]
 [0.911]] [[0.818]
 [0.818]
 [0.818]
 [0.818]
 [0.818]
 [0.818]
 [0.807]] [[0.911]
 [0.911]
 [0.911]
 [0.911]
 [0.911]
 [0.911]
 [0.911]]
Printing some Q and Qe and total Qs values:  [[-0.042]
 [-0.042]
 [-0.042]
 [-0.042]
 [-0.042]
 [-0.042]
 [ 0.13 ]] [[2.571]
 [2.571]
 [2.571]
 [2.571]
 [2.571]
 [2.571]
 [6.28 ]] [[-0.009]
 [-0.009]
 [-0.009]
 [-0.009]
 [-0.009]
 [-0.009]
 [ 1.541]]
maxi score, test score, baseline:  -0.9976777777777778 -1.0 -0.9976777777777778
probs:  [0.027399787843693513, 0.00701331085250666, 0.9585735904512931, 0.00701331085250666]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9976777777777778 -1.0 -0.9976777777777778
probs:  [0.027399787843693513, 0.00701331085250666, 0.9585735904512931, 0.00701331085250666]
Printing some Q and Qe and total Qs values:  [[0.894]
 [0.814]
 [0.76 ]
 [0.76 ]
 [0.76 ]
 [0.76 ]
 [0.799]] [[2.359]
 [3.126]
 [3.124]
 [3.124]
 [3.124]
 [3.124]
 [3.175]] [[0.935]
 [1.177]
 [1.132]
 [1.132]
 [1.132]
 [1.132]
 [1.184]]
using explorer policy with actor:  0
from probs:  [0.027399787843693513, 0.00701331085250666, 0.9585735904512931, 0.00701331085250666]
maxi score, test score, baseline:  -0.9976827050997783 -1.0 -0.9976827050997783
probs:  [0.017305356648780752, 0.007075994797582821, 0.9685426537560536, 0.007075994797582821]
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
probs:  [0.017305460902107384, 0.007076033112888063, 0.9685424728721165, 0.007076033112888063]
siam score:  -0.73910594
line 256 mcts: sample exp_bonus 2.0374892592808447
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
probs:  [0.017305460902107384, 0.007076033112888063, 0.9685424728721165, 0.007076033112888063]
maxi score, test score, baseline:  -0.9976876106194691 -1.0 -0.9976876106194691
probs:  [0.017305460902107384, 0.007076033112888063, 0.9685424728721165, 0.007076033112888063]
Printing some Q and Qe and total Qs values:  [[0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.858]] [[4.093]
 [4.093]
 [4.093]
 [4.093]
 [4.093]
 [4.093]
 [2.914]] [[0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.858]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
Printing some Q and Qe and total Qs values:  [[0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [1.028]] [[0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.756]
 [0.853]] [[0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [1.908]]
line 256 mcts: sample exp_bonus 0.6064596030987448
siam score:  -0.7176184
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
line 256 mcts: sample exp_bonus 0.9421868523751072
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
Printing some Q and Qe and total Qs values:  [[0.299]
 [0.506]
 [0.681]
 [0.487]
 [0.487]
 [0.409]
 [0.888]] [[2.225]
 [2.052]
 [1.333]
 [2.899]
 [2.899]
 [1.467]
 [2.648]] [[1.134]
 [1.34 ]
 [1.025]
 [2.034]
 [2.034]
 [0.671]
 [2.506]]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
Printing some Q and Qe and total Qs values:  [[0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.728]] [[2.175]
 [2.175]
 [2.175]
 [2.175]
 [2.175]
 [2.175]
 [4.765]] [[1.106]
 [1.106]
 [1.106]
 [1.106]
 [1.106]
 [1.106]
 [2.041]]
maxi score, test score, baseline:  -0.9976924944812362 -1.0 -0.9976924944812362
probs:  [0.01730556469533728, 0.007076071259100025, 0.9685422927864626, 0.007076071259100025]
maxi score, test score, baseline:  -0.9976973568281938 -1.0 -0.9976973568281938
probs:  [0.017305668031509826, 0.00707610923733561, 0.9685421134938191, 0.00707610923733561]
siam score:  -0.70578325
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.026584177696501638, 0.006858672010780143, 0.9499023656609885, 0.0166547846317296]
905 702
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.026584177696501638, 0.006858672010780143, 0.9499023656609885, 0.0166547846317296]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.026584177696501638, 0.006858672010780143, 0.9499023656609885, 0.0166547846317296]
Printing some Q and Qe and total Qs values:  [[0.705]
 [0.738]
 [0.705]
 [0.705]
 [0.705]
 [0.705]
 [0.705]] [[0.907]
 [2.149]
 [0.907]
 [0.907]
 [0.907]
 [0.907]
 [0.907]] [[0.963]
 [1.456]
 [0.963]
 [0.963]
 [0.963]
 [0.963]
 [0.963]]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
Printing some Q and Qe and total Qs values:  [[0.531]
 [0.483]
 [0.531]
 [0.531]
 [0.531]
 [0.531]
 [0.483]] [[3.286]
 [3.106]
 [3.286]
 [3.286]
 [3.286]
 [3.286]
 [2.881]] [[1.558]
 [1.414]
 [1.558]
 [1.558]
 [1.558]
 [1.558]
 [1.298]]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.026584177696501638, 0.006858672010780143, 0.9499023656609885, 0.0166547846317296]
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.026584177696501638, 0.006858672010780143, 0.9499023656609885, 0.0166547846317296]
actor:  1 policy actor:  1  step number:  82 total reward:  0.13499999999999934  reward:  1.0 rdn_beta:  0.5
Printing some Q and Qe and total Qs values:  [[0.424]
 [0.594]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.679]
 [0.922]] [[ 1.391]
 [ 1.229]
 [ 1.642]
 [ 1.642]
 [ 1.642]
 [-0.33 ]
 [ 0.568]] [[1.891]
 [1.999]
 [2.147]
 [2.147]
 [2.147]
 [1.16 ]
 [1.996]]
first move QE:  0.8260542362582313
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
maxi score, test score, baseline:  -0.9977021978021978 -1.0 -0.9977021978021978
probs:  [0.0174080764097505, 0.004756280817020872, 0.9667962067125211, 0.011039436060707479]
from probs:  [0.017408147360576047, 0.004756296659948105, 0.9667960767080672, 0.011039479271408588]
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.017408147360576047, 0.004756296659948105, 0.9667960767080672, 0.011039479271408588]
first move QE:  0.8253008891274344
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.017408147360576047, 0.004756296659948105, 0.9667960767080672, 0.011039479271408588]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.017408147360576047, 0.004756296659948105, 0.9667960767080672, 0.011039479271408588]
line 256 mcts: sample exp_bonus 1.2672777746017516
Printing some Q and Qe and total Qs values:  [[0.228]
 [0.154]
 [0.311]
 [0.293]
 [0.248]
 [0.308]
 [0.313]] [[1.378]
 [1.754]
 [1.696]
 [1.004]
 [1.471]
 [1.765]
 [2.735]] [[-0.155]
 [ 0.057]
 [ 0.295]
 [-0.383]
 [-0.031]
 [ 0.355]
 [ 1.265]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.017408147360576047, 0.004756296659948105, 0.9667960767080672, 0.011039479271408588]
siam score:  -0.700226
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.636]] [[0.531]
 [0.531]
 [0.531]
 [0.531]
 [0.531]
 [0.531]
 [0.785]] [[1.339]
 [1.339]
 [1.339]
 [1.339]
 [1.339]
 [1.339]
 [1.533]]
maxi score, test score, baseline:  -0.9977070175438597 -1.0 -0.9977070175438597
probs:  [0.017408147360576047, 0.004756296659948105, 0.9667960767080672, 0.011039479271408588]
maxi score, test score, baseline:  -0.9977118161925602 -1.0 -0.9977118161925602
probs:  [0.017408218000742794, 0.004756312433508467, 0.9667959472728369, 0.011039522292911956]
maxi score, test score, baseline:  -0.9977118161925602 -1.0 -0.9977118161925602
probs:  [0.017408218000742794, 0.004756312433508467, 0.9667959472728369, 0.011039522292911956]
siam score:  -0.69543105
Printing some Q and Qe and total Qs values:  [[0.549]
 [0.478]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.519]] [[2.43 ]
 [3.198]
 [2.43 ]
 [2.43 ]
 [2.43 ]
 [2.43 ]
 [3.283]] [[0.965]
 [1.464]
 [0.965]
 [0.965]
 [0.965]
 [0.965]
 [1.597]]
using explorer policy with actor:  1
using another actor
maxi score, test score, baseline:  -0.9977118161925602 -1.0 -0.9977118161925602
probs:  [0.017408218000742794, 0.004756312433508467, 0.9667959472728369, 0.011039522292911956]
maxi score, test score, baseline:  -0.9977118161925602 -1.0 -0.9977118161925602
probs:  [0.017408218000742794, 0.004756312433508467, 0.9667959472728369, 0.011039522292911956]
maxi score, test score, baseline:  -0.9977118161925602 -1.0 -0.9977118161925602
probs:  [0.017408218000742794, 0.004756312433508467, 0.9667959472728369, 0.011039522292911956]
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.504]
 [0.539]
 [0.539]
 [0.539]
 [0.534]
 [0.613]] [[4.793]
 [4.815]
 [5.539]
 [5.539]
 [5.539]
 [4.298]
 [5.291]] [[0.945]
 [0.947]
 [1.455]
 [1.455]
 [1.455]
 [0.655]
 [1.391]]
using explorer policy with actor:  1
using explorer policy with actor:  1
in main func line 156:  926
Printing some Q and Qe and total Qs values:  [[0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]] [[0.67]
 [0.67]
 [0.67]
 [0.67]
 [0.67]
 [0.67]
 [0.67]] [[0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]]
maxi score, test score, baseline:  -0.9977165938864629 -1.0 -0.9977165938864629
probs:  [0.017408288332286827, 0.004756328138156533, 0.9667958184030989, 0.01103956512645771]
siam score:  -0.7024956
maxi score, test score, baseline:  -0.9977165938864629 -1.0 -0.9977165938864629
probs:  [0.017408288332286827, 0.004756328138156533, 0.9667958184030989, 0.01103956512645771]
maxi score, test score, baseline:  -0.9977165938864629 -1.0 -0.9977165938864629
Printing some Q and Qe and total Qs values:  [[0.55 ]
 [0.539]
 [0.539]
 [0.539]
 [0.539]
 [0.539]
 [0.539]] [[0.667]
 [1.024]
 [1.024]
 [1.024]
 [1.024]
 [1.024]
 [1.024]] [[-0.082]
 [ 0.253]
 [ 0.253]
 [ 0.253]
 [ 0.253]
 [ 0.253]
 [ 0.253]]
maxi score, test score, baseline:  -0.9977165938864629 -1.0 -0.9977165938864629
probs:  [0.017408288332286827, 0.004756328138156533, 0.9667958184030989, 0.01103956512645771]
maxi score, test score, baseline:  -0.9977165938864629 -1.0 -0.9977165938864629
probs:  [0.017408288332286827, 0.004756328138156533, 0.9667958184030989, 0.01103956512645771]
rdn beta is 0 so we're just using the maxi policy
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.4110],
        [-0.0000],
        [-0.4805],
        [-0.4935],
        [-0.4164],
        [-0.0000],
        [-0.4164],
        [-0.3362],
        [-0.4091],
        [-0.4741]], dtype=torch.float64)
-0.024259925299500003 -0.4352454095077969
-0.8464499999999999 -0.8464499999999999
-0.024259925299500003 -0.5047469696531643
-0.024259925299500003 -0.5177630104169739
-0.024259925299500003 -0.4406323047519738
-0.91285926435 -0.91285926435
-0.0727797758985 -0.4891323200939778
-0.0727797758985 -0.40894644653327344
-0.0727797758985 -0.48184502311433064
-0.034159925299499995 -0.5082980794482006
maxi score, test score, baseline:  -0.9977165938864629 -1.0 -0.9977165938864629
probs:  [0.017408288332286827, 0.004756328138156533, 0.9667958184030989, 0.01103956512645771]
maxi score, test score, baseline:  -0.9977165938864629 -1.0 -0.9977165938864629
probs:  [0.017408288332286827, 0.004756328138156533, 0.9667958184030989, 0.01103956512645771]
first move QE:  0.8278004606533991
maxi score, test score, baseline:  -0.9977213507625272 -1.0 -0.9977213507625272
probs:  [0.017408358357226105, 0.004756343774342923, 0.9667956900951561, 0.011039607773274836]
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
probs:  [0.017408428077561433, 0.0047563593425143345, 0.9667955623453425, 0.011039650234581758]
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.573]] [[1.15 ]
 [1.15 ]
 [1.15 ]
 [1.15 ]
 [1.15 ]
 [1.15 ]
 [1.275]] [[0.078]
 [0.078]
 [0.078]
 [0.078]
 [0.078]
 [0.078]
 [0.327]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
probs:  [0.017408428077561433, 0.0047563593425143345, 0.9667955623453425, 0.011039650234581758]
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
probs:  [0.017408428077561433, 0.0047563593425143345, 0.9667955623453425, 0.011039650234581758]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
probs:  [0.017408428077561433, 0.0047563593425143345, 0.9667955623453425, 0.011039650234581758]
first move QE:  0.8291906116667567
siam score:  -0.6947588
Printing some Q and Qe and total Qs values:  [[0.553]
 [0.605]
 [0.584]
 [0.566]
 [0.557]
 [0.551]
 [0.616]] [[0.366]
 [0.832]
 [0.451]
 [0.248]
 [0.262]
 [0.518]
 [1.318]] [[0.405]
 [0.916]
 [0.537]
 [0.324]
 [0.32 ]
 [0.539]
 [1.372]]
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
using another actor
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
probs:  [0.017408428077561433, 0.0047563593425143345, 0.9667955623453425, 0.011039650234581758]
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
probs:  [0.017408428077561433, 0.0047563593425143345, 0.9667955623453425, 0.011039650234581758]
maxi score, test score, baseline:  -0.9977260869565218 -1.0 -0.9977260869565218
probs:  [0.017408428077561433, 0.0047563593425143345, 0.9667955623453425, 0.011039650234581758]
siam score:  -0.6892624
maxi score, test score, baseline:  -0.9977308026030369 -1.0 -0.9977308026030369
probs:  [0.01740849749527576, 0.004756374843113584, 0.9667954351500248, 0.01103969251158606]
maxi score, test score, baseline:  -0.9977308026030369 -1.0 -0.9977308026030369
probs:  [0.01740849749527576, 0.004756374843113584, 0.9667954351500248, 0.01103969251158606]
maxi score, test score, baseline:  -0.9977308026030369 -1.0 -0.9977308026030369
probs:  [0.01740849749527576, 0.004756374843113584, 0.9667954351500248, 0.01103969251158606]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.017408566612335103, 0.004756390276579656, 0.9667953085056, 0.011039734605485248]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.017408566612335103, 0.004756390276579656, 0.9667953085056, 0.011039734605485248]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.017408566612335103, 0.004756390276579656, 0.9667953085056, 0.011039734605485248]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.017408566612335103, 0.004756390276579656, 0.9667953085056, 0.011039734605485248]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.017408566612335103, 0.004756390276579656, 0.9667953085056, 0.011039734605485248]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.017408566612335103, 0.004756390276579656, 0.9667953085056, 0.011039734605485248]
maxi score, test score, baseline:  -0.9977354978354979 -1.0 -0.9977354978354979
probs:  [0.017408566612335103, 0.004756390276579656, 0.9667953085056, 0.011039734605485248]
940 716
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.017408703952268886, 0.004756420943849261, 0.9667950568551756, 0.01103981824870632]
943 718
using explorer policy with actor:  1
using another actor
Printing some Q and Qe and total Qs values:  [[0.223]
 [0.223]
 [0.223]
 [0.223]
 [0.223]
 [0.223]
 [0.199]] [[1.091]
 [1.091]
 [1.091]
 [1.091]
 [1.091]
 [1.091]
 [1.491]] [[0.223]
 [0.223]
 [0.223]
 [0.223]
 [0.223]
 [0.223]
 [0.199]]
first move QE:  0.8342136264791311
Printing some Q and Qe and total Qs values:  [[0.729]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.968]] [[1.875]
 [1.671]
 [1.671]
 [1.671]
 [1.671]
 [1.671]
 [2.187]] [[1.816]
 [1.535]
 [1.535]
 [1.535]
 [1.535]
 [1.535]
 [2.495]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.017512901233440088, 0.0047802941800621, 0.9729265104064359, 0.0047802941800621]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.017512901233440088, 0.0047802941800621, 0.9729265104064359, 0.0047802941800621]
Printing some Q and Qe and total Qs values:  [[0.665]
 [0.891]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]] [[0.933]
 [1.282]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.933]] [[1.101]
 [1.865]
 [1.101]
 [1.101]
 [1.101]
 [1.101]
 [1.101]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.017512901233440088, 0.0047802941800621, 0.9729265104064359, 0.0047802941800621]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.017512901233440088, 0.0047802941800621, 0.9729265104064359, 0.0047802941800621]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.8234257288347036
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.017512901233440088, 0.0047802941800621, 0.9729265104064359, 0.0047802941800621]
Printing some Q and Qe and total Qs values:  [[0.455]
 [0.544]
 [0.455]
 [0.455]
 [0.455]
 [0.455]
 [0.459]] [[1.522]
 [1.977]
 [1.522]
 [1.522]
 [1.522]
 [1.522]
 [1.588]] [[1.059]
 [1.544]
 [1.059]
 [1.059]
 [1.059]
 [1.059]
 [1.116]]
maxi score, test score, baseline:  -0.9977448275862069 -1.0 -0.9977448275862069
probs:  [0.017512901233440088, 0.0047802941800621, 0.9729265104064359, 0.0047802941800621]
siam score:  -0.67739195
maxi score, test score, baseline:  -0.9977540772532189 -1.0 -0.9977540772532189
probs:  [0.017513039134840924, 0.004780324977811986, 0.9729263109095352, 0.004780324977811986]
Printing some Q and Qe and total Qs values:  [[0.766]
 [0.937]
 [0.807]
 [0.75 ]
 [0.754]
 [0.803]
 [1.169]] [[ 0.103]
 [ 0.336]
 [-0.072]
 [-0.238]
 [-0.131]
 [ 0.473]
 [ 1.152]] [[0.502]
 [0.823]
 [0.45 ]
 [0.294]
 [0.358]
 [0.751]
 [1.537]]
maxi score, test score, baseline:  -0.9977540772532189 -1.0 -0.9977540772532189
probs:  [0.017513039134840924, 0.004780324977811986, 0.9729263109095352, 0.004780324977811986]
siam score:  -0.68146425
Printing some Q and Qe and total Qs values:  [[0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]] [[3.442]
 [3.442]
 [3.442]
 [3.442]
 [3.442]
 [3.442]
 [3.442]] [[1.448]
 [1.448]
 [1.448]
 [1.448]
 [1.448]
 [1.448]
 [1.448]]
Printing some Q and Qe and total Qs values:  [[0.388]
 [0.393]
 [0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.49 ]] [[2.996]
 [2.082]
 [2.231]
 [2.231]
 [2.231]
 [2.231]
 [2.251]] [[1.46 ]
 [0.557]
 [0.922]
 [0.922]
 [0.922]
 [0.922]
 [0.919]]
maxi score, test score, baseline:  -0.9977540772532189 -1.0 -0.9977540772532189
probs:  [0.017513039134840924, 0.004780324977811986, 0.9729263109095352, 0.004780324977811986]
maxi score, test score, baseline:  -0.9977540772532189 -1.0 -0.9977540772532189
probs:  [0.017513039134840924, 0.004780324977811986, 0.9729263109095352, 0.004780324977811986]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
from probs:  [0.017513039134840924, 0.004780324977811986, 0.9729263109095352, 0.004780324977811986]
line 256 mcts: sample exp_bonus 2.2749208608806315
maxi score, test score, baseline:  -0.9977540772532189 -1.0 -0.9977540772532189
probs:  [0.017513039134840924, 0.004780324977811986, 0.9729263109095352, 0.004780324977811986]
from probs:  [0.017513107642396775, 0.004780340277720781, 0.9729262118021615, 0.004780340277720781]
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.017513107642396775, 0.004780340277720781, 0.9729262118021615, 0.004780340277720781]
Printing some Q and Qe and total Qs values:  [[1.13 ]
 [0.715]
 [0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.466]] [[1.669]
 [1.01 ]
 [1.611]
 [1.611]
 [1.611]
 [1.611]
 [1.646]] [[2.72 ]
 [1.83 ]
 [1.887]
 [1.887]
 [1.887]
 [1.887]
 [1.912]]
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.017513107642396775, 0.004780340277720781, 0.9729262118021615, 0.004780340277720781]
siam score:  -0.6807001
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.017513107642396775, 0.004780340277720781, 0.9729262118021615, 0.004780340277720781]
Printing some Q and Qe and total Qs values:  [[0.517]
 [0.531]
 [0.517]
 [0.517]
 [0.517]
 [0.515]
 [0.506]] [[-0.377]
 [ 0.136]
 [-0.377]
 [-0.377]
 [-0.377]
 [-1.004]
 [-0.814]] [[0.517]
 [0.531]
 [0.517]
 [0.517]
 [0.517]
 [0.515]
 [0.506]]
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.017513107642396775, 0.004780340277720781, 0.9729262118021615, 0.004780340277720781]
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.017513107642396775, 0.004780340277720781, 0.9729262118021615, 0.004780340277720781]
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.017513107642396775, 0.004780340277720781, 0.9729262118021615, 0.004780340277720781]
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.017513107642396775, 0.004780340277720781, 0.9729262118021615, 0.004780340277720781]
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
using explorer policy with actor:  1
using explorer policy with actor:  0
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9977586723768737 -1.0 -0.9977586723768737
probs:  [0.017513107642396775, 0.004780340277720781, 0.9729262118021615, 0.004780340277720781]
954 736
maxi score, test score, baseline:  -0.997767803837953 -1.0 -0.997767803837953
probs:  [0.017513243780672514, 0.004780370681717165, 0.972926014855893, 0.004780370681717165]
Printing some Q and Qe and total Qs values:  [[0.552]
 [0.498]
 [0.636]
 [0.697]
 [0.532]
 [0.575]
 [0.526]] [[1.131]
 [2.551]
 [0.847]
 [0.513]
 [0.697]
 [0.955]
 [2.089]] [[0.552]
 [0.498]
 [0.636]
 [0.697]
 [0.532]
 [0.575]
 [0.526]]
Printing some Q and Qe and total Qs values:  [[0.206]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.867]] [[1.712]
 [1.413]
 [1.413]
 [1.413]
 [1.413]
 [1.413]
 [1.189]] [[1.673]
 [1.939]
 [1.939]
 [1.939]
 [1.939]
 [1.939]
 [2.162]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.997772340425532 -1.0 -0.997772340425532
probs:  [0.01751331141512518, 0.004780385786638406, 0.9729259170115978, 0.004780385786638406]
Printing some Q and Qe and total Qs values:  [[0.405]
 [0.182]
 [0.405]
 [0.405]
 [0.405]
 [0.405]
 [0.585]] [[0.846]
 [1.344]
 [0.846]
 [0.846]
 [0.846]
 [0.846]
 [0.932]] [[1.226]
 [1.263]
 [1.226]
 [1.226]
 [1.226]
 [1.226]
 [1.535]]
start point for exploration sampling:  10768
siam score:  -0.6774662
maxi score, test score, baseline:  -0.997772340425532 -1.0 -0.997772340425532
probs:  [0.01751331141512518, 0.004780385786638406, 0.9729259170115978, 0.004780385786638406]
maxi score, test score, baseline:  -0.997772340425532 -1.0 -0.997772340425532
probs:  [0.01751331141512518, 0.004780385786638406, 0.9729259170115978, 0.004780385786638406]
maxi score, test score, baseline:  -0.9977768577494692 -1.0 -0.9977768577494692
probs:  [0.01751337876225032, 0.0047804008273915405, 0.9729258195829665, 0.0047804008273915405]
Printing some Q and Qe and total Qs values:  [[-0.029]
 [-0.004]
 [ 0.107]
 [ 0.107]
 [ 0.107]
 [ 0.107]
 [ 0.573]] [[1.429]
 [1.729]
 [1.667]
 [1.667]
 [1.667]
 [1.667]
 [1.987]] [[0.24 ]
 [0.484]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [1.467]]
maxi score, test score, baseline:  -0.9977768577494692 -1.0 -0.9977768577494692
probs:  [0.01751337876225032, 0.0047804008273915405, 0.9729258195829665, 0.0047804008273915405]
maxi score, test score, baseline:  -0.9977768577494692 -1.0 -0.9977768577494692
probs:  [0.01751337876225032, 0.0047804008273915405, 0.9729258195829665, 0.0047804008273915405]
maxi score, test score, baseline:  -0.9977768577494692 -1.0 -0.9977768577494692
siam score:  -0.67945486
maxi score, test score, baseline:  -0.9977768577494692 -1.0 -0.9977768577494692
probs:  [0.01751337876225032, 0.0047804008273915405, 0.9729258195829665, 0.0047804008273915405]
maxi score, test score, baseline:  -0.9977768577494692 -1.0 -0.9977768577494692
probs:  [0.01751337876225032, 0.0047804008273915405, 0.9729258195829665, 0.0047804008273915405]
Printing some Q and Qe and total Qs values:  [[-0.086]
 [-0.1  ]
 [-0.071]
 [-0.08 ]
 [-0.08 ]
 [-0.08 ]
 [-0.085]] [[2.276]
 [2.3  ]
 [3.188]
 [4.388]
 [4.388]
 [4.388]
 [3.491]] [[-0.15 ]
 [-0.152]
 [ 0.258]
 [ 0.769]
 [ 0.769]
 [ 0.769]
 [ 0.376]]
line 256 mcts: sample exp_bonus 0.8438026995425639
maxi score, test score, baseline:  -0.9977768577494692 -1.0 -0.9977768577494692
probs:  [0.01751337876225032, 0.0047804008273915405, 0.9729258195829665, 0.0047804008273915405]
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]] [[-0.64]
 [-0.64]
 [-0.64]
 [-0.64]
 [-0.64]
 [-0.64]
 [-0.64]] [[0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]]
maxi score, test score, baseline:  -0.9977768577494692 -1.0 -0.9977768577494692
probs:  [0.01751337876225032, 0.0047804008273915405, 0.9729258195829665, 0.0047804008273915405]
maxi score, test score, baseline:  -0.9977768577494692 -1.0 -0.9977768577494692
probs:  [0.01751337876225032, 0.0047804008273915405, 0.9729258195829665, 0.0047804008273915405]
maxi score, test score, baseline:  -0.9977858350951374 -1.0 -0.9977858350951374
probs:  [0.017513512601809535, 0.004780430718022156, 0.972925625962146, 0.004780430718022156]
maxi score, test score, baseline:  -0.9977858350951374 -1.0 -0.9977858350951374
probs:  [0.017513512601809535, 0.004780430718022156, 0.972925625962146, 0.004780430718022156]
maxi score, test score, baseline:  -0.9977858350951374 -1.0 -0.9977858350951374
maxi score, test score, baseline:  -0.9977858350951374 -1.0 -0.9977858350951374
maxi score, test score, baseline:  -0.9977858350951374 -1.0 -0.9977858350951374
probs:  [0.017513512601809535, 0.004780430718022156, 0.972925625962146, 0.004780430718022156]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9977858350951374 -1.0 -0.9977858350951374
probs:  [0.017513512601809535, 0.004780430718022156, 0.972925625962146, 0.004780430718022156]
Printing some Q and Qe and total Qs values:  [[0.165]
 [0.164]
 [0.186]
 [0.175]
 [0.189]
 [0.185]
 [0.178]] [[-0.022]
 [ 0.077]
 [-0.218]
 [-1.815]
 [-0.843]
 [-0.764]
 [-0.133]] [[0.165]
 [0.164]
 [0.186]
 [0.175]
 [0.189]
 [0.185]
 [0.178]]
maxi score, test score, baseline:  -0.9977947368421053 -1.0 -0.9977947368421053
maxi score, test score, baseline:  -0.9977947368421053 -1.0 -0.9977947368421053
maxi score, test score, baseline:  -0.9977947368421053 -1.0 -0.9977947368421053
probs:  [0.01751364531378249, 0.004780460356832026, 0.9729254339725535, 0.004780460356832026]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.24523309455842152
Printing some Q and Qe and total Qs values:  [[0.546]
 [0.559]
 [0.652]
 [0.652]
 [0.652]
 [0.928]
 [0.652]] [[-0.397]
 [ 0.314]
 [ 0.064]
 [ 0.064]
 [ 0.064]
 [ 2.361]
 [ 0.064]] [[0.047]
 [0.498]
 [0.459]
 [0.459]
 [0.459]
 [2.206]
 [0.459]]
maxi score, test score, baseline:  -0.9977947368421053 -1.0 -0.9977947368421053
probs:  [0.01751364531378249, 0.004780460356832026, 0.9729254339725535, 0.004780460356832026]
Printing some Q and Qe and total Qs values:  [[0.643]
 [0.652]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.803]] [[1.786]
 [1.941]
 [1.786]
 [1.786]
 [1.786]
 [1.786]
 [2.078]] [[1.906]
 [2.026]
 [1.906]
 [1.906]
 [1.906]
 [1.906]
 [2.331]]
UNIT TEST: sample policy line 217 mcts : [0.184 0.082 0.531 0.061 0.041 0.041 0.061]
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
maxi score, test score, baseline:  -0.9977991596638656 -1.0 -0.9977991596638656
probs:  [0.017513711251367515, 0.004780475082796558, 0.9729253385830393, 0.004780475082796558]
Printing some Q and Qe and total Qs values:  [[0.305]
 [0.372]
 [0.517]
 [0.473]
 [0.417]
 [0.49 ]
 [0.497]] [[ 1.421]
 [ 0.989]
 [-0.103]
 [-0.156]
 [ 0.289]
 [-0.105]
 [ 2.622]] [[1.145]
 [0.933]
 [0.364]
 [0.265]
 [0.501]
 [0.326]
 [2.27 ]]
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
probs:  [0.017513776912358763, 0.004780489746990091, 0.9729252435936612, 0.004780489746990091]
Printing some Q and Qe and total Qs values:  [[-0.071]
 [-0.058]
 [-0.069]
 [-0.069]
 [-0.069]
 [-0.062]
 [-0.058]] [[2.042]
 [2.503]
 [2.679]
 [2.679]
 [2.679]
 [2.389]
 [3.356]] [[-0.058]
 [ 0.263]
 [ 0.364]
 [ 0.364]
 [ 0.364]
 [ 0.182]
 [ 0.826]]
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
probs:  [0.017513776912358763, 0.004780489746990091, 0.9729252435936612, 0.004780489746990091]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
probs:  [0.017513776912358763, 0.004780489746990091, 0.9729252435936612, 0.004780489746990091]
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
probs:  [0.017513776912358763, 0.004780489746990091, 0.9729252435936612, 0.004780489746990091]
Printing some Q and Qe and total Qs values:  [[0.501]
 [0.507]
 [0.475]
 [0.456]
 [0.461]
 [0.473]
 [0.463]] [[ 0.069]
 [ 0.154]
 [-0.123]
 [-0.421]
 [-0.382]
 [-0.301]
 [-0.359]] [[ 0.472]
 [ 0.571]
 [ 0.229]
 [-0.107]
 [-0.058]
 [ 0.047]
 [-0.032]]
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
probs:  [0.035856929067087415, 0.008983188831710431, 0.9461766932694917, 0.008983188831710431]
maxi score, test score, baseline:  -0.9978035639412998 -1.0 -0.9978035639412998
probs:  [0.035856929067087415, 0.008983188831710431, 0.9461766932694917, 0.008983188831710431]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.03585712940231112, 0.008983233933484963, 0.946176402730719, 0.008983233933484963]
from probs:  [0.03585712940231112, 0.008983233933484963, 0.946176402730719, 0.008983233933484963]
from probs:  [0.03585712940231112, 0.008983233933484963, 0.946176402730719, 0.008983233933484963]
UNIT TEST: sample policy line 217 mcts : [0.102 0.143 0.49  0.061 0.061 0.061 0.082]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.03585712940231112, 0.008983233933484963, 0.946176402730719, 0.008983233933484963]
maxi score, test score, baseline:  -0.997807949790795 -1.0 -0.997807949790795
probs:  [0.03585712940231112, 0.008983233933484963, 0.946176402730719, 0.008983233933484963]
maxi score, test score, baseline:  -0.9978166666666667 -1.0 -0.9978166666666667
probs:  [0.03585752756957436, 0.008983323573496267, 0.9461758252834332, 0.008983323573496267]
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
maxi score, test score, baseline:  -0.997820997920998 -1.0 -0.997820997920998
probs:  [0.035857725412017795, 0.008983368114075236, 0.9461755383598317, 0.008983368114075236]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
981 765
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
siam score:  -0.68986773
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
Printing some Q and Qe and total Qs values:  [[0.44 ]
 [0.26 ]
 [0.44 ]
 [0.44 ]
 [0.44 ]
 [0.44 ]
 [0.719]] [[1.391]
 [1.762]
 [1.391]
 [1.391]
 [1.391]
 [1.391]
 [1.907]] [[1.044]
 [1.051]
 [1.044]
 [1.044]
 [1.044]
 [1.044]
 [1.721]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
Printing some Q and Qe and total Qs values:  [[0.112]
 [0.112]
 [0.112]
 [0.112]
 [0.112]
 [0.112]
 [0.143]] [[4.032]
 [4.032]
 [4.032]
 [4.032]
 [4.032]
 [4.032]
 [4.576]] [[0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.394]
 [0.833]]
maxi score, test score, baseline:  -0.9978253112033195 -1.0 -0.9978253112033195
probs:  [0.0358579224338668, 0.008983412469915037, 0.9461752526263031, 0.008983412469915037]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.8965576131661015
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.03585831403611842, 0.008983500631955592, 0.9461746846999703, 0.008983500631955592]
Printing some Q and Qe and total Qs values:  [[0.234]
 [0.234]
 [0.234]
 [0.234]
 [0.234]
 [0.234]
 [0.234]] [[3.01]
 [3.01]
 [3.01]
 [3.01]
 [3.01]
 [3.01]
 [3.01]] [[0.58]
 [0.58]
 [0.58]
 [0.58]
 [0.58]
 [0.58]
 [0.58]]
Printing some Q and Qe and total Qs values:  [[1.017]
 [1.017]
 [1.017]
 [1.017]
 [1.017]
 [1.017]
 [1.396]] [[0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.845]
 [0.813]] [[2.177]
 [2.177]
 [2.177]
 [2.177]
 [2.177]
 [2.177]
 [2.889]]
maxi score, test score, baseline:  -0.9978338842975206 -1.0 -0.9978338842975206
probs:  [0.03585831403611842, 0.008983500631955592, 0.9461746846999703, 0.008983500631955592]
Printing some Q and Qe and total Qs values:  [[0.523]
 [0.508]
 [0.523]
 [0.523]
 [0.523]
 [0.523]
 [0.523]] [[1.34 ]
 [1.477]
 [1.34 ]
 [1.34 ]
 [1.34 ]
 [1.34 ]
 [1.34 ]] [[0.523]
 [0.508]
 [0.523]
 [0.523]
 [0.523]
 [0.523]
 [0.523]]
Printing some Q and Qe and total Qs values:  [[0.615]
 [0.554]
 [0.626]
 [0.615]
 [0.624]
 [0.601]
 [0.606]] [[1.255]
 [1.978]
 [1.067]
 [0.61 ]
 [0.889]
 [1.125]
 [2.038]] [[0.543]
 [0.99 ]
 [0.418]
 [0.062]
 [0.283]
 [0.425]
 [1.111]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.2978874154111177
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.03585850862658476, 0.008983544440421938, 0.9461744024925713, 0.008983544440421938]
Printing some Q and Qe and total Qs values:  [[0.124]
 [0.077]
 [0.092]
 [0.118]
 [0.078]
 [0.118]
 [0.096]] [[1.283]
 [2.025]
 [1.757]
 [1.533]
 [1.806]
 [1.533]
 [1.58 ]] [[-0.408]
 [ 0.051]
 [-0.118]
 [-0.24 ]
 [-0.103]
 [-0.24 ]
 [-0.237]]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.03585850862658476, 0.008983544440421938, 0.9461744024925713, 0.008983544440421938]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
Printing some Q and Qe and total Qs values:  [[0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]
 [0.284]] [[2.252]
 [2.252]
 [2.252]
 [2.252]
 [2.252]
 [2.252]
 [2.252]] [[-0.081]
 [-0.081]
 [-0.081]
 [-0.081]
 [-0.081]
 [-0.081]
 [-0.081]]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.022623992324041536, 0.009093527999148391, 0.9591889516776616, 0.009093527999148391]
line 256 mcts: sample exp_bonus 0.5363257420184976
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.022623992324041536, 0.009093527999148391, 0.9591889516776616, 0.009093527999148391]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.022623992324041536, 0.009093527999148391, 0.9591889516776616, 0.009093527999148391]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.009205044251772604, 0.009205044251772604, 0.9723848672446821, 0.009205044251772604]
Starting evaluation
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
probs:  [0.009205044251772604, 0.009205044251772604, 0.9723848672446821, 0.009205044251772604]
Printing some Q and Qe and total Qs values:  [[0.308]
 [0.394]
 [0.308]
 [0.308]
 [0.308]
 [0.308]
 [0.437]] [[0.69 ]
 [0.775]
 [0.69 ]
 [0.69 ]
 [0.69 ]
 [0.69 ]
 [0.608]] [[0.308]
 [0.394]
 [0.308]
 [0.308]
 [0.308]
 [0.308]
 [0.437]]
Printing some Q and Qe and total Qs values:  [[0.096]
 [0.123]
 [0.14 ]
 [0.165]
 [0.14 ]
 [0.142]
 [0.105]] [[ 0.752]
 [ 1.094]
 [ 0.157]
 [ 0.601]
 [-0.211]
 [-0.53 ]
 [ 0.823]] [[0.096]
 [0.123]
 [0.14 ]
 [0.165]
 [0.14 ]
 [0.142]
 [0.105]]
maxi score, test score, baseline:  -0.9978381443298969 -1.0 -0.9978381443298969
maxi score, test score, baseline:  -0.9978423868312757 -1.0 -0.9978423868312757
probs:  [0.009205090361813429, 0.009205090361813429, 0.9723847289145598, 0.009205090361813429]
Printing some Q and Qe and total Qs values:  [[0.49]
 [0.48]
 [0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]] [[1.354]
 [1.4  ]
 [1.354]
 [1.354]
 [1.354]
 [1.354]
 [1.354]] [[0.49]
 [0.48]
 [0.49]
 [0.49]
 [0.49]
 [0.49]
 [0.49]]
line 256 mcts: sample exp_bonus 1.4966222894949426
Printing some Q and Qe and total Qs values:  [[0.17 ]
 [0.17 ]
 [0.17 ]
 [0.17 ]
 [0.17 ]
 [0.17 ]
 [0.151]] [[0.041]
 [0.041]
 [0.041]
 [0.041]
 [0.041]
 [0.041]
 [0.799]] [[0.17 ]
 [0.17 ]
 [0.17 ]
 [0.17 ]
 [0.17 ]
 [0.17 ]
 [0.151]]
Printing some Q and Qe and total Qs values:  [[0.375]
 [0.153]
 [0.181]
 [0.181]
 [0.181]
 [0.186]
 [0.148]] [[ 1.06 ]
 [ 1.013]
 [ 0.672]
 [ 0.672]
 [ 0.672]
 [-0.108]
 [ 0.815]] [[0.375]
 [0.153]
 [0.181]
 [0.181]
 [0.181]
 [0.186]
 [0.148]]
maxi score, test score, baseline:  -0.9978423868312757 -1.0 -0.9978423868312757
probs:  [0.009205090361813429, 0.009205090361813429, 0.9723847289145598, 0.009205090361813429]
maxi score, test score, baseline:  -0.997846611909651 -1.0 -0.997846611909651
probs:  [0.009205136282582328, 0.009205136282582328, 0.9723845911522532, 0.009205136282582328]
using explorer policy with actor:  0
using explorer policy with actor:  0
start point for exploration sampling:  10768
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.342]
 [0.411]
 [0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]] [[0.96 ]
 [1.035]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]
 [0.96 ]] [[0.342]
 [0.411]
 [0.342]
 [0.342]
 [0.342]
 [0.342]
 [0.342]]
siam score:  -0.6862987
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.009205318096056634, 0.009205318096056634, 0.97238404571183, 0.009205318096056634]
using explorer policy with actor:  0
first move QE:  0.8337918339543333
siam score:  -0.6862692
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.009205318096056634, 0.009205318096056634, 0.97238404571183, 0.009205318096056634]
Printing some Q and Qe and total Qs values:  [[0.584]
 [0.519]
 [0.716]
 [0.63 ]
 [0.599]
 [0.616]
 [0.547]] [[3.35 ]
 [4.092]
 [2.651]
 [2.936]
 [3.059]
 [3.329]
 [3.501]] [[0.584]
 [0.519]
 [0.716]
 [0.63 ]
 [0.599]
 [0.616]
 [0.547]]
maxi score, test score, baseline:  -0.9978633401221996 -1.0 -0.9978633401221996
probs:  [0.009205318096056634, 0.009205318096056634, 0.97238404571183, 0.009205318096056634]
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.47 ]
 [0.425]
 [0.475]
 [0.444]
 [0.446]
 [0.464]
 [0.449]] [[1.174]
 [2.332]
 [0.823]
 [0.486]
 [0.574]
 [1.128]
 [0.76 ]] [[0.47 ]
 [0.425]
 [0.475]
 [0.444]
 [0.446]
 [0.464]
 [0.449]]
using explorer policy with actor:  0
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus -0.08906332065798525
using explorer policy with actor:  0
siam score:  -0.6822872
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.3215932756730266
maxi score, test score, baseline:  -0.9978838709677419 -1.0 -0.9978838709677419
probs:  [0.009205541241066794, 0.009205541241066794, 0.9723833762767995, 0.009205541241066794]
maxi score, test score, baseline:  -0.9978838709677419 -1.0 -0.9978838709677419
maxi score, test score, baseline:  -0.9978838709677419 -1.0 -0.9978838709677419
probs:  [0.009205541241066794, 0.009205541241066794, 0.9723833762767995, 0.009205541241066794]
Printing some Q and Qe and total Qs values:  [[-0.01 ]
 [-0.005]
 [-0.01 ]
 [-0.01 ]
 [-0.01 ]
 [-0.01 ]
 [-0.036]] [[6.101]
 [5.795]
 [6.101]
 [6.101]
 [6.101]
 [6.101]
 [7.606]] [[0.927]
 [0.83 ]
 [0.927]
 [0.927]
 [0.927]
 [0.927]
 [1.403]]
maxi score, test score, baseline:  -0.9978879275653924 -1.0 -0.9978879275653924
probs:  [0.00920558533154378, 0.00920558533154378, 0.9723832440053688, 0.00920558533154378]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]] [[0.836]
 [0.835]
 [0.836]
 [0.836]
 [0.836]
 [0.836]
 [0.825]] [[0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]]
maxi score, test score, baseline:  -0.9978919678714859 -1.0 -0.9978919678714859
probs:  [0.009205629245034435, 0.009205629245034435, 0.9723831122648968, 0.009205629245034435]
Printing some Q and Qe and total Qs values:  [[0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.502]] [[1.766]
 [1.766]
 [1.766]
 [1.766]
 [1.766]
 [1.766]
 [1.451]] [[0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.483]
 [0.502]]
maxi score, test score, baseline:  -0.997895991983968 -1.0 -0.997895991983968
probs:  [0.009205672982602307, 0.009205672982602307, 0.9723829810521932, 0.009205672982602307]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.009205716545302422, 0.009205716545302422, 0.9723828503640927, 0.009205716545302422]
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.009205716545302422, 0.009205716545302422, 0.9723828503640927, 0.009205716545302422]
first move QE:  0.8359434592248973
line 256 mcts: sample exp_bonus 2.292858767698261
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.009205716545302422, 0.009205716545302422, 0.9723828503640927, 0.009205716545302422]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.009205716545302422, 0.009205716545302422, 0.9723828503640927, 0.009205716545302422]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 1.4336970101373387
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.009205716545302422, 0.009205716545302422, 0.9723828503640927, 0.009205716545302422]
Printing some Q and Qe and total Qs values:  [[-0.024]
 [-0.008]
 [ 0.052]
 [-0.023]
 [-0.02 ]
 [ 0.029]
 [-0.009]] [[2.369]
 [2.468]
 [1.862]
 [2.454]
 [2.433]
 [2.299]
 [3.428]] [[-0.229]
 [-0.161]
 [-0.412]
 [-0.184]
 [-0.192]
 [-0.21 ]
 [ 0.333]]
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
Printing some Q and Qe and total Qs values:  [[0.203]
 [0.2  ]
 [0.203]
 [0.203]
 [0.203]
 [0.203]
 [0.241]] [[4.006]
 [4.259]
 [4.006]
 [4.006]
 [4.006]
 [4.006]
 [3.986]] [[0.661]
 [0.852]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.704]]
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.009205716545302422, 0.009205716545302422, 0.9723828503640927, 0.009205716545302422]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.796]
 [0.728]
 [0.678]
 [0.678]
 [0.678]
 [0.825]
 [0.759]] [[2.703]
 [3.965]
 [2.998]
 [2.998]
 [2.998]
 [3.496]
 [4.776]] [[0.796]
 [0.728]
 [0.678]
 [0.678]
 [0.678]
 [0.825]
 [0.759]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9979 -1.0 -0.9979
probs:  [0.009205716545302422, 0.009205716545302422, 0.9723828503640927, 0.009205716545302422]
Printing some Q and Qe and total Qs values:  [[-0.016]
 [-0.032]
 [-0.007]
 [-0.022]
 [-0.022]
 [-0.023]
 [-0.028]] [[3.161]
 [3.962]
 [2.977]
 [3.305]
 [3.183]
 [3.235]
 [3.731]] [[-0.259]
 [ 0.356]
 [-0.392]
 [-0.153]
 [-0.251]
 [-0.211]
 [ 0.177]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.009227464609112607, 0.009227464609112607, 0.972317606172662, 0.009227464609112607]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.009227464609112607, 0.009227464609112607, 0.972317606172662, 0.009227464609112607]
line 256 mcts: sample exp_bonus 0.0886630716707193
using another actor
using another actor
from probs:  [0.009227464609112607, 0.009227464609112607, 0.972317606172662, 0.009227464609112607]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.02189531055016925, 0.008853886711613608, 0.9473554921880478, 0.02189531055016925]
line 256 mcts: sample exp_bonus 1.4760411865742065
using explorer policy with actor:  0
actor:  1 policy actor:  1  step number:  49 total reward:  0.5999999999999998  reward:  1.0 rdn_beta:  0.5
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.009360960114245545, 0.004141129281371262, 0.9771369504901375, 0.009360960114245545]
Printing some Q and Qe and total Qs values:  [[0.306]
 [0.339]
 [0.349]
 [0.297]
 [0.329]
 [0.324]
 [0.315]] [[-0.016]
 [ 0.292]
 [ 0.261]
 [-0.178]
 [-0.011]
 [-0.076]
 [-0.097]] [[0.306]
 [0.339]
 [0.349]
 [0.297]
 [0.329]
 [0.324]
 [0.315]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.714]
 [0.799]] [[2.437]
 [2.437]
 [2.437]
 [2.437]
 [2.437]
 [2.066]
 [2.539]] [[0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.714]
 [0.799]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.009360960114245545, 0.004141129281371262, 0.9771369504901375, 0.009360960114245545]
Printing some Q and Qe and total Qs values:  [[0.4  ]
 [0.464]
 [0.4  ]
 [0.4  ]
 [0.4  ]
 [0.4  ]
 [0.4  ]] [[0.949]
 [1.132]
 [0.949]
 [0.949]
 [0.949]
 [0.949]
 [0.949]] [[0.4  ]
 [0.464]
 [0.4  ]
 [0.4  ]
 [0.4  ]
 [0.4  ]
 [0.4  ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.009360960114245545, 0.004141129281371262, 0.9771369504901375, 0.009360960114245545]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.009360960114245545, 0.004141129281371262, 0.9771369504901375, 0.009360960114245545]
rdn probs:  [0.009360960114245545, 0.004141129281371262, 0.9771369504901375, 0.009360960114245545]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.009360960114245545, 0.004141129281371262, 0.9771369504901375, 0.009360960114245545]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.009360960114245545, 0.004141129281371262, 0.9771369504901375, 0.009360960114245545]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.009360960114245545, 0.004141129281371262, 0.9771369504901375, 0.009360960114245545]
using another actor
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.628]
 [0.634]
 [0.628]
 [0.628]
 [0.628]
 [0.628]
 [0.628]] [[1.562]
 [2.02 ]
 [1.562]
 [1.562]
 [1.562]
 [1.562]
 [1.562]] [[1.028]
 [1.498]
 [1.028]
 [1.028]
 [1.028]
 [1.028]
 [1.028]]
using explorer policy with actor:  1
first move QE:  0.8348452788888318
Printing some Q and Qe and total Qs values:  [[0.646]
 [0.725]
 [0.646]
 [0.646]
 [0.646]
 [0.646]
 [0.646]] [[0.72 ]
 [1.104]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]] [[0.714]
 [1.256]
 [0.714]
 [0.714]
 [0.714]
 [0.714]
 [0.714]]
Printing some Q and Qe and total Qs values:  [[0.501]
 [0.548]
 [0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.492]] [[1.818]
 [2.367]
 [1.818]
 [1.818]
 [1.818]
 [1.818]
 [1.639]] [[0.819]
 [1.097]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.734]]
Printing some Q and Qe and total Qs values:  [[0.412]
 [0.435]
 [0.412]
 [0.412]
 [0.412]
 [0.412]
 [0.412]] [[2.499]
 [3.175]
 [2.499]
 [2.499]
 [2.499]
 [2.499]
 [2.499]] [[0.609]
 [1.096]
 [0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.609]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
Printing some Q and Qe and total Qs values:  [[0.59 ]
 [0.559]
 [0.615]
 [0.599]
 [0.68 ]
 [0.6  ]
 [0.797]] [[1.358]
 [3.465]
 [1.415]
 [1.159]
 [1.427]
 [1.037]
 [1.111]] [[0.59 ]
 [0.559]
 [0.615]
 [0.599]
 [0.68 ]
 [0.6  ]
 [0.797]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
Printing some Q and Qe and total Qs values:  [[0.254]
 [0.585]
 [0.592]
 [0.592]
 [0.592]
 [0.592]
 [0.596]] [[2.169]
 [2.169]
 [2.12 ]
 [2.12 ]
 [2.12 ]
 [2.12 ]
 [2.056]] [[1.59 ]
 [2.221]
 [2.189]
 [2.189]
 [2.189]
 [2.189]
 [2.135]]
siam score:  -0.6665153
line 256 mcts: sample exp_bonus 2.862329283652148
Printing some Q and Qe and total Qs values:  [[0.81 ]
 [1.111]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.81 ]
 [0.968]] [[0.969]
 [1.023]
 [0.969]
 [0.969]
 [0.969]
 [0.969]
 [0.96 ]] [[0.713]
 [1.052]
 [0.713]
 [0.713]
 [0.713]
 [0.713]
 [0.872]]
siam score:  -0.6648803
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
Printing some Q and Qe and total Qs values:  [[0.418]
 [0.478]
 [0.438]
 [0.422]
 [0.443]
 [0.511]
 [0.475]] [[-0.186]
 [ 0.08 ]
 [ 0.131]
 [-0.329]
 [-0.051]
 [ 0.253]
 [ 0.235]] [[0.142]
 [0.529]
 [0.5  ]
 [0.007]
 [0.327]
 [0.768]
 [0.678]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.559]
 [0.612]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.569]] [[3.558]
 [3.735]
 [3.558]
 [3.558]
 [3.558]
 [3.558]
 [3.335]] [[1.449]
 [1.69 ]
 [1.449]
 [1.449]
 [1.449]
 [1.449]
 [1.275]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.799]
 [0.814]
 [0.799]
 [0.799]
 [0.799]
 [0.799]
 [0.796]] [[3.501]
 [2.335]
 [3.501]
 [3.501]
 [3.501]
 [3.501]
 [3.19 ]] [[1.918]
 [1.422]
 [1.918]
 [1.918]
 [1.918]
 [1.918]
 [1.779]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
Printing some Q and Qe and total Qs values:  [[0.736]
 [0.756]
 [0.736]
 [0.736]
 [0.736]
 [0.736]
 [0.808]] [[3.445]
 [3.317]
 [3.445]
 [3.445]
 [3.445]
 [3.445]
 [4.83 ]] [[1.849]
 [1.812]
 [1.849]
 [1.849]
 [1.849]
 [1.849]
 [2.473]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.8813761824162838
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
Printing some Q and Qe and total Qs values:  [[0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]] [[2.695]
 [2.695]
 [2.695]
 [2.695]
 [2.695]
 [2.695]
 [2.695]] [[2.391]
 [2.391]
 [2.391]
 [2.391]
 [2.391]
 [2.391]
 [2.391]]
Printing some Q and Qe and total Qs values:  [[0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.944]
 [1.014]] [[0.996]
 [0.996]
 [0.996]
 [0.996]
 [0.996]
 [0.964]
 [1.008]] [[0.838]
 [0.838]
 [0.838]
 [0.838]
 [0.838]
 [0.789]
 [0.973]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.541]
 [0.541]
 [0.541]
 [0.541]
 [0.63 ]
 [0.639]] [[2.224]
 [2.224]
 [2.224]
 [2.224]
 [2.224]
 [0.408]
 [1.975]] [[2.042]
 [2.042]
 [2.042]
 [2.042]
 [2.042]
 [0.404]
 [1.988]]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
Printing some Q and Qe and total Qs values:  [[0.634]
 [0.627]
 [0.634]
 [0.634]
 [0.634]
 [0.634]
 [0.634]] [[3.78]
 [5.18]
 [3.78]
 [3.78]
 [3.78]
 [3.78]
 [3.78]] [[1.061]
 [2.155]
 [1.061]
 [1.061]
 [1.061]
 [1.061]
 [1.061]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
Printing some Q and Qe and total Qs values:  [[0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.584]] [[1.232]
 [3.033]
 [1.232]
 [1.232]
 [1.232]
 [1.232]
 [1.311]] [[0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.584]]
Printing some Q and Qe and total Qs values:  [[0.632]
 [0.574]
 [0.592]
 [0.632]
 [0.585]
 [0.632]
 [0.56 ]] [[1.708]
 [2.798]
 [1.537]
 [1.708]
 [1.157]
 [1.708]
 [1.695]] [[0.632]
 [0.574]
 [0.592]
 [0.632]
 [0.585]
 [0.632]
 [0.56 ]]
line 256 mcts: sample exp_bonus 2.966677231106815
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0041576987445755284, 0.0041576987445755284, 0.9822795731947802, 0.00940502931606889]
using explorer policy with actor:  1
actor:  1 policy actor:  1  step number:  113 total reward:  0.14999999999999936  reward:  1.0 rdn_beta:  0.5
Printing some Q and Qe and total Qs values:  [[0.713]
 [0.672]
 [0.891]
 [0.998]
 [0.921]
 [0.775]
 [0.941]] [[1.173]
 [1.18 ]
 [1.2  ]
 [1.013]
 [0.979]
 [1.189]
 [1.222]] [[1.299]
 [1.238]
 [1.613]
 [1.634]
 [1.481]
 [1.414]
 [1.712]]
siam score:  -0.6625901
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0034068479802090695, 0.0034068479802090695, 0.9857782853367171, 0.0074080187028648225]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0034068479802090695, 0.0034068479802090695, 0.9857782853367171, 0.0074080187028648225]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0034068479802090695, 0.0034068479802090695, 0.9857782853367171, 0.0074080187028648225]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0034068479802090695, 0.0034068479802090695, 0.9857782853367171, 0.0074080187028648225]
using another actor
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.307]
 [0.307]
 [0.307]
 [0.307]
 [0.307]
 [0.307]
 [0.343]] [[0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.627]] [[0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.548]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.212]
 [0.229]
 [0.233]
 [0.246]
 [0.16 ]
 [0.216]
 [0.42 ]] [[1.934]
 [1.908]
 [2.004]
 [1.585]
 [1.685]
 [1.886]
 [4.658]] [[-0.052]
 [-0.047]
 [ 0.01 ]
 [-0.207]
 [-0.247]
 [-0.074]
 [ 1.68 ]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.201]
 [0.258]
 [0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]] [[-0.184]
 [ 0.229]
 [-0.184]
 [-0.184]
 [-0.184]
 [-0.184]
 [-0.184]] [[0.201]
 [0.258]
 [0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.736]
 [0.718]
 [0.718]
 [0.718]
 [0.718]
 [0.718]] [[0.924]
 [0.941]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]] [[1.462]
 [1.515]
 [1.462]
 [1.462]
 [1.462]
 [1.462]
 [1.462]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.769]
 [0.758]
 [0.769]
 [0.769]
 [0.769]
 [0.769]
 [0.771]] [[1.269]
 [1.766]
 [1.269]
 [1.269]
 [1.269]
 [1.269]
 [0.986]] [[0.895]
 [1.156]
 [0.895]
 [0.895]
 [0.895]
 [0.895]
 [0.741]]
start point for exploration sampling:  10768
siam score:  -0.6602559
1041 790
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.687]
 [1.153]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]] [[-0.083]
 [ 1.037]
 [-0.083]
 [-0.083]
 [-0.083]
 [-0.083]
 [-0.083]] [[0.222]
 [1.45 ]
 [0.222]
 [0.222]
 [0.222]
 [0.222]
 [0.222]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
from probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
first move QE:  0.8357022556630191
siam score:  -0.64938253
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
siam score:  -0.6525102
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
line 256 mcts: sample exp_bonus -0.10298461845300057
1049 797
using another actor
siam score:  -0.6509919
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.662]
 [0.662]
 [0.662]
 [0.662]
 [0.662]
 [0.662]
 [0.689]] [[4.095]
 [4.095]
 [4.095]
 [4.095]
 [4.095]
 [4.095]
 [3.903]] [[1.847]
 [1.847]
 [1.847]
 [1.847]
 [1.847]
 [1.847]
 [1.722]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.585]
 [0.585]] [[2.632]
 [2.632]
 [2.632]
 [2.632]
 [2.632]
 [2.632]
 [2.632]] [[1.064]
 [1.064]
 [1.064]
 [1.064]
 [1.064]
 [1.064]
 [1.064]]
line 256 mcts: sample exp_bonus 1.5764050679780448
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.523]
 [0.488]
 [0.529]
 [0.529]
 [0.536]
 [0.53 ]
 [0.557]] [[1.038]
 [1.37 ]
 [1.128]
 [1.081]
 [1.187]
 [1.307]
 [0.817]] [[0.523]
 [0.488]
 [0.529]
 [0.529]
 [0.536]
 [0.53 ]
 [0.557]]
line 256 mcts: sample exp_bonus 1.1197983603007573
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.624]] [[2.345]
 [2.345]
 [2.345]
 [2.345]
 [2.345]
 [2.345]
 [2.054]] [[0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.589]
 [0.624]]
Printing some Q and Qe and total Qs values:  [[0.414]
 [0.503]
 [0.534]
 [0.604]
 [0.653]
 [0.622]
 [0.544]] [[2.843]
 [3.828]
 [4.527]
 [1.842]
 [1.273]
 [3.538]
 [3.328]] [[0.414]
 [0.503]
 [0.534]
 [0.604]
 [0.653]
 [0.622]
 [0.544]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
1056 802
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
from probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
rdn beta is 0 so we're just using the maxi policy
from probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
from probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.293]
 [0.277]
 [0.312]
 [0.312]
 [0.293]
 [0.298]
 [0.304]] [[-1.918]
 [-0.11 ]
 [ 0.   ]
 [ 0.   ]
 [-1.727]
 [-2.459]
 [-3.597]] [[0.293]
 [0.277]
 [0.312]
 [0.312]
 [0.293]
 [0.298]
 [0.304]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
siam score:  -0.64819765
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]] [[0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]] [[2.178]
 [2.178]
 [2.178]
 [2.178]
 [2.178]
 [2.178]
 [2.178]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.549]
 [0.502]
 [0.555]
 [0.63 ]
 [0.63 ]
 [0.475]
 [0.473]] [[-0.265]
 [ 0.421]
 [-0.141]
 [ 0.355]
 [ 0.355]
 [-0.332]
 [-0.32 ]] [[0.549]
 [0.502]
 [0.555]
 [0.63 ]
 [0.63 ]
 [0.475]
 [0.473]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.083]
 [1.47 ]] [[0.972]
 [0.972]
 [0.972]
 [0.972]
 [0.972]
 [0.972]
 [0.831]] [[0.307]
 [0.307]
 [0.307]
 [0.307]
 [0.307]
 [0.307]
 [2.939]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.716]
 [0.692]
 [0.704]
 [0.697]
 [0.7  ]
 [0.7  ]
 [0.697]] [[0.157]
 [1.633]
 [0.582]
 [0.356]
 [0.463]
 [0.537]
 [0.345]] [[0.11 ]
 [0.936]
 [0.342]
 [0.203]
 [0.268]
 [0.311]
 [0.197]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
using explorer policy with actor:  1
siam score:  -0.63714457
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
Printing some Q and Qe and total Qs values:  [[0.408]
 [0.414]
 [0.53 ]
 [0.492]
 [0.523]
 [0.513]
 [0.464]] [[3.036]
 [3.447]
 [1.697]
 [2.649]
 [3.533]
 [3.134]
 [3.947]] [[ 0.505]
 [ 0.738]
 [-0.094]
 [ 0.386]
 [ 0.904]
 [ 0.675]
 [ 1.066]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
siam score:  -0.62699986
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.004775352662678649, 0.004775352662678649, 0.9794015135784919, 0.011047781096150936]
actor:  1 policy actor:  1  step number:  76 total reward:  0.3149999999999995  reward:  1.0 rdn_beta:  0.5
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
Printing some Q and Qe and total Qs values:  [[0.302]
 [0.257]
 [0.302]
 [0.302]
 [0.302]
 [0.302]
 [0.303]] [[1.226]
 [1.484]
 [1.226]
 [1.226]
 [1.226]
 [1.226]
 [0.762]] [[-0.081]
 [ 0.088]
 [-0.081]
 [-0.081]
 [-0.081]
 [-0.081]
 [-0.542]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]
 [-0.028]] [[4.369]
 [4.369]
 [4.369]
 [4.369]
 [4.369]
 [4.369]
 [4.369]] [[0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]
 [0.948]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
line 256 mcts: sample exp_bonus 0.7339799251364414
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Printing some Q and Qe and total Qs values:  [[0.597]
 [0.738]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]] [[0.848]
 [0.574]
 [0.848]
 [0.848]
 [0.848]
 [0.848]
 [0.848]] [[1.346]
 [1.354]
 [1.346]
 [1.346]
 [1.346]
 [1.346]
 [1.346]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
siam score:  -0.6380169
Printing some Q and Qe and total Qs values:  [[0.257]
 [0.154]
 [0.257]
 [0.158]
 [0.257]
 [0.257]
 [0.275]] [[2.738]
 [3.336]
 [2.738]
 [2.779]
 [2.738]
 [2.738]
 [3.005]] [[-0.376]
 [ 0.015]
 [-0.376]
 [-0.534]
 [-0.376]
 [-0.376]
 [-0.073]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
Printing some Q and Qe and total Qs values:  [[0.224]
 [0.4  ]
 [0.398]
 [0.534]
 [0.534]
 [0.291]
 [0.365]] [[2.645]
 [3.647]
 [2.96 ]
 [4.305]
 [4.305]
 [2.439]
 [3.067]] [[0.63 ]
 [1.452]
 [1.033]
 [2.014]
 [2.014]
 [0.586]
 [1.057]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
Printing some Q and Qe and total Qs values:  [[0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.642]] [[3.886]
 [3.886]
 [3.886]
 [3.886]
 [3.886]
 [3.886]
 [3.775]] [[1.526]
 [1.526]
 [1.526]
 [1.526]
 [1.526]
 [1.526]
 [1.554]]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
line 256 mcts: sample exp_bonus -0.4402504717568852
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
line 256 mcts: sample exp_bonus 3.1416266430397246
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
siam score:  -0.635715
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
using another actor
siam score:  -0.6358702
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
probs:  [0.0035379452099097704, 0.0035379452099097704, 0.985167416318404, 0.007756693261776429]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.9999 -1.0 -0.9999
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
actor:  0 policy actor:  1  step number:  84 total reward:  0.23499999999999943  reward:  1.0 rdn_beta:  0.5
using another actor
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.524]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.558]] [[2.496]
 [3.864]
 [2.496]
 [2.496]
 [2.496]
 [2.496]
 [1.953]] [[0.513]
 [0.524]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.558]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
line 256 mcts: sample exp_bonus 1.0244717490831432
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
Printing some Q and Qe and total Qs values:  [[0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.872]] [[0.941]
 [0.941]
 [0.941]
 [0.941]
 [0.941]
 [0.941]
 [0.958]] [[1.493]
 [1.493]
 [1.493]
 [1.493]
 [1.493]
 [1.493]
 [1.627]]
Printing some Q and Qe and total Qs values:  [[0.713]
 [0.781]
 [0.713]
 [0.713]
 [0.713]
 [0.713]
 [0.713]] [[0.649]
 [1.82 ]
 [0.649]
 [0.649]
 [0.649]
 [0.649]
 [0.649]] [[0.271]
 [1.135]
 [0.271]
 [0.271]
 [0.271]
 [0.271]
 [0.271]]
Printing some Q and Qe and total Qs values:  [[0.154]
 [0.153]
 [0.154]
 [0.154]
 [0.154]
 [0.154]
 [0.154]] [[-0.735]
 [-0.564]
 [-0.735]
 [-0.735]
 [-0.735]
 [-0.735]
 [-0.735]] [[0.154]
 [0.153]
 [0.154]
 [0.154]
 [0.154]
 [0.154]
 [0.154]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
using another actor
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
from probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.3087333893523145
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
siam score:  -0.6472402
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
siam score:  -0.6475435
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
siam score:  -0.6501233
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
first move QE:  0.808863482856423
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.6601656877704156
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.454]
 [0.466]
 [0.462]
 [0.466]
 [0.466]
 [0.435]
 [0.466]] [[0.671]
 [0.184]
 [0.026]
 [0.184]
 [0.184]
 [0.246]
 [0.184]] [[0.454]
 [0.466]
 [0.462]
 [0.466]
 [0.466]
 [0.435]
 [0.466]]
line 256 mcts: sample exp_bonus 2.8425236427225347
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
line 256 mcts: sample exp_bonus 0.6817641152432221
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
Printing some Q and Qe and total Qs values:  [[0.592]
 [0.584]
 [0.591]
 [0.59 ]
 [0.59 ]
 [0.677]
 [0.605]] [[2.992]
 [2.989]
 [3.002]
 [3.232]
 [3.31 ]
 [4.01 ]
 [3.782]] [[0.992]
 [0.982]
 [0.997]
 [1.127]
 [1.172]
 [1.668]
 [1.456]]
Printing some Q and Qe and total Qs values:  [[0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.529]] [[ 0.952]
 [ 0.952]
 [ 0.952]
 [ 0.952]
 [ 0.952]
 [ 0.952]
 [-0.281]] [[0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.529]]
Printing some Q and Qe and total Qs values:  [[0.275]
 [0.265]
 [0.307]
 [0.296]
 [0.606]
 [0.314]
 [0.303]] [[1.036]
 [2.218]
 [0.944]
 [0.634]
 [0.874]
 [0.958]
 [1.886]] [[0.275]
 [0.265]
 [0.307]
 [0.296]
 [0.606]
 [0.314]
 [0.303]]
Printing some Q and Qe and total Qs values:  [[0.767]
 [0.843]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.952]] [[1.603]
 [1.763]
 [1.603]
 [1.603]
 [1.603]
 [1.603]
 [1.739]] [[1.764]
 [1.951]
 [1.764]
 [1.764]
 [1.764]
 [1.764]
 [2.068]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
Printing some Q and Qe and total Qs values:  [[0.303]
 [0.364]
 [0.305]
 [0.305]
 [0.305]
 [0.305]
 [0.431]] [[1.702]
 [1.777]
 [1.601]
 [1.601]
 [1.601]
 [1.601]
 [1.676]] [[0.303]
 [0.364]
 [0.305]
 [0.305]
 [0.305]
 [0.305]
 [0.431]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Printing some Q and Qe and total Qs values:  [[0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.409]] [[2.835]
 [2.835]
 [2.835]
 [2.835]
 [2.835]
 [2.835]
 [3.75 ]] [[0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.41 ]
 [0.409]]
Printing some Q and Qe and total Qs values:  [[-0.008]
 [ 0.274]
 [ 0.357]
 [ 0.329]
 [ 0.329]
 [ 0.272]
 [ 0.222]] [[1.795]
 [1.681]
 [0.333]
 [0.   ]
 [0.   ]
 [0.011]
 [1.725]] [[-0.008]
 [ 0.274]
 [ 0.357]
 [ 0.329]
 [ 0.329]
 [ 0.272]
 [ 0.222]]
siam score:  -0.6467626
siam score:  -0.6436169
Printing some Q and Qe and total Qs values:  [[0.347]
 [0.435]
 [0.594]
 [0.541]
 [0.518]
 [0.521]
 [0.487]] [[2.107]
 [3.623]
 [1.827]
 [1.451]
 [1.162]
 [1.59 ]
 [2.134]] [[ 0.211]
 [ 1.138]
 [ 0.328]
 [ 0.064]
 [-0.12 ]
 [ 0.119]
 [ 0.379]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
UNIT TEST: sample policy line 217 mcts : [0.02  0.041 0.02  0.02  0.02  0.02  0.857]
deleting a thread, now have 3 threads
Frames:  67203 train batches done:  7870 episodes:  1973
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.0035332301226541182, 0.0035332301226541182, 0.9851896956699101, 0.007743844084781797]
siam score:  -0.6385803
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
deleting a thread, now have 2 threads
Frames:  67326 train batches done:  7890 episodes:  1976
1116 861
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.597]
 [0.608]
 [0.66 ]
 [0.611]
 [0.611]
 [0.613]
 [0.627]] [[1.808]
 [2.26 ]
 [2.598]
 [2.423]
 [2.423]
 [2.117]
 [2.146]] [[0.533]
 [1.007]
 [1.449]
 [1.175]
 [1.175]
 [0.874]
 [0.93 ]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[1.181]
 [1.453]
 [1.179]
 [1.163]
 [1.163]
 [1.173]
 [1.186]] [[0.148]
 [0.54 ]
 [0.094]
 [0.745]
 [0.745]
 [0.209]
 [0.33 ]] [[1.929]
 [2.865]
 [1.869]
 [2.489]
 [2.489]
 [1.973]
 [2.12 ]]
siam score:  -0.6204547
siam score:  -0.61980796
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.3834593813187643
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
siam score:  -0.62291473
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.518]
 [0.505]
 [0.464]
 [0.582]
 [0.747]
 [0.502]
 [0.891]] [[1.626]
 [0.943]
 [1.388]
 [2.056]
 [1.058]
 [1.615]
 [1.315]] [[1.296]
 [0.588]
 [0.951]
 [1.854]
 [1.186]
 [1.255]
 [1.732]]
siam score:  -0.6227043
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Printing some Q and Qe and total Qs values:  [[0.328]
 [0.328]
 [0.328]
 [0.328]
 [0.328]
 [0.328]
 [0.328]] [[-0.163]
 [-0.163]
 [-0.163]
 [-0.163]
 [-0.163]
 [-0.163]
 [-0.163]] [[0.328]
 [0.328]
 [0.328]
 [0.328]
 [0.328]
 [0.328]
 [0.328]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
1121 877
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.471]
 [0.471]
 [0.471]
 [0.471]
 [0.471]
 [0.471]
 [1.041]] [[0.407]
 [0.407]
 [0.407]
 [0.407]
 [0.407]
 [0.407]
 [0.852]] [[0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.629]
 [1.927]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.817]] [[1.322]
 [1.322]
 [1.322]
 [1.322]
 [1.322]
 [1.322]
 [1.38 ]] [[2.18 ]
 [2.18 ]
 [2.18 ]
 [2.18 ]
 [2.18 ]
 [2.18 ]
 [2.301]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
1125 884
1125 886
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
from probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus -3.2641989418184805
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.72 ]
 [1.062]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.942]] [[1.645]
 [1.603]
 [1.645]
 [1.645]
 [1.645]
 [1.645]
 [1.236]] [[2.136]
 [2.425]
 [2.136]
 [2.136]
 [2.136]
 [2.136]
 [2.152]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.314]
 [0.357]
 [0.353]
 [0.313]
 [0.329]
 [0.319]
 [0.305]] [[-1.456]
 [-0.536]
 [-1.125]
 [-1.797]
 [-1.653]
 [-1.826]
 [-1.742]] [[0.314]
 [0.357]
 [0.353]
 [0.313]
 [0.329]
 [0.319]
 [0.305]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Printing some Q and Qe and total Qs values:  [[0.69 ]
 [0.599]
 [0.693]
 [0.715]
 [0.76 ]
 [0.731]
 [0.657]] [[0.657]
 [1.997]
 [1.008]
 [0.598]
 [0.675]
 [0.648]
 [0.797]] [[0.284]
 [1.443]
 [0.642]
 [0.277]
 [0.442]
 [0.358]
 [0.358]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.743]] [[0.228]
 [0.228]
 [0.228]
 [0.228]
 [0.228]
 [0.228]
 [0.228]] [[2.296]
 [2.296]
 [2.296]
 [2.296]
 [2.296]
 [2.296]
 [2.296]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
using another actor
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
siam score:  -0.6341732
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
first move QE:  0.8001071338268932
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
from probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.514]
 [0.501]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.547]] [[-0.339]
 [ 0.605]
 [-0.339]
 [-0.339]
 [-0.339]
 [-0.339]
 [-0.925]] [[0.514]
 [0.501]
 [0.514]
 [0.514]
 [0.514]
 [0.514]
 [0.547]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[1.142]
 [1.142]
 [1.142]
 [1.142]
 [1.142]
 [1.142]
 [1.142]] [[0.799]
 [0.786]
 [0.799]
 [0.799]
 [0.799]
 [0.799]
 [0.789]] [[1.76 ]
 [1.747]
 [1.76 ]
 [1.76 ]
 [1.76 ]
 [1.76 ]
 [1.75 ]]
siam score:  -0.6451255
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
1140 920
using explorer policy with actor:  0
using another actor
from probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.63 ]
 [0.618]
 [0.627]
 [0.627]
 [0.627]
 [0.63 ]
 [0.625]] [[1.745]
 [2.577]
 [1.936]
 [1.936]
 [1.936]
 [1.501]
 [2.103]] [[0.63 ]
 [0.618]
 [0.627]
 [0.627]
 [0.627]
 [0.63 ]
 [0.625]]
Printing some Q and Qe and total Qs values:  [[0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.694]] [[2.206]
 [2.206]
 [2.206]
 [2.206]
 [2.206]
 [2.206]
 [1.166]] [[0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.642]
 [0.694]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.486]
 [0.501]
 [0.486]
 [0.486]
 [0.486]
 [0.486]
 [0.791]] [[3.944]
 [3.759]
 [3.944]
 [3.944]
 [3.944]
 [3.944]
 [1.756]] [[0.486]
 [0.501]
 [0.486]
 [0.486]
 [0.486]
 [0.486]
 [0.791]]
Printing some Q and Qe and total Qs values:  [[0.879]
 [0.879]
 [0.879]
 [0.879]
 [0.879]
 [0.879]
 [1.231]] [[1.749]
 [1.749]
 [1.749]
 [1.749]
 [1.749]
 [1.749]
 [8.257]] [[0.599]
 [0.599]
 [0.599]
 [0.599]
 [0.599]
 [0.599]
 [2.245]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.508]
 [0.508]
 [0.508]
 [0.508]
 [0.508]
 [0.508]
 [0.508]] [[2.816]
 [2.816]
 [2.816]
 [2.816]
 [2.816]
 [2.816]
 [2.816]] [[1.864]
 [1.864]
 [1.864]
 [1.864]
 [1.864]
 [1.864]
 [1.864]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.176]
 [0.243]
 [0.176]
 [0.176]
 [0.176]
 [0.183]
 [0.228]] [[0.273]
 [0.948]
 [0.273]
 [0.273]
 [0.273]
 [0.199]
 [0.689]] [[0.176]
 [0.243]
 [0.176]
 [0.176]
 [0.176]
 [0.183]
 [0.228]]
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.495]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.415]] [[1.687]
 [3.383]
 [1.687]
 [1.687]
 [1.687]
 [1.687]
 [1.56 ]] [[0.817]
 [2.022]
 [0.817]
 [0.817]
 [0.817]
 [0.817]
 [0.724]]
Printing some Q and Qe and total Qs values:  [[0.313]
 [0.292]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.316]] [[1.078]
 [2.259]
 [1.078]
 [1.078]
 [1.078]
 [1.078]
 [2.107]] [[0.313]
 [0.292]
 [0.313]
 [0.313]
 [0.313]
 [0.313]
 [0.316]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
from probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.292]] [[-0.551]
 [-0.551]
 [-0.551]
 [-0.551]
 [-0.551]
 [-0.551]
 [-2.847]] [[0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.292]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
siam score:  -0.64110124
Printing some Q and Qe and total Qs values:  [[0.331]
 [0.329]
 [0.315]
 [0.159]
 [0.411]
 [0.298]
 [0.195]] [[1.696]
 [2.577]
 [2.276]
 [4.315]
 [2.43 ]
 [2.358]
 [2.55 ]] [[-0.373]
 [ 0.363]
 [ 0.086]
 [ 1.535]
 [ 0.376]
 [ 0.128]
 [ 0.114]]
siam score:  -0.64687693
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using another actor
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.613]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]] [[0.434]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]] [[0.613]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.635]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using another actor
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
line 256 mcts: sample exp_bonus 1.6666069473994527
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.297]
 [0.267]
 [0.295]
 [0.297]
 [0.277]
 [0.289]
 [0.368]] [[1.878]
 [1.734]
 [1.445]
 [1.436]
 [1.474]
 [1.479]
 [0.758]] [[0.297]
 [0.267]
 [0.295]
 [0.297]
 [0.277]
 [0.289]
 [0.368]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Printing some Q and Qe and total Qs values:  [[0.12]
 [0.12]
 [0.12]
 [0.12]
 [0.12]
 [0.12]
 [0.12]] [[2.225]
 [2.225]
 [2.225]
 [2.225]
 [2.225]
 [2.225]
 [2.225]] [[1.166]
 [1.166]
 [1.166]
 [1.166]
 [1.166]
 [1.166]
 [1.166]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.434]
 [0.465]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.448]] [[3.739]
 [3.459]
 [3.739]
 [3.739]
 [3.739]
 [3.739]
 [3.713]] [[1.729]
 [1.518]
 [1.729]
 [1.729]
 [1.729]
 [1.729]
 [1.732]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 3.154702811929903
siam score:  -0.68592644
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
line 256 mcts: sample exp_bonus -1.39612482118602
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.95 ]] [[1.052]
 [1.052]
 [1.052]
 [1.052]
 [1.052]
 [1.052]
 [0.967]] [[0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [1.04 ]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
Printing some Q and Qe and total Qs values:  [[0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.649]] [[1.872]
 [1.872]
 [1.872]
 [1.872]
 [1.872]
 [1.872]
 [1.98 ]] [[0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.649]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
from probs:  [0.004672888204592798, 0.004672888204592798, 0.979879410766292, 0.010774812824522348]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
Starting evaluation
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
using explorer policy with actor:  0
using another actor
from probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
using explorer policy with actor:  0
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.9578489610862175
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Printing some Q and Qe and total Qs values:  [[0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]] [[2.135]
 [2.135]
 [2.135]
 [2.135]
 [2.135]
 [2.135]
 [2.135]] [[0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]
 [0.625]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.547]
 [0.552]
 [0.59 ]
 [0.567]
 [0.567]
 [0.575]
 [0.542]] [[2.506]
 [2.625]
 [1.543]
 [1.626]
 [1.626]
 [0.689]
 [2.025]] [[0.547]
 [0.552]
 [0.59 ]
 [0.567]
 [0.567]
 [0.575]
 [0.542]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
Printing some Q and Qe and total Qs values:  [[0.502]
 [0.502]
 [0.502]
 [0.502]
 [0.502]
 [0.502]
 [0.502]] [[3.057]
 [3.057]
 [3.057]
 [3.057]
 [3.057]
 [3.057]
 [3.057]] [[0.502]
 [0.502]
 [0.502]
 [0.502]
 [0.502]
 [0.502]
 [0.502]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Printing some Q and Qe and total Qs values:  [[0.63 ]
 [0.67 ]
 [0.641]
 [0.635]
 [0.638]
 [0.639]
 [0.772]] [[ 0.371]
 [ 1.059]
 [ 0.169]
 [ 0.273]
 [ 0.31 ]
 [ 0.37 ]
 [-0.139]] [[0.63 ]
 [0.67 ]
 [0.641]
 [0.635]
 [0.638]
 [0.639]
 [0.772]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
Printing some Q and Qe and total Qs values:  [[0.545]
 [0.545]
 [0.61 ]
 [0.545]
 [0.545]
 [0.763]
 [0.57 ]] [[0.717]
 [0.717]
 [0.588]
 [0.717]
 [0.717]
 [0.669]
 [0.619]] [[0.545]
 [0.545]
 [0.61 ]
 [0.545]
 [0.545]
 [0.763]
 [0.57 ]]
Printing some Q and Qe and total Qs values:  [[0.733]
 [0.434]
 [0.592]
 [0.525]
 [0.551]
 [0.605]
 [0.718]] [[ 0.769]
 [ 1.295]
 [ 0.712]
 [ 0.187]
 [-0.161]
 [ 0.619]
 [ 1.319]] [[0.733]
 [0.434]
 [0.592]
 [0.525]
 [0.551]
 [0.605]
 [0.718]]
line 256 mcts: sample exp_bonus 1.5768165184681422
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
siam score:  -0.6898324
Printing some Q and Qe and total Qs values:  [[0.746]
 [0.654]
 [0.687]
 [0.654]
 [0.682]
 [0.766]
 [0.73 ]] [[0.966]
 [0.857]
 [0.874]
 [0.857]
 [0.722]
 [0.576]
 [0.511]] [[0.746]
 [0.654]
 [0.687]
 [0.654]
 [0.682]
 [0.766]
 [0.73 ]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
Printing some Q and Qe and total Qs values:  [[0.434]
 [0.463]
 [0.485]
 [0.434]
 [0.434]
 [0.434]
 [0.49 ]] [[0.337]
 [1.542]
 [0.456]
 [0.337]
 [0.337]
 [0.337]
 [0.883]] [[0.434]
 [0.463]
 [0.485]
 [0.434]
 [0.434]
 [0.434]
 [0.49 ]]
Printing some Q and Qe and total Qs values:  [[-0.03 ]
 [-0.03 ]
 [-0.03 ]
 [-0.03 ]
 [-0.03 ]
 [-0.03 ]
 [-0.013]] [[2.716]
 [2.716]
 [2.716]
 [2.716]
 [2.716]
 [2.716]
 [3.793]] [[-0.013]
 [-0.013]
 [-0.013]
 [-0.013]
 [-0.013]
 [-0.013]
 [ 0.579]]
Printing some Q and Qe and total Qs values:  [[-0.048]
 [-0.034]
 [-0.036]
 [-0.036]
 [-0.036]
 [-0.036]
 [-0.003]] [[3.129]
 [2.176]
 [4.012]
 [4.012]
 [4.012]
 [4.012]
 [3.669]] [[ 0.115]
 [-0.449]
 [ 0.669]
 [ 0.669]
 [ 0.669]
 [ 0.669]
 [ 0.5  ]]
line 256 mcts: sample exp_bonus -0.1226496678822914
Printing some Q and Qe and total Qs values:  [[0.452]
 [0.46 ]
 [0.471]
 [0.472]
 [0.563]
 [0.463]
 [0.527]] [[ 1.305]
 [ 1.019]
 [ 0.922]
 [ 0.424]
 [ 0.   ]
 [ 0.744]
 [-0.229]] [[0.452]
 [0.46 ]
 [0.471]
 [0.472]
 [0.563]
 [0.463]
 [0.527]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
line 256 mcts: sample exp_bonus -0.023590928100466837
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
first move QE:  0.7971295459222204
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
rdn probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004672888204592797, 0.004672888204592797, 0.979879410766292, 0.010774812824522346]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
in main func line 156:  1165
Printing some Q and Qe and total Qs values:  [[0.235]
 [0.259]
 [0.228]
 [0.228]
 [0.203]
 [0.197]
 [0.241]] [[-0.108]
 [-0.124]
 [ 0.   ]
 [ 0.   ]
 [-0.555]
 [-0.417]
 [-0.099]] [[0.235]
 [0.259]
 [0.228]
 [0.228]
 [0.203]
 [0.197]
 [0.241]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]
 [0.93]] [[0.802]
 [0.802]
 [0.802]
 [0.802]
 [0.802]
 [0.802]
 [0.802]] [[1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]
 [1.008]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
first move QE:  0.797194183004287
Printing some Q and Qe and total Qs values:  [[0.25 ]
 [0.137]
 [0.38 ]
 [0.137]
 [0.137]
 [0.25 ]
 [0.059]] [[1.221]
 [1.565]
 [1.42 ]
 [1.565]
 [1.565]
 [1.443]
 [2.372]] [[0.066]
 [0.183]
 [0.524]
 [0.183]
 [0.183]
 [0.288]
 [0.835]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.8036414105520848
Printing some Q and Qe and total Qs values:  [[ 0.18 ]
 [ 0.067]
 [ 0.53 ]
 [ 0.067]
 [ 0.067]
 [ 0.169]
 [-0.001]] [[1.152]
 [1.552]
 [1.275]
 [1.552]
 [1.552]
 [1.325]
 [2.021]] [[-0.205]
 [-0.032]
 [ 0.617]
 [-0.032]
 [-0.032]
 [-0.054]
 [ 0.302]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.2241313885404055
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]
 [0.356]] [[2.837]
 [2.837]
 [2.837]
 [2.837]
 [2.837]
 [2.837]
 [2.837]] [[1.739]
 [1.739]
 [1.739]
 [1.739]
 [1.739]
 [1.739]
 [1.739]]
Printing some Q and Qe and total Qs values:  [[0.344]
 [0.332]
 [0.344]
 [0.344]
 [0.344]
 [0.344]
 [0.31 ]] [[2.633]
 [2.937]
 [2.633]
 [2.633]
 [2.633]
 [2.633]
 [3.   ]] [[1.292]
 [1.535]
 [1.292]
 [1.292]
 [1.292]
 [1.292]
 [1.552]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
siam score:  -0.68390363
Printing some Q and Qe and total Qs values:  [[0.531]
 [0.531]
 [0.531]
 [0.531]
 [0.531]
 [0.531]
 [0.598]] [[2.239]
 [2.239]
 [2.239]
 [2.239]
 [2.239]
 [2.239]
 [7.3  ]] [[0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [0.577]
 [1.926]]
Printing some Q and Qe and total Qs values:  [[0.388]
 [0.236]
 [0.409]
 [0.401]
 [0.385]
 [0.399]
 [0.353]] [[0.634]
 [1.316]
 [0.191]
 [0.2  ]
 [0.066]
 [0.589]
 [1.722]] [[ 0.114]
 [ 0.42 ]
 [-0.21 ]
 [-0.214]
 [-0.348]
 [ 0.096]
 [ 0.935]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
siam score:  -0.6823961
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.594]
 [0.55 ]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.611]] [[0.685]
 [1.53 ]
 [0.685]
 [0.685]
 [0.685]
 [0.685]
 [1.447]] [[0.494]
 [1.251]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [1.288]]
Printing some Q and Qe and total Qs values:  [[0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.68 ]] [[2.128]
 [2.128]
 [2.128]
 [2.128]
 [2.128]
 [2.128]
 [2.061]] [[0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.68 ]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
line 256 mcts: sample exp_bonus -0.7768608850624045
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.816]
 [0.631]
 [0.67 ]
 [0.64 ]
 [0.43 ]
 [0.65 ]
 [0.661]] [[ 3.812]
 [ 0.635]
 [ 0.207]
 [-0.396]
 [ 0.211]
 [-0.146]
 [ 0.057]] [[2.373]
 [0.783]
 [0.626]
 [0.329]
 [0.412]
 [0.45 ]
 [0.551]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.008]
 [0.015]] [[-1.847]
 [-1.892]
 [-1.892]
 [-1.892]
 [-2.082]
 [-1.838]
 [-1.951]] [[0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.009]
 [0.008]
 [0.015]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
siam score:  -0.6956878
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.288625605720114
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
siam score:  -0.6969528
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
line 256 mcts: sample exp_bonus 1.1713501338931527
Printing some Q and Qe and total Qs values:  [[0.486]
 [0.486]
 [0.486]
 [0.8  ]
 [0.617]
 [0.486]
 [0.608]] [[4.037]
 [4.037]
 [4.037]
 [3.365]
 [2.831]
 [4.037]
 [6.303]] [[0.762]
 [0.762]
 [0.762]
 [0.739]
 [0.268]
 [0.762]
 [2.072]]
line 256 mcts: sample exp_bonus 0.14123387130211568
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.986]
 [0.986]
 [0.986]
 [0.986]
 [0.986]
 [0.986]
 [0.986]] [[0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.785]] [[0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.61]
 [0.6 ]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.646]
 [0.592]
 [0.592]
 [0.592]
 [0.592]
 [0.592]
 [0.592]] [[1.098]
 [1.75 ]
 [1.75 ]
 [1.75 ]
 [1.75 ]
 [1.75 ]
 [1.75 ]] [[1.902]
 [2.132]
 [2.132]
 [2.132]
 [2.132]
 [2.132]
 [2.132]]
first move QE:  0.7927369331029133
from probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.956]
 [0.956]
 [0.956]
 [0.956]
 [0.956]
 [0.956]
 [1.247]] [[1.641]
 [1.641]
 [1.641]
 [1.641]
 [1.641]
 [1.641]
 [1.891]] [[1.276]
 [1.276]
 [1.276]
 [1.276]
 [1.276]
 [1.276]
 [1.798]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
siam score:  -0.6795321
from probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
first move QE:  0.789592607024321
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
siam score:  -0.67718536
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.547]
 [0.406]
 [0.831]
 [0.565]
 [0.831]
 [0.831]
 [0.528]] [[0.904]
 [1.435]
 [0.714]
 [0.898]
 [0.714]
 [0.714]
 [1.29 ]] [[0.007]
 [0.256]
 [0.385]
 [0.036]
 [0.385]
 [0.385]
 [0.355]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
first move QE:  0.7848417997038235
using another actor
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.84 ]
 [1.363]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [0.84 ]
 [1.007]] [[0.873]
 [1.025]
 [0.873]
 [0.873]
 [0.873]
 [0.873]
 [0.874]] [[1.399]
 [2.276]
 [1.399]
 [1.399]
 [1.399]
 [1.399]
 [1.645]]
siam score:  -0.668409
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
siam score:  -0.66536224
Printing some Q and Qe and total Qs values:  [[0.62 ]
 [0.597]
 [0.676]
 [0.68 ]
 [0.685]
 [0.686]
 [1.084]] [[0.707]
 [0.944]
 [0.791]
 [0.533]
 [0.607]
 [0.756]
 [0.923]] [[0.074]
 [0.237]
 [0.241]
 [0.029]
 [0.1  ]
 [0.23 ]
 [1.051]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]
 [0.658]] [[0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]] [[0.363]
 [0.363]
 [0.363]
 [0.363]
 [0.363]
 [0.363]
 [0.363]]
Printing some Q and Qe and total Qs values:  [[1.018]
 [1.017]
 [1.018]
 [1.018]
 [1.018]
 [1.018]
 [1.231]] [[0.838]
 [0.631]
 [0.838]
 [0.838]
 [0.838]
 [0.838]
 [1.146]] [[0.926]
 [0.787]
 [0.926]
 [0.926]
 [0.926]
 [0.926]
 [1.414]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
siam score:  -0.6594385
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Printing some Q and Qe and total Qs values:  [[0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.65 ]] [[-1.369]
 [-1.369]
 [-1.369]
 [-1.369]
 [-1.369]
 [-1.369]
 [-1.189]] [[0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.427]
 [0.65 ]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Printing some Q and Qe and total Qs values:  [[0.457]
 [0.457]
 [0.376]
 [0.457]
 [0.457]
 [0.457]
 [0.633]] [[-0.393]
 [-0.393]
 [ 0.968]
 [-0.393]
 [-0.393]
 [-0.393]
 [ 1.898]] [[0.457]
 [0.457]
 [0.376]
 [0.457]
 [0.457]
 [0.457]
 [0.633]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
using another actor
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
in main func line 156:  1204
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.004695552796824853, 0.004695552796824853, 0.9859133416095256, 0.004695552796824853]
Printing some Q and Qe and total Qs values:  [[0.404]
 [0.437]
 [0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.389]] [[-0.706]
 [-0.554]
 [-0.706]
 [-0.706]
 [-0.706]
 [-0.706]
 [-0.867]] [[0.404]
 [0.437]
 [0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.389]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.01055611568775314, 0.01055611568775314, 0.9742818730069259, 0.004605895617567791]
using explorer policy with actor:  1
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.727814413256365
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.01055611568775314, 0.01055611568775314, 0.9742818730069259, 0.004605895617567791]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.01055611568775314, 0.01055611568775314, 0.9742818730069259, 0.004605895617567791]
siam score:  -0.66188216
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.01055611568775314, 0.01055611568775314, 0.9742818730069259, 0.004605895617567791]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.01055611568775314, 0.01055611568775314, 0.9742818730069259, 0.004605895617567791]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.01055611568775314, 0.01055611568775314, 0.9742818730069259, 0.004605895617567791]
first move QE:  0.7658232010500686
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Printing some Q and Qe and total Qs values:  [[0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]] [[-2.517]
 [-2.517]
 [-2.517]
 [-2.517]
 [-2.517]
 [-2.517]
 [-2.517]] [[0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]
 [0.151]]
using another actor
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
using another actor
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
Printing some Q and Qe and total Qs values:  [[0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.824]] [[2.214]
 [2.214]
 [2.214]
 [2.214]
 [2.214]
 [2.214]
 [1.067]] [[0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.574]
 [0.824]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
siam score:  -0.6573764
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
Printing some Q and Qe and total Qs values:  [[0.233]
 [0.27 ]
 [0.242]
 [0.233]
 [0.24 ]
 [0.233]
 [0.246]] [[0.   ]
 [0.584]
 [0.424]
 [0.   ]
 [0.109]
 [0.   ]
 [0.46 ]] [[0.233]
 [0.27 ]
 [0.242]
 [0.233]
 [0.24 ]
 [0.233]
 [0.246]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
using explorer policy with actor:  1
from probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
siam score:  -0.6612375
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
Printing some Q and Qe and total Qs values:  [[0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.599]] [[0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.639]] [[0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.599]]
using another actor
siam score:  -0.66597015
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
Printing some Q and Qe and total Qs values:  [[0.358]
 [0.643]
 [0.657]
 [0.672]
 [0.678]
 [0.661]
 [0.541]] [[1.686]
 [1.446]
 [1.531]
 [1.521]
 [2.199]
 [2.297]
 [2.033]] [[0.682]
 [0.916]
 [0.994]
 [1.009]
 [1.495]
 [1.54 ]
 [1.186]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
using another actor
from probs:  [0.010556115687753142, 0.010556115687753142, 0.9742818730069259, 0.004605895617567792]
Printing some Q and Qe and total Qs values:  [[0.608]
 [0.62 ]
 [0.608]
 [0.608]
 [0.608]
 [0.608]
 [0.603]] [[1.117]
 [2.97 ]
 [1.117]
 [1.117]
 [1.117]
 [1.117]
 [1.889]] [[0.608]
 [0.62 ]
 [0.608]
 [0.608]
 [0.608]
 [0.608]
 [0.603]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
Printing some Q and Qe and total Qs values:  [[0.654]
 [0.697]
 [0.654]
 [0.654]
 [0.654]
 [0.654]
 [0.713]] [[0.726]
 [1.185]
 [0.726]
 [0.726]
 [0.726]
 [0.726]
 [1.079]] [[2.182]
 [2.586]
 [2.182]
 [2.182]
 [2.182]
 [2.182]
 [2.531]]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
line 256 mcts: sample exp_bonus -0.2803265022635804
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
Printing some Q and Qe and total Qs values:  [[0.696]
 [0.696]
 [0.696]
 [0.696]
 [0.696]
 [0.696]
 [0.651]] [[1.657]
 [1.657]
 [1.657]
 [1.657]
 [1.657]
 [1.657]
 [1.177]] [[1.549]
 [1.549]
 [1.549]
 [1.549]
 [1.549]
 [1.549]
 [1.133]]
Printing some Q and Qe and total Qs values:  [[0.34 ]
 [0.34 ]
 [0.673]
 [0.454]
 [0.34 ]
 [0.34 ]
 [0.492]] [[2.127]
 [2.127]
 [1.307]
 [1.134]
 [2.127]
 [2.127]
 [1.709]] [[1.473]
 [1.473]
 [1.32 ]
 [0.708]
 [1.473]
 [1.473]
 [1.358]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
siam score:  -0.66615903
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
siam score:  -0.6629704
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
maxi score, test score, baseline:  -0.99743 -1.0 -0.99743
probs:  [0.015677598041078353, 0.015677598041078353, 0.9621050440555458, 0.006539759862297372]
actor:  0 policy actor:  1  step number:  66 total reward:  0.3949999999999996  reward:  1.0 rdn_beta:  0.5
using another actor
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.015625078612782527, 0.015625078612782527, 0.9622296254024636, 0.0065202173719712195]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.015760040707266148, 0.006571181525492109, 0.9710975962417497, 0.006571181525492109]
Printing some Q and Qe and total Qs values:  [[0.322]
 [0.209]
 [0.357]
 [0.349]
 [0.33 ]
 [0.417]
 [0.282]] [[0.769]
 [1.474]
 [1.175]
 [0.447]
 [0.997]
 [1.792]
 [1.829]] [[-0.081]
 [ 0.398]
 [ 0.393]
 [-0.35 ]
 [ 0.162]
 [ 1.13 ]
 [ 0.898]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.015760040707266148, 0.006571181525492109, 0.9710975962417497, 0.006571181525492109]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.289]
 [0.289]
 [0.289]
 [0.289]
 [0.289]
 [0.289]
 [0.289]] [[0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]
 [0.888]] [[-0.205]
 [-0.205]
 [-0.205]
 [-0.205]
 [-0.205]
 [-0.205]
 [-0.205]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.015760040707266148, 0.006571181525492109, 0.9710975962417497, 0.006571181525492109]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.015760040707266148, 0.006571181525492109, 0.9710975962417497, 0.006571181525492109]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.015760040707266148, 0.006571181525492109, 0.9710975962417497, 0.006571181525492109]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
UNIT TEST: sample policy line 217 mcts : [0.    0.939 0.    0.02  0.02  0.    0.02 ]
line 256 mcts: sample exp_bonus 3.7549615640382137
from probs:  [0.01576004070726614, 0.006571181525492107, 0.9710975962417497, 0.006571181525492107]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.01576004070726614, 0.006571181525492107, 0.9710975962417497, 0.006571181525492107]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 0.5333303343766556
siam score:  -0.6690445
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.01576004070726614, 0.006571181525492107, 0.9710975962417497, 0.006571181525492107]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.01576004070726614, 0.006571181525492107, 0.9710975962417497, 0.006571181525492107]
Printing some Q and Qe and total Qs values:  [[0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]] [[-0.9]
 [-0.9]
 [-0.9]
 [-0.9]
 [-0.9]
 [-0.9]
 [-0.9]] [[0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.01576004070726614, 0.006571181525492107, 0.9710975962417497, 0.006571181525492107]
line 256 mcts: sample exp_bonus 0.3154165069684094
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.01576004070726614, 0.006571181525492107, 0.9710975962417497, 0.006571181525492107]
Printing some Q and Qe and total Qs values:  [[0.822]
 [0.825]
 [1.04 ]
 [0.825]
 [0.825]
 [0.825]
 [0.825]] [[ 0.246]
 [ 0.063]
 [-0.1  ]
 [ 0.063]
 [ 0.063]
 [ 0.063]
 [ 0.063]] [[0.869]
 [0.815]
 [1.191]
 [0.815]
 [0.815]
 [0.815]
 [0.815]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.01576004070726614, 0.006571181525492107, 0.9710975962417497, 0.006571181525492107]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.01576004070726614, 0.006571181525492107, 0.9710975962417497, 0.006571181525492107]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.01576004070726614, 0.006571181525492107, 0.9710975962417497, 0.006571181525492107]
1228 1060
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
from probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
first move QE:  0.749702031560505
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.084]
 [1.084]
 [1.084]
 [1.084]
 [1.084]
 [1.084]
 [1.43 ]] [[1.973]
 [1.973]
 [1.973]
 [1.973]
 [1.973]
 [1.973]
 [2.949]] [[1.454]
 [1.454]
 [1.454]
 [1.454]
 [1.454]
 [1.454]
 [1.925]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
main train batch thing paused
add a thread
Adding thread: now have 3 threads
line 256 mcts: sample exp_bonus -0.6298211137600379
using explorer policy with actor:  0
main train batch thing paused
add a thread
Adding thread: now have 4 threads
Printing some Q and Qe and total Qs values:  [[0.355]
 [0.355]
 [0.355]
 [0.355]
 [0.355]
 [0.355]
 [0.37 ]] [[-0.135]
 [-0.135]
 [-0.135]
 [-0.135]
 [-0.135]
 [-0.135]
 [ 0.398]] [[0.355]
 [0.355]
 [0.355]
 [0.355]
 [0.355]
 [0.355]
 [0.37 ]]
Printing some Q and Qe and total Qs values:  [[0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.406]] [[0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]] [[0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.406]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.4527],
        [-0.0000],
        [-0.0000],
        [-0.0000],
        [-0.3849],
        [-0.4742],
        [-0.4460],
        [-0.5110],
        [-0.4527],
        [-0.3873]], dtype=torch.float64)
-0.0727797758985 -0.5255244886848544
-0.9702 -0.9702
-0.014849999999999244 -0.014849999999999244
-0.7226999999999999 -0.7226999999999999
-0.0536639152995 -0.43851784704501023
-0.0727797758985 -0.5469987420567456
-0.0727797758985 -0.5187691456381499
-0.024259925299500003 -0.5352482314722075
-0.0530787758985 -0.5058234886848543
-0.034159925299499995 -0.4214154390067377
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.434]
 [0.505]
 [0.535]
 [0.488]
 [0.53 ]
 [0.586]] [[-1.236]
 [-1.746]
 [-1.257]
 [-1.371]
 [-1.33 ]
 [-1.32 ]
 [-1.4  ]] [[0.563]
 [0.434]
 [0.505]
 [0.535]
 [0.488]
 [0.53 ]
 [0.586]]
Printing some Q and Qe and total Qs values:  [[0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]] [[-1.698]
 [-1.698]
 [-1.698]
 [-1.698]
 [-1.698]
 [-1.698]
 [-1.698]] [[0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]
 [0.445]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
using explorer policy with actor:  1
using another actor
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
Printing some Q and Qe and total Qs values:  [[0.196]
 [0.312]
 [0.391]
 [0.479]
 [0.466]
 [0.826]
 [0.506]] [[2.395]
 [1.407]
 [1.095]
 [0.834]
 [0.741]
 [0.98 ]
 [2.878]] [[1.239]
 [0.628]
 [0.504]
 [0.434]
 [0.339]
 [1.114]
 [2.133]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
using another actor
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
Printing some Q and Qe and total Qs values:  [[0.225]
 [0.477]
 [0.225]
 [0.225]
 [0.225]
 [0.225]
 [0.225]] [[1.702]
 [2.06 ]
 [1.702]
 [1.702]
 [1.702]
 [1.702]
 [1.702]] [[1.023]
 [1.548]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.314]
 [0.353]
 [0.328]
 [0.281]
 [0.25 ]
 [0.368]
 [0.31 ]] [[2.722]
 [2.975]
 [2.659]
 [3.252]
 [2.653]
 [2.555]
 [3.332]] [[ 0.019]
 [ 0.325]
 [-0.012]
 [ 0.446]
 [-0.161]
 [-0.035]
 [ 0.574]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
Printing some Q and Qe and total Qs values:  [[0.664]
 [0.645]
 [0.685]
 [0.666]
 [0.675]
 [0.663]
 [0.669]] [[4.58 ]
 [4.715]
 [4.521]
 [5.009]
 [4.705]
 [4.852]
 [4.892]] [[0.664]
 [0.645]
 [0.685]
 [0.666]
 [0.675]
 [0.663]
 [0.669]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.00662309478639138, 0.00662309478639138, 0.9801307156408257, 0.00662309478639138]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]] [[0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.751]] [[0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
using explorer policy with actor:  1
using explorer policy with actor:  1
1238 1106
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
Printing some Q and Qe and total Qs values:  [[0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]] [[-0.235]
 [-0.235]
 [-0.235]
 [-0.235]
 [-0.235]
 [-0.235]
 [-0.235]] [[0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.778]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.282]
 [0.452]
 [0.478]
 [0.442]
 [0.435]
 [0.448]] [[-0.346]
 [ 0.981]
 [-0.263]
 [-0.318]
 [-0.428]
 [-0.568]
 [-0.545]] [[0.507]
 [0.282]
 [0.452]
 [0.478]
 [0.442]
 [0.435]
 [0.448]]
Printing some Q and Qe and total Qs values:  [[0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.465]] [[-0.238]
 [-0.238]
 [-0.238]
 [-0.238]
 [-0.238]
 [-0.238]
 [-0.205]] [[0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.462]
 [0.465]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
siam score:  -0.66976136
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
line 256 mcts: sample exp_bonus 0.7123982565979429
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
1244 1121
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
using another actor
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
using explorer policy with actor:  0
1246 1132
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
Printing some Q and Qe and total Qs values:  [[0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]] [[1.832]
 [1.832]
 [1.832]
 [1.832]
 [1.832]
 [1.832]
 [1.832]] [[0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.661]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
from probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
line 256 mcts: sample exp_bonus 0.8464962638935163
Printing some Q and Qe and total Qs values:  [[0.502]
 [0.502]
 [0.502]
 [0.502]
 [0.502]
 [0.502]
 [0.502]] [[1.508]
 [1.508]
 [1.508]
 [1.508]
 [1.508]
 [1.508]
 [1.508]] [[1.969]
 [1.969]
 [1.969]
 [1.969]
 [1.969]
 [1.969]
 [1.969]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
from probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
Printing some Q and Qe and total Qs values:  [[0.684]
 [0.66 ]
 [0.684]
 [0.684]
 [0.684]
 [0.684]
 [0.684]] [[0.016]
 [1.111]
 [0.016]
 [0.016]
 [0.016]
 [0.016]
 [0.016]] [[0.971]
 [1.574]
 [0.971]
 [0.971]
 [0.971]
 [0.971]
 [0.971]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
first move QE:  0.7344814771554065
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
Printing some Q and Qe and total Qs values:  [[0.418]
 [0.532]
 [0.543]
 [0.663]
 [0.575]
 [0.394]
 [0.346]] [[3.005]
 [3.046]
 [3.062]
 [3.261]
 [2.105]
 [2.066]
 [3.915]] [[0.849]
 [1.006]
 [1.029]
 [1.285]
 [0.507]
 [0.273]
 [1.297]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
Printing some Q and Qe and total Qs values:  [[0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]] [[-0.236]
 [-0.236]
 [-0.236]
 [-0.236]
 [-0.236]
 [-0.236]
 [-0.236]] [[2.387]
 [2.387]
 [2.387]
 [2.387]
 [2.387]
 [2.387]
 [2.387]]
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.712]
 [0.657]
 [0.657]
 [0.657]
 [0.672]
 [0.663]] [[1.373]
 [2.05 ]
 [1.981]
 [1.981]
 [1.981]
 [1.399]
 [1.732]] [[0.83 ]
 [1.407]
 [1.276]
 [1.276]
 [1.276]
 [0.872]
 [1.103]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
1253 1153
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
siam score:  -0.64334136
Printing some Q and Qe and total Qs values:  [[0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.813]] [[1.735]
 [1.735]
 [1.735]
 [1.735]
 [1.735]
 [1.735]
 [1.431]] [[1.013]
 [1.013]
 [1.013]
 [1.013]
 [1.013]
 [1.013]
 [0.787]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.297]
 [0.383]
 [0.301]
 [0.295]
 [0.295]
 [0.31 ]
 [0.291]] [[-0.059]
 [ 1.043]
 [-0.336]
 [-0.625]
 [-0.484]
 [-0.147]
 [-0.467]] [[-0.039]
 [ 1.144]
 [-0.287]
 [-0.567]
 [-0.437]
 [-0.096]
 [-0.427]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
Printing some Q and Qe and total Qs values:  [[0.746]
 [0.876]
 [0.746]
 [0.726]
 [0.726]
 [0.747]
 [0.73 ]] [[-0.142]
 [ 0.992]
 [-0.103]
 [ 1.103]
 [ 1.103]
 [-0.406]
 [ 0.103]] [[0.693]
 [1.691]
 [0.72 ]
 [1.556]
 [1.556]
 [0.505]
 [0.845]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.9662525306708728
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.006437424614618376, 0.015345548437516813, 0.962871478510348, 0.015345548437516813]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
from probs:  [0.0064374246146183785, 0.015345548437516641, 0.9628714785103485, 0.015345548437516641]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3094076479566415, 0.33696485051602076, 0.01666265101131689, 0.33696485051602076]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3274732191859524, 0.3274732191859524, 0.017580342442142814, 0.3274732191859524]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3274732191859524, 0.3274732191859524, 0.017580342442142814, 0.3274732191859524]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.34736706561727665, 0.34736706561727665, 0.018590906246877273, 0.2866749625185694]
UNIT TEST: sample policy line 217 mcts : [0.082 0.49  0.02  0.347 0.02  0.02  0.02 ]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3583251234642601, 0.3268144061105704, 0.019147551572786244, 0.29571291885238327]
from probs:  [0.3583251234642601, 0.3268144061105704, 0.019147551572786244, 0.29571291885238327]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.36984269032867595, 0.3052123454703059, 0.019732618730712078, 0.3052123454703059]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
Printing some Q and Qe and total Qs values:  [[0.657]
 [1.258]
 [0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.657]] [[-0.241]
 [-0.166]
 [-0.241]
 [-0.241]
 [-0.241]
 [-0.241]
 [-0.241]] [[0.729]
 [1.957]
 [0.729]
 [0.729]
 [0.729]
 [0.729]
 [0.729]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.36984269032867595, 0.3052123454703059, 0.019732618730712078, 0.3052123454703059]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.299]
 [0.302]
 [0.379]
 [0.491]
 [0.445]
 [0.447]
 [0.67 ]] [[-0.299]
 [ 0.954]
 [-0.607]
 [-0.507]
 [-0.672]
 [-0.38 ]
 [ 0.002]] [[0.299]
 [0.302]
 [0.379]
 [0.491]
 [0.445]
 [0.447]
 [0.67 ]]
using explorer policy with actor:  0
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.350076849104632, 0.31371366966136277, 0.022495811572642497, 0.31371366966136277]
first move QE:  0.7246203396844201
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.36312830419351483, 0.3254055760202698, 0.02329964721902164, 0.28816647256719363]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3660055660413204, 0.3660055660413204, 0.026090955857641946, 0.2418979120597172]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
Printing some Q and Qe and total Qs values:  [[0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.906]
 [0.889]] [[0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.773]
 [0.857]] [[1.577]
 [1.577]
 [1.577]
 [1.577]
 [1.577]
 [1.577]
 [1.599]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.40696141501364935, 0.40696141501364935, 0.03252607888496538, 0.15355109108773604]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.4293114365905098, 0.37447676911198446, 0.03426193516440443, 0.16194985913310128]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.45393171683407857, 0.3386924150360072, 0.036174115334583444, 0.17120175279533068]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.42035983704294083, 0.3595679729708701, 0.0383487386174668, 0.18172345136872217]
Printing some Q and Qe and total Qs values:  [[0.148]
 [0.436]
 [0.181]
 [0.345]
 [0.323]
 [0.054]
 [0.297]] [[1.782]
 [1.264]
 [1.214]
 [0.285]
 [0.253]
 [0.88 ]
 [0.798]] [[0.611]
 [1.013]
 [0.486]
 [0.503]
 [0.45 ]
 [0.121]
 [0.578]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.38287603177780904, 0.38287603177780904, 0.040776757428678416, 0.19347117901570343]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.38287603177780904, 0.38287603177780904, 0.040776757428678416, 0.19347117901570343]
Printing some Q and Qe and total Qs values:  [[0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.385]] [[1.179]
 [1.179]
 [1.179]
 [1.179]
 [1.179]
 [1.179]
 [0.193]] [[0.468]
 [0.468]
 [0.468]
 [0.468]
 [0.468]
 [0.468]
 [0.157]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.40906806161870796, 0.340754250887053, 0.04350520176993703, 0.20667248572430197]
Printing some Q and Qe and total Qs values:  [[0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.423]
 [0.406]] [[0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.839]] [[0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.899]
 [0.907]]
Printing some Q and Qe and total Qs values:  [[0.203]
 [0.192]
 [0.226]
 [0.224]
 [0.153]
 [0.215]
 [0.181]] [[-0.135]
 [ 0.514]
 [-0.705]
 [-0.78 ]
 [-0.373]
 [-0.63 ]
 [-0.454]] [[-0.108]
 [ 0.085]
 [-0.252]
 [-0.281]
 [-0.289]
 [-0.251]
 [-0.26 ]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
Printing some Q and Qe and total Qs values:  [[-0.007]
 [ 0.216]
 [ 0.219]
 [ 0.357]
 [ 0.27 ]
 [ 0.26 ]
 [ 0.167]] [[3.203]
 [2.367]
 [2.046]
 [1.336]
 [2.102]
 [1.993]
 [2.415]] [[1.055]
 [0.945]
 [0.737]
 [0.539]
 [0.874]
 [0.783]
 [0.878]]
Printing some Q and Qe and total Qs values:  [[0.758]
 [0.78 ]
 [0.758]
 [0.758]
 [0.758]
 [0.758]
 [0.737]] [[-0.006]
 [-0.236]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.855]] [[1.197]
 [1.165]
 [1.197]
 [1.197]
 [1.197]
 [1.197]
 [0.872]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.26488935951556036, 0.26488935951556036, 0.08119422123841652, 0.38902705973046287]
Printing some Q and Qe and total Qs values:  [[0.477]
 [0.443]
 [0.438]
 [0.524]
 [0.467]
 [0.457]
 [0.446]] [[1.442]
 [1.928]
 [1.583]
 [1.383]
 [1.854]
 [2.09 ]
 [1.896]] [[-0.142]
 [ 0.279]
 [-0.062]
 [-0.131]
 [ 0.242]
 [ 0.455]
 [ 0.252]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3024623960014148, 0.3024623960014148, 0.0926128119957557, 0.3024623960014148]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3024623960014148, 0.3024623960014148, 0.0926128119957557, 0.3024623960014148]
Printing some Q and Qe and total Qs values:  [[0.038]
 [0.038]
 [0.038]
 [0.038]
 [0.038]
 [0.038]
 [0.041]] [[0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.953]] [[0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.083]
 [0.163]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.37270992921996515, 0.37270992921996515, 0.16176287723424052, 0.09281726432582926]
siam score:  -0.618415
Printing some Q and Qe and total Qs values:  [[0.08 ]
 [0.394]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]
 [0.08 ]] [[-1.29 ]
 [-0.942]
 [-1.29 ]
 [-1.29 ]
 [-1.29 ]
 [-1.29 ]
 [-1.29 ]] [[-0.651]
 [ 0.095]
 [-0.651]
 [-0.651]
 [-0.651]
 [-0.651]
 [-0.651]]
Printing some Q and Qe and total Qs values:  [[0.317]
 [0.328]
 [0.292]
 [0.293]
 [0.293]
 [0.304]
 [0.318]] [[-2.018]
 [-2.026]
 [-1.962]
 [-1.984]
 [-2.16 ]
 [-2.161]
 [-1.935]] [[0.131]
 [0.151]
 [0.1  ]
 [0.095]
 [0.037]
 [0.058]
 [0.161]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3229264218635576, 0.3229264218635576, 0.22513512569039304, 0.12901203058249175]
from probs:  [0.15996091443629437, 0.4007556432276544, 0.2793225278997569, 0.15996091443629437]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.09325931514895175, 0.37274626478073386, 0.30184372446410485, 0.23215069560620957]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.09325931514895175, 0.37274626478073386, 0.30184372446410485, 0.23215069560620957]
UNIT TEST: sample policy line 217 mcts : [0.184 0.02  0.041 0.327 0.102 0.041 0.286]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.09325931514895175, 0.37274626478073386, 0.30184372446410485, 0.23215069560620957]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.09325931514895175, 0.37274626478073386, 0.30184372446410485, 0.23215069560620957]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.10842356838154796, 0.27014292142434393, 0.35129058876976405, 0.27014292142434393]
first move QE:  0.7095469214318957
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12924723544432604, 0.12924723544432604, 0.419191396267892, 0.32231413284345595]
Printing some Q and Qe and total Qs values:  [[0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.408]] [[-1.485]
 [-1.485]
 [-1.485]
 [-1.485]
 [-1.485]
 [-1.485]
 [-1.597]] [[0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.408]]
Printing some Q and Qe and total Qs values:  [[0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.378]] [[-1.024]
 [-1.024]
 [-1.024]
 [-1.024]
 [-1.024]
 [-1.024]
 [-0.959]] [[0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.378]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12917786145375454, 0.12917786145375454, 0.6124664156387364, 0.12917786145375454]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12917786145375454, 0.12917786145375454, 0.6124664156387364, 0.12917786145375454]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]] [[-1.673]
 [-1.673]
 [-1.673]
 [-1.673]
 [-1.673]
 [-1.673]
 [-1.673]] [[0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]
 [0.467]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12917786145375454, 0.12917786145375454, 0.6124664156387364, 0.12917786145375454]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12917786145375454, 0.12917786145375454, 0.6124664156387364, 0.12917786145375454]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12917786145375454, 0.12917786145375454, 0.6124664156387364, 0.12917786145375454]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12917786145375454, 0.12917786145375454, 0.6124664156387364, 0.12917786145375454]
siam score:  -0.6359488
siam score:  -0.6343648
Printing some Q and Qe and total Qs values:  [[0.457]
 [0.601]
 [0.616]
 [0.616]
 [0.616]
 [0.616]
 [0.655]] [[ 0.9  ]
 [ 0.167]
 [-0.259]
 [-0.259]
 [-0.259]
 [-0.259]
 [-0.433]] [[1.099]
 [1.142]
 [1.03 ]
 [1.03 ]
 [1.03 ]
 [1.03 ]
 [1.05 ]]
first move QE:  0.7049101494007061
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12917786145375454, 0.12917786145375454, 0.6124664156387364, 0.12917786145375454]
Printing some Q and Qe and total Qs values:  [[0.988]
 [0.985]
 [1.205]
 [0.985]
 [0.985]
 [0.976]
 [0.982]] [[-0.278]
 [-0.217]
 [-0.422]
 [-0.217]
 [-0.217]
 [-0.245]
 [-0.204]] [[1.725]
 [1.738]
 [2.112]
 [1.738]
 [1.738]
 [1.711]
 [1.736]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.09350609343474306, 0.2310637505156305, 0.5819240626148834, 0.09350609343474306]
Printing some Q and Qe and total Qs values:  [[0.229]
 [0.222]
 [0.217]
 [0.228]
 [0.269]
 [0.226]
 [0.235]] [[-0.63 ]
 [ 0.525]
 [-0.663]
 [-1.177]
 [-1.207]
 [-0.638]
 [-0.893]] [[0.229]
 [0.222]
 [0.217]
 [0.228]
 [0.269]
 [0.226]
 [0.235]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.09350609343474306, 0.2310637505156305, 0.5819240626148834, 0.09350609343474306]
Printing some Q and Qe and total Qs values:  [[0.342]
 [0.483]
 [0.329]
 [0.557]
 [0.442]
 [0.366]
 [0.441]] [[0.698]
 [0.714]
 [0.698]
 [0.816]
 [0.702]
 [0.715]
 [0.73 ]] [[0.703]
 [0.991]
 [0.676]
 [1.172]
 [0.904]
 [0.756]
 [0.911]]
siam score:  -0.63274574
first move QE:  0.7025842931611678
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.09350609343474306, 0.2310637505156305, 0.5819240626148834, 0.09350609343474306]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.0663509646219279, 0.26069044230913596, 0.5100197443270181, 0.16293884874191797]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.07346306968713974, 0.1805619127123474, 0.5654131048881657, 0.1805619127123474]
from probs:  [0.07346306968713974, 0.1805619127123474, 0.5654131048881657, 0.1805619127123474]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.08219407246937419, 0.08219407246937419, 0.633415416544445, 0.2021964385168065]
siam score:  -0.63413936
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.08219407246937419, 0.08219407246937419, 0.633415416544445, 0.2021964385168065]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
from probs:  [0.08219407246937419, 0.08219407246937419, 0.633415416544445, 0.2021964385168065]
Printing some Q and Qe and total Qs values:  [[0.33 ]
 [0.328]
 [0.328]
 [0.328]
 [0.333]
 [0.328]
 [0.361]] [[-1.694]
 [-1.224]
 [-1.224]
 [-1.224]
 [-1.605]
 [-1.224]
 [-1.314]] [[0.33 ]
 [0.328]
 [0.328]
 [0.328]
 [0.333]
 [0.328]
 [0.361]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.06056014604504449, 0.14805711404066427, 0.5547807899978218, 0.2366019499164696]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.06056014604504449, 0.14805711404066427, 0.5547807899978218, 0.2366019499164696]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.04803093346837582, 0.18620146345772587, 0.5092398219569235, 0.2565277811169747]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.04803093346837582, 0.18620146345772587, 0.5092398219569235, 0.2565277811169747]
Printing some Q and Qe and total Qs values:  [[0.438]
 [0.446]
 [0.472]
 [0.437]
 [0.446]
 [0.45 ]
 [0.44 ]] [[ 0.266]
 [ 0.955]
 [ 0.236]
 [-0.126]
 [-0.388]
 [-0.139]
 [-0.152]] [[0.438]
 [0.446]
 [0.472]
 [0.437]
 [0.446]
 [0.45 ]
 [0.44 ]]
siam score:  -0.6308112
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.05160426137979655, 0.20027185689519075, 0.5478520248298219, 0.20027185689519075]
Printing some Q and Qe and total Qs values:  [[1.381]
 [1.381]
 [1.381]
 [1.381]
 [1.381]
 [1.381]
 [1.381]] [[0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]
 [0.701]] [[2.176]
 [2.176]
 [2.176]
 [2.176]
 [2.176]
 [2.176]
 [2.176]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.05160426137979655, 0.20027185689519075, 0.5478520248298219, 0.20027185689519075]
Printing some Q and Qe and total Qs values:  [[0.26 ]
 [0.322]
 [0.273]
 [0.256]
 [0.256]
 [0.259]
 [0.277]] [[-1.132]
 [-0.622]
 [-1.122]
 [-0.944]
 [-0.944]
 [-1.078]
 [-1.108]] [[0.26 ]
 [0.322]
 [0.273]
 [0.256]
 [0.256]
 [0.259]
 [0.277]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.05160426137979655, 0.20027185689519075, 0.5478520248298219, 0.20027185689519075]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.05571193521300565, 0.21644629942572616, 0.5922381934981527, 0.13560357186311559]
from probs:  [0.05571193521300565, 0.21644629942572616, 0.5922381934981527, 0.13560357186311559]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.05571193521300565, 0.21644629942572616, 0.5922381934981527, 0.13560357186311559]
Printing some Q and Qe and total Qs values:  [[0.713]
 [1.001]
 [0.713]
 [0.713]
 [0.713]
 [0.713]
 [0.713]] [[-0.415]
 [ 1.027]
 [-0.415]
 [-0.415]
 [-0.415]
 [-0.415]
 [-0.415]] [[0.595]
 [1.482]
 [0.595]
 [0.595]
 [0.595]
 [0.595]
 [0.595]]
UNIT TEST: sample policy line 217 mcts : [0.041 0.143 0.735 0.02  0.02  0.02  0.02 ]
Printing some Q and Qe and total Qs values:  [[0.703]
 [1.064]
 [0.703]
 [0.703]
 [0.703]
 [0.703]
 [0.7  ]] [[-0.368]
 [ 0.497]
 [-0.368]
 [-0.368]
 [-0.368]
 [-0.368]
 [-0.533]] [[0.477]
 [1.353]
 [0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.382]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.05571193521300565, 0.21644629942572616, 0.5922381934981527, 0.13560357186311559]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.05571193521300565, 0.21644629942572616, 0.5922381934981527, 0.13560357186311559]
siam score:  -0.63598543
using explorer policy with actor:  0
siam score:  -0.6372924
using explorer policy with actor:  0
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.779]
 [0.779]
 [0.779]
 [0.779]
 [0.779]
 [0.779]
 [0.779]] [[0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.689]] [[0.779]
 [0.779]
 [0.779]
 [0.779]
 [0.779]
 [0.779]
 [0.779]]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 1.3472680289438832
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3307828328174935, 0.33550821582656287, 0.002926118538449955, 0.3307828328174935]
Printing some Q and Qe and total Qs values:  [[0.5  ]
 [0.619]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.626]] [[0.797]
 [1.072]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.125]] [[1.723]
 [1.958]
 [1.648]
 [1.648]
 [1.648]
 [1.648]
 [1.473]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.32764430458061666, 0.3370840640661633, 0.002935211028317034, 0.33233642032490307]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.367]
 [0.56 ]
 [0.415]
 [0.56 ]
 [0.35 ]
 [0.667]
 [0.335]] [[1.466]
 [1.41 ]
 [1.651]
 [1.41 ]
 [1.559]
 [1.101]
 [1.132]] [[1.863]
 [2.034]
 [2.05 ]
 [2.034]
 [1.912]
 [1.924]
 [1.584]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.32764430458061666, 0.3370840640661633, 0.002935211028317034, 0.33233642032490307]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3291903902756046, 0.33867482985779374, 0.0029443895909970065, 0.3291903902756046]
Printing some Q and Qe and total Qs values:  [[0.022]
 [0.022]
 [0.022]
 [0.022]
 [0.022]
 [0.022]
 [1.452]] [[1.654]
 [1.654]
 [1.654]
 [1.654]
 [1.654]
 [1.654]
 [0.673]] [[0.654]
 [0.654]
 [0.654]
 [0.654]
 [0.654]
 [0.654]
 [2.206]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.33708950438213325, 0.3323178508480455, 0.002991283831192142, 0.3276013609386291]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.467]
 [0.424]
 [0.436]
 [0.436]
 [0.428]
 [0.48 ]] [[-0.339]
 [-0.083]
 [-0.503]
 [-0.407]
 [-0.407]
 [-0.595]
 [-0.234]] [[0.451]
 [0.467]
 [0.424]
 [0.436]
 [0.436]
 [0.428]
 [0.48 ]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
Printing some Q and Qe and total Qs values:  [[0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.486]
 [0.512]] [[ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [-0.344]
 [ 0.   ]] [[0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.486]
 [0.512]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.043309096795500726
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.594]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]] [[0.304]
 [0.408]
 [0.304]
 [0.304]
 [0.304]
 [0.304]
 [0.304]] [[0.587]
 [0.594]
 [0.587]
 [0.587]
 [0.587]
 [0.587]
 [0.587]]
Printing some Q and Qe and total Qs values:  [[0.227]
 [0.524]
 [0.569]
 [0.506]
 [0.435]
 [0.546]
 [0.744]] [[1.976]
 [0.684]
 [1.039]
 [0.292]
 [1.869]
 [1.078]
 [1.751]] [[0.227]
 [0.524]
 [0.569]
 [0.506]
 [0.435]
 [0.546]
 [0.744]]
using another actor
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3323266163549702, 0.3323266163549702, 0.003020150935089461, 0.3323266163549702]
Printing some Q and Qe and total Qs values:  [[0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.623]] [[2.406]
 [2.406]
 [2.406]
 [2.406]
 [2.406]
 [2.406]
 [2.6  ]] [[0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.626]
 [0.623]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.081]
 [0.351]
 [0.409]
 [0.261]
 [0.368]
 [0.384]
 [0.34 ]] [[ 1.456]
 [ 0.944]
 [-0.797]
 [ 1.258]
 [ 0.232]
 [-0.681]
 [ 0.769]] [[0.081]
 [0.351]
 [0.409]
 [0.261]
 [0.368]
 [0.384]
 [0.34 ]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3355035340192184, 0.33072845345352, 0.003039559073741591, 0.33072845345352]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3355035340192184, 0.33072845345352, 0.003039559073741591, 0.33072845345352]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3355035340192184, 0.33072845345352, 0.003039559073741591, 0.33072845345352]
from probs:  [0.3355035340192184, 0.33072845345352, 0.003039559073741591, 0.33072845345352]
first move QE:  0.6974136328753587
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3370964451160391, 0.3275556387292047, 0.0030492903424412885, 0.3322986258123148]
siam score:  -0.6432989
Printing some Q and Qe and total Qs values:  [[0.266]
 [0.276]
 [0.288]
 [0.266]
 [0.266]
 [0.266]
 [0.266]] [[0.525]
 [1.202]
 [0.227]
 [0.525]
 [0.525]
 [0.525]
 [0.525]] [[0.266]
 [0.276]
 [0.288]
 [0.266]
 [0.266]
 [0.266]
 [0.266]]
using explorer policy with actor:  0
using explorer policy with actor:  0
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3370964451160391, 0.3275556387292047, 0.0030492903424412885, 0.3322986258123148]
Printing some Q and Qe and total Qs values:  [[0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]] [[1.733]
 [1.733]
 [1.733]
 [1.733]
 [1.733]
 [1.733]
 [1.733]] [[0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]
 [0.62]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.3370964451160391, 0.3275556387292047, 0.0030492903424412885, 0.3322986258123148]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
Printing some Q and Qe and total Qs values:  [[0.655]
 [0.519]
 [0.614]
 [0.614]
 [0.614]
 [0.608]
 [0.635]] [[1.976]
 [1.832]
 [1.48 ]
 [1.48 ]
 [1.48 ]
 [1.549]
 [0.214]] [[0.655]
 [0.519]
 [0.614]
 [0.614]
 [0.614]
 [0.608]
 [0.635]]
actor:  1 policy actor:  1  step number:  54 total reward:  0.47499999999999964  reward:  1.0 rdn_beta:  0.333
Printing some Q and Qe and total Qs values:  [[0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.901]] [[0.961]
 [0.961]
 [0.961]
 [0.961]
 [0.961]
 [0.961]
 [1.929]] [[0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.711]
 [0.901]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12129148488386393, 0.7574033287676254, 0.0017309141575190252, 0.11957427219099154]
Printing some Q and Qe and total Qs values:  [[0.785]
 [0.787]
 [0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.931]] [[0.925]
 [1.149]
 [0.925]
 [0.925]
 [0.925]
 [0.925]
 [1.135]] [[0.785]
 [0.787]
 [0.785]
 [0.785]
 [0.785]
 [0.785]
 [0.931]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.795]
 [0.769]
 [0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.882]] [[1.01 ]
 [1.12 ]
 [1.01 ]
 [1.01 ]
 [1.01 ]
 [1.01 ]
 [1.353]] [[0.795]
 [0.769]
 [0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.882]]
Printing some Q and Qe and total Qs values:  [[0.719]
 [0.727]
 [0.719]
 [0.719]
 [0.719]
 [0.719]
 [0.916]] [[1.348]
 [1.812]
 [1.348]
 [1.348]
 [1.348]
 [1.348]
 [1.744]] [[0.719]
 [0.727]
 [0.719]
 [0.719]
 [0.719]
 [0.719]
 [0.916]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12149686384845271, 0.7586947336066919, 0.0017321688401523922, 0.11807623370470283]
Printing some Q and Qe and total Qs values:  [[0.64 ]
 [0.557]
 [0.761]
 [0.562]
 [0.761]
 [0.565]
 [0.552]] [[0.824]
 [1.106]
 [0.899]
 [0.448]
 [0.899]
 [0.861]
 [0.571]] [[0.64 ]
 [0.557]
 [0.761]
 [0.562]
 [0.761]
 [0.565]
 [0.552]]
maxi score, test score, baseline:  -0.99464 -1.0 -0.99464
probs:  [0.12149686384845271, 0.7586947336066919, 0.0017321688401523922, 0.11807623370470283]
Printing some Q and Qe and total Qs values:  [[0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.589]] [[0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.771]] [[0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.589]]
actor:  0 policy actor:  1  step number:  68 total reward:  0.4249999999999996  reward:  1.0 rdn_beta:  0.667
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1211950009621175, 0.7592961296274321, 0.001732942616734631, 0.11777592679371594]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1211950009621175, 0.7592961296274321, 0.001732942616734631, 0.11777592679371594]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.12183745357702992, 0.7580255602313648, 0.0017368814226469353, 0.11840010476895818]
Printing some Q and Qe and total Qs values:  [[0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]] [[0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]
 [0.814]] [[0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]
 [0.597]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]] [[0.103]
 [0.103]
 [0.103]
 [0.103]
 [0.103]
 [0.103]
 [0.103]] [[0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]]
Printing some Q and Qe and total Qs values:  [[0.635]
 [0.599]
 [0.636]
 [0.629]
 [0.627]
 [0.631]
 [0.674]] [[1.652]
 [3.193]
 [1.997]
 [2.067]
 [2.121]
 [2.029]
 [0.386]] [[0.635]
 [0.599]
 [0.636]
 [0.629]
 [0.627]
 [0.631]
 [0.674]]
line 256 mcts: sample exp_bonus 2.554625922937329
Printing some Q and Qe and total Qs values:  [[0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.606]] [[2.639]
 [2.639]
 [2.639]
 [2.639]
 [2.639]
 [2.639]
 [3.414]] [[0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.606]]
Printing some Q and Qe and total Qs values:  [[0.744]
 [0.845]
 [0.744]
 [0.744]
 [0.744]
 [0.744]
 [0.842]] [[-0.246]
 [ 0.627]
 [-0.246]
 [-0.246]
 [-0.246]
 [-0.246]
 [ 0.651]] [[0.995]
 [1.629]
 [0.995]
 [0.995]
 [0.995]
 [0.995]
 [1.637]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.12412006387909921, 0.7517643831668608, 0.0017618302900495428, 0.12235372266399051]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
line 256 mcts: sample exp_bonus 1.7465046189489577
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.4332137575731863
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.12560551289885472, 0.7505728934263554, 0.0017710695751458785, 0.12205052409964408]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.12560551289885472, 0.7505728934263554, 0.0017710695751458785, 0.12205052409964408]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.12623951273120704, 0.749319037775298, 0.0017750129654098513, 0.12266643652808533]
from probs:  [0.12623951273120704, 0.749319037775298, 0.0017750129654098513, 0.12266643652808533]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1268731122493589, 0.7480659738219613, 0.001778953865775499, 0.1232819600629043]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1268731122493589, 0.7480659738219613, 0.001778953865775499, 0.1232819600629043]
Printing some Q and Qe and total Qs values:  [[0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]] [[-1.449]
 [-1.449]
 [-1.449]
 [-1.449]
 [-1.449]
 [-1.449]
 [-1.449]] [[0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]
 [0.549]]
using explorer policy with actor:  1
rdn probs:  [0.12750631183233482, 0.7468137008167526, 0.0017828922786003018, 0.12389709507231231]
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.759]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.739]] [[0.912]
 [1.261]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [1.161]] [[0.657]
 [0.759]
 [0.661]
 [0.661]
 [0.661]
 [0.661]
 [0.739]]
line 256 mcts: sample exp_bonus 1.9100141448349266
first move QE:  0.6893687342075309
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12004501295389232, 0.7616809933693854, 0.0018033937729794488, 0.11647059990374278]
start point for exploration sampling:  10768
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.924]] [[0.752]
 [0.752]
 [0.752]
 [0.752]
 [0.752]
 [0.752]
 [0.71 ]] [[1.239]
 [1.239]
 [1.239]
 [1.239]
 [1.239]
 [1.239]
 [1.732]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12126032694230668, 0.7592786127250463, 0.0018116359052400136, 0.117649424427407]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12247460773449041, 0.7568782744587675, 0.0018198710304718885, 0.11882724677627021]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
1314 1250
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12368785664743748, 0.7544799759671716, 0.0018280991576067889, 0.1200040682277841]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12451976020724985, 0.7546584574631611, 0.001833741040472759, 0.11898804128911622]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12474370393441815, 0.7560248180538179, 0.0018352598033898658, 0.11739621820837408]
UNIT TEST: sample policy line 217 mcts : [0.224 0.245 0.122 0.204 0.02  0.082 0.102]
Printing some Q and Qe and total Qs values:  [[0.039]
 [0.18 ]
 [0.039]
 [0.039]
 [0.039]
 [0.039]
 [0.039]] [[-0.195]
 [ 0.884]
 [-0.195]
 [-0.195]
 [-0.195]
 [-0.195]
 [-0.195]] [[-0.348]
 [ 0.294]
 [-0.348]
 [-0.348]
 [-0.348]
 [-0.348]
 [-0.348]]
Printing some Q and Qe and total Qs values:  [[0.085]
 [0.085]
 [0.085]
 [0.085]
 [0.089]
 [0.085]
 [0.091]] [[-1.755]
 [-1.755]
 [-1.755]
 [-1.755]
 [-1.331]
 [-1.755]
 [-1.321]] [[0.085]
 [0.085]
 [0.085]
 [0.085]
 [0.089]
 [0.085]
 [0.091]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.116189612125166
Printing some Q and Qe and total Qs values:  [[0.587]
 [0.61 ]
 [0.617]
 [0.613]
 [0.606]
 [0.592]
 [0.598]] [[2.895]
 [3.144]
 [3.493]
 [2.509]
 [1.914]
 [3.54 ]
 [3.499]] [[0.587]
 [0.61 ]
 [0.617]
 [0.613]
 [0.606]
 [0.592]
 [0.598]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12370786849979011, 0.7562598220596456, 0.0018409924547061404, 0.11819131698585814]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12370786849979011, 0.7562598220596456, 0.0018409924547061404, 0.11819131698585814]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12370786849979011, 0.7562598220596456, 0.0018409924547061404, 0.11819131698585814]
line 256 mcts: sample exp_bonus 2.082508000809423
first move QE:  0.6841904349238196
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12370786849979011, 0.7562598220596456, 0.0018409924547061404, 0.11819131698585814]
Printing some Q and Qe and total Qs values:  [[0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]] [[1.017]
 [1.017]
 [1.017]
 [1.017]
 [1.017]
 [1.017]
 [1.017]] [[0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]
 [0.607]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.998203901469508
from probs:  [0.1255169387762535, 0.7527105518504716, 0.0018534494576109587, 0.11991905991566393]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.126954803414179, 0.7517348885867575, 0.001863350390816488, 0.11944695760824697]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12816333041963618, 0.7493815477748892, 0.0018716721374138403, 0.12058344966806074]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12816333041963618, 0.7493815477748892, 0.0018716721374138403, 0.12058344966806074]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12816333041963618, 0.7493815477748892, 0.0018716721374138403, 0.12058344966806074]
Printing some Q and Qe and total Qs values:  [[0.546]
 [0.546]
 [0.584]
 [0.546]
 [0.546]
 [0.534]
 [0.546]] [[0.575]
 [0.575]
 [0.801]
 [0.575]
 [0.575]
 [0.851]
 [0.575]] [[0.546]
 [0.546]
 [0.584]
 [0.546]
 [0.546]
 [0.534]
 [0.546]]
Printing some Q and Qe and total Qs values:  [[0.805]
 [1.001]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[0.292]
 [1.891]
 [0.292]
 [0.292]
 [0.292]
 [0.292]
 [0.292]] [[1.531]
 [2.457]
 [1.531]
 [1.531]
 [1.531]
 [1.531]
 [1.531]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
Printing some Q and Qe and total Qs values:  [[0.464]
 [0.493]
 [0.453]
 [0.47 ]
 [0.47 ]
 [0.454]
 [0.464]] [[-0.25 ]
 [-0.587]
 [-0.517]
 [ 0.   ]
 [ 0.   ]
 [-0.716]
 [-0.527]] [[0.464]
 [0.493]
 [0.453]
 [0.47 ]
 [0.47 ]
 [0.454]
 [0.464]]
Printing some Q and Qe and total Qs values:  [[0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.637]] [[0.638]
 [0.638]
 [0.638]
 [0.638]
 [0.638]
 [0.638]
 [0.621]] [[0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.637]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12900517806192205, 0.7495967628240131, 0.001877468981606024, 0.11952059013245875]
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.769]
 [0.582]
 [0.582]
 [0.582]
 [0.582]
 [0.582]] [[0.834]
 [2.085]
 [0.834]
 [0.834]
 [0.834]
 [0.834]
 [0.834]] [[1.111]
 [1.847]
 [1.111]
 [1.111]
 [1.111]
 [1.111]
 [1.111]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12900517806192205, 0.7495967628240131, 0.001877468981606024, 0.11952059013245875]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12900517806192205, 0.7495967628240131, 0.001877468981606024, 0.11952059013245875]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12900517806192205, 0.7495967628240131, 0.001877468981606024, 0.11952059013245875]
Printing some Q and Qe and total Qs values:  [[0.11 ]
 [0.403]
 [0.255]
 [0.255]
 [0.255]
 [0.255]
 [0.327]] [[1.993]
 [2.435]
 [2.419]
 [2.419]
 [2.419]
 [2.419]
 [2.186]] [[0.993]
 [1.525]
 [1.34 ]
 [1.34 ]
 [1.34 ]
 [1.34 ]
 [1.334]]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[-0.072]
 [-0.062]
 [-0.047]
 [-0.06 ]
 [-0.033]
 [-0.033]
 [-0.074]] [[2.183]
 [3.224]
 [3.949]
 [1.022]
 [3.12 ]
 [3.12 ]
 [3.135]] [[-0.497]
 [ 0.197]
 [ 0.695]
 [-1.224]
 [ 0.186]
 [ 0.186]
 [ 0.116]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12791032479431558, 0.7498911099248753, 0.0018833783030598882, 0.12031518697774927]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12791032479431558, 0.7498911099248753, 0.0018833783030598882, 0.12031518697774927]
Printing some Q and Qe and total Qs values:  [[1.122]
 [1.122]
 [1.122]
 [1.122]
 [1.122]
 [1.122]
 [1.122]] [[0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.67 ]] [[2.013]
 [2.013]
 [2.013]
 [2.013]
 [2.013]
 [2.013]
 [2.007]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.12850927626450737, 0.7487248632414064, 0.0018875660656453115, 0.12087829442844109]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.539]
 [0.539]
 [0.539]
 [0.539]
 [0.539]
 [0.539]
 [0.539]] [[2.174]
 [2.174]
 [2.174]
 [2.174]
 [2.174]
 [2.174]
 [2.174]] [[1.649]
 [1.649]
 [1.649]
 [1.649]
 [1.649]
 [1.649]
 [1.649]]
siam score:  -0.6330849
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.131501197889794, 0.7428991513993896, 0.0019084850516808286, 0.12369116565913556]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.131501197889794, 0.7428991513993896, 0.0019084850516808286, 0.12369116565913556]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13175043747756804, 0.7443160425058049, 0.0019102276907299529, 0.12202329232589715]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13175043747756804, 0.7443160425058049, 0.0019102276907299529, 0.12202329232589715]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13001874764477395, 0.7458036849244656, 0.0019120573470515665, 0.12226551008370887]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13001874764477395, 0.7458036849244656, 0.0019120573470515665, 0.12226551008370887]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
Printing some Q and Qe and total Qs values:  [[1.14 ]
 [0.685]
 [0.685]
 [0.685]
 [0.685]
 [0.685]
 [0.685]] [[0.432]
 [0.611]
 [0.611]
 [0.611]
 [0.611]
 [0.611]
 [0.611]] [[1.533]
 [0.741]
 [0.741]
 [0.741]
 [0.741]
 [0.741]
 [0.741]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13085900805174716, 0.7460650269213289, 0.0019180230657931227, 0.1211579419611309]
Printing some Q and Qe and total Qs values:  [[0.366]
 [0.361]
 [0.361]
 [0.361]
 [0.361]
 [0.361]
 [0.361]] [[0.161]
 [0.053]
 [0.053]
 [0.053]
 [0.053]
 [0.053]
 [0.053]] [[-0.315]
 [-0.397]
 [-0.397]
 [-0.397]
 [-0.397]
 [-0.397]
 [-0.397]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13204975760101953, 0.7437640254328473, 0.0019264772031577317, 0.12225973976297558]
Printing some Q and Qe and total Qs values:  [[0.326]
 [0.319]
 [0.323]
 [0.319]
 [0.319]
 [0.319]
 [0.34 ]] [[-0.24 ]
 [-0.048]
 [-0.262]
 [-0.048]
 [-0.048]
 [-0.048]
 [-0.212]] [[-0.044]
 [ 0.07 ]
 [-0.065]
 [ 0.07 ]
 [ 0.07 ]
 [ 0.07 ]
 [ 0.001]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13204975760101953, 0.7437640254328473, 0.0019264772031577317, 0.12225973976297558]
Printing some Q and Qe and total Qs values:  [[0.485]
 [0.128]
 [0.485]
 [0.562]
 [0.521]
 [0.509]
 [0.53 ]] [[-1.437]
 [ 1.009]
 [-1.561]
 [-1.671]
 [-1.557]
 [-1.377]
 [-1.352]] [[0.282]
 [0.974]
 [0.22 ]
 [0.281]
 [0.276]
 [0.349]
 [0.394]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1308960894683243, 0.7441144369140272, 0.0019325936906243334, 0.12305687992702408]
siam score:  -0.6338457
first move QE:  0.6739086936293512
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
Printing some Q and Qe and total Qs values:  [[0.737]
 [0.737]
 [0.737]
 [0.737]
 [0.737]
 [0.737]
 [0.737]] [[1.797]
 [1.797]
 [1.797]
 [1.797]
 [1.797]
 [1.797]
 [1.797]] [[1.902]
 [1.902]
 [1.902]
 [1.902]
 [1.902]
 [1.902]
 [1.902]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13148436355610554, 0.7429691484545473, 0.0019368351387552452, 0.12360965285059165]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13148436355610554, 0.7429691484545473, 0.0019368351387552452, 0.12360965285059165]
siam score:  -0.6330311
Printing some Q and Qe and total Qs values:  [[0.482]
 [0.41 ]
 [0.421]
 [0.444]
 [0.411]
 [0.454]
 [0.36 ]] [[-0.556]
 [ 1.619]
 [-0.08 ]
 [ 0.402]
 [-0.495]
 [-0.359]
 [ 0.191]] [[-0.103]
 [ 0.478]
 [-0.067]
 [ 0.141]
 [-0.225]
 [-0.094]
 [-0.098]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[-0.016]
 [-0.016]
 [-0.016]
 [-0.016]
 [-0.016]
 [ 1.169]
 [-0.016]] [[1.72 ]
 [1.72 ]
 [1.72 ]
 [1.72 ]
 [1.72 ]
 [0.746]
 [1.72 ]] [[0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [1.36 ]
 [0.819]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1329163907094859, 0.742117092587038, 0.0019471600349546135, 0.12301935666852148]
Printing some Q and Qe and total Qs values:  [[0.942]
 [0.964]
 [0.964]
 [0.964]
 [0.964]
 [0.964]
 [0.964]] [[0.853]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.663]] [[1.963]
 [1.891]
 [1.891]
 [1.891]
 [1.891]
 [1.891]
 [1.891]]
Printing some Q and Qe and total Qs values:  [[0.464]
 [0.271]
 [0.271]
 [0.271]
 [0.271]
 [0.271]
 [0.271]] [[0.418]
 [0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.366]] [[0.867]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13232399784810808, 0.7413545106633044, 0.0019576400647959005, 0.12436385142379153]
Printing some Q and Qe and total Qs values:  [[0.386]
 [0.387]
 [0.386]
 [0.386]
 [0.386]
 [0.386]
 [0.386]] [[0.165]
 [0.899]
 [0.165]
 [0.165]
 [0.165]
 [0.165]
 [0.165]] [[0.873]
 [1.366]
 [0.873]
 [0.873]
 [0.873]
 [0.873]
 [0.873]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13407327763926816, 0.7379491709221921, 0.0019704488328151763, 0.12600710260572442]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13407327763926816, 0.7379491709221921, 0.0019704488328151763, 0.12600710260572442]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13407327763926816, 0.7379491709221921, 0.0019704488328151763, 0.12600710260572442]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13407327763926816, 0.7379491709221921, 0.0019704488328151763, 0.12600710260572442]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 1.946327408367269
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13286962752628956, 0.7383388895945907, 0.0019767441719460376, 0.12681473870717366]
Printing some Q and Qe and total Qs values:  [[0.414]
 [0.443]
 [0.438]
 [0.438]
 [0.438]
 [0.476]
 [0.408]] [[-1.172]
 [-0.753]
 [-1.364]
 [-1.364]
 [-1.364]
 [-0.914]
 [-0.941]] [[0.414]
 [0.443]
 [0.438]
 [0.438]
 [0.438]
 [0.476]
 [0.408]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13344576435877123, 0.7372087842070468, 0.0019810288324814064, 0.1273644226017005]
1347 1277
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13459770966917997, 0.7349492175068217, 0.001989595711618696, 0.12846347711237957]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13459770966917997, 0.7349492175068217, 0.001989595711618696, 0.12846347711237957]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13459770966917997, 0.7349492175068217, 0.001989595711618696, 0.12846347711237957]
from probs:  [0.13459770966917997, 0.7349492175068217, 0.001989595711618696, 0.12846347711237957]
first move QE:  0.6688230338686466
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13517351820948018, 0.7338197560717941, 0.001993877930684479, 0.12901284778804123]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13517351820948018, 0.7338197560717941, 0.001993877930684479, 0.12901284778804123]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
using explorer policy with actor:  1
from probs:  [0.13747565899845465, 0.7293040550059586, 0.0020109986756694743, 0.13120928731991718]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1380509210083379, 0.7281756656026671, 0.002015276830254084, 0.13175813655874102]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13833386484416454, 0.7296768960716058, 0.002017381049631745, 0.1299718580345977]
Printing some Q and Qe and total Qs values:  [[0.825]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]] [[3.52 ]
 [0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.897]] [[0.825]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]
 [0.682]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13948883522935385, 0.7274286879105176, 0.002025970425887424, 0.13105650643424108]
Printing some Q and Qe and total Qs values:  [[0.974]
 [0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]
 [0.947]] [[0.958]
 [0.796]
 [0.796]
 [0.796]
 [0.796]
 [0.796]
 [0.796]] [[2.119]
 [1.972]
 [1.972]
 [1.972]
 [1.972]
 [1.972]
 [1.972]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14006617100342988, 0.7263048746806631, 0.002030264002807659, 0.1315986903130995]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14006617100342988, 0.7263048746806631, 0.002030264002807659, 0.1315986903130995]
using another actor
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14064340719952226, 0.7251812552843805, 0.0020345568391783695, 0.13214078067691887]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14179758096078843, 0.7229345977919744, 0.00204314029103746, 0.13322468095619977]
Printing some Q and Qe and total Qs values:  [[0.571]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.719]] [[2.113]
 [1.31 ]
 [1.31 ]
 [1.31 ]
 [1.31 ]
 [1.31 ]
 [2.768]] [[1.311]
 [0.865]
 [0.865]
 [0.865]
 [0.865]
 [0.865]
 [2.027]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1429513567191285, 0.7206887150323561, 0.002051720782996516, 0.13430820746551875]
using explorer policy with actor:  1
using another actor
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14352809541153017, 0.7195660640521233, 0.002056009919491938, 0.13484983061685465]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14352809541153017, 0.7195660640521233, 0.002056009919491938, 0.13484983061685465]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1416339909656166, 0.7211607593847004, 0.0020583623240516048, 0.1351468873256313]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1416339909656166, 0.7211607593847004, 0.0020583623240516048, 0.1351468873256313]
line 256 mcts: sample exp_bonus 4.816028762004799
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1416339909656166, 0.7211607593847004, 0.0020583623240516048, 0.1351468873256313]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1406146921085969, 0.7231739648785365, 0.0020673154660322147, 0.13414402754683435]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1406146921085969, 0.7231739648785365, 0.0020673154660322147, 0.13414402754683435]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1406146921085969, 0.7231739648785365, 0.0020673154660322147, 0.13414402754683435]
first move QE:  0.6659208504484837
Printing some Q and Qe and total Qs values:  [[0.453]
 [0.46 ]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.46 ]] [[3.332]
 [4.066]
 [3.332]
 [3.332]
 [3.332]
 [3.332]
 [3.844]] [[0.453]
 [0.46 ]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.46 ]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1406146921085969, 0.7231739648785365, 0.0020673154660322147, 0.13414402754683435]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.842]
 [0.528]
 [0.661]
 [0.588]
 [0.588]
 [0.657]
 [0.714]] [[0.866]
 [1.443]
 [0.998]
 [1.253]
 [1.253]
 [1.163]
 [1.259]] [[0.842]
 [0.528]
 [0.661]
 [0.588]
 [0.588]
 [0.657]
 [0.714]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14091116468468337, 0.7247074700139922, 0.002069590311633539, 0.132311774989691]
Printing some Q and Qe and total Qs values:  [[0.599]
 [0.583]
 [0.594]
 [0.594]
 [0.594]
 [0.594]
 [0.613]] [[1.478]
 [1.42 ]
 [1.402]
 [1.402]
 [1.402]
 [1.402]
 [1.14 ]] [[1.882]
 [1.811]
 [1.822]
 [1.822]
 [1.822]
 [1.822]
 [1.685]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14091116468468337, 0.7247074700139922, 0.002069590311633539, 0.132311774989691]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1414797799728737, 0.7236008243577225, 0.002073953318844053, 0.1328454423505596]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1414797799728737, 0.7236008243577225, 0.002073953318844053, 0.1328454423505596]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14204833724762236, 0.722494291607885, 0.0020783158809151744, 0.13337905526357743]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14204833724762236, 0.722494291607885, 0.0020783158809151744, 0.13337905526357743]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14204833724762236, 0.722494291607885, 0.0020783158809151744, 0.13337905526357743]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14204833724762236, 0.722494291607885, 0.0020783158809151744, 0.13337905526357743]
Printing some Q and Qe and total Qs values:  [[0.064]
 [0.018]
 [0.043]
 [0.101]
 [0.044]
 [0.04 ]
 [0.036]] [[3.559]
 [3.177]
 [4.449]
 [3.491]
 [3.783]
 [3.668]
 [3.652]] [[0.977]
 [0.733]
 [1.443]
 [0.97 ]
 [1.082]
 [1.017]
 [1.004]]
Printing some Q and Qe and total Qs values:  [[-0.001]
 [-0.006]
 [-0.001]
 [ 0.002]
 [ 0.002]
 [ 0.   ]
 [-0.001]] [[3.896]
 [3.504]
 [3.519]
 [3.728]
 [3.728]
 [2.892]
 [3.251]] [[0.791]
 [0.535]
 [0.549]
 [0.686]
 [0.686]
 [0.148]
 [0.377]]
Printing some Q and Qe and total Qs values:  [[0.779]
 [0.779]
 [0.777]
 [0.777]
 [0.777]
 [0.777]
 [0.776]] [[1.138]
 [1.157]
 [1.143]
 [1.131]
 [1.117]
 [1.12 ]
 [1.134]] [[0.192]
 [0.213]
 [0.195]
 [0.181]
 [0.165]
 [0.169]
 [0.184]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14264511717674785, 0.7255468871682873, 0.002082894996510451, 0.12972510065845444]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
first move QE:  0.6663549200035445
Printing some Q and Qe and total Qs values:  [[0.63 ]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]] [[-0.62 ]
 [-0.245]
 [-1.038]
 [-1.038]
 [-1.038]
 [-1.038]
 [-1.038]] [[0.63 ]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]]
Printing some Q and Qe and total Qs values:  [[0.07 ]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.105]
 [0.07 ]] [[1.987]
 [1.987]
 [1.987]
 [1.987]
 [1.987]
 [1.479]
 [1.987]] [[0.07 ]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.105]
 [0.07 ]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14439046225062843, 0.7263781697567102, 0.0020962870971105115, 0.12713508089555092]
1369 1296
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14554660014633458, 0.7241961468138907, 0.0021051581881277245, 0.12815209485164697]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14554660014633458, 0.7241961468138907, 0.0021051581881277245, 0.12815209485164697]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14554660014633458, 0.7241961468138907, 0.0021051581881277245, 0.12815209485164697]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1461246393981355, 0.7231051913889677, 0.0021095935057773682, 0.12866057570711945]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1461246393981355, 0.7231051913889677, 0.0021095935057773682, 0.12866057570711945]
Printing some Q and Qe and total Qs values:  [[-0.004]
 [-0.025]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]
 [-0.004]] [[-0.307]
 [ 1.174]
 [-0.307]
 [-0.307]
 [-0.307]
 [-0.307]
 [-0.307]] [[-0.848]
 [-0.394]
 [-0.848]
 [-0.848]
 [-0.848]
 [-0.848]
 [-0.848]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1461246393981355, 0.7231051913889677, 0.0021095935057773682, 0.12866057570711945]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1461246393981355, 0.7231051913889677, 0.0021095935057773682, 0.12866057570711945]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1461246393981355, 0.7231051913889677, 0.0021095935057773682, 0.12866057570711945]
from probs:  [0.1441839636064143, 0.7247521542414056, 0.002112133316865023, 0.12895174883531518]
Printing some Q and Qe and total Qs values:  [[0.155]
 [0.088]
 [0.184]
 [0.184]
 [0.184]
 [0.185]
 [0.165]] [[-0.946]
 [-0.25 ]
 [-0.983]
 [-0.983]
 [-0.983]
 [-1.063]
 [-0.857]] [[0.155]
 [0.088]
 [0.184]
 [0.184]
 [0.184]
 [0.185]
 [0.165]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1441839636064143, 0.7247521542414056, 0.002112133316865023, 0.12895174883531518]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1441839636064143, 0.7247521542414056, 0.002112133316865023, 0.12895174883531518]
Printing some Q and Qe and total Qs values:  [[0.544]
 [0.532]
 [0.544]
 [0.609]
 [0.145]
 [0.533]
 [0.56 ]] [[-0.005]
 [ 0.236]
 [-0.651]
 [-1.322]
 [ 0.421]
 [-1.097]
 [-0.693]] [[0.544]
 [0.532]
 [0.544]
 [0.609]
 [0.145]
 [0.533]
 [0.56 ]]
Printing some Q and Qe and total Qs values:  [[0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.043]] [[-1.165]
 [-1.165]
 [-1.165]
 [-1.165]
 [-1.165]
 [-1.165]
 [-0.826]] [[0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.047]
 [0.043]]
Printing some Q and Qe and total Qs values:  [[0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]] [[-1.229]
 [-1.229]
 [-1.229]
 [-1.229]
 [-1.229]
 [-1.229]
 [-1.229]] [[0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14475555961419134, 0.7236653126732535, 0.002116588777323446, 0.1294625389352317]
Printing some Q and Qe and total Qs values:  [[0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]] [[-1.788]
 [-1.788]
 [-1.788]
 [-1.788]
 [-1.788]
 [-1.788]
 [-1.788]] [[0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]
 [0.13]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14475555961419134, 0.7236653126732535, 0.002116588777323446, 0.1294625389352317]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14475555961419134, 0.7236653126732535, 0.002116588777323446, 0.1294625389352317]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14475555961419134, 0.7236653126732535, 0.002116588777323446, 0.1294625389352317]
using explorer policy with actor:  1
from probs:  [0.14475555961419134, 0.7236653126732535, 0.002116588777323446, 0.1294625389352317]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14532714643120087, 0.7225784885805703, 0.0021210441661419347, 0.12997332082208699]
line 256 mcts: sample exp_bonus 0.2824109440355975
Printing some Q and Qe and total Qs values:  [[0.77 ]
 [0.556]
 [0.561]
 [0.618]
 [0.572]
 [0.598]
 [0.565]] [[-0.109]
 [ 0.404]
 [-0.442]
 [-0.146]
 [-0.657]
 [-0.531]
 [-0.435]] [[0.77 ]
 [0.556]
 [0.561]
 [0.618]
 [0.572]
 [0.598]
 [0.565]]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.494]] [[0.84]
 [0.84]
 [0.84]
 [0.84]
 [0.84]
 [0.84]
 [0.84]] [[0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.494]
 [0.494]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
Printing some Q and Qe and total Qs values:  [[0.297]
 [0.297]
 [0.297]
 [0.297]
 [0.297]
 [0.297]
 [0.297]] [[3.702]
 [3.702]
 [3.702]
 [3.702]
 [3.702]
 [3.702]
 [3.702]] [[1.194]
 [1.194]
 [1.194]
 [1.194]
 [1.194]
 [1.194]
 [1.194]]
Printing some Q and Qe and total Qs values:  [[0.567]
 [0.632]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]] [[-0.194]
 [ 0.965]
 [-0.194]
 [-0.194]
 [-0.194]
 [-0.194]
 [-0.194]] [[0.323]
 [1.041]
 [0.323]
 [0.323]
 [0.323]
 [0.323]
 [0.323]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14395119247947283, 0.7231403322425384, 0.002128083986537827, 0.13078039129145091]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14395119247947283, 0.7231403322425384, 0.002128083986537827, 0.13078039129145091]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14395119247947283, 0.7231403322425384, 0.002128083986537827, 0.13078039129145091]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14395119247947283, 0.7231403322425384, 0.002128083986537827, 0.13078039129145091]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14395119247947283, 0.7231403322425384, 0.002128083986537827, 0.13078039129145091]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14395119247947283, 0.7231403322425384, 0.002128083986537827, 0.13078039129145091]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14508155718929955, 0.7209747946125001, 0.00213703539217493, 0.1318066128060252]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14508155718929955, 0.7209747946125001, 0.00213703539217493, 0.1318066128060252]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14508155718929955, 0.7209747946125001, 0.00213703539217493, 0.1318066128060252]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14369236137309122, 0.7215423083307623, 0.0021441406879374606, 0.13262118960820907]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14175014759313026, 0.7231823209980522, 0.002146753898436582, 0.13292077751038103]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14066943816961186, 0.7253141823244755, 0.00215640804622375, 0.13185997145968886]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14066943816961186, 0.7253141823244755, 0.00215640804622375, 0.13185997145968886]
siam score:  -0.6789232
Printing some Q and Qe and total Qs values:  [[0.514]
 [0.526]
 [0.511]
 [0.514]
 [0.514]
 [0.514]
 [0.528]] [[-0.638]
 [-0.628]
 [-0.711]
 [-0.638]
 [-0.638]
 [-0.638]
 [-0.662]] [[0.289]
 [0.32 ]
 [0.236]
 [0.289]
 [0.289]
 [0.289]
 [0.302]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1387413668839364, 0.726944998306912, 0.0021590206908965546, 0.13215461411825513]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13928357765475788, 0.7258819264120598, 0.0021635986581393317, 0.13267089727504303]
Printing some Q and Qe and total Qs values:  [[-0.139]
 [-0.065]
 [-0.085]
 [-0.085]
 [-0.083]
 [-0.067]
 [-0.061]] [[1.506]
 [1.946]
 [2.304]
 [1.28 ]
 [1.696]
 [1.504]
 [2.25 ]] [[-0.539]
 [-0.245]
 [-0.165]
 [-0.507]
 [-0.363]
 [-0.397]
 [-0.134]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13843290671996417, 0.7253882768051296, 0.0021754141980594114, 0.1340034022768466]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1389689463226836, 0.7243288738587093, 0.002180014157881703, 0.13452216566072556]
Printing some Q and Qe and total Qs values:  [[0.999]
 [0.847]
 [0.847]
 [0.847]
 [0.847]
 [0.847]
 [0.847]] [[0.805]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]
 [0.862]] [[1.897]
 [1.656]
 [1.656]
 [1.656]
 [1.656]
 [1.656]
 [1.656]]
using explorer policy with actor:  1
from probs:  [0.14057741188970302, 0.7211499797018749, 0.002193817013018323, 0.13607879139540385]
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.136]
 [0.666]
 [0.688]
 [0.678]
 [0.654]
 [0.724]] [[-0.033]
 [ 1.195]
 [-0.334]
 [-0.354]
 [-0.314]
 [-0.067]
 [-0.294]] [[0.676]
 [0.538]
 [0.579]
 [0.611]
 [0.617]
 [0.733]
 [0.722]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
using explorer policy with actor:  1
using explorer policy with actor:  1
from probs:  [0.14196579830337777, 0.7206422280220891, 0.0022057312851883606, 0.13518624238934474]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1422797119875193, 0.7222447472990648, 0.0022084250979727015, 0.13326711561544302]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1422797119875193, 0.7222447472990648, 0.0022084250979727015, 0.13326711561544302]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1422797119875193, 0.7222447472990648, 0.0022084250979727015, 0.13326711561544302]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1433622072426053, 0.7201395206956989, 0.002217714401703162, 0.13428055765999267]
Printing some Q and Qe and total Qs values:  [[0.885]
 [0.267]
 [0.464]
 [0.46 ]
 [0.47 ]
 [0.484]
 [0.428]] [[ 0.362]
 [ 0.931]
 [ 0.05 ]
 [-0.036]
 [ 0.042]
 [ 0.219]
 [ 0.472]] [[1.419]
 [0.941]
 [0.161]
 [0.039]
 [0.162]
 [0.426]
 [0.653]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14308534330886571, 0.7229323345992789, 0.002235416190441839, 0.13174690590141366]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14162956425929132, 0.7235765733194923, 0.0022430366244057414, 0.13255082579681063]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14162956425929132, 0.7235765733194923, 0.0022430366244057414, 0.13255082579681063]
Printing some Q and Qe and total Qs values:  [[-0.046]
 [-0.042]
 [-0.038]
 [-0.037]
 [-0.037]
 [-0.035]
 [-0.047]] [[1.365]
 [1.983]
 [2.331]
 [1.468]
 [2.106]
 [1.932]
 [2.408]] [[-0.601]
 [-0.388]
 [-0.262]
 [-0.549]
 [-0.335]
 [-0.389]
 [-0.255]]
Printing some Q and Qe and total Qs values:  [[-0.047]
 [-0.045]
 [-0.051]
 [-0.041]
 [-0.04 ]
 [-0.042]
 [-0.036]] [[1.103]
 [1.561]
 [1.388]
 [1.212]
 [1.569]
 [1.487]
 [1.696]] [[-0.724]
 [-0.567]
 [-0.637]
 [-0.675]
 [-0.554]
 [-0.587]
 [-0.506]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13880281129057537, 0.7224155816042477, 0.0022804818922865797, 0.13650112521289043]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13911874109639494, 0.7240694764119018, 0.0022834266025167794, 0.13452835588918644]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.421]
 [0.452]
 [0.452]
 [0.616]
 [0.452]
 [0.452]
 [0.583]] [[1.3  ]
 [0.993]
 [0.993]
 [0.497]
 [0.993]
 [0.993]
 [1.398]] [[1.209]
 [1.067]
 [1.067]
 [1.065]
 [1.067]
 [1.067]
 [1.599]]
1404 1324
siam score:  -0.6665259
1406 1326
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14104017908233638, 0.7202812561152299, 0.002323508020223898, 0.13635505678220974]
Printing some Q and Qe and total Qs values:  [[0.347]
 [0.354]
 [0.37 ]
 [0.367]
 [0.351]
 [0.348]
 [0.334]] [[-1.184]
 [-0.95 ]
 [-1.252]
 [-1.448]
 [-1.602]
 [-1.535]
 [-1.348]] [[0.347]
 [0.354]
 [0.37 ]
 [0.367]
 [0.351]
 [0.348]
 [0.334]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14155550891196206, 0.7192629517513967, 0.0023283928812141237, 0.13685314645542718]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14155550891196206, 0.7192629517513967, 0.0023283928812141237, 0.13685314645542718]
Printing some Q and Qe and total Qs values:  [[0.418]
 [0.418]
 [0.418]
 [0.418]
 [0.418]
 [0.418]
 [0.291]] [[1.852]
 [1.852]
 [1.852]
 [1.852]
 [1.852]
 [1.852]
 [3.042]] [[0.357]
 [0.357]
 [0.357]
 [0.357]
 [0.357]
 [0.357]
 [0.896]]
from probs:  [0.14155550891196206, 0.7192629517513967, 0.0023283928812141237, 0.13685314645542718]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.13952100036152265, 0.720971186266309, 0.0023315616366875605, 0.1371762517354808]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14053965837899937, 0.7189412915110309, 0.002341382712222033, 0.1381776673977477]
Printing some Q and Qe and total Qs values:  [[0.277]
 [0.269]
 [0.285]
 [0.275]
 [0.275]
 [0.288]
 [0.291]] [[-0.833]
 [ 0.283]
 [-0.466]
 [ 0.   ]
 [ 0.   ]
 [-0.932]
 [-2.721]] [[0.277]
 [0.269]
 [0.285]
 [0.275]
 [0.275]
 [0.288]
 [0.291]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14189216418554648, 0.7186069278600583, 0.0023544224777360917, 0.1371464854766591]
Printing some Q and Qe and total Qs values:  [[0.31 ]
 [0.428]
 [0.359]
 [0.525]
 [0.26 ]
 [0.364]
 [0.256]] [[2.669]
 [2.667]
 [2.648]
 [1.923]
 [2.674]
 [2.118]
 [2.588]] [[1.739]
 [1.961]
 [1.819]
 [1.677]
 [1.649]
 [1.497]
 [1.588]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14189216418554648, 0.7186069278600583, 0.0023544224777360917, 0.1371464854766591]
Printing some Q and Qe and total Qs values:  [[0.5 ]
 [0.5 ]
 [0.5 ]
 [0.5 ]
 [0.5 ]
 [0.5 ]
 [0.48]] [[1.636]
 [1.636]
 [1.636]
 [1.636]
 [1.636]
 [1.636]
 [2.024]] [[0.037]
 [0.037]
 [0.037]
 [0.037]
 [0.037]
 [0.037]
 [0.254]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14410527279104043, 0.7189577322481734, 0.0023757594783856196, 0.13456123548240045]
from probs:  [0.143899308248139, 0.7194010854104494, 0.0023974959418130415, 0.13430211039959833]
using explorer policy with actor:  1
from probs:  [0.14544362577771752, 0.7164010192745667, 0.002412641360123022, 0.13574271358759263]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1457874559930208, 0.7181039055777517, 0.002416013369012801, 0.13369262506021473]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1457874559930208, 0.7181039055777517, 0.002416013369012801, 0.13369262506021473]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1457874559930208, 0.7181039055777517, 0.002416013369012801, 0.13369262506021473]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1463051215819567, 0.7171067395978253, 0.002421090214764372, 0.13416704860545348]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14716998925275804, 0.7178106514668966, 0.0024295721379480333, 0.13258978714239728]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14716998925275804, 0.7178106514668966, 0.0024295721379480333, 0.13258978714239728]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14555318778100712, 0.7186177147954912, 0.0024382982031820604, 0.13339079922031952]
1418 1347
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14744838242946026, 0.7173597567260138, 0.0024572070238165333, 0.13273465382070931]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14744838242946026, 0.7173597567260138, 0.0024572070238165333, 0.13273465382070931]
Printing some Q and Qe and total Qs values:  [[0.52 ]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.685]] [[-0.258]
 [-0.258]
 [-0.258]
 [-0.258]
 [-0.258]
 [-0.258]
 [ 0.786]] [[1.108]
 [1.108]
 [1.108]
 [1.108]
 [1.108]
 [1.108]
 [2.107]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14683380581396316, 0.7162167072367541, 0.0024764880365577406, 0.13447299891272488]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14683380581396316, 0.7162167072367541, 0.0024764880365577406, 0.13447299891272488]
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.436]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.358]] [[-1.604]
 [-1.084]
 [-1.604]
 [-1.604]
 [-1.604]
 [-1.604]
 [-1.804]] [[0.368]
 [0.436]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.358]]
using another actor
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1483712604550101, 0.7132565008807666, 0.0024920955049886574, 0.1358801431592346]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1483712604550101, 0.7132565008807666, 0.0024920955049886574, 0.1358801431592346]
Printing some Q and Qe and total Qs values:  [[0.491]
 [0.491]
 [0.491]
 [0.491]
 [0.491]
 [0.491]
 [0.491]] [[-0.943]
 [-0.943]
 [-0.943]
 [-0.943]
 [-0.943]
 [-0.943]
 [-0.943]] [[0.491]
 [0.491]
 [0.491]
 [0.491]
 [0.491]
 [0.491]
 [0.491]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1483712604550101, 0.7132565008807666, 0.0024920955049886574, 0.1358801431592346]
Printing some Q and Qe and total Qs values:  [[0.579]
 [0.61 ]
 [0.579]
 [0.579]
 [0.579]
 [0.579]
 [0.592]] [[1.714]
 [2.546]
 [1.714]
 [1.714]
 [1.714]
 [1.714]
 [2.034]] [[0.579]
 [0.61 ]
 [0.579]
 [0.579]
 [0.579]
 [0.579]
 [0.592]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
Printing some Q and Qe and total Qs values:  [[0.505]
 [0.514]
 [0.518]
 [0.511]
 [0.509]
 [0.507]
 [0.508]] [[-2.142]
 [-0.255]
 [-1.833]
 [-2.372]
 [-2.134]
 [-1.534]
 [-2.051]] [[0.854]
 [1.457]
 [0.974]
 [0.793]
 [0.864]
 [1.047]
 [0.888]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14670127575275704, 0.714099502418421, 0.00250116744178468, 0.1366980543870373]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14670127575275704, 0.714099502418421, 0.00250116744178468, 0.1366980543870373]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14670127575275704, 0.714099502418421, 0.00250116744178468, 0.1366980543870373]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14670127575275704, 0.714099502418421, 0.00250116744178468, 0.1366980543870373]
Printing some Q and Qe and total Qs values:  [[-0.008]
 [-0.008]
 [-0.008]
 [-0.008]
 [-0.008]
 [-0.008]
 [-0.008]] [[1.834]
 [1.834]
 [1.834]
 [1.834]
 [1.834]
 [1.834]
 [1.834]] [[-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]
 [-0.005]]
from probs:  [0.14670127575275704, 0.714099502418421, 0.00250116744178468, 0.1366980543870373]
from probs:  [0.1445289074313744, 0.7159213346814121, 0.002505012793301597, 0.13704474509391196]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14488226724042044, 0.7176813903138353, 0.0025087277525398786, 0.13492761469320444]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.1427160068219729, 0.7195033279677078, 0.002512573326505917, 0.13526809188381342]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.8840783919880324
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14321288662632733, 0.7185303640968447, 0.0025178904785509524, 0.13573885879827707]
siam score:  -0.6430928
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
siam score:  -0.6434195
1429 1358
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
UNIT TEST: sample policy line 217 mcts : [0.041 0.755 0.02  0.02  0.02  0.02  0.122]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
Printing some Q and Qe and total Qs values:  [[0.574]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]] [[0.865]
 [0.857]
 [0.857]
 [0.857]
 [0.857]
 [0.857]
 [0.857]] [[0.574]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.527]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
line 256 mcts: sample exp_bonus 1.8382592354365475
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.524]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.585]] [[1.833]
 [1.351]
 [1.833]
 [1.833]
 [1.833]
 [1.833]
 [1.696]] [[1.457]
 [1.253]
 [1.457]
 [1.457]
 [1.457]
 [1.457]
 [1.502]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14570161031788437, 0.7136570764018615, 0.002544522517426589, 0.13809679076282755]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14570161031788437, 0.7136570764018615, 0.002544522517426589, 0.13809679076282755]
Printing some Q and Qe and total Qs values:  [[0.346]
 [0.33 ]
 [0.346]
 [0.346]
 [0.346]
 [0.346]
 [0.346]] [[ 0.   ]
 [-1.706]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[0.346]
 [0.33 ]
 [0.346]
 [0.346]
 [0.346]
 [0.346]
 [0.346]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.222]
 [0.275]
 [0.267]
 [0.267]
 [0.211]
 [0.267]
 [0.19 ]] [[0.774]
 [1.387]
 [1.44 ]
 [1.44 ]
 [0.745]
 [1.44 ]
 [1.932]] [[-0.733]
 [-0.218]
 [-0.199]
 [-0.199]
 [-0.773]
 [-0.199]
 [-0.025]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.043]
 [0.029]
 [0.101]
 [0.219]
 [0.219]
 [0.219]
 [0.281]] [[0.909]
 [1.275]
 [1.277]
 [1.381]
 [1.381]
 [1.381]
 [1.227]] [[-0.899]
 [-0.683]
 [-0.539]
 [-0.233]
 [-0.233]
 [-0.233]
 [-0.21 ]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14570161031788437, 0.7136570764018615, 0.002544522517426589, 0.13809679076282755]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14620022174721592, 0.7126807217541428, 0.0025498581997342898, 0.13856919829890704]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14620022174721592, 0.7126807217541428, 0.0025498581997342898, 0.13856919829890704]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14620022174721592, 0.7126807217541428, 0.0025498581997342898, 0.13856919829890704]
Printing some Q and Qe and total Qs values:  [[0.556]
 [0.47 ]
 [0.47 ]
 [0.47 ]
 [0.47 ]
 [0.47 ]
 [0.47 ]] [[-0.128]
 [-0.205]
 [-0.205]
 [-0.205]
 [-0.205]
 [-0.205]
 [-0.205]] [[0.483]
 [0.286]
 [0.286]
 [0.286]
 [0.286]
 [0.286]
 [0.286]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14620022174721592, 0.7126807217541428, 0.0025498581997342898, 0.13856919829890704]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14620022174721592, 0.7126807217541428, 0.0025498581997342898, 0.13856919829890704]
Printing some Q and Qe and total Qs values:  [[0.338]
 [0.338]
 [0.338]
 [0.338]
 [0.338]
 [0.338]
 [0.338]] [[-0.369]
 [-0.369]
 [-0.369]
 [-0.369]
 [-0.369]
 [-0.369]
 [-0.369]] [[-0.054]
 [-0.054]
 [-0.054]
 [-0.054]
 [-0.054]
 [-0.054]
 [-0.054]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14620022174721592, 0.7126807217541428, 0.0025498581997342898, 0.13856919829890704]
using explorer policy with actor:  1
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14620022174721592, 0.7126807217541428, 0.0025498581997342898, 0.13856919829890704]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14400029593693064, 0.7145209097735263, 0.0025538759366533085, 0.1389249183528897]
Printing some Q and Qe and total Qs values:  [[0.277]
 [0.356]
 [0.282]
 [0.277]
 [0.277]
 [0.277]
 [0.275]] [[0.538]
 [1.347]
 [0.059]
 [0.538]
 [0.538]
 [0.538]
 [0.417]] [[0.237]
 [0.665]
 [0.086]
 [0.237]
 [0.237]
 [0.237]
 [0.191]]
using another actor
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14327057042104321, 0.7134427705322961, 0.0025740671013376203, 0.1407125919453232]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -1.2357777321497254
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14327057042104321, 0.7134427705322961, 0.0025740671013376203, 0.1407125919453232]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14327057042104321, 0.7134427705322961, 0.0025740671013376203, 0.1407125919453232]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14107233740947087, 0.7152771948771641, 0.0025781303038941625, 0.14107233740947087]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14107233740947087, 0.7152771948771641, 0.0025781303038941625, 0.14107233740947087]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14107233740947087, 0.7152771948771641, 0.0025781303038941625, 0.14107233740947087]
Printing some Q and Qe and total Qs values:  [[0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.655]
 [0.612]
 [0.612]] [[0.404]
 [0.404]
 [0.404]
 [0.404]
 [0.792]
 [0.404]
 [0.404]] [[0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.655]
 [0.612]
 [0.612]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14155327265206735, 0.7143098923921213, 0.002583562303744055, 0.14155327265206735]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14203451302680134, 0.7133419761964397, 0.002588997749957569, 0.14203451302680134]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14203451302680134, 0.7133419761964397, 0.002588997749957569, 0.14203451302680134]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14203451302680134, 0.7133419761964397, 0.002588997749957569, 0.14203451302680134]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.14203451302680134, 0.7133419761964397, 0.002588997749957569, 0.14203451302680134]
rdn beta is 0 so we're just using the maxi policy
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.0000],
        [-0.3438],
        [-0.4672],
        [-0.0000],
        [-0.5261],
        [-0.4585],
        [-0.3641],
        [-0.3690],
        [-0.0000],
        [-0.3055]], dtype=torch.float64)
-0.9560860847999999 -0.9560860847999999
-0.0439609252995 -0.3877207483085366
-0.024259925299500003 -0.49148966449055886
-0.9213435 -0.9213435
-0.024259925299500003 -0.5504065932273015
-0.024259925299500003 -0.482740009315234
-0.024259925299500003 -0.3883929469276178
-0.024259925299500003 -0.39322410327228424
-0.7472777399999999 -0.7472777399999999
-0.0727797758985 -0.3782307947834219
using explorer policy with actor:  1
actor:  1 policy actor:  1  step number:  57 total reward:  0.48999999999999966  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.539]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]] [[1.586]
 [1.461]
 [1.461]
 [1.461]
 [1.461]
 [1.461]
 [1.461]] [[2.264]
 [2.141]
 [2.141]
 [2.141]
 [2.141]
 [2.141]
 [2.141]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
using explorer policy with actor:  1
from probs:  [0.08033616068689878, 0.8359240775226783, 0.0019256838616829636, 0.08181407792874004]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08033616068689878, 0.8359240775226783, 0.0019256838616829636, 0.08181407792874004]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08084198443352356, 0.834897080753807, 0.0019316108500270703, 0.0823293239626422]
Printing some Q and Qe and total Qs values:  [[0.55 ]
 [1.303]
 [0.55 ]
 [0.55 ]
 [0.55 ]
 [0.55 ]
 [0.55 ]] [[0.922]
 [0.603]
 [0.922]
 [0.922]
 [0.922]
 [0.922]
 [0.922]] [[0.614]
 [1.907]
 [0.614]
 [0.614]
 [0.614]
 [0.614]
 [0.614]]
Printing some Q and Qe and total Qs values:  [[0.83 ]
 [0.688]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]] [[-0.807]
 [ 0.368]
 [-0.328]
 [-0.328]
 [-0.328]
 [-0.328]
 [-0.328]] [[0.83 ]
 [0.688]
 [0.681]
 [0.681]
 [0.681]
 [0.681]
 [0.681]]
Printing some Q and Qe and total Qs values:  [[0.895]
 [0.592]
 [0.623]
 [0.581]
 [0.581]
 [0.581]
 [0.581]] [[-0.942]
 [-0.006]
 [-0.689]
 [-0.642]
 [-0.642]
 [-0.642]
 [-0.642]] [[0.895]
 [0.592]
 [0.623]
 [0.581]
 [0.581]
 [0.581]
 [0.581]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08109504241150546, 0.8343832857264706, 0.0019345760561801835, 0.08258709580584356]
Printing some Q and Qe and total Qs values:  [[0.621]
 [0.62 ]
 [0.745]
 [0.621]
 [0.621]
 [0.621]
 [0.621]] [[0.139]
 [1.184]
 [0.091]
 [0.139]
 [0.139]
 [0.139]
 [0.139]] [[0.621]
 [0.62 ]
 [0.745]
 [0.621]
 [0.621]
 [0.621]
 [0.621]]
line 256 mcts: sample exp_bonus 2.7224424565683143
Printing some Q and Qe and total Qs values:  [[0.43 ]
 [0.429]
 [0.357]
 [0.4  ]
 [0.4  ]
 [0.4  ]
 [0.412]] [[1.905]
 [2.454]
 [1.359]
 [2.075]
 [2.075]
 [2.075]
 [2.175]] [[ 0.136]
 [ 0.499]
 [-0.373]
 [ 0.188]
 [ 0.188]
 [ 0.188]
 [ 0.28 ]]
siam score:  -0.66300565
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08236179560103161, 0.8318113395865724, 0.0019494192331549333, 0.0838774455792409]
Printing some Q and Qe and total Qs values:  [[0.453]
 [0.446]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.473]] [[1.782]
 [2.78 ]
 [1.782]
 [1.782]
 [1.782]
 [1.782]
 [2.86 ]] [[0.07 ]
 [0.722]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.07 ]
 [0.828]]
using another actor
from probs:  [0.08236179560103161, 0.8318113395865724, 0.0019494192331549333, 0.0838774455792409]
Starting evaluation
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08312302018637155, 0.8302657909745396, 0.0019583388801162785, 0.08465284995897274]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]] [[1.27]
 [1.27]
 [1.27]
 [1.27]
 [1.27]
 [1.27]
 [1.27]] [[0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]
 [0.482]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08337695749939729, 0.8297502105935997, 0.001961314389875321, 0.08491151751712776]
Printing some Q and Qe and total Qs values:  [[0.603]
 [0.425]
 [0.437]
 [0.425]
 [0.425]
 [0.449]
 [0.419]] [[0.816]
 [1.4  ]
 [0.962]
 [1.4  ]
 [1.4  ]
 [0.943]
 [1.057]] [[0.603]
 [0.425]
 [0.437]
 [0.425]
 [0.425]
 [0.449]
 [0.419]]
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.641]] [[1.424]
 [1.692]
 [1.692]
 [1.692]
 [1.692]
 [1.692]
 [0.512]] [[1.968]
 [2.123]
 [2.123]
 [2.123]
 [2.123]
 [2.123]
 [1.354]]
Printing some Q and Qe and total Qs values:  [[0.288]
 [0.184]
 [0.288]
 [0.288]
 [0.288]
 [0.288]
 [0.247]] [[ 0.2  ]
 [ 0.516]
 [ 0.2  ]
 [ 0.2  ]
 [ 0.2  ]
 [ 0.2  ]
 [-1.022]] [[0.288]
 [0.184]
 [0.288]
 [0.288]
 [0.288]
 [0.288]
 [0.247]]
Printing some Q and Qe and total Qs values:  [[0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]] [[2.678]
 [2.678]
 [2.678]
 [2.678]
 [2.678]
 [2.678]
 [2.678]] [[0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]
 [0.559]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.315]
 [0.315]
 [0.315]
 [0.315]
 [0.315]
 [0.315]
 [0.315]] [[-0.87]
 [-0.87]
 [-0.87]
 [-0.87]
 [-0.87]
 [-0.87]
 [-0.87]] [[0.315]
 [0.315]
 [0.315]
 [0.315]
 [0.315]
 [0.315]
 [0.315]]
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.537]
 [0.537]
 [0.537]
 [0.537]
 [0.537]
 [0.522]] [[2.78 ]
 [2.78 ]
 [2.78 ]
 [2.78 ]
 [2.78 ]
 [2.78 ]
 [3.016]] [[0.537]
 [0.537]
 [0.537]
 [0.537]
 [0.537]
 [0.537]
 [0.522]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08363099279914674, 0.8292344312657947, 0.0019642910477935256, 0.08517028488726502]
line 256 mcts: sample exp_bonus 4.759157119446827
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08388512614234607, 0.8287184528759513, 0.001967268854535582, 0.08542915212716717]
line 256 mcts: sample exp_bonus 0.8757184202373296
line 256 mcts: sample exp_bonus 5.693341511131242
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08439368718621765, 0.8276858984490093, 0.0019732279171525645, 0.08594718644762059]
Printing some Q and Qe and total Qs values:  [[0.564]
 [0.55 ]
 [0.565]
 [0.584]
 [0.575]
 [0.567]
 [0.563]] [[2.693]
 [3.163]
 [3.081]
 [3.076]
 [3.109]
 [3.586]
 [3.506]] [[0.564]
 [0.55 ]
 [0.565]
 [0.584]
 [0.575]
 [0.567]
 [0.563]]
Printing some Q and Qe and total Qs values:  [[0.573]
 [0.569]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.576]] [[5.67 ]
 [4.883]
 [5.67 ]
 [5.67 ]
 [5.67 ]
 [5.67 ]
 [4.56 ]] [[0.573]
 [0.569]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.576]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08439368718621765, 0.8276858984490093, 0.0019732279171525645, 0.08594718644762059]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08452396683869119, 0.8289773118539994, 0.0019747544686180454, 0.08452396683869119]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08452396683869119, 0.8289773118539994, 0.0019747544686180454, 0.08452396683869119]
Printing some Q and Qe and total Qs values:  [[0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.599]] [[-0.097]
 [-0.097]
 [-0.097]
 [-0.097]
 [-0.097]
 [-0.097]
 [ 0.87 ]] [[0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.599]]
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.768]] [[2.124]
 [2.124]
 [2.124]
 [2.124]
 [2.124]
 [2.124]
 [2.636]] [[1.61 ]
 [1.61 ]
 [1.61 ]
 [1.61 ]
 [1.61 ]
 [1.61 ]
 [2.101]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08465339560464863, 0.8302602907396138, 0.001976271049823141, 0.08311004260591431]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08658186364331148, 0.8279801561383054, 0.001998867868702065, 0.08343911234968097]
Printing some Q and Qe and total Qs values:  [[0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.797]] [[ 2.018]
 [ 2.018]
 [ 2.018]
 [ 2.018]
 [ 2.018]
 [ 2.018]
 [-0.206]] [[0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.797]]
Printing some Q and Qe and total Qs values:  [[0.367]
 [0.354]
 [0.354]
 [0.354]
 [0.795]
 [0.354]
 [0.388]] [[-2.264]
 [-2.483]
 [-2.483]
 [-2.483]
 [-4.589]
 [-2.483]
 [-2.388]] [[0.367]
 [0.354]
 [0.354]
 [0.354]
 [0.795]
 [0.354]
 [0.388]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08658186364331148, 0.8279801561383054, 0.001998867868702065, 0.08343911234968097]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus -3.474894106530519
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08513631638555792, 0.829293211002278, 0.002000460159948935, 0.08357001245221514]
line 256 mcts: sample exp_bonus 0.8133396325305503
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08513631638555792, 0.829293211002278, 0.002000460159948935, 0.08357001245221514]
Printing some Q and Qe and total Qs values:  [[0.801]
 [0.602]
 [0.557]
 [0.557]
 [0.557]
 [0.557]
 [0.557]] [[-2.157]
 [-0.599]
 [-1.245]
 [-1.245]
 [-1.245]
 [-1.245]
 [-1.245]] [[0.801]
 [0.602]
 [0.557]
 [0.557]
 [0.557]
 [0.557]
 [0.557]]
Printing some Q and Qe and total Qs values:  [[0.677]
 [0.597]
 [0.68 ]
 [0.654]
 [0.656]
 [0.645]
 [0.708]] [[0.955]
 [1.616]
 [1.12 ]
 [0.962]
 [0.976]
 [1.277]
 [0.818]] [[0.677]
 [0.597]
 [0.68 ]
 [0.654]
 [0.656]
 [0.645]
 [0.708]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08513631638555792, 0.829293211002278, 0.002000460159948935, 0.08357001245221514]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.9649272642881703
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.666]
 [0.676]
 [0.665]
 [0.681]
 [0.68 ]
 [0.693]
 [0.689]] [[2.662]
 [2.574]
 [2.506]
 [2.488]
 [2.549]
 [1.912]
 [2.488]] [[0.666]
 [0.676]
 [0.665]
 [0.681]
 [0.68 ]
 [0.693]
 [0.689]]
Printing some Q and Qe and total Qs values:  [[0.526]
 [0.526]
 [0.528]
 [0.526]
 [0.526]
 [0.526]
 [0.542]] [[ 0.411]
 [ 0.411]
 [ 0.685]
 [ 0.411]
 [ 0.411]
 [ 0.411]
 [-2.208]] [[0.526]
 [0.526]
 [0.528]
 [0.526]
 [0.526]
 [0.526]
 [0.542]]
Printing some Q and Qe and total Qs values:  [[0.669]
 [0.563]
 [0.669]
 [0.672]
 [0.674]
 [0.676]
 [0.676]] [[2.42 ]
 [2.635]
 [2.421]
 [2.163]
 [2.447]
 [2.196]
 [2.06 ]] [[0.669]
 [0.563]
 [0.669]
 [0.672]
 [0.674]
 [0.676]
 [0.676]]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08628583717259729, 0.8285744272539922, 0.0020141828292095884, 0.08312555274420089]
from probs:  [0.08628583717259729, 0.8285744272539922, 0.0020141828292095884, 0.08312555274420089]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.58710980749526
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.0865406787235257, 0.828071144687945, 0.0020172250589427882, 0.08337095152958669]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.0865406787235257, 0.828071144687945, 0.0020172250589427882, 0.08337095152958669]
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
maxi score, test score, baseline:  -0.99179 -0.92875 -0.92875
probs:  [0.08807205650599173, 0.825046850819305, 0.002035506234071442, 0.0848455864406319]
rdn probs:  [0.08807205650599173, 0.825046850819305, 0.002035506234071442, 0.0848455864406319]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.659]
 [0.592]
 [0.703]
 [0.584]
 [0.659]
 [0.659]
 [0.606]] [[4.347]
 [4.841]
 [3.992]
 [5.031]
 [4.347]
 [4.347]
 [4.983]] [[0.733]
 [0.914]
 [0.596]
 [1.016]
 [0.733]
 [0.733]
 [1.027]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09745843935760348, 0.8063418211631069, 0.0020135899201110864, 0.0941861495591785]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09597122727651645, 0.8076732817086983, 0.0020152722528468275, 0.09434021876193839]
siam score:  -0.67180306
Printing some Q and Qe and total Qs values:  [[0.223]
 [0.188]
 [0.154]
 [0.223]
 [0.223]
 [0.223]
 [0.165]] [[3.56 ]
 [4.469]
 [5.723]
 [3.56 ]
 [3.56 ]
 [3.56 ]
 [4.989]] [[0.06 ]
 [0.414]
 [0.923]
 [0.06 ]
 [0.06 ]
 [0.06 ]
 [0.614]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
1467 1406
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09651773060145812, 0.8065837951837563, 0.002021137224960337, 0.09487733698982535]
1467 1407
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09679111248589334, 0.8060387923161393, 0.0020240711085350105, 0.09514602408943246]
using another actor
from probs:  [0.09733813690562178, 0.8049482669580876, 0.0020299416729409243, 0.0956836544633497]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09733813690562178, 0.8049482669580876, 0.0020299416729409243, 0.0956836544633497]
Sims:  50 1 epoch:  91165 pick best:  False frame count:  91165
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0977714617852589, 0.8057305794146922, 0.0020345920350140776, 0.09446336676503492]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09626850683315082, 0.8070755809022989, 0.0020363278699852836, 0.09461958439456483]
Printing some Q and Qe and total Qs values:  [[0.767]
 [0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.629]] [[-1.045]
 [-1.006]
 [-1.006]
 [-1.006]
 [-1.006]
 [-1.006]
 [-1.006]] [[0.767]
 [0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.629]]
Printing some Q and Qe and total Qs values:  [[0.804]
 [0.677]
 [0.613]
 [0.599]
 [0.599]
 [0.642]
 [0.62 ]] [[-1.661]
 [ 0.185]
 [-1.058]
 [-1.195]
 [-1.195]
 [-0.936]
 [-0.883]] [[0.804]
 [0.677]
 [0.613]
 [0.599]
 [0.599]
 [0.642]
 [0.62 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09626850683315082, 0.8070755809022989, 0.0020363278699852836, 0.09461958439456483]
Printing some Q and Qe and total Qs values:  [[0.489]
 [0.517]
 [0.485]
 [0.521]
 [0.498]
 [0.523]
 [0.437]] [[3.223]
 [4.231]
 [5.485]
 [3.954]
 [3.187]
 [3.503]
 [6.619]] [[0.513]
 [0.866]
 [1.241]
 [0.781]
 [0.51 ]
 [0.637]
 [1.561]]
UNIT TEST: sample policy line 217 mcts : [0.02  0.082 0.02  0.    0.02  0.469 0.388]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09653933127205963, 0.8065356620789488, 0.0020392850918768317, 0.09488572155711476]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09681024693077331, 0.8059955613987101, 0.002042243309827691, 0.0951519483606887]
Printing some Q and Qe and total Qs values:  [[0.907]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]] [[-0.828]
 [-0.526]
 [-0.526]
 [-0.526]
 [-0.526]
 [-0.526]
 [-0.526]] [[0.907]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09681024693077331, 0.8059955613987101, 0.002042243309827691, 0.0951519483606887]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[1.337]
 [1.337]
 [1.337]
 [1.337]
 [1.337]
 [1.337]
 [1.337]] [[0.66]
 [0.66]
 [0.66]
 [0.66]
 [0.66]
 [0.66]
 [0.66]] [[1.6]
 [1.6]
 [1.6]
 [1.6]
 [1.6]
 [1.6]
 [1.6]]
Printing some Q and Qe and total Qs values:  [[0.561]
 [0.679]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.556]] [[1.233]
 [1.616]
 [1.233]
 [1.233]
 [1.233]
 [1.233]
 [1.312]] [[0.561]
 [0.679]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.556]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09789482268604571, 0.8038333382700283, 0.002054086152295885, 0.0962177528916299]
using explorer policy with actor:  0
UNIT TEST: sample policy line 217 mcts : [0.633 0.184 0.02  0.02  0.02  0.02  0.102]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09789482268604571, 0.8038333382700283, 0.002054086152295885, 0.0962177528916299]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09816619513583236, 0.8032923269256728, 0.0020570493581000054, 0.09648442858039502]
Printing some Q and Qe and total Qs values:  [[0.154]
 [0.627]
 [0.496]
 [0.627]
 [0.627]
 [0.782]
 [0.627]] [[1.503]
 [1.608]
 [0.846]
 [1.608]
 [1.608]
 [1.295]
 [1.608]] [[1.06 ]
 [1.781]
 [0.933]
 [1.781]
 [1.781]
 [1.711]
 [1.781]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09843765908246092, 0.8027511331721241, 0.0020600135629884955, 0.09675119418242649]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.752]
 [0.752]
 [0.752]
 [0.752]
 [0.752]
 [0.752]
 [0.752]] [[2.46]
 [2.46]
 [2.46]
 [2.46]
 [2.46]
 [2.46]
 [2.46]] [[1.802]
 [1.802]
 [1.802]
 [1.802]
 [1.802]
 [1.802]
 [1.802]]
siam score:  -0.6588255
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09843765908246092, 0.8027511331721241, 0.0020600135629884955, 0.09675119418242649]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09870921457221339, 0.8022097569171146, 0.0020629787674667248, 0.09701804974320512]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.579]
 [0.579]
 [0.737]
 [0.579]
 [0.579]
 [0.74 ]
 [0.727]] [[1.351]
 [1.351]
 [0.317]
 [1.351]
 [1.351]
 [0.876]
 [1.7  ]] [[1.863]
 [1.863]
 [1.49 ]
 [1.863]
 [1.863]
 [1.869]
 [2.392]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09931093804100376, 0.8043653802825954, 0.002069549185637754, 0.09425413249076309]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0994744823779444, 0.8057017644977044, 0.002071334980506889, 0.09275241814384438]
from probs:  [0.0994744823779444, 0.8057017644977044, 0.002071334980506889, 0.09275241814384438]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10018793705339339, 0.8059690906824567, 0.002079125428789053, 0.091763846835361]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10018793705339339, 0.8059690906824567, 0.002079125428789053, 0.091763846835361]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10046353896776997, 0.8054382835585818, 0.0020821348175201104, 0.0920160426561281]
Printing some Q and Qe and total Qs values:  [[0.685]
 [0.818]
 [0.685]
 [0.685]
 [0.685]
 [0.685]
 [0.685]] [[-1.188]
 [ 0.167]
 [-1.188]
 [-1.188]
 [-1.188]
 [-1.188]
 [-1.188]] [[0.561]
 [1.242]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]]
siam score:  -0.6687687
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
siam score:  -0.66739625
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10046353896776997, 0.8054382835585818, 0.0020821348175201104, 0.0920160426561281]
Printing some Q and Qe and total Qs values:  [[0.335]
 [0.335]
 [0.335]
 [0.335]
 [0.335]
 [0.335]
 [0.335]] [[3.315]
 [3.315]
 [3.315]
 [3.315]
 [3.315]
 [3.315]
 [3.315]] [[0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10046353896776997, 0.8054382835585818, 0.0020821348175201104, 0.0920160426561281]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10073924414888079, 0.8049072775437872, 0.0020851453338548965, 0.09226833297347688]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10156697987334905, 0.8033130650354047, 0.0020941836548228144, 0.09302577143642347]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.759]
 [0.991]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.874]] [[2.337]
 [1.923]
 [2.337]
 [2.337]
 [2.337]
 [2.337]
 [3.1  ]] [[1.733]
 [1.86 ]
 [1.733]
 [1.733]
 [1.733]
 [1.733]
 [2.227]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10156697987334905, 0.8033130650354047, 0.0020941836548228144, 0.09302577143642347]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10156697987334905, 0.8033130650354047, 0.0020941836548228144, 0.09302577143642347]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10184309870234469, 0.802781262338031, 0.0020971986879160785, 0.0932784402717083]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.41417468394300105
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10228914827605692, 0.8035948905030171, 0.002102069251183605, 0.09201389196974237]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10256640445752753, 0.803065475776508, 0.0021050967034058473, 0.09226302306255876]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10312123658940893, 0.8020060357315628, 0.00211115509951347, 0.09276157257951485]
Printing some Q and Qe and total Qs values:  [[0.586]
 [0.561]
 [0.638]
 [0.592]
 [0.593]
 [0.638]
 [0.591]] [[3.241]
 [4.309]
 [3.476]
 [3.22 ]
 [2.956]
 [3.476]
 [3.27 ]] [[0.585]
 [1.246]
 [0.844]
 [0.582]
 [0.408]
 [0.844]
 [0.614]]
Printing some Q and Qe and total Qs values:  [[0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.884]] [[1.041]
 [1.041]
 [1.041]
 [1.041]
 [1.041]
 [1.041]
 [0.668]] [[0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.757]
 [0.884]]
Printing some Q and Qe and total Qs values:  [[0.518]
 [0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.552]] [[1.803]
 [1.836]
 [1.836]
 [1.836]
 [1.836]
 [1.836]
 [1.836]] [[1.925]
 [1.99 ]
 [1.99 ]
 [1.99 ]
 [1.99 ]
 [1.99 ]
 [1.99 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[1.165]
 [1.129]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.885]] [[0.783]
 [0.985]
 [3.661]
 [3.661]
 [3.661]
 [3.661]
 [2.82 ]] [[1.688]
 [1.72 ]
 [2.184]
 [2.184]
 [2.184]
 [2.184]
 [2.099]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1041287115605256, 0.8017696811725856, 0.0021221560529421095, 0.09197945121394671]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1041287115605256, 0.8017696811725856, 0.0021221560529421095, 0.09197945121394671]
Printing some Q and Qe and total Qs values:  [[0.394]
 [0.325]
 [0.404]
 [0.45 ]
 [0.435]
 [0.396]
 [0.398]] [[ 0.696]
 [ 1.174]
 [ 0.214]
 [-0.167]
 [-0.075]
 [ 0.47 ]
 [ 0.433]] [[ 0.114]
 [ 0.293]
 [-0.187]
 [-0.349]
 [-0.318]
 [-0.034]
 [-0.054]]
line 256 mcts: sample exp_bonus 1.0102336645280467
Printing some Q and Qe and total Qs values:  [[0.431]
 [0.576]
 [0.573]
 [0.657]
 [0.571]
 [0.543]
 [0.557]] [[1.536]
 [1.621]
 [1.045]
 [0.611]
 [1.205]
 [1.135]
 [1.309]] [[0.244]
 [0.591]
 [0.202]
 [0.08 ]
 [0.303]
 [0.201]
 [0.345]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10468650178765425, 0.8007137189480225, 0.002128246749473053, 0.09247153251485034]
Printing some Q and Qe and total Qs values:  [[0.638]
 [0.636]
 [0.638]
 [0.638]
 [0.638]
 [0.638]
 [0.644]] [[-0.824]
 [ 1.092]
 [-0.824]
 [-0.824]
 [-0.824]
 [-0.824]
 [-0.789]] [[0.933]
 [1.648]
 [0.933]
 [0.933]
 [0.933]
 [0.933]
 [0.953]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10524473168791505, 0.7996569243707286, 0.002134342246940783, 0.0929640016944157]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.71 ]
 [0.463]
 [0.707]
 [0.718]
 [0.715]
 [0.698]
 [0.696]] [[-0.347]
 [ 0.966]
 [-0.169]
 [-0.362]
 [-0.347]
 [ 0.043]
 [-0.216]] [[0.26 ]
 [0.64 ]
 [0.373]
 [0.266]
 [0.271]
 [0.496]
 [0.319]]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10417736893778755, 0.8000545440855583, 0.0021425305867164373, 0.09362555638993762]
using explorer policy with actor:  1
siam score:  -0.6602034
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1047288150806772, 0.7990019178129429, 0.002148658060948666, 0.0941206090454312]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10500470534380114, 0.7984752855333132, 0.0021517236558395037, 0.09436828546704616]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10528070715817897, 0.7979484403194158, 0.0021547904902483677, 0.09461606203215697]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.288]
 [0.629]
 [0.443]
 [0.573]
 [0.573]
 [0.584]
 [0.536]] [[1.758]
 [1.657]
 [0.441]
 [1.415]
 [1.415]
 [2.053]
 [1.72 ]] [[0.74 ]
 [1.355]
 [0.174]
 [1.081]
 [1.081]
 [1.528]
 [1.211]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
using another actor
Printing some Q and Qe and total Qs values:  [[0.599]
 [0.767]
 [0.678]
 [0.655]
 [0.404]
 [0.684]
 [0.617]] [[-0.6  ]
 [ 0.215]
 [-1.793]
 [-2.407]
 [-0.834]
 [-2.076]
 [-1.498]] [[1.07 ]
 [1.677]
 [0.83 ]
 [0.578]
 [0.601]
 [0.747]
 [0.806]]
from probs:  [0.10473869815045529, 0.7973089182131605, 0.002169235998013099, 0.0957831476383711]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10583034894752301, 0.7952075075732381, 0.0021815814144629042, 0.09678056206477596]
from probs:  [0.10583034894752301, 0.7952075075732381, 0.0021815814144629042, 0.09678056206477596]
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10324749250294502, 0.7985267209549153, 0.002194329704119181, 0.09603145683802033]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10324749250294502, 0.7985267209549153, 0.002194329704119181, 0.09603145683802033]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10324749250294502, 0.7985267209549153, 0.002194329704119181, 0.09603145683802033]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10324749250294502, 0.7985267209549153, 0.002194329704119181, 0.09603145683802033]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10324749250294502, 0.7985267209549153, 0.002194329704119181, 0.09603145683802033]
first move QE:  0.6120111116712408
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10431527865161529, 0.7964539901959465, 0.0022068433898482253, 0.09702388776258986]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10458252147555971, 0.7959352323697721, 0.0022099752835484272, 0.09727227087111961]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.573]
 [0.74 ]
 [0.676]
 [0.74 ]
 [0.74 ]
 [0.693]
 [0.565]] [[2.996]
 [1.053]
 [1.067]
 [1.053]
 [1.053]
 [1.143]
 [1.503]] [[2.332]
 [1.399]
 [1.284]
 [1.399]
 [1.399]
 [1.366]
 [1.35 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10565268028828219, 0.7938578959191415, 0.0022225167751937845, 0.09826690701738254]
Printing some Q and Qe and total Qs values:  [[0.729]
 [0.714]
 [0.729]
 [0.729]
 [0.729]
 [0.729]
 [0.708]] [[0.857]
 [0.945]
 [0.857]
 [0.857]
 [0.857]
 [0.857]
 [1.386]] [[1.123]
 [1.12 ]
 [1.123]
 [1.123]
 [1.123]
 [1.123]
 [1.256]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
siam score:  -0.65658754
Printing some Q and Qe and total Qs values:  [[0.609]
 [0.573]
 [0.603]
 [0.602]
 [0.577]
 [0.577]
 [0.571]] [[2.466]
 [4.157]
 [3.508]
 [4.235]
 [4.416]
 [4.416]
 [4.066]] [[0.733]
 [1.585]
 [1.284]
 [1.674]
 [1.732]
 [1.732]
 [1.533]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.384]
 [0.302]
 [0.417]
 [0.384]
 [0.384]
 [0.388]
 [0.293]] [[2.057]
 [2.726]
 [2.193]
 [2.057]
 [2.057]
 [1.555]
 [2.612]] [[-0.017]
 [ 0.263]
 [ 0.139]
 [-0.017]
 [-0.017]
 [-0.343]
 [ 0.17 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.764]
 [0.95 ]
 [0.765]
 [0.757]
 [0.775]
 [0.772]
 [0.766]] [[-0.069]
 [ 1.095]
 [ 0.651]
 [-0.324]
 [ 0.163]
 [-0.008]
 [ 0.801]] [[0.163]
 [1.169]
 [0.585]
 [0.001]
 [0.318]
 [0.212]
 [0.674]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10514573931573751, 0.796696400185725, 0.0022388081559181956, 0.09591905234261938]
Printing some Q and Qe and total Qs values:  [[0.523]
 [0.52 ]
 [0.523]
 [0.523]
 [0.523]
 [0.503]
 [0.523]] [[0.899]
 [1.79 ]
 [0.899]
 [0.899]
 [0.899]
 [0.718]
 [0.899]] [[-0.159]
 [ 0.429]
 [-0.159]
 [-0.159]
 [-0.159]
 [-0.319]
 [-0.159]]
siam score:  -0.6549748
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10514573931573751, 0.796696400185725, 0.0022388081559181956, 0.09591905234261938]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.563]
 [0.566]
 [0.593]
 [0.563]
 [0.563]
 [0.563]
 [0.557]] [[-0.346]
 [ 1.231]
 [-0.191]
 [-0.346]
 [-0.346]
 [-0.346]
 [-0.041]] [[0.563]
 [0.566]
 [0.593]
 [0.563]
 [0.563]
 [0.563]
 [0.557]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1054120764035552, 0.79618414284087, 0.0022419862888004263, 0.09616179446677431]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
siam score:  -0.66241264
siam score:  -0.6643262
Printing some Q and Qe and total Qs values:  [[1.177]
 [1.177]
 [1.177]
 [1.177]
 [1.177]
 [1.177]
 [1.177]] [[0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]
 [0.59]] [[2.288]
 [2.288]
 [2.288]
 [2.288]
 [2.288]
 [2.288]
 [2.288]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.903]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]] [[0.32 ]
 [0.737]
 [0.737]
 [0.737]
 [0.737]
 [0.737]
 [0.737]] [[2.292]
 [2.369]
 [2.369]
 [2.369]
 [2.369]
 [2.369]
 [2.369]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10424752642933482, 0.7966718880970608, 0.0022507329262476, 0.09682985254735695]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10451042876817121, 0.7961617757397549, 0.0022539277272696037, 0.09707386776480416]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10477345813444716, 0.7956514169096834, 0.002257124071934756, 0.09731800088393468]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.561]
 [0.715]
 [0.581]
 [0.581]
 [0.581]
 [0.581]] [[-0.185]
 [ 0.214]
 [-1.161]
 [-0.185]
 [-0.185]
 [-0.185]
 [-0.185]] [[1.6  ]
 [1.692]
 [1.541]
 [1.6  ]
 [1.6  ]
 [1.6  ]
 [1.6  ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10437551971258516, 0.7946206851581035, 0.002275587388909055, 0.09872820774040225]
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.469]
 [0.428]
 [0.365]
 [0.36 ]
 [0.37 ]
 [0.378]] [[-1.574]
 [-1.217]
 [-0.92 ]
 [-1.478]
 [-1.383]
 [-1.46 ]
 [-1.53 ]] [[0.205]
 [0.526]
 [0.542]
 [0.23 ]
 [0.252]
 [0.247]
 [0.238]]
line 256 mcts: sample exp_bonus 1.5535566058794292
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1036952671249586, 0.794111140617433, 0.002290963647140819, 0.09990262861046764]
from probs:  [0.1036952671249586, 0.794111140617433, 0.002290963647140819, 0.09990262861046764]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10395197292230307, 0.7936039722202536, 0.0022942004826658566, 0.10014985437477748]
1524 1469
from probs:  [0.10420880804511772, 0.793096548317386, 0.0022974389488719326, 0.10039720468862436]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10498009034441212, 0.7915727416423811, 0.002307164143908486, 0.10114000386929829]
siam score:  -0.6641853
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.43 ]
 [0.451]
 [0.454]
 [0.422]
 [0.431]
 [0.442]
 [0.418]] [[-1.651]
 [-1.268]
 [-1.662]
 [-1.624]
 [-1.717]
 [-1.57 ]
 [-1.448]] [[0.43 ]
 [0.451]
 [0.454]
 [0.422]
 [0.431]
 [0.442]
 [0.418]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10517819851746943, 0.7930789310438128, 0.0023096621146554874, 0.09943320832406229]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.7864017463783881
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10543653468100125, 0.7925732469335801, 0.0023129195076718187, 0.09967729887774683]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10543653468100125, 0.7925732469335801, 0.0023129195076718187, 0.09967729887774683]
Printing some Q and Qe and total Qs values:  [[0.488]
 [0.526]
 [0.627]
 [0.65 ]
 [0.524]
 [0.645]
 [0.622]] [[0.913]
 [0.835]
 [1.201]
 [1.403]
 [1.351]
 [2.369]
 [1.944]] [[0.607]
 [0.656]
 [0.98 ]
 [1.094]
 [0.825]
 [1.406]
 [1.219]]
Printing some Q and Qe and total Qs values:  [[0.233]
 [0.205]
 [0.233]
 [0.233]
 [0.233]
 [0.233]
 [0.225]] [[3.174]
 [2.726]
 [3.174]
 [3.174]
 [3.174]
 [3.174]
 [2.346]] [[0.668]
 [0.315]
 [0.668]
 [0.668]
 [0.668]
 [0.668]
 [0.102]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10569500359355792, 0.7920673029717202, 0.002316178574537217, 0.09992151486018479]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10621234007524379, 0.7910546346915395, 0.00232270173497863, 0.10041032349823809]
in main func line 156:  1531
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10673020878257664, 0.7900409245980524, 0.0023292316063198326, 0.10089963501305119]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10673020878257664, 0.7900409245980524, 0.0023292316063198326, 0.10089963501305119]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10673020878257664, 0.7900409245980524, 0.0023292316063198326, 0.10089963501305119]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10698934297758762, 0.7895336783687847, 0.002332499061814957, 0.10114447959181275]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
line 256 mcts: sample exp_bonus 0.6170249899822332
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10724861053729415, 0.7890261710827358, 0.0023357681989222183, 0.10138945018104807]
Printing some Q and Qe and total Qs values:  [[-0.051]
 [-0.019]
 [-0.038]
 [-0.06 ]
 [-0.06 ]
 [-0.044]
 [-0.034]] [[1.061]
 [1.553]
 [1.006]
 [1.114]
 [1.114]
 [1.077]
 [1.352]] [[-1.357]
 [-1.128]
 [-1.35 ]
 [-1.356]
 [-1.356]
 [-1.338]
 [-1.225]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10724861053729415, 0.7890261710827358, 0.0023357681989222183, 0.10138945018104807]
Printing some Q and Qe and total Qs values:  [[-0.011]
 [-0.01 ]
 [-0.011]
 [-0.011]
 [-0.012]
 [-0.011]
 [-0.01 ]] [[0.72 ]
 [0.891]
 [1.046]
 [0.626]
 [0.597]
 [0.713]
 [0.816]] [[ 0.02 ]
 [ 0.134]
 [ 0.236]
 [-0.044]
 [-0.065]
 [ 0.013]
 [ 0.084]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10398127690805278, 0.7916407973550792, 0.0023443638812976945, 0.10203356185557028]
Printing some Q and Qe and total Qs values:  [[1.148]
 [0.764]
 [0.677]
 [0.691]
 [0.713]
 [0.7  ]
 [0.699]] [[-0.84 ]
 [-0.532]
 [-0.863]
 [-1.125]
 [-1.006]
 [-0.921]
 [-0.976]] [[1.467]
 [0.933]
 [0.561]
 [0.421]
 [0.539]
 [0.567]
 [0.53 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10398127690805278, 0.7916407973550792, 0.0023443638812976945, 0.10203356185557028]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10398127690805278, 0.7916407973550792, 0.0023443638812976945, 0.10203356185557028]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10398127690805278, 0.7916407973550792, 0.0023443638812976945, 0.10203356185557028]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10398127690805278, 0.7916407973550792, 0.0023443638812976945, 0.10203356185557028]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10398127690805278, 0.7916407973550792, 0.0023443638812976945, 0.10203356185557028]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.532]
 [0.431]
 [0.42 ]
 [0.439]
 [0.471]
 [0.439]
 [0.444]] [[-1.095]
 [-0.242]
 [-0.806]
 [-1.006]
 [-0.966]
 [-0.893]
 [-0.789]] [[0.532]
 [0.431]
 [0.42 ]
 [0.439]
 [0.471]
 [0.439]
 [0.444]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10423321539079834, 0.7911383866541608, 0.0023476624187027703, 0.1022807355363382]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1024796729113221, 0.792690336935653, 0.0023503172417025887, 0.1024796729113221]
using explorer policy with actor:  1
first move QE:  0.5989403156838077
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10272795231029555, 0.7921904648444711, 0.0023536305349378538, 0.10272795231029555]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.545]
 [0.589]
 [0.581]
 [0.538]
 [0.538]
 [0.555]
 [0.551]] [[2.396]
 [3.066]
 [2.73 ]
 [2.9  ]
 [2.9  ]
 [2.167]
 [2.082]] [[0.873]
 [1.408]
 [1.168]
 [1.195]
 [1.195]
 [0.74 ]
 [0.676]]
siam score:  -0.6597642
Printing some Q and Qe and total Qs values:  [[0.625]
 [0.623]
 [0.617]
 [0.628]
 [0.622]
 [0.628]
 [0.618]] [[2.118]
 [2.409]
 [1.676]
 [1.587]
 [1.467]
 [1.476]
 [1.449]] [[0.55 ]
 [0.739]
 [0.24 ]
 [0.202]
 [0.11 ]
 [0.129]
 [0.091]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10322491650890273, 0.7911899044507066, 0.002360262531487798, 0.10322491650890273]
Printing some Q and Qe and total Qs values:  [[0.673]
 [0.673]
 [0.673]
 [0.673]
 [0.673]
 [0.673]
 [0.673]] [[1.597]
 [1.597]
 [1.597]
 [1.597]
 [1.597]
 [1.597]
 [1.597]] [[0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.439]
 [0.446]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]] [[-0.224]
 [ 0.431]
 [-0.224]
 [-0.224]
 [-0.224]
 [-0.224]
 [-0.224]] [[0.439]
 [0.446]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10397137796470317, 0.7896870199969798, 0.0023702240736137906, 0.10397137796470317]
siam score:  -0.6617423
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10437791676216261, 0.7928007113309262, 0.0023756493414896795, 0.1004457225654216]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]] [[1.086]
 [1.086]
 [1.086]
 [1.086]
 [1.086]
 [1.086]
 [1.086]] [[0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]
 [0.617]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10462898146787981, 0.7923047808568184, 0.0023789998046956718, 0.10068723787060602]
Printing some Q and Qe and total Qs values:  [[0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.887]
 [0.887]] [[1.606]
 [1.606]
 [1.606]
 [1.606]
 [1.606]
 [1.606]
 [1.606]] [[1.365]
 [1.365]
 [1.365]
 [1.365]
 [1.365]
 [1.365]
 [1.365]]
Printing some Q and Qe and total Qs values:  [[0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]
 [0.656]] [[0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.934]
 [0.934]] [[0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.795]
 [0.795]]
siam score:  -0.66249686
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10462898146787981, 0.7923047808568184, 0.0023789998046956718, 0.10068723787060602]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.64]
 [0.64]
 [0.64]
 [0.64]
 [0.64]
 [0.64]
 [0.64]] [[1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]
 [1.663]] [[1.83]
 [1.83]
 [1.83]
 [1.83]
 [1.83]
 [1.83]
 [1.83]]
Printing some Q and Qe and total Qs values:  [[0.699]
 [0.887]
 [0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.711]] [[-1.182]
 [-0.974]
 [-0.913]
 [-0.913]
 [-0.913]
 [-0.913]
 [-0.898]] [[0.156]
 [0.669]
 [0.361]
 [0.361]
 [0.361]
 [0.361]
 [0.368]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.789]
 [0.798]
 [0.789]
 [0.789]
 [0.789]
 [0.789]
 [0.727]] [[3.201]
 [2.967]
 [3.201]
 [3.201]
 [3.201]
 [3.201]
 [3.174]] [[1.868]
 [1.729]
 [1.868]
 [1.868]
 [1.868]
 [1.868]
 [1.725]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10588643192097504, 0.7898209271522969, 0.0023957805045731004, 0.1018968604221551]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10588643192097504, 0.7898209271522969, 0.0023957805045731004, 0.1018968604221551]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1063904069105526, 0.7888254206162205, 0.0024025060602600183, 0.10238166641296705]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.566]
 [0.501]
 [0.577]
 [0.501]
 [0.501]
 [0.792]
 [0.659]] [[1.174]
 [1.498]
 [1.383]
 [1.498]
 [1.498]
 [1.248]
 [1.348]] [[0.124]
 [0.21 ]
 [0.284]
 [0.21 ]
 [0.21 ]
 [0.625]
 [0.426]]
line 256 mcts: sample exp_bonus 4.713463294302016
Printing some Q and Qe and total Qs values:  [[0.74 ]
 [0.779]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]
 [0.74 ]] [[3.26 ]
 [3.962]
 [3.26 ]
 [3.26 ]
 [3.26 ]
 [3.26 ]
 [3.26 ]] [[1.442]
 [1.988]
 [1.442]
 [1.442]
 [1.442]
 [1.442]
 [1.442]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10664260806054456, 0.7883272453130502, 0.0024058716893361697, 0.1026242749370691]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10664260806054456, 0.7883272453130502, 0.0024058716893361697, 0.1026242749370691]
siam score:  -0.64435303
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10714743827512317, 0.7873300494429869, 0.0024126086580167636, 0.1031099036238731]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10533200258332309, 0.7889342699145091, 0.002415498685596932, 0.10331822881657088]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10558081913173699, 0.7884380540606141, 0.0024188838148277414, 0.10356224299282125]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1058297789019703, 0.7879415525788623, 0.002422270892579944, 0.10380639762658742]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.106078882017719, 0.7874447652225668, 0.002425659920536411, 0.1040506928391779]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.106078882017719, 0.7874447652225668, 0.002425659920536411, 0.1040506928391779]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10450640710828704, 0.788555203887187, 0.0024319818962386572, 0.10450640710828704]
Printing some Q and Qe and total Qs values:  [[0.638]
 [0.537]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]] [[-1.734]
 [-0.073]
 [-0.491]
 [-0.491]
 [-0.491]
 [-0.491]
 [-0.491]] [[0.638]
 [0.537]
 [0.512]
 [0.512]
 [0.512]
 [0.512]
 [0.512]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10475198652419675, 0.7880606382120767, 0.0024353887395297128, 0.10475198652419675]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1049977098420723, 0.7875657827367294, 0.0024387975791258947, 0.1049977098420723]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1049977098420723, 0.7875657827367294, 0.0024387975791258947, 0.1049977098420723]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10524357718843394, 0.7870706372063496, 0.0024422084167823785, 0.10524357718843394]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10548958868995037, 0.7865752013658428, 0.002445621254256395, 0.10548958868995037]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10548958868995037, 0.7865752013658428, 0.002445621254256395, 0.10548958868995037]
Printing some Q and Qe and total Qs values:  [[0.729]
 [0.814]
 [0.868]
 [0.903]
 [0.876]
 [0.876]
 [0.834]] [[1.784]
 [1.9  ]
 [1.512]
 [1.838]
 [2.47 ]
 [2.47 ]
 [2.19 ]] [[1.787]
 [2.054]
 [1.718]
 [2.131]
 [2.775]
 [2.775]
 [2.4  ]]
Printing some Q and Qe and total Qs values:  [[0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]
 [0.728]] [[2.088]
 [2.088]
 [2.088]
 [2.088]
 [2.088]
 [2.088]
 [2.088]] [[1.935]
 [1.935]
 [1.935]
 [1.935]
 [1.935]
 [1.935]
 [1.935]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10435931127528587, 0.788822911086202, 0.0024584663632262636, 0.10435931127528587]
Printing some Q and Qe and total Qs values:  [[0.524]
 [0.505]
 [0.634]
 [0.638]
 [0.63 ]
 [0.624]
 [0.626]] [[ 0.172]
 [ 0.217]
 [-0.562]
 [-1.09 ]
 [-0.944]
 [-0.29 ]
 [-0.527]] [[1.451]
 [1.446]
 [1.306]
 [1.12 ]
 [1.164]
 [1.393]
 [1.31 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10484673839101358, 0.7878411604222055, 0.0024653627957671896, 0.10484673839101358]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10557898848799514, 0.7863662998825949, 0.0024757231414147232, 0.10557898848799514]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
line 256 mcts: sample exp_bonus 4.520567328643729
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10606789640706003, 0.7853815666605656, 0.0024826405253143067, 0.10606789640706003]
line 256 mcts: sample exp_bonus 10.0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10606789640706003, 0.7853815666605656, 0.0024826405253143067, 0.10606789640706003]
siam score:  -0.6496998
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10631257312816536, 0.7848887513746312, 0.0024861023690382006, 0.10631257312816536]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10631257312816536, 0.7848887513746312, 0.0024861023690382006, 0.10631257312816536]
Printing some Q and Qe and total Qs values:  [[0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.561]] [[3.22 ]
 [3.22 ]
 [3.22 ]
 [3.22 ]
 [3.22 ]
 [3.22 ]
 [3.187]] [[0.763]
 [0.763]
 [0.763]
 [0.763]
 [0.763]
 [0.763]
 [0.723]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.5947316580604225
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10631257312816536, 0.7848887513746312, 0.0024861023690382006, 0.10631257312816536]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.6058443762764943
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.1049339680188067, 0.7855454145571404, 0.002496174363007373, 0.10702444306104542]
siam score:  -0.6522851
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.654]
 [0.606]
 [0.654]
 [0.654]
 [0.654]
 [0.622]
 [0.654]] [[4.6  ]
 [5.041]
 [4.6  ]
 [4.6  ]
 [4.6  ]
 [4.782]
 [4.6  ]] [[1.244]
 [1.442]
 [1.244]
 [1.244]
 [1.244]
 [1.302]
 [1.244]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10354944974265458, 0.7862042609284771, 0.002506298394840234, 0.1077399909340281]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10354944974265458, 0.7862042609284771, 0.002506298394840234, 0.1077399909340281]
Printing some Q and Qe and total Qs values:  [[0.854]
 [0.854]
 [0.854]
 [0.854]
 [0.854]
 [0.854]
 [0.861]] [[3.499]
 [3.499]
 [3.499]
 [3.499]
 [3.499]
 [3.499]
 [3.331]] [[2.021]
 [2.021]
 [2.021]
 [2.021]
 [2.021]
 [2.021]
 [1.96 ]]
Printing some Q and Qe and total Qs values:  [[0.683]
 [0.896]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]] [[1.305]
 [2.375]
 [1.305]
 [1.305]
 [1.305]
 [1.305]
 [1.305]] [[0.772]
 [1.442]
 [0.772]
 [0.772]
 [0.772]
 [0.772]
 [0.772]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.10354944974265458, 0.7862042609284771, 0.002506298394840234, 0.1077399909340281]
siam score:  -0.6418924
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.13168790014327406, 0.7283631770710192, 0.002920687328243017, 0.13702823545746382]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.13168790014327406, 0.7283631770710192, 0.002920687328243017, 0.13702823545746382]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
siam score:  -0.6428183
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.13168790014327406, 0.7283631770710192, 0.002920687328243017, 0.13702823545746382]
start point for exploration sampling:  10768
actor:  1 policy actor:  1  step number:  90 total reward:  0.13499999999999934  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09777954813057609, 0.798064806134128, 0.0024213262893821607, 0.1017343194459137]
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]] [[0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]] [[0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0960144419133489, 0.7996293750606734, 0.0024241240357205074, 0.10193205899025712]
in main func line 156:  1574
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0942579671974629, 0.8011862931282189, 0.002426908100870131, 0.102128831573448]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0942579671974629, 0.8011862931282189, 0.002426908100870131, 0.102128831573448]
using explorer policy with actor:  1
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus -1.0565602997126702
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0942579671974629, 0.8011862931282189, 0.002426908100870131, 0.102128831573448]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0942579671974629, 0.8011862931282189, 0.002426908100870131, 0.102128831573448]
siam score:  -0.64061815
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0942579671974629, 0.8011862931282189, 0.002426908100870131, 0.102128831573448]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0942579671974629, 0.8011862931282189, 0.002426908100870131, 0.102128831573448]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0942579671974629, 0.8011862931282189, 0.002426908100870131, 0.102128831573448]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0942579671974629, 0.8011862931282189, 0.002426908100870131, 0.102128831573448]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0925100608243132, 0.8027356163197923, 0.0024296785849393186, 0.10232464427095503]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.133973714245963
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.576]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]] [[0.031]
 [0.18 ]
 [0.18 ]
 [0.18 ]
 [0.18 ]
 [0.18 ]
 [0.18 ]] [[0.576]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]]
using another actor
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.109]
 [0.142]
 [0.121]
 [0.115]
 [0.112]
 [0.117]
 [0.132]] [[2.163]
 [3.13 ]
 [2.845]
 [2.276]
 [2.497]
 [2.615]
 [3.218]] [[-0.346]
 [ 0.432]
 [ 0.19 ]
 [-0.253]
 [-0.087]
 [ 0.009]
 [ 0.489]]
Printing some Q and Qe and total Qs values:  [[0.711]
 [0.769]
 [0.685]
 [0.685]
 [0.685]
 [0.685]
 [0.713]] [[1.231]
 [0.652]
 [1.463]
 [1.463]
 [1.463]
 [1.463]
 [0.951]] [[1.594]
 [1.326]
 [1.698]
 [1.698]
 [1.698]
 [1.698]
 [1.413]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0925100608243132, 0.8027356163197923, 0.0024296785849393186, 0.10232464427095503]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.52 ]
 [0.503]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.52 ]
 [0.497]] [[1.453]
 [2.365]
 [1.453]
 [1.453]
 [1.453]
 [1.453]
 [2.218]] [[0.734]
 [1.451]
 [0.734]
 [0.734]
 [0.734]
 [0.734]
 [1.325]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0925100608243132, 0.8027356163197923, 0.0024296785849393186, 0.10232464427095503]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0925100608243132, 0.8027356163197923, 0.0024296785849393186, 0.10232464427095503]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0925100608243132, 0.8027356163197923, 0.0024296785849393186, 0.10232464427095503]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09269398900731249, 0.804346981090277, 0.002432560011132742, 0.10052646989127775]
Printing some Q and Qe and total Qs values:  [[ 0.003]
 [ 0.063]
 [ 0.086]
 [ 0.048]
 [-0.002]
 [-0.025]
 [ 0.186]] [[0.798]
 [0.755]
 [0.642]
 [0.593]
 [0.669]
 [0.88 ]
 [1.742]] [[-0.628]
 [-0.596]
 [-0.651]
 [-0.724]
 [-0.724]
 [-0.601]
 [ 0.226]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0928770205091034, 0.8059504901831485, 0.00243542738988287, 0.09873706191786548]
Printing some Q and Qe and total Qs values:  [[0.656]
 [0.636]
 [0.609]
 [0.656]
 [0.656]
 [0.656]
 [0.598]] [[1.634]
 [2.61 ]
 [0.931]
 [1.634]
 [1.634]
 [1.634]
 [2.297]] [[ 0.442]
 [ 0.975]
 [-0.05 ]
 [ 0.442]
 [ 0.442]
 [ 0.442]
 [ 0.725]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0928770205091034, 0.8059504901831485, 0.00243542738988287, 0.09873706191786548]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0928770205091034, 0.8059504901831485, 0.00243542738988287, 0.09873706191786548]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0928770205091034, 0.8059504901831485, 0.00243542738988287, 0.09873706191786548]
siam score:  -0.6392114
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0930591618709513, 0.8075462009053643, 0.002438280823665424, 0.09695635640001897]
Printing some Q and Qe and total Qs values:  [[-0.016]
 [ 0.009]
 [-0.004]
 [ 0.011]
 [ 0.018]
 [-0.025]
 [ 0.016]] [[3.107]
 [4.054]
 [3.528]
 [4.807]
 [2.569]
 [1.782]
 [3.824]] [[ 0.543]
 [ 1.079]
 [ 0.782]
 [ 1.491]
 [ 0.277]
 [-0.187]
 [ 0.96 ]]
Printing some Q and Qe and total Qs values:  [[0.164]
 [0.19 ]
 [0.213]
 [0.213]
 [0.178]
 [0.18 ]
 [0.213]] [[-1.409]
 [-0.836]
 [ 0.   ]
 [ 0.   ]
 [-1.627]
 [-1.492]
 [ 0.   ]] [[0.164]
 [0.19 ]
 [0.213]
 [0.213]
 [0.178]
 [0.18 ]
 [0.213]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09324041957065152, 0.8091341700078318, 0.002441120413961804, 0.09518429000755467]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09324041957065152, 0.8091341700078318, 0.002441120413961804, 0.09518429000755467]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09324041957065152, 0.8091341700078318, 0.002441120413961804, 0.09518429000755467]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09324041957065152, 0.8091341700078318, 0.002441120413961804, 0.09518429000755467]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09324041957065152, 0.8091341700078318, 0.002441120413961804, 0.09518429000755467]
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]
 [0.644]] [[1.583]
 [1.583]
 [1.583]
 [1.583]
 [1.583]
 [1.583]
 [1.583]] [[2.061]
 [2.061]
 [2.061]
 [2.061]
 [2.061]
 [2.061]
 [2.061]]
siam score:  -0.6387918
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
using explorer policy with actor:  1
from probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
line 256 mcts: sample exp_bonus 3.278539495961515
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
siam score:  -0.64108676
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
line 256 mcts: sample exp_bonus 0.5212510400845412
Printing some Q and Qe and total Qs values:  [[-0.   ]
 [-0.   ]
 [-0.006]
 [ 0.014]
 [ 0.019]
 [-0.003]
 [ 0.019]] [[1.933]
 [1.573]
 [1.402]
 [1.848]
 [1.956]
 [1.875]
 [1.964]] [[-0.533]
 [-0.773]
 [-0.898]
 [-0.562]
 [-0.48 ]
 [-0.576]
 [-0.475]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
Printing some Q and Qe and total Qs values:  [[0.801]
 [0.866]
 [0.801]
 [0.801]
 [0.801]
 [0.801]
 [0.834]] [[2.686]
 [3.229]
 [2.686]
 [2.686]
 [2.686]
 [2.686]
 [3.398]] [[1.872]
 [2.139]
 [1.872]
 [1.872]
 [1.872]
 [1.872]
 [2.165]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
line 256 mcts: sample exp_bonus 1.7030693251533735
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.751]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.712]] [[2.212]
 [3.319]
 [2.212]
 [2.212]
 [2.212]
 [2.212]
 [2.52 ]] [[1.698]
 [2.18 ]
 [1.698]
 [1.698]
 [1.698]
 [1.698]
 [1.824]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
line 256 mcts: sample exp_bonus 5.055041878700813
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09342080002329721, 0.8107144536921346, 0.002443946261271113, 0.09342080002329721]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.645]
 [0.61 ]
 [0.53 ]
 [0.517]
 [0.517]
 [0.535]
 [0.517]] [[-0.358]
 [ 0.649]
 [ 0.311]
 [ 0.141]
 [ 0.141]
 [ 0.305]
 [ 0.141]] [[0.645]
 [0.61 ]
 [0.53 ]
 [0.517]
 [0.517]
 [0.535]
 [0.517]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
siam score:  -0.6449129
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
Printing some Q and Qe and total Qs values:  [[0.503]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]] [[-1.348]
 [-0.652]
 [-0.652]
 [-0.652]
 [-0.652]
 [-0.652]
 [-0.652]] [[0.503]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]
 [0.434]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
Printing some Q and Qe and total Qs values:  [[0.516]
 [0.516]
 [0.516]
 [0.516]
 [0.516]
 [0.516]
 [0.516]] [[2.224]
 [2.224]
 [2.224]
 [2.224]
 [2.224]
 [2.224]
 [2.224]] [[1.971]
 [1.971]
 [1.971]
 [1.971]
 [1.971]
 [1.971]
 [1.971]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
Printing some Q and Qe and total Qs values:  [[0.672]
 [0.163]
 [0.163]
 [0.163]
 [0.163]
 [0.163]
 [0.163]] [[0.42 ]
 [0.674]
 [0.674]
 [0.674]
 [0.674]
 [0.674]
 [0.674]] [[ 0.685]
 [-0.163]
 [-0.163]
 [-0.163]
 [-0.163]
 [-0.163]
 [-0.163]]
first move QE:  0.5923332301260661
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
Printing some Q and Qe and total Qs values:  [[0.428]
 [0.686]
 [0.686]
 [0.686]
 [0.686]
 [0.726]
 [0.686]] [[1.405]
 [1.053]
 [1.053]
 [1.053]
 [1.053]
 [1.125]
 [1.053]] [[0.629]
 [1.027]
 [1.027]
 [1.027]
 [1.027]
 [1.131]
 [1.027]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
from probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.093600309582036, 0.8122871076171619, 0.002446758465122014, 0.09166582433568]
Printing some Q and Qe and total Qs values:  [[0.157]
 [0.187]
 [0.184]
 [0.157]
 [0.185]
 [0.16 ]
 [0.158]] [[-1.071]
 [-0.949]
 [-0.88 ]
 [-1.435]
 [-1.162]
 [-1.295]
 [-1.067]] [[0.157]
 [0.187]
 [0.184]
 [0.157]
 [0.185]
 [0.16 ]
 [0.158]]
line 256 mcts: sample exp_bonus -1.5670542657262012
Printing some Q and Qe and total Qs values:  [[0.506]
 [0.356]
 [0.722]
 [0.91 ]
 [0.48 ]
 [0.666]
 [0.496]] [[ 1.297]
 [ 1.677]
 [ 0.063]
 [ 1.327]
 [ 0.76 ]
 [-0.555]
 [ 1.232]] [[1.317]
 [1.271]
 [0.928]
 [2.145]
 [0.907]
 [0.405]
 [1.254]]
Printing some Q and Qe and total Qs values:  [[-0.016]
 [-0.017]
 [-0.007]
 [-0.004]
 [-0.007]
 [-0.011]
 [-0.016]] [[ 0.335]
 [ 1.206]
 [ 0.133]
 [-0.021]
 [-0.036]
 [ 0.086]
 [ 0.136]] [[-1.332]
 [-1.042]
 [-1.382]
 [-1.427]
 [-1.437]
 [-1.404]
 [-1.397]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
first move QE:  0.5922625477226666
Printing some Q and Qe and total Qs values:  [[0.31 ]
 [0.228]
 [0.238]
 [0.323]
 [0.241]
 [0.251]
 [0.234]] [[-1.622]
 [ 0.442]
 [-1.077]
 [-0.975]
 [-1.087]
 [-0.656]
 [-0.944]] [[0.31 ]
 [0.228]
 [0.238]
 [0.323]
 [0.241]
 [0.251]
 [0.234]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09184226803298538, 0.8138658823199434, 0.0024495816140858205, 0.09184226803298538]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09184226803298538, 0.8138658823199434, 0.0024495816140858205, 0.09184226803298538]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09184226803298538, 0.8138658823199434, 0.0024495816140858205, 0.09184226803298538]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09184226803298538, 0.8138658823199434, 0.0024495816140858205, 0.09184226803298538]
Printing some Q and Qe and total Qs values:  [[0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]
 [0.687]] [[1.279]
 [1.279]
 [1.279]
 [1.279]
 [1.279]
 [1.279]
 [1.279]] [[2.547]
 [2.547]
 [2.547]
 [2.547]
 [2.547]
 [2.547]
 [2.547]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09184226803298538, 0.8138658823199434, 0.0024495816140858205, 0.09184226803298538]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09184226803298538, 0.8138658823199434, 0.0024495816140858205, 0.09184226803298538]
Printing some Q and Qe and total Qs values:  [[0.635]
 [0.662]
 [0.635]
 [0.635]
 [0.635]
 [0.635]
 [0.694]] [[1.143]
 [1.044]
 [1.143]
 [1.143]
 [1.143]
 [1.143]
 [1.181]] [[2.439]
 [2.428]
 [2.439]
 [2.439]
 [2.439]
 [2.439]
 [2.583]]
Printing some Q and Qe and total Qs values:  [[0.611]
 [0.653]
 [0.595]
 [0.59 ]
 [0.592]
 [0.611]
 [0.64 ]] [[-0.794]
 [-0.371]
 [-1.122]
 [-1.23 ]
 [-1.205]
 [-1.023]
 [-0.751]] [[0.55 ]
 [0.827]
 [0.362]
 [0.299]
 [0.315]
 [0.436]
 [0.616]]
Printing some Q and Qe and total Qs values:  [[0.685]
 [0.711]
 [0.685]
 [0.685]
 [0.685]
 [0.685]
 [0.731]] [[1.938]
 [2.069]
 [1.938]
 [1.938]
 [1.938]
 [1.938]
 [2.395]] [[1.266]
 [1.374]
 [1.266]
 [1.266]
 [1.266]
 [1.266]
 [1.573]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09026522781523807, 0.8170143327282453, 0.0024552116412785126, 0.09026522781523807]
Printing some Q and Qe and total Qs values:  [[0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.552]] [[3.59 ]
 [3.59 ]
 [3.59 ]
 [3.59 ]
 [3.59 ]
 [3.59 ]
 [3.263]] [[1.451]
 [1.451]
 [1.451]
 [1.451]
 [1.451]
 [1.451]
 [1.264]]
using explorer policy with actor:  1
using another actor
Printing some Q and Qe and total Qs values:  [[0.771]
 [0.768]
 [0.744]
 [0.771]
 [0.771]
 [0.771]
 [0.748]] [[3.679]
 [4.9  ]
 [4.321]
 [3.679]
 [3.679]
 [3.679]
 [3.933]] [[1.421]
 [1.989]
 [1.684]
 [1.421]
 [1.421]
 [1.421]
 [1.507]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09026522781523807, 0.8170143327282453, 0.0024552116412785126, 0.09026522781523807]
Printing some Q and Qe and total Qs values:  [[0.458]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.453]] [[-0.364]
 [-0.3  ]
 [-0.3  ]
 [-0.3  ]
 [-0.3  ]
 [-0.3  ]
 [-0.3  ]] [[0.458]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.453]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.09026522781523807, 0.8170143327282453, 0.0024552116412785126, 0.09026522781523807]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
actor:  1 policy actor:  1  step number:  52 total reward:  0.6249999999999998  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
Starting evaluation
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
first move QE:  0.5931041744190895
Printing some Q and Qe and total Qs values:  [[0.467]
 [0.473]
 [0.464]
 [0.456]
 [0.449]
 [0.463]
 [0.468]] [[ 0.354]
 [ 1.054]
 [ 0.182]
 [-0.184]
 [ 0.278]
 [ 0.487]
 [ 0.52 ]] [[0.467]
 [0.473]
 [0.464]
 [0.456]
 [0.449]
 [0.463]
 [0.468]]
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.8901088163085222
Printing some Q and Qe and total Qs values:  [[0.818]
 [0.783]
 [0.717]
 [0.717]
 [0.716]
 [0.782]
 [0.762]] [[1.009]
 [1.766]
 [1.261]
 [0.919]
 [1.166]
 [1.255]
 [1.259]] [[0.818]
 [0.783]
 [0.717]
 [0.717]
 [0.716]
 [0.782]
 [0.762]]
rdn beta is 0 so we're just using the maxi policy
line 256 mcts: sample exp_bonus 3.791052374084452
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
Printing some Q and Qe and total Qs values:  [[0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]] [[0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.501]
 [0.501]] [[0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]
 [0.459]]
Printing some Q and Qe and total Qs values:  [[0.394]
 [0.217]
 [0.413]
 [0.398]
 [0.427]
 [0.426]
 [0.463]] [[0.579]
 [0.816]
 [0.685]
 [0.332]
 [0.308]
 [0.366]
 [0.072]] [[0.394]
 [0.217]
 [0.413]
 [0.398]
 [0.427]
 [0.426]
 [0.463]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
Printing some Q and Qe and total Qs values:  [[0.595]
 [0.454]
 [0.594]
 [0.578]
 [0.615]
 [0.622]
 [0.631]] [[1.638]
 [1.43 ]
 [1.805]
 [1.402]
 [1.45 ]
 [1.606]
 [1.623]] [[0.595]
 [0.454]
 [0.594]
 [0.578]
 [0.615]
 [0.622]
 [0.631]]
Printing some Q and Qe and total Qs values:  [[0.337]
 [0.718]
 [0.527]
 [0.603]
 [0.308]
 [0.556]
 [0.27 ]] [[3.345]
 [3.754]
 [3.092]
 [2.752]
 [3.206]
 [3.216]
 [2.611]] [[1.455]
 [2.091]
 [1.586]
 [1.539]
 [1.363]
 [1.672]
 [1.073]]
Printing some Q and Qe and total Qs values:  [[0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.57 ]] [[0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.673]] [[0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.552]
 [0.57 ]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
Printing some Q and Qe and total Qs values:  [[0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.464]] [[0.37 ]
 [0.37 ]
 [0.37 ]
 [0.37 ]
 [0.37 ]
 [0.37 ]
 [0.707]] [[0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.464]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.569]] [[0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.833]] [[0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.569]]
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.444]
 [0.627]
 [0.621]
 [0.621]
 [0.621]
 [0.671]] [[0.991]
 [1.402]
 [0.861]
 [0.739]
 [0.739]
 [0.739]
 [0.602]] [[1.454]
 [1.314]
 [1.32 ]
 [1.227]
 [1.227]
 [1.227]
 [1.237]]
Printing some Q and Qe and total Qs values:  [[0.633]
 [0.602]
 [0.623]
 [0.634]
 [0.631]
 [0.646]
 [0.572]] [[5.23 ]
 [5.258]
 [5.274]
 [4.209]
 [4.977]
 [5.704]
 [5.072]] [[0.633]
 [0.602]
 [0.623]
 [0.634]
 [0.631]
 [0.646]
 [0.572]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.436]] [[1.824]
 [1.824]
 [1.824]
 [1.824]
 [1.824]
 [1.824]
 [1.824]] [[0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.436]
 [0.436]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.362]
 [0.411]
 [0.451]
 [0.451]
 [0.451]
 [0.657]] [[1.53 ]
 [1.442]
 [1.276]
 [1.53 ]
 [1.53 ]
 [1.53 ]
 [0.684]] [[0.451]
 [0.362]
 [0.411]
 [0.451]
 [0.451]
 [0.451]
 [0.657]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
Printing some Q and Qe and total Qs values:  [[0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.795]] [[0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.778]
 [0.667]] [[0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.795]]
line 256 mcts: sample exp_bonus 0.4747878551543085
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]] [[0.508]
 [0.508]
 [0.508]
 [0.508]
 [0.508]
 [0.508]
 [0.508]] [[0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]
 [0.497]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.584]
 [0.618]
 [0.592]
 [0.589]
 [0.583]
 [0.59 ]
 [0.591]] [[-0.606]
 [-0.136]
 [-0.529]
 [-0.927]
 [-0.884]
 [-0.818]
 [-0.688]] [[0.584]
 [0.965]
 [0.651]
 [0.38 ]
 [0.396]
 [0.455]
 [0.543]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.72 ]
 [0.784]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.783]] [[1.506]
 [1.351]
 [1.506]
 [1.506]
 [1.506]
 [1.506]
 [1.613]] [[1.932]
 [1.958]
 [1.932]
 [1.932]
 [1.932]
 [1.932]
 [2.129]]
Printing some Q and Qe and total Qs values:  [[0.166]
 [0.248]
 [0.166]
 [0.166]
 [0.166]
 [0.166]
 [0.166]] [[0.366]
 [0.923]
 [0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.366]] [[-0.515]
 [-0.006]
 [-0.515]
 [-0.515]
 [-0.515]
 [-0.515]
 [-0.515]]
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.67 ]
 [0.537]
 [0.537]
 [0.537]
 [0.537]
 [0.531]] [[2.429]
 [2.39 ]
 [2.429]
 [2.429]
 [2.429]
 [2.429]
 [2.443]] [[0.751]
 [0.991]
 [0.751]
 [0.751]
 [0.751]
 [0.751]
 [0.748]]
Printing some Q and Qe and total Qs values:  [[0.095]
 [0.164]
 [0.106]
 [0.104]
 [0.111]
 [0.111]
 [0.139]] [[-0.043]
 [ 0.694]
 [-0.044]
 [-0.667]
 [-0.596]
 [-0.245]
 [ 0.795]] [[-0.295]
 [ 0.154]
 [-0.281]
 [-0.581]
 [-0.537]
 [-0.369]
 [ 0.166]]
rdn probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
line 256 mcts: sample exp_bonus 1.6050658425698816
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.465]
 [0.478]
 [0.471]
 [0.466]
 [0.466]
 [0.507]
 [0.459]] [[ 0.409]
 [-0.119]
 [ 0.024]
 [ 0.   ]
 [ 0.   ]
 [ 0.179]
 [ 0.265]] [[0.465]
 [0.478]
 [0.471]
 [0.466]
 [0.466]
 [0.507]
 [0.459]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.347]
 [0.342]
 [0.347]
 [0.347]
 [0.347]
 [0.347]
 [0.367]] [[3.167]
 [2.756]
 [3.167]
 [3.167]
 [3.167]
 [3.167]
 [2.534]] [[0.469]
 [0.185]
 [0.469]
 [0.469]
 [0.469]
 [0.469]
 [0.088]]
Printing some Q and Qe and total Qs values:  [[0.284]
 [0.266]
 [0.294]
 [0.284]
 [0.284]
 [0.284]
 [0.296]] [[3.08 ]
 [2.912]
 [2.684]
 [3.08 ]
 [3.08 ]
 [3.08 ]
 [3.054]] [[0.422]
 [0.273]
 [0.178]
 [0.422]
 [0.422]
 [0.422]
 [0.428]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
siam score:  -0.6469623
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
1650 1555
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using another actor
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.058705623557666155, 0.8806494149473859, 0.0019393379372816552, 0.058705623557666155]
line 256 mcts: sample exp_bonus -0.16287740981376078
Printing some Q and Qe and total Qs values:  [[0.568]
 [0.474]
 [0.474]
 [0.474]
 [0.474]
 [0.474]
 [0.474]] [[1.08 ]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]] [[0.568]
 [0.474]
 [0.474]
 [0.474]
 [0.474]
 [0.474]
 [0.474]]
line 256 mcts: sample exp_bonus 2.9776101150320957
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.63 ]
 [0.665]
 [0.657]
 [0.657]
 [0.657]
 [0.657]] [[0.792]
 [1.951]
 [0.33 ]
 [0.792]
 [0.792]
 [0.792]
 [0.792]] [[0.512]
 [1.232]
 [0.221]
 [0.512]
 [0.512]
 [0.512]
 [0.512]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.05753957637548756, 0.8817425732645686, 0.0019405102175142595, 0.05877734014242969]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.05753957637548756, 0.8817425732645686, 0.0019405102175142595, 0.05877734014242969]
Printing some Q and Qe and total Qs values:  [[0.643]
 [0.635]
 [0.653]
 [0.653]
 [0.651]
 [0.659]
 [0.697]] [[2.039]
 [2.148]
 [2.015]
 [1.702]
 [1.801]
 [2.024]
 [1.736]] [[0.52 ]
 [0.576]
 [0.525]
 [0.315]
 [0.378]
 [0.542]
 [0.426]]
Printing some Q and Qe and total Qs values:  [[0.252]
 [0.242]
 [0.257]
 [0.261]
 [0.287]
 [0.287]
 [0.263]] [[3.86 ]
 [4.145]
 [3.607]
 [3.343]
 [4.28 ]
 [4.28 ]
 [4.838]] [[0.499]
 [0.67 ]
 [0.342]
 [0.174]
 [0.849]
 [0.849]
 [1.174]]
Printing some Q and Qe and total Qs values:  [[0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.301]] [[3.786]
 [3.786]
 [3.786]
 [3.786]
 [3.786]
 [3.786]
 [2.502]] [[0.917]
 [0.917]
 [0.917]
 [0.917]
 [0.917]
 [0.917]
 [0.493]]
actor:  1 policy actor:  1  step number:  47 total reward:  0.5499999999999997  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0437706820729249, 0.9098117624425124, 0.0017105168844624794, 0.04470703860010039]
first move QE:  0.5932411610290146
using another actor
first move QE:  0.5929101812503181
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0437706820729249, 0.9098117624425124, 0.0017105168844624794, 0.04470703860010039]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0437706820729249, 0.9098117624425124, 0.0017105168844624794, 0.04470703860010039]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0437706820729249, 0.9098117624425124, 0.0017105168844624794, 0.04470703860010039]
using explorer policy with actor:  0
line 256 mcts: sample exp_bonus 1.3801119422931711
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.0437706820729249, 0.9098117624425124, 0.0017105168844624794, 0.04470703860010039]
Printing some Q and Qe and total Qs values:  [[0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]] [[2.884]
 [2.884]
 [2.884]
 [2.884]
 [2.884]
 [2.884]
 [2.884]] [[0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]
 [0.567]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.04288140147760455, 0.9106595983822939, 0.0017111834437570634, 0.04474781669634429]
Printing some Q and Qe and total Qs values:  [[0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.732]
 [0.731]] [[2.723]
 [2.723]
 [2.723]
 [2.723]
 [2.723]
 [2.723]
 [3.171]] [[1.775]
 [1.775]
 [1.775]
 [1.775]
 [1.775]
 [1.775]
 [2.001]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.042920851866795263, 0.9115163789012332, 0.0017118570351814428, 0.043850912196790104]
siam score:  -0.6448564
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.042920851866795263, 0.9115163789012332, 0.0017118570351814428, 0.043850912196790104]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.042920851866795263, 0.9115163789012332, 0.0017118570351814428, 0.043850912196790104]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.042920851866795263, 0.9115163789012332, 0.0017118570351814428, 0.043850912196790104]
Printing some Q and Qe and total Qs values:  [[0.51 ]
 [0.548]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.547]] [[2.434]
 [2.005]
 [2.434]
 [2.434]
 [2.434]
 [2.434]
 [2.245]] [[1.343]
 [1.133]
 [1.343]
 [1.343]
 [1.343]
 [1.343]
 [1.291]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.042920851866795263, 0.9115163789012332, 0.0017118570351814428, 0.043850912196790104]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.042920851866795263, 0.9115163789012332, 0.0017118570351814428, 0.043850912196790104]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.042920851866795263, 0.9115163789012332, 0.0017118570351814428, 0.043850912196790104]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.042920851866795263, 0.9115163789012332, 0.0017118570351814428, 0.043850912196790104]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.042920851866795263, 0.9115163789012332, 0.0017118570351814428, 0.043850912196790104]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.042920851866795263, 0.9115163789012332, 0.0017118570351814428, 0.043850912196790104]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.04207513067518153, 0.9132127189400696, 0.001713190679070086, 0.04299895970567875]
Printing some Q and Qe and total Qs values:  [[0.504]
 [0.533]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.504]] [[-0.376]
 [-0.448]
 [-0.376]
 [-0.376]
 [-0.376]
 [-0.376]
 [-0.376]] [[0.504]
 [0.533]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.504]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.04207513067518153, 0.9132127189400696, 0.001713190679070086, 0.04299895970567875]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.04207513067518153, 0.9132127189400696, 0.001713190679070086, 0.04299895970567875]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
actor:  1 policy actor:  1  step number:  72 total reward:  0.1849999999999994  reward:  1.0 rdn_beta:  0.333
using explorer policy with actor:  0
1670 1570
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
siam score:  -0.6365625
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
line 256 mcts: sample exp_bonus 0.5849867593706957
using another actor
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
Printing some Q and Qe and total Qs values:  [[-0.019]
 [-0.02 ]
 [-0.019]
 [-0.019]
 [ 0.773]
 [-0.014]
 [-0.017]] [[0.733]
 [0.994]
 [0.597]
 [0.592]
 [0.856]
 [0.601]
 [0.592]] [[ 0.021]
 [ 0.193]
 [-0.07 ]
 [-0.073]
 [ 1.688]
 [-0.057]
 [-0.069]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]
 [0.707]] [[0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]] [[0.744]
 [0.744]
 [0.744]
 [0.744]
 [0.744]
 [0.744]
 [0.744]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
line 256 mcts: sample exp_bonus -0.0217553524725555
Printing some Q and Qe and total Qs values:  [[0.447]
 [0.482]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.453]] [[-0.072]
 [-0.023]
 [-0.225]
 [-0.225]
 [-0.225]
 [-0.225]
 [-0.225]] [[0.447]
 [0.482]
 [0.453]
 [0.453]
 [0.453]
 [0.453]
 [0.453]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
1677 1576
Printing some Q and Qe and total Qs values:  [[0.698]
 [0.748]
 [0.686]
 [0.699]
 [0.699]
 [0.699]
 [0.689]] [[-0.549]
 [-0.593]
 [-0.444]
 [-0.274]
 [-0.274]
 [-0.274]
 [-0.298]] [[0.785]
 [0.855]
 [0.83 ]
 [0.969]
 [0.969]
 [0.969]
 [0.934]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
Printing some Q and Qe and total Qs values:  [[0.592]
 [0.623]
 [0.592]
 [0.592]
 [0.592]
 [0.592]
 [0.592]] [[1.09 ]
 [2.134]
 [1.09 ]
 [1.09 ]
 [1.09 ]
 [1.09 ]
 [1.09 ]] [[1.116]
 [1.723]
 [1.116]
 [1.116]
 [1.116]
 [1.116]
 [1.116]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
Printing some Q and Qe and total Qs values:  [[0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.435]] [[3.72]
 [3.72]
 [3.72]
 [3.72]
 [3.72]
 [3.72]
 [3.72]] [[1.412]
 [1.412]
 [1.412]
 [1.412]
 [1.412]
 [1.412]
 [1.412]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
first move QE:  0.5921096870901189
Printing some Q and Qe and total Qs values:  [[1.056]
 [1.353]
 [1.056]
 [1.056]
 [1.056]
 [1.056]
 [1.261]] [[0.921]
 [0.718]
 [0.921]
 [0.921]
 [0.921]
 [0.921]
 [0.862]] [[1.493]
 [1.839]
 [1.493]
 [1.493]
 [1.493]
 [1.493]
 [1.774]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
line 256 mcts: sample exp_bonus 3.8692553510982455
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
Printing some Q and Qe and total Qs values:  [[0.369]
 [0.383]
 [0.369]
 [0.369]
 [0.369]
 [0.369]
 [0.391]] [[2.307]
 [2.023]
 [2.307]
 [2.307]
 [2.307]
 [2.307]
 [1.497]] [[0.655]
 [0.492]
 [0.655]
 [0.655]
 [0.655]
 [0.655]
 [0.158]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03695487668607337, 0.9236577677456588, 0.0016237993457581497, 0.03776355622250969]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.036984095921208174, 0.9244074986913524, 0.001624309466231199, 0.036984095921208174]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.036984095921208174, 0.9244074986913524, 0.001624309466231199, 0.036984095921208174]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[-0.3745],
        [-0.5063],
        [-0.0000],
        [-0.0000],
        [ 0.1671],
        [-0.5151],
        [-0.5063],
        [-0.0000],
        [-0.0000],
        [-0.0000]], dtype=torch.float64)
-0.0727797758985 -0.44725969087197465
-0.024259925299500003 -0.5305744267082678
-0.84430764 -0.84430764
-0.7236277114769998 -0.7236277114769998
-0.0438629152995 0.12319499040140215
-0.0727797758985 -0.5878484509297496
-0.024259925299500003 -0.5305744267082678
-0.04410598499999926 -0.04410598499999926
-0.9372103732035 -0.9372103732035
-0.21284999999999943 -0.21284999999999943
from probs:  [0.036984095921208174, 0.9244074986913524, 0.001624309466231199, 0.036984095921208174]
line 256 mcts: sample exp_bonus -0.5611984721613877
Printing some Q and Qe and total Qs values:  [[0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]] [[-0.993]
 [-0.993]
 [-0.993]
 [-0.993]
 [-0.993]
 [-0.993]
 [-0.993]] [[0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]
 [0.392]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.036984095921208174, 0.9244074986913524, 0.001624309466231199, 0.036984095921208174]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.036984095921208174, 0.9244074986913524, 0.001624309466231199, 0.036984095921208174]
siam score:  -0.63664275
using explorer policy with actor:  1
siam score:  -0.6406964
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.036984095921208174, 0.9244074986913524, 0.001624309466231199, 0.036984095921208174]
Printing some Q and Qe and total Qs values:  [[0.582]
 [0.666]
 [0.582]
 [0.582]
 [0.582]
 [0.582]
 [0.584]] [[-0.459]
 [ 0.797]
 [-0.459]
 [-0.459]
 [-0.459]
 [-0.459]
 [-0.211]] [[0.48 ]
 [1.033]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.573]]
Printing some Q and Qe and total Qs values:  [[0.493]
 [0.559]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]] [[0.666]
 [1.94 ]
 [0.666]
 [0.666]
 [0.666]
 [0.666]
 [0.666]] [[0.56 ]
 [1.271]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]]
actor:  1 policy actor:  1  step number:  54 total reward:  0.6049999999999998  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
Printing some Q and Qe and total Qs values:  [[0.649]
 [0.424]
 [0.653]
 [0.514]
 [0.514]
 [0.514]
 [0.495]] [[1.65 ]
 [2.038]
 [1.906]
 [2.685]
 [2.685]
 [2.685]
 [2.037]] [[0.753]
 [0.576]
 [0.918]
 [1.14 ]
 [1.14 ]
 [1.14 ]
 [0.706]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
Printing some Q and Qe and total Qs values:  [[0.433]
 [0.433]
 [0.433]
 [0.433]
 [0.433]
 [0.433]
 [0.426]] [[0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [0.553]] [[0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.483]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
1698 1593
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.518]
 [0.457]
 [0.616]
 [0.627]
 [0.59 ]
 [0.612]
 [0.533]] [[ 1.229]
 [ 1.356]
 [-0.779]
 [-0.362]
 [-0.138]
 [-0.922]
 [ 1.209]] [[1.701]
 [1.668]
 [0.643]
 [0.92 ]
 [0.991]
 [0.547]
 [1.718]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.28235117280611854
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
siam score:  -0.6482228
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
Printing some Q and Qe and total Qs values:  [[0.37 ]
 [0.356]
 [0.353]
 [0.345]
 [0.353]
 [0.353]
 [0.356]] [[0.662]
 [0.591]
 [0.543]
 [0.45 ]
 [0.549]
 [0.58 ]
 [0.591]] [[-0.013]
 [-0.088]
 [-0.126]
 [-0.205]
 [-0.122]
 [-0.101]
 [-0.089]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
line 256 mcts: sample exp_bonus 2.317954405592722
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
Printing some Q and Qe and total Qs values:  [[0.574]
 [0.563]
 [0.563]
 [0.563]
 [0.798]
 [0.563]
 [0.734]] [[-0.434]
 [-0.327]
 [-0.327]
 [-0.327]
 [-1.803]
 [-0.327]
 [-1.353]] [[0.574]
 [0.563]
 [0.563]
 [0.563]
 [0.798]
 [0.563]
 [0.734]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
Printing some Q and Qe and total Qs values:  [[0.543]
 [0.509]
 [0.434]
 [0.434]
 [0.815]
 [0.434]
 [0.853]] [[-0.072]
 [ 0.829]
 [-0.231]
 [-0.231]
 [-0.977]
 [-0.231]
 [ 0.158]] [[0.543]
 [0.509]
 [0.434]
 [0.434]
 [0.815]
 [0.434]
 [0.853]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  0
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.836]
 [0.633]
 [0.747]
 [0.869]
 [0.857]
 [0.731]
 [0.625]] [[3.269]
 [3.368]
 [3.361]
 [2.729]
 [2.614]
 [2.851]
 [3.273]] [[1.521]
 [1.228]
 [1.421]
 [1.269]
 [1.181]
 [1.1  ]
 [1.159]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
first move QE:  0.5920393992155488
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.659]
 [0.633]
 [0.659]
 [0.659]
 [0.659]
 [0.659]
 [0.659]] [[1.55]
 [2.71]
 [1.55]
 [1.55]
 [1.55]
 [1.55]
 [1.55]] [[0.952]
 [1.529]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.415]
 [0.374]
 [0.415]
 [0.423]
 [0.415]
 [0.415]
 [0.371]] [[3.504]
 [3.611]
 [3.504]
 [2.88 ]
 [3.504]
 [3.504]
 [3.193]] [[1.042]
 [1.031]
 [1.042]
 [0.644]
 [1.042]
 [1.042]
 [0.747]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.03026226082500057, 0.9379685212266069, 0.0015069571233921233, 0.03026226082500057]
actor:  1 policy actor:  1  step number:  42 total reward:  0.6349999999999998  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
line 256 mcts: sample exp_bonus 0.5709643103472022
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.8  ]
 [0.897]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]
 [0.8  ]] [[0.508]
 [2.353]
 [0.508]
 [0.508]
 [0.508]
 [0.508]
 [0.508]] [[0.819]
 [1.806]
 [0.819]
 [0.819]
 [0.819]
 [0.819]
 [0.819]]
Printing some Q and Qe and total Qs values:  [[0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]] [[0.589]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]
 [0.653]] [[0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]]
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.707]
 [0.726]
 [0.724]
 [0.712]
 [0.737]
 [0.685]] [[5.314]
 [3.938]
 [3.664]
 [2.425]
 [1.999]
 [3.346]
 [3.317]] [[2.06 ]
 [1.391]
 [1.291]
 [0.719]
 [0.508]
 [1.16 ]
 [1.075]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
Printing some Q and Qe and total Qs values:  [[0.836]
 [0.724]
 [0.724]
 [0.724]
 [0.724]
 [0.724]
 [0.724]] [[3.459]
 [2.424]
 [2.424]
 [2.424]
 [2.424]
 [2.424]
 [2.424]] [[0.836]
 [0.724]
 [0.724]
 [0.724]
 [0.724]
 [0.724]
 [0.724]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
Printing some Q and Qe and total Qs values:  [[0.789]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]] [[0.607]
 [0.606]
 [0.606]
 [0.606]
 [0.606]
 [0.606]
 [0.606]] [[0.789]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]
 [0.717]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.607]
 [0.556]
 [0.384]
 [0.468]
 [0.607]
 [0.393]
 [0.452]] [[1.492]
 [1.539]
 [1.287]
 [1.285]
 [1.492]
 [0.754]
 [1.586]] [[1.558]
 [1.486]
 [0.975]
 [1.142]
 [1.558]
 [0.638]
 [1.309]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.595]
 [0.656]
 [0.656]
 [0.783]
 [0.656]
 [0.656]
 [0.609]] [[1.28 ]
 [1.288]
 [1.288]
 [1.164]
 [1.288]
 [1.288]
 [1.636]] [[1.568]
 [1.695]
 [1.695]
 [1.867]
 [1.695]
 [1.695]
 [1.834]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.6  ]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]] [[0.312]
 [0.5  ]
 [0.312]
 [0.312]
 [0.312]
 [0.312]
 [0.312]] [[0.652]
 [1.079]
 [0.652]
 [0.652]
 [0.652]
 [0.652]
 [0.652]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Showing what the boot values, the n step returns and the n step returns with V look like
tensor([[ 0.2792],
        [-0.0000],
        [-0.0000],
        [-0.0000],
        [-0.0000],
        [-0.0000],
        [-0.0000],
        [-0.4750],
        [-0.0000],
        [ 0.1583]], dtype=torch.float64)
-0.0727797758985 0.20637508997090004
-0.94167714465 -0.94167714465
-0.9608890648499999 -0.9608890648499999
-0.7820999999999999 -0.7820999999999999
-0.7018221820499999 -0.7018221820499999
-0.849159135 -0.849159135
-0.93163455 -0.93163455
-0.024259925299500003 -0.49928720590323367
0.9117840748499999 0.9117840748499999
-0.0727797758985 0.08553454927761454
Printing some Q and Qe and total Qs values:  [[0.562]
 [0.551]
 [0.55 ]
 [0.562]
 [0.562]
 [0.562]
 [0.562]] [[ 0.   ]
 [ 0.645]
 [-0.635]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[0.562]
 [0.551]
 [0.55 ]
 [0.562]
 [0.562]
 [0.562]
 [0.562]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029238228604650588, 0.9400344636096365, 0.0014890791810622714, 0.029238228604650588]
Printing some Q and Qe and total Qs values:  [[0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]
 [0.73]] [[0.942]
 [0.942]
 [0.942]
 [0.942]
 [0.942]
 [0.942]
 [0.942]] [[2.051]
 [2.051]
 [2.051]
 [2.051]
 [2.051]
 [2.051]
 [2.051]]
using another actor
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.673]
 [0.681]
 [0.705]
 [0.7  ]
 [0.695]
 [0.716]
 [0.711]] [[1.824]
 [2.727]
 [2.612]
 [1.729]
 [1.804]
 [1.719]
 [2.09 ]] [[0.236]
 [0.853]
 [0.826]
 [0.228]
 [0.267]
 [0.252]
 [0.491]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029256096130126995, 0.9406285492637646, 0.0014893911190889237, 0.02862596348701935]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029256096130126995, 0.9406285492637646, 0.0014893911190889237, 0.02862596348701935]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029256096130126995, 0.9406285492637646, 0.0014893911190889237, 0.02862596348701935]
Printing some Q and Qe and total Qs values:  [[0.681]
 [0.672]
 [0.684]
 [0.684]
 [0.684]
 [0.646]
 [0.646]] [[0.356]
 [2.13 ]
 [1.319]
 [1.319]
 [1.319]
 [0.117]
 [2.269]] [[0.505]
 [1.579]
 [1.103]
 [1.103]
 [1.103]
 [0.293]
 [1.617]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029256096130126995, 0.9406285492637646, 0.0014893911190889237, 0.02862596348701935]
Printing some Q and Qe and total Qs values:  [[0.8]
 [0.8]
 [0.8]
 [0.8]
 [0.8]
 [0.8]
 [0.8]] [[1.274]
 [1.274]
 [1.274]
 [1.274]
 [1.274]
 [1.274]
 [1.274]] [[2.359]
 [2.359]
 [2.359]
 [2.359]
 [2.359]
 [2.359]
 [2.359]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029256096130126995, 0.9406285492637646, 0.0014893911190889237, 0.02862596348701935]
Printing some Q and Qe and total Qs values:  [[0.518]
 [0.562]
 [0.501]
 [0.527]
 [0.449]
 [0.482]
 [0.706]] [[1.823]
 [1.036]
 [1.599]
 [1.888]
 [1.63 ]
 [1.651]
 [2.212]] [[0.507]
 [0.072]
 [0.323]
 [0.57 ]
 [0.242]
 [0.32 ]
 [1.142]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029256096130126995, 0.9406285492637646, 0.0014893911190889237, 0.02862596348701935]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029256096130126995, 0.9406285492637646, 0.0014893911190889237, 0.02862596348701935]
siam score:  -0.638286
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029256096130126995, 0.9406285492637646, 0.0014893911190889237, 0.02862596348701935]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.029256096130126995, 0.9406285492637646, 0.0014893911190889237, 0.02862596348701935]
actor:  1 policy actor:  1  step number:  51 total reward:  0.5699999999999997  reward:  1.0 rdn_beta:  0.333
line 256 mcts: sample exp_bonus 1.3412781324378604
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02509764477296933, 0.948925328211892, 0.001416791300384637, 0.02456023571475402]
Printing some Q and Qe and total Qs values:  [[0.722]
 [0.795]
 [0.732]
 [0.711]
 [0.72 ]
 [0.71 ]
 [0.723]] [[1.081]
 [0.963]
 [1.303]
 [1.534]
 [1.758]
 [1.261]
 [1.277]] [[1.631]
 [1.619]
 [1.91 ]
 [2.146]
 [2.428]
 [1.822]
 [1.864]]
Printing some Q and Qe and total Qs values:  [[0.548]
 [0.574]
 [0.548]
 [0.615]
 [0.548]
 [0.548]
 [0.548]] [[0.   ]
 [0.562]
 [0.   ]
 [0.225]
 [0.   ]
 [0.   ]
 [0.   ]] [[-0.283]
 [ 0.519]
 [-0.283]
 [ 0.151]
 [-0.283]
 [-0.283]
 [-0.283]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02509764477296933, 0.948925328211892, 0.001416791300384637, 0.02456023571475402]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
siam score:  -0.6409506
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.634]
 [0.527]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.605]] [[1.13 ]
 [1.581]
 [1.164]
 [1.164]
 [1.164]
 [1.164]
 [0.928]] [[1.356]
 [1.442]
 [1.45 ]
 [1.45 ]
 [1.45 ]
 [1.45 ]
 [1.165]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02509764477296933, 0.948925328211892, 0.001416791300384637, 0.02456023571475402]
Printing some Q and Qe and total Qs values:  [[0.334]
 [0.44 ]
 [0.334]
 [0.334]
 [0.334]
 [0.334]
 [0.334]] [[-1.092]
 [ 0.743]
 [-1.092]
 [-1.092]
 [-1.092]
 [-1.092]
 [-1.092]] [[-0.186]
 [ 0.639]
 [-0.186]
 [-0.186]
 [-0.186]
 [-0.186]
 [-0.186]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02509764477296933, 0.948925328211892, 0.001416791300384637, 0.02456023571475402]
Printing some Q and Qe and total Qs values:  [[1.158]
 [1.252]
 [1.158]
 [1.158]
 [1.158]
 [1.158]
 [1.158]] [[0.373]
 [0.381]
 [0.373]
 [0.373]
 [0.373]
 [0.373]
 [0.373]] [[1.935]
 [2.127]
 [1.935]
 [1.935]
 [1.935]
 [1.935]
 [1.935]]
siam score:  -0.63767695
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02509764477296933, 0.948925328211892, 0.001416791300384637, 0.02456023571475402]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02509764477296933, 0.948925328211892, 0.001416791300384637, 0.02456023571475402]
Printing some Q and Qe and total Qs values:  [[0.092]
 [0.161]
 [0.536]
 [0.185]
 [0.169]
 [0.128]
 [0.157]] [[1.518]
 [1.915]
 [1.073]
 [0.685]
 [0.903]
 [1.142]
 [2.001]] [[-0.503]
 [-0.232]
 [ 0.238]
 [-0.595]
 [-0.554]
 [-0.556]
 [-0.211]]
line 256 mcts: sample exp_bonus 1.1957006821505338
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02509764477296933, 0.948925328211892, 0.001416791300384637, 0.02456023571475402]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02509764477296933, 0.948925328211892, 0.001416791300384637, 0.02456023571475402]
using another actor
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.274]
 [0.323]
 [0.445]
 [0.389]
 [0.157]
 [0.343]
 [0.283]] [[1.365]
 [0.95 ]
 [0.069]
 [1.236]
 [0.778]
 [0.653]
 [1.636]] [[0.274]
 [0.323]
 [0.445]
 [0.389]
 [0.157]
 [0.343]
 [0.283]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.025110545712730345, 0.9494327287298497, 0.001417016529876898, 0.024039709027542818]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.805]
 [0.919]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[1.323]
 [2.315]
 [1.323]
 [1.323]
 [1.323]
 [1.323]
 [1.323]] [[1.477]
 [1.995]
 [1.477]
 [1.477]
 [1.477]
 [1.477]
 [1.477]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024585583763555546, 0.9499450164805396, 0.0014172439287578526, 0.02405215582714694]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024585583763555546, 0.9499450164805396, 0.0014172439287578526, 0.02405215582714694]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024585583763555546, 0.9499450164805396, 0.0014172439287578526, 0.02405215582714694]
Printing some Q and Qe and total Qs values:  [[0.471]
 [0.673]
 [0.471]
 [0.471]
 [0.471]
 [0.471]
 [0.671]] [[2.04 ]
 [2.435]
 [2.04 ]
 [2.04 ]
 [2.04 ]
 [2.04 ]
 [2.3  ]] [[1.14 ]
 [1.704]
 [1.14 ]
 [1.14 ]
 [1.14 ]
 [1.14 ]
 [1.623]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024585583763555546, 0.9499450164805396, 0.0014172439287578526, 0.02405215582714694]
using explorer policy with actor:  1
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024585583763555546, 0.9499450164805396, 0.0014172439287578526, 0.02405215582714694]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024585583763555546, 0.9499450164805396, 0.0014172439287578526, 0.02405215582714694]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024585583763555546, 0.9499450164805396, 0.0014172439287578526, 0.02405215582714694]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024585583763555546, 0.9499450164805396, 0.0014172439287578526, 0.02405215582714694]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.29 ]
 [0.027]
 [0.335]
 [0.339]
 [0.312]
 [0.293]
 [0.059]] [[0.537]
 [0.757]
 [0.417]
 [0.178]
 [0.358]
 [0.827]
 [0.766]] [[0.475]
 [0.095]
 [0.485]
 [0.334]
 [0.399]
 [0.673]
 [0.164]]
Printing some Q and Qe and total Qs values:  [[0.677]
 [0.604]
 [0.592]
 [0.592]
 [0.592]
 [0.592]
 [0.592]] [[-1.355]
 [-0.111]
 [-0.603]
 [-0.603]
 [-0.603]
 [-0.603]
 [-0.603]] [[0.677]
 [0.604]
 [0.592]
 [0.592]
 [0.592]
 [0.592]
 [0.592]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
Printing some Q and Qe and total Qs values:  [[0.336]
 [0.336]
 [0.336]
 [0.336]
 [0.336]
 [0.336]
 [0.336]] [[0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]] [[0.563]
 [0.563]
 [0.563]
 [0.563]
 [0.563]
 [0.563]
 [0.563]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
from probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.18080041377893463
siam score:  -0.6394867
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
using explorer policy with actor:  1
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.0979839070585333
Printing some Q and Qe and total Qs values:  [[0.473]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]] [[-1.353]
 [-0.928]
 [-0.928]
 [-0.928]
 [-0.928]
 [-0.928]
 [-0.928]] [[0.473]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
Printing some Q and Qe and total Qs values:  [[0.693]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]] [[1.877]
 [1.806]
 [1.806]
 [1.806]
 [1.806]
 [1.806]
 [1.806]] [[0.693]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]]
Printing some Q and Qe and total Qs values:  [[0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]] [[0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]
 [0.977]] [[1.331]
 [1.331]
 [1.331]
 [1.331]
 [1.331]
 [1.331]
 [1.331]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
Printing some Q and Qe and total Qs values:  [[0.89 ]
 [0.658]
 [0.658]
 [0.815]
 [0.658]
 [0.826]
 [0.658]] [[1.111]
 [1.733]
 [1.733]
 [1.099]
 [1.733]
 [1.029]
 [1.719]] [[2.486]
 [2.44 ]
 [2.44 ]
 [2.34 ]
 [2.44 ]
 [2.318]
 [2.432]]
Printing some Q and Qe and total Qs values:  [[1.192]
 [1.192]
 [1.192]
 [1.192]
 [1.192]
 [1.192]
 [1.361]] [[0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.806]
 [0.862]] [[1.818]
 [1.818]
 [1.818]
 [1.818]
 [1.818]
 [1.818]
 [2.193]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
Printing some Q and Qe and total Qs values:  [[0.69 ]
 [0.838]
 [0.707]
 [0.721]
 [0.704]
 [0.721]
 [0.7  ]] [[-0.916]
 [ 0.637]
 [-0.625]
 [-0.724]
 [-0.686]
 [-0.42 ]
 [-0.528]] [[0.277]
 [1.134]
 [0.424]
 [0.399]
 [0.394]
 [0.529]
 [0.456]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.54 ]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]] [[-0.048]
 [ 0.527]
 [-0.048]
 [-0.048]
 [-0.048]
 [-0.048]
 [-0.048]] [[0.511]
 [0.54 ]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.583]
 [0.612]
 [0.571]
 [0.583]
 [0.583]
 [0.583]
 [0.696]] [[1.991]
 [2.717]
 [0.598]
 [1.991]
 [1.991]
 [1.991]
 [2.493]] [[0.583]
 [0.612]
 [0.571]
 [0.583]
 [0.583]
 [0.583]
 [0.696]]
siam score:  -0.63001156
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024064510428077425, 0.9504535095006456, 0.001417469643199765, 0.024064510428077425]
siam score:  -0.6257791
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024076773850985535, 0.9509582497983265, 0.0014176936918495928, 0.023547282658838344]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024076773850985535, 0.9509582497983265, 0.0014176936918495928, 0.023547282658838344]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024076773850985535, 0.9509582497983265, 0.0014176936918495928, 0.023547282658838344]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024076773850985535, 0.9509582497983265, 0.0014176936918495928, 0.023547282658838344]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024076773850985535, 0.9509582497983265, 0.0014176936918495928, 0.023547282658838344]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024076773850985535, 0.9509582497983265, 0.0014176936918495928, 0.023547282658838344]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024076773850985535, 0.9509582497983265, 0.0014176936918495928, 0.023547282658838344]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024076773850985535, 0.9509582497983265, 0.0014176936918495928, 0.023547282658838344]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024076773850985535, 0.9509582497983265, 0.0014176936918495928, 0.023547282658838344]
Printing some Q and Qe and total Qs values:  [[0.538]
 [0.335]
 [0.335]
 [0.335]
 [0.335]
 [0.335]
 [0.335]] [[1.146]
 [0.47 ]
 [0.47 ]
 [0.47 ]
 [0.47 ]
 [0.47 ]
 [0.47 ]] [[0.538]
 [0.335]
 [0.335]
 [0.335]
 [0.335]
 [0.335]
 [0.335]]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[1.028]
 [1.028]
 [1.028]
 [1.028]
 [1.028]
 [1.028]
 [0.917]] [[1.439]
 [1.439]
 [1.439]
 [1.439]
 [1.439]
 [1.439]
 [1.511]] [[1.295]
 [1.295]
 [1.295]
 [1.295]
 [1.295]
 [1.295]
 [1.119]]
UNIT TEST: sample policy line 217 mcts : [0.041 0.224 0.102 0.388 0.02  0.02  0.204]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.024076773850985535, 0.9509582497983265, 0.0014176936918495928, 0.023547282658838344]
rdn beta is 0 so we're just using the maxi policy
1768 1655
Printing some Q and Qe and total Qs values:  [[0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [0.924]
 [1.271]] [[1.265]
 [1.265]
 [1.265]
 [1.265]
 [1.265]
 [1.265]
 [2.542]] [[1.341]
 [1.341]
 [1.341]
 [1.341]
 [1.341]
 [1.341]
 [2.705]]
Printing some Q and Qe and total Qs values:  [[0.658]
 [0.573]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]] [[0.107]
 [1.561]
 [0.139]
 [0.139]
 [0.139]
 [0.139]
 [0.139]] [[0.658]
 [0.573]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02355927749529301, 0.9514635270305752, 0.001417917978838752, 0.02355927749529301]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02355927749529301, 0.9514635270305752, 0.001417917978838752, 0.02355927749529301]
actor:  1 policy actor:  1  step number:  71 total reward:  0.26999999999999946  reward:  1.0 rdn_beta:  0.333
Printing some Q and Qe and total Qs values:  [[0.491]
 [0.491]
 [0.491]
 [0.491]
 [0.491]
 [0.491]
 [0.496]] [[4.311]
 [4.311]
 [4.311]
 [4.311]
 [4.311]
 [4.311]
 [4.279]] [[1.329]
 [1.329]
 [1.329]
 [1.329]
 [1.329]
 [1.329]
 [1.317]]
Printing some Q and Qe and total Qs values:  [[0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.479]] [[1.217]
 [1.217]
 [1.217]
 [1.217]
 [1.217]
 [1.217]
 [2.636]] [[1.436]
 [1.436]
 [1.436]
 [1.436]
 [1.436]
 [1.436]
 [1.986]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021577207608416783, 0.9554647287925349, 0.0013808559906315593, 0.021577207608416783]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.649]
 [0.604]
 [0.629]
 [0.642]
 [0.608]
 [0.611]
 [0.608]] [[-0.48 ]
 [ 0.386]
 [-0.106]
 [-0.849]
 [-0.837]
 [-0.562]
 [-0.21 ]] [[1.505]
 [1.805]
 [1.633]
 [1.345]
 [1.307]
 [1.424]
 [1.565]]
siam score:  -0.63015723
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
siam score:  -0.6308537
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021577207608416783, 0.9554647287925349, 0.0013808559906315593, 0.021577207608416783]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021577207608416783, 0.9554647287925349, 0.0013808559906315593, 0.021577207608416783]
Printing some Q and Qe and total Qs values:  [[0.429]
 [0.532]
 [0.484]
 [0.541]
 [0.53 ]
 [0.437]
 [0.514]] [[2.756]
 [3.388]
 [3.512]
 [2.752]
 [2.616]
 [2.563]
 [3.644]] [[0.669]
 [1.294]
 [1.282]
 [0.889]
 [0.777]
 [0.556]
 [1.429]]
using explorer policy with actor:  1
siam score:  -0.6278278
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.455]
 [0.508]
 [0.562]
 [0.609]
 [0.57 ]
 [0.633]
 [0.546]] [[2.437]
 [2.793]
 [2.653]
 [2.044]
 [1.908]
 [2.804]
 [4.741]] [[0.655]
 [0.976]
 [0.989]
 [0.699]
 [0.542]
 [1.216]
 [2.257]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021577207608416783, 0.9554647287925349, 0.0013808559906315593, 0.021577207608416783]
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.616]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]] [[1.46 ]
 [2.432]
 [1.46 ]
 [1.46 ]
 [1.46 ]
 [1.46 ]
 [1.46 ]] [[0.372]
 [1.239]
 [0.372]
 [0.372]
 [0.372]
 [0.372]
 [0.372]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021577207608416783, 0.9554647287925349, 0.0013808559906315593, 0.021577207608416783]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021577207608416783, 0.9554647287925349, 0.0013808559906315593, 0.021577207608416783]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021577207608416783, 0.9554647287925349, 0.0013808559906315593, 0.021577207608416783]
Printing some Q and Qe and total Qs values:  [[1.201]
 [1.155]
 [1.222]
 [1.201]
 [1.201]
 [1.201]
 [1.401]] [[0.769]
 [0.762]
 [0.551]
 [0.769]
 [0.769]
 [0.769]
 [0.865]] [[2.539]
 [2.456]
 [2.449]
 [2.539]
 [2.539]
 [2.539]
 [2.934]]
Printing some Q and Qe and total Qs values:  [[0.454]
 [0.48 ]
 [0.454]
 [0.454]
 [0.454]
 [0.527]
 [0.484]] [[2.117]
 [1.625]
 [2.117]
 [2.117]
 [2.117]
 [1.693]
 [1.777]] [[0.333]
 [0.057]
 [0.333]
 [0.333]
 [0.333]
 [0.195]
 [0.165]]
siam score:  -0.6283812
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021577207608416783, 0.9554647287925349, 0.0013808559906315593, 0.021577207608416783]
from probs:  [0.021577207608416783, 0.9554647287925349, 0.0013808559906315593, 0.021577207608416783]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
siam score:  -0.6334878
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02110770903077127, 0.9559241359497865, 0.0013810412227643638, 0.021587113796677954]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02110770903077127, 0.9559241359497865, 0.0013810412227643638, 0.021587113796677954]
siam score:  -0.63233393
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02110770903077127, 0.9559241359497865, 0.0013810412227643638, 0.021587113796677954]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02110770903077127, 0.9559241359497865, 0.0013810412227643638, 0.021587113796677954]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.046]
 [0.02 ]
 [0.01 ]
 [0.01 ]
 [0.012]
 [0.01 ]
 [0.012]] [[-1.326]
 [ 0.088]
 [-1.566]
 [-1.566]
 [-1.249]
 [-1.566]
 [-0.84 ]] [[0.046]
 [0.02 ]
 [0.01 ]
 [0.01 ]
 [0.012]
 [0.01 ]
 [0.012]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
from probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
1789 1678
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
from probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
using another actor
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.099]
 [0.162]
 [0.102]
 [0.102]
 [0.102]
 [0.105]
 [0.102]] [[-1.713]
 [-0.925]
 [-1.089]
 [-1.089]
 [-1.089]
 [-1.168]
 [-0.958]] [[0.099]
 [0.162]
 [0.102]
 [0.102]
 [0.102]
 [0.105]
 [0.102]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
using another actor
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
Printing some Q and Qe and total Qs values:  [[0.698]
 [0.698]
 [0.698]
 [0.698]
 [0.698]
 [0.698]
 [0.649]] [[2.004]
 [2.004]
 [2.004]
 [2.004]
 [2.004]
 [2.004]
 [1.779]] [[1.219]
 [1.219]
 [1.219]
 [1.219]
 [1.219]
 [1.219]
 [0.972]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
siam score:  -0.6233769
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
in main func line 156:  1800
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.322]
 [0.322]
 [0.341]
 [0.322]
 [0.322]
 [0.322]
 [0.342]] [[ 0.082]
 [ 0.082]
 [-0.265]
 [ 0.082]
 [ 0.082]
 [ 0.082]
 [ 0.166]] [[0.322]
 [0.322]
 [0.341]
 [0.322]
 [0.322]
 [0.322]
 [0.342]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02064169279536389, 0.9563801356143969, 0.001381225081002314, 0.021596946509236648]
Printing some Q and Qe and total Qs values:  [[0.57 ]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [0.697]
 [1.12 ]] [[1.523]
 [1.363]
 [1.363]
 [1.363]
 [1.363]
 [1.363]
 [2.035]] [[1.746]
 [1.858]
 [1.858]
 [1.858]
 [1.858]
 [1.858]
 [2.842]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.3110449024380475
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02017912030175561, 0.9568327655571267, 0.001381407580574512, 0.0216067065605431]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02017912030175561, 0.9568327655571267, 0.001381407580574512, 0.0216067065605431]
Printing some Q and Qe and total Qs values:  [[1.321]
 [0.746]
 [0.746]
 [0.746]
 [0.746]
 [0.746]
 [0.782]] [[3.345]
 [1.904]
 [1.904]
 [1.904]
 [1.904]
 [1.904]
 [1.317]] [[2.723]
 [1.573]
 [1.573]
 [1.573]
 [1.573]
 [1.573]
 [1.399]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.410717821686255
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.633]
 [0.635]
 [0.617]
 [0.617]
 [0.625]
 [0.621]] [[0.411]
 [1.117]
 [0.459]
 [0.244]
 [0.244]
 [0.391]
 [0.832]] [[0.65 ]
 [0.633]
 [0.635]
 [0.617]
 [0.617]
 [0.625]
 [0.621]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02017912030175561, 0.9568327655571267, 0.001381407580574512, 0.0216067065605431]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02017912030175561, 0.9568327655571267, 0.001381407580574512, 0.0216067065605431]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02017912030175561, 0.9568327655571267, 0.001381407580574512, 0.0216067065605431]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02017912030175561, 0.9568327655571267, 0.001381407580574512, 0.0216067065605431]
Printing some Q and Qe and total Qs values:  [[0.98 ]
 [1.144]
 [0.978]
 [0.986]
 [0.986]
 [0.986]
 [0.99 ]] [[-0.593]
 [-0.451]
 [-0.464]
 [-0.264]
 [-0.264]
 [-0.264]
 [-0.425]] [[1.476]
 [1.852]
 [1.515]
 [1.598]
 [1.598]
 [1.598]
 [1.552]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02017912030175561, 0.9568327655571267, 0.001381407580574512, 0.0216067065605431]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02017912030175561, 0.9568327655571267, 0.001381407580574512, 0.0216067065605431]
Printing some Q and Qe and total Qs values:  [[0.08 ]
 [0.051]
 [0.109]
 [0.092]
 [0.003]
 [0.038]
 [0.036]] [[1.061]
 [2.586]
 [3.033]
 [0.543]
 [1.166]
 [3.209]
 [3.246]] [[-0.664]
 [-0.214]
 [ 0.051]
 [-0.814]
 [-0.784]
 [-0.032]
 [-0.023]]
Printing some Q and Qe and total Qs values:  [[1.016]
 [1.016]
 [1.016]
 [1.016]
 [1.016]
 [1.016]
 [1.153]] [[3.352]
 [3.352]
 [3.352]
 [3.352]
 [3.352]
 [3.352]
 [4.197]] [[1.372]
 [1.372]
 [1.372]
 [1.372]
 [1.372]
 [1.372]
 [1.837]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.019719953517902167, 0.9572820629925575, 0.0013815887364858098, 0.021616394753054678]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.019719953517902167, 0.9572820629925575, 0.0013815887364858098, 0.021616394753054678]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.019719953517902167, 0.9572820629925575, 0.0013815887364858098, 0.021616394753054678]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.096]
 [0.141]
 [0.081]
 [0.081]
 [0.081]
 [0.081]
 [0.141]] [[1.309]
 [1.002]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [0.829]] [[0.096]
 [0.141]
 [0.081]
 [0.081]
 [0.081]
 [0.081]
 [0.141]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.374]
 [0.436]
 [0.366]
 [0.416]
 [0.376]
 [0.385]
 [0.374]] [[-0.094]
 [-0.022]
 [-0.373]
 [-0.17 ]
 [-0.563]
 [-0.33 ]
 [-0.512]] [[0.374]
 [0.436]
 [0.366]
 [0.416]
 [0.376]
 [0.385]
 [0.374]]
Printing some Q and Qe and total Qs values:  [[0.365]
 [0.691]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.369]] [[0.833]
 [0.376]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.94 ]] [[0.365]
 [0.691]
 [0.365]
 [0.365]
 [0.365]
 [0.365]
 [0.369]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021789178413832596, 0.9522982429206152, 0.0014350873184135614, 0.024477491347138627]
from probs:  [0.021789178413832596, 0.9522982429206152, 0.0014350873184135614, 0.024477491347138627]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021789178413832596, 0.9522982429206152, 0.0014350873184135614, 0.024477491347138627]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.67]
 [0.54]
 [0.54]
 [0.54]
 [0.54]
 [0.54]
 [0.54]] [[0.852]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]
 [0.72 ]] [[0.67]
 [0.54]
 [0.54]
 [0.54]
 [0.54]
 [0.54]
 [0.54]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021789178413832596, 0.9522982429206152, 0.0014350873184135614, 0.024477491347138627]
siam score:  -0.6244228
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021789178413832596, 0.9522982429206152, 0.0014350873184135614, 0.024477491347138627]
Printing some Q and Qe and total Qs values:  [[0.577]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]] [[0.64 ]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]
 [0.759]] [[0.577]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]]
Printing some Q and Qe and total Qs values:  [[0.799]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[0.669]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]] [[0.799]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021789178413832596, 0.9522982429206152, 0.0014350873184135614, 0.024477491347138627]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021789178413832596, 0.9522982429206152, 0.0014350873184135614, 0.024477491347138627]
Printing some Q and Qe and total Qs values:  [[0.909]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]] [[0.51 ]
 [0.758]
 [0.758]
 [0.758]
 [0.758]
 [0.758]
 [0.758]] [[0.909]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]
 [0.833]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.583]
 [0.524]
 [0.568]
 [0.576]
 [0.565]
 [0.575]
 [0.607]] [[1.407]
 [1.611]
 [1.675]
 [1.515]
 [1.468]
 [1.506]
 [1.548]] [[0.583]
 [0.524]
 [0.568]
 [0.576]
 [0.565]
 [0.575]
 [0.607]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
1813 1706
Printing some Q and Qe and total Qs values:  [[0.84 ]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]] [[1.918]
 [0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.731]
 [0.731]] [[0.84 ]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]
 [0.598]]
Printing some Q and Qe and total Qs values:  [[0.556]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]] [[1.63 ]
 [1.512]
 [1.512]
 [1.512]
 [1.512]
 [1.512]
 [1.512]] [[0.556]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]
 [0.564]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021789178413832596, 0.9522982429206152, 0.0014350873184135614, 0.024477491347138627]
using explorer policy with actor:  1
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021275468264220648, 0.9527993526388157, 0.0014353186044658193, 0.024489860492497816]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021275468264220648, 0.9527993526388157, 0.0014353186044658193, 0.024489860492497816]
Printing some Q and Qe and total Qs values:  [[0.904]
 [0.749]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.773]] [[0.775]
 [1.094]
 [1.015]
 [1.015]
 [1.015]
 [1.015]
 [1.047]] [[0.904]
 [0.749]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.773]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021275468264220648, 0.9527993526388157, 0.0014353186044658193, 0.024489860492497816]
in main func line 156:  1815
1815 1708
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021275468264220648, 0.9527993526388157, 0.0014353186044658193, 0.024489860492497816]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021275468264220648, 0.9527993526388157, 0.0014353186044658193, 0.024489860492497816]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021275468264220648, 0.9527993526388157, 0.0014353186044658193, 0.024489860492497816]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021275468264220648, 0.9527993526388157, 0.0014353186044658193, 0.024489860492497816]
line 256 mcts: sample exp_bonus -0.7562732958918466
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021275468264220648, 0.9527993526388157, 0.0014353186044658193, 0.024489860492497816]
Printing some Q and Qe and total Qs values:  [[0.305]
 [0.216]
 [0.289]
 [0.316]
 [0.318]
 [0.3  ]
 [0.537]] [[ 0.212]
 [ 0.832]
 [ 0.25 ]
 [-0.003]
 [ 0.118]
 [ 0.566]
 [ 0.32 ]] [[0.204]
 [0.434]
 [0.197]
 [0.085]
 [0.167]
 [0.426]
 [0.732]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.021275468264220648, 0.9527993526388157, 0.0014353186044658193, 0.024489860492497816]
Printing some Q and Qe and total Qs values:  [[0.674]
 [0.857]
 [0.716]
 [0.689]
 [0.702]
 [0.67 ]
 [0.681]] [[2.675]
 [2.495]
 [3.067]
 [2.568]
 [2.892]
 [2.578]
 [2.891]] [[0.833]
 [1.077]
 [1.178]
 [0.79 ]
 [1.032]
 [0.759]
 [0.99 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
Printing some Q and Qe and total Qs values:  [[0.674]
 [0.412]
 [0.769]
 [0.452]
 [0.769]
 [0.769]
 [0.769]] [[0.017]
 [0.927]
 [0.   ]
 [0.115]
 [0.   ]
 [0.   ]
 [0.   ]] [[0.674]
 [0.412]
 [0.769]
 [0.452]
 [0.769]
 [0.769]
 [0.769]]
Printing some Q and Qe and total Qs values:  [[0.786]
 [0.672]
 [0.777]
 [0.777]
 [0.777]
 [0.764]
 [0.812]] [[0.509]
 [0.822]
 [0.741]
 [0.741]
 [0.741]
 [0.601]
 [0.596]] [[0.786]
 [0.672]
 [0.777]
 [0.777]
 [0.777]
 [0.764]
 [0.812]]
using explorer policy with actor:  1
in main func line 156:  1818
Printing some Q and Qe and total Qs values:  [[0.578]
 [0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]] [[0.311]
 [0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]] [[0.578]
 [0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]
 [0.463]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.85 ]
 [0.412]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.487]
 [0.467]] [[-1.108]
 [ 0.929]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.286]
 [ 0.235]] [[0.85 ]
 [0.412]
 [0.83 ]
 [0.83 ]
 [0.83 ]
 [0.487]
 [0.467]]
Printing some Q and Qe and total Qs values:  [[1.226]
 [1.071]
 [0.929]
 [0.878]
 [0.878]
 [0.926]
 [1.18 ]] [[-0.016]
 [ 0.509]
 [ 0.626]
 [ 0.67 ]
 [ 0.67 ]
 [ 0.66 ]
 [ 0.292]] [[1.657]
 [1.697]
 [1.49 ]
 [1.418]
 [1.418]
 [1.508]
 [1.77 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
Printing some Q and Qe and total Qs values:  [[0.851]
 [0.541]
 [0.541]
 [0.541]
 [0.541]
 [0.541]
 [0.541]] [[-1.126]
 [ 0.396]
 [ 0.396]
 [ 0.396]
 [ 0.396]
 [ 0.396]
 [ 0.396]] [[0.851]
 [0.541]
 [0.541]
 [0.541]
 [0.541]
 [0.541]
 [0.541]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
Printing some Q and Qe and total Qs values:  [[0.733]
 [0.76 ]
 [0.717]
 [0.835]
 [0.835]
 [0.835]
 [0.835]] [[0.541]
 [0.587]
 [0.57 ]
 [0.814]
 [0.814]
 [0.814]
 [0.814]] [[1.04 ]
 [1.125]
 [1.027]
 [1.425]
 [1.425]
 [1.425]
 [1.425]]
line 256 mcts: sample exp_bonus 0.9674254948256352
Printing some Q and Qe and total Qs values:  [[0.74 ]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]] [[0.486]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]
 [0.627]] [[0.74 ]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.605]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.003081646245005
siam score:  -0.63447845
Printing some Q and Qe and total Qs values:  [[0.604]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]] [[0.757]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]] [[0.604]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]
 [0.513]]
Printing some Q and Qe and total Qs values:  [[0.778]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.544]] [[0.484]
 [0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]
 [0.525]] [[0.778]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.544]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.899]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]] [[-1.204]
 [ 0.004]
 [ 0.004]
 [ 0.004]
 [ 0.004]
 [ 0.004]
 [ 0.004]] [[0.899]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
Printing some Q and Qe and total Qs values:  [[1.144]
 [1.359]
 [1.144]
 [1.144]
 [1.144]
 [1.144]
 [1.144]] [[0.881]
 [1.376]
 [0.881]
 [0.881]
 [0.881]
 [0.881]
 [0.881]] [[1.968]
 [2.619]
 [1.968]
 [1.968]
 [1.968]
 [1.968]
 [1.968]]
Printing some Q and Qe and total Qs values:  [[0.831]
 [0.456]
 [0.477]
 [0.83 ]
 [0.83 ]
 [0.47 ]
 [0.462]] [[-2.604]
 [ 0.98 ]
 [ 0.359]
 [ 0.   ]
 [ 0.   ]
 [ 0.385]
 [ 0.298]] [[0.831]
 [0.456]
 [0.477]
 [0.83 ]
 [0.83 ]
 [0.47 ]
 [0.462]]
rdn probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.612]
 [0.917]
 [0.612]
 [0.612]
 [0.612]
 [0.612]
 [0.644]] [[-0.584]
 [ 0.381]
 [-0.584]
 [-0.584]
 [-0.584]
 [-0.584]
 [-0.147]] [[0.488]
 [1.265]
 [0.488]
 [0.488]
 [0.488]
 [0.488]
 [0.709]]
Printing some Q and Qe and total Qs values:  [[0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.391]
 [0.408]] [[5.175]
 [5.175]
 [5.175]
 [5.175]
 [5.175]
 [5.175]
 [3.83 ]] [[1.561]
 [1.561]
 [1.561]
 [1.561]
 [1.561]
 [1.561]
 [0.7  ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
UNIT TEST: sample policy line 217 mcts : [0.02  0.02  0.02  0.02  0.02  0.02  0.878]
Printing some Q and Qe and total Qs values:  [[0.708]
 [0.713]
 [0.708]
 [0.708]
 [0.708]
 [0.708]
 [0.699]] [[1.632]
 [2.746]
 [1.632]
 [1.632]
 [1.632]
 [1.632]
 [2.66 ]] [[1.236]
 [1.757]
 [1.236]
 [1.236]
 [1.236]
 [1.236]
 [1.698]]
Printing some Q and Qe and total Qs values:  [[0.201]
 [0.283]
 [0.245]
 [0.221]
 [0.312]
 [0.221]
 [0.211]] [[2.32 ]
 [2.189]
 [2.226]
 [2.235]
 [2.261]
 [2.287]
 [2.686]] [[-0.238]
 [-0.162]
 [-0.212]
 [-0.256]
 [-0.056]
 [-0.219]
 [ 0.025]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -0.544672237933941
line 256 mcts: sample exp_bonus 2.7820431759467845
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
Printing some Q and Qe and total Qs values:  [[0.146]
 [0.149]
 [0.146]
 [0.146]
 [0.146]
 [0.146]
 [0.05 ]] [[3.106]
 [2.004]
 [3.106]
 [3.106]
 [3.106]
 [3.106]
 [3.26 ]] [[ 0.721]
 [-0.004]
 [ 0.721]
 [ 0.721]
 [ 0.721]
 [ 0.721]
 [ 0.631]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.816]
 [0.623]] [[1.6  ]
 [1.6  ]
 [1.6  ]
 [1.6  ]
 [1.6  ]
 [0.968]
 [1.6  ]] [[2.626]
 [2.626]
 [2.626]
 [2.626]
 [2.626]
 [2.593]
 [2.626]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.02076543400428562, 0.9532968766306265, 0.0014355482355342063, 0.02450214112955367]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.020259036320047687, 0.9537908532457225, 0.0014357762293189281, 0.024514334204910698]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.020259036320047687, 0.9537908532457225, 0.0014357762293189281, 0.024514334204910698]
actor:  1 policy actor:  1  step number:  54 total reward:  0.48499999999999965  reward:  1.0 rdn_beta:  0.333
first move QE:  0.5751911350451779
Printing some Q and Qe and total Qs values:  [[0.263]
 [0.28 ]
 [0.326]
 [0.305]
 [0.326]
 [0.284]
 [0.326]] [[-1.148]
 [-0.807]
 [ 0.   ]
 [-0.954]
 [ 0.   ]
 [-1.081]
 [ 0.   ]] [[0.263]
 [0.28 ]
 [0.326]
 [0.305]
 [0.326]
 [0.284]
 [0.326]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
line 256 mcts: sample exp_bonus 1.5923927970858731
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
Printing some Q and Qe and total Qs values:  [[0.48 ]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]] [[0.843]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]
 [0.816]] [[0.252]
 [0.16 ]
 [0.16 ]
 [0.16 ]
 [0.16 ]
 [0.16 ]
 [0.16 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
1837 1737
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
Printing some Q and Qe and total Qs values:  [[0.472]
 [0.39 ]
 [0.528]
 [0.528]
 [0.528]
 [0.528]
 [0.533]] [[1.864]
 [1.872]
 [1.681]
 [1.681]
 [1.681]
 [1.681]
 [2.091]] [[0.963]
 [0.804]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [1.236]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
line 256 mcts: sample exp_bonus 4.560343686491736
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
siam score:  -0.63859826
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
siam score:  -0.6386537
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
using another actor
from probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.64 ]
 [0.765]
 [0.591]
 [0.64 ]
 [0.64 ]
 [0.594]
 [0.6  ]] [[-0.309]
 [ 0.701]
 [-0.665]
 [-0.309]
 [-0.309]
 [-0.867]
 [-0.65 ]] [[0.869]
 [1.342]
 [0.698]
 [0.869]
 [0.869]
 [0.631]
 [0.712]]
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.533]
 [0.529]
 [0.537]
 [0.537]
 [0.538]
 [0.527]] [[3.194]
 [3.198]
 [3.643]
 [3.194]
 [3.194]
 [3.256]
 [3.007]] [[1.138]
 [1.133]
 [1.423]
 [1.138]
 [1.138]
 [1.182]
 [0.995]]
siam score:  -0.6389925
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
first move QE:  0.5733457578783788
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
Printing some Q and Qe and total Qs values:  [[0.569]
 [0.591]
 [0.586]
 [0.566]
 [0.569]
 [0.583]
 [0.578]] [[4.059]
 [3.997]
 [4.078]
 [4.095]
 [4.059]
 [4.032]
 [4.303]] [[1.1  ]
 [1.102]
 [1.147]
 [1.119]
 [1.1  ]
 [1.11 ]
 [1.28 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.558]
 [0.569]
 [0.516]
 [0.5  ]
 [0.5  ]
 [0.565]
 [0.529]] [[3.065]
 [3.824]
 [4.104]
 [3.907]
 [3.907]
 [4.672]
 [4.284]] [[0.934]
 [1.462]
 [1.544]
 [1.378]
 [1.378]
 [2.018]
 [1.688]]
Printing some Q and Qe and total Qs values:  [[0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]] [[1.409]
 [1.409]
 [1.409]
 [1.409]
 [1.409]
 [1.409]
 [1.409]] [[0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]]
start point for exploration sampling:  10768
using explorer policy with actor:  1
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.719]
 [0.719]
 [0.719]
 [0.719]
 [0.719]
 [0.719]
 [1.196]] [[1.218]
 [1.218]
 [1.218]
 [1.218]
 [1.218]
 [1.218]
 [1.14 ]] [[1.74]
 [1.74]
 [1.74]
 [1.74]
 [1.74]
 [1.74]
 [2.64]]
Printing some Q and Qe and total Qs values:  [[0.724]
 [0.754]
 [0.74 ]
 [0.727]
 [0.723]
 [0.964]
 [0.771]] [[2.996]
 [3.339]
 [3.106]
 [2.996]
 [2.987]
 [2.539]
 [3.452]] [[1.022]
 [1.309]
 [1.127]
 [1.028]
 [1.013]
 [1.197]
 [1.419]]
UNIT TEST: sample policy line 217 mcts : [0.02  0.367 0.02  0.02  0.02  0.367 0.184]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
Printing some Q and Qe and total Qs values:  [[0.298]
 [0.298]
 [0.298]
 [0.298]
 [0.298]
 [0.298]
 [0.298]] [[-0.21]
 [-0.21]
 [-0.21]
 [-0.21]
 [-0.21]
 [-0.21]
 [-0.21]] [[0.298]
 [0.298]
 [0.298]
 [0.298]
 [0.298]
 [0.298]
 [0.298]]
Printing some Q and Qe and total Qs values:  [[0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]] [[1.283]
 [1.283]
 [1.283]
 [1.283]
 [1.283]
 [1.283]
 [1.283]] [[0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]
 [0.409]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017930475921549813, 0.9590155240075705, 0.0013826169436587158, 0.021671383127221062]
Printing some Q and Qe and total Qs values:  [[0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]
 [0.784]] [[2.375]
 [2.375]
 [2.375]
 [2.375]
 [2.375]
 [2.375]
 [2.375]] [[1.027]
 [1.027]
 [1.027]
 [1.027]
 [1.027]
 [1.027]
 [1.027]]
first move QE:  0.57247280613145
Printing some Q and Qe and total Qs values:  [[0.771]
 [0.771]
 [0.771]
 [0.771]
 [0.771]
 [0.771]
 [0.816]] [[3.368]
 [3.368]
 [3.368]
 [3.368]
 [3.368]
 [3.368]
 [3.213]] [[2.187]
 [2.187]
 [2.187]
 [2.187]
 [2.187]
 [2.187]
 [2.178]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017487429520142195, 0.9594490396095062, 0.0013827918853660832, 0.021680738984985442]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017487429520142195, 0.9594490396095062, 0.0013827918853660832, 0.021680738984985442]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017487429520142195, 0.9594490396095062, 0.0013827918853660832, 0.021680738984985442]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017487429520142195, 0.9594490396095062, 0.0013827918853660832, 0.021680738984985442]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017487429520142195, 0.9594490396095062, 0.0013827918853660832, 0.021680738984985442]
siam score:  -0.64093363
Printing some Q and Qe and total Qs values:  [[0.98 ]
 [0.98 ]
 [0.98 ]
 [0.98 ]
 [0.98 ]
 [0.98 ]
 [1.121]] [[2.145]
 [2.145]
 [2.145]
 [2.145]
 [2.145]
 [2.145]
 [2.933]] [[2.196]
 [2.196]
 [2.196]
 [2.196]
 [2.196]
 [2.196]
 [2.575]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017047574250142288, 0.9598794327275475, 0.0013829655670203843, 0.021690027455290053]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017047574250142288, 0.9598794327275475, 0.0013829655670203843, 0.021690027455290053]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017047574250142288, 0.9598794327275475, 0.0013829655670203843, 0.021690027455290053]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017047574250142288, 0.9598794327275475, 0.0013829655670203843, 0.021690027455290053]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017047574250142288, 0.9598794327275475, 0.0013829655670203843, 0.021690027455290053]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017047574250142288, 0.9598794327275475, 0.0013829655670203843, 0.021690027455290053]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.312]
 [0.663]
 [0.663]
 [0.35 ]
 [0.618]
 [0.461]] [[1.263]
 [1.534]
 [1.155]
 [1.155]
 [0.483]
 [2.296]
 [1.599]] [[1.29 ]
 [1.358]
 [1.806]
 [1.806]
 [0.735]
 [2.476]
 [1.699]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.017047574250142288, 0.9598794327275475, 0.0013829655670203843, 0.021690027455290053]
first move QE:  0.5734045175631097
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
Printing some Q and Qe and total Qs values:  [[1.079]
 [1.079]
 [1.079]
 [1.079]
 [1.079]
 [1.079]
 [1.409]] [[0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [0.75 ]
 [1.177]] [[1.937]
 [1.937]
 [1.937]
 [1.937]
 [1.937]
 [1.937]
 [2.813]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
siam score:  -0.64240426
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
using another actor
from probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[1.148]
 [1.148]
 [1.148]
 [1.148]
 [1.148]
 [1.148]
 [1.294]] [[0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.952]
 [0.953]] [[1.677]
 [1.677]
 [1.677]
 [1.677]
 [1.677]
 [1.677]
 [1.885]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
Printing some Q and Qe and total Qs values:  [[0.805]
 [0.835]
 [0.805]
 [0.805]
 [0.805]
 [0.805]
 [0.805]] [[1.654]
 [2.356]
 [1.654]
 [1.654]
 [1.654]
 [1.654]
 [1.654]] [[1.156]
 [1.545]
 [1.156]
 [1.156]
 [1.156]
 [1.156]
 [1.156]]
Printing some Q and Qe and total Qs values:  [[0.747]
 [0.842]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]] [[1.396]
 [2.021]
 [1.396]
 [1.396]
 [1.396]
 [1.396]
 [1.098]] [[0.987]
 [1.342]
 [0.987]
 [0.987]
 [0.987]
 [0.987]
 [0.849]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
Printing some Q and Qe and total Qs values:  [[0.624]
 [0.694]
 [0.758]
 [0.65 ]
 [0.634]
 [0.801]
 [0.641]] [[-0.027]
 [ 1.522]
 [ 0.134]
 [-0.044]
 [-0.005]
 [ 1.29 ]
 [ 0.202]] [[0.099]
 [0.964]
 [0.289]
 [0.111]
 [0.118]
 [0.927]
 [0.233]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
from probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
from probs:  [0.016610875758113788, 0.9603067369761198, 0.0013831380021864473, 0.021699249263580033]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
from probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
siam score:  -0.64557266
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.756]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]
 [0.665]] [[2.131]
 [1.56 ]
 [1.56 ]
 [1.56 ]
 [1.56 ]
 [1.56 ]
 [1.56 ]] [[2.149]
 [1.586]
 [1.586]
 [1.586]
 [1.586]
 [1.586]
 [1.586]]
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.757]
 [0.766]
 [0.763]
 [0.75 ]
 [0.766]
 [0.757]] [[2.47 ]
 [3.682]
 [3.618]
 [3.177]
 [2.887]
 [3.18 ]
 [3.878]] [[0.478]
 [1.331]
 [1.307]
 [1.007]
 [0.787]
 [1.014]
 [1.462]]
Printing some Q and Qe and total Qs values:  [[0.522]
 [0.464]
 [0.543]
 [0.541]
 [0.505]
 [0.47 ]
 [0.456]] [[0.621]
 [2.085]
 [0.423]
 [0.236]
 [0.197]
 [0.504]
 [1.177]] [[ 0.132]
 [ 0.99 ]
 [ 0.041]
 [-0.087]
 [-0.185]
 [-0.051]
 [ 0.369]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.623]
 [0.841]
 [0.697]
 [0.625]
 [0.57 ]
 [0.619]
 [0.644]] [[-0.046]
 [ 0.594]
 [ 0.048]
 [-0.082]
 [-0.104]
 [-0.156]
 [ 0.079]] [[1.621]
 [2.376]
 [1.807]
 [1.605]
 [1.496]
 [1.551]
 [1.731]]
Printing some Q and Qe and total Qs values:  [[0.697]
 [0.389]
 [0.697]
 [0.582]
 [0.697]
 [0.625]
 [0.495]] [[1.126]
 [1.217]
 [1.126]
 [0.388]
 [1.126]
 [1.683]
 [1.875]] [[1.602]
 [1.046]
 [1.602]
 [0.881]
 [1.602]
 [1.83 ]
 [1.697]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
Printing some Q and Qe and total Qs values:  [[0.639]
 [0.63 ]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]] [[3.429]
 [3.913]
 [3.429]
 [3.429]
 [3.429]
 [3.429]
 [3.429]] [[0.636]
 [0.94 ]
 [0.636]
 [0.636]
 [0.636]
 [0.636]
 [0.636]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
UNIT TEST: sample policy line 217 mcts : [0.061 0.327 0.122 0.061 0.02  0.02  0.388]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
Printing some Q and Qe and total Qs values:  [[0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.768]
 [0.457]] [[1.974]
 [1.974]
 [1.974]
 [1.974]
 [1.974]
 [1.974]
 [2.161]] [[2.108]
 [2.108]
 [2.108]
 [2.108]
 [2.108]
 [2.108]
 [1.61 ]]
1889 1775
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
Printing some Q and Qe and total Qs values:  [[0.504]
 [1.   ]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [1.   ]] [[1.976]
 [0.561]
 [1.976]
 [1.976]
 [1.976]
 [1.976]
 [0.561]] [[0.504]
 [1.   ]
 [0.504]
 [0.504]
 [0.504]
 [0.504]
 [1.   ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
Printing some Q and Qe and total Qs values:  [[1.041]
 [0.399]
 [0.852]
 [0.567]
 [0.567]
 [0.827]
 [0.568]] [[1.286]
 [0.95 ]
 [0.709]
 [1.786]
 [1.786]
 [0.984]
 [1.015]] [[1.766]
 [0.259]
 [1.004]
 [1.151]
 [1.151]
 [1.138]
 [0.641]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
first move QE:  0.5746646081676379
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
siam score:  -0.6433088
first move QE:  0.5750968389523079
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
Printing some Q and Qe and total Qs values:  [[0.748]
 [0.763]
 [0.748]
 [0.748]
 [0.748]
 [0.748]
 [0.729]] [[2.102]
 [3.085]
 [2.102]
 [2.102]
 [2.102]
 [2.102]
 [2.836]] [[1.574]
 [2.106]
 [1.574]
 [1.574]
 [1.574]
 [1.574]
 [1.925]]
Printing some Q and Qe and total Qs values:  [[0.466]
 [0.433]
 [0.465]
 [0.45 ]
 [0.459]
 [0.531]
 [0.427]] [[0.636]
 [2.381]
 [0.579]
 [0.142]
 [0.339]
 [0.724]
 [1.356]] [[0.466]
 [0.433]
 [0.465]
 [0.45 ]
 [0.459]
 [0.531]
 [0.427]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.9331916655762944
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
Printing some Q and Qe and total Qs values:  [[0.56 ]
 [0.548]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.56 ]
 [0.544]] [[2.871]
 [2.832]
 [2.871]
 [2.871]
 [2.871]
 [2.871]
 [2.981]] [[1.647]
 [1.597]
 [1.647]
 [1.647]
 [1.647]
 [1.647]
 [1.688]]
Printing some Q and Qe and total Qs values:  [[0.493]
 [0.523]
 [0.413]
 [0.515]
 [0.476]
 [0.509]
 [0.526]] [[2.146]
 [3.055]
 [2.372]
 [2.304]
 [1.394]
 [2.483]
 [3.23 ]] [[ 0.46 ]
 [ 1.12 ]
 [ 0.45 ]
 [ 0.608]
 [-0.071]
 [ 0.714]
 [ 1.241]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
actor:  1 policy actor:  1  step number:  58 total reward:  0.3949999999999996  reward:  1.0 rdn_beta:  0.333
using another actor
from probs:  [0.016618436128090185, 0.9607712140227355, 0.0013833254381338622, 0.021227024411040497]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.015111051171391093, 0.9642680309604478, 0.0013459544988331789, 0.01927496336932802]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.015111051171391093, 0.9642680309604478, 0.0013459544988331789, 0.01927496336932802]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.015111051171391093, 0.9642680309604478, 0.0013459544988331789, 0.01927496336932802]
start point for exploration sampling:  10768
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
UNIT TEST: sample policy line 217 mcts : [0.02  0.816 0.02  0.02  0.02  0.082 0.02 ]
Printing some Q and Qe and total Qs values:  [[1.174]
 [1.174]
 [1.174]
 [1.174]
 [1.174]
 [1.174]
 [1.294]] [[0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.844]] [[2.091]
 [2.091]
 [2.091]
 [2.091]
 [2.091]
 [2.091]
 [2.365]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.015111051171391093, 0.9642680309604478, 0.0013459544988331789, 0.01927496336932802]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.0019316949209842
siam score:  -0.6323641
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.573]
 [0.438]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]] [[1.89 ]
 [1.467]
 [1.89 ]
 [1.89 ]
 [1.89 ]
 [1.89 ]
 [1.89 ]] [[ 0.295]
 [-0.256]
 [ 0.295]
 [ 0.295]
 [ 0.295]
 [ 0.295]
 [ 0.295]]
siam score:  -0.63309157
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.015111051171391093, 0.9642680309604478, 0.0013459544988331789, 0.01927496336932802]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.015111051171391093, 0.9642680309604478, 0.0013459544988331789, 0.01927496336932802]
using explorer policy with actor:  1
actor:  1 policy actor:  1  step number:  64 total reward:  0.36499999999999955  reward:  1.0 rdn_beta:  0.333
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.738]
 [0.776]
 [0.761]
 [0.764]
 [0.766]
 [0.726]
 [0.733]] [[-0.716]
 [-0.219]
 [-0.558]
 [-0.829]
 [-0.644]
 [-0.423]
 [-0.258]] [[0.902]
 [1.308]
 [1.052]
 [0.878]
 [1.006]
 [1.073]
 [1.197]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013922756558525148, 0.967420321911406, 0.0013164944158919327, 0.017340427114176927]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013922756558525148, 0.967420321911406, 0.0013164944158919327, 0.017340427114176927]
Printing some Q and Qe and total Qs values:  [[0.811]
 [0.858]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.854]] [[3.266]
 [2.93 ]
 [3.266]
 [3.266]
 [3.266]
 [3.266]
 [3.173]] [[1.983]
 [1.91 ]
 [1.983]
 [1.983]
 [1.983]
 [1.983]
 [1.996]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013922756558525148, 0.967420321911406, 0.0013164944158919327, 0.017340427114176927]
Printing some Q and Qe and total Qs values:  [[0.576]
 [0.576]
 [0.576]
 [0.576]
 [0.576]
 [0.576]
 [0.552]] [[4.643]
 [4.643]
 [4.643]
 [4.643]
 [4.643]
 [4.643]
 [5.325]] [[1.428]
 [1.428]
 [1.428]
 [1.428]
 [1.428]
 [1.428]
 [1.835]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  1
actor:  1 policy actor:  1  step number:  79 total reward:  0.23999999999999944  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013080284974733552, 0.9693488906324241, 0.0012956079434082411, 0.01627521644943423]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013080284974733552, 0.9693488906324241, 0.0012956079434082411, 0.01627521644943423]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013080284974733552, 0.9693488906324241, 0.0012956079434082411, 0.01627521644943423]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013080284974733552, 0.9693488906324241, 0.0012956079434082411, 0.01627521644943423]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013080284974733552, 0.9693488906324241, 0.0012956079434082411, 0.01627521644943423]
Printing some Q and Qe and total Qs values:  [[0.406]
 [0.427]
 [0.406]
 [0.406]
 [0.406]
 [0.406]
 [0.406]] [[0.61 ]
 [2.237]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.61 ]] [[0.374]
 [1.222]
 [0.374]
 [0.374]
 [0.374]
 [0.374]
 [0.374]]
siam score:  -0.63177264
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013080284974733552, 0.9693488906324241, 0.0012956079434082411, 0.01627521644943423]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013080284974733552, 0.9693488906324241, 0.0012956079434082411, 0.01627521644943423]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.013080284974733552, 0.9693488906324241, 0.0012956079434082411, 0.01627521644943423]
actor:  1 policy actor:  1  step number:  61 total reward:  0.35999999999999954  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01220082552850935, 0.9713621312117188, 0.0012738044714841028, 0.015163238788288005]
Printing some Q and Qe and total Qs values:  [[0.798]
 [0.798]
 [0.798]
 [0.798]
 [0.798]
 [0.798]
 [0.798]] [[0.53]
 [0.53]
 [0.53]
 [0.53]
 [0.53]
 [0.53]
 [0.53]] [[0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.688]
 [0.688]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01220082552850935, 0.9713621312117188, 0.0012738044714841028, 0.015163238788288005]
Printing some Q and Qe and total Qs values:  [[0.489]
 [0.499]
 [0.489]
 [0.489]
 [0.489]
 [0.489]
 [0.508]] [[4.266]
 [4.193]
 [4.266]
 [4.266]
 [4.266]
 [4.266]
 [3.941]] [[0.884]
 [0.853]
 [0.884]
 [0.884]
 [0.884]
 [0.884]
 [0.704]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01220082552850935, 0.9713621312117188, 0.0012738044714841028, 0.015163238788288005]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01220082552850935, 0.9713621312117188, 0.0012738044714841028, 0.015163238788288005]
actor:  1 policy actor:  1  step number:  53 total reward:  0.6099999999999998  reward:  1.0 rdn_beta:  0.333
Printing some Q and Qe and total Qs values:  [[0.936]
 [0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]] [[0.582]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.61 ]
 [0.61 ]] [[0.936]
 [0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]
 [0.935]]
Printing some Q and Qe and total Qs values:  [[0.657]
 [0.731]
 [0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.696]] [[-0.267]
 [-0.62 ]
 [-0.267]
 [-0.267]
 [-0.267]
 [-0.267]
 [-0.155]] [[1.409]
 [1.322]
 [1.409]
 [1.409]
 [1.409]
 [1.409]
 [1.562]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01116201097993819, 0.9737401642324837, 0.001248050283566285, 0.013849774504011786]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.647]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]] [[-1.219]
 [-0.638]
 [-0.638]
 [-0.638]
 [-0.638]
 [-0.638]
 [-0.638]] [[0.647]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01116201097993819, 0.9737401642324837, 0.001248050283566285, 0.013849774504011786]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01116201097993819, 0.9737401642324837, 0.001248050283566285, 0.013849774504011786]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01116201097993819, 0.9737401642324837, 0.001248050283566285, 0.013849774504011786]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01116201097993819, 0.9737401642324837, 0.001248050283566285, 0.013849774504011786]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01116201097993819, 0.9737401642324837, 0.001248050283566285, 0.013849774504011786]
siam score:  -0.63670754
from probs:  [0.01116201097993819, 0.9737401642324837, 0.001248050283566285, 0.013849774504011786]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.436]
 [0.432]
 [0.441]
 [0.432]
 [0.432]
 [0.442]
 [0.446]] [[0.224]
 [0.3  ]
 [0.223]
 [0.3  ]
 [0.3  ]
 [0.279]
 [0.301]] [[0.521]
 [0.563]
 [0.529]
 [0.563]
 [0.563]
 [0.569]
 [0.593]]
Printing some Q and Qe and total Qs values:  [[0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.61 ]] [[1.589]
 [1.589]
 [1.589]
 [1.589]
 [1.589]
 [1.589]
 [6.732]] [[0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [0.565]
 [1.914]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 1.5899763941255223
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.011162010979938188, 0.9737401642324837, 0.0012480502835662847, 0.013849774504011784]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.01116201097993819, 0.9737401642324837, 0.001248050283566285, 0.013849774504011786]
line 256 mcts: sample exp_bonus -0.4624116481918681
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.011162010979938188, 0.9737401642324837, 0.0012480502835662847, 0.013849774504011784]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.011162010979938188, 0.9737401642324837, 0.0012480502835662847, 0.013849774504011784]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
actor:  1 policy actor:  1  step number:  59 total reward:  0.5999999999999998  reward:  1.0 rdn_beta:  0.333
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010309309128924998, 0.9756921518720159, 0.0012269101833057808, 0.012771628815753423]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010309309128924998, 0.9756921518720159, 0.0012269101833057808, 0.012771628815753423]
Printing some Q and Qe and total Qs values:  [[0.749]
 [0.749]
 [0.749]
 [0.749]
 [0.749]
 [0.749]
 [0.735]] [[0.942]
 [0.942]
 [0.942]
 [0.942]
 [0.942]
 [0.942]
 [1.56 ]] [[1.195]
 [1.195]
 [1.195]
 [1.195]
 [1.195]
 [1.195]
 [1.373]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010309309128924998, 0.9756921518720159, 0.0012269101833057808, 0.012771628815753423]
Printing some Q and Qe and total Qs values:  [[0.57 ]
 [0.661]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]
 [0.57 ]] [[-0.089]
 [ 0.743]
 [-0.089]
 [-0.089]
 [-0.089]
 [-0.089]
 [-0.089]] [[0.041]
 [0.501]
 [0.041]
 [0.041]
 [0.041]
 [0.041]
 [0.041]]
Printing some Q and Qe and total Qs values:  [[0.473]
 [0.595]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]] [[-0.703]
 [-0.475]
 [-0.797]
 [-0.797]
 [-0.797]
 [-0.797]
 [-0.797]] [[0.187]
 [0.423]
 [0.167]
 [0.167]
 [0.167]
 [0.167]
 [0.167]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010309309128924998, 0.9756921518720159, 0.0012269101833057808, 0.012771628815753423]
actor:  1 policy actor:  1  step number:  90 total reward:  0.17499999999999938  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009658591034442802, 0.9768577368992342, 0.0012170089013165636, 0.012266663165006318]
deleting a thread, now have 3 threads
Frames:  117166 train batches done:  13728 episodes:  3738
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.524]
 [0.551]
 [0.541]
 [0.541]
 [0.543]
 [0.562]] [[2.681]
 [3.487]
 [3.814]
 [2.681]
 [2.681]
 [2.921]
 [3.467]] [[-0.062]
 [ 0.44 ]
 [ 0.712]
 [-0.062]
 [-0.062]
 [ 0.103]
 [ 0.503]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.024]
 [0.064]
 [0.064]
 [0.064]
 [0.064]
 [0.064]
 [0.092]] [[1.202]
 [1.623]
 [1.623]
 [1.623]
 [1.623]
 [1.623]
 [0.253]] [[0.024]
 [0.064]
 [0.064]
 [0.064]
 [0.064]
 [0.064]
 [0.092]]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
line 256 mcts: sample exp_bonus 2.4163078472173254
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
using explorer policy with actor:  1
first move QE:  0.5720482467635849
Printing some Q and Qe and total Qs values:  [[0.669]
 [0.717]
 [0.669]
 [0.669]
 [0.669]
 [0.669]
 [0.669]] [[2.326]
 [2.852]
 [2.326]
 [2.326]
 [2.326]
 [2.326]
 [2.326]] [[1.017]
 [1.464]
 [1.017]
 [1.017]
 [1.017]
 [1.017]
 [1.017]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.65 ]
 [0.742]
 [0.798]
 [0.662]
 [0.662]
 [0.651]
 [0.667]] [[2.736]
 [3.051]
 [2.192]
 [2.943]
 [2.943]
 [2.213]
 [3.366]] [[0.637]
 [1.031]
 [0.57 ]
 [0.797]
 [0.797]
 [0.29 ]
 [1.09 ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
from probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
line 256 mcts: sample exp_bonus 0.5998897780164988
Printing some Q and Qe and total Qs values:  [[0.882]
 [0.939]
 [0.882]
 [0.882]
 [0.882]
 [0.882]
 [0.882]] [[0.68 ]
 [1.272]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]] [[1.42 ]
 [1.876]
 [1.42 ]
 [1.42 ]
 [1.42 ]
 [1.42 ]
 [1.42 ]]
Printing some Q and Qe and total Qs values:  [[0.776]
 [0.799]
 [0.776]
 [0.776]
 [0.776]
 [0.776]
 [0.776]] [[0.008]
 [0.332]
 [0.008]
 [0.008]
 [0.008]
 [0.008]
 [0.008]] [[0.923]
 [1.184]
 [0.923]
 [0.923]
 [0.923]
 [0.923]
 [0.923]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
start point for exploration sampling:  10768
siam score:  -0.6253272
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
siam score:  -0.62224555
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
siam score:  -0.6204367
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
from probs:  [0.010021674065467922, 0.9760129934490236, 0.0012262715968407358, 0.01273906088866772]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.676]
 [0.586]
 [0.502]
 [0.542]
 [0.473]
 [0.493]] [[0.588]
 [0.744]
 [0.876]
 [0.636]
 [0.77 ]
 [1.02 ]
 [0.764]] [[ 0.428]
 [ 0.382]
 [ 0.291]
 [-0.037]
 [ 0.131]
 [ 0.159]
 [ 0.03 ]]
actor:  1 policy actor:  1  step number:  72 total reward:  0.3149999999999995  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
siam score:  -0.625194
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
Printing some Q and Qe and total Qs values:  [[0.5  ]
 [0.992]
 [0.5  ]
 [0.5  ]
 [0.5  ]
 [0.5  ]
 [0.5  ]] [[2.419]
 [0.895]
 [2.419]
 [2.419]
 [2.419]
 [2.419]
 [2.419]] [[0.789]
 [0.757]
 [0.789]
 [0.789]
 [0.789]
 [0.789]
 [0.789]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
first move QE:  0.5717972818757053
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
Printing some Q and Qe and total Qs values:  [[0.737]
 [0.695]
 [0.97 ]
 [0.772]
 [0.772]
 [0.717]
 [0.518]] [[1.65 ]
 [1.79 ]
 [2.965]
 [1.559]
 [1.559]
 [1.32 ]
 [1.632]] [[1.24 ]
 [1.248]
 [2.398]
 [1.248]
 [1.248]
 [1.017]
 [0.851]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
line 256 mcts: sample exp_bonus 4.08435291238642
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
Printing some Q and Qe and total Qs values:  [[0.884]
 [0.748]
 [0.884]
 [0.884]
 [0.884]
 [0.694]
 [0.884]] [[ 1.749]
 [ 0.358]
 [ 1.749]
 [ 1.749]
 [ 1.749]
 [-0.287]
 [ 1.749]] [[2.187]
 [0.989]
 [2.187]
 [2.187]
 [2.187]
 [0.452]
 [2.187]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
Printing some Q and Qe and total Qs values:  [[0.397]
 [0.468]
 [0.397]
 [0.397]
 [0.397]
 [0.397]
 [0.397]] [[2.426]
 [2.918]
 [2.426]
 [2.426]
 [2.426]
 [2.426]
 [2.426]] [[0.113]
 [0.582]
 [0.113]
 [0.113]
 [0.113]
 [0.113]
 [0.113]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
Printing some Q and Qe and total Qs values:  [[0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]
 [0.727]] [[-0.187]
 [-0.187]
 [-0.187]
 [-0.187]
 [-0.187]
 [-0.187]
 [-0.187]] [[1.924]
 [1.924]
 [1.924]
 [1.924]
 [1.924]
 [1.924]
 [1.924]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
from probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
Printing some Q and Qe and total Qs values:  [[0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.357]] [[0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.379]] [[0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.353]
 [0.357]]
Printing some Q and Qe and total Qs values:  [[0.084]
 [0.038]
 [0.077]
 [0.072]
 [0.048]
 [0.064]
 [0.077]] [[ 0.013]
 [ 1.024]
 [-0.125]
 [-0.438]
 [-0.175]
 [-0.053]
 [ 0.032]] [[0.084]
 [0.038]
 [0.077]
 [0.072]
 [0.048]
 [0.064]
 [0.077]]
siam score:  -0.63661283
siam score:  -0.636559
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
siam score:  -0.6331937
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
siam score:  -0.6341277
Printing some Q and Qe and total Qs values:  [[0.689]
 [0.839]
 [0.689]
 [0.689]
 [0.689]
 [0.689]
 [0.817]] [[2.666]
 [2.449]
 [2.666]
 [2.666]
 [2.666]
 [2.666]
 [2.592]] [[1.472]
 [1.577]
 [1.472]
 [1.472]
 [1.472]
 [1.472]
 [1.612]]
siam score:  -0.63405
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.331]
 [0.236]
 [0.941]
 [0.689]
 [0.42 ]
 [0.643]
 [0.511]] [[1.198]
 [1.008]
 [1.763]
 [0.48 ]
 [0.529]
 [0.01 ]
 [0.945]] [[0.437]
 [0.247]
 [1.395]
 [0.579]
 [0.276]
 [0.336]
 [0.552]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
siam score:  -0.63762385
Printing some Q and Qe and total Qs values:  [[0.785]
 [0.647]
 [0.818]
 [0.818]
 [0.818]
 [0.818]
 [0.629]] [[1.682]
 [1.768]
 [1.476]
 [1.476]
 [1.476]
 [1.476]
 [2.269]] [[0.578]
 [0.359]
 [0.508]
 [0.508]
 [0.508]
 [0.508]
 [0.658]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.692]
 [0.67 ]
 [0.692]
 [0.692]
 [0.692]
 [0.692]
 [0.658]] [[3.182]
 [3.655]
 [3.182]
 [3.182]
 [3.182]
 [3.182]
 [3.455]] [[1.53 ]
 [1.69 ]
 [1.53 ]
 [1.53 ]
 [1.53 ]
 [1.53 ]
 [1.596]]
first move QE:  0.5723661219121424
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009540008669434965, 0.9771336288236462, 0.0012139837190641666, 0.012112378787854546]
actor:  1 policy actor:  1  step number:  67 total reward:  0.3099999999999995  reward:  1.0 rdn_beta:  0.333
Printing some Q and Qe and total Qs values:  [[0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.648]] [[0.5  ]
 [0.5  ]
 [0.5  ]
 [0.5  ]
 [0.5  ]
 [0.5  ]
 [0.297]] [[0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.648]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009110287862792176, 0.9781334107077125, 0.001203021011770753, 0.011553280417724566]
from probs:  [0.009110287862792176, 0.9781334107077125, 0.001203021011770753, 0.011553280417724566]
siam score:  -0.6322487
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009110287862792176, 0.9781334107077125, 0.001203021011770753, 0.011553280417724566]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009110287862792176, 0.9781334107077125, 0.001203021011770753, 0.011553280417724566]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009110287862792176, 0.9781334107077125, 0.001203021011770753, 0.011553280417724566]
Printing some Q and Qe and total Qs values:  [[0.749]
 [0.749]
 [0.749]
 [0.749]
 [0.749]
 [0.749]
 [0.764]] [[1.599]
 [1.599]
 [1.599]
 [1.599]
 [1.599]
 [1.599]
 [1.387]] [[2.513]
 [2.513]
 [2.513]
 [2.513]
 [2.513]
 [2.513]
 [2.4  ]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009110287862792176, 0.9781334107077125, 0.001203021011770753, 0.011553280417724566]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009110287862792176, 0.9781334107077125, 0.001203021011770753, 0.011553280417724566]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009110287862792176, 0.9781334107077125, 0.001203021011770753, 0.011553280417724566]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
siam score:  -0.63528717
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
UNIT TEST: sample policy line 217 mcts : [0.102 0.061 0.082 0.061 0.061 0.02  0.612]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
Printing some Q and Qe and total Qs values:  [[0.421]
 [0.395]
 [0.378]
 [0.421]
 [0.421]
 [0.421]
 [0.421]] [[ 0.   ]
 [ 0.904]
 [-0.147]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]] [[0.421]
 [0.395]
 [0.378]
 [0.421]
 [0.421]
 [0.421]
 [0.421]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009792739403023068, 0.9765456293479816, 0.0012204311915010296, 0.012441200057494207]
Printing some Q and Qe and total Qs values:  [[0.437]
 [0.476]
 [0.424]
 [0.451]
 [0.588]
 [0.484]
 [0.437]] [[0.231]
 [1.41 ]
 [0.233]
 [0.576]
 [0.058]
 [0.419]
 [0.619]] [[0.437]
 [0.476]
 [0.424]
 [0.451]
 [0.588]
 [0.484]
 [0.437]]
actor:  1 policy actor:  1  step number:  65 total reward:  0.3999999999999996  reward:  1.0 rdn_beta:  0.333
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
Starting evaluation
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.746]
 [0.546]
 [0.503]
 [0.503]
 [0.503]
 [0.503]
 [0.503]] [[0.522]
 [1.772]
 [1.343]
 [1.343]
 [1.343]
 [1.343]
 [1.343]] [[0.746]
 [0.546]
 [0.503]
 [0.503]
 [0.503]
 [0.503]
 [0.503]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
start point for exploration sampling:  10768
using explorer policy with actor:  1
using explorer policy with actor:  1
using explorer policy with actor:  1
first move QE:  0.575949946564665
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
Printing some Q and Qe and total Qs values:  [[0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]
 [0.803]] [[2.958]
 [2.958]
 [2.958]
 [2.958]
 [2.958]
 [2.958]
 [2.958]] [[2.022]
 [2.022]
 [2.022]
 [2.022]
 [2.022]
 [2.022]
 [2.022]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
first move QE:  0.5763599010685257
Printing some Q and Qe and total Qs values:  [[0.903]
 [0.883]
 [0.903]
 [0.903]
 [0.903]
 [0.903]
 [0.878]] [[4.807]
 [5.751]
 [4.807]
 [4.807]
 [4.807]
 [4.807]
 [5.54 ]] [[1.805]
 [2.039]
 [1.805]
 [1.805]
 [1.805]
 [1.805]
 [1.979]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
Printing some Q and Qe and total Qs values:  [[0.623]
 [0.711]
 [0.623]
 [0.623]
 [0.623]
 [0.623]
 [0.607]] [[3.5  ]
 [4.006]
 [3.5  ]
 [3.5  ]
 [3.5  ]
 [3.5  ]
 [2.946]] [[1.095]
 [1.591]
 [1.095]
 [1.095]
 [1.095]
 [1.095]
 [0.707]]
Printing some Q and Qe and total Qs values:  [[0.661]
 [0.525]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]] [[-0.177]
 [ 1.064]
 [-0.145]
 [-0.145]
 [-0.145]
 [-0.145]
 [-0.145]] [[0.661]
 [0.525]
 [0.487]
 [0.487]
 [0.487]
 [0.487]
 [0.487]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
line 256 mcts: sample exp_bonus 1.2716347970074648
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.794]
 [0.781]
 [0.794]
 [0.794]
 [0.794]
 [0.794]
 [0.794]] [[4.072]
 [6.248]
 [4.072]
 [4.072]
 [4.072]
 [4.072]
 [4.072]] [[1.306]
 [2.197]
 [1.306]
 [1.306]
 [1.306]
 [1.306]
 [1.306]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
Printing some Q and Qe and total Qs values:  [[0.636]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]] [[4.074]
 [3.899]
 [3.899]
 [3.899]
 [3.899]
 [3.899]
 [3.899]] [[0.636]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]
 [0.566]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
rdn probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.583]
 [0.57 ]
 [0.887]
 [0.578]
 [0.624]
 [0.551]] [[4.648]
 [4.515]
 [4.617]
 [3.69 ]
 [4.123]
 [5.364]
 [4.71 ]] [[1.459]
 [1.455]
 [1.493]
 [1.509]
 [1.206]
 [2.05 ]
 [1.515]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
from probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
siam score:  -0.62785506
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
Printing some Q and Qe and total Qs values:  [[0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]] [[3.613]
 [3.613]
 [3.613]
 [3.613]
 [3.613]
 [3.613]
 [3.613]] [[0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]
 [0.446]]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
maxi score, test score, baseline:  -0.99179 -1.0 -0.99179
probs:  [0.009276648762313695, 0.9777463579725706, 0.0012072650833128591, 0.011769728181803066]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00934950910170195, 0.9775971991137836, 0.001207279280424313, 0.011846012504090155]
siam score:  -0.62926203
Printing some Q and Qe and total Qs values:  [[0.358]
 [0.291]
 [0.246]
 [0.246]
 [0.246]
 [0.246]
 [0.396]] [[2.193]
 [2.1  ]
 [2.721]
 [2.721]
 [2.721]
 [2.721]
 [3.175]] [[-0.059]
 [-0.254]
 [ 0.07 ]
 [ 0.07 ]
 [ 0.07 ]
 [ 0.07 ]
 [ 0.672]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00934950910170195, 0.9775971991137836, 0.001207279280424313, 0.011846012504090155]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00934950910170195, 0.9775971991137836, 0.001207279280424313, 0.011846012504090155]
start point for exploration sampling:  10768
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[ 0.305]
 [ 0.305]
 [ 0.305]
 [ 0.305]
 [ 0.305]
 [ 0.305]
 [-0.052]] [[6.73 ]
 [6.73 ]
 [6.73 ]
 [6.73 ]
 [6.73 ]
 [6.73 ]
 [6.722]] [[1.157]
 [1.157]
 [1.157]
 [1.157]
 [1.157]
 [1.157]
 [0.861]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00934950910170195, 0.9775971991137836, 0.001207279280424313, 0.011846012504090155]
Printing some Q and Qe and total Qs values:  [[0.093]
 [0.093]
 [0.093]
 [0.093]
 [0.093]
 [0.093]
 [0.123]] [[2.963]
 [2.963]
 [2.963]
 [2.963]
 [2.963]
 [2.963]
 [3.206]] [[-0.021]
 [-0.021]
 [-0.021]
 [-0.021]
 [-0.021]
 [-0.021]
 [ 0.136]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
Printing some Q and Qe and total Qs values:  [[0.658]
 [0.667]
 [0.926]
 [0.681]
 [0.435]
 [0.651]
 [0.67 ]] [[1.009]
 [1.591]
 [0.84 ]
 [0.391]
 [0.56 ]
 [0.028]
 [1.484]] [[1.955]
 [2.361]
 [2.377]
 [1.589]
 [1.21 ]
 [1.287]
 [2.295]]
line 256 mcts: sample exp_bonus 4.031414737630583
Printing some Q and Qe and total Qs values:  [[0.832]
 [0.852]
 [0.832]
 [0.832]
 [0.832]
 [0.832]
 [0.832]] [[2.46 ]
 [3.843]
 [2.46 ]
 [2.46 ]
 [2.46 ]
 [2.46 ]
 [2.46 ]] [[1.522]
 [2.05 ]
 [1.522]
 [1.522]
 [1.522]
 [1.522]
 [1.522]]
using explorer policy with actor:  1
siam score:  -0.6285381
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.5388613641540085
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
Printing some Q and Qe and total Qs values:  [[0.269]
 [0.268]
 [0.264]
 [0.28 ]
 [0.265]
 [0.28 ]
 [0.283]] [[3.735]
 [4.739]
 [4.376]
 [4.53 ]
 [4.19 ]
 [4.53 ]
 [4.815]] [[0.251]
 [0.697]
 [0.529]
 [0.619]
 [0.448]
 [0.619]
 [0.751]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
Printing some Q and Qe and total Qs values:  [[-0.043]
 [ 0.092]
 [ 0.08 ]
 [ 0.107]
 [ 0.016]
 [ 0.08 ]
 [ 0.051]] [[5.267]
 [4.625]
 [4.418]
 [5.027]
 [2.846]
 [4.418]
 [5.009]] [[1.272]
 [1.19 ]
 [1.106]
 [1.343]
 [0.5  ]
 [1.106]
 [1.279]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
Printing some Q and Qe and total Qs values:  [[0.079]
 [0.052]
 [0.079]
 [0.079]
 [0.079]
 [0.079]
 [0.093]] [[3.234]
 [3.406]
 [3.234]
 [3.234]
 [3.234]
 [3.234]
 [3.031]] [[0.743]
 [0.79 ]
 [0.743]
 [0.743]
 [0.743]
 [0.743]
 [0.659]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
from probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
first move QE:  0.5813825812173937
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
Printing some Q and Qe and total Qs values:  [[0.911]
 [0.775]
 [0.889]
 [0.888]
 [0.75 ]
 [0.906]
 [0.808]] [[1.523]
 [1.161]
 [2.041]
 [1.921]
 [2.529]
 [1.972]
 [2.065]] [[1.047]
 [0.632]
 [1.291]
 [1.225]
 [1.329]
 [1.281]
 [1.173]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009997305872623789, 0.9760916236493969, 0.0012236623323352341, 0.012687408145643965]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739903, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739903, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739903, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 4.5206387928018685
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
from probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739895, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
Printing some Q and Qe and total Qs values:  [[0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]
 [0.639]] [[3.84]
 [3.84]
 [3.84]
 [3.84]
 [3.84]
 [3.84]
 [3.84]] [[1.779]
 [1.779]
 [1.779]
 [1.779]
 [1.779]
 [1.779]
 [1.779]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739895, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739895, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739895, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739895, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739895, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
siam score:  -0.6477563
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
rdn beta is 0 so we're just using the maxi policy
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
siam score:  -0.6569634
Printing some Q and Qe and total Qs values:  [[0.086]
 [0.086]
 [0.137]
 [0.086]
 [0.086]
 [0.109]
 [0.09 ]] [[4.06 ]
 [4.06 ]
 [4.567]
 [4.06 ]
 [4.06 ]
 [4.332]
 [4.257]] [[0.419]
 [0.419]
 [0.759]
 [0.419]
 [0.419]
 [0.595]
 [0.528]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739903, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
Printing some Q and Qe and total Qs values:  [[0.592]
 [0.784]
 [0.592]
 [0.592]
 [0.592]
 [0.592]
 [0.592]] [[1.946]
 [3.821]
 [1.946]
 [1.946]
 [1.946]
 [1.946]
 [1.946]] [[0.77 ]
 [2.221]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739903, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
siam score:  -0.66039306
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739903, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739903, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739903, 0.9751007574671796, 0.0012344445298962546, 0.013241156866184088]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
Printing some Q and Qe and total Qs values:  [[0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]
 [0.615]] [[2.322]
 [2.322]
 [2.322]
 [2.322]
 [2.322]
 [2.322]
 [2.322]] [[2.036]
 [2.036]
 [2.036]
 [2.036]
 [2.036]
 [2.036]
 [2.036]]
Printing some Q and Qe and total Qs values:  [[0.7]
 [0.7]
 [0.7]
 [0.7]
 [0.7]
 [0.7]
 [0.7]] [[5.417]
 [5.417]
 [5.417]
 [5.417]
 [5.417]
 [5.417]
 [5.417]] [[1.367]
 [1.367]
 [1.367]
 [1.367]
 [1.367]
 [1.367]
 [1.367]]
Printing some Q and Qe and total Qs values:  [[0.837]
 [0.855]
 [0.837]
 [0.837]
 [0.837]
 [0.837]
 [0.85 ]] [[4.226]
 [4.357]
 [4.226]
 [4.226]
 [4.226]
 [4.226]
 [4.688]] [[1.705]
 [1.828]
 [1.705]
 [1.705]
 [1.705]
 [1.705]
 [2.037]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.879]
 [0.93 ]
 [0.933]
 [0.919]
 [0.92 ]
 [0.926]
 [0.929]] [[1.195]
 [1.165]
 [1.592]
 [1.223]
 [1.13 ]
 [1.26 ]
 [1.375]] [[1.037]
 [1.099]
 [1.317]
 [1.111]
 [1.066]
 [1.141]
 [1.202]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
Printing some Q and Qe and total Qs values:  [[0.93 ]
 [0.883]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.93 ]
 [0.94 ]] [[3.723]
 [4.474]
 [3.723]
 [3.723]
 [3.723]
 [3.723]
 [4.31 ]] [[1.839]
 [2.054]
 [1.839]
 [1.839]
 [1.839]
 [1.839]
 [2.056]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010423641136739905, 0.9751007574671796, 0.0012344445298962548, 0.01324115686618409]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010156763991706336, 0.9753642577433036, 0.0012345090260408498, 0.013244469238949197]
from probs:  [0.010156763991706336, 0.9753642577433036, 0.0012345090260408498, 0.013244469238949197]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010156763991706336, 0.9753642577433036, 0.0012345090260408498, 0.013244469238949197]
actor:  1 policy actor:  1  step number:  60 total reward:  0.49499999999999966  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
Printing some Q and Qe and total Qs values:  [[0.961]
 [0.937]
 [0.92 ]
 [0.961]
 [0.961]
 [0.971]
 [1.094]] [[4.363]
 [3.983]
 [4.692]
 [4.363]
 [4.363]
 [4.326]
 [3.701]] [[1.937]
 [1.802]
 [1.999]
 [1.937]
 [1.937]
 [1.936]
 [1.859]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.548]
 [0.621]] [[5.236]
 [5.236]
 [5.236]
 [5.236]
 [5.236]
 [5.236]
 [5.132]] [[1.356]
 [1.356]
 [1.356]
 [1.356]
 [1.356]
 [1.356]
 [1.432]]
siam score:  -0.6516119
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
using another actor
siam score:  -0.6549933
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.1816855110059614
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
2028 1878
using another actor
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
siam score:  -0.6637932
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
first move QE:  0.5811822100047698
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.68 ]
 [0.797]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.68 ]
 [0.73 ]] [[1.724]
 [1.845]
 [1.724]
 [1.724]
 [1.724]
 [1.724]
 [1.9  ]] [[1.434]
 [1.748]
 [1.434]
 [1.434]
 [1.434]
 [1.434]
 [1.651]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
using explorer policy with actor:  1
first move QE:  0.581248358426174
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009513213530287236, 0.9768850269715695, 0.0012177546805389418, 0.012384004817604431]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Printing some Q and Qe and total Qs values:  [[0.367]
 [0.349]
 [0.357]
 [0.362]
 [0.364]
 [0.366]
 [0.364]] [[4.084]
 [5.516]
 [4.595]
 [4.55 ]
 [4.609]
 [4.575]
 [4.663]] [[0.54 ]
 [1.406]
 [0.842]
 [0.824]
 [0.864]
 [0.847]
 [0.898]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
first move QE:  0.5811863638608085
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.5006040245390041
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Printing some Q and Qe and total Qs values:  [[ 0.026]
 [ 0.029]
 [-0.006]
 [ 0.023]
 [ 0.023]
 [ 0.023]
 [-0.007]] [[2.316]
 [3.24 ]
 [3.349]
 [3.404]
 [3.404]
 [3.404]
 [3.624]] [[-0.757]
 [-0.135]
 [-0.132]
 [-0.038]
 [-0.038]
 [-0.038]
 [ 0.048]]
Printing some Q and Qe and total Qs values:  [[-0.005]
 [-0.048]
 [-0.036]
 [ 0.049]
 [ 0.049]
 [-0.008]
 [-0.028]] [[3.787]
 [4.715]
 [4.36 ]
 [3.856]
 [3.856]
 [3.567]
 [4.365]] [[0.602]
 [1.051]
 [0.871]
 [0.73 ]
 [0.73 ]
 [0.472]
 [0.888]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
siam score:  -0.6497874
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
in main func line 156:  2040
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Printing some Q and Qe and total Qs values:  [[0.527]
 [0.529]
 [0.527]
 [0.527]
 [0.527]
 [0.527]
 [0.552]] [[4.669]
 [5.7  ]
 [4.669]
 [4.669]
 [4.669]
 [4.669]
 [4.94 ]] [[1.195]
 [1.852]
 [1.195]
 [1.195]
 [1.195]
 [1.195]
 [1.415]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Printing some Q and Qe and total Qs values:  [[0.343]
 [0.429]
 [0.574]
 [0.64 ]
 [0.527]
 [0.536]
 [0.398]] [[0.471]
 [0.734]
 [0.517]
 [0.242]
 [0.379]
 [0.744]
 [1.047]] [[0.343]
 [0.429]
 [0.574]
 [0.64 ]
 [0.527]
 [0.536]
 [0.398]]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Printing some Q and Qe and total Qs values:  [[0.586]
 [0.61 ]
 [0.661]
 [0.643]
 [0.586]
 [0.505]
 [0.632]] [[6.144]
 [6.019]
 [3.991]
 [5.1  ]
 [6.144]
 [4.986]
 [5.902]] [[1.494]
 [1.472]
 [0.704]
 [1.136]
 [1.494]
 [0.919]
 [1.451]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
siam score:  -0.6466214
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Printing some Q and Qe and total Qs values:  [[0.209]
 [0.262]
 [0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.253]] [[4.672]
 [4.583]
 [4.672]
 [4.672]
 [4.672]
 [4.672]
 [4.881]] [[0.826]
 [0.867]
 [0.826]
 [0.826]
 [0.826]
 [0.826]
 [1.027]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]
 [0.572]] [[0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]] [[1.374]
 [1.374]
 [1.374]
 [1.374]
 [1.374]
 [1.374]
 [1.374]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Printing some Q and Qe and total Qs values:  [[0.187]
 [0.193]
 [0.187]
 [0.187]
 [0.187]
 [0.187]
 [0.187]] [[4.371]
 [4.744]
 [4.371]
 [4.371]
 [4.371]
 [4.371]
 [4.371]] [[0.376]
 [0.602]
 [0.376]
 [0.376]
 [0.376]
 [0.376]
 [0.376]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Printing some Q and Qe and total Qs values:  [[0.357]
 [0.308]
 [0.357]
 [0.357]
 [0.357]
 [0.357]
 [0.357]] [[3.995]
 [5.002]
 [3.995]
 [3.995]
 [3.995]
 [3.995]
 [3.995]] [[0.209]
 [0.781]
 [0.209]
 [0.209]
 [0.209]
 [0.209]
 [0.209]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Printing some Q and Qe and total Qs values:  [[0.249]
 [0.312]
 [0.249]
 [0.297]
 [0.249]
 [0.249]
 [0.364]] [[4.56 ]
 [4.779]
 [4.56 ]
 [4.43 ]
 [4.56 ]
 [4.56 ]
 [5.397]] [[0.588]
 [0.747]
 [0.588]
 [0.593]
 [0.588]
 [0.588]
 [1.047]]
Printing some Q and Qe and total Qs values:  [[0.283]
 [0.137]
 [0.284]
 [0.227]
 [0.23 ]
 [0.299]
 [0.267]] [[2.777]
 [3.443]
 [3.151]
 [3.222]
 [3.092]
 [3.183]
 [3.286]] [[-0.463]
 [-0.311]
 [-0.213]
 [-0.278]
 [-0.359]
 [-0.161]
 [-0.157]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010264033123863436, 0.97511077086837, 0.0012373016960948603, 0.01338789431167182]
Printing some Q and Qe and total Qs values:  [[0.255]
 [0.359]
 [0.136]
 [0.374]
 [0.359]
 [0.125]
 [0.19 ]] [[2.933]
 [2.359]
 [3.001]
 [2.592]
 [2.359]
 [3.254]
 [2.863]] [[0.356]
 [0.204]
 [0.189]
 [0.366]
 [0.204]
 [0.316]
 [0.203]]
Printing some Q and Qe and total Qs values:  [[0.418]
 [0.252]
 [0.418]
 [0.418]
 [0.418]
 [0.418]
 [0.401]] [[1.886]
 [2.54 ]
 [1.886]
 [1.886]
 [1.886]
 [1.886]
 [2.186]] [[0.115]
 [0.217]
 [0.115]
 [0.115]
 [0.115]
 [0.115]
 [0.281]]
actor:  1 policy actor:  1  step number:  126 total reward:  0.024999999999999245  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009943643398144774, 0.9758678814061373, 0.0012289605939097806, 0.012959514601808192]
Printing some Q and Qe and total Qs values:  [[0.705]
 [0.748]
 [0.705]
 [0.705]
 [0.705]
 [0.705]
 [0.705]] [[0.96]
 [2.43]
 [0.96]
 [0.96]
 [0.96]
 [0.96]
 [0.96]] [[0.959]
 [1.537]
 [0.959]
 [0.959]
 [0.959]
 [0.959]
 [0.959]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009943643398144774, 0.9758678814061373, 0.0012289605939097806, 0.012959514601808192]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
line 256 mcts: sample exp_bonus 3.0109987629486863
first move QE:  0.5803674608836873
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.684]
 [0.658]
 [0.631]
 [0.631]
 [0.631]
 [0.625]] [[3.991]
 [4.532]
 [2.179]
 [3.991]
 [3.991]
 [3.991]
 [4.86 ]] [[1.238]
 [1.549]
 [0.47 ]
 [1.238]
 [1.238]
 [1.238]
 [1.616]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009943643398144774, 0.9758678814061373, 0.0012289605939097806, 0.012959514601808192]
Printing some Q and Qe and total Qs values:  [[0.521]
 [0.436]
 [0.549]
 [0.538]
 [0.589]
 [0.687]
 [1.036]] [[0.683]
 [1.115]
 [0.763]
 [1.472]
 [0.638]
 [0.534]
 [0.316]] [[0.336]
 [0.453]
 [0.444]
 [0.896]
 [0.441]
 [0.568]
 [1.121]]
Printing some Q and Qe and total Qs values:  [[0.922]
 [0.922]
 [0.922]
 [0.922]
 [0.922]
 [0.922]
 [1.326]] [[0.807]
 [0.807]
 [0.807]
 [0.807]
 [0.807]
 [0.807]
 [0.662]] [[1.22 ]
 [1.22 ]
 [1.22 ]
 [1.22 ]
 [1.22 ]
 [1.22 ]
 [1.931]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.59 ]
 [0.382]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.59 ]
 [0.571]] [[5.09 ]
 [3.76 ]
 [5.09 ]
 [5.09 ]
 [5.09 ]
 [5.09 ]
 [5.536]] [[1.665]
 [0.669]
 [1.665]
 [1.665]
 [1.665]
 [1.665]
 [1.864]]
Printing some Q and Qe and total Qs values:  [[0.154]
 [0.121]
 [0.137]
 [0.139]
 [0.132]
 [0.074]
 [0.132]] [[ 0.613]
 [ 0.9  ]
 [ 0.613]
 [ 0.279]
 [-0.134]
 [ 0.694]
 [ 0.875]] [[0.154]
 [0.121]
 [0.137]
 [0.139]
 [0.132]
 [0.074]
 [0.132]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
from probs:  [0.009943643398144774, 0.9758678814061373, 0.0012289605939097806, 0.012959514601808192]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
line 256 mcts: sample exp_bonus 1.487949113282902
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009943643398144774, 0.9758678814061373, 0.0012289605939097806, 0.012959514601808192]
siam score:  -0.6397229
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009943643398144774, 0.9758678814061373, 0.0012289605939097806, 0.012959514601808192]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009943643398144774, 0.9758678814061373, 0.0012289605939097806, 0.012959514601808192]
siam score:  -0.64558446
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009943643398144774, 0.9758678814061373, 0.0012289605939097806, 0.012959514601808192]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00968485842621272, 0.9761234687713639, 0.0012290216662551859, 0.012962651136168383]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00968485842621272, 0.9761234687713639, 0.0012290216662551859, 0.012962651136168383]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00968485842621272, 0.9761234687713639, 0.0012290216662551859, 0.012962651136168383]
Printing some Q and Qe and total Qs values:  [[0.487]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]] [[3.833]
 [1.752]
 [1.752]
 [1.752]
 [1.752]
 [1.752]
 [1.752]] [[0.487]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]
 [0.389]]
line 256 mcts: sample exp_bonus 2.2549126651393445
2061 1893
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.561]
 [0.561]
 [0.676]
 [0.561]
 [0.561]
 [0.561]] [[2.301]
 [2.351]
 [2.351]
 [2.318]
 [2.351]
 [2.351]
 [2.351]] [[1.749]
 [1.676]
 [1.676]
 [1.883]
 [1.676]
 [1.676]
 [1.676]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010526934193726528, 0.9740990695802957, 0.0012516033253371411, 0.014122392900640608]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010526934193726528, 0.9740990695802957, 0.0012516033253371411, 0.014122392900640608]
Printing some Q and Qe and total Qs values:  [[0.508]
 [0.724]
 [0.508]
 [0.508]
 [0.508]
 [0.508]
 [0.505]] [[2.033]
 [2.157]
 [2.033]
 [2.033]
 [2.033]
 [2.033]
 [1.39 ]] [[0.554]
 [0.859]
 [0.554]
 [0.554]
 [0.554]
 [0.554]
 [0.296]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010526934193726528, 0.9740990695802957, 0.0012516033253371411, 0.014122392900640608]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.734]
 [0.734]
 [0.734]
 [0.734]
 [0.734]
 [0.734]] [[4.825]
 [4.825]
 [4.825]
 [4.825]
 [4.825]
 [4.825]
 [4.825]] [[1.938]
 [1.938]
 [1.938]
 [1.938]
 [1.938]
 [1.938]
 [1.938]]
Printing some Q and Qe and total Qs values:  [[0.435]
 [0.474]
 [0.435]
 [0.435]
 [0.435]
 [0.435]
 [0.448]] [[5.461]
 [4.375]
 [5.461]
 [5.461]
 [5.461]
 [5.461]
 [5.078]] [[1.555]
 [0.91 ]
 [1.555]
 [1.555]
 [1.555]
 [1.555]
 [1.324]]
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.010526934193726528, 0.9740990695802957, 0.0012516033253371411, 0.014122392900640608]
actor:  1 policy actor:  1  step number:  53 total reward:  0.5699999999999997  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076539, 0.9759781450471285, 0.0012306427155085536, 0.013045904475286382]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076539, 0.9759781450471285, 0.0012306427155085536, 0.013045904475286382]
Printing some Q and Qe and total Qs values:  [[0.63 ]
 [0.615]
 [0.63 ]
 [0.63 ]
 [0.63 ]
 [0.63 ]
 [0.57 ]] [[5.566]
 [4.997]
 [5.566]
 [5.566]
 [5.566]
 [5.566]
 [8.704]] [[1.134]
 [0.948]
 [1.134]
 [1.134]
 [1.134]
 [1.134]
 [2.033]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076539, 0.9759781450471285, 0.0012306427155085536, 0.013045904475286382]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076539, 0.9759781450471285, 0.0012306427155085536, 0.013045904475286382]
Printing some Q and Qe and total Qs values:  [[0.783]
 [0.82 ]
 [0.808]
 [0.812]
 [0.82 ]
 [0.8  ]
 [0.826]] [[2.298]
 [2.221]
 [2.427]
 [2.391]
 [2.221]
 [2.264]
 [2.466]] [[0.677]
 [0.7  ]
 [0.813]
 [0.796]
 [0.7  ]
 [0.688]
 [0.875]]
line 256 mcts: sample exp_bonus 4.619839526725609
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076539, 0.9759781450471285, 0.0012306427155085536, 0.013045904475286382]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.748]
 [0.703]
 [0.703]
 [0.703]
 [0.703]
 [0.74 ]] [[1.673]
 [2.059]
 [1.673]
 [1.673]
 [1.673]
 [1.673]
 [2.234]] [[1.226]
 [1.572]
 [1.226]
 [1.226]
 [1.226]
 [1.226]
 [1.673]]
Printing some Q and Qe and total Qs values:  [[0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.573]
 [0.68 ]] [[1.851]
 [1.851]
 [1.851]
 [1.851]
 [1.851]
 [1.851]
 [2.025]] [[1.124]
 [1.124]
 [1.124]
 [1.124]
 [1.124]
 [1.124]
 [1.455]]
start point for exploration sampling:  10768
Printing some Q and Qe and total Qs values:  [[0.855]
 [0.91 ]
 [0.855]
 [0.855]
 [0.855]
 [0.855]
 [0.819]] [[4.106]
 [3.722]
 [4.106]
 [4.106]
 [4.106]
 [4.106]
 [4.399]] [[1.999]
 [1.909]
 [1.999]
 [1.999]
 [1.999]
 [1.999]
 [2.074]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
first move QE:  0.5834642459263826
Printing some Q and Qe and total Qs values:  [[0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.544]
 [0.567]] [[1.438]
 [1.438]
 [1.438]
 [1.438]
 [1.438]
 [1.438]
 [1.625]] [[-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [-0.006]
 [ 0.165]]
siam score:  -0.65502375
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.412]
 [0.451]
 [0.413]
 [0.414]
 [0.414]
 [0.409]
 [0.42 ]] [[ 0.201]
 [ 0.755]
 [ 0.182]
 [-0.086]
 [ 0.325]
 [ 0.279]
 [ 0.374]] [[0.412]
 [0.451]
 [0.413]
 [0.414]
 [0.414]
 [0.409]
 [0.42 ]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.567]
 [0.616]
 [0.589]
 [0.757]
 [0.561]
 [0.757]
 [0.578]] [[ 0.288]
 [ 0.282]
 [ 0.176]
 [ 1.646]
 [-0.202]
 [ 1.646]
 [ 0.17 ]] [[0.822]
 [0.916]
 [0.793]
 [2.108]
 [0.484]
 [2.108]
 [0.766]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009745307762076537, 0.9759781450471285, 0.0012306427155085533, 0.01304590447528638]
actor:  1 policy actor:  1  step number:  127 total reward:  0.09999999999999931  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009407731246288147, 0.9767896986529323, 0.0012215900410489685, 0.012580980059730877]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009407731246288147, 0.9767896986529323, 0.0012215900410489685, 0.012580980059730877]
siam score:  -0.65045744
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009407731246288147, 0.9767896986529323, 0.0012215900410489685, 0.012580980059730877]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009407731246288147, 0.9767896986529323, 0.0012215900410489685, 0.012580980059730877]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009407731246288147, 0.9767896986529323, 0.0012215900410489685, 0.012580980059730877]
Printing some Q and Qe and total Qs values:  [[0.202]
 [0.233]
 [0.202]
 [0.202]
 [0.202]
 [0.202]
 [0.2  ]] [[5.669]
 [4.54 ]
 [5.669]
 [5.114]
 [5.669]
 [5.669]
 [5.644]] [[1.26 ]
 [0.78 ]
 [1.26 ]
 [1.003]
 [1.26 ]
 [1.26 ]
 [1.245]]
in main func line 156:  2077
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009407731246288147, 0.9767896986529323, 0.0012215900410489685, 0.012580980059730877]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009407731246288147, 0.9767896986529323, 0.0012215900410489685, 0.012580980059730877]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009407731246288147, 0.9767896986529323, 0.0012215900410489685, 0.012580980059730877]
siam score:  -0.6609379
Printing some Q and Qe and total Qs values:  [[0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]
 [0.201]] [[1.739]
 [1.739]
 [1.739]
 [1.739]
 [1.739]
 [1.739]
 [1.739]] [[-0.368]
 [-0.368]
 [-0.368]
 [-0.368]
 [-0.368]
 [-0.368]
 [-0.368]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009407731246288147, 0.9767896986529323, 0.0012215900410489685, 0.012580980059730877]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.5736149398541989
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009407731246288147, 0.9767896986529323, 0.0012215900410489685, 0.012580980059730877]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00941006752280248, 0.977060716368075, 0.001221652692180616, 0.012307563416941936]
siam score:  -0.65865827
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.602]
 [0.613]
 [0.602]
 [0.602]
 [0.602]
 [0.602]
 [0.602]] [[3.16 ]
 [3.299]
 [3.16 ]
 [3.16 ]
 [3.16 ]
 [3.16 ]
 [3.16 ]] [[1.785]
 [1.88 ]
 [1.785]
 [1.785]
 [1.785]
 [1.785]
 [1.785]]
Printing some Q and Qe and total Qs values:  [[0.532]
 [0.532]
 [0.532]
 [0.532]
 [0.532]
 [0.532]
 [0.532]] [[4.379]
 [4.379]
 [4.379]
 [4.379]
 [4.379]
 [4.379]
 [4.379]] [[0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]
 [0.812]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00941006752280248, 0.977060716368075, 0.001221652692180616, 0.012307563416941936]
actor:  1 policy actor:  1  step number:  70 total reward:  0.5249999999999997  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
from probs:  [0.00882744894987318, 0.9784422102208165, 0.001206028808325664, 0.011524312020984659]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00882744894987318, 0.9784422102208165, 0.001206028808325664, 0.011524312020984659]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00882744894987318, 0.9784422102208165, 0.001206028808325664, 0.011524312020984659]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00882744894987318, 0.9784422102208165, 0.001206028808325664, 0.011524312020984659]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00882744894987318, 0.9784422102208165, 0.001206028808325664, 0.011524312020984659]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00882744894987318, 0.9784422102208165, 0.001206028808325664, 0.011524312020984659]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00882744894987318, 0.9784422102208165, 0.001206028808325664, 0.011524312020984659]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00882744894987318, 0.9784422102208165, 0.001206028808325664, 0.011524312020984659]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.00882744894987318, 0.9784422102208165, 0.001206028808325664, 0.011524312020984659]
start point for exploration sampling:  10768
using another actor
actor:  1 policy actor:  1  step number:  86 total reward:  0.2849999999999995  reward:  1.0 rdn_beta:  0.333
Printing some Q and Qe and total Qs values:  [[0.754]
 [0.763]
 [0.754]
 [0.754]
 [0.754]
 [0.754]
 [0.7  ]] [[3.688]
 [3.915]
 [3.688]
 [3.688]
 [3.688]
 [3.688]
 [4.207]] [[1.64 ]
 [1.762]
 [1.64 ]
 [1.64 ]
 [1.64 ]
 [1.64 ]
 [1.812]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
siam score:  -0.6654655
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
siam score:  -0.6648432
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
siam score:  -0.6683026
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.605]
 [0.681]
 [0.622]
 [0.612]
 [0.628]
 [0.62 ]
 [0.612]] [[1.295]
 [2.836]
 [3.066]
 [0.786]
 [3.245]
 [1.551]
 [2.881]] [[0.824]
 [2.002]
 [2.036]
 [0.498]
 [2.169]
 [1.024]
 [1.893]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
using another actor
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008460961398162341, 0.9793112183906887, 0.0011962008364616254, 0.011031619374687388]
Printing some Q and Qe and total Qs values:  [[0.585]
 [0.565]
 [0.585]
 [0.6  ]
 [0.585]
 [0.585]
 [0.585]] [[5.199]
 [5.99 ]
 [5.199]
 [4.767]
 [5.199]
 [5.199]
 [5.199]] [[1.43 ]
 [1.863]
 [1.43 ]
 [1.201]
 [1.43 ]
 [1.43 ]
 [1.43 ]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009022588929012733, 0.9779794980895331, 0.0012112618106898095, 0.011786651170764344]
Printing some Q and Qe and total Qs values:  [[0.367]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]] [[2.19 ]
 [2.193]
 [2.193]
 [2.193]
 [2.193]
 [2.193]
 [2.193]] [[0.367]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]
 [0.364]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009022588929012733, 0.9779794980895331, 0.0012112618106898095, 0.011786651170764344]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009022588929012733, 0.9779794980895331, 0.0012112618106898095, 0.011786651170764344]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009022588929012733, 0.9779794980895331, 0.0012112618106898095, 0.011786651170764344]
Printing some Q and Qe and total Qs values:  [[0.307]
 [0.254]
 [0.305]
 [0.312]
 [0.296]
 [0.281]
 [0.273]] [[-0.014]
 [ 2.328]
 [ 1.217]
 [ 1.168]
 [ 0.874]
 [ 1.394]
 [ 2.082]] [[0.307]
 [0.254]
 [0.305]
 [0.312]
 [0.296]
 [0.281]
 [0.273]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
rdn beta is 0 so we're just using the maxi policy
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009022588929012733, 0.9779794980895331, 0.0012112618106898095, 0.011786651170764344]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009022588929012733, 0.9779794980895331, 0.0012112618106898095, 0.011786651170764344]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009022588929012731, 0.9779794980895331, 0.0012112618106898093, 0.011786651170764342]
Printing some Q and Qe and total Qs values:  [[0.637]
 [0.686]
 [0.637]
 [0.637]
 [0.637]
 [0.637]
 [0.637]] [[3.166]
 [3.934]
 [3.166]
 [3.166]
 [3.166]
 [3.166]
 [3.166]] [[1.184]
 [1.607]
 [1.184]
 [1.184]
 [1.184]
 [1.184]
 [1.184]]
line 256 mcts: sample exp_bonus 3.7608756907568672
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009022588929012731, 0.9779794980895331, 0.0012112618106898093, 0.011786651170764342]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.009022588929012731, 0.9779794980895331, 0.0012112618106898093, 0.011786651170764342]
Printing some Q and Qe and total Qs values:  [[0.21 ]
 [0.218]
 [0.213]
 [0.24 ]
 [0.28 ]
 [0.274]
 [0.185]] [[3.58 ]
 [3.593]
 [3.167]
 [2.654]
 [2.916]
 [3.24 ]
 [3.541]] [[0.594]
 [0.619]
 [0.324]
 [0.037]
 [0.292]
 [0.495]
 [0.518]]
using explorer policy with actor:  1
actor:  1 policy actor:  1  step number:  55 total reward:  0.48999999999999966  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008513387236784698, 0.9791869072596214, 0.001197606722321933, 0.011102098781271937]
siam score:  -0.6648096
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.008513387236784698, 0.9791869072596214, 0.001197606722321933, 0.011102098781271937]
actor:  1 policy actor:  1  step number:  78 total reward:  0.23499999999999943  reward:  1.0 rdn_beta:  0.333
first move QE:  0.5884584893883918
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
actor:  1 policy actor:  1  step number:  52 total reward:  0.5449999999999997  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004823, 0.9809785152953677, 0.0011773446879968811, 0.01008632915463064]
Printing some Q and Qe and total Qs values:  [[0.619]
 [0.617]
 [0.54 ]
 [0.54 ]
 [0.54 ]
 [0.54 ]
 [0.537]] [[2.139]
 [1.915]
 [1.09 ]
 [1.09 ]
 [1.09 ]
 [1.09 ]
 [2.014]] [[1.939]
 [1.834]
 [1.347]
 [1.347]
 [1.347]
 [1.347]
 [1.769]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004823, 0.9809785152953677, 0.0011773446879968811, 0.01008632915463064]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004823, 0.9809785152953677, 0.0011773446879968811, 0.01008632915463064]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004823, 0.9809785152953677, 0.0011773446879968811, 0.01008632915463064]
from probs:  [0.007757810862004823, 0.9809785152953677, 0.0011773446879968811, 0.01008632915463064]
Printing some Q and Qe and total Qs values:  [[0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.544]] [[2.556]
 [2.556]
 [2.556]
 [2.556]
 [2.556]
 [2.556]
 [5.718]] [[0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.422]
 [0.544]]
Printing some Q and Qe and total Qs values:  [[0.266]
 [0.266]
 [0.266]
 [0.266]
 [0.266]
 [0.266]
 [0.231]] [[5.95 ]
 [5.95 ]
 [5.95 ]
 [5.95 ]
 [5.95 ]
 [5.95 ]
 [9.428]] [[0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [0.774]
 [1.611]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004823, 0.9809785152953677, 0.0011773446879968811, 0.01008632915463064]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004823, 0.9809785152953677, 0.0011773446879968811, 0.01008632915463064]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004823, 0.9809785152953677, 0.0011773446879968811, 0.01008632915463064]
first move QE:  0.5899115086193043
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004823, 0.9809785152953677, 0.0011773446879968811, 0.01008632915463064]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004814, 0.9809785152953677, 0.0011773446879968811, 0.010086329154630633]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004814, 0.9809785152953677, 0.0011773446879968811, 0.010086329154630633]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004814, 0.9809785152953677, 0.0011773446879968811, 0.010086329154630633]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.6315436224594997
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004814, 0.9809785152953677, 0.0011773446879968811, 0.010086329154630633]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.007757810862004814, 0.9809785152953677, 0.0011773446879968811, 0.010086329154630633]
actor:  1 policy actor:  1  step number:  63 total reward:  0.2999999999999995  reward:  1.0 rdn_beta:  0.167
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08600149461829047, 0.903468159196661, 0.001163002741964538, 0.009367343443083879]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08600149461829047, 0.903468159196661, 0.001163002741964538, 0.009367343443083879]
Printing some Q and Qe and total Qs values:  [[0.781]
 [0.849]
 [0.781]
 [0.781]
 [0.781]
 [0.781]
 [0.781]] [[3.078]
 [3.888]
 [3.078]
 [3.078]
 [3.078]
 [3.078]
 [3.078]] [[1.851]
 [2.266]
 [1.851]
 [1.851]
 [1.851]
 [1.851]
 [1.851]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08600149461829047, 0.903468159196661, 0.001163002741964538, 0.009367343443083879]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08600149461829047, 0.903468159196661, 0.001163002741964538, 0.009367343443083879]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08600149461829047, 0.903468159196661, 0.001163002741964538, 0.009367343443083879]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08600149461829047, 0.903468159196661, 0.001163002741964538, 0.009367343443083879]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08600149461829047, 0.903468159196661, 0.001163002741964538, 0.009367343443083879]
Printing some Q and Qe and total Qs values:  [[0.629]
 [0.501]
 [0.629]
 [0.629]
 [0.629]
 [0.629]
 [0.206]] [[2.539]
 [3.49 ]
 [2.539]
 [2.539]
 [2.539]
 [2.539]
 [2.381]] [[1.14 ]
 [1.403]
 [1.14 ]
 [1.14 ]
 [1.14 ]
 [1.14 ]
 [0.477]]
Printing some Q and Qe and total Qs values:  [[0.558]
 [0.513]
 [0.545]
 [0.545]
 [0.545]
 [0.545]
 [0.521]] [[1.193]
 [1.312]
 [0.974]
 [0.974]
 [0.974]
 [0.974]
 [1.387]] [[1.761]
 [1.753]
 [1.625]
 [1.625]
 [1.625]
 [1.625]
 [1.804]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08600149461829047, 0.903468159196661, 0.001163002741964538, 0.009367343443083879]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08600149461829047, 0.903468159196661, 0.001163002741964538, 0.009367343443083879]
Printing some Q and Qe and total Qs values:  [[0.33 ]
 [0.365]
 [0.33 ]
 [0.33 ]
 [0.33 ]
 [0.33 ]
 [0.33 ]] [[0.835]
 [0.992]
 [0.835]
 [0.835]
 [0.835]
 [0.835]
 [0.835]] [[-0.275]
 [-0.152]
 [-0.275]
 [-0.275]
 [-0.275]
 [-0.275]
 [-0.275]]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
first move QE:  0.5903612397554633
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
Printing some Q and Qe and total Qs values:  [[0.135]
 [0.134]
 [0.125]
 [0.122]
 [0.124]
 [0.124]
 [0.124]] [[4.496]
 [4.451]
 [4.304]
 [4.428]
 [4.301]
 [4.443]
 [4.365]] [[0.627]
 [0.594]
 [0.478]
 [0.556]
 [0.476]
 [0.57 ]
 [0.517]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
line 256 mcts: sample exp_bonus 0.3205286903774801
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
Printing some Q and Qe and total Qs values:  [[0.791]
 [0.791]
 [0.791]
 [0.791]
 [0.791]
 [0.791]
 [0.791]] [[1.816]
 [1.816]
 [1.816]
 [1.816]
 [1.816]
 [1.816]
 [1.816]] [[2.325]
 [2.325]
 [2.325]
 [2.325]
 [2.325]
 [2.325]
 [2.325]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
Printing some Q and Qe and total Qs values:  [[0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.48 ]
 [0.533]] [[4.886]
 [4.886]
 [4.886]
 [4.886]
 [4.886]
 [4.886]
 [5.393]] [[1.406]
 [1.406]
 [1.406]
 [1.406]
 [1.406]
 [1.406]
 [1.735]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
first move QE:  0.5904621226098163
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
Printing some Q and Qe and total Qs values:  [[-0.062]
 [-0.075]
 [-0.062]
 [-0.086]
 [-0.062]
 [-0.062]
 [-0.13 ]] [[4.802]
 [3.081]
 [4.802]
 [3.862]
 [4.802]
 [4.802]
 [4.742]] [[ 0.922]
 [-0.057]
 [ 0.922]
 [ 0.359]
 [ 0.922]
 [ 0.922]
 [ 0.776]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[-0.059]
 [-0.049]
 [-0.06 ]
 [-0.056]
 [-0.056]
 [-0.062]
 [-0.059]] [[2.885]
 [2.452]
 [2.942]
 [2.75 ]
 [2.839]
 [2.951]
 [2.97 ]] [[ 0.074]
 [-0.195]
 [ 0.11 ]
 [-0.011]
 [ 0.049]
 [ 0.111]
 [ 0.129]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
Printing some Q and Qe and total Qs values:  [[0.271]
 [0.013]
 [0.137]
 [0.129]
 [0.193]
 [0.129]
 [0.002]] [[1.635]
 [2.677]
 [2.015]
 [1.981]
 [1.933]
 [1.981]
 [2.868]] [[-0.304]
 [-0.127]
 [-0.319]
 [-0.358]
 [-0.261]
 [-0.358]
 [-0.022]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08554732398404881, 0.9039180731820419, 0.0011630859907382808, 0.009371516843171253]
actor:  1 policy actor:  1  step number:  100 total reward:  0.11499999999999932  reward:  1.0 rdn_beta:  0.333
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.644]
 [0.614]
 [0.644]
 [0.594]
 [0.644]
 [0.644]
 [0.599]] [[4.192]
 [3.953]
 [4.192]
 [3.87 ]
 [4.192]
 [4.192]
 [4.104]] [[1.801]
 [1.643]
 [1.801]
 [1.575]
 [1.801]
 [1.801]
 [1.693]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08313528033929297, 0.9065738156467575, 0.001158319887499314, 0.009132584126450233]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08313528033929297, 0.9065738156467575, 0.001158319887499314, 0.009132584126450233]
siam score:  -0.6754638
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08313528033929297, 0.9065738156467575, 0.001158319887499314, 0.009132584126450233]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
Printing some Q and Qe and total Qs values:  [[0.674]
 [0.493]
 [0.726]
 [0.689]
 [0.694]
 [0.709]
 [0.729]] [[2.178]
 [2.127]
 [1.957]
 [2.134]
 [2.051]
 [2.087]
 [2.04 ]] [[0.638]
 [0.244]
 [0.596]
 [0.64 ]
 [0.595]
 [0.648]
 [0.657]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08313528033929297, 0.9065738156467575, 0.001158319887499314, 0.009132584126450233]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08313528033929297, 0.9065738156467575, 0.001158319887499314, 0.009132584126450233]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.08313528033929297, 0.9065738156467575, 0.001158319887499314, 0.009132584126450233]
actor:  1 policy actor:  1  step number:  61 total reward:  0.5099999999999997  reward:  1.0 rdn_beta:  0.333
using another actor
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07904089823325373, 0.9110818702374868, 0.001150229549723052, 0.008727001979536455]
siam score:  -0.6673078
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.511]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]] [[-0.604]
 [-0.446]
 [-0.446]
 [-0.446]
 [-0.446]
 [-0.446]
 [-0.446]] [[0.511]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]
 [0.51 ]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
actor:  1 policy actor:  1  step number:  100 total reward:  0.14499999999999935  reward:  1.0 rdn_beta:  0.333
using another actor
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07687150175758456, 0.9134704498785583, 0.0011459429077330659, 0.008512105456124209]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07687150175758456, 0.9134704498785583, 0.0011459429077330659, 0.008512105456124209]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.718]
 [0.571]
 [0.595]
 [0.698]
 [0.698]
 [0.635]
 [0.636]] [[2.245]
 [3.818]
 [1.37 ]
 [2.646]
 [2.646]
 [2.598]
 [1.305]] [[0.718]
 [0.571]
 [0.595]
 [0.698]
 [0.698]
 [0.635]
 [0.636]]
actor:  1 policy actor:  1  step number:  53 total reward:  0.4199999999999996  reward:  1.0 rdn_beta:  0.333
using another actor
from probs:  [0.07375481717123092, 0.9169020260953071, 0.0011397844617471679, 0.008203372271714788]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -1.0744467577969972
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07336168799605694, 0.9172920251114565, 0.0011398456793643397, 0.008206441213122202]
Printing some Q and Qe and total Qs values:  [[0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]] [[-0.339]
 [-0.339]
 [-0.339]
 [-0.339]
 [-0.339]
 [-0.339]
 [-0.339]] [[0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]
 [0.345]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07297131118142154, 0.9176792936818137, 0.0011399064683871344, 0.008209488668377576]
Printing some Q and Qe and total Qs values:  [[0.529]
 [0.524]
 [0.511]
 [0.511]
 [0.529]
 [0.554]
 [0.509]] [[-2.245]
 [ 0.246]
 [-0.277]
 [-0.546]
 [-0.799]
 [ 0.088]
 [ 0.007]] [[0.529]
 [0.524]
 [0.511]
 [0.511]
 [0.529]
 [0.554]
 [0.509]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07297131118142154, 0.9176792936818137, 0.0011399064683871344, 0.008209488668377576]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07297131118142154, 0.9176792936818137, 0.0011399064683871344, 0.008209488668377576]
Printing some Q and Qe and total Qs values:  [[0.663]
 [0.917]
 [0.663]
 [0.663]
 [0.663]
 [0.663]
 [0.727]] [[2.314]
 [2.361]
 [2.314]
 [2.314]
 [2.314]
 [2.314]
 [2.153]] [[1.375]
 [1.765]
 [1.375]
 [1.375]
 [1.375]
 [1.375]
 [1.391]]
Printing some Q and Qe and total Qs values:  [[0.586]
 [0.655]
 [0.586]
 [0.586]
 [0.586]
 [0.586]
 [0.586]] [[0.643]
 [1.242]
 [0.643]
 [0.643]
 [0.643]
 [0.643]
 [0.643]] [[2.026]
 [2.486]
 [2.026]
 [2.026]
 [2.026]
 [2.026]
 [2.026]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07297131118142154, 0.9176792936818137, 0.0011399064683871344, 0.008209488668377576]
siam score:  -0.66130316
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07297131118142154, 0.9176792936818137, 0.0011399064683871344, 0.008209488668377576]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07297131118142154, 0.9176792936818137, 0.0011399064683871344, 0.008209488668377576]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07297131118142154, 0.9176792936818137, 0.0011399064683871344, 0.008209488668377576]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.07297131118142154, 0.9176792936818137, 0.0011399064683871344, 0.008209488668377576]
actor:  1 policy actor:  1  step number:  50 total reward:  0.5149999999999997  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06975216342720685, 0.9212275048924323, 0.001133470859032728, 0.00788686082132806]
first move QE:  0.5901419427093377
start point for exploration sampling:  10768
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]] [[0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]
 [0.242]] [[0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]
 [0.324]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06975216342720685, 0.9212275048924323, 0.001133470859032728, 0.00788686082132806]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06975216342720685, 0.9212275048924323, 0.001133470859032728, 0.00788686082132806]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06975216342720685, 0.9212275048924323, 0.001133470859032728, 0.00788686082132806]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06975216342720685, 0.9212275048924323, 0.001133470859032728, 0.00788686082132806]
actor:  1 policy actor:  1  step number:  53 total reward:  0.5399999999999997  reward:  1.0 rdn_beta:  0.333
actor:  1 policy actor:  1  step number:  117 total reward:  0.2899999999999995  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
Starting evaluation
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
Printing some Q and Qe and total Qs values:  [[0.183]
 [0.203]
 [0.252]
 [0.195]
 [0.252]
 [0.252]
 [0.128]] [[ 1.385]
 [ 1.171]
 [ 0.   ]
 [-0.365]
 [ 0.   ]
 [ 0.   ]
 [ 1.204]] [[0.183]
 [0.203]
 [0.252]
 [0.195]
 [0.252]
 [0.252]
 [0.128]]
Printing some Q and Qe and total Qs values:  [[-0.008]
 [ 0.084]
 [ 0.193]
 [ 0.183]
 [ 0.183]
 [ 0.183]
 [ 0.101]] [[ 1.651]
 [ 0.614]
 [-0.653]
 [ 0.   ]
 [ 0.   ]
 [ 0.   ]
 [ 0.896]] [[-0.008]
 [ 0.084]
 [ 0.193]
 [ 0.183]
 [ 0.183]
 [ 0.183]
 [ 0.101]]
line 256 mcts: sample exp_bonus 2.287634818806502
Printing some Q and Qe and total Qs values:  [[0.398]
 [0.415]
 [0.396]
 [0.407]
 [0.374]
 [0.543]
 [0.418]] [[0.701]
 [0.278]
 [1.46 ]
 [0.658]
 [0.243]
 [1.616]
 [1.082]] [[0.398]
 [0.415]
 [0.396]
 [0.407]
 [0.374]
 [0.543]
 [0.418]]
Printing some Q and Qe and total Qs values:  [[0.087]
 [0.191]
 [0.087]
 [0.087]
 [0.087]
 [0.087]
 [0.146]] [[0.613]
 [1.997]
 [0.613]
 [0.613]
 [0.613]
 [0.613]
 [2.242]] [[0.087]
 [0.191]
 [0.087]
 [0.087]
 [0.087]
 [0.087]
 [0.146]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.387]
 [0.405]
 [0.371]
 [0.37 ]
 [0.361]
 [0.372]
 [0.386]] [[0.13 ]
 [0.427]
 [0.393]
 [0.167]
 [0.306]
 [0.588]
 [0.237]] [[0.387]
 [0.405]
 [0.371]
 [0.37 ]
 [0.361]
 [0.372]
 [0.386]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
Printing some Q and Qe and total Qs values:  [[0.486]
 [0.486]
 [0.486]
 [0.486]
 [0.486]
 [0.486]
 [0.486]] [[2.342]
 [2.342]
 [2.342]
 [2.342]
 [2.342]
 [2.342]
 [2.342]] [[0.486]
 [0.486]
 [0.486]
 [0.486]
 [0.486]
 [0.486]
 [0.486]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.386]] [[3.065]
 [3.065]
 [3.065]
 [3.065]
 [3.065]
 [3.065]
 [2.672]] [[0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.366]
 [0.386]]
using explorer policy with actor:  0
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.678]] [[4.315]
 [4.315]
 [4.315]
 [4.315]
 [4.315]
 [4.315]
 [4.315]] [[1.81]
 [1.81]
 [1.81]
 [1.81]
 [1.81]
 [1.81]
 [1.81]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 2.118856966340858
Printing some Q and Qe and total Qs values:  [[0.747]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.506]] [[2.238]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]
 [0.909]] [[0.747]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.506]
 [0.506]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]] [[0.879]
 [0.879]
 [0.879]
 [0.879]
 [0.879]
 [0.879]
 [0.879]] [[0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]
 [0.683]]
line 256 mcts: sample exp_bonus 2.2409393074780843
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
Printing some Q and Qe and total Qs values:  [[0.812]
 [0.543]
 [0.534]
 [0.534]
 [0.534]
 [0.534]
 [0.534]] [[-1.547]
 [ 0.477]
 [-0.704]
 [-0.704]
 [-0.704]
 [-0.704]
 [-0.704]] [[0.812]
 [0.543]
 [0.534]
 [0.534]
 [0.534]
 [0.534]
 [0.534]]
siam score:  -0.6620492
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
using explorer policy with actor:  1
line 256 mcts: sample exp_bonus 3.433488546593368
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
using explorer policy with actor:  0
siam score:  -0.65620196
Printing some Q and Qe and total Qs values:  [[0.792]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]] [[1.821]
 [1.589]
 [1.589]
 [1.589]
 [1.589]
 [1.589]
 [1.589]] [[0.792]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]
 [0.622]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
Printing some Q and Qe and total Qs values:  [[0.717]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]] [[2.004]
 [1.765]
 [1.765]
 [1.765]
 [1.765]
 [1.765]
 [1.765]] [[0.717]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]
 [0.621]]
Printing some Q and Qe and total Qs values:  [[0.859]
 [0.624]
 [0.624]
 [0.624]
 [0.624]
 [0.624]
 [0.624]] [[1.442]
 [1.336]
 [1.336]
 [1.336]
 [1.336]
 [1.336]
 [1.336]] [[0.859]
 [0.624]
 [0.624]
 [0.624]
 [0.624]
 [0.624]
 [0.624]]
line 256 mcts: sample exp_bonus 3.221264223213015
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.835]
 [0.835]
 [0.835]
 [0.835]
 [0.835]
 [0.835]
 [0.835]] [[1.696]
 [1.696]
 [1.696]
 [1.696]
 [1.696]
 [1.696]
 [1.696]] [[0.835]
 [0.835]
 [0.835]
 [0.835]
 [0.835]
 [0.835]
 [0.835]]
Printing some Q and Qe and total Qs values:  [[0.679]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]] [[0.54 ]
 [0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]
 [0.007]] [[0.679]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]
 [0.493]]
Printing some Q and Qe and total Qs values:  [[0.549]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]] [[0.752]
 [0.325]
 [0.325]
 [0.325]
 [0.325]
 [0.325]
 [0.325]] [[0.549]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]]
Printing some Q and Qe and total Qs values:  [[0.802]
 [0.639]
 [0.894]
 [0.791]
 [0.746]
 [0.843]
 [0.874]] [[1.609]
 [1.585]
 [1.563]
 [1.538]
 [1.548]
 [1.611]
 [1.695]] [[0.802]
 [0.639]
 [0.894]
 [0.791]
 [0.746]
 [0.843]
 [0.874]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
Printing some Q and Qe and total Qs values:  [[0.704]
 [0.509]
 [0.49 ]
 [0.49 ]
 [0.49 ]
 [0.49 ]
 [0.49 ]] [[-1.441]
 [ 0.578]
 [-0.484]
 [-0.484]
 [-0.484]
 [-0.484]
 [-0.484]] [[0.704]
 [0.509]
 [0.49 ]
 [0.49 ]
 [0.49 ]
 [0.49 ]
 [0.49 ]]
Printing some Q and Qe and total Qs values:  [[0.663]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]] [[ 0.014]
 [-0.387]
 [-0.387]
 [-0.387]
 [-0.387]
 [-0.387]
 [-0.387]] [[0.663]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]
 [0.439]]
line 256 mcts: sample exp_bonus 4.557816097508533
Printing some Q and Qe and total Qs values:  [[0.783]
 [0.715]
 [0.745]
 [0.792]
 [0.849]
 [0.811]
 [0.83 ]] [[1.726]
 [1.926]
 [1.581]
 [1.571]
 [1.483]
 [1.762]
 [1.712]] [[0.783]
 [0.715]
 [0.745]
 [0.792]
 [0.849]
 [0.811]
 [0.83 ]]
Printing some Q and Qe and total Qs values:  [[0.653]
 [0.498]
 [0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]] [[0.291]
 [0.45 ]
 [0.167]
 [0.167]
 [0.167]
 [0.167]
 [0.167]] [[0.653]
 [0.498]
 [0.481]
 [0.481]
 [0.481]
 [0.481]
 [0.481]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
in main func line 156:  2147
from probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
2149 1917
2150 1917
Printing some Q and Qe and total Qs values:  [[0.69 ]
 [0.789]
 [0.688]
 [0.678]
 [0.789]
 [0.789]
 [0.656]] [[-0.487]
 [ 0.   ]
 [-0.116]
 [-0.163]
 [ 0.   ]
 [ 0.   ]
 [-0.253]] [[0.69 ]
 [0.789]
 [0.688]
 [0.678]
 [0.789]
 [0.789]
 [0.656]]
Printing some Q and Qe and total Qs values:  [[0.734]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]] [[-0.39 ]
 [-0.245]
 [-0.245]
 [-0.245]
 [-0.245]
 [-0.245]
 [-0.245]] [[0.734]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]
 [0.702]]
line 256 mcts: sample exp_bonus 1.7321436967853323
Printing some Q and Qe and total Qs values:  [[0.542]
 [0.624]
 [0.542]
 [0.542]
 [0.542]
 [0.542]
 [0.542]] [[0.561]
 [1.661]
 [0.561]
 [0.561]
 [0.561]
 [0.561]
 [0.561]] [[0.847]
 [1.455]
 [0.847]
 [0.847]
 [0.847]
 [0.847]
 [0.847]]
using explorer policy with actor:  0
start point for exploration sampling:  10768
line 256 mcts: sample exp_bonus -3.504491982799453
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
rdn probs:  [0.06474150836088999, 0.9267503525018876, 0.001123453729941876, 0.007384685407280336]
siam score:  -0.66844976
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
siam score:  -0.66949725
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
siam score:  -0.6683473
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
Printing some Q and Qe and total Qs values:  [[0.605]
 [0.639]
 [0.605]
 [0.605]
 [0.605]
 [0.605]
 [0.54 ]] [[3.158]
 [3.037]
 [3.158]
 [3.158]
 [3.158]
 [3.158]
 [4.112]] [[1.754]
 [1.747]
 [1.754]
 [1.754]
 [1.754]
 [1.754]
 [2.019]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
siam score:  -0.6731902
using explorer policy with actor:  1
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.773]
 [0.774]
 [0.773]
 [0.732]
 [0.773]
 [0.773]
 [0.773]] [[ 0.946]
 [ 1.926]
 [ 0.946]
 [-0.333]
 [ 0.946]
 [ 0.946]
 [ 0.946]] [[1.043]
 [1.548]
 [1.043]
 [0.327]
 [1.043]
 [1.043]
 [1.043]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
line 256 mcts: sample exp_bonus 3.086029779345953
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]
 [0.747]] [[1.435]
 [1.435]
 [1.435]
 [1.435]
 [1.435]
 [1.435]
 [1.435]] [[1.488]
 [1.488]
 [1.488]
 [1.488]
 [1.488]
 [1.488]
 [1.488]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
UNIT TEST: sample policy line 217 mcts : [0.184 0.02  0.633 0.02  0.02  0.041 0.082]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.0666518606606389, 0.924644722700545, 0.0011272728404857707, 0.007576143798330312]
actor:  1 policy actor:  1  step number:  80 total reward:  0.5149999999999997  reward:  1.0 rdn_beta:  0.333
first move QE:  0.5899865840504563
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06396262049451994, 0.9276088588117181, 0.0011218966041366745, 0.00730662408962539]
using another actor
siam score:  -0.6775155
using explorer policy with actor:  1
siam score:  -0.6749564
first move QE:  0.5892166924508008
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06396262049451994, 0.9276088588117181, 0.0011218966041366745, 0.00730662408962539]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06396262049451994, 0.9276088588117181, 0.0011218966041366745, 0.00730662408962539]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06396262049451994, 0.9276088588117181, 0.0011218966041366745, 0.00730662408962539]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06396262049451994, 0.9276088588117181, 0.0011218966041366745, 0.00730662408962539]
2165 1928
using another actor
Printing some Q and Qe and total Qs values:  [[0.401]
 [0.671]
 [0.546]
 [0.586]
 [0.542]
 [0.459]
 [0.351]] [[3.98 ]
 [5.803]
 [2.42 ]
 [2.674]
 [2.702]
 [2.998]
 [3.673]] [[0.908]
 [1.831]
 [0.514]
 [0.645]
 [0.608]
 [0.625]
 [0.747]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06396262049451994, 0.9276088588117181, 0.0011218966041366745, 0.00730662408962539]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
Printing some Q and Qe and total Qs values:  [[0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]] [[0.259]
 [0.875]
 [0.259]
 [0.259]
 [0.259]
 [0.259]
 [0.259]] [[0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]
 [0.379]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
Printing some Q and Qe and total Qs values:  [[0.66 ]
 [0.629]
 [0.64 ]
 [0.678]
 [0.671]
 [0.663]
 [0.709]] [[0.792]
 [1.622]
 [1.294]
 [1.362]
 [1.054]
 [1.117]
 [1.26 ]] [[0.338]
 [0.83 ]
 [0.633]
 [0.755]
 [0.535]
 [0.561]
 [0.748]]
Printing some Q and Qe and total Qs values:  [[0.792]
 [0.656]
 [0.794]
 [0.801]
 [0.8  ]
 [0.818]
 [0.796]] [[0.484]
 [1.502]
 [0.598]
 [0.771]
 [0.715]
 [0.771]
 [1.159]] [[0.136]
 [0.543]
 [0.216]
 [0.347]
 [0.307]
 [0.379]
 [0.595]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
using explorer policy with actor:  0
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 0.6117968256523377
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
using another actor
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
line 256 mcts: sample exp_bonus 1.0360245328144186
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06362019902419914, 0.9279489181433062, 0.001121942801311804, 0.007308940031182915]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.763]
 [0.784]
 [0.773]
 [0.789]
 [0.788]
 [0.783]] [[-1.917]
 [-1.595]
 [-1.127]
 [-1.931]
 [-1.77 ]
 [-1.025]
 [-0.914]] [[0.873]
 [1.003]
 [1.202]
 [0.911]
 [0.997]
 [1.245]
 [1.27 ]]
Printing some Q and Qe and total Qs values:  [[0.516]
 [0.688]
 [0.773]
 [0.726]
 [0.726]
 [0.726]
 [0.735]] [[1.742]
 [1.634]
 [0.54 ]
 [1.005]
 [1.005]
 [1.005]
 [1.299]] [[1.851]
 [2.122]
 [1.563]
 [1.78 ]
 [1.78 ]
 [1.78 ]
 [1.994]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.485]
 [0.536]
 [0.536]
 [0.554]
 [0.554]
 [0.583]
 [0.557]] [[-0.749]
 [ 0.838]
 [-0.166]
 [ 0.   ]
 [ 0.   ]
 [ 1.017]
 [ 0.298]] [[0.216]
 [0.848]
 [0.513]
 [0.606]
 [0.606]
 [1.003]
 [0.711]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06328019381638351, 0.9282865778805824, 0.0011219886725012355, 0.007311239630532856]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.849774599467442
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06328019381638351, 0.9282865778805824, 0.0011219886725012355, 0.007311239630532856]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06328019381638351, 0.9282865778805824, 0.0011219886725012355, 0.007311239630532856]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06294257938582179, 0.9286218633329921, 0.0011220342211432652, 0.007313523060042762]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06294257938582179, 0.9286218633329921, 0.0011220342211432652, 0.007313523060042762]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06294257938582179, 0.9286218633329921, 0.0011220342211432652, 0.007313523060042762]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06294257938582179, 0.9286218633329921, 0.0011220342211432652, 0.007313523060042762]
Printing some Q and Qe and total Qs values:  [[0.67 ]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.809]] [[1.87 ]
 [1.87 ]
 [1.87 ]
 [1.87 ]
 [1.87 ]
 [1.87 ]
 [3.922]] [[0.67 ]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.67 ]
 [0.809]]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06294257938582179, 0.9286218633329921, 0.0011220342211432652, 0.007313523060042762]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06294257938582179, 0.9286218633329921, 0.0011220342211432652, 0.007313523060042762]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06294257938582179, 0.9286218633329921, 0.0011220342211432652, 0.007313523060042762]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06294257938582179, 0.9286218633329921, 0.0011220342211432652, 0.007313523060042762]
actor:  1 policy actor:  1  step number:  122 total reward:  0.2049999999999994  reward:  1.0 rdn_beta:  0.333
Printing some Q and Qe and total Qs values:  [[0.513]
 [0.36 ]
 [0.513]
 [0.513]
 [0.513]
 [0.691]
 [0.618]] [[1.774]
 [2.63 ]
 [1.774]
 [1.774]
 [1.774]
 [2.058]
 [2.1  ]] [[0.288]
 [0.551]
 [0.288]
 [0.288]
 [0.288]
 [0.832]
 [0.715]]
Printing some Q and Qe and total Qs values:  [[0.897]
 [0.907]
 [0.897]
 [0.897]
 [0.897]
 [0.897]
 [0.897]] [[1.695]
 [2.351]
 [1.695]
 [1.695]
 [1.695]
 [1.695]
 [1.695]] [[2.145]
 [2.59 ]
 [2.145]
 [2.145]
 [2.145]
 [2.145]
 [2.145]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06137926693662705, 0.9303477876032007, 0.0011188539647638712, 0.0071540914954082765]
Printing some Q and Qe and total Qs values:  [[0.703]
 [0.703]
 [0.703]
 [0.703]
 [0.703]
 [0.703]
 [0.703]] [[-0.107]
 [-0.107]
 [-0.107]
 [-0.107]
 [-0.107]
 [-0.107]
 [-0.107]] [[0.94]
 [0.94]
 [0.94]
 [0.94]
 [0.94]
 [0.94]
 [0.94]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06137926693662705, 0.9303477876032007, 0.0011188539647638712, 0.0071540914954082765]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06137926693662705, 0.9303477876032007, 0.0011188539647638712, 0.0071540914954082765]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.723]
 [0.719]
 [0.736]
 [0.755]
 [0.746]
 [0.731]
 [0.745]] [[3.568]
 [3.948]
 [3.316]
 [3.187]
 [3.15 ]
 [3.646]
 [4.194]] [[0.855]
 [1.101]
 [0.715]
 [0.666]
 [0.623]
 [0.924]
 [1.317]]
Printing some Q and Qe and total Qs values:  [[0.534]
 [0.524]
 [0.574]
 [0.606]
 [0.586]
 [0.57 ]
 [0.564]] [[4.275]
 [4.387]
 [3.77 ]
 [3.157]
 [3.314]
 [3.705]
 [4.155]] [[1.116]
 [1.171]
 [0.859]
 [0.516]
 [0.581]
 [0.809]
 [1.096]]
siam score:  -0.68839836
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.06137926693662705, 0.9303477876032007, 0.0011188539647638712, 0.0071540914954082765]
actor:  1 policy actor:  1  step number:  40 total reward:  0.7049999999999998  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05846738933833314, 0.9335625513705851, 0.0011129303137926536, 0.006857128977288987]
Printing some Q and Qe and total Qs values:  [[0.783]
 [0.94 ]
 [0.664]
 [0.783]
 [0.783]
 [0.783]
 [0.766]] [[1.313]
 [1.314]
 [0.084]
 [1.313]
 [1.313]
 [1.313]
 [0.871]] [[1.616]
 [1.89 ]
 [0.694]
 [1.616]
 [1.616]
 [1.616]
 [1.33 ]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.663]
 [0.728]
 [0.65 ]
 [0.674]
 [0.612]
 [0.696]
 [0.629]] [[2.671]
 [3.225]
 [3.053]
 [2.104]
 [2.115]
 [3.168]
 [3.063]] [[0.769]
 [1.27 ]
 [0.999]
 [0.414]
 [0.298]
 [1.167]
 [0.963]]
Printing some Q and Qe and total Qs values:  [[0.522]
 [0.525]
 [0.525]
 [0.573]
 [0.601]
 [0.564]
 [0.601]] [[3.5  ]
 [4.19 ]
 [4.405]
 [2.674]
 [3.546]
 [4.749]
 [3.546]] [[0.838]
 [1.304]
 [1.448]
 [0.39 ]
 [1.027]
 [1.753]
 [1.027]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05846738933833314, 0.9335625513705851, 0.0011129303137926536, 0.006857128977288987]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05846738933833314, 0.9335625513705851, 0.0011129303137926536, 0.006857128977288987]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05846738933833314, 0.9335625513705851, 0.0011129303137926536, 0.006857128977288987]
in main func line 156:  2186
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05846738933833314, 0.9335625513705851, 0.0011129303137926536, 0.006857128977288987]
Printing some Q and Qe and total Qs values:  [[0.668]
 [0.639]
 [0.668]
 [0.668]
 [0.61 ]
 [0.611]
 [0.668]] [[ 0.32 ]
 [ 1.573]
 [ 0.32 ]
 [ 0.32 ]
 [-0.008]
 [-0.084]
 [ 0.32 ]] [[0.511]
 [1.113]
 [0.511]
 [0.511]
 [0.251]
 [0.212]
 [0.511]]
Printing some Q and Qe and total Qs values:  [[0.508]
 [0.509]
 [0.508]
 [0.508]
 [0.508]
 [0.508]
 [0.49 ]] [[2.386]
 [3.09 ]
 [2.386]
 [2.386]
 [2.386]
 [2.386]
 [2.136]] [[1.028]
 [1.39 ]
 [1.028]
 [1.028]
 [1.028]
 [1.028]
 [0.873]]
siam score:  -0.6815605
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
using another actor
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05846738933833314, 0.9335625513705851, 0.0011129303137926536, 0.006857128977288987]
using explorer policy with actor:  0
first move QE:  0.5851395864216442
Printing some Q and Qe and total Qs values:  [[0.772]
 [0.813]
 [0.765]
 [0.822]
 [0.781]
 [0.711]
 [0.611]] [[2.724]
 [2.282]
 [2.966]
 [2.411]
 [2.202]
 [2.057]
 [4.15 ]] [[0.846]
 [0.658]
 [0.977]
 [0.751]
 [0.555]
 [0.345]
 [1.403]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05846738933833314, 0.9335625513705851, 0.0011129303137926536, 0.006857128977288987]
from probs:  [0.05846738933833314, 0.9335625513705851, 0.0011129303137926536, 0.006857128977288987]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.468]
 [0.496]
 [0.468]
 [0.468]
 [0.468]
 [0.468]
 [0.477]] [[1.307]
 [1.852]
 [1.307]
 [1.307]
 [1.307]
 [1.307]
 [1.164]] [[0.468]
 [0.496]
 [0.468]
 [0.468]
 [0.468]
 [0.468]
 [0.477]]
actor:  1 policy actor:  1  step number:  56 total reward:  0.5249999999999997  reward:  1.0 rdn_beta:  0.333
using explorer policy with actor:  1
using another actor
Printing some Q and Qe and total Qs values:  [[0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]
 [0.733]] [[4.597]
 [4.597]
 [4.597]
 [4.597]
 [4.597]
 [4.597]
 [4.597]] [[1.867]
 [1.867]
 [1.867]
 [1.867]
 [1.867]
 [1.867]
 [1.867]]
using another actor
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
Printing some Q and Qe and total Qs values:  [[0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.901]
 [0.843]] [[4.376]
 [4.376]
 [4.376]
 [4.376]
 [4.376]
 [4.376]
 [4.079]] [[1.769]
 [1.769]
 [1.769]
 [1.769]
 [1.769]
 [1.769]
 [1.558]]
Printing some Q and Qe and total Qs values:  [[0.556]
 [0.555]
 [0.55 ]
 [0.551]
 [0.552]
 [0.553]
 [0.537]] [[3.868]
 [4.038]
 [3.725]
 [3.273]
 [3.479]
 [3.631]
 [2.609]] [[0.556]
 [0.555]
 [0.55 ]
 [0.551]
 [0.552]
 [0.553]
 [0.537]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
first move QE:  0.5854562572942598
start point for exploration sampling:  10768
siam score:  -0.67362577
from probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810488, 0.9362173589817957, 0.0011086268781878095, 0.006641390561911664]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
Printing some Q and Qe and total Qs values:  [[0.346]
 [0.388]
 [0.338]
 [0.335]
 [0.329]
 [0.319]
 [0.324]] [[0.412]
 [3.044]
 [0.51 ]
 [0.482]
 [0.658]
 [0.654]
 [0.309]] [[ 0.068]
 [ 1.605]
 [ 0.108]
 [ 0.088]
 [ 0.177]
 [ 0.157]
 [-0.027]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
Printing some Q and Qe and total Qs values:  [[0.464]
 [0.485]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]] [[-0.544]
 [-0.142]
 [-0.544]
 [-0.544]
 [-0.544]
 [-0.544]
 [-0.544]] [[0.464]
 [0.485]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]]
Printing some Q and Qe and total Qs values:  [[0.253]
 [0.263]
 [0.263]
 [0.263]
 [0.263]
 [0.263]
 [0.276]] [[-0.413]
 [-0.029]
 [-0.029]
 [-0.029]
 [-0.029]
 [-0.029]
 [-0.469]] [[0.253]
 [0.263]
 [0.263]
 [0.263]
 [0.263]
 [0.263]
 [0.276]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
first move QE:  0.5858233986131902
from probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
start point for exploration sampling:  10768
from probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810489, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810489, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
using another actor
Printing some Q and Qe and total Qs values:  [[0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.575]
 [0.596]
 [0.548]] [[2.183]
 [2.183]
 [2.183]
 [2.183]
 [2.183]
 [2.029]
 [1.983]] [[ 0.006]
 [ 0.006]
 [ 0.006]
 [ 0.006]
 [ 0.006]
 [-0.055]
 [-0.181]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
using another actor
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810489, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
Printing some Q and Qe and total Qs values:  [[0.131]
 [0.131]
 [0.131]
 [0.131]
 [0.131]
 [0.131]
 [0.131]] [[-0.295]
 [-0.295]
 [-0.295]
 [-0.295]
 [-0.295]
 [-0.295]
 [-0.295]] [[0.131]
 [0.131]
 [0.131]
 [0.131]
 [0.131]
 [0.131]
 [0.131]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
Printing some Q and Qe and total Qs values:  [[0.496]
 [0.563]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.532]] [[1.403]
 [1.285]
 [1.403]
 [1.403]
 [1.403]
 [1.403]
 [1.092]] [[0.496]
 [0.563]
 [0.496]
 [0.496]
 [0.496]
 [0.496]
 [0.532]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
probs:  [0.05603262357810487, 0.9362173589817957, 0.0011086268781878093, 0.0066413905619116635]
Printing some Q and Qe and total Qs values:  [[0.402]
 [0.402]
 [0.402]
 [0.432]
 [0.402]
 [0.402]
 [0.421]] [[4.756]
 [4.756]
 [4.756]
 [3.993]
 [4.756]
 [4.756]
 [4.147]] [[0.402]
 [0.402]
 [0.402]
 [0.432]
 [0.402]
 [0.402]
 [0.421]]
maxi score, test score, baseline:  -0.99426 -1.0 -0.99426
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.05608656968544599, 0.9361178912224097, 0.0011086341570733817, 0.006686904935070774]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.05608656968544599, 0.9361178912224097, 0.0011086341570733817, 0.006686904935070774]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.05608656968544598, 0.9361178912224097, 0.0011086341570733815, 0.006686904935070773]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
Printing some Q and Qe and total Qs values:  [[0.641]
 [0.734]
 [0.641]
 [0.641]
 [0.641]
 [0.848]
 [1.015]] [[2.525]
 [2.548]
 [2.525]
 [2.525]
 [2.525]
 [3.411]
 [1.826]] [[0.97 ]
 [1.172]
 [0.97 ]
 [0.97 ]
 [0.97 ]
 [1.974]
 [1.252]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.05608656968544598, 0.9361178912224097, 0.0011086341570733815, 0.006686904935070773]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
first move QE:  0.5843942731650368
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.05608656968544599, 0.9361178912224097, 0.0011086341570733817, 0.006686904935070774]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.05608656968544599, 0.9361178912224097, 0.0011086341570733817, 0.006686904935070774]
actor:  1 policy actor:  1  step number:  83 total reward:  0.5299999999999997  reward:  1.0 rdn_beta:  0.333
using another actor
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.05410259617280641, 0.938310866166703, 0.0011045784424011077, 0.006481959218089519]
actor:  1 policy actor:  1  step number:  58 total reward:  0.4149999999999996  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.052516135786722935, 0.9400644520158234, 0.0011013353392932137, 0.006318076858160395]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.052516135786722935, 0.9400644520158234, 0.0011013353392932137, 0.006318076858160395]
Printing some Q and Qe and total Qs values:  [[0.609]
 [0.603]
 [0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.585]] [[2.466]
 [3.086]
 [2.466]
 [2.466]
 [2.466]
 [2.466]
 [3.278]] [[1.174]
 [1.483]
 [1.174]
 [1.174]
 [1.174]
 [1.174]
 [1.553]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.052516135786722935, 0.9400644520158234, 0.0011013353392932137, 0.006318076858160395]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.052516135786722935, 0.9400644520158234, 0.0011013353392932137, 0.006318076858160395]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.052516135786722935, 0.9400644520158234, 0.0011013353392932137, 0.006318076858160395]
actor:  1 policy actor:  1  step number:  89 total reward:  0.25999999999999945  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.0513246174954908, 0.9413814906464766, 0.0010988995919481777, 0.006194992266084383]
siam score:  -0.6786336
siam score:  -0.67726195
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.0513246174954908, 0.9413814906464766, 0.0010988995919481777, 0.006194992266084383]
Printing some Q and Qe and total Qs values:  [[0.428]
 [0.552]
 [0.428]
 [0.428]
 [0.428]
 [0.428]
 [0.428]] [[0.096]
 [0.478]
 [0.096]
 [0.096]
 [0.096]
 [0.096]
 [0.096]] [[0.271]
 [0.635]
 [0.271]
 [0.271]
 [0.271]
 [0.271]
 [0.271]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.0513246174954908, 0.9413814906464766, 0.0010988995919481777, 0.006194992266084383]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.0513246174954908, 0.9413814906464766, 0.0010988995919481777, 0.006194992266084383]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.0513246174954908, 0.9413814906464766, 0.0010988995919481777, 0.006194992266084383]
first move QE:  0.5834265239110739
actor:  1 policy actor:  1  step number:  72 total reward:  0.3949999999999997  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
Printing some Q and Qe and total Qs values:  [[0.4  ]
 [0.4  ]
 [0.4  ]
 [0.4  ]
 [0.4  ]
 [0.414]
 [0.4  ]] [[2.461]
 [2.461]
 [2.461]
 [2.461]
 [2.461]
 [1.66 ]
 [2.461]] [[-0.08 ]
 [-0.08 ]
 [-0.08 ]
 [-0.08 ]
 [-0.08 ]
 [-0.584]
 [-0.08 ]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403864, 0.9429157376693028, 0.0010960621367471681, 0.006051608340546285]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403864, 0.9429157376693028, 0.0010960621367471681, 0.006051608340546285]
Printing some Q and Qe and total Qs values:  [[0.854]
 [0.836]
 [0.943]
 [0.854]
 [0.854]
 [0.975]
 [0.974]] [[2.026]
 [1.817]
 [1.923]
 [2.026]
 [2.026]
 [1.947]
 [2.053]] [[1.326]
 [1.151]
 [1.435]
 [1.326]
 [1.326]
 [1.516]
 [1.584]]
Printing some Q and Qe and total Qs values:  [[0.375]
 [0.36 ]
 [0.375]
 [0.375]
 [0.375]
 [0.375]
 [0.366]] [[3.423]
 [3.287]
 [3.423]
 [3.423]
 [3.423]
 [3.423]
 [3.618]] [[0.39 ]
 [0.268]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.39 ]
 [0.501]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403864, 0.9429157376693028, 0.0010960621367471681, 0.006051608340546285]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403864, 0.9429157376693028, 0.0010960621367471681, 0.006051608340546285]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403885, 0.9429157376693026, 0.0010960621367471681, 0.006051608340546281]
Printing some Q and Qe and total Qs values:  [[0.866]
 [0.611]
 [0.609]
 [0.609]
 [0.609]
 [0.609]
 [0.613]] [[ 0.466]
 [ 0.384]
 [-0.037]
 [-0.037]
 [-0.037]
 [-0.037]
 [ 0.043]] [[2.47 ]
 [1.906]
 [1.621]
 [1.621]
 [1.621]
 [1.621]
 [1.684]]
2222 1974
siam score:  -0.67422104
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403885, 0.9429157376693026, 0.0010960621367471681, 0.006051608340546281]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403885, 0.9429157376693026, 0.0010960621367471681, 0.006051608340546281]
from probs:  [0.049936591853403885, 0.9429157376693026, 0.0010960621367471681, 0.006051608340546281]
Printing some Q and Qe and total Qs values:  [[0.546]
 [0.543]
 [0.538]
 [0.546]
 [0.546]
 [0.555]
 [0.551]] [[2.685]
 [3.09 ]
 [2.545]
 [2.685]
 [2.685]
 [1.818]
 [2.89 ]] [[0.595]
 [0.858]
 [0.485]
 [0.595]
 [0.595]
 [0.035]
 [0.742]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403885, 0.9429157376693026, 0.0010960621367471681, 0.006051608340546281]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403885, 0.9429157376693026, 0.0010960621367471681, 0.006051608340546281]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403885, 0.9429157376693026, 0.0010960621367471681, 0.006051608340546281]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403885, 0.9429157376693026, 0.0010960621367471681, 0.006051608340546281]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403864, 0.9429157376693028, 0.0010960621367471681, 0.006051608340546285]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403864, 0.9429157376693028, 0.0010960621367471681, 0.006051608340546285]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403864, 0.9429157376693028, 0.0010960621367471681, 0.006051608340546285]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049936591853403864, 0.9429157376693028, 0.0010960621367471681, 0.006051608340546285]
Printing some Q and Qe and total Qs values:  [[0.464]
 [0.5  ]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]] [[1.971]
 [3.164]
 [1.971]
 [1.971]
 [1.971]
 [1.971]
 [1.971]] [[0.464]
 [0.5  ]
 [0.464]
 [0.464]
 [0.464]
 [0.464]
 [0.464]]
Printing some Q and Qe and total Qs values:  [[0.499]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.65 ]
 [0.648]
 [0.439]] [[1.165]
 [1.896]
 [1.896]
 [1.896]
 [1.896]
 [1.123]
 [2.052]] [[1.637]
 [2.389]
 [2.389]
 [2.389]
 [2.389]
 [1.895]
 [2.086]]
actor:  1 policy actor:  1  step number:  50 total reward:  0.5349999999999997  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04835455311197415, 0.9446644360761886, 0.0010928280725346952, 0.005888182739302716]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04835455311197415, 0.9446644360761886, 0.0010928280725346952, 0.005888182739302716]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
siam score:  -0.6687203
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049831845433832955, 0.94303151858682, 0.0010958480101028278, 0.006040787969244241]
Printing some Q and Qe and total Qs values:  [[0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.485]
 [0.608]] [[1.457]
 [1.457]
 [1.457]
 [1.457]
 [1.457]
 [1.457]
 [1.915]] [[0.87 ]
 [0.87 ]
 [0.87 ]
 [0.87 ]
 [0.87 ]
 [0.87 ]
 [1.421]]
Printing some Q and Qe and total Qs values:  [[0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.484]
 [0.747]] [[1.784]
 [1.784]
 [1.784]
 [1.784]
 [1.784]
 [1.784]
 [2.716]] [[0.958]
 [0.958]
 [0.958]
 [0.958]
 [0.958]
 [0.958]
 [1.982]]
using another actor
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04983184543383295, 0.94303151858682, 0.0010958480101028278, 0.0060407879692442375]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04983184543383295, 0.94303151858682, 0.0010958480101028278, 0.0060407879692442375]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04983184543383295, 0.94303151858682, 0.0010958480101028278, 0.0060407879692442375]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04983184543383295, 0.94303151858682, 0.0010958480101028278, 0.0060407879692442375]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04983184543383295, 0.94303151858682, 0.0010958480101028278, 0.0060407879692442375]
from probs:  [0.04983184543383295, 0.94303151858682, 0.0010958480101028278, 0.0060407879692442375]
line 256 mcts: sample exp_bonus 3.2147716518693477
Printing some Q and Qe and total Qs values:  [[0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]] [[-0.349]
 [-0.349]
 [-0.349]
 [-0.349]
 [-0.349]
 [-0.349]
 [-0.349]] [[0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]
 [0.442]]
using another actor
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049831845433832955, 0.94303151858682, 0.0010958480101028278, 0.006040787969244241]
siam score:  -0.6858235
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049831845433832955, 0.94303151858682, 0.0010958480101028278, 0.006040787969244241]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049831845433832955, 0.94303151858682, 0.0010958480101028278, 0.006040787969244241]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.049831845433832955, 0.94303151858682, 0.0010958480101028278, 0.006040787969244241]
actor:  1 policy actor:  1  step number:  51 total reward:  0.6499999999999998  reward:  1.0 rdn_beta:  0.333
using explorer policy with actor:  1
siam score:  -0.68235016
Printing some Q and Qe and total Qs values:  [[0.957]
 [0.957]
 [0.957]
 [0.957]
 [0.957]
 [0.957]
 [0.957]] [[0.579]
 [0.579]
 [0.572]
 [0.579]
 [0.579]
 [0.579]
 [0.579]] [[0.957]
 [0.957]
 [0.957]
 [0.957]
 [0.957]
 [0.957]
 [0.957]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
2239 1985
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
Printing some Q and Qe and total Qs values:  [[0.581]
 [0.635]
 [0.581]
 [0.581]
 [0.581]
 [0.581]
 [0.621]] [[2.94 ]
 [4.323]
 [2.94 ]
 [2.94 ]
 [2.94 ]
 [2.94 ]
 [3.906]] [[1.213]
 [2.183]
 [1.213]
 [1.213]
 [1.213]
 [1.213]
 [1.894]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: -1.1586674440611282
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
Printing some Q and Qe and total Qs values:  [[0.591]
 [0.801]
 [0.591]
 [0.591]
 [0.591]
 [0.591]
 [0.591]] [[0.236]
 [1.06 ]
 [0.236]
 [0.236]
 [0.236]
 [0.236]
 [0.236]] [[0.511]
 [1.222]
 [0.511]
 [0.511]
 [0.511]
 [0.511]
 [0.511]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
Printing some Q and Qe and total Qs values:  [[0.541]
 [0.541]
 [0.736]
 [0.541]
 [0.541]
 [0.553]
 [0.541]] [[0.948]
 [0.948]
 [4.054]
 [0.948]
 [0.948]
 [1.449]
 [0.948]] [[0.596]
 [0.596]
 [2.318]
 [0.596]
 [0.596]
 [0.846]
 [0.596]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
first move QE:  0.5769048162122841
Printing some Q and Qe and total Qs values:  [[0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.468]] [[0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [0.811]
 [1.039]] [[0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.393]
 [0.468]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
from probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
using explorer policy with actor:  1
siam score:  -0.6843861
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
Printing some Q and Qe and total Qs values:  [[0.398]
 [0.072]
 [0.322]
 [0.358]
 [0.378]
 [0.338]
 [0.315]] [[1.343]
 [2.452]
 [1.362]
 [1.508]
 [1.496]
 [1.488]
 [1.645]] [[ 0.126]
 [ 0.204]
 [-0.002]
 [ 0.151]
 [ 0.181]
 [ 0.102]
 [ 0.157]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04802018360529409, 0.9450340296950617, 0.00109214454157747, 0.0058536421580668045]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
Printing some Q and Qe and total Qs values:  [[0.457]
 [0.462]
 [0.453]
 [0.461]
 [0.449]
 [0.445]
 [0.452]] [[-1.818]
 [-0.621]
 [-2.053]
 [-2.313]
 [-2.317]
 [-2.161]
 [-1.738]] [[0.518]
 [0.927]
 [0.43 ]
 [0.361]
 [0.335]
 [0.379]
 [0.533]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.047762218425882554, 0.9452906482913994, 0.0010921706722919183, 0.005854962610426148]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.047762218425882554, 0.9452906482913994, 0.0010921706722919183, 0.005854962610426148]
Printing some Q and Qe and total Qs values:  [[0.586]
 [0.682]
 [0.586]
 [0.586]
 [0.586]
 [0.586]
 [0.586]] [[1.742]
 [1.787]
 [1.742]
 [1.742]
 [1.742]
 [1.742]
 [1.742]] [[0.713]
 [0.934]
 [0.713]
 [0.713]
 [0.713]
 [0.713]
 [0.713]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.047762218425882554, 0.9452906482913994, 0.0010921706722919183, 0.005854962610426148]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.047762218425882554, 0.9452906482913994, 0.0010921706722919183, 0.005854962610426148]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.047762218425882554, 0.9452906482913994, 0.0010921706722919183, 0.005854962610426148]
Printing some Q and Qe and total Qs values:  [[0.633]
 [0.65 ]
 [0.633]
 [0.633]
 [0.633]
 [0.633]
 [0.615]] [[-0.59 ]
 [-0.795]
 [-0.59 ]
 [-0.59 ]
 [-0.59 ]
 [-0.59 ]
 [-0.803]] [[1.102]
 [1.   ]
 [1.102]
 [1.102]
 [1.102]
 [1.102]
 [0.924]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
actor:  1 policy actor:  1  step number:  112 total reward:  0.2149999999999994  reward:  1.0 rdn_beta:  0.333
first move QE:  0.5746388661256272
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.262]
 [0.32 ]
 [0.31 ]
 [0.287]
 [0.262]
 [0.262]
 [0.246]] [[3.97 ]
 [4.041]
 [3.964]
 [3.648]
 [3.97 ]
 [3.97 ]
 [3.213]] [[1.416]
 [1.533]
 [1.481]
 [1.298]
 [1.416]
 [1.416]
 [1.034]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
siam score:  -0.692013
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
Printing some Q and Qe and total Qs values:  [[0.509]
 [0.509]
 [0.509]
 [0.509]
 [0.509]
 [0.509]
 [0.491]] [[2.186]
 [2.186]
 [2.186]
 [2.186]
 [2.186]
 [2.186]
 [2.084]] [[1.329]
 [1.329]
 [1.329]
 [1.329]
 [1.329]
 [1.329]
 [1.227]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.641]
 [0.634]
 [0.641]
 [0.641]
 [0.641]
 [0.641]
 [0.648]] [[4.005]
 [4.57 ]
 [4.005]
 [4.005]
 [4.005]
 [4.005]
 [4.327]] [[1.487]
 [1.783]
 [1.487]
 [1.487]
 [1.487]
 [1.487]
 [1.673]]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
siam score:  -0.68240005
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.784]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]] [[2.072]
 [1.661]
 [2.072]
 [2.072]
 [2.072]
 [2.072]
 [2.072]] [[1.312]
 [1.704]
 [1.312]
 [1.312]
 [1.312]
 [1.312]
 [1.312]]
unit test line 137 mCTS: want to be seeing expV values centred around 0, max(abs)=5, std hopefully 1: 3.9103209516139996
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
Printing some Q and Qe and total Qs values:  [[0.576]
 [0.596]
 [0.576]
 [0.576]
 [0.576]
 [0.576]
 [0.588]] [[0.477]
 [1.208]
 [0.477]
 [0.477]
 [0.477]
 [0.477]
 [0.842]] [[1.641]
 [2.128]
 [1.641]
 [1.641]
 [1.641]
 [1.641]
 [1.888]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
Printing some Q and Qe and total Qs values:  [[0.77 ]
 [1.055]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.77 ]
 [0.876]] [[4.472]
 [5.291]
 [4.472]
 [4.472]
 [4.472]
 [4.472]
 [3.499]] [[1.654]
 [2.627]
 [1.654]
 [1.654]
 [1.654]
 [1.654]
 [1.272]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
Printing some Q and Qe and total Qs values:  [[0.636]
 [0.636]
 [0.636]
 [0.636]
 [0.636]
 [0.636]
 [0.636]] [[-1.217]
 [-1.217]
 [-1.217]
 [-1.217]
 [-1.217]
 [-1.217]
 [-1.217]] [[0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]
 [0.953]]
Printing some Q and Qe and total Qs values:  [[0.692]
 [0.68 ]
 [0.696]
 [0.692]
 [0.692]
 [0.748]
 [0.661]] [[3.935]
 [3.822]
 [3.854]
 [3.935]
 [3.935]
 [3.475]
 [3.651]] [[1.533]
 [1.433]
 [1.486]
 [1.533]
 [1.533]
 [1.338]
 [1.281]]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
Printing some Q and Qe and total Qs values:  [[1.181]
 [1.176]
 [1.194]
 [1.181]
 [1.181]
 [1.285]
 [1.184]] [[1.14 ]
 [1.026]
 [1.332]
 [1.14 ]
 [1.14 ]
 [1.267]
 [1.084]] [[2.254]
 [2.172]
 [2.402]
 [2.254]
 [2.254]
 [2.536]
 [2.224]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04684097230441965, 0.9463095048176547, 0.0010902765228224599, 0.0057592463551033365]
actor:  1 policy actor:  1  step number:  68 total reward:  0.37499999999999956  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04571219806997724, 0.9475578780467371, 0.0010879556803597393, 0.005641968202926019]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04571219806997724, 0.9475578780467371, 0.0010879556803597393, 0.005641968202926019]
Printing some Q and Qe and total Qs values:  [[0.386]
 [0.419]
 [0.389]
 [0.398]
 [0.408]
 [0.412]
 [0.387]] [[1.749]
 [2.186]
 [1.506]
 [1.389]
 [1.541]
 [1.81 ]
 [2.002]] [[ 0.054]
 [ 0.267]
 [-0.02 ]
 [-0.042]
 [ 0.03 ]
 [ 0.127]
 [ 0.143]]
first move QE:  0.5725006905603436
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04571219806997724, 0.9475578780467371, 0.0010879556803597393, 0.005641968202926019]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04571219806997724, 0.9475578780467371, 0.0010879556803597393, 0.005641968202926019]
actor:  1 policy actor:  1  step number:  61 total reward:  0.5899999999999997  reward:  1.0 rdn_beta:  0.333
from probs:  [0.044286113022861444, 0.9491350635820655, 0.0010850235451002627, 0.005493799849972718]
first move QE:  0.5717661926814686
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.044048160259149316, 0.9493718707489286, 0.0010850457756367356, 0.005494923216285304]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.044048160259149316, 0.9493718707489286, 0.0010850457756367356, 0.005494923216285304]
rdn beta is 0 so we're just using the maxi policy
Printing some Q and Qe and total Qs values:  [[0.707]
 [0.731]
 [0.825]
 [0.705]
 [0.713]
 [0.718]
 [0.71 ]] [[1.574]
 [1.865]
 [3.155]
 [1.439]
 [1.951]
 [1.733]
 [1.726]] [[0.408]
 [0.648]
 [1.697]
 [0.313]
 [0.67 ]
 [0.535]
 [0.514]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
Printing some Q and Qe and total Qs values:  [[0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]] [[0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]
 [0.073]] [[0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]
 [0.767]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.044048160259149316, 0.9493718707489286, 0.0010850457756367356, 0.005494923216285304]
Printing some Q and Qe and total Qs values:  [[0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.451]
 [0.684]] [[1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [1.023]
 [2.442]] [[0.546]
 [0.546]
 [0.546]
 [0.546]
 [0.546]
 [0.546]
 [1.448]]
line 256 mcts: sample exp_bonus 2.8233706320278427
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.044048160259149316, 0.9493718707489286, 0.0010850457756367356, 0.005494923216285304]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.044048160259149316, 0.9493718707489286, 0.0010850457756367356, 0.005494923216285304]
Printing some Q and Qe and total Qs values:  [[0.751]
 [0.722]
 [0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.712]] [[3.343]
 [3.757]
 [3.844]
 [3.844]
 [3.844]
 [3.844]
 [3.679]] [[1.341]
 [1.559]
 [1.605]
 [1.605]
 [1.605]
 [1.605]
 [1.488]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.669]
 [0.677]
 [0.614]
 [0.633]
 [0.592]
 [0.566]
 [0.648]] [[2.838]
 [4.092]
 [3.161]
 [3.061]
 [2.217]
 [2.43 ]
 [4.177]] [[ 0.495]
 [ 1.347]
 [ 0.601]
 [ 0.571]
 [-0.072]
 [ 0.017]
 [ 1.347]]
Printing some Q and Qe and total Qs values:  [[0.712]
 [0.652]
 [0.712]
 [0.712]
 [0.712]
 [0.712]
 [0.639]] [[4.295]
 [4.085]
 [4.295]
 [4.295]
 [4.295]
 [4.295]
 [4.221]] [[1.553]
 [1.293]
 [1.553]
 [1.553]
 [1.553]
 [1.553]
 [1.358]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
first move QE:  0.5684454784082024
Printing some Q and Qe and total Qs values:  [[1.233]
 [1.24 ]
 [1.232]
 [1.249]
 [1.233]
 [1.233]
 [1.224]] [[0.512]
 [0.432]
 [0.37 ]
 [0.129]
 [0.512]
 [0.512]
 [0.574]] [[2.983]
 [2.972]
 [2.94 ]
 [2.898]
 [2.983]
 [2.983]
 [2.985]]
Printing some Q and Qe and total Qs values:  [[0.808]
 [0.802]
 [0.807]
 [0.791]
 [0.788]
 [0.837]
 [0.806]] [[3.234]
 [3.626]
 [3.879]
 [3.887]
 [2.933]
 [3.973]
 [3.974]] [[1.362]
 [1.581]
 [1.739]
 [1.716]
 [1.151]
 [1.848]
 [1.792]]
Printing some Q and Qe and total Qs values:  [[0.822]
 [0.974]
 [0.822]
 [0.822]
 [0.822]
 [0.822]
 [0.883]] [[0.916]
 [1.844]
 [0.916]
 [0.916]
 [0.916]
 [0.916]
 [1.626]] [[1.768]
 [2.24 ]
 [1.768]
 [1.768]
 [1.768]
 [1.768]
 [2.073]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.043811906395027, 0.9496069871953632, 0.001085067847454946, 0.005496038562154932]
Printing some Q and Qe and total Qs values:  [[0.715]
 [0.765]
 [0.715]
 [0.715]
 [0.715]
 [0.715]
 [0.715]] [[-0.69]
 [ 2.05]
 [-0.69]
 [-0.69]
 [-0.69]
 [-0.69]
 [-0.69]] [[0.596]
 [1.499]
 [0.596]
 [0.596]
 [0.596]
 [0.596]
 [0.596]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04381190639502698, 0.9496069871953632, 0.0010850678474549457, 0.005496038562154928]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04381190639502698, 0.9496069871953632, 0.0010850678474549457, 0.005496038562154928]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04381190639502698, 0.9496069871953632, 0.0010850678474549457, 0.005496038562154928]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.043811906395026995, 0.9496069871953632, 0.001085067847454946, 0.005496038562154932]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.043811906395026995, 0.9496069871953632, 0.001085067847454946, 0.005496038562154932]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
2275 2027
using another actor
from probs:  [0.043811906395026995, 0.9496069871953632, 0.001085067847454946, 0.005496038562154932]
from probs:  [0.043811906395026995, 0.9496069871953632, 0.001085067847454946, 0.005496038562154932]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04381190639502698, 0.9496069871953632, 0.0010850678474549457, 0.005496038562154928]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04381190639502698, 0.9496069871953632, 0.0010850678474549457, 0.005496038562154928]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04381190639502698, 0.9496069871953632, 0.0010850678474549457, 0.005496038562154928]
siam score:  -0.6666278
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04381190639502698, 0.9496069871953632, 0.0010850678474549457, 0.005496038562154928]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04381190639502698, 0.9496069871953632, 0.0010850678474549457, 0.005496038562154928]
using explorer policy with actor:  0
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04381190639502698, 0.9496069871953632, 0.0010850678474549457, 0.005496038562154928]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04381190639502698, 0.9496069871953632, 0.0010850678474549457, 0.005496038562154928]
actor:  1 policy actor:  1  step number:  47 total reward:  0.5999999999999998  reward:  1.0 rdn_beta:  0.333
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04247177622780397, 0.9510907546234469, 0.001082280537618126, 0.005355188611131216]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04247177622780397, 0.9510907546234469, 0.001082280537618126, 0.005355188611131216]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04247177622780397, 0.9510907546234469, 0.001082280537618126, 0.005355188611131216]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04247177622780397, 0.9510907546234469, 0.001082280537618126, 0.005355188611131216]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04224422751444809, 0.9513172436081941, 0.0010823011018641813, 0.005356227775493749]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04224422751444809, 0.9513172436081941, 0.0010823011018641813, 0.005356227775493749]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04224422751444809, 0.9513172436081941, 0.0010823011018641813, 0.005356227775493749]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04224422751444809, 0.9513172436081941, 0.0010823011018641813, 0.005356227775493749]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04224422751444809, 0.9513172436081941, 0.0010823011018641813, 0.005356227775493749]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04224422751444809, 0.9513172436081941, 0.0010823011018641813, 0.005356227775493749]
Printing some Q and Qe and total Qs values:  [[0.663]
 [0.702]
 [0.583]
 [0.574]
 [0.528]
 [0.497]
 [0.686]] [[4.185]
 [4.169]
 [2.962]
 [3.3  ]
 [2.766]
 [2.454]
 [4.193]] [[ 1.307]
 [ 1.373]
 [ 0.367]
 [ 0.567]
 [ 0.134]
 [-0.126]
 [ 1.357]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04324925554772958, 0.9502038750198, 0.0010844034720512907, 0.005462465960419017]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04324925554772958, 0.9502038750198, 0.0010844034720512907, 0.005462465960419017]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04324925554772958, 0.9502038750198, 0.0010844034720512907, 0.005462465960419017]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04324925554772958, 0.9502038750198, 0.0010844034720512907, 0.005462465960419017]
start point for exploration sampling:  10768
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
in main func line 156:  2283
2284 2040
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04324925554772958, 0.9502038750198, 0.0010844034720512907, 0.005462465960419017]
actor:  1 policy actor:  1  step number:  78 total reward:  0.5149999999999997  reward:  1.0 rdn_beta:  0.333
in main func line 156:  2285
2285 2042
siam score:  -0.66643095
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04206853524640835, 0.9515118752462991, 0.0010819335795919651, 0.005337655927700603]
Printing some Q and Qe and total Qs values:  [[0.27 ]
 [0.27 ]
 [0.26 ]
 [0.27 ]
 [0.27 ]
 [0.258]
 [0.269]] [[3.331]
 [3.331]
 [2.909]
 [3.331]
 [3.331]
 [3.057]
 [2.841]] [[ 0.14 ]
 [ 0.14 ]
 [-0.16 ]
 [ 0.14 ]
 [ 0.14 ]
 [-0.066]
 [-0.188]]
actor:  1 policy actor:  1  step number:  55 total reward:  0.47999999999999965  reward:  1.0 rdn_beta:  0.333
using another actor
Printing some Q and Qe and total Qs values:  [[0.15 ]
 [0.16 ]
 [0.288]
 [0.269]
 [0.26 ]
 [0.268]
 [0.254]] [[2.266]
 [2.609]
 [2.186]
 [2.273]
 [2.314]
 [2.37 ]
 [2.422]] [[-0.559]
 [-0.309]
 [-0.336]
 [-0.315]
 [-0.306]
 [-0.254]
 [-0.245]]
Printing some Q and Qe and total Qs values:  [[0.127]
 [0.16 ]
 [0.226]
 [0.258]
 [0.27 ]
 [0.232]
 [0.223]] [[2.864]
 [2.649]
 [2.569]
 [1.975]
 [2.234]
 [2.596]
 [2.48 ]] [[0.437]
 [0.359]
 [0.439]
 [0.107]
 [0.303]
 [0.47 ]
 [0.375]]
from probs:  [0.041001773088292, 0.9526936328080818, 0.0010797020707348063, 0.005224892032891408]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041001773088292, 0.9526936328080818, 0.0010797020707348063, 0.005224892032891408]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041001773088292, 0.9526936328080818, 0.0010797020707348063, 0.005224892032891408]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041001773088292, 0.9526936328080818, 0.0010797020707348063, 0.005224892032891408]
siam score:  -0.67296547
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
actor:  1 policy actor:  1  step number:  89 total reward:  0.10999999999999932  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
actor:  1 policy actor:  1  step number:  57 total reward:  0.47999999999999965  reward:  1.0 rdn_beta:  0.333
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.040275993845146754, 0.9534976499943367, 0.0010781838477672049, 0.005148172312749441]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.49 ]
 [0.562]
 [0.633]
 [0.572]
 [0.523]
 [0.651]
 [0.506]] [[ 1.309]
 [ 1.286]
 [-0.461]
 [-0.205]
 [ 0.273]
 [-0.791]
 [ 1.086]] [[1.756]
 [1.871]
 [0.958]
 [1.   ]
 [1.198]
 [0.793]
 [1.652]]
using explorer policy with actor:  1
Printing some Q and Qe and total Qs values:  [[0.507]
 [0.514]
 [0.507]
 [0.507]
 [0.507]
 [0.507]
 [0.507]] [[0.678]
 [1.935]
 [0.678]
 [0.678]
 [0.678]
 [0.678]
 [0.678]] [[0.713]
 [1.337]
 [0.713]
 [0.713]
 [0.713]
 [0.713]
 [0.713]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04099550171792066, 0.9528024627391053, 0.00107968895195437, 0.005122346591019811]
siam score:  -0.68380827
Printing some Q and Qe and total Qs values:  [[0.661]
 [0.673]
 [0.673]
 [0.673]
 [0.673]
 [0.673]
 [0.673]] [[0.391]
 [0.388]
 [0.388]
 [0.388]
 [0.388]
 [0.388]
 [0.388]] [[0.661]
 [0.673]
 [0.673]
 [0.673]
 [0.673]
 [0.673]
 [0.673]]
siam score:  -0.6861442
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04099550171792066, 0.9528024627391053, 0.00107968895195437, 0.005122346591019811]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04099550171792066, 0.9528024627391053, 0.00107968895195437, 0.005122346591019811]
line 256 mcts: sample exp_bonus 3.0070588108732945
using explorer policy with actor:  1
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04099550171792066, 0.9528024627391053, 0.00107968895195437, 0.005122346591019811]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
using explorer policy with actor:  0
actor:  1 policy actor:  1  step number:  60 total reward:  0.47499999999999964  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04084119681681401, 0.9529730084539957, 0.0010793661688945262, 0.00510642856029581]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
2293 2060
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04084119681681401, 0.9529730084539957, 0.0010793661688945262, 0.00510642856029581]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04084119681681401, 0.9529730084539957, 0.0010793661688945262, 0.00510642856029581]
Printing some Q and Qe and total Qs values:  [[0.373]
 [0.375]
 [0.369]
 [0.369]
 [0.369]
 [0.361]
 [0.374]] [[3.634]
 [3.869]
 [3.435]
 [3.435]
 [3.435]
 [3.534]
 [3.778]] [[0.57 ]
 [0.73 ]
 [0.431]
 [0.431]
 [0.431]
 [0.48 ]
 [0.668]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04209989247461954, 0.9515818332596212, 0.0010819991742814254, 0.005236275091478043]
2295 2063
line 256 mcts: sample exp_bonus 1.59268937507073
Printing some Q and Qe and total Qs values:  [[0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]
 [0.498]] [[4.176]
 [4.176]
 [4.176]
 [4.176]
 [4.176]
 [4.176]
 [4.176]] [[1.106]
 [1.106]
 [1.106]
 [1.106]
 [1.106]
 [1.106]
 [1.106]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04209989247461954, 0.9515818332596212, 0.0010819991742814254, 0.005236275091478043]
line 256 mcts: sample exp_bonus 2.8568177514169917
Printing some Q and Qe and total Qs values:  [[0.664]
 [0.831]
 [0.502]
 [0.876]
 [0.793]
 [0.692]
 [0.558]] [[2.553]
 [2.379]
 [2.462]
 [2.756]
 [2.886]
 [2.821]
 [3.015]] [[1.28 ]
 [1.432]
 [1.011]
 [1.67 ]
 [1.616]
 [1.444]
 [1.347]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04209989247461954, 0.9515818332596212, 0.0010819991742814254, 0.005236275091478043]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04209989247461954, 0.9515818332596212, 0.0010819991742814254, 0.005236275091478043]
Printing some Q and Qe and total Qs values:  [[0.631]
 [0.832]
 [0.637]
 [0.793]
 [0.793]
 [0.623]
 [0.804]] [[2.754]
 [3.613]
 [2.185]
 [3.457]
 [3.457]
 [1.737]
 [3.657]] [[0.678]
 [1.57 ]
 [0.343]
 [1.403]
 [1.403]
 [0.045]
 [1.546]]
actor:  1 policy actor:  1  step number:  51 total reward:  0.5199999999999997  reward:  1.0 rdn_beta:  0.333
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04097447918649161, 0.9528256979223408, 0.0010796449759239803, 0.00512017791524358]
first move QE:  0.5593329173179215
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04097447918649161, 0.9528256979223408, 0.0010796449759239803, 0.00512017791524358]
using explorer policy with actor:  1
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
Printing some Q and Qe and total Qs values:  [[0.458]
 [0.458]
 [0.458]
 [0.458]
 [0.458]
 [0.458]
 [0.494]] [[3.916]
 [3.916]
 [3.916]
 [3.916]
 [3.916]
 [3.916]
 [4.254]] [[1.325]
 [1.325]
 [1.325]
 [1.325]
 [1.325]
 [1.325]
 [1.485]]
Printing some Q and Qe and total Qs values:  [[0.368]
 [0.534]
 [0.368]
 [0.368]
 [0.368]
 [0.368]
 [0.368]] [[-3.143]
 [-1.995]
 [-3.143]
 [-3.143]
 [-3.143]
 [-3.143]
 [-2.773]] [[0.043]
 [0.757]
 [0.043]
 [0.043]
 [0.043]
 [0.043]
 [0.165]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04097447918649161, 0.9528256979223408, 0.0010796449759239803, 0.00512017791524358]
Printing some Q and Qe and total Qs values:  [[-0.035]
 [ 0.186]
 [-0.035]
 [-0.035]
 [-0.035]
 [-0.035]
 [-0.035]] [[-2.592]
 [-0.753]
 [-2.592]
 [-2.592]
 [-2.592]
 [-2.592]
 [-2.592]] [[-0.746]
 [ 0.294]
 [-0.746]
 [-0.746]
 [-0.746]
 [-0.746]
 [-0.746]]
Printing some Q and Qe and total Qs values:  [[0.614]
 [0.622]
 [0.614]
 [0.614]
 [0.62 ]
 [0.62 ]
 [0.621]] [[3.342]
 [3.954]
 [3.342]
 [3.342]
 [3.631]
 [4.181]
 [4.135]] [[0.614]
 [0.622]
 [0.614]
 [0.614]
 [0.62 ]
 [0.62 ]
 [0.621]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04097447918649161, 0.9528256979223408, 0.0010796449759239803, 0.00512017791524358]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04075521231594825, 0.9530439997374397, 0.0010796641562158963, 0.005121123790396261]
Printing some Q and Qe and total Qs values:  [[0.658]
 [0.73 ]
 [0.657]
 [0.657]
 [0.657]
 [0.657]
 [0.662]] [[2.143]
 [2.926]
 [3.131]
 [3.131]
 [3.131]
 [3.131]
 [2.585]] [[0.167]
 [0.834]
 [0.824]
 [0.824]
 [0.824]
 [0.824]
 [0.47 ]]
Training Flag: True
Self play flag: True
resampling flag: False
add more workers flag:  False
expV_train_flag:  True
expV_train_start_flag:  10768
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04075521231594825, 0.9530439997374397, 0.0010796641562158963, 0.005121123790396261]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04053750082525547, 0.9532607530183539, 0.00107968320045151, 0.00512206295593909]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04053750082525547, 0.9532607530183539, 0.00107968320045151, 0.00512206295593909]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.04032132822316388, 0.9534759741837504, 0.0010797021100733878, 0.005122995483012162]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041552806266107044, 0.9521126385132511, 0.0010823227551379053, 0.0052522324655039435]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
Printing some Q and Qe and total Qs values:  [[0.75 ]
 [0.766]
 [0.651]
 [0.75 ]
 [0.75 ]
 [0.606]
 [0.707]] [[3.076]
 [3.363]
 [1.478]
 [3.076]
 [3.076]
 [1.092]
 [2.681]] [[1.219]
 [1.353]
 [0.455]
 [1.219]
 [1.219]
 [0.245]
 [1.008]]
Starting evaluation
Printing some Q and Qe and total Qs values:  [[0.744]
 [0.759]
 [0.744]
 [0.744]
 [0.744]
 [0.744]
 [0.76 ]] [[4.438]
 [4.184]
 [4.438]
 [4.438]
 [4.438]
 [4.438]
 [4.161]] [[2.068]
 [1.978]
 [2.068]
 [2.068]
 [2.068]
 [2.068]
 [1.969]]
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.42 ]
 [0.502]
 [0.42 ]
 [0.42 ]
 [0.42 ]
 [0.416]
 [0.457]] [[2.414]
 [2.122]
 [2.132]
 [2.414]
 [2.414]
 [2.153]
 [1.949]] [[0.42 ]
 [0.502]
 [0.42 ]
 [0.42 ]
 [0.42 ]
 [0.416]
 [0.457]]
line 256 mcts: sample exp_bonus 1.8229434405762208
using explorer policy with actor:  0
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041552806266107044, 0.9521126385132511, 0.0010823227551379053, 0.0052522324655039435]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041552806266107044, 0.9521126385132511, 0.0010823227551379053, 0.0052522324655039435]
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.56 ]
 [0.562]
 [0.766]
 [0.562]
 [0.546]
 [0.551]] [[3.557]
 [3.919]
 [3.459]
 [3.029]
 [3.459]
 [3.712]
 [3.766]] [[0.537]
 [0.56 ]
 [0.562]
 [0.766]
 [0.562]
 [0.546]
 [0.551]]
line 256 mcts: sample exp_bonus 0.6249557319513985
using explorer policy with actor:  0
Printing some Q and Qe and total Qs values:  [[0.537]
 [0.557]
 [0.288]
 [0.288]
 [0.288]
 [0.418]
 [0.604]] [[1.569]
 [1.92 ]
 [3.858]
 [3.858]
 [3.858]
 [1.664]
 [2.417]] [[0.537]
 [0.557]
 [0.288]
 [0.288]
 [0.288]
 [0.418]
 [0.604]]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041552806266107044, 0.9521126385132511, 0.0010823227551379053, 0.0052522324655039435]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041552806266107044, 0.9521126385132511, 0.0010823227551379053, 0.0052522324655039435]
line 256 mcts: sample exp_bonus 3.0274645463496044
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041552806266107044, 0.9521126385132511, 0.0010823227551379053, 0.0052522324655039435]
using explorer policy with actor:  1
using explorer policy with actor:  0
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041552806266107044, 0.9521126385132511, 0.0010823227551379053, 0.0052522324655039435]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041552806266107044, 0.9521126385132511, 0.0010823227551379053, 0.0052522324655039435]
maxi score, test score, baseline:  -0.99705 -1.0 -0.99705
probs:  [0.041552806266107044, 0.9521126385132511, 0.0010823227551379053, 0.0052522324655039435]
